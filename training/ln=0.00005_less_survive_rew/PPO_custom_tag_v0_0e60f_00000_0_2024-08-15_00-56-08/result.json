{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8643499178388131, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.538097694185045, "policy_loss": -0.005210361840996753, "vf_loss": 7.542072789126603, "vf_explained_var": 0.012022973683776049, "kl": 0.006176362853917001, "entropy": 1.603362873054686, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3073325613503735, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.427515083393723, "policy_loss": -0.005678890971713281, "vf_loss": 7.431321289930394, "vf_explained_var": 0.003977029506491606, "kl": 0.00936340295857537, "entropy": 1.6000664664323998, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 266.03999999999894, "episode_reward_min": -241.09000000000026, "episode_reward_mean": 20.239444444444498, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -303.52, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 167.29999999999973, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": -95.35250000000005, "predator_policy": 105.47222222222223}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-85.17000000000029, -10.499999999999961, 122.71000000000039, -103.93999999999951, -69.49999999999956, 87.87000000000123, -241.09000000000026, -77.27999999999966, -136.50000000000028, 266.03999999999894, 86.73000000000074, 129.67000000000004, 256.69999999999936, 60.480000000000594, -20.34999999999991, -19.55999999999993, 226.17999999999898, -108.17999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-163.93, -247.24000000000063, 12.529999999999973, -205.02999999999997, 2.0000000000000013, 21.709999999999862, -120.79000000000025, -229.15000000000055, -197.86000000000013, -126.6399999999993, -29.889999999999834, -46.240000000000265, -303.52, -229.57000000000008, 2.0000000000000013, -255.27999999999975, -229.51000000000045, -196.99000000000007, 167.29999999999973, -5.259999999999863, -154.78000000000026, 20.510000000000232, -188.2300000000007, 110.89999999999995, 156.05, -68.34999999999957, -142.7500000000001, 39.229999999999784, -269.34999999999974, 2.0000000000000013, -116.58999999999969, -192.97000000000008, 47.0299999999998, 122.15000000000008, -207.16000000000008, -209.01999999999998], "policy_predator_policy_reward": [186.0, 140.0, 161.0, 21.0, 61.0, 38.0, 55.0, 191.0, 157.0, 98.0, 103.0, 61.0, 136.0, 156.0, 2.0, 174.0, 145.0, 145.0, 87.0, 17.0, 151.0, 70.0, 151.0, 56.0, 27.0, 142.0, 140.0, 24.0, 63.0, 184.0, 128.0, 162.0, 4.0, 53.0, 135.0, 173.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1310795065004855, "mean_inference_ms": 2.903597936296399, "mean_action_processing_ms": 0.4305892158761115, "mean_env_wait_ms": 0.39485425338791674, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007960531446668837, "StateBufferConnector_ms": 0.00521805551317003, "ViewRequirementAgentConnector_ms": 0.2014511161380344}, "num_episodes": 18, "episode_return_max": 266.03999999999894, "episode_return_min": -241.09000000000026, "episode_return_mean": 20.239444444444498, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 314.2420052970739, "num_env_steps_trained_throughput_per_sec": 314.2420052970739, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 12729.051, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12729.0, "sample_time_ms": 2332.147, "learn_time_ms": 10380.804, "learn_throughput": 385.327, "synch_weights_time_ms": 12.719}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "0e60f_00000", "date": "2024-08-15_00-56-29", "timestamp": 1723663589, "time_this_iter_s": 12.79593300819397, "time_total_s": 12.79593300819397, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2abd790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12.79593300819397, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 46.88947368421053, "ram_util_percent": 83.78947368421052}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1490428347278525, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.747967459411218, "policy_loss": -0.006780063849627459, "vf_loss": 7.752949537045111, "vf_explained_var": 0.04180021024254895, "kl": 0.008990029991495344, "entropy": 1.5929854574026885, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3132560990632527, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.339371326234605, "policy_loss": -0.0068256481606069775, "vf_loss": 6.344495210445747, "vf_explained_var": 0.015211924516334735, "kl": 0.008508826729047705, "entropy": 1.5984066099716874, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 388.26, "episode_reward_min": -241.09000000000026, "episode_reward_mean": 83.63805555555558, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -303.52, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": -58.12541666666669, "predator_policy": 99.94444444444444}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-85.17000000000029, -10.499999999999961, 122.71000000000039, -103.93999999999951, -69.49999999999956, 87.87000000000123, -241.09000000000026, -77.27999999999966, -136.50000000000028, 266.03999999999894, 86.73000000000074, 129.67000000000004, 256.69999999999936, 60.480000000000594, -20.34999999999991, -19.55999999999993, 226.17999999999898, -108.17999999999999, 161.38000000000008, 157.9500000000001, 122.64000000000026, 145.62000000000012, 263.4199999999999, 179.44999999999914, 86.9800000000001, 96.01000000000002, 114.9700000000003, 104.72000000000004, 225.21999999999957, 34.94000000000019, 148.9000000000001, 136.49000000000012, 142.06000000000014, 388.26, 92.43000000000036, 45.220000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-163.93, -247.24000000000063, 12.529999999999973, -205.02999999999997, 2.0000000000000013, 21.709999999999862, -120.79000000000025, -229.15000000000055, -197.86000000000013, -126.6399999999993, -29.889999999999834, -46.240000000000265, -303.52, -229.57000000000008, 2.0000000000000013, -255.27999999999975, -229.51000000000045, -196.99000000000007, 167.29999999999973, -5.259999999999863, -154.78000000000026, 20.510000000000232, -188.2300000000007, 110.89999999999995, 156.05, -68.34999999999957, -142.7500000000001, 39.229999999999784, -269.34999999999974, 2.0000000000000013, -116.58999999999969, -192.97000000000008, 47.0299999999998, 122.15000000000008, -207.16000000000008, -209.01999999999998, -20.170000000000158, -1.4499999999999602, -275.95000000000005, 110.90000000000009, -85.80999999999999, -15.549999999999855, -184.93000000000092, 145.55, -65.64999999999989, 184.07, 120.4700000000002, -2.020000000000042, -18.099999999999763, -152.92000000000002, 0.47000000000008413, -60.459999999999766, 6.439999999999998, -92.46999999999923, 77.05999999999999, -267.3400000000003, -100.77999999999938, 200.0, -166.06000000000083, -76.0, -76.53999999999995, 69.44, 2.0000000000000013, 22.48999999999995, 2.0000000000000013, 17.060000000000016, 127.16, 190.09999999999997, -84.90999999999997, -94.65999999999984, -187.7800000000001, 2.0000000000000013], "policy_predator_policy_reward": [186.0, 140.0, 161.0, 21.0, 61.0, 38.0, 55.0, 191.0, 157.0, 98.0, 103.0, 61.0, 136.0, 156.0, 2.0, 174.0, 145.0, 145.0, 87.0, 17.0, 151.0, 70.0, 151.0, 56.0, 27.0, 142.0, 140.0, 24.0, 63.0, 184.0, 128.0, 162.0, 4.0, 53.0, 135.0, 173.0, 101.0, 82.0, 161.0, 162.0, 96.0, 128.0, 97.0, 88.0, 65.0, 80.0, 33.0, 28.0, 172.0, 86.0, 102.0, 54.0, 103.0, 98.0, 153.0, 142.0, 64.0, 62.0, 126.0, 151.0, 57.0, 99.0, 24.0, 88.0, 70.0, 53.0, 34.0, 37.0, 97.0, 175.0, 85.0, 146.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0817619655218733, "mean_inference_ms": 2.8377312974363145, "mean_action_processing_ms": 0.4148649651072919, "mean_env_wait_ms": 0.3874801492514595, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008717510435316298, "StateBufferConnector_ms": 0.004679958025614421, "ViewRequirementAgentConnector_ms": 0.19471711582607693}, "num_episodes": 18, "episode_return_max": 388.26, "episode_return_min": -241.09000000000026, "episode_return_mean": 83.63805555555558, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 326.68872940925576, "num_env_steps_trained_throughput_per_sec": 326.68872940925576, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 12486.623, "restore_workers_time_ms": 0.175, "training_step_time_ms": 12486.305, "sample_time_ms": 2214.947, "learn_time_ms": 10255.566, "learn_throughput": 390.032, "synch_weights_time_ms": 12.975}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "0e60f_00000", "date": "2024-08-15_00-56-45", "timestamp": 1723663605, "time_this_iter_s": 12.29400897026062, "time_total_s": 25.08994197845459, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2a9af70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 25.08994197845459, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 44.46190476190476, "ram_util_percent": 83.79047619047618}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4756722072287212, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.940488923542084, "policy_loss": -0.005772516152097119, "vf_loss": 8.944666372531305, "vf_explained_var": 0.07518884353536777, "kl": 0.00797527336911583, "entropy": 1.5781777773584638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7793934147193948, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.325949771568258, "policy_loss": -0.006429093245604129, "vf_loss": 6.330657700382212, "vf_explained_var": 0.0627370247134456, "kl": 0.008605753676178073, "entropy": 1.5936707033051385, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 388.26, "episode_reward_min": -241.09000000000026, "episode_reward_mean": 115.62481481481485, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -303.52, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": -33.76166666666667, "predator_policy": 91.57407407407408}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-85.17000000000029, -10.499999999999961, 122.71000000000039, -103.93999999999951, -69.49999999999956, 87.87000000000123, -241.09000000000026, -77.27999999999966, -136.50000000000028, 266.03999999999894, 86.73000000000074, 129.67000000000004, 256.69999999999936, 60.480000000000594, -20.34999999999991, -19.55999999999993, 226.17999999999898, -108.17999999999999, 161.38000000000008, 157.9500000000001, 122.64000000000026, 145.62000000000012, 263.4199999999999, 179.44999999999914, 86.9800000000001, 96.01000000000002, 114.9700000000003, 104.72000000000004, 225.21999999999957, 34.94000000000019, 148.9000000000001, 136.49000000000012, 142.06000000000014, 388.26, 92.43000000000036, 45.220000000000006, 137.93000000000035, 135.90000000000003, 78.25999999999995, 271.23999999999995, 301.5399999999999, 221.9699999999999, 210.9, 3.8999999999999133, 170.55999999999992, 177.88000000000017, 216.1900000000001, 348.8599999999998, 23.389999999999983, 379.6699999999999, 159.55, 239.41999999999967, 195.36999999999986, -39.75999999999925], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-163.93, -247.24000000000063, 12.529999999999973, -205.02999999999997, 2.0000000000000013, 21.709999999999862, -120.79000000000025, -229.15000000000055, -197.86000000000013, -126.6399999999993, -29.889999999999834, -46.240000000000265, -303.52, -229.57000000000008, 2.0000000000000013, -255.27999999999975, -229.51000000000045, -196.99000000000007, 167.29999999999973, -5.259999999999863, -154.78000000000026, 20.510000000000232, -188.2300000000007, 110.89999999999995, 156.05, -68.34999999999957, -142.7500000000001, 39.229999999999784, -269.34999999999974, 2.0000000000000013, -116.58999999999969, -192.97000000000008, 47.0299999999998, 122.15000000000008, -207.16000000000008, -209.01999999999998, -20.170000000000158, -1.4499999999999602, -275.95000000000005, 110.90000000000009, -85.80999999999999, -15.549999999999855, -184.93000000000092, 145.55, -65.64999999999989, 184.07, 120.4700000000002, -2.020000000000042, -18.099999999999763, -152.92000000000002, 0.47000000000008413, -60.459999999999766, 6.439999999999998, -92.46999999999923, 77.05999999999999, -267.3400000000003, -100.77999999999938, 200.0, -166.06000000000083, -76.0, -76.53999999999995, 69.44, 2.0000000000000013, 22.48999999999995, 2.0000000000000013, 17.060000000000016, 127.16, 190.09999999999997, -84.90999999999997, -94.65999999999984, -187.7800000000001, 2.0000000000000013, 56.93000000000015, 2.0000000000000013, -19.600000000000037, -32.499999999999915, 9.919999999999963, -61.659999999999826, -38.77000000000004, 130.01, 40.040000000000006, 150.49999999999991, 113.60000000000007, -25.629999999999818, -40.63000000000007, 123.52999999999993, -95.19999999999987, -61.89999999999999, 69.5599999999999, -73.0, -85.15000000000016, 131.03, 134.44999999999996, -59.25999999999996, 90.3800000000001, 146.4799999999999, 33.20000000000017, -253.81000000000006, 143.57000000000005, 133.10000000000002, -36.90999999999977, 100.45999999999997, -38.95000000000002, 40.37000000000016, 95.0, -61.62999999999988, -132.31000000000057, -88.44999999999932], "policy_predator_policy_reward": [186.0, 140.0, 161.0, 21.0, 61.0, 38.0, 55.0, 191.0, 157.0, 98.0, 103.0, 61.0, 136.0, 156.0, 2.0, 174.0, 145.0, 145.0, 87.0, 17.0, 151.0, 70.0, 151.0, 56.0, 27.0, 142.0, 140.0, 24.0, 63.0, 184.0, 128.0, 162.0, 4.0, 53.0, 135.0, 173.0, 101.0, 82.0, 161.0, 162.0, 96.0, 128.0, 97.0, 88.0, 65.0, 80.0, 33.0, 28.0, 172.0, 86.0, 102.0, 54.0, 103.0, 98.0, 153.0, 142.0, 64.0, 62.0, 126.0, 151.0, 57.0, 99.0, 24.0, 88.0, 70.0, 53.0, 34.0, 37.0, 97.0, 175.0, 85.0, 146.0, 54.0, 25.0, 57.0, 131.0, 111.0, 19.0, 57.0, 123.0, 80.0, 31.0, 103.0, 31.0, 27.0, 101.0, 56.0, 105.0, 88.0, 86.0, 79.0, 53.0, 118.0, 23.0, 57.0, 55.0, 142.0, 102.0, 50.0, 53.0, 32.0, 64.0, 135.0, 103.0, 99.0, 63.0, 72.0, 109.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0179454005964919, "mean_inference_ms": 2.693678327570997, "mean_action_processing_ms": 0.3931995344759508, "mean_env_wait_ms": 0.3669057458118848, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0078649432570846, "StateBufferConnector_ms": 0.004276522883662471, "ViewRequirementAgentConnector_ms": 0.1652359962463379}, "num_episodes": 18, "episode_return_max": 388.26, "episode_return_min": -241.09000000000026, "episode_return_mean": 115.62481481481485, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.42573780717134, "num_env_steps_trained_throughput_per_sec": 357.42573780717134, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 12054.799, "restore_workers_time_ms": 0.123, "training_step_time_ms": 12054.568, "sample_time_ms": 1896.379, "learn_time_ms": 10141.998, "learn_throughput": 394.4, "synch_weights_time_ms": 13.484}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "0e60f_00000", "date": "2024-08-15_00-56-56", "timestamp": 1723663616, "time_this_iter_s": 11.25100588798523, "time_total_s": 36.34094786643982, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2abd280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 36.34094786643982, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 38.9875, "ram_util_percent": 83.58125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.483973953868977, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.500455650450691, "policy_loss": -0.003484942528749348, "vf_loss": 9.50236964906965, "vf_explained_var": 0.021950821649460564, "kl": 0.007854780024706479, "entropy": 1.565431555490645, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6795438886319518, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.279613318014396, "policy_loss": -0.008430880211939218, "vf_loss": 8.285975634610212, "vf_explained_var": 0.03158398630127074, "kl": 0.010342722669241194, "entropy": 1.5726205909693682, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 388.26, "episode_reward_min": -241.09000000000026, "episode_reward_mean": 126.08583333333337, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -351.94000000000005, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 223.0}, "policy_reward_mean": {"prey_policy": -32.81125, "predator_policy": 95.85416666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-85.17000000000029, -10.499999999999961, 122.71000000000039, -103.93999999999951, -69.49999999999956, 87.87000000000123, -241.09000000000026, -77.27999999999966, -136.50000000000028, 266.03999999999894, 86.73000000000074, 129.67000000000004, 256.69999999999936, 60.480000000000594, -20.34999999999991, -19.55999999999993, 226.17999999999898, -108.17999999999999, 161.38000000000008, 157.9500000000001, 122.64000000000026, 145.62000000000012, 263.4199999999999, 179.44999999999914, 86.9800000000001, 96.01000000000002, 114.9700000000003, 104.72000000000004, 225.21999999999957, 34.94000000000019, 148.9000000000001, 136.49000000000012, 142.06000000000014, 388.26, 92.43000000000036, 45.220000000000006, 137.93000000000035, 135.90000000000003, 78.25999999999995, 271.23999999999995, 301.5399999999999, 221.9699999999999, 210.9, 3.8999999999999133, 170.55999999999992, 177.88000000000017, 216.1900000000001, 348.8599999999998, 23.389999999999983, 379.6699999999999, 159.55, 239.41999999999967, 195.36999999999986, -39.75999999999925, 106.60000000000005, 145.0, 108.90999999999995, 125.12000000000002, 162.70999999999998, 31.199999999999946, 220.31, 300.06999999999994, 94.03999999999999, 373.03999999999996, -59.07999999999997, -59.68999999999946, 353.2, 280.0399999999999, 292.17, 174.55999999999995, 164.0, 22.239999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-163.93, -247.24000000000063, 12.529999999999973, -205.02999999999997, 2.0000000000000013, 21.709999999999862, -120.79000000000025, -229.15000000000055, -197.86000000000013, -126.6399999999993, -29.889999999999834, -46.240000000000265, -303.52, -229.57000000000008, 2.0000000000000013, -255.27999999999975, -229.51000000000045, -196.99000000000007, 167.29999999999973, -5.259999999999863, -154.78000000000026, 20.510000000000232, -188.2300000000007, 110.89999999999995, 156.05, -68.34999999999957, -142.7500000000001, 39.229999999999784, -269.34999999999974, 2.0000000000000013, -116.58999999999969, -192.97000000000008, 47.0299999999998, 122.15000000000008, -207.16000000000008, -209.01999999999998, -20.170000000000158, -1.4499999999999602, -275.95000000000005, 110.90000000000009, -85.80999999999999, -15.549999999999855, -184.93000000000092, 145.55, -65.64999999999989, 184.07, 120.4700000000002, -2.020000000000042, -18.099999999999763, -152.92000000000002, 0.47000000000008413, -60.459999999999766, 6.439999999999998, -92.46999999999923, 77.05999999999999, -267.3400000000003, -100.77999999999938, 200.0, -166.06000000000083, -76.0, -76.53999999999995, 69.44, 2.0000000000000013, 22.48999999999995, 2.0000000000000013, 17.060000000000016, 127.16, 190.09999999999997, -84.90999999999997, -94.65999999999984, -187.7800000000001, 2.0000000000000013, 56.93000000000015, 2.0000000000000013, -19.600000000000037, -32.499999999999915, 9.919999999999963, -61.659999999999826, -38.77000000000004, 130.01, 40.040000000000006, 150.49999999999991, 113.60000000000007, -25.629999999999818, -40.63000000000007, 123.52999999999993, -95.19999999999987, -61.89999999999999, 69.5599999999999, -73.0, -85.15000000000016, 131.03, 134.44999999999996, -59.25999999999996, 90.3800000000001, 146.4799999999999, 33.20000000000017, -253.81000000000006, 143.57000000000005, 133.10000000000002, -36.90999999999977, 100.45999999999997, -38.95000000000002, 40.37000000000016, 95.0, -61.62999999999988, -132.31000000000057, -88.44999999999932, 38.359999999999985, -144.76000000000008, -163.0, 29.0, -78.6399999999998, 7.550000000000267, 82.04000000000002, -248.92000000000002, -44.13999999999959, 52.85, -145.56999999999988, -122.23000000000005, -95.91999999999997, 171.23, -22.95999999999998, 161.02999999999997, -12.969999999999999, -106.99000000000001, 106.03999999999999, 74.0, -103.69, -217.3899999999997, -43.750000000000234, -252.94000000000005, 119.12, 69.08000000000001, 112.88, -16.840000000000032, 13.010000000000005, 88.16, -137.49999999999994, 56.05999999999999, -16.0, 29.0, -351.94000000000005, 38.18000000000001], "policy_predator_policy_reward": [186.0, 140.0, 161.0, 21.0, 61.0, 38.0, 55.0, 191.0, 157.0, 98.0, 103.0, 61.0, 136.0, 156.0, 2.0, 174.0, 145.0, 145.0, 87.0, 17.0, 151.0, 70.0, 151.0, 56.0, 27.0, 142.0, 140.0, 24.0, 63.0, 184.0, 128.0, 162.0, 4.0, 53.0, 135.0, 173.0, 101.0, 82.0, 161.0, 162.0, 96.0, 128.0, 97.0, 88.0, 65.0, 80.0, 33.0, 28.0, 172.0, 86.0, 102.0, 54.0, 103.0, 98.0, 153.0, 142.0, 64.0, 62.0, 126.0, 151.0, 57.0, 99.0, 24.0, 88.0, 70.0, 53.0, 34.0, 37.0, 97.0, 175.0, 85.0, 146.0, 54.0, 25.0, 57.0, 131.0, 111.0, 19.0, 57.0, 123.0, 80.0, 31.0, 103.0, 31.0, 27.0, 101.0, 56.0, 105.0, 88.0, 86.0, 79.0, 53.0, 118.0, 23.0, 57.0, 55.0, 142.0, 102.0, 50.0, 53.0, 32.0, 64.0, 135.0, 103.0, 99.0, 63.0, 72.0, 109.0, 80.0, 133.0, 110.0, 169.0, 59.0, 121.0, 104.0, 188.0, 48.0, 106.0, 132.0, 167.0, 127.0, 18.0, 112.0, 50.0, 56.0, 158.0, 80.0, 113.0, 170.0, 92.0, 93.0, 144.0, 96.0, 69.0, 110.0, 74.0, 81.0, 110.0, 118.0, 138.0, 58.0, 93.0, 113.0, 223.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9760729144376019, "mean_inference_ms": 2.591075276695222, "mean_action_processing_ms": 0.37969390472028597, "mean_env_wait_ms": 0.35336318447147197, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010876523123847114, "StateBufferConnector_ms": 0.004086063967810737, "ViewRequirementAgentConnector_ms": 0.15524725119272867}, "num_episodes": 18, "episode_return_max": 388.26, "episode_return_min": -241.09000000000026, "episode_return_mean": 126.08583333333337, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 274.7034098527838, "num_env_steps_trained_throughput_per_sec": 274.7034098527838, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 12681.392, "restore_workers_time_ms": 0.095, "training_step_time_ms": 12681.207, "sample_time_ms": 1800.315, "learn_time_ms": 10857.053, "learn_throughput": 368.424, "synch_weights_time_ms": 19.257}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "0e60f_00000", "date": "2024-08-15_00-57-11", "timestamp": 1723663631, "time_this_iter_s": 14.66048288345337, "time_total_s": 51.00143074989319, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fc7a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 51.00143074989319, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 61.32857142857144, "ram_util_percent": 83.93333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6129831261735745, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.39753058852342, "policy_loss": -0.005059940824851827, "vf_loss": 9.400234114429939, "vf_explained_var": 0.0030584428991590226, "kl": 0.011782083939518663, "entropy": 1.5648366765370445, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7823137793591413, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.218918947694164, "policy_loss": -0.00362750166514642, "vf_loss": 9.22041867674974, "vf_explained_var": -0.018109283655408828, "kl": 0.010638742629130483, "entropy": 1.558823782552487, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 388.26, "episode_reward_min": -319.96000000000004, "episode_reward_mean": 106.1737373737374, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 223.0}, "policy_reward_mean": {"prey_policy": -56.00909090909091, "predator_policy": 109.0959595959596}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-85.17000000000029, -10.499999999999961, 122.71000000000039, -103.93999999999951, -69.49999999999956, 87.87000000000123, -241.09000000000026, -77.27999999999966, -136.50000000000028, 266.03999999999894, 86.73000000000074, 129.67000000000004, 256.69999999999936, 60.480000000000594, -20.34999999999991, -19.55999999999993, 226.17999999999898, -108.17999999999999, 161.38000000000008, 157.9500000000001, 122.64000000000026, 145.62000000000012, 263.4199999999999, 179.44999999999914, 86.9800000000001, 96.01000000000002, 114.9700000000003, 104.72000000000004, 225.21999999999957, 34.94000000000019, 148.9000000000001, 136.49000000000012, 142.06000000000014, 388.26, 92.43000000000036, 45.220000000000006, 137.93000000000035, 135.90000000000003, 78.25999999999995, 271.23999999999995, 301.5399999999999, 221.9699999999999, 210.9, 3.8999999999999133, 170.55999999999992, 177.88000000000017, 216.1900000000001, 348.8599999999998, 23.389999999999983, 379.6699999999999, 159.55, 239.41999999999967, 195.36999999999986, -39.75999999999925, 106.60000000000005, 145.0, 108.90999999999995, 125.12000000000002, 162.70999999999998, 31.199999999999946, 220.31, 300.06999999999994, 94.03999999999999, 373.03999999999996, -59.07999999999997, -59.68999999999946, 353.2, 280.0399999999999, 292.17, 174.55999999999995, 164.0, 22.239999999999995, 214.60000000000002, -119.77000000000004, -128.80999999999997, -87.5999999999998, -185.91, 297.08, 42.080000000000155, 304.1999999999998, -73.99000000000001, 315.17999999999995, -197.2599999999997, -91.57999999999998, 227.7899999999998, -319.96000000000004, 40.06999999999999, 279.02, 83.48000000000003, 26.110000000000007, 311.44, 180.12, 96.01000000000003, 70.83999999999989, 162.96000000000004, 62.44999999999996, -191.61, -85.91000000000001, 201.99], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-163.93, -247.24000000000063, 12.529999999999973, -205.02999999999997, 2.0000000000000013, 21.709999999999862, -120.79000000000025, -229.15000000000055, -197.86000000000013, -126.6399999999993, -29.889999999999834, -46.240000000000265, -303.52, -229.57000000000008, 2.0000000000000013, -255.27999999999975, -229.51000000000045, -196.99000000000007, 167.29999999999973, -5.259999999999863, -154.78000000000026, 20.510000000000232, -188.2300000000007, 110.89999999999995, 156.05, -68.34999999999957, -142.7500000000001, 39.229999999999784, -269.34999999999974, 2.0000000000000013, -116.58999999999969, -192.97000000000008, 47.0299999999998, 122.15000000000008, -207.16000000000008, -209.01999999999998, -20.170000000000158, -1.4499999999999602, -275.95000000000005, 110.90000000000009, -85.80999999999999, -15.549999999999855, -184.93000000000092, 145.55, -65.64999999999989, 184.07, 120.4700000000002, -2.020000000000042, -18.099999999999763, -152.92000000000002, 0.47000000000008413, -60.459999999999766, 6.439999999999998, -92.46999999999923, 77.05999999999999, -267.3400000000003, -100.77999999999938, 200.0, -166.06000000000083, -76.0, -76.53999999999995, 69.44, 2.0000000000000013, 22.48999999999995, 2.0000000000000013, 17.060000000000016, 127.16, 190.09999999999997, -84.90999999999997, -94.65999999999984, -187.7800000000001, 2.0000000000000013, 56.93000000000015, 2.0000000000000013, -19.600000000000037, -32.499999999999915, 9.919999999999963, -61.659999999999826, -38.77000000000004, 130.01, 40.040000000000006, 150.49999999999991, 113.60000000000007, -25.629999999999818, -40.63000000000007, 123.52999999999993, -95.19999999999987, -61.89999999999999, 69.5599999999999, -73.0, -85.15000000000016, 131.03, 134.44999999999996, -59.25999999999996, 90.3800000000001, 146.4799999999999, 33.20000000000017, -253.81000000000006, 143.57000000000005, 133.10000000000002, -36.90999999999977, 100.45999999999997, -38.95000000000002, 40.37000000000016, 95.0, -61.62999999999988, -132.31000000000057, -88.44999999999932, 38.359999999999985, -144.76000000000008, -163.0, 29.0, -78.6399999999998, 7.550000000000267, 82.04000000000002, -248.92000000000002, -44.13999999999959, 52.85, -145.56999999999988, -122.23000000000005, -95.91999999999997, 171.23, -22.95999999999998, 161.02999999999997, -12.969999999999999, -106.99000000000001, 106.03999999999999, 74.0, -103.69, -217.3899999999997, -43.750000000000234, -252.94000000000005, 119.12, 69.08000000000001, 112.88, -16.840000000000032, 13.010000000000005, 88.16, -137.49999999999994, 56.05999999999999, -16.0, 29.0, -351.94000000000005, 38.18000000000001, -57.429999999999794, 86.03, -313.9000000000001, -160.87, -292.0, -202.80999999999997, -87.66999999999983, -283.93, -187.0, -369.90999999999997, 17.0, 78.08, -23.589999999999804, -181.33000000000015, -47.82999999999993, 194.02999999999997, -139.99, -271.0, 149.09000000000003, -36.909999999999954, -273.66999999999996, -263.5900000000004, -263.77000000000004, -211.81, 68.6, 1.1899999999999977, -379.0, -340.96000000000004, -205.0, -79.93, 33.019999999999996, 116.0, -49.65999999999984, -197.85999999999999, -196.96000000000004, -118.93, 169.31, -145.87, -64.0, 44.120000000000005, -215.64999999999998, -30.339999999999932, -211.92999999999998, 0.7699999999998681, -155.80000000000004, 13.759999999999998, -85.62999999999984, -140.92, -266.62, -277.99, -214.0, -237.91000000000003, 39.620000000000005, -91.63000000000002], "policy_predator_policy_reward": [186.0, 140.0, 161.0, 21.0, 61.0, 38.0, 55.0, 191.0, 157.0, 98.0, 103.0, 61.0, 136.0, 156.0, 2.0, 174.0, 145.0, 145.0, 87.0, 17.0, 151.0, 70.0, 151.0, 56.0, 27.0, 142.0, 140.0, 24.0, 63.0, 184.0, 128.0, 162.0, 4.0, 53.0, 135.0, 173.0, 101.0, 82.0, 161.0, 162.0, 96.0, 128.0, 97.0, 88.0, 65.0, 80.0, 33.0, 28.0, 172.0, 86.0, 102.0, 54.0, 103.0, 98.0, 153.0, 142.0, 64.0, 62.0, 126.0, 151.0, 57.0, 99.0, 24.0, 88.0, 70.0, 53.0, 34.0, 37.0, 97.0, 175.0, 85.0, 146.0, 54.0, 25.0, 57.0, 131.0, 111.0, 19.0, 57.0, 123.0, 80.0, 31.0, 103.0, 31.0, 27.0, 101.0, 56.0, 105.0, 88.0, 86.0, 79.0, 53.0, 118.0, 23.0, 57.0, 55.0, 142.0, 102.0, 50.0, 53.0, 32.0, 64.0, 135.0, 103.0, 99.0, 63.0, 72.0, 109.0, 80.0, 133.0, 110.0, 169.0, 59.0, 121.0, 104.0, 188.0, 48.0, 106.0, 132.0, 167.0, 127.0, 18.0, 112.0, 50.0, 56.0, 158.0, 80.0, 113.0, 170.0, 92.0, 93.0, 144.0, 96.0, 69.0, 110.0, 74.0, 81.0, 110.0, 118.0, 138.0, 58.0, 93.0, 113.0, 223.0, 92.0, 94.0, 182.0, 173.0, 200.0, 166.0, 102.0, 182.0, 194.0, 177.0, 122.0, 80.0, 178.0, 69.0, 77.0, 81.0, 189.0, 148.0, 127.0, 76.0, 184.0, 156.0, 193.0, 191.0, 123.0, 35.0, 200.0, 200.0, 146.0, 179.0, 88.0, 42.0, 178.0, 153.0, 183.0, 159.0, 114.0, 174.0, 139.0, 61.0, 181.0, 161.0, 187.0, 95.0, 171.0, 134.0, 150.0, 139.0, 175.0, 178.0, 167.0, 199.0, 161.0, 93.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9891737688793384, "mean_inference_ms": 2.6357059087296597, "mean_action_processing_ms": 0.3812356502510883, "mean_env_wait_ms": 0.3583698586626617, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014876596855394768, "StateBufferConnector_ms": 0.004365468266034367, "ViewRequirementAgentConnector_ms": 0.23250483503245345}, "num_episodes": 27, "episode_return_max": 388.26, "episode_return_min": -319.96000000000004, "episode_return_mean": 106.1737373737374, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.81212023836707, "num_env_steps_trained_throughput_per_sec": 197.81212023836707, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 14189.358, "restore_workers_time_ms": 0.079, "training_step_time_ms": 14189.199, "sample_time_ms": 2148.325, "learn_time_ms": 12016.46, "learn_throughput": 332.877, "synch_weights_time_ms": 19.666}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "0e60f_00000", "date": "2024-08-15_00-57-31", "timestamp": 1723663651, "time_this_iter_s": 20.282378911972046, "time_total_s": 71.28380966186523, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2b014c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 71.28380966186523, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 84.57241379310348, "ram_util_percent": 84.14827586206897}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6290393512242685, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.449530761960952, "policy_loss": -0.0032844401840564042, "vf_loss": 9.451171944633362, "vf_explained_var": -0.020239351256183848, "kl": 0.008216252397758687, "entropy": 1.5434397739077372, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2295183563989305, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.006214934051352, "policy_loss": -0.015004749770803506, "vf_loss": 9.017396482841047, "vf_explained_var": 0.018264767480274988, "kl": 0.01911597798833039, "entropy": 1.5081836750267674, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 388.26, "episode_reward_min": -319.96000000000004, "episode_reward_mean": 101.49439999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 18.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 223.0}, "policy_reward_mean": {"prey_policy": -66.2728, "predator_policy": 117.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-108.17999999999999, 161.38000000000008, 157.9500000000001, 122.64000000000026, 145.62000000000012, 263.4199999999999, 179.44999999999914, 86.9800000000001, 96.01000000000002, 114.9700000000003, 104.72000000000004, 225.21999999999957, 34.94000000000019, 148.9000000000001, 136.49000000000012, 142.06000000000014, 388.26, 92.43000000000036, 45.220000000000006, 137.93000000000035, 135.90000000000003, 78.25999999999995, 271.23999999999995, 301.5399999999999, 221.9699999999999, 210.9, 3.8999999999999133, 170.55999999999992, 177.88000000000017, 216.1900000000001, 348.8599999999998, 23.389999999999983, 379.6699999999999, 159.55, 239.41999999999967, 195.36999999999986, -39.75999999999925, 106.60000000000005, 145.0, 108.90999999999995, 125.12000000000002, 162.70999999999998, 31.199999999999946, 220.31, 300.06999999999994, 94.03999999999999, 373.03999999999996, -59.07999999999997, -59.68999999999946, 353.2, 280.0399999999999, 292.17, 174.55999999999995, 164.0, 22.239999999999995, 214.60000000000002, -119.77000000000004, -128.80999999999997, -87.5999999999998, -185.91, 297.08, 42.080000000000155, 304.1999999999998, -73.99000000000001, 315.17999999999995, -197.2599999999997, -91.57999999999998, 227.7899999999998, -319.96000000000004, 40.06999999999999, 279.02, 83.48000000000003, 26.110000000000007, 311.44, 180.12, 96.01000000000003, 70.83999999999989, 162.96000000000004, 62.44999999999996, -191.61, -85.91000000000001, 201.99, 13.130000000000003, -111.96000000000001, -161.5700000000001, -136.18999999999966, -25.390000000000065, 95.23000000000005, -55.0, -237.5399999999999, -186.60000000000008, -63.179999999999964, 108.08000000000004, 8.18000000000001, 193.26, 136.11000000000004, 155.31999999999996, 180.5799999999997, 225.63999999999987, -27.370000000000033], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-207.16000000000008, -209.01999999999998, -20.170000000000158, -1.4499999999999602, -275.95000000000005, 110.90000000000009, -85.80999999999999, -15.549999999999855, -184.93000000000092, 145.55, -65.64999999999989, 184.07, 120.4700000000002, -2.020000000000042, -18.099999999999763, -152.92000000000002, 0.47000000000008413, -60.459999999999766, 6.439999999999998, -92.46999999999923, 77.05999999999999, -267.3400000000003, -100.77999999999938, 200.0, -166.06000000000083, -76.0, -76.53999999999995, 69.44, 2.0000000000000013, 22.48999999999995, 2.0000000000000013, 17.060000000000016, 127.16, 190.09999999999997, -84.90999999999997, -94.65999999999984, -187.7800000000001, 2.0000000000000013, 56.93000000000015, 2.0000000000000013, -19.600000000000037, -32.499999999999915, 9.919999999999963, -61.659999999999826, -38.77000000000004, 130.01, 40.040000000000006, 150.49999999999991, 113.60000000000007, -25.629999999999818, -40.63000000000007, 123.52999999999993, -95.19999999999987, -61.89999999999999, 69.5599999999999, -73.0, -85.15000000000016, 131.03, 134.44999999999996, -59.25999999999996, 90.3800000000001, 146.4799999999999, 33.20000000000017, -253.81000000000006, 143.57000000000005, 133.10000000000002, -36.90999999999977, 100.45999999999997, -38.95000000000002, 40.37000000000016, 95.0, -61.62999999999988, -132.31000000000057, -88.44999999999932, 38.359999999999985, -144.76000000000008, -163.0, 29.0, -78.6399999999998, 7.550000000000267, 82.04000000000002, -248.92000000000002, -44.13999999999959, 52.85, -145.56999999999988, -122.23000000000005, -95.91999999999997, 171.23, -22.95999999999998, 161.02999999999997, -12.969999999999999, -106.99000000000001, 106.03999999999999, 74.0, -103.69, -217.3899999999997, -43.750000000000234, -252.94000000000005, 119.12, 69.08000000000001, 112.88, -16.840000000000032, 13.010000000000005, 88.16, -137.49999999999994, 56.05999999999999, -16.0, 29.0, -351.94000000000005, 38.18000000000001, -57.429999999999794, 86.03, -313.9000000000001, -160.87, -292.0, -202.80999999999997, -87.66999999999983, -283.93, -187.0, -369.90999999999997, 17.0, 78.08, -23.589999999999804, -181.33000000000015, -47.82999999999993, 194.02999999999997, -139.99, -271.0, 149.09000000000003, -36.909999999999954, -273.66999999999996, -263.5900000000004, -263.77000000000004, -211.81, 68.6, 1.1899999999999977, -379.0, -340.96000000000004, -205.0, -79.93, 33.019999999999996, 116.0, -49.65999999999984, -197.85999999999999, -196.96000000000004, -118.93, 169.31, -145.87, -64.0, 44.120000000000005, -215.64999999999998, -30.339999999999932, -211.92999999999998, 0.7699999999998681, -155.80000000000004, 13.759999999999998, -85.62999999999984, -140.92, -266.62, -277.99, -214.0, -237.91000000000003, 39.620000000000005, -91.63000000000002, -28.930000000000007, -219.94000000000005, -209.98000000000002, -209.98000000000002, -268.78, -261.79000000000013, -152.22999999999968, -337.96000000000004, -176.59000000000003, -152.800000000001, -157.96, -52.809999999999945, -181.0, -223.0, -350.95000000000005, -239.58999999999986, -247.0, -205.60000000000014, -134.35000000000016, -239.83, -133.0, -2.919999999999959, -144.82, -97.0, 74.18000000000006, -173.92000000000002, -89.88999999999996, -25.0, -5.920000000000007, -165.76, -149.58999999999997, 51.16999999999999, 71.57, 16.06999999999999, -283.0, -72.36999999999992], "policy_predator_policy_reward": [135.0, 173.0, 101.0, 82.0, 161.0, 162.0, 96.0, 128.0, 97.0, 88.0, 65.0, 80.0, 33.0, 28.0, 172.0, 86.0, 102.0, 54.0, 103.0, 98.0, 153.0, 142.0, 64.0, 62.0, 126.0, 151.0, 57.0, 99.0, 24.0, 88.0, 70.0, 53.0, 34.0, 37.0, 97.0, 175.0, 85.0, 146.0, 54.0, 25.0, 57.0, 131.0, 111.0, 19.0, 57.0, 123.0, 80.0, 31.0, 103.0, 31.0, 27.0, 101.0, 56.0, 105.0, 88.0, 86.0, 79.0, 53.0, 118.0, 23.0, 57.0, 55.0, 142.0, 102.0, 50.0, 53.0, 32.0, 64.0, 135.0, 103.0, 99.0, 63.0, 72.0, 109.0, 80.0, 133.0, 110.0, 169.0, 59.0, 121.0, 104.0, 188.0, 48.0, 106.0, 132.0, 167.0, 127.0, 18.0, 112.0, 50.0, 56.0, 158.0, 80.0, 113.0, 170.0, 92.0, 93.0, 144.0, 96.0, 69.0, 110.0, 74.0, 81.0, 110.0, 118.0, 138.0, 58.0, 93.0, 113.0, 223.0, 92.0, 94.0, 182.0, 173.0, 200.0, 166.0, 102.0, 182.0, 194.0, 177.0, 122.0, 80.0, 178.0, 69.0, 77.0, 81.0, 189.0, 148.0, 127.0, 76.0, 184.0, 156.0, 193.0, 191.0, 123.0, 35.0, 200.0, 200.0, 146.0, 179.0, 88.0, 42.0, 178.0, 153.0, 183.0, 159.0, 114.0, 174.0, 139.0, 61.0, 181.0, 161.0, 187.0, 95.0, 171.0, 134.0, 150.0, 139.0, 175.0, 178.0, 167.0, 199.0, 161.0, 93.0, 183.0, 79.0, 158.0, 150.0, 200.0, 169.0, 177.0, 177.0, 133.0, 171.0, 162.0, 144.0, 185.0, 164.0, 200.0, 153.0, 68.0, 198.0, 120.0, 191.0, 88.0, 156.0, 57.0, 193.0, 172.0, 121.0, 98.0, 153.0, 153.0, 174.0, 142.0, 137.0, 21.0, 117.0, 172.0, 156.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9764549798302073, "mean_inference_ms": 2.6251227238930204, "mean_action_processing_ms": 0.3745709591584726, "mean_env_wait_ms": 0.35771078808098866, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016883373260498047, "StateBufferConnector_ms": 0.004138469696044922, "ViewRequirementAgentConnector_ms": 0.2358003854751587}, "num_episodes": 18, "episode_return_max": 388.26, "episode_return_min": -319.96000000000004, "episode_return_mean": 101.49439999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 304.0013524687855, "num_env_steps_trained_throughput_per_sec": 304.0013524687855, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 14017.44, "restore_workers_time_ms": 0.068, "training_step_time_ms": 14017.299, "sample_time_ms": 2212.382, "learn_time_ms": 11782.412, "learn_throughput": 339.489, "synch_weights_time_ms": 18.341}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "0e60f_00000", "date": "2024-08-15_00-57-44", "timestamp": 1723663664, "time_this_iter_s": 13.193396091461182, "time_total_s": 84.47720575332642, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2b01700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 84.47720575332642, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 59.51052631578946, "ram_util_percent": 83.17368421052632}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.089425017310198, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.627693397027475, "policy_loss": -0.007137712278950309, "vf_loss": 8.632153693708792, "vf_explained_var": -0.04138085135707149, "kl": 0.013387069652708207, "entropy": 1.5473672255006417, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3398522507261346, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.919125438871838, "policy_loss": -0.009308145883143264, "vf_loss": 8.925807595631433, "vf_explained_var": -0.03502069850447317, "kl": 0.01312988249489053, "entropy": 1.522994094361704, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 379.6699999999999, "episode_reward_min": -319.96000000000004, "episode_reward_mean": 82.68610000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 18.0}, "policy_reward_max": {"prey_policy": 194.02999999999997, "predator_policy": 223.0}, "policy_reward_mean": {"prey_policy": -82.71695, "predator_policy": 124.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.220000000000006, 137.93000000000035, 135.90000000000003, 78.25999999999995, 271.23999999999995, 301.5399999999999, 221.9699999999999, 210.9, 3.8999999999999133, 170.55999999999992, 177.88000000000017, 216.1900000000001, 348.8599999999998, 23.389999999999983, 379.6699999999999, 159.55, 239.41999999999967, 195.36999999999986, -39.75999999999925, 106.60000000000005, 145.0, 108.90999999999995, 125.12000000000002, 162.70999999999998, 31.199999999999946, 220.31, 300.06999999999994, 94.03999999999999, 373.03999999999996, -59.07999999999997, -59.68999999999946, 353.2, 280.0399999999999, 292.17, 174.55999999999995, 164.0, 22.239999999999995, 214.60000000000002, -119.77000000000004, -128.80999999999997, -87.5999999999998, -185.91, 297.08, 42.080000000000155, 304.1999999999998, -73.99000000000001, 315.17999999999995, -197.2599999999997, -91.57999999999998, 227.7899999999998, -319.96000000000004, 40.06999999999999, 279.02, 83.48000000000003, 26.110000000000007, 311.44, 180.12, 96.01000000000003, 70.83999999999989, 162.96000000000004, 62.44999999999996, -191.61, -85.91000000000001, 201.99, 13.130000000000003, -111.96000000000001, -161.5700000000001, -136.18999999999966, -25.390000000000065, 95.23000000000005, -55.0, -237.5399999999999, -186.60000000000008, -63.179999999999964, 108.08000000000004, 8.18000000000001, 193.26, 136.11000000000004, 155.31999999999996, 180.5799999999997, 225.63999999999987, -27.370000000000033, 70.83000000000055, 13.1899999999999, -2.8600000000000385, -85.22999999999999, 155.47999999999982, 89.22000000000044, 110.12000000000049, 72.40000000000035, 8.480000000000008, -91.78000000000003, 91.18000000000039, 101.8500000000003, 57.67999999999968, -143.72, -11.120000000000038, 108.46000000000039, 89.07000000000035, -20.819999999999734], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-187.7800000000001, 2.0000000000000013, 56.93000000000015, 2.0000000000000013, -19.600000000000037, -32.499999999999915, 9.919999999999963, -61.659999999999826, -38.77000000000004, 130.01, 40.040000000000006, 150.49999999999991, 113.60000000000007, -25.629999999999818, -40.63000000000007, 123.52999999999993, -95.19999999999987, -61.89999999999999, 69.5599999999999, -73.0, -85.15000000000016, 131.03, 134.44999999999996, -59.25999999999996, 90.3800000000001, 146.4799999999999, 33.20000000000017, -253.81000000000006, 143.57000000000005, 133.10000000000002, -36.90999999999977, 100.45999999999997, -38.95000000000002, 40.37000000000016, 95.0, -61.62999999999988, -132.31000000000057, -88.44999999999932, 38.359999999999985, -144.76000000000008, -163.0, 29.0, -78.6399999999998, 7.550000000000267, 82.04000000000002, -248.92000000000002, -44.13999999999959, 52.85, -145.56999999999988, -122.23000000000005, -95.91999999999997, 171.23, -22.95999999999998, 161.02999999999997, -12.969999999999999, -106.99000000000001, 106.03999999999999, 74.0, -103.69, -217.3899999999997, -43.750000000000234, -252.94000000000005, 119.12, 69.08000000000001, 112.88, -16.840000000000032, 13.010000000000005, 88.16, -137.49999999999994, 56.05999999999999, -16.0, 29.0, -351.94000000000005, 38.18000000000001, -57.429999999999794, 86.03, -313.9000000000001, -160.87, -292.0, -202.80999999999997, -87.66999999999983, -283.93, -187.0, -369.90999999999997, 17.0, 78.08, -23.589999999999804, -181.33000000000015, -47.82999999999993, 194.02999999999997, -139.99, -271.0, 149.09000000000003, -36.909999999999954, -273.66999999999996, -263.5900000000004, -263.77000000000004, -211.81, 68.6, 1.1899999999999977, -379.0, -340.96000000000004, -205.0, -79.93, 33.019999999999996, 116.0, -49.65999999999984, -197.85999999999999, -196.96000000000004, -118.93, 169.31, -145.87, -64.0, 44.120000000000005, -215.64999999999998, -30.339999999999932, -211.92999999999998, 0.7699999999998681, -155.80000000000004, 13.759999999999998, -85.62999999999984, -140.92, -266.62, -277.99, -214.0, -237.91000000000003, 39.620000000000005, -91.63000000000002, -28.930000000000007, -219.94000000000005, -209.98000000000002, -209.98000000000002, -268.78, -261.79000000000013, -152.22999999999968, -337.96000000000004, -176.59000000000003, -152.800000000001, -157.96, -52.809999999999945, -181.0, -223.0, -350.95000000000005, -239.58999999999986, -247.0, -205.60000000000014, -134.35000000000016, -239.83, -133.0, -2.919999999999959, -144.82, -97.0, 74.18000000000006, -173.92000000000002, -89.88999999999996, -25.0, -5.920000000000007, -165.76, -149.58999999999997, 51.16999999999999, 71.57, 16.06999999999999, -283.0, -72.36999999999992, 10.099999999999806, -175.27000000000066, -158.8900000000002, -71.92000000000002, -140.44000000000028, -109.41999999999976, -296.77, -171.4600000000001, -34.09000000000002, -129.42999999999992, -120.72999999999993, -95.05000000000001, -34.30000000000009, -102.5799999999998, -109.5999999999998, 2.0000000000000013, -81.84999999999941, -183.6700000000003, -162.83999999999946, -309.94, 41.47999999999994, -205.30000000000058, 31.670000000000144, -237.82000000000016, -102.99999999999949, 0.68, -215.76999999999998, -308.95, -202.6000000000002, -93.52000000000004, 0.1700000000000088, -29.709999999999802, 43.90999999999986, -289.84000000000015, -174.94000000000088, -51.880000000000194], "policy_predator_policy_reward": [85.0, 146.0, 54.0, 25.0, 57.0, 131.0, 111.0, 19.0, 57.0, 123.0, 80.0, 31.0, 103.0, 31.0, 27.0, 101.0, 56.0, 105.0, 88.0, 86.0, 79.0, 53.0, 118.0, 23.0, 57.0, 55.0, 142.0, 102.0, 50.0, 53.0, 32.0, 64.0, 135.0, 103.0, 99.0, 63.0, 72.0, 109.0, 80.0, 133.0, 110.0, 169.0, 59.0, 121.0, 104.0, 188.0, 48.0, 106.0, 132.0, 167.0, 127.0, 18.0, 112.0, 50.0, 56.0, 158.0, 80.0, 113.0, 170.0, 92.0, 93.0, 144.0, 96.0, 69.0, 110.0, 74.0, 81.0, 110.0, 118.0, 138.0, 58.0, 93.0, 113.0, 223.0, 92.0, 94.0, 182.0, 173.0, 200.0, 166.0, 102.0, 182.0, 194.0, 177.0, 122.0, 80.0, 178.0, 69.0, 77.0, 81.0, 189.0, 148.0, 127.0, 76.0, 184.0, 156.0, 193.0, 191.0, 123.0, 35.0, 200.0, 200.0, 146.0, 179.0, 88.0, 42.0, 178.0, 153.0, 183.0, 159.0, 114.0, 174.0, 139.0, 61.0, 181.0, 161.0, 187.0, 95.0, 171.0, 134.0, 150.0, 139.0, 175.0, 178.0, 167.0, 199.0, 161.0, 93.0, 183.0, 79.0, 158.0, 150.0, 200.0, 169.0, 177.0, 177.0, 133.0, 171.0, 162.0, 144.0, 185.0, 164.0, 200.0, 153.0, 68.0, 198.0, 120.0, 191.0, 88.0, 156.0, 57.0, 193.0, 172.0, 121.0, 98.0, 153.0, 153.0, 174.0, 142.0, 137.0, 21.0, 117.0, 172.0, 156.0, 91.0, 145.0, 101.0, 143.0, 119.0, 128.0, 193.0, 190.0, 141.0, 178.0, 196.0, 109.0, 144.0, 103.0, 62.0, 118.0, 123.0, 151.0, 175.0, 206.0, 135.0, 120.0, 158.0, 150.0, 26.0, 134.0, 195.0, 186.0, 100.0, 185.0, 105.0, 33.0, 167.0, 168.0, 104.0, 102.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9681692963001787, "mean_inference_ms": 2.6043380615275824, "mean_action_processing_ms": 0.37054186254749355, "mean_env_wait_ms": 0.35523479491400123, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015825271606445312, "StateBufferConnector_ms": 0.00391995906829834, "ViewRequirementAgentConnector_ms": 0.21884393692016602}, "num_episodes": 18, "episode_return_max": 379.6699999999999, "episode_return_min": -319.96000000000004, "episode_return_mean": 82.68610000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.8753999118738, "num_env_steps_trained_throughput_per_sec": 340.8753999118738, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 13691.307, "restore_workers_time_ms": 0.06, "training_step_time_ms": 13691.179, "sample_time_ms": 2083.384, "learn_time_ms": 11586.506, "learn_throughput": 345.229, "synch_weights_time_ms": 17.492}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "0e60f_00000", "date": "2024-08-15_00-57-56", "timestamp": 1723663676, "time_this_iter_s": 11.770299911499023, "time_total_s": 96.24750566482544, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fcb5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 96.24750566482544, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 50.775, "ram_util_percent": 83.11875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9280869985068285, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.468245095298403, "policy_loss": -0.008934860738122432, "vf_loss": 7.475153850626063, "vf_explained_var": -0.02429888223214124, "kl": 0.010130531535517467, "entropy": 1.5586483817251902, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.169331455798376, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.034194359955965, "policy_loss": -0.008301253278281481, "vf_loss": 9.040358829498292, "vf_explained_var": -0.05666129371476552, "kl": 0.010683892449955174, "entropy": 1.5102263139669228, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 373.03999999999996, "episode_reward_min": -319.96000000000004, "episode_reward_mean": 44.323200000000035, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.02999999999997, "predator_policy": 223.0}, "policy_reward_mean": {"prey_policy": -113.90840000000004, "predator_policy": 136.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-39.75999999999925, 106.60000000000005, 145.0, 108.90999999999995, 125.12000000000002, 162.70999999999998, 31.199999999999946, 220.31, 300.06999999999994, 94.03999999999999, 373.03999999999996, -59.07999999999997, -59.68999999999946, 353.2, 280.0399999999999, 292.17, 174.55999999999995, 164.0, 22.239999999999995, 214.60000000000002, -119.77000000000004, -128.80999999999997, -87.5999999999998, -185.91, 297.08, 42.080000000000155, 304.1999999999998, -73.99000000000001, 315.17999999999995, -197.2599999999997, -91.57999999999998, 227.7899999999998, -319.96000000000004, 40.06999999999999, 279.02, 83.48000000000003, 26.110000000000007, 311.44, 180.12, 96.01000000000003, 70.83999999999989, 162.96000000000004, 62.44999999999996, -191.61, -85.91000000000001, 201.99, 13.130000000000003, -111.96000000000001, -161.5700000000001, -136.18999999999966, -25.390000000000065, 95.23000000000005, -55.0, -237.5399999999999, -186.60000000000008, -63.179999999999964, 108.08000000000004, 8.18000000000001, 193.26, 136.11000000000004, 155.31999999999996, 180.5799999999997, 225.63999999999987, -27.370000000000033, 70.83000000000055, 13.1899999999999, -2.8600000000000385, -85.22999999999999, 155.47999999999982, 89.22000000000044, 110.12000000000049, 72.40000000000035, 8.480000000000008, -91.78000000000003, 91.18000000000039, 101.8500000000003, 57.67999999999968, -143.72, -11.120000000000038, 108.46000000000039, 89.07000000000035, -20.819999999999734, 16.129999999999953, -2.4800000000002917, -110.22999999999999, -13.759999999999971, -184.6300000000001, 66.0100000000002, 36.18000000000012, -83.40999999999923, -203.2300000000003, 4.340000000000091, -194.85000000000014, 72.71000000000004, -124.86000000000001, 88.16000000000064, 87.66000000000027, 11.399999999999986, -38.749999999999986, 55.069999999999816], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-132.31000000000057, -88.44999999999932, 38.359999999999985, -144.76000000000008, -163.0, 29.0, -78.6399999999998, 7.550000000000267, 82.04000000000002, -248.92000000000002, -44.13999999999959, 52.85, -145.56999999999988, -122.23000000000005, -95.91999999999997, 171.23, -22.95999999999998, 161.02999999999997, -12.969999999999999, -106.99000000000001, 106.03999999999999, 74.0, -103.69, -217.3899999999997, -43.750000000000234, -252.94000000000005, 119.12, 69.08000000000001, 112.88, -16.840000000000032, 13.010000000000005, 88.16, -137.49999999999994, 56.05999999999999, -16.0, 29.0, -351.94000000000005, 38.18000000000001, -57.429999999999794, 86.03, -313.9000000000001, -160.87, -292.0, -202.80999999999997, -87.66999999999983, -283.93, -187.0, -369.90999999999997, 17.0, 78.08, -23.589999999999804, -181.33000000000015, -47.82999999999993, 194.02999999999997, -139.99, -271.0, 149.09000000000003, -36.909999999999954, -273.66999999999996, -263.5900000000004, -263.77000000000004, -211.81, 68.6, 1.1899999999999977, -379.0, -340.96000000000004, -205.0, -79.93, 33.019999999999996, 116.0, -49.65999999999984, -197.85999999999999, -196.96000000000004, -118.93, 169.31, -145.87, -64.0, 44.120000000000005, -215.64999999999998, -30.339999999999932, -211.92999999999998, 0.7699999999998681, -155.80000000000004, 13.759999999999998, -85.62999999999984, -140.92, -266.62, -277.99, -214.0, -237.91000000000003, 39.620000000000005, -91.63000000000002, -28.930000000000007, -219.94000000000005, -209.98000000000002, -209.98000000000002, -268.78, -261.79000000000013, -152.22999999999968, -337.96000000000004, -176.59000000000003, -152.800000000001, -157.96, -52.809999999999945, -181.0, -223.0, -350.95000000000005, -239.58999999999986, -247.0, -205.60000000000014, -134.35000000000016, -239.83, -133.0, -2.919999999999959, -144.82, -97.0, 74.18000000000006, -173.92000000000002, -89.88999999999996, -25.0, -5.920000000000007, -165.76, -149.58999999999997, 51.16999999999999, 71.57, 16.06999999999999, -283.0, -72.36999999999992, 10.099999999999806, -175.27000000000066, -158.8900000000002, -71.92000000000002, -140.44000000000028, -109.41999999999976, -296.77, -171.4600000000001, -34.09000000000002, -129.42999999999992, -120.72999999999993, -95.05000000000001, -34.30000000000009, -102.5799999999998, -109.5999999999998, 2.0000000000000013, -81.84999999999941, -183.6700000000003, -162.83999999999946, -309.94, 41.47999999999994, -205.30000000000058, 31.670000000000144, -237.82000000000016, -102.99999999999949, 0.68, -215.76999999999998, -308.95, -202.6000000000002, -93.52000000000004, 0.1700000000000088, -29.709999999999802, 43.90999999999986, -289.84000000000015, -174.94000000000088, -51.880000000000194, -221.41000000000045, -78.45999999999997, -58.300000000000296, -34.180000000000355, -222.42999999999995, -272.80000000000007, -18.099999999999962, -313.6600000000003, -340.84000000000015, -150.78999999999996, -24.339999999999844, -170.64999999999998, -120.54999999999984, -85.26999999999987, -74.64999999999935, -318.7600000000002, -202.69000000000014, -256.5400000000002, -162.93999999999997, -124.71999999999936, -303.9100000000001, -261.94000000000005, -79.54000000000003, -142.75000000000017, -194.38000000000056, -277.4800000000005, -181.36000000000058, 49.51999999999971, -205.36000000000058, -26.97999999999988, -297.5800000000004, -2.0199999999999987, -207.40000000000023, -131.35000000000056, 2.0000000000000013, -151.93000000000006], "policy_predator_policy_reward": [72.0, 109.0, 80.0, 133.0, 110.0, 169.0, 59.0, 121.0, 104.0, 188.0, 48.0, 106.0, 132.0, 167.0, 127.0, 18.0, 112.0, 50.0, 56.0, 158.0, 80.0, 113.0, 170.0, 92.0, 93.0, 144.0, 96.0, 69.0, 110.0, 74.0, 81.0, 110.0, 118.0, 138.0, 58.0, 93.0, 113.0, 223.0, 92.0, 94.0, 182.0, 173.0, 200.0, 166.0, 102.0, 182.0, 194.0, 177.0, 122.0, 80.0, 178.0, 69.0, 77.0, 81.0, 189.0, 148.0, 127.0, 76.0, 184.0, 156.0, 193.0, 191.0, 123.0, 35.0, 200.0, 200.0, 146.0, 179.0, 88.0, 42.0, 178.0, 153.0, 183.0, 159.0, 114.0, 174.0, 139.0, 61.0, 181.0, 161.0, 187.0, 95.0, 171.0, 134.0, 150.0, 139.0, 175.0, 178.0, 167.0, 199.0, 161.0, 93.0, 183.0, 79.0, 158.0, 150.0, 200.0, 169.0, 177.0, 177.0, 133.0, 171.0, 162.0, 144.0, 185.0, 164.0, 200.0, 153.0, 68.0, 198.0, 120.0, 191.0, 88.0, 156.0, 57.0, 193.0, 172.0, 121.0, 98.0, 153.0, 153.0, 174.0, 142.0, 137.0, 21.0, 117.0, 172.0, 156.0, 91.0, 145.0, 101.0, 143.0, 119.0, 128.0, 193.0, 190.0, 141.0, 178.0, 196.0, 109.0, 144.0, 103.0, 62.0, 118.0, 123.0, 151.0, 175.0, 206.0, 135.0, 120.0, 158.0, 150.0, 26.0, 134.0, 195.0, 186.0, 100.0, 185.0, 105.0, 33.0, 167.0, 168.0, 104.0, 102.0, 199.0, 117.0, 90.0, 0.0, 193.0, 192.0, 136.0, 182.0, 200.0, 107.0, 89.0, 172.0, 126.0, 116.0, 138.0, 172.0, 118.0, 138.0, 122.0, 170.0, 176.0, 195.0, 161.0, 134.0, 147.0, 200.0, 134.0, 86.0, 174.0, 146.0, 135.0, 176.0, 139.0, 161.0, 106.0, 99.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9790358122600535, "mean_inference_ms": 2.627674121012916, "mean_action_processing_ms": 0.37276987912717785, "mean_env_wait_ms": 0.35952998442695444, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016782045364379883, "StateBufferConnector_ms": 0.0038338899612426758, "ViewRequirementAgentConnector_ms": 0.21703219413757324}, "num_episodes": 18, "episode_return_max": 373.03999999999996, "episode_return_min": -319.96000000000004, "episode_return_mean": 44.323200000000035, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 337.1741998516308, "num_env_steps_trained_throughput_per_sec": 337.1741998516308, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 13462.808, "restore_workers_time_ms": 0.054, "training_step_time_ms": 13462.688, "sample_time_ms": 2000.575, "learn_time_ms": 11439.842, "learn_throughput": 349.655, "synch_weights_time_ms": 17.843}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "0e60f_00000", "date": "2024-08-15_00-58-08", "timestamp": 1723663688, "time_this_iter_s": 11.90861701965332, "time_total_s": 108.15612268447876, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fc79d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 108.15612268447876, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 51.9, "ram_util_percent": 83.12352941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.51699592658767, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.657593836860051, "policy_loss": -0.007018529392887282, "vf_loss": 6.662293812332961, "vf_explained_var": -0.01608390246749555, "kl": 0.011592821470788082, "entropy": 1.5435511566974498, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9318103127378636, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.576606317802712, "policy_loss": -0.006645445042491827, "vf_loss": 8.580915425315736, "vf_explained_var": -0.07737853013018452, "kl": 0.011681739700003543, "entropy": 1.4965790236437762, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 315.17999999999995, "episode_reward_min": -319.96000000000004, "episode_reward_mean": 14.990400000000047, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 194.02999999999997, "predator_policy": 217.0}, "policy_reward_mean": {"prey_policy": -128.76480000000004, "predator_policy": 136.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-87.5999999999998, -185.91, 297.08, 42.080000000000155, 304.1999999999998, -73.99000000000001, 315.17999999999995, -197.2599999999997, -91.57999999999998, 227.7899999999998, -319.96000000000004, 40.06999999999999, 279.02, 83.48000000000003, 26.110000000000007, 311.44, 180.12, 96.01000000000003, 70.83999999999989, 162.96000000000004, 62.44999999999996, -191.61, -85.91000000000001, 201.99, 13.130000000000003, -111.96000000000001, -161.5700000000001, -136.18999999999966, -25.390000000000065, 95.23000000000005, -55.0, -237.5399999999999, -186.60000000000008, -63.179999999999964, 108.08000000000004, 8.18000000000001, 193.26, 136.11000000000004, 155.31999999999996, 180.5799999999997, 225.63999999999987, -27.370000000000033, 70.83000000000055, 13.1899999999999, -2.8600000000000385, -85.22999999999999, 155.47999999999982, 89.22000000000044, 110.12000000000049, 72.40000000000035, 8.480000000000008, -91.78000000000003, 91.18000000000039, 101.8500000000003, 57.67999999999968, -143.72, -11.120000000000038, 108.46000000000039, 89.07000000000035, -20.819999999999734, 16.129999999999953, -2.4800000000002917, -110.22999999999999, -13.759999999999971, -184.6300000000001, 66.0100000000002, 36.18000000000012, -83.40999999999923, -203.2300000000003, 4.340000000000091, -194.85000000000014, 72.71000000000004, -124.86000000000001, 88.16000000000064, 87.66000000000027, 11.399999999999986, -38.749999999999986, 55.069999999999816, 138.19999999999862, -40.67000000000029, -11.190000000000037, -260.1300000000003, 41.76999999999979, 43.21000000000003, 85.24000000000049, -10.140000000000004, -289.1900000000003, 31.88000000000026, 32.390000000000136, -32.84999999999998, -288.8900000000003, 43.98999999999995, 70.23000000000008, -90.83999999999928, 87.80000000000035, 17.030000000000236, 89.57000000000062, 7.919999999999964, 62.40999999999992, 99.68000000000097], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-87.66999999999983, -283.93, -187.0, -369.90999999999997, 17.0, 78.08, -23.589999999999804, -181.33000000000015, -47.82999999999993, 194.02999999999997, -139.99, -271.0, 149.09000000000003, -36.909999999999954, -273.66999999999996, -263.5900000000004, -263.77000000000004, -211.81, 68.6, 1.1899999999999977, -379.0, -340.96000000000004, -205.0, -79.93, 33.019999999999996, 116.0, -49.65999999999984, -197.85999999999999, -196.96000000000004, -118.93, 169.31, -145.87, -64.0, 44.120000000000005, -215.64999999999998, -30.339999999999932, -211.92999999999998, 0.7699999999998681, -155.80000000000004, 13.759999999999998, -85.62999999999984, -140.92, -266.62, -277.99, -214.0, -237.91000000000003, 39.620000000000005, -91.63000000000002, -28.930000000000007, -219.94000000000005, -209.98000000000002, -209.98000000000002, -268.78, -261.79000000000013, -152.22999999999968, -337.96000000000004, -176.59000000000003, -152.800000000001, -157.96, -52.809999999999945, -181.0, -223.0, -350.95000000000005, -239.58999999999986, -247.0, -205.60000000000014, -134.35000000000016, -239.83, -133.0, -2.919999999999959, -144.82, -97.0, 74.18000000000006, -173.92000000000002, -89.88999999999996, -25.0, -5.920000000000007, -165.76, -149.58999999999997, 51.16999999999999, 71.57, 16.06999999999999, -283.0, -72.36999999999992, 10.099999999999806, -175.27000000000066, -158.8900000000002, -71.92000000000002, -140.44000000000028, -109.41999999999976, -296.77, -171.4600000000001, -34.09000000000002, -129.42999999999992, -120.72999999999993, -95.05000000000001, -34.30000000000009, -102.5799999999998, -109.5999999999998, 2.0000000000000013, -81.84999999999941, -183.6700000000003, -162.83999999999946, -309.94, 41.47999999999994, -205.30000000000058, 31.670000000000144, -237.82000000000016, -102.99999999999949, 0.68, -215.76999999999998, -308.95, -202.6000000000002, -93.52000000000004, 0.1700000000000088, -29.709999999999802, 43.90999999999986, -289.84000000000015, -174.94000000000088, -51.880000000000194, -221.41000000000045, -78.45999999999997, -58.300000000000296, -34.180000000000355, -222.42999999999995, -272.80000000000007, -18.099999999999962, -313.6600000000003, -340.84000000000015, -150.78999999999996, -24.339999999999844, -170.64999999999998, -120.54999999999984, -85.26999999999987, -74.64999999999935, -318.7600000000002, -202.69000000000014, -256.5400000000002, -162.93999999999997, -124.71999999999936, -303.9100000000001, -261.94000000000005, -79.54000000000003, -142.75000000000017, -194.38000000000056, -277.4800000000005, -181.36000000000058, 49.51999999999971, -205.36000000000058, -26.97999999999988, -297.5800000000004, -2.0199999999999987, -207.40000000000023, -131.35000000000056, 2.0000000000000013, -151.93000000000006, -131.01999999999953, 37.21999999999976, -68.58999999999958, -203.08000000000084, -103.56999999999927, -95.61999999999935, -268.4200000000001, -349.71000000000026, -1.030000000000008, -215.20000000000024, -84.4299999999992, -28.359999999999978, -28.47999999999977, -21.279999999999998, -19.179999999999833, -166.96000000000095, -292.73000000000013, -299.4600000000001, -77.64999999999968, -11.470000000000145, -219.10000000000082, 52.489999999999704, -166.83999999999943, -201.01000000000036, -294.55000000000007, -246.34000000000023, -77.11000000000006, -175.900000000001, -54.27999999999993, -183.48999999999995, -164.17000000000036, -132.66999999999973, -15.130000000000008, -141.0700000000008, -34.18000000000011, -144.79000000000028, -26.04999999999987, -65.37999999999968, -115.86999999999948, -40.210000000000356, -87.51999999999994, -102.06999999999952, -70.72000000000001, -76.60000000000001], "policy_predator_policy_reward": [102.0, 182.0, 194.0, 177.0, 122.0, 80.0, 178.0, 69.0, 77.0, 81.0, 189.0, 148.0, 127.0, 76.0, 184.0, 156.0, 193.0, 191.0, 123.0, 35.0, 200.0, 200.0, 146.0, 179.0, 88.0, 42.0, 178.0, 153.0, 183.0, 159.0, 114.0, 174.0, 139.0, 61.0, 181.0, 161.0, 187.0, 95.0, 171.0, 134.0, 150.0, 139.0, 175.0, 178.0, 167.0, 199.0, 161.0, 93.0, 183.0, 79.0, 158.0, 150.0, 200.0, 169.0, 177.0, 177.0, 133.0, 171.0, 162.0, 144.0, 185.0, 164.0, 200.0, 153.0, 68.0, 198.0, 120.0, 191.0, 88.0, 156.0, 57.0, 193.0, 172.0, 121.0, 98.0, 153.0, 153.0, 174.0, 142.0, 137.0, 21.0, 117.0, 172.0, 156.0, 91.0, 145.0, 101.0, 143.0, 119.0, 128.0, 193.0, 190.0, 141.0, 178.0, 196.0, 109.0, 144.0, 103.0, 62.0, 118.0, 123.0, 151.0, 175.0, 206.0, 135.0, 120.0, 158.0, 150.0, 26.0, 134.0, 195.0, 186.0, 100.0, 185.0, 105.0, 33.0, 167.0, 168.0, 104.0, 102.0, 199.0, 117.0, 90.0, 0.0, 193.0, 192.0, 136.0, 182.0, 200.0, 107.0, 89.0, 172.0, 126.0, 116.0, 138.0, 172.0, 118.0, 138.0, 122.0, 170.0, 176.0, 195.0, 161.0, 134.0, 147.0, 200.0, 134.0, 86.0, 174.0, 146.0, 135.0, 176.0, 139.0, 161.0, 106.0, 99.0, 109.0, 123.0, 134.0, 97.0, 87.0, 101.0, 209.0, 149.0, 125.0, 133.0, 80.0, 76.0, 96.0, 39.0, 112.0, 64.0, 217.0, 86.0, 53.0, 68.0, 80.0, 119.0, 178.0, 157.0, 183.0, 69.0, 171.0, 126.0, 133.0, 175.0, 196.0, 10.0, 134.0, 110.0, 103.0, 93.0, 112.0, 69.0, 95.0, 69.0, 115.0, 137.0, 109.0, 138.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9896839066205757, "mean_inference_ms": 2.6535286139597334, "mean_action_processing_ms": 0.37457205317788755, "mean_env_wait_ms": 0.3639186362166513, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013709545135498047, "StateBufferConnector_ms": 0.003746509552001953, "ViewRequirementAgentConnector_ms": 0.21006083488464355}, "num_episodes": 22, "episode_return_max": 315.17999999999995, "episode_return_min": -319.96000000000004, "episode_return_mean": 14.990400000000047, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.6905608662329, "num_env_steps_trained_throughput_per_sec": 348.6905608662329, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 13241.552, "restore_workers_time_ms": 0.05, "training_step_time_ms": 13241.44, "sample_time_ms": 1930.885, "learn_time_ms": 11288.805, "learn_throughput": 354.333, "synch_weights_time_ms": 17.326}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "0e60f_00000", "date": "2024-08-15_00-58-20", "timestamp": 1723663700, "time_this_iter_s": 11.53196406364441, "time_total_s": 119.68808674812317, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2a2ef70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 119.68808674812317, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 47.10588235294118, "ram_util_percent": 83.45882352941177}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4635679811554612, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.638392712325646, "policy_loss": -0.0043441694924637436, "vf_loss": 6.641502452527405, "vf_explained_var": -0.004281851822737033, "kl": 0.0061721658502474335, "entropy": 1.5540796676010051, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.760771336505022, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.685139525630486, "policy_loss": -0.005437252097442825, "vf_loss": 8.68903763634818, "vf_explained_var": -5.267603056771415e-05, "kl": 0.007695650530933212, "entropy": 1.5114768795235447, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 225.63999999999987, "episode_reward_min": -289.1900000000003, "episode_reward_mean": 1.9535000000000873, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -369.8500000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 74.18000000000006, "predator_policy": 217.0}, "policy_reward_mean": {"prey_policy": -126.85325000000005, "predator_policy": 127.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [201.99, 13.130000000000003, -111.96000000000001, -161.5700000000001, -136.18999999999966, -25.390000000000065, 95.23000000000005, -55.0, -237.5399999999999, -186.60000000000008, -63.179999999999964, 108.08000000000004, 8.18000000000001, 193.26, 136.11000000000004, 155.31999999999996, 180.5799999999997, 225.63999999999987, -27.370000000000033, 70.83000000000055, 13.1899999999999, -2.8600000000000385, -85.22999999999999, 155.47999999999982, 89.22000000000044, 110.12000000000049, 72.40000000000035, 8.480000000000008, -91.78000000000003, 91.18000000000039, 101.8500000000003, 57.67999999999968, -143.72, -11.120000000000038, 108.46000000000039, 89.07000000000035, -20.819999999999734, 16.129999999999953, -2.4800000000002917, -110.22999999999999, -13.759999999999971, -184.6300000000001, 66.0100000000002, 36.18000000000012, -83.40999999999923, -203.2300000000003, 4.340000000000091, -194.85000000000014, 72.71000000000004, -124.86000000000001, 88.16000000000064, 87.66000000000027, 11.399999999999986, -38.749999999999986, 55.069999999999816, 138.19999999999862, -40.67000000000029, -11.190000000000037, -260.1300000000003, 41.76999999999979, 43.21000000000003, 85.24000000000049, -10.140000000000004, -289.1900000000003, 31.88000000000026, 32.390000000000136, -32.84999999999998, -288.8900000000003, 43.98999999999995, 70.23000000000008, -90.83999999999928, 87.80000000000035, 17.030000000000236, 89.57000000000062, 7.919999999999964, 62.40999999999992, 99.68000000000097, -50.03999999999989, -16.409999999999478, 34.75999999999966, -217.38999999999976, 32.14000000000007, 15.269999999999733, 44.6199999999997, -149.93999999999946, -74.1099999999997, 41.33000000000004, -8.21999999999986, -108.39999999999934, 41.92000000000013, 88.18000000000127, -29.16999999999982, -182.9900000000003, 77.88000000000032, 32.7100000000001, 49.889999999999944, 88.34000000000098, 150.9899999999997, 37.14000000000023, 62.81999999999982], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [39.620000000000005, -91.63000000000002, -28.930000000000007, -219.94000000000005, -209.98000000000002, -209.98000000000002, -268.78, -261.79000000000013, -152.22999999999968, -337.96000000000004, -176.59000000000003, -152.800000000001, -157.96, -52.809999999999945, -181.0, -223.0, -350.95000000000005, -239.58999999999986, -247.0, -205.60000000000014, -134.35000000000016, -239.83, -133.0, -2.919999999999959, -144.82, -97.0, 74.18000000000006, -173.92000000000002, -89.88999999999996, -25.0, -5.920000000000007, -165.76, -149.58999999999997, 51.16999999999999, 71.57, 16.06999999999999, -283.0, -72.36999999999992, 10.099999999999806, -175.27000000000066, -158.8900000000002, -71.92000000000002, -140.44000000000028, -109.41999999999976, -296.77, -171.4600000000001, -34.09000000000002, -129.42999999999992, -120.72999999999993, -95.05000000000001, -34.30000000000009, -102.5799999999998, -109.5999999999998, 2.0000000000000013, -81.84999999999941, -183.6700000000003, -162.83999999999946, -309.94, 41.47999999999994, -205.30000000000058, 31.670000000000144, -237.82000000000016, -102.99999999999949, 0.68, -215.76999999999998, -308.95, -202.6000000000002, -93.52000000000004, 0.1700000000000088, -29.709999999999802, 43.90999999999986, -289.84000000000015, -174.94000000000088, -51.880000000000194, -221.41000000000045, -78.45999999999997, -58.300000000000296, -34.180000000000355, -222.42999999999995, -272.80000000000007, -18.099999999999962, -313.6600000000003, -340.84000000000015, -150.78999999999996, -24.339999999999844, -170.64999999999998, -120.54999999999984, -85.26999999999987, -74.64999999999935, -318.7600000000002, -202.69000000000014, -256.5400000000002, -162.93999999999997, -124.71999999999936, -303.9100000000001, -261.94000000000005, -79.54000000000003, -142.75000000000017, -194.38000000000056, -277.4800000000005, -181.36000000000058, 49.51999999999971, -205.36000000000058, -26.97999999999988, -297.5800000000004, -2.0199999999999987, -207.40000000000023, -131.35000000000056, 2.0000000000000013, -151.93000000000006, -131.01999999999953, 37.21999999999976, -68.58999999999958, -203.08000000000084, -103.56999999999927, -95.61999999999935, -268.4200000000001, -349.71000000000026, -1.030000000000008, -215.20000000000024, -84.4299999999992, -28.359999999999978, -28.47999999999977, -21.279999999999998, -19.179999999999833, -166.96000000000095, -292.73000000000013, -299.4600000000001, -77.64999999999968, -11.470000000000145, -219.10000000000082, 52.489999999999704, -166.83999999999943, -201.01000000000036, -294.55000000000007, -246.34000000000023, -77.11000000000006, -175.900000000001, -54.27999999999993, -183.48999999999995, -164.17000000000036, -132.66999999999973, -15.130000000000008, -141.0700000000008, -34.18000000000011, -144.79000000000028, -26.04999999999987, -65.37999999999968, -115.86999999999948, -40.210000000000356, -87.51999999999994, -102.06999999999952, -70.72000000000001, -76.60000000000001, -58.3, -146.74000000000007, -32.17000000000031, -46.24000000000035, -152.82999999999942, -29.409999999999833, -190.95999999999975, -268.4300000000001, -102.51999999999985, -141.33999999999983, -181.02999999999952, -54.7, -139.14999999999992, -44.229999999999954, -233.1700000000004, -152.76999999999936, -253.0500000000003, -148.0600000000003, -276.6700000000003, 2.0000000000000013, -224.2299999999998, -31.99000000000014, -169.93000000000097, -218.47000000000045, -4.030000000000042, 6.949999999999958, -4.030000000000042, 35.20999999999976, -164.92000000000098, -48.25000000000024, -369.8500000000001, -143.14000000000004, -20.109999999999708, -0.009999999999998581, -135.82000000000087, -23.46999999999976, -143.64999999999998, -90.45999999999923, 10.339999999999977, 2.0000000000000013, -16.720000000000066, -53.29, -273.5200000000003, -9.340000000000035, -182.8399999999999, -66.33999999999995], "policy_predator_policy_reward": [161.0, 93.0, 183.0, 79.0, 158.0, 150.0, 200.0, 169.0, 177.0, 177.0, 133.0, 171.0, 162.0, 144.0, 185.0, 164.0, 200.0, 153.0, 68.0, 198.0, 120.0, 191.0, 88.0, 156.0, 57.0, 193.0, 172.0, 121.0, 98.0, 153.0, 153.0, 174.0, 142.0, 137.0, 21.0, 117.0, 172.0, 156.0, 91.0, 145.0, 101.0, 143.0, 119.0, 128.0, 193.0, 190.0, 141.0, 178.0, 196.0, 109.0, 144.0, 103.0, 62.0, 118.0, 123.0, 151.0, 175.0, 206.0, 135.0, 120.0, 158.0, 150.0, 26.0, 134.0, 195.0, 186.0, 100.0, 185.0, 105.0, 33.0, 167.0, 168.0, 104.0, 102.0, 199.0, 117.0, 90.0, 0.0, 193.0, 192.0, 136.0, 182.0, 200.0, 107.0, 89.0, 172.0, 126.0, 116.0, 138.0, 172.0, 118.0, 138.0, 122.0, 170.0, 176.0, 195.0, 161.0, 134.0, 147.0, 200.0, 134.0, 86.0, 174.0, 146.0, 135.0, 176.0, 139.0, 161.0, 106.0, 99.0, 109.0, 123.0, 134.0, 97.0, 87.0, 101.0, 209.0, 149.0, 125.0, 133.0, 80.0, 76.0, 96.0, 39.0, 112.0, 64.0, 217.0, 86.0, 53.0, 68.0, 80.0, 119.0, 178.0, 157.0, 183.0, 69.0, 171.0, 126.0, 133.0, 175.0, 196.0, 10.0, 134.0, 110.0, 103.0, 93.0, 112.0, 69.0, 95.0, 69.0, 115.0, 137.0, 109.0, 138.0, 15.0, 140.0, 33.0, 29.0, 110.0, 107.0, 196.0, 46.0, 185.0, 91.0, 122.0, 129.0, 128.0, 100.0, 175.0, 61.0, 182.0, 145.0, 160.0, 156.0, 94.0, 154.0, 81.0, 199.0, 7.0, 32.0, 50.0, 7.0, 85.0, 99.0, 130.0, 200.0, 51.0, 47.0, 118.0, 74.0, 106.0, 178.0, 16.0, 60.0, 94.0, 127.0, 173.0, 147.0, 146.0, 166.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.959761803857295, "mean_inference_ms": 2.567044211724271, "mean_action_processing_ms": 0.3653006953440417, "mean_env_wait_ms": 0.3522938201405363, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011052608489990234, "StateBufferConnector_ms": 0.004163861274719238, "ViewRequirementAgentConnector_ms": 0.1465442180633545}, "num_episodes": 23, "episode_return_max": 225.63999999999987, "episode_return_min": -289.1900000000003, "episode_return_mean": 1.9535000000000873, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.7016086689876, "num_env_steps_trained_throughput_per_sec": 339.7016086689876, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 13094.902, "restore_workers_time_ms": 0.046, "training_step_time_ms": 13094.796, "sample_time_ms": 1869.038, "learn_time_ms": 11204.853, "learn_throughput": 356.988, "synch_weights_time_ms": 16.756}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "0e60f_00000", "date": "2024-08-15_00-58-31", "timestamp": 1723663711, "time_this_iter_s": 11.81210994720459, "time_total_s": 131.50019669532776, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2a00dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 131.50019669532776, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 50.22352941176471, "ram_util_percent": 83.50588235294119}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4277369791553134, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.87188559360605, "policy_loss": -0.009734283801335742, "vf_loss": 6.878540783584433, "vf_explained_var": 0.0022849789687565394, "kl": 0.015395524048723191, "entropy": 1.5257055601745686, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3499800432611395, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 9.116533588227771, "policy_loss": -0.005974667343291301, "vf_loss": 9.120749952427294, "vf_explained_var": -0.06344767553465706, "kl": 0.008791609267683461, "entropy": 1.482678490782541, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 155.47999999999982, "episode_reward_min": -289.1900000000003, "episode_reward_mean": -5.507199999999911, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.7400000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 52.489999999999704, "predator_policy": 236.0}, "policy_reward_mean": {"prey_policy": -128.31860000000003, "predator_policy": 125.565}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-27.370000000000033, 70.83000000000055, 13.1899999999999, -2.8600000000000385, -85.22999999999999, 155.47999999999982, 89.22000000000044, 110.12000000000049, 72.40000000000035, 8.480000000000008, -91.78000000000003, 91.18000000000039, 101.8500000000003, 57.67999999999968, -143.72, -11.120000000000038, 108.46000000000039, 89.07000000000035, -20.819999999999734, 16.129999999999953, -2.4800000000002917, -110.22999999999999, -13.759999999999971, -184.6300000000001, 66.0100000000002, 36.18000000000012, -83.40999999999923, -203.2300000000003, 4.340000000000091, -194.85000000000014, 72.71000000000004, -124.86000000000001, 88.16000000000064, 87.66000000000027, 11.399999999999986, -38.749999999999986, 55.069999999999816, 138.19999999999862, -40.67000000000029, -11.190000000000037, -260.1300000000003, 41.76999999999979, 43.21000000000003, 85.24000000000049, -10.140000000000004, -289.1900000000003, 31.88000000000026, 32.390000000000136, -32.84999999999998, -288.8900000000003, 43.98999999999995, 70.23000000000008, -90.83999999999928, 87.80000000000035, 17.030000000000236, 89.57000000000062, 7.919999999999964, 62.40999999999992, 99.68000000000097, -50.03999999999989, -16.409999999999478, 34.75999999999966, -217.38999999999976, 32.14000000000007, 15.269999999999733, 44.6199999999997, -149.93999999999946, -74.1099999999997, 41.33000000000004, -8.21999999999986, -108.39999999999934, 41.92000000000013, 88.18000000000127, -29.16999999999982, -182.9900000000003, 77.88000000000032, 32.7100000000001, 49.889999999999944, 88.34000000000098, 150.9899999999997, 37.14000000000023, 62.81999999999982, -32.19000000000017, 39.900000000000084, -143.16999999999996, 58.619999999999905, -81.79999999999933, -33.22000000000053, 76.6200000000008, 4.68000000000009, 19.990000000000038, -228.14000000000004, 13.769999999999785, 55.049999999999656, 40.52999999999989, 48.63999999999952, -184.65000000000043, 33.20000000000019, -35.73999999999986, -58.069999999999915], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-283.0, -72.36999999999992, 10.099999999999806, -175.27000000000066, -158.8900000000002, -71.92000000000002, -140.44000000000028, -109.41999999999976, -296.77, -171.4600000000001, -34.09000000000002, -129.42999999999992, -120.72999999999993, -95.05000000000001, -34.30000000000009, -102.5799999999998, -109.5999999999998, 2.0000000000000013, -81.84999999999941, -183.6700000000003, -162.83999999999946, -309.94, 41.47999999999994, -205.30000000000058, 31.670000000000144, -237.82000000000016, -102.99999999999949, 0.68, -215.76999999999998, -308.95, -202.6000000000002, -93.52000000000004, 0.1700000000000088, -29.709999999999802, 43.90999999999986, -289.84000000000015, -174.94000000000088, -51.880000000000194, -221.41000000000045, -78.45999999999997, -58.300000000000296, -34.180000000000355, -222.42999999999995, -272.80000000000007, -18.099999999999962, -313.6600000000003, -340.84000000000015, -150.78999999999996, -24.339999999999844, -170.64999999999998, -120.54999999999984, -85.26999999999987, -74.64999999999935, -318.7600000000002, -202.69000000000014, -256.5400000000002, -162.93999999999997, -124.71999999999936, -303.9100000000001, -261.94000000000005, -79.54000000000003, -142.75000000000017, -194.38000000000056, -277.4800000000005, -181.36000000000058, 49.51999999999971, -205.36000000000058, -26.97999999999988, -297.5800000000004, -2.0199999999999987, -207.40000000000023, -131.35000000000056, 2.0000000000000013, -151.93000000000006, -131.01999999999953, 37.21999999999976, -68.58999999999958, -203.08000000000084, -103.56999999999927, -95.61999999999935, -268.4200000000001, -349.71000000000026, -1.030000000000008, -215.20000000000024, -84.4299999999992, -28.359999999999978, -28.47999999999977, -21.279999999999998, -19.179999999999833, -166.96000000000095, -292.73000000000013, -299.4600000000001, -77.64999999999968, -11.470000000000145, -219.10000000000082, 52.489999999999704, -166.83999999999943, -201.01000000000036, -294.55000000000007, -246.34000000000023, -77.11000000000006, -175.900000000001, -54.27999999999993, -183.48999999999995, -164.17000000000036, -132.66999999999973, -15.130000000000008, -141.0700000000008, -34.18000000000011, -144.79000000000028, -26.04999999999987, -65.37999999999968, -115.86999999999948, -40.210000000000356, -87.51999999999994, -102.06999999999952, -70.72000000000001, -76.60000000000001, -58.3, -146.74000000000007, -32.17000000000031, -46.24000000000035, -152.82999999999942, -29.409999999999833, -190.95999999999975, -268.4300000000001, -102.51999999999985, -141.33999999999983, -181.02999999999952, -54.7, -139.14999999999992, -44.229999999999954, -233.1700000000004, -152.76999999999936, -253.0500000000003, -148.0600000000003, -276.6700000000003, 2.0000000000000013, -224.2299999999998, -31.99000000000014, -169.93000000000097, -218.47000000000045, -4.030000000000042, 6.949999999999958, -4.030000000000042, 35.20999999999976, -164.92000000000098, -48.25000000000024, -369.8500000000001, -143.14000000000004, -20.109999999999708, -0.009999999999998581, -135.82000000000087, -23.46999999999976, -143.64999999999998, -90.45999999999923, 10.339999999999977, 2.0000000000000013, -16.720000000000066, -53.29, -273.5200000000003, -9.340000000000035, -182.8399999999999, -66.33999999999995, -32.64999999999999, -307.54000000000025, -179.05000000000084, -8.049999999999999, -92.4699999999993, -371.7000000000002, -10.06, -263.32000000000056, -248.26000000000022, -106.53999999999928, -199.00000000000063, -42.22000000000035, -55.96000000000018, -67.41999999999938, -10.060000000000041, -212.26000000000025, -47.56000000000029, -88.4499999999992, -335.5600000000004, -315.5799999999998, -124.62999999999948, -79.59999999999933, -182.95000000000016, 2.0000000000000013, -28.149999999999746, -62.320000000000334, -45.460000000000306, -31.900000000000183, -316.6000000000001, -209.05000000000024, -387.7400000000002, -10.060000000000022, -261.3099999999999, -75.4299999999997, -177.04000000000028, -187.0299999999997], "policy_predator_policy_reward": [172.0, 156.0, 91.0, 145.0, 101.0, 143.0, 119.0, 128.0, 193.0, 190.0, 141.0, 178.0, 196.0, 109.0, 144.0, 103.0, 62.0, 118.0, 123.0, 151.0, 175.0, 206.0, 135.0, 120.0, 158.0, 150.0, 26.0, 134.0, 195.0, 186.0, 100.0, 185.0, 105.0, 33.0, 167.0, 168.0, 104.0, 102.0, 199.0, 117.0, 90.0, 0.0, 193.0, 192.0, 136.0, 182.0, 200.0, 107.0, 89.0, 172.0, 126.0, 116.0, 138.0, 172.0, 118.0, 138.0, 122.0, 170.0, 176.0, 195.0, 161.0, 134.0, 147.0, 200.0, 134.0, 86.0, 174.0, 146.0, 135.0, 176.0, 139.0, 161.0, 106.0, 99.0, 109.0, 123.0, 134.0, 97.0, 87.0, 101.0, 209.0, 149.0, 125.0, 133.0, 80.0, 76.0, 96.0, 39.0, 112.0, 64.0, 217.0, 86.0, 53.0, 68.0, 80.0, 119.0, 178.0, 157.0, 183.0, 69.0, 171.0, 126.0, 133.0, 175.0, 196.0, 10.0, 134.0, 110.0, 103.0, 93.0, 112.0, 69.0, 95.0, 69.0, 115.0, 137.0, 109.0, 138.0, 15.0, 140.0, 33.0, 29.0, 110.0, 107.0, 196.0, 46.0, 185.0, 91.0, 122.0, 129.0, 128.0, 100.0, 175.0, 61.0, 182.0, 145.0, 160.0, 156.0, 94.0, 154.0, 81.0, 199.0, 7.0, 32.0, 50.0, 7.0, 85.0, 99.0, 130.0, 200.0, 51.0, 47.0, 118.0, 74.0, 106.0, 178.0, 16.0, 60.0, 94.0, 127.0, 173.0, 147.0, 146.0, 166.0, 182.0, 126.0, 76.0, 151.0, 218.0, 103.0, 182.0, 150.0, 82.0, 191.0, 120.0, 88.0, 100.0, 100.0, 145.0, 82.0, 59.0, 97.0, 217.0, 206.0, 121.0, 97.0, 118.0, 118.0, 95.0, 36.0, 87.0, 39.0, 171.0, 170.0, 195.0, 236.0, 171.0, 130.0, 154.0, 152.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.92759394774953, "mean_inference_ms": 2.471412949230684, "mean_action_processing_ms": 0.35492046669298377, "mean_env_wait_ms": 0.3383285250176496, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008203864097595215, "StateBufferConnector_ms": 0.003990530967712402, "ViewRequirementAgentConnector_ms": 0.12223732471466064}, "num_episodes": 18, "episode_return_max": 155.47999999999982, "episode_return_min": -289.1900000000003, "episode_return_mean": -5.507199999999911, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.9327841428634, "num_env_steps_trained_throughput_per_sec": 346.9327841428634, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 12974.959, "restore_workers_time_ms": 0.046, "training_step_time_ms": 12974.853, "sample_time_ms": 1769.444, "learn_time_ms": 11184.418, "learn_throughput": 357.64, "synch_weights_time_ms": 16.843}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "0e60f_00000", "date": "2024-08-15_00-58-43", "timestamp": 1723663723, "time_this_iter_s": 11.581097841262817, "time_total_s": 143.08129453659058, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2afb940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 143.08129453659058, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 49.0625, "ram_util_percent": 83.34375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.361977896977354, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7703809171126634, "policy_loss": -0.011944211116947588, "vf_loss": 3.7800081815669144, "vf_explained_var": -0.0029598772841155844, "kl": 0.01158475150264749, "entropy": 1.511082705429622, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.162823151028346, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.595047794574152, "policy_loss": -0.00777361028798161, "vf_loss": 7.600397649896208, "vf_explained_var": -0.08884345551647206, "kl": 0.012118770551967053, "entropy": 1.4783033708415965, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 150.9899999999997, "episode_reward_min": -289.1900000000003, "episode_reward_mean": -7.848899999999945, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.7400000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 52.489999999999704, "predator_policy": 236.0}, "policy_reward_mean": {"prey_policy": -118.65445000000004, "predator_policy": 114.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.819999999999734, 16.129999999999953, -2.4800000000002917, -110.22999999999999, -13.759999999999971, -184.6300000000001, 66.0100000000002, 36.18000000000012, -83.40999999999923, -203.2300000000003, 4.340000000000091, -194.85000000000014, 72.71000000000004, -124.86000000000001, 88.16000000000064, 87.66000000000027, 11.399999999999986, -38.749999999999986, 55.069999999999816, 138.19999999999862, -40.67000000000029, -11.190000000000037, -260.1300000000003, 41.76999999999979, 43.21000000000003, 85.24000000000049, -10.140000000000004, -289.1900000000003, 31.88000000000026, 32.390000000000136, -32.84999999999998, -288.8900000000003, 43.98999999999995, 70.23000000000008, -90.83999999999928, 87.80000000000035, 17.030000000000236, 89.57000000000062, 7.919999999999964, 62.40999999999992, 99.68000000000097, -50.03999999999989, -16.409999999999478, 34.75999999999966, -217.38999999999976, 32.14000000000007, 15.269999999999733, 44.6199999999997, -149.93999999999946, -74.1099999999997, 41.33000000000004, -8.21999999999986, -108.39999999999934, 41.92000000000013, 88.18000000000127, -29.16999999999982, -182.9900000000003, 77.88000000000032, 32.7100000000001, 49.889999999999944, 88.34000000000098, 150.9899999999997, 37.14000000000023, 62.81999999999982, -32.19000000000017, 39.900000000000084, -143.16999999999996, 58.619999999999905, -81.79999999999933, -33.22000000000053, 76.6200000000008, 4.68000000000009, 19.990000000000038, -228.14000000000004, 13.769999999999785, 55.049999999999656, 40.52999999999989, 48.63999999999952, -184.65000000000043, 33.20000000000019, -35.73999999999986, -58.069999999999915, -25.029999999999863, 135.45999999999992, 46.48999999999963, 24.550000000000434, 23.040000000000145, 37.42999999999962, -101.22999999999918, -18.160000000000128, -31.94000000000039, 30.36000000000036, 40.39999999999958, 77.71999999999994, 41.72999999999957, 40.99000000000031, 34.71999999999993, 53.82999999999986, -32.90000000000019, -5.750000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-174.94000000000088, -51.880000000000194, -221.41000000000045, -78.45999999999997, -58.300000000000296, -34.180000000000355, -222.42999999999995, -272.80000000000007, -18.099999999999962, -313.6600000000003, -340.84000000000015, -150.78999999999996, -24.339999999999844, -170.64999999999998, -120.54999999999984, -85.26999999999987, -74.64999999999935, -318.7600000000002, -202.69000000000014, -256.5400000000002, -162.93999999999997, -124.71999999999936, -303.9100000000001, -261.94000000000005, -79.54000000000003, -142.75000000000017, -194.38000000000056, -277.4800000000005, -181.36000000000058, 49.51999999999971, -205.36000000000058, -26.97999999999988, -297.5800000000004, -2.0199999999999987, -207.40000000000023, -131.35000000000056, 2.0000000000000013, -151.93000000000006, -131.01999999999953, 37.21999999999976, -68.58999999999958, -203.08000000000084, -103.56999999999927, -95.61999999999935, -268.4200000000001, -349.71000000000026, -1.030000000000008, -215.20000000000024, -84.4299999999992, -28.359999999999978, -28.47999999999977, -21.279999999999998, -19.179999999999833, -166.96000000000095, -292.73000000000013, -299.4600000000001, -77.64999999999968, -11.470000000000145, -219.10000000000082, 52.489999999999704, -166.83999999999943, -201.01000000000036, -294.55000000000007, -246.34000000000023, -77.11000000000006, -175.900000000001, -54.27999999999993, -183.48999999999995, -164.17000000000036, -132.66999999999973, -15.130000000000008, -141.0700000000008, -34.18000000000011, -144.79000000000028, -26.04999999999987, -65.37999999999968, -115.86999999999948, -40.210000000000356, -87.51999999999994, -102.06999999999952, -70.72000000000001, -76.60000000000001, -58.3, -146.74000000000007, -32.17000000000031, -46.24000000000035, -152.82999999999942, -29.409999999999833, -190.95999999999975, -268.4300000000001, -102.51999999999985, -141.33999999999983, -181.02999999999952, -54.7, -139.14999999999992, -44.229999999999954, -233.1700000000004, -152.76999999999936, -253.0500000000003, -148.0600000000003, -276.6700000000003, 2.0000000000000013, -224.2299999999998, -31.99000000000014, -169.93000000000097, -218.47000000000045, -4.030000000000042, 6.949999999999958, -4.030000000000042, 35.20999999999976, -164.92000000000098, -48.25000000000024, -369.8500000000001, -143.14000000000004, -20.109999999999708, -0.009999999999998581, -135.82000000000087, -23.46999999999976, -143.64999999999998, -90.45999999999923, 10.339999999999977, 2.0000000000000013, -16.720000000000066, -53.29, -273.5200000000003, -9.340000000000035, -182.8399999999999, -66.33999999999995, -32.64999999999999, -307.54000000000025, -179.05000000000084, -8.049999999999999, -92.4699999999993, -371.7000000000002, -10.06, -263.32000000000056, -248.26000000000022, -106.53999999999928, -199.00000000000063, -42.22000000000035, -55.96000000000018, -67.41999999999938, -10.060000000000041, -212.26000000000025, -47.56000000000029, -88.4499999999992, -335.5600000000004, -315.5799999999998, -124.62999999999948, -79.59999999999933, -182.95000000000016, 2.0000000000000013, -28.149999999999746, -62.320000000000334, -45.460000000000306, -31.900000000000183, -316.6000000000001, -209.05000000000024, -387.7400000000002, -10.060000000000022, -261.3099999999999, -75.4299999999997, -177.04000000000028, -187.0299999999997, -209.11000000000075, -47.920000000000215, -32.5900000000001, 0.050000000000000315, -9.88000000000005, -61.63000000000027, 17.780000000000264, -44.23000000000034, -15.729999999999908, -245.23000000000053, -82.56999999999942, 2.0000000000000013, -136.09000000000083, -227.14000000000067, -64.3599999999993, -47.800000000000075, -72.84999999999954, -148.09000000000077, 2.0000000000000013, -105.63999999999943, 17.09000000000014, -106.68999999999933, -21.159999999999926, -22.11999999999994, -69.66999999999936, -28.599999999999827, -34.180000000000355, 15.169999999999767, -68.40999999999976, -88.86999999999946, 2.0000000000000013, -32.169999999999845, -94.59999999999938, -259.3000000000003, -44.23000000000035, -102.51999999999931], "policy_predator_policy_reward": [104.0, 102.0, 199.0, 117.0, 90.0, 0.0, 193.0, 192.0, 136.0, 182.0, 200.0, 107.0, 89.0, 172.0, 126.0, 116.0, 138.0, 172.0, 118.0, 138.0, 122.0, 170.0, 176.0, 195.0, 161.0, 134.0, 147.0, 200.0, 134.0, 86.0, 174.0, 146.0, 135.0, 176.0, 139.0, 161.0, 106.0, 99.0, 109.0, 123.0, 134.0, 97.0, 87.0, 101.0, 209.0, 149.0, 125.0, 133.0, 80.0, 76.0, 96.0, 39.0, 112.0, 64.0, 217.0, 86.0, 53.0, 68.0, 80.0, 119.0, 178.0, 157.0, 183.0, 69.0, 171.0, 126.0, 133.0, 175.0, 196.0, 10.0, 134.0, 110.0, 103.0, 93.0, 112.0, 69.0, 95.0, 69.0, 115.0, 137.0, 109.0, 138.0, 15.0, 140.0, 33.0, 29.0, 110.0, 107.0, 196.0, 46.0, 185.0, 91.0, 122.0, 129.0, 128.0, 100.0, 175.0, 61.0, 182.0, 145.0, 160.0, 156.0, 94.0, 154.0, 81.0, 199.0, 7.0, 32.0, 50.0, 7.0, 85.0, 99.0, 130.0, 200.0, 51.0, 47.0, 118.0, 74.0, 106.0, 178.0, 16.0, 60.0, 94.0, 127.0, 173.0, 147.0, 146.0, 166.0, 182.0, 126.0, 76.0, 151.0, 218.0, 103.0, 182.0, 150.0, 82.0, 191.0, 120.0, 88.0, 100.0, 100.0, 145.0, 82.0, 59.0, 97.0, 217.0, 206.0, 121.0, 97.0, 118.0, 118.0, 95.0, 36.0, 87.0, 39.0, 171.0, 170.0, 195.0, 236.0, 171.0, 130.0, 154.0, 152.0, 140.0, 92.0, 96.0, 72.0, 75.0, 43.0, 41.0, 10.0, 153.0, 131.0, 57.0, 61.0, 146.0, 116.0, 7.0, 87.0, 98.0, 91.0, 74.0, 60.0, 46.0, 84.0, 27.0, 94.0, 60.0, 80.0, 22.0, 38.0, 102.0, 90.0, 38.0, 46.0, 132.0, 189.0, 55.0, 86.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9016432080496812, "mean_inference_ms": 2.395716377593048, "mean_action_processing_ms": 0.3464306539107085, "mean_env_wait_ms": 0.32712158163907384, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008262276649475098, "StateBufferConnector_ms": 0.004026532173156738, "ViewRequirementAgentConnector_ms": 0.12338876724243164}, "num_episodes": 18, "episode_return_max": 150.9899999999997, "episode_return_min": -289.1900000000003, "episode_return_mean": -7.848899999999945, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 326.61038924986167, "num_env_steps_trained_throughput_per_sec": 326.61038924986167, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 12975.242, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12975.189, "sample_time_ms": 1686.429, "learn_time_ms": 11267.859, "learn_throughput": 354.992, "synch_weights_time_ms": 16.679}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "0e60f_00000", "date": "2024-08-15_00-58-55", "timestamp": 1723663735, "time_this_iter_s": 12.303224086761475, "time_total_s": 155.38451862335205, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fe0550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 155.38451862335205, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 52.099999999999994, "ram_util_percent": 83.23888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4400232027447413, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.0120202499722675, "policy_loss": -0.006181723610300905, "vf_loss": 4.016941661809487, "vf_explained_var": 0.04388055407180988, "kl": 0.006301444952398547, "entropy": 1.5001537966349767, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.113606978471948, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.805923906709782, "policy_loss": -0.008527766722229817, "vf_loss": 6.81248185924752, "vf_explained_var": -0.14556939589283455, "kl": 0.009849093249153321, "entropy": 1.4618654341294022, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 232.36000000000007, "episode_reward_min": -289.1900000000003, "episode_reward_mean": 7.218200000000056, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.7400000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 129.70999999999998, "predator_policy": 236.0}, "policy_reward_mean": {"prey_policy": -94.45090000000002, "predator_policy": 98.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [55.069999999999816, 138.19999999999862, -40.67000000000029, -11.190000000000037, -260.1300000000003, 41.76999999999979, 43.21000000000003, 85.24000000000049, -10.140000000000004, -289.1900000000003, 31.88000000000026, 32.390000000000136, -32.84999999999998, -288.8900000000003, 43.98999999999995, 70.23000000000008, -90.83999999999928, 87.80000000000035, 17.030000000000236, 89.57000000000062, 7.919999999999964, 62.40999999999992, 99.68000000000097, -50.03999999999989, -16.409999999999478, 34.75999999999966, -217.38999999999976, 32.14000000000007, 15.269999999999733, 44.6199999999997, -149.93999999999946, -74.1099999999997, 41.33000000000004, -8.21999999999986, -108.39999999999934, 41.92000000000013, 88.18000000000127, -29.16999999999982, -182.9900000000003, 77.88000000000032, 32.7100000000001, 49.889999999999944, 88.34000000000098, 150.9899999999997, 37.14000000000023, 62.81999999999982, -32.19000000000017, 39.900000000000084, -143.16999999999996, 58.619999999999905, -81.79999999999933, -33.22000000000053, 76.6200000000008, 4.68000000000009, 19.990000000000038, -228.14000000000004, 13.769999999999785, 55.049999999999656, 40.52999999999989, 48.63999999999952, -184.65000000000043, 33.20000000000019, -35.73999999999986, -58.069999999999915, -25.029999999999863, 135.45999999999992, 46.48999999999963, 24.550000000000434, 23.040000000000145, 37.42999999999962, -101.22999999999918, -18.160000000000128, -31.94000000000039, 30.36000000000036, 40.39999999999958, 77.71999999999994, 41.72999999999957, 40.99000000000031, 34.71999999999993, 53.82999999999986, -32.90000000000019, -5.750000000000007, 133.69000000000017, 232.36000000000007, -21.239999999999416, 30.950000000000575, -39.010000000000595, 45.379999999999676, 13.43999999999983, 73.64000000000023, 102.01000000000101, 15.229999999999995, -21.839999999999655, 81.12999999999991, -22.519999999999712, -41.39000000000072, 23.39000000000034, 213.16999999999928, 75.4800000000002, 18.410000000000355], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -151.93000000000006, -131.01999999999953, 37.21999999999976, -68.58999999999958, -203.08000000000084, -103.56999999999927, -95.61999999999935, -268.4200000000001, -349.71000000000026, -1.030000000000008, -215.20000000000024, -84.4299999999992, -28.359999999999978, -28.47999999999977, -21.279999999999998, -19.179999999999833, -166.96000000000095, -292.73000000000013, -299.4600000000001, -77.64999999999968, -11.470000000000145, -219.10000000000082, 52.489999999999704, -166.83999999999943, -201.01000000000036, -294.55000000000007, -246.34000000000023, -77.11000000000006, -175.900000000001, -54.27999999999993, -183.48999999999995, -164.17000000000036, -132.66999999999973, -15.130000000000008, -141.0700000000008, -34.18000000000011, -144.79000000000028, -26.04999999999987, -65.37999999999968, -115.86999999999948, -40.210000000000356, -87.51999999999994, -102.06999999999952, -70.72000000000001, -76.60000000000001, -58.3, -146.74000000000007, -32.17000000000031, -46.24000000000035, -152.82999999999942, -29.409999999999833, -190.95999999999975, -268.4300000000001, -102.51999999999985, -141.33999999999983, -181.02999999999952, -54.7, -139.14999999999992, -44.229999999999954, -233.1700000000004, -152.76999999999936, -253.0500000000003, -148.0600000000003, -276.6700000000003, 2.0000000000000013, -224.2299999999998, -31.99000000000014, -169.93000000000097, -218.47000000000045, -4.030000000000042, 6.949999999999958, -4.030000000000042, 35.20999999999976, -164.92000000000098, -48.25000000000024, -369.8500000000001, -143.14000000000004, -20.109999999999708, -0.009999999999998581, -135.82000000000087, -23.46999999999976, -143.64999999999998, -90.45999999999923, 10.339999999999977, 2.0000000000000013, -16.720000000000066, -53.29, -273.5200000000003, -9.340000000000035, -182.8399999999999, -66.33999999999995, -32.64999999999999, -307.54000000000025, -179.05000000000084, -8.049999999999999, -92.4699999999993, -371.7000000000002, -10.06, -263.32000000000056, -248.26000000000022, -106.53999999999928, -199.00000000000063, -42.22000000000035, -55.96000000000018, -67.41999999999938, -10.060000000000041, -212.26000000000025, -47.56000000000029, -88.4499999999992, -335.5600000000004, -315.5799999999998, -124.62999999999948, -79.59999999999933, -182.95000000000016, 2.0000000000000013, -28.149999999999746, -62.320000000000334, -45.460000000000306, -31.900000000000183, -316.6000000000001, -209.05000000000024, -387.7400000000002, -10.060000000000022, -261.3099999999999, -75.4299999999997, -177.04000000000028, -187.0299999999997, -209.11000000000075, -47.920000000000215, -32.5900000000001, 0.050000000000000315, -9.88000000000005, -61.63000000000027, 17.780000000000264, -44.23000000000034, -15.729999999999908, -245.23000000000053, -82.56999999999942, 2.0000000000000013, -136.09000000000083, -227.14000000000067, -64.3599999999993, -47.800000000000075, -72.84999999999954, -148.09000000000077, 2.0000000000000013, -105.63999999999943, 17.09000000000014, -106.68999999999933, -21.159999999999926, -22.11999999999994, -69.66999999999936, -28.599999999999827, -34.180000000000355, 15.169999999999767, -68.40999999999976, -88.86999999999946, 2.0000000000000013, -32.169999999999845, -94.59999999999938, -259.3000000000003, -44.23000000000035, -102.51999999999931, 129.70999999999998, -2.020000000000042, 49.07, 66.28999999999996, -24.12999999999971, -20.109999999999705, -8.050000000000042, 2.0000000000000013, -53.470000000000304, -79.53999999999927, 12.4700000000001, -16.089999999999716, -142.81000000000097, -136.74999999999994, -28.14999999999979, 1.7899999999999103, 2.0000000000000013, -46.99000000000017, -88.68999999999936, -56.07999999999975, -121.8399999999994, 2.0000000000000013, 45.41000000000019, -54.28000000000034, -51.55000000000024, -183.97000000000074, -34.18000000000036, -40.210000000000356, -46.24000000000034, -42.37000000000011, 81.1700000000006, 101.00000000000007, -34.5100000000001, -0.00999999999999836, -94.47999999999922, 12.88999999999996], "policy_predator_policy_reward": [106.0, 99.0, 109.0, 123.0, 134.0, 97.0, 87.0, 101.0, 209.0, 149.0, 125.0, 133.0, 80.0, 76.0, 96.0, 39.0, 112.0, 64.0, 217.0, 86.0, 53.0, 68.0, 80.0, 119.0, 178.0, 157.0, 183.0, 69.0, 171.0, 126.0, 133.0, 175.0, 196.0, 10.0, 134.0, 110.0, 103.0, 93.0, 112.0, 69.0, 95.0, 69.0, 115.0, 137.0, 109.0, 138.0, 15.0, 140.0, 33.0, 29.0, 110.0, 107.0, 196.0, 46.0, 185.0, 91.0, 122.0, 129.0, 128.0, 100.0, 175.0, 61.0, 182.0, 145.0, 160.0, 156.0, 94.0, 154.0, 81.0, 199.0, 7.0, 32.0, 50.0, 7.0, 85.0, 99.0, 130.0, 200.0, 51.0, 47.0, 118.0, 74.0, 106.0, 178.0, 16.0, 60.0, 94.0, 127.0, 173.0, 147.0, 146.0, 166.0, 182.0, 126.0, 76.0, 151.0, 218.0, 103.0, 182.0, 150.0, 82.0, 191.0, 120.0, 88.0, 100.0, 100.0, 145.0, 82.0, 59.0, 97.0, 217.0, 206.0, 121.0, 97.0, 118.0, 118.0, 95.0, 36.0, 87.0, 39.0, 171.0, 170.0, 195.0, 236.0, 171.0, 130.0, 154.0, 152.0, 140.0, 92.0, 96.0, 72.0, 75.0, 43.0, 41.0, 10.0, 153.0, 131.0, 57.0, 61.0, 146.0, 116.0, 7.0, 87.0, 98.0, 91.0, 74.0, 60.0, 46.0, 84.0, 27.0, 94.0, 60.0, 80.0, 22.0, 38.0, 102.0, 90.0, 38.0, 46.0, 132.0, 189.0, 55.0, 86.0, 2.0, 4.0, 85.0, 32.0, 0.0, 23.0, 15.0, 22.0, 41.0, 53.0, 26.0, 23.0, 133.0, 160.0, 72.0, 28.0, 58.0, 89.0, 82.0, 78.0, 91.0, 7.0, 39.0, 51.0, 117.0, 96.0, 23.0, 10.0, 48.0, 64.0, 9.0, 22.0, 10.0, 100.0, 54.0, 46.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8796349856079684, "mean_inference_ms": 2.333194262802908, "mean_action_processing_ms": 0.33913181913221296, "mean_env_wait_ms": 0.31757323929879705, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006765484809875488, "StateBufferConnector_ms": 0.005361795425415039, "ViewRequirementAgentConnector_ms": 0.11988019943237305}, "num_episodes": 18, "episode_return_max": 232.36000000000007, "episode_return_min": -289.1900000000003, "episode_return_mean": 7.218200000000056, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.79953529864224, "num_env_steps_trained_throughput_per_sec": 329.79953529864224, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 13068.987, "restore_workers_time_ms": 0.013, "training_step_time_ms": 13068.929, "sample_time_ms": 1694.751, "learn_time_ms": 11353.033, "learn_throughput": 352.329, "synch_weights_time_ms": 16.761}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "0e60f_00000", "date": "2024-08-15_00-59-08", "timestamp": 1723663748, "time_this_iter_s": 12.161442995071411, "time_total_s": 167.54596161842346, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fe0f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 167.54596161842346, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 53.211764705882345, "ram_util_percent": 83.4764705882353}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5843135538870696, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.434281335810505, "policy_loss": -0.008364819786412809, "vf_loss": 6.44051328689333, "vf_explained_var": 0.08979891283171518, "kl": 0.010664261600560748, "entropy": 1.4565225460541942, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.857487783230171, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.778135818653006, "policy_loss": -0.007795126399976354, "vf_loss": 6.782965275850246, "vf_explained_var": 0.015727922872260765, "kl": 0.014828304001054504, "entropy": 1.4519864857512177, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 292.03000000000014, "episode_reward_min": -228.14000000000004, "episode_reward_mean": 49.58029999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.7400000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.12000000000006, "predator_policy": 236.0}, "policy_reward_mean": {"prey_policy": -60.984850000000016, "predator_policy": 85.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.14000000000007, 15.269999999999733, 44.6199999999997, -149.93999999999946, -74.1099999999997, 41.33000000000004, -8.21999999999986, -108.39999999999934, 41.92000000000013, 88.18000000000127, -29.16999999999982, -182.9900000000003, 77.88000000000032, 32.7100000000001, 49.889999999999944, 88.34000000000098, 150.9899999999997, 37.14000000000023, 62.81999999999982, -32.19000000000017, 39.900000000000084, -143.16999999999996, 58.619999999999905, -81.79999999999933, -33.22000000000053, 76.6200000000008, 4.68000000000009, 19.990000000000038, -228.14000000000004, 13.769999999999785, 55.049999999999656, 40.52999999999989, 48.63999999999952, -184.65000000000043, 33.20000000000019, -35.73999999999986, -58.069999999999915, -25.029999999999863, 135.45999999999992, 46.48999999999963, 24.550000000000434, 23.040000000000145, 37.42999999999962, -101.22999999999918, -18.160000000000128, -31.94000000000039, 30.36000000000036, 40.39999999999958, 77.71999999999994, 41.72999999999957, 40.99000000000031, 34.71999999999993, 53.82999999999986, -32.90000000000019, -5.750000000000007, 133.69000000000017, 232.36000000000007, -21.239999999999416, 30.950000000000575, -39.010000000000595, 45.379999999999676, 13.43999999999983, 73.64000000000023, 102.01000000000101, 15.229999999999995, -21.839999999999655, 81.12999999999991, -22.519999999999712, -41.39000000000072, 23.39000000000034, 213.16999999999928, 75.4800000000002, 18.410000000000355, 112.00000000000013, 134.29999999999973, 253.87999999999903, 211.29999999999927, 272.6599999999995, 178.21999999999977, -2.3099999999999934, 268.12000000000006, 269.98999999999904, 171.7599999999986, 4.11000000000001, 238.85999999999893, 32.20000000000009, 181.10000000000008, 99.08000000000008, 91.85000000000089, 211.79999999999947, 198.7899999999998, 5.4499999999999345, 187.34999999999945, 140.5900000000001, 6.689999999999923, 292.03000000000014, 76.34000000000037, 15.569999999999954, 28.260000000000424, 189.62999999999954], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-102.51999999999985, -141.33999999999983, -181.02999999999952, -54.7, -139.14999999999992, -44.229999999999954, -233.1700000000004, -152.76999999999936, -253.0500000000003, -148.0600000000003, -276.6700000000003, 2.0000000000000013, -224.2299999999998, -31.99000000000014, -169.93000000000097, -218.47000000000045, -4.030000000000042, 6.949999999999958, -4.030000000000042, 35.20999999999976, -164.92000000000098, -48.25000000000024, -369.8500000000001, -143.14000000000004, -20.109999999999708, -0.009999999999998581, -135.82000000000087, -23.46999999999976, -143.64999999999998, -90.45999999999923, 10.339999999999977, 2.0000000000000013, -16.720000000000066, -53.29, -273.5200000000003, -9.340000000000035, -182.8399999999999, -66.33999999999995, -32.64999999999999, -307.54000000000025, -179.05000000000084, -8.049999999999999, -92.4699999999993, -371.7000000000002, -10.06, -263.32000000000056, -248.26000000000022, -106.53999999999928, -199.00000000000063, -42.22000000000035, -55.96000000000018, -67.41999999999938, -10.060000000000041, -212.26000000000025, -47.56000000000029, -88.4499999999992, -335.5600000000004, -315.5799999999998, -124.62999999999948, -79.59999999999933, -182.95000000000016, 2.0000000000000013, -28.149999999999746, -62.320000000000334, -45.460000000000306, -31.900000000000183, -316.6000000000001, -209.05000000000024, -387.7400000000002, -10.060000000000022, -261.3099999999999, -75.4299999999997, -177.04000000000028, -187.0299999999997, -209.11000000000075, -47.920000000000215, -32.5900000000001, 0.050000000000000315, -9.88000000000005, -61.63000000000027, 17.780000000000264, -44.23000000000034, -15.729999999999908, -245.23000000000053, -82.56999999999942, 2.0000000000000013, -136.09000000000083, -227.14000000000067, -64.3599999999993, -47.800000000000075, -72.84999999999954, -148.09000000000077, 2.0000000000000013, -105.63999999999943, 17.09000000000014, -106.68999999999933, -21.159999999999926, -22.11999999999994, -69.66999999999936, -28.599999999999827, -34.180000000000355, 15.169999999999767, -68.40999999999976, -88.86999999999946, 2.0000000000000013, -32.169999999999845, -94.59999999999938, -259.3000000000003, -44.23000000000035, -102.51999999999931, 129.70999999999998, -2.020000000000042, 49.07, 66.28999999999996, -24.12999999999971, -20.109999999999705, -8.050000000000042, 2.0000000000000013, -53.470000000000304, -79.53999999999927, 12.4700000000001, -16.089999999999716, -142.81000000000097, -136.74999999999994, -28.14999999999979, 1.7899999999999103, 2.0000000000000013, -46.99000000000017, -88.68999999999936, -56.07999999999975, -121.8399999999994, 2.0000000000000013, 45.41000000000019, -54.28000000000034, -51.55000000000024, -183.97000000000074, -34.18000000000036, -40.210000000000356, -46.24000000000034, -42.37000000000011, 81.1700000000006, 101.00000000000007, -34.5100000000001, -0.00999999999999836, -94.47999999999922, 12.88999999999996, 2.0000000000000013, 101.00000000000001, -51.88000000000005, -108.82000000000002, -62.320000000000334, 147.19999999999993, -29.859999999999843, 88.16, 93.41000000000011, -22.74999999999998, 145.42999999999998, -40.210000000000356, -152.92000000000098, -22.38999999999975, 44.53999999999989, 115.5800000000001, -56.290000000000234, 118.28000000000009, 11.120000000000017, -28.359999999999754, 2.0000000000000013, -176.8900000000008, 188.12000000000006, -50.26000000000022, -16.089999999999712, -71.70999999999982, 2.0000000000000013, -40.899999999999956, 0.22999999999999177, -10.15000000000004, -40.96000000000021, 20.810000000000027, -68.34999999999927, 176.14999999999992, 69.22999999999996, 9.560000000000121, 2.0000000000000013, -108.54999999999926, 131.35999999999987, -195.0100000000009, 66.58999999999995, 2.0000000000000013, -1.1500000000000206, -30.159999999999734, 114.77000000000011, 135.26000000000002, 3.979999999999972, 65.3600000000002, -13.900000000000016, -83.52999999999925, -52.270000000000344, 48.52999999999988, 80.20999999999997, -42.580000000000254], "policy_predator_policy_reward": [185.0, 91.0, 122.0, 129.0, 128.0, 100.0, 175.0, 61.0, 182.0, 145.0, 160.0, 156.0, 94.0, 154.0, 81.0, 199.0, 7.0, 32.0, 50.0, 7.0, 85.0, 99.0, 130.0, 200.0, 51.0, 47.0, 118.0, 74.0, 106.0, 178.0, 16.0, 60.0, 94.0, 127.0, 173.0, 147.0, 146.0, 166.0, 182.0, 126.0, 76.0, 151.0, 218.0, 103.0, 182.0, 150.0, 82.0, 191.0, 120.0, 88.0, 100.0, 100.0, 145.0, 82.0, 59.0, 97.0, 217.0, 206.0, 121.0, 97.0, 118.0, 118.0, 95.0, 36.0, 87.0, 39.0, 171.0, 170.0, 195.0, 236.0, 171.0, 130.0, 154.0, 152.0, 140.0, 92.0, 96.0, 72.0, 75.0, 43.0, 41.0, 10.0, 153.0, 131.0, 57.0, 61.0, 146.0, 116.0, 7.0, 87.0, 98.0, 91.0, 74.0, 60.0, 46.0, 84.0, 27.0, 94.0, 60.0, 80.0, 22.0, 38.0, 102.0, 90.0, 38.0, 46.0, 132.0, 189.0, 55.0, 86.0, 2.0, 4.0, 85.0, 32.0, 0.0, 23.0, 15.0, 22.0, 41.0, 53.0, 26.0, 23.0, 133.0, 160.0, 72.0, 28.0, 58.0, 89.0, 82.0, 78.0, 91.0, 7.0, 39.0, 51.0, 117.0, 96.0, 23.0, 10.0, 48.0, 64.0, 9.0, 22.0, 10.0, 100.0, 54.0, 46.0, 1.0, 8.0, 147.0, 148.0, 85.0, 84.0, 65.0, 88.0, 52.0, 150.0, 26.0, 47.0, 67.0, 106.0, 47.0, 61.0, 95.0, 113.0, 78.0, 111.0, 97.0, 82.0, 48.0, 53.0, 64.0, 56.0, 83.0, 137.0, 27.0, 82.0, 30.0, 82.0, 77.0, 27.0, 54.0, 66.0, 57.0, 55.0, 106.0, 145.0, 13.0, 59.0, 30.0, 8.0, 41.0, 1.0, 1.0, 6.0, 63.0, 50.0, 0.0, 32.0, 89.0, 63.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8520003702260783, "mean_inference_ms": 2.2529716319079363, "mean_action_processing_ms": 0.32900728082694364, "mean_env_wait_ms": 0.30687709084869946, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006788134574890137, "StateBufferConnector_ms": 0.005345582962036133, "ViewRequirementAgentConnector_ms": 0.12113738059997559}, "num_episodes": 27, "episode_return_max": 292.03000000000014, "episode_return_min": -228.14000000000004, "episode_return_mean": 49.58029999999998, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.54367942260825, "num_env_steps_trained_throughput_per_sec": 342.54367942260825, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 12780.605, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12780.547, "sample_time_ms": 1672.153, "learn_time_ms": 11089.831, "learn_throughput": 360.691, "synch_weights_time_ms": 14.424}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "0e60f_00000", "date": "2024-08-15_00-59-19", "timestamp": 1723663759, "time_this_iter_s": 11.738202095031738, "time_total_s": 179.2841637134552, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2afb9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 179.2841637134552, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 49.2375, "ram_util_percent": 83.21875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7136869403104933, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.680773387888752, "policy_loss": -0.00855086228068642, "vf_loss": 6.687281617159566, "vf_explained_var": 0.08997685474062724, "kl": 0.010213172081098312, "entropy": 1.4399404452591347, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.715839582460898, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.08242631740671, "policy_loss": -0.00866315210183895, "vf_loss": 8.088428085064763, "vf_explained_var": -0.03625805642869737, "kl": 0.01330702286310405, "entropy": 1.4551316299135724, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 396.13999999999993, "episode_reward_min": -228.14000000000004, "episode_reward_mean": 83.1987999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.7400000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.12000000000006, "predator_policy": 236.0}, "policy_reward_mean": {"prey_policy": -41.17559999999999, "predator_policy": 82.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [62.81999999999982, -32.19000000000017, 39.900000000000084, -143.16999999999996, 58.619999999999905, -81.79999999999933, -33.22000000000053, 76.6200000000008, 4.68000000000009, 19.990000000000038, -228.14000000000004, 13.769999999999785, 55.049999999999656, 40.52999999999989, 48.63999999999952, -184.65000000000043, 33.20000000000019, -35.73999999999986, -58.069999999999915, -25.029999999999863, 135.45999999999992, 46.48999999999963, 24.550000000000434, 23.040000000000145, 37.42999999999962, -101.22999999999918, -18.160000000000128, -31.94000000000039, 30.36000000000036, 40.39999999999958, 77.71999999999994, 41.72999999999957, 40.99000000000031, 34.71999999999993, 53.82999999999986, -32.90000000000019, -5.750000000000007, 133.69000000000017, 232.36000000000007, -21.239999999999416, 30.950000000000575, -39.010000000000595, 45.379999999999676, 13.43999999999983, 73.64000000000023, 102.01000000000101, 15.229999999999995, -21.839999999999655, 81.12999999999991, -22.519999999999712, -41.39000000000072, 23.39000000000034, 213.16999999999928, 75.4800000000002, 18.410000000000355, 112.00000000000013, 134.29999999999973, 253.87999999999903, 211.29999999999927, 272.6599999999995, 178.21999999999977, -2.3099999999999934, 268.12000000000006, 269.98999999999904, 171.7599999999986, 4.11000000000001, 238.85999999999893, 32.20000000000009, 181.10000000000008, 99.08000000000008, 91.85000000000089, 211.79999999999947, 198.7899999999998, 5.4499999999999345, 187.34999999999945, 140.5900000000001, 6.689999999999923, 292.03000000000014, 76.34000000000037, 15.569999999999954, 28.260000000000424, 189.62999999999954, 116.12999999999997, 230.8399999999997, 170.61000000000007, 70.11, 187.79999999999953, 269.96999999999906, 214.8699999999995, 193.14999999999998, 396.13999999999993, 158.87999999999982, 164.06999999999988, 318.1099999999997, 203.01000000000013, 280.3700000000001, 77.06999999999998, 3.6100000000000527, 253.80999999999977, 200.88], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-182.8399999999999, -66.33999999999995, -32.64999999999999, -307.54000000000025, -179.05000000000084, -8.049999999999999, -92.4699999999993, -371.7000000000002, -10.06, -263.32000000000056, -248.26000000000022, -106.53999999999928, -199.00000000000063, -42.22000000000035, -55.96000000000018, -67.41999999999938, -10.060000000000041, -212.26000000000025, -47.56000000000029, -88.4499999999992, -335.5600000000004, -315.5799999999998, -124.62999999999948, -79.59999999999933, -182.95000000000016, 2.0000000000000013, -28.149999999999746, -62.320000000000334, -45.460000000000306, -31.900000000000183, -316.6000000000001, -209.05000000000024, -387.7400000000002, -10.060000000000022, -261.3099999999999, -75.4299999999997, -177.04000000000028, -187.0299999999997, -209.11000000000075, -47.920000000000215, -32.5900000000001, 0.050000000000000315, -9.88000000000005, -61.63000000000027, 17.780000000000264, -44.23000000000034, -15.729999999999908, -245.23000000000053, -82.56999999999942, 2.0000000000000013, -136.09000000000083, -227.14000000000067, -64.3599999999993, -47.800000000000075, -72.84999999999954, -148.09000000000077, 2.0000000000000013, -105.63999999999943, 17.09000000000014, -106.68999999999933, -21.159999999999926, -22.11999999999994, -69.66999999999936, -28.599999999999827, -34.180000000000355, 15.169999999999767, -68.40999999999976, -88.86999999999946, 2.0000000000000013, -32.169999999999845, -94.59999999999938, -259.3000000000003, -44.23000000000035, -102.51999999999931, 129.70999999999998, -2.020000000000042, 49.07, 66.28999999999996, -24.12999999999971, -20.109999999999705, -8.050000000000042, 2.0000000000000013, -53.470000000000304, -79.53999999999927, 12.4700000000001, -16.089999999999716, -142.81000000000097, -136.74999999999994, -28.14999999999979, 1.7899999999999103, 2.0000000000000013, -46.99000000000017, -88.68999999999936, -56.07999999999975, -121.8399999999994, 2.0000000000000013, 45.41000000000019, -54.28000000000034, -51.55000000000024, -183.97000000000074, -34.18000000000036, -40.210000000000356, -46.24000000000034, -42.37000000000011, 81.1700000000006, 101.00000000000007, -34.5100000000001, -0.00999999999999836, -94.47999999999922, 12.88999999999996, 2.0000000000000013, 101.00000000000001, -51.88000000000005, -108.82000000000002, -62.320000000000334, 147.19999999999993, -29.859999999999843, 88.16, 93.41000000000011, -22.74999999999998, 145.42999999999998, -40.210000000000356, -152.92000000000098, -22.38999999999975, 44.53999999999989, 115.5800000000001, -56.290000000000234, 118.28000000000009, 11.120000000000017, -28.359999999999754, 2.0000000000000013, -176.8900000000008, 188.12000000000006, -50.26000000000022, -16.089999999999712, -71.70999999999982, 2.0000000000000013, -40.899999999999956, 0.22999999999999177, -10.15000000000004, -40.96000000000021, 20.810000000000027, -68.34999999999927, 176.14999999999992, 69.22999999999996, 9.560000000000121, 2.0000000000000013, -108.54999999999926, 131.35999999999987, -195.0100000000009, 66.58999999999995, 2.0000000000000013, -1.1500000000000206, -30.159999999999734, 114.77000000000011, 135.26000000000002, 3.979999999999972, 65.3600000000002, -13.900000000000016, -83.52999999999925, -52.270000000000344, 48.52999999999988, 80.20999999999997, -42.580000000000254, 2.0000000000000013, -196.87000000000012, 114.20000000000005, -28.360000000000007, -45.81999999999998, 22.429999999999975, -24.159999999999727, -93.72999999999993, 12.709999999999965, 17.089999999999996, 6.85999999999996, 120.11000000000001, -18.939999999999987, -33.19000000000036, 12.889999999999848, -35.73999999999992, 67.1, 109.04, -91.0, 1.8800000000000014, -30.159999999999716, -74.76999999999997, 113.81000000000016, 62.30000000000004, -19.599999999999785, 133.61, -2.9200000000000017, 48.29000000000003, 13.129999999999782, -4.060000000000041, -2.0200000000000404, -72.36999999999918, 18.709999999999965, 85.09999999999998, -27.730000000000004, -13.3899999999998], "policy_predator_policy_reward": [146.0, 166.0, 182.0, 126.0, 76.0, 151.0, 218.0, 103.0, 182.0, 150.0, 82.0, 191.0, 120.0, 88.0, 100.0, 100.0, 145.0, 82.0, 59.0, 97.0, 217.0, 206.0, 121.0, 97.0, 118.0, 118.0, 95.0, 36.0, 87.0, 39.0, 171.0, 170.0, 195.0, 236.0, 171.0, 130.0, 154.0, 152.0, 140.0, 92.0, 96.0, 72.0, 75.0, 43.0, 41.0, 10.0, 153.0, 131.0, 57.0, 61.0, 146.0, 116.0, 7.0, 87.0, 98.0, 91.0, 74.0, 60.0, 46.0, 84.0, 27.0, 94.0, 60.0, 80.0, 22.0, 38.0, 102.0, 90.0, 38.0, 46.0, 132.0, 189.0, 55.0, 86.0, 2.0, 4.0, 85.0, 32.0, 0.0, 23.0, 15.0, 22.0, 41.0, 53.0, 26.0, 23.0, 133.0, 160.0, 72.0, 28.0, 58.0, 89.0, 82.0, 78.0, 91.0, 7.0, 39.0, 51.0, 117.0, 96.0, 23.0, 10.0, 48.0, 64.0, 9.0, 22.0, 10.0, 100.0, 54.0, 46.0, 1.0, 8.0, 147.0, 148.0, 85.0, 84.0, 65.0, 88.0, 52.0, 150.0, 26.0, 47.0, 67.0, 106.0, 47.0, 61.0, 95.0, 113.0, 78.0, 111.0, 97.0, 82.0, 48.0, 53.0, 64.0, 56.0, 83.0, 137.0, 27.0, 82.0, 30.0, 82.0, 77.0, 27.0, 54.0, 66.0, 57.0, 55.0, 106.0, 145.0, 13.0, 59.0, 30.0, 8.0, 41.0, 1.0, 1.0, 6.0, 63.0, 50.0, 0.0, 32.0, 89.0, 63.0, 145.0, 166.0, 86.0, 59.0, 155.0, 39.0, 50.0, 138.0, 62.0, 96.0, 46.0, 97.0, 133.0, 134.0, 70.0, 146.0, 131.0, 89.0, 119.0, 129.0, 190.0, 79.0, 88.0, 54.0, 84.0, 5.0, 146.0, 89.0, 30.0, 38.0, 13.0, 65.0, 70.0, 80.0, 155.0, 87.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8390146988949856, "mean_inference_ms": 2.2101315591717876, "mean_action_processing_ms": 0.3241994543965474, "mean_env_wait_ms": 0.2991914238867232, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0036153793334960938, "StateBufferConnector_ms": 0.004387974739074707, "ViewRequirementAgentConnector_ms": 0.09414613246917725}, "num_episodes": 18, "episode_return_max": 396.13999999999993, "episode_return_min": -228.14000000000004, "episode_return_mean": 83.1987999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 330.06595784617986, "num_env_steps_trained_throughput_per_sec": 330.06595784617986, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 11970.363, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11970.306, "sample_time_ms": 1452.125, "learn_time_ms": 10501.011, "learn_throughput": 380.916, "synch_weights_time_ms": 13.436}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "0e60f_00000", "date": "2024-08-15_00-59-32", "timestamp": 1723663772, "time_this_iter_s": 12.159330129623413, "time_total_s": 191.4434938430786, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2afb790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 191.4434938430786, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 61.38333333333334, "ram_util_percent": 83.85555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9781011292227992, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.6795951944179635, "policy_loss": -0.009234379641292863, "vf_loss": 5.68706738128864, "vf_explained_var": 0.05301491807377528, "kl": 0.008810925982520946, "entropy": 1.4419831571124848, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.830810804720278, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.979502996061214, "policy_loss": -0.006082323132447465, "vf_loss": 7.9837489988438035, "vf_explained_var": 0.03910442767319856, "kl": 0.009181675030279089, "entropy": 1.461969014387282, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 396.13999999999993, "episode_reward_min": -101.22999999999918, "episode_reward_mean": 113.02449999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -259.3000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.12000000000006, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -18.202749999999995, "predator_policy": 74.715}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-58.069999999999915, -25.029999999999863, 135.45999999999992, 46.48999999999963, 24.550000000000434, 23.040000000000145, 37.42999999999962, -101.22999999999918, -18.160000000000128, -31.94000000000039, 30.36000000000036, 40.39999999999958, 77.71999999999994, 41.72999999999957, 40.99000000000031, 34.71999999999993, 53.82999999999986, -32.90000000000019, -5.750000000000007, 133.69000000000017, 232.36000000000007, -21.239999999999416, 30.950000000000575, -39.010000000000595, 45.379999999999676, 13.43999999999983, 73.64000000000023, 102.01000000000101, 15.229999999999995, -21.839999999999655, 81.12999999999991, -22.519999999999712, -41.39000000000072, 23.39000000000034, 213.16999999999928, 75.4800000000002, 18.410000000000355, 112.00000000000013, 134.29999999999973, 253.87999999999903, 211.29999999999927, 272.6599999999995, 178.21999999999977, -2.3099999999999934, 268.12000000000006, 269.98999999999904, 171.7599999999986, 4.11000000000001, 238.85999999999893, 32.20000000000009, 181.10000000000008, 99.08000000000008, 91.85000000000089, 211.79999999999947, 198.7899999999998, 5.4499999999999345, 187.34999999999945, 140.5900000000001, 6.689999999999923, 292.03000000000014, 76.34000000000037, 15.569999999999954, 28.260000000000424, 189.62999999999954, 116.12999999999997, 230.8399999999997, 170.61000000000007, 70.11, 187.79999999999953, 269.96999999999906, 214.8699999999995, 193.14999999999998, 396.13999999999993, 158.87999999999982, 164.06999999999988, 318.1099999999997, 203.01000000000013, 280.3700000000001, 77.06999999999998, 3.6100000000000527, 253.80999999999977, 200.88, 205.27999999999943, 213.5299999999998, 192.05999999999966, 93.88000000000017, 9.809999999999924, 12.999999999999915, 138.3800000000001, 371.1899999999998, 52.98000000000001, 173.28999999999985, -7.270000000000076, 164.11000000000024, 133.2400000000004, 137.9199999999999, 200.08999999999992, 258.6699999999998, 197.11999999999995, 150.19999999999965], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-177.04000000000028, -187.0299999999997, -209.11000000000075, -47.920000000000215, -32.5900000000001, 0.050000000000000315, -9.88000000000005, -61.63000000000027, 17.780000000000264, -44.23000000000034, -15.729999999999908, -245.23000000000053, -82.56999999999942, 2.0000000000000013, -136.09000000000083, -227.14000000000067, -64.3599999999993, -47.800000000000075, -72.84999999999954, -148.09000000000077, 2.0000000000000013, -105.63999999999943, 17.09000000000014, -106.68999999999933, -21.159999999999926, -22.11999999999994, -69.66999999999936, -28.599999999999827, -34.180000000000355, 15.169999999999767, -68.40999999999976, -88.86999999999946, 2.0000000000000013, -32.169999999999845, -94.59999999999938, -259.3000000000003, -44.23000000000035, -102.51999999999931, 129.70999999999998, -2.020000000000042, 49.07, 66.28999999999996, -24.12999999999971, -20.109999999999705, -8.050000000000042, 2.0000000000000013, -53.470000000000304, -79.53999999999927, 12.4700000000001, -16.089999999999716, -142.81000000000097, -136.74999999999994, -28.14999999999979, 1.7899999999999103, 2.0000000000000013, -46.99000000000017, -88.68999999999936, -56.07999999999975, -121.8399999999994, 2.0000000000000013, 45.41000000000019, -54.28000000000034, -51.55000000000024, -183.97000000000074, -34.18000000000036, -40.210000000000356, -46.24000000000034, -42.37000000000011, 81.1700000000006, 101.00000000000007, -34.5100000000001, -0.00999999999999836, -94.47999999999922, 12.88999999999996, 2.0000000000000013, 101.00000000000001, -51.88000000000005, -108.82000000000002, -62.320000000000334, 147.19999999999993, -29.859999999999843, 88.16, 93.41000000000011, -22.74999999999998, 145.42999999999998, -40.210000000000356, -152.92000000000098, -22.38999999999975, 44.53999999999989, 115.5800000000001, -56.290000000000234, 118.28000000000009, 11.120000000000017, -28.359999999999754, 2.0000000000000013, -176.8900000000008, 188.12000000000006, -50.26000000000022, -16.089999999999712, -71.70999999999982, 2.0000000000000013, -40.899999999999956, 0.22999999999999177, -10.15000000000004, -40.96000000000021, 20.810000000000027, -68.34999999999927, 176.14999999999992, 69.22999999999996, 9.560000000000121, 2.0000000000000013, -108.54999999999926, 131.35999999999987, -195.0100000000009, 66.58999999999995, 2.0000000000000013, -1.1500000000000206, -30.159999999999734, 114.77000000000011, 135.26000000000002, 3.979999999999972, 65.3600000000002, -13.900000000000016, -83.52999999999925, -52.270000000000344, 48.52999999999988, 80.20999999999997, -42.580000000000254, 2.0000000000000013, -196.87000000000012, 114.20000000000005, -28.360000000000007, -45.81999999999998, 22.429999999999975, -24.159999999999727, -93.72999999999993, 12.709999999999965, 17.089999999999996, 6.85999999999996, 120.11000000000001, -18.939999999999987, -33.19000000000036, 12.889999999999848, -35.73999999999992, 67.1, 109.04, -91.0, 1.8800000000000014, -30.159999999999716, -74.76999999999997, 113.81000000000016, 62.30000000000004, -19.599999999999785, 133.61, -2.9200000000000017, 48.29000000000003, 13.129999999999782, -4.060000000000041, -2.0200000000000404, -72.36999999999918, 18.709999999999965, 85.09999999999998, -27.730000000000004, -13.3899999999998, 103.43000000000006, 1.8500000000000014, -14.080000000000041, -16.390000000000114, -3.939999999999994, 2.0000000000000013, -19.120000000000122, 2.0000000000000013, 2.0000000000000013, -36.19000000000036, 2.0000000000000013, 2.0000000000000013, -29.07999999999992, -55.539999999999765, 96.08000000000001, -5.890000000000004, -68.02, 2.0000000000000013, 2.0000000000000013, 48.290000000000035, 2.0000000000000013, -49.27000000000034, -53.68000000000001, -40.210000000000356, 4.969999999999958, -120.7299999999999, 11.659999999999965, 57.259999999999955, 10.910000000000002, -63.820000000000036, -57.85000000000001, 46.51999999999997, -189.49000000000004, 31.609999999999978, -76.71999999999987, 9.919999999999959], "policy_predator_policy_reward": [154.0, 152.0, 140.0, 92.0, 96.0, 72.0, 75.0, 43.0, 41.0, 10.0, 153.0, 131.0, 57.0, 61.0, 146.0, 116.0, 7.0, 87.0, 98.0, 91.0, 74.0, 60.0, 46.0, 84.0, 27.0, 94.0, 60.0, 80.0, 22.0, 38.0, 102.0, 90.0, 38.0, 46.0, 132.0, 189.0, 55.0, 86.0, 2.0, 4.0, 85.0, 32.0, 0.0, 23.0, 15.0, 22.0, 41.0, 53.0, 26.0, 23.0, 133.0, 160.0, 72.0, 28.0, 58.0, 89.0, 82.0, 78.0, 91.0, 7.0, 39.0, 51.0, 117.0, 96.0, 23.0, 10.0, 48.0, 64.0, 9.0, 22.0, 10.0, 100.0, 54.0, 46.0, 1.0, 8.0, 147.0, 148.0, 85.0, 84.0, 65.0, 88.0, 52.0, 150.0, 26.0, 47.0, 67.0, 106.0, 47.0, 61.0, 95.0, 113.0, 78.0, 111.0, 97.0, 82.0, 48.0, 53.0, 64.0, 56.0, 83.0, 137.0, 27.0, 82.0, 30.0, 82.0, 77.0, 27.0, 54.0, 66.0, 57.0, 55.0, 106.0, 145.0, 13.0, 59.0, 30.0, 8.0, 41.0, 1.0, 1.0, 6.0, 63.0, 50.0, 0.0, 32.0, 89.0, 63.0, 145.0, 166.0, 86.0, 59.0, 155.0, 39.0, 50.0, 138.0, 62.0, 96.0, 46.0, 97.0, 133.0, 134.0, 70.0, 146.0, 131.0, 89.0, 119.0, 129.0, 190.0, 79.0, 88.0, 54.0, 84.0, 5.0, 146.0, 89.0, 30.0, 38.0, 13.0, 65.0, 70.0, 80.0, 155.0, 87.0, 56.0, 44.0, 133.0, 111.0, 143.0, 51.0, 56.0, 55.0, 29.0, 15.0, 4.0, 5.0, 111.0, 112.0, 150.0, 131.0, 115.0, 4.0, 65.0, 58.0, 8.0, 32.0, 125.0, 133.0, 128.0, 121.0, 31.0, 38.0, 143.0, 110.0, 124.0, 146.0, 175.0, 180.0, 106.0, 111.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8271260167304662, "mean_inference_ms": 2.1726911741015944, "mean_action_processing_ms": 0.31952938564312544, "mean_env_wait_ms": 0.2935478836089105, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037077665328979492, "StateBufferConnector_ms": 0.004493355751037598, "ViewRequirementAgentConnector_ms": 0.11352527141571045}, "num_episodes": 18, "episode_return_max": 396.13999999999993, "episode_return_min": -101.22999999999918, "episode_return_mean": 113.02449999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.32136288964494, "num_env_steps_trained_throughput_per_sec": 346.32136288964494, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 11809.576, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11809.519, "sample_time_ms": 1335.915, "learn_time_ms": 10455.965, "learn_throughput": 382.557, "synch_weights_time_ms": 13.753}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "0e60f_00000", "date": "2024-08-15_00-59-43", "timestamp": 1723663783, "time_this_iter_s": 11.592464923858643, "time_total_s": 203.03595876693726, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2abd9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 203.03595876693726, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 60.1, "ram_util_percent": 83.925}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.51844069008474, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.629628707239868, "policy_loss": -0.005325892854545994, "vf_loss": 6.633571783196989, "vf_explained_var": 0.0425784377509324, "kl": 0.006914042344237383, "entropy": 1.4052425574373315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.52636851576901, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.996416678252044, "policy_loss": -0.01313309378271538, "vf_loss": 7.005941615281282, "vf_explained_var": 0.07422864481254861, "kl": 0.018040795218478133, "entropy": 1.4682453432411113, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 396.13999999999993, "episode_reward_min": -65.59999999999832, "episode_reward_mean": 138.1240999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -199.83999999999992, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.12000000000006, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": -6.752949999999978, "predator_policy": 75.815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.750000000000007, 133.69000000000017, 232.36000000000007, -21.239999999999416, 30.950000000000575, -39.010000000000595, 45.379999999999676, 13.43999999999983, 73.64000000000023, 102.01000000000101, 15.229999999999995, -21.839999999999655, 81.12999999999991, -22.519999999999712, -41.39000000000072, 23.39000000000034, 213.16999999999928, 75.4800000000002, 18.410000000000355, 112.00000000000013, 134.29999999999973, 253.87999999999903, 211.29999999999927, 272.6599999999995, 178.21999999999977, -2.3099999999999934, 268.12000000000006, 269.98999999999904, 171.7599999999986, 4.11000000000001, 238.85999999999893, 32.20000000000009, 181.10000000000008, 99.08000000000008, 91.85000000000089, 211.79999999999947, 198.7899999999998, 5.4499999999999345, 187.34999999999945, 140.5900000000001, 6.689999999999923, 292.03000000000014, 76.34000000000037, 15.569999999999954, 28.260000000000424, 189.62999999999954, 116.12999999999997, 230.8399999999997, 170.61000000000007, 70.11, 187.79999999999953, 269.96999999999906, 214.8699999999995, 193.14999999999998, 396.13999999999993, 158.87999999999982, 164.06999999999988, 318.1099999999997, 203.01000000000013, 280.3700000000001, 77.06999999999998, 3.6100000000000527, 253.80999999999977, 200.88, 205.27999999999943, 213.5299999999998, 192.05999999999966, 93.88000000000017, 9.809999999999924, 12.999999999999915, 138.3800000000001, 371.1899999999998, 52.98000000000001, 173.28999999999985, -7.270000000000076, 164.11000000000024, 133.2400000000004, 137.9199999999999, 200.08999999999992, 258.6699999999998, 197.11999999999995, 150.19999999999965, -9.29000000000006, 191.33999999999995, 142.16000000000057, -65.59999999999832, 150.0800000000005, 186.2699999999997, 369.00999999999914, 163.7199999999986, 364.5699999999996, 164.54999999999944, 25.55000000000043, 168.48000000000053, 169.35, 67.72000000000013, 116.7400000000002, 312.92999999999995, 157.01999999999987, 154.75000000000023], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-44.23000000000035, -102.51999999999931, 129.70999999999998, -2.020000000000042, 49.07, 66.28999999999996, -24.12999999999971, -20.109999999999705, -8.050000000000042, 2.0000000000000013, -53.470000000000304, -79.53999999999927, 12.4700000000001, -16.089999999999716, -142.81000000000097, -136.74999999999994, -28.14999999999979, 1.7899999999999103, 2.0000000000000013, -46.99000000000017, -88.68999999999936, -56.07999999999975, -121.8399999999994, 2.0000000000000013, 45.41000000000019, -54.28000000000034, -51.55000000000024, -183.97000000000074, -34.18000000000036, -40.210000000000356, -46.24000000000034, -42.37000000000011, 81.1700000000006, 101.00000000000007, -34.5100000000001, -0.00999999999999836, -94.47999999999922, 12.88999999999996, 2.0000000000000013, 101.00000000000001, -51.88000000000005, -108.82000000000002, -62.320000000000334, 147.19999999999993, -29.859999999999843, 88.16, 93.41000000000011, -22.74999999999998, 145.42999999999998, -40.210000000000356, -152.92000000000098, -22.38999999999975, 44.53999999999989, 115.5800000000001, -56.290000000000234, 118.28000000000009, 11.120000000000017, -28.359999999999754, 2.0000000000000013, -176.8900000000008, 188.12000000000006, -50.26000000000022, -16.089999999999712, -71.70999999999982, 2.0000000000000013, -40.899999999999956, 0.22999999999999177, -10.15000000000004, -40.96000000000021, 20.810000000000027, -68.34999999999927, 176.14999999999992, 69.22999999999996, 9.560000000000121, 2.0000000000000013, -108.54999999999926, 131.35999999999987, -195.0100000000009, 66.58999999999995, 2.0000000000000013, -1.1500000000000206, -30.159999999999734, 114.77000000000011, 135.26000000000002, 3.979999999999972, 65.3600000000002, -13.900000000000016, -83.52999999999925, -52.270000000000344, 48.52999999999988, 80.20999999999997, -42.580000000000254, 2.0000000000000013, -196.87000000000012, 114.20000000000005, -28.360000000000007, -45.81999999999998, 22.429999999999975, -24.159999999999727, -93.72999999999993, 12.709999999999965, 17.089999999999996, 6.85999999999996, 120.11000000000001, -18.939999999999987, -33.19000000000036, 12.889999999999848, -35.73999999999992, 67.1, 109.04, -91.0, 1.8800000000000014, -30.159999999999716, -74.76999999999997, 113.81000000000016, 62.30000000000004, -19.599999999999785, 133.61, -2.9200000000000017, 48.29000000000003, 13.129999999999782, -4.060000000000041, -2.0200000000000404, -72.36999999999918, 18.709999999999965, 85.09999999999998, -27.730000000000004, -13.3899999999998, 103.43000000000006, 1.8500000000000014, -14.080000000000041, -16.390000000000114, -3.939999999999994, 2.0000000000000013, -19.120000000000122, 2.0000000000000013, 2.0000000000000013, -36.19000000000036, 2.0000000000000013, 2.0000000000000013, -29.07999999999992, -55.539999999999765, 96.08000000000001, -5.890000000000004, -68.02, 2.0000000000000013, 2.0000000000000013, 48.290000000000035, 2.0000000000000013, -49.27000000000034, -53.68000000000001, -40.210000000000356, 4.969999999999958, -120.7299999999999, 11.659999999999965, 57.259999999999955, 10.910000000000002, -63.820000000000036, -57.85000000000001, 46.51999999999997, -189.49000000000004, 31.609999999999978, -76.71999999999987, 9.919999999999959, -34.180000000000355, -20.109999999999705, -41.94999999999999, -17.710000000000043, -199.83999999999992, 2.0000000000000013, -52.27000000000034, -64.32999999999916, -14.500000000000057, -10.419999999999945, 67.03999999999992, 15.230000000000157, 73.91000000000041, 85.10000000000002, -4.539999999999955, 48.259999999999806, 20.240000000000013, 65.33000000000011, -20.10999999999971, 65.66000000000001, -82.44999999999925, 2.0000000000000013, -30.159999999999712, 136.64000000000027, 9.919999999999959, -91.56999999999982, -39.40000000000002, -69.87999999999943, -14.050000000000006, -55.21000000000002, 138.5600000000002, -73.62999999999981, -115.80999999999992, 6.829999999999844, -94.74999999999937, 15.499999999999982], "policy_predator_policy_reward": [55.0, 86.0, 2.0, 4.0, 85.0, 32.0, 0.0, 23.0, 15.0, 22.0, 41.0, 53.0, 26.0, 23.0, 133.0, 160.0, 72.0, 28.0, 58.0, 89.0, 82.0, 78.0, 91.0, 7.0, 39.0, 51.0, 117.0, 96.0, 23.0, 10.0, 48.0, 64.0, 9.0, 22.0, 10.0, 100.0, 54.0, 46.0, 1.0, 8.0, 147.0, 148.0, 85.0, 84.0, 65.0, 88.0, 52.0, 150.0, 26.0, 47.0, 67.0, 106.0, 47.0, 61.0, 95.0, 113.0, 78.0, 111.0, 97.0, 82.0, 48.0, 53.0, 64.0, 56.0, 83.0, 137.0, 27.0, 82.0, 30.0, 82.0, 77.0, 27.0, 54.0, 66.0, 57.0, 55.0, 106.0, 145.0, 13.0, 59.0, 30.0, 8.0, 41.0, 1.0, 1.0, 6.0, 63.0, 50.0, 0.0, 32.0, 89.0, 63.0, 145.0, 166.0, 86.0, 59.0, 155.0, 39.0, 50.0, 138.0, 62.0, 96.0, 46.0, 97.0, 133.0, 134.0, 70.0, 146.0, 131.0, 89.0, 119.0, 129.0, 190.0, 79.0, 88.0, 54.0, 84.0, 5.0, 146.0, 89.0, 30.0, 38.0, 13.0, 65.0, 70.0, 80.0, 155.0, 87.0, 56.0, 44.0, 133.0, 111.0, 143.0, 51.0, 56.0, 55.0, 29.0, 15.0, 4.0, 5.0, 111.0, 112.0, 150.0, 131.0, 115.0, 4.0, 65.0, 58.0, 8.0, 32.0, 125.0, 133.0, 128.0, 121.0, 31.0, 38.0, 143.0, 110.0, 124.0, 146.0, 175.0, 180.0, 106.0, 111.0, 24.0, 21.0, 124.0, 127.0, 173.0, 167.0, 11.0, 40.0, 97.0, 78.0, 60.0, 44.0, 112.0, 98.0, 38.0, 82.0, 118.0, 161.0, 42.0, 77.0, 46.0, 60.0, 24.0, 38.0, 129.0, 122.0, 87.0, 90.0, 90.0, 96.0, 104.0, 144.0, 136.0, 130.0, 129.0, 105.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8170071232363216, "mean_inference_ms": 2.141354858475948, "mean_action_processing_ms": 0.3155864028033004, "mean_env_wait_ms": 0.2887628694565448, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0037130117416381836, "StateBufferConnector_ms": 0.004491925239562988, "ViewRequirementAgentConnector_ms": 0.11331319808959961}, "num_episodes": 18, "episode_return_max": 396.13999999999993, "episode_return_min": -65.59999999999832, "episode_return_mean": 138.1240999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.53807451522675, "num_env_steps_trained_throughput_per_sec": 311.53807451522675, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 11920.079, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11920.02, "sample_time_ms": 1336.023, "learn_time_ms": 10565.599, "learn_throughput": 378.587, "synch_weights_time_ms": 14.225}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "0e60f_00000", "date": "2024-08-15_00-59-56", "timestamp": 1723663796, "time_this_iter_s": 12.869302988052368, "time_total_s": 215.90526175498962, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fcb5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 215.90526175498962, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 66.0, "ram_util_percent": 83.86842105263158}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2358237463645834, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.559403623601116, "policy_loss": -0.006386672624845117, "vf_loss": 6.564295945091853, "vf_explained_var": -0.11158157826731445, "kl": 0.007471768363677898, "entropy": 1.4065750299938142, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8564545394251586, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.989940607232391, "policy_loss": -0.008479295321617019, "vf_loss": 7.995415288178378, "vf_explained_var": 0.03569838101901705, "kl": 0.01502309441116576, "entropy": 1.475491625669772, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 396.13999999999993, "episode_reward_min": -226.7800000000001, "episode_reward_mean": 144.11259999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -321.8500000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.12000000000006, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -15.048699999999972, "predator_policy": 87.105}, "custom_metrics": {}, "hist_stats": {"episode_reward": [211.29999999999927, 272.6599999999995, 178.21999999999977, -2.3099999999999934, 268.12000000000006, 269.98999999999904, 171.7599999999986, 4.11000000000001, 238.85999999999893, 32.20000000000009, 181.10000000000008, 99.08000000000008, 91.85000000000089, 211.79999999999947, 198.7899999999998, 5.4499999999999345, 187.34999999999945, 140.5900000000001, 6.689999999999923, 292.03000000000014, 76.34000000000037, 15.569999999999954, 28.260000000000424, 189.62999999999954, 116.12999999999997, 230.8399999999997, 170.61000000000007, 70.11, 187.79999999999953, 269.96999999999906, 214.8699999999995, 193.14999999999998, 396.13999999999993, 158.87999999999982, 164.06999999999988, 318.1099999999997, 203.01000000000013, 280.3700000000001, 77.06999999999998, 3.6100000000000527, 253.80999999999977, 200.88, 205.27999999999943, 213.5299999999998, 192.05999999999966, 93.88000000000017, 9.809999999999924, 12.999999999999915, 138.3800000000001, 371.1899999999998, 52.98000000000001, 173.28999999999985, -7.270000000000076, 164.11000000000024, 133.2400000000004, 137.9199999999999, 200.08999999999992, 258.6699999999998, 197.11999999999995, 150.19999999999965, -9.29000000000006, 191.33999999999995, 142.16000000000057, -65.59999999999832, 150.0800000000005, 186.2699999999997, 369.00999999999914, 163.7199999999986, 364.5699999999996, 164.54999999999944, 25.55000000000043, 168.48000000000053, 169.35, 67.72000000000013, 116.7400000000002, 312.92999999999995, 157.01999999999987, 154.75000000000023, 226.66999999999987, 60.03999999999988, -226.7800000000001, 216.22999999999945, 137.88999999999996, 199.94999999999976, 134.73000000000047, 91.17000000000014, 130.04000000000036, 118.81000000000033, 16.98000000000009, -216.3100000000004, 7.959999999999792, 13.639999999999924, 273.6699999999996, 81.90000000000002, 136.50000000000026, 15.729999999999928, 225.13999999999916, 151.6099999999995, 58.550000000000026, 151.4399999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-29.859999999999843, 88.16, 93.41000000000011, -22.74999999999998, 145.42999999999998, -40.210000000000356, -152.92000000000098, -22.38999999999975, 44.53999999999989, 115.5800000000001, -56.290000000000234, 118.28000000000009, 11.120000000000017, -28.359999999999754, 2.0000000000000013, -176.8900000000008, 188.12000000000006, -50.26000000000022, -16.089999999999712, -71.70999999999982, 2.0000000000000013, -40.899999999999956, 0.22999999999999177, -10.15000000000004, -40.96000000000021, 20.810000000000027, -68.34999999999927, 176.14999999999992, 69.22999999999996, 9.560000000000121, 2.0000000000000013, -108.54999999999926, 131.35999999999987, -195.0100000000009, 66.58999999999995, 2.0000000000000013, -1.1500000000000206, -30.159999999999734, 114.77000000000011, 135.26000000000002, 3.979999999999972, 65.3600000000002, -13.900000000000016, -83.52999999999925, -52.270000000000344, 48.52999999999988, 80.20999999999997, -42.580000000000254, 2.0000000000000013, -196.87000000000012, 114.20000000000005, -28.360000000000007, -45.81999999999998, 22.429999999999975, -24.159999999999727, -93.72999999999993, 12.709999999999965, 17.089999999999996, 6.85999999999996, 120.11000000000001, -18.939999999999987, -33.19000000000036, 12.889999999999848, -35.73999999999992, 67.1, 109.04, -91.0, 1.8800000000000014, -30.159999999999716, -74.76999999999997, 113.81000000000016, 62.30000000000004, -19.599999999999785, 133.61, -2.9200000000000017, 48.29000000000003, 13.129999999999782, -4.060000000000041, -2.0200000000000404, -72.36999999999918, 18.709999999999965, 85.09999999999998, -27.730000000000004, -13.3899999999998, 103.43000000000006, 1.8500000000000014, -14.080000000000041, -16.390000000000114, -3.939999999999994, 2.0000000000000013, -19.120000000000122, 2.0000000000000013, 2.0000000000000013, -36.19000000000036, 2.0000000000000013, 2.0000000000000013, -29.07999999999992, -55.539999999999765, 96.08000000000001, -5.890000000000004, -68.02, 2.0000000000000013, 2.0000000000000013, 48.290000000000035, 2.0000000000000013, -49.27000000000034, -53.68000000000001, -40.210000000000356, 4.969999999999958, -120.7299999999999, 11.659999999999965, 57.259999999999955, 10.910000000000002, -63.820000000000036, -57.85000000000001, 46.51999999999997, -189.49000000000004, 31.609999999999978, -76.71999999999987, 9.919999999999959, -34.180000000000355, -20.109999999999705, -41.94999999999999, -17.710000000000043, -199.83999999999992, 2.0000000000000013, -52.27000000000034, -64.32999999999916, -14.500000000000057, -10.419999999999945, 67.03999999999992, 15.230000000000157, 73.91000000000041, 85.10000000000002, -4.539999999999955, 48.259999999999806, 20.240000000000013, 65.33000000000011, -20.10999999999971, 65.66000000000001, -82.44999999999925, 2.0000000000000013, -30.159999999999712, 136.64000000000027, 9.919999999999959, -91.56999999999982, -39.40000000000002, -69.87999999999943, -14.050000000000006, -55.21000000000002, 138.5600000000002, -73.62999999999981, -115.80999999999992, 6.829999999999844, -94.74999999999937, 15.499999999999982, -122.80000000000013, 15.470000000000013, -98.76999999999987, -21.189999999999724, -278.8300000000001, -296.95, -3.790000000000026, -50.980000000000004, -118.26999999999975, -88.83999999999993, -86.6799999999999, -15.370000000000086, -59.97999999999948, -65.28999999999964, -22.63000000000003, -134.1999999999996, -205.96000000000004, 2.0000000000000013, -94.44999999999973, 18.259999999999984, -2.020000000000042, 2.0000000000000013, -282.46000000000026, -321.8500000000001, -55.959999999999496, -14.080000000000041, -28.14999999999971, -37.21000000000033, 71.24000000000001, -22.570000000000054, -169.51000000000045, 15.41000000000001, -48.25000000000035, 86.75000000000006, -25.26999999999975, 2.0000000000000013, -12.070000000000041, 74.21000000000004, -133.29999999999993, 4.909999999999962, -6.040000000000042, 42.59000000000002, 22.73000000000025, -113.29000000000002], "policy_predator_policy_reward": [65.0, 88.0, 52.0, 150.0, 26.0, 47.0, 67.0, 106.0, 47.0, 61.0, 95.0, 113.0, 78.0, 111.0, 97.0, 82.0, 48.0, 53.0, 64.0, 56.0, 83.0, 137.0, 27.0, 82.0, 30.0, 82.0, 77.0, 27.0, 54.0, 66.0, 57.0, 55.0, 106.0, 145.0, 13.0, 59.0, 30.0, 8.0, 41.0, 1.0, 1.0, 6.0, 63.0, 50.0, 0.0, 32.0, 89.0, 63.0, 145.0, 166.0, 86.0, 59.0, 155.0, 39.0, 50.0, 138.0, 62.0, 96.0, 46.0, 97.0, 133.0, 134.0, 70.0, 146.0, 131.0, 89.0, 119.0, 129.0, 190.0, 79.0, 88.0, 54.0, 84.0, 5.0, 146.0, 89.0, 30.0, 38.0, 13.0, 65.0, 70.0, 80.0, 155.0, 87.0, 56.0, 44.0, 133.0, 111.0, 143.0, 51.0, 56.0, 55.0, 29.0, 15.0, 4.0, 5.0, 111.0, 112.0, 150.0, 131.0, 115.0, 4.0, 65.0, 58.0, 8.0, 32.0, 125.0, 133.0, 128.0, 121.0, 31.0, 38.0, 143.0, 110.0, 124.0, 146.0, 175.0, 180.0, 106.0, 111.0, 24.0, 21.0, 124.0, 127.0, 173.0, 167.0, 11.0, 40.0, 97.0, 78.0, 60.0, 44.0, 112.0, 98.0, 38.0, 82.0, 118.0, 161.0, 42.0, 77.0, 46.0, 60.0, 24.0, 38.0, 129.0, 122.0, 87.0, 90.0, 90.0, 96.0, 104.0, 144.0, 136.0, 130.0, 129.0, 105.0, 143.0, 191.0, 79.0, 101.0, 149.0, 200.0, 127.0, 144.0, 156.0, 189.0, 128.0, 174.0, 138.0, 122.0, 117.0, 131.0, 136.0, 198.0, 51.0, 144.0, 15.0, 2.0, 188.0, 200.0, 18.0, 60.0, 32.0, 47.0, 128.0, 97.0, 128.0, 108.0, 60.0, 38.0, 2.0, 37.0, 135.0, 28.0, 114.0, 166.0, 9.0, 13.0, 140.0, 102.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8056297994725223, "mean_inference_ms": 2.1068462351825845, "mean_action_processing_ms": 0.3112904138099893, "mean_env_wait_ms": 0.2840218775948955, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003747224807739258, "StateBufferConnector_ms": 0.0031595230102539062, "ViewRequirementAgentConnector_ms": 0.1182030439376831}, "num_episodes": 22, "episode_return_max": 396.13999999999993, "episode_return_min": -226.7800000000001, "episode_return_mean": 144.11259999999987, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 332.0875870971471, "num_env_steps_trained_throughput_per_sec": 332.0875870971471, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 11938.249, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11938.192, "sample_time_ms": 1320.777, "learn_time_ms": 10600.397, "learn_throughput": 377.344, "synch_weights_time_ms": 13.541}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "0e60f_00000", "date": "2024-08-15_01-00-08", "timestamp": 1723663808, "time_this_iter_s": 12.093626022338867, "time_total_s": 227.9988877773285, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb0af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 227.9988877773285, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 65.42941176470588, "ram_util_percent": 83.69411764705882}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5860928902550349, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.197897680474337, "policy_loss": -0.0072392972246571275, "vf_loss": 6.203267374240532, "vf_explained_var": -0.07145440975824992, "kl": 0.009348000787348935, "entropy": 1.4063865484384002, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3293360505469893, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.557167332008403, "policy_loss": -0.004623799109043031, "vf_loss": 8.560177269436064, "vf_explained_var": 0.00497565887592457, "kl": 0.008069232315900997, "entropy": 1.4834227804784421, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 396.13999999999993, "episode_reward_min": -355.6400000000003, "episode_reward_mean": 111.20549999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.9000000000001, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 138.5600000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -48.50724999999999, "predator_policy": 104.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [189.62999999999954, 116.12999999999997, 230.8399999999997, 170.61000000000007, 70.11, 187.79999999999953, 269.96999999999906, 214.8699999999995, 193.14999999999998, 396.13999999999993, 158.87999999999982, 164.06999999999988, 318.1099999999997, 203.01000000000013, 280.3700000000001, 77.06999999999998, 3.6100000000000527, 253.80999999999977, 200.88, 205.27999999999943, 213.5299999999998, 192.05999999999966, 93.88000000000017, 9.809999999999924, 12.999999999999915, 138.3800000000001, 371.1899999999998, 52.98000000000001, 173.28999999999985, -7.270000000000076, 164.11000000000024, 133.2400000000004, 137.9199999999999, 200.08999999999992, 258.6699999999998, 197.11999999999995, 150.19999999999965, -9.29000000000006, 191.33999999999995, 142.16000000000057, -65.59999999999832, 150.0800000000005, 186.2699999999997, 369.00999999999914, 163.7199999999986, 364.5699999999996, 164.54999999999944, 25.55000000000043, 168.48000000000053, 169.35, 67.72000000000013, 116.7400000000002, 312.92999999999995, 157.01999999999987, 154.75000000000023, 226.66999999999987, 60.03999999999988, -226.7800000000001, 216.22999999999945, 137.88999999999996, 199.94999999999976, 134.73000000000047, 91.17000000000014, 130.04000000000036, 118.81000000000033, 16.98000000000009, -216.3100000000004, 7.959999999999792, 13.639999999999924, 273.6699999999996, 81.90000000000002, 136.50000000000026, 15.729999999999928, 225.13999999999916, 151.6099999999995, 58.550000000000026, 151.4399999999992, 31.090000000000078, -18.429999999999474, 74.38999999999999, -257.49, -22.479999999999535, -52.319999999999965, 101.360000000001, -62.93000000000002, 248.13999999999953, 76.09000000000019, 155.78000000000026, 77.81999999999998, -355.6400000000003, 39.150000000000254, 93.23000000000086, -190.7800000000011, -211.3300000000002, 92.79000000000002, 106.9800000000007, -99.03000000000031, -128.6100000000001, 191.4599999999998, -0.14000000000004098], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [80.20999999999997, -42.580000000000254, 2.0000000000000013, -196.87000000000012, 114.20000000000005, -28.360000000000007, -45.81999999999998, 22.429999999999975, -24.159999999999727, -93.72999999999993, 12.709999999999965, 17.089999999999996, 6.85999999999996, 120.11000000000001, -18.939999999999987, -33.19000000000036, 12.889999999999848, -35.73999999999992, 67.1, 109.04, -91.0, 1.8800000000000014, -30.159999999999716, -74.76999999999997, 113.81000000000016, 62.30000000000004, -19.599999999999785, 133.61, -2.9200000000000017, 48.29000000000003, 13.129999999999782, -4.060000000000041, -2.0200000000000404, -72.36999999999918, 18.709999999999965, 85.09999999999998, -27.730000000000004, -13.3899999999998, 103.43000000000006, 1.8500000000000014, -14.080000000000041, -16.390000000000114, -3.939999999999994, 2.0000000000000013, -19.120000000000122, 2.0000000000000013, 2.0000000000000013, -36.19000000000036, 2.0000000000000013, 2.0000000000000013, -29.07999999999992, -55.539999999999765, 96.08000000000001, -5.890000000000004, -68.02, 2.0000000000000013, 2.0000000000000013, 48.290000000000035, 2.0000000000000013, -49.27000000000034, -53.68000000000001, -40.210000000000356, 4.969999999999958, -120.7299999999999, 11.659999999999965, 57.259999999999955, 10.910000000000002, -63.820000000000036, -57.85000000000001, 46.51999999999997, -189.49000000000004, 31.609999999999978, -76.71999999999987, 9.919999999999959, -34.180000000000355, -20.109999999999705, -41.94999999999999, -17.710000000000043, -199.83999999999992, 2.0000000000000013, -52.27000000000034, -64.32999999999916, -14.500000000000057, -10.419999999999945, 67.03999999999992, 15.230000000000157, 73.91000000000041, 85.10000000000002, -4.539999999999955, 48.259999999999806, 20.240000000000013, 65.33000000000011, -20.10999999999971, 65.66000000000001, -82.44999999999925, 2.0000000000000013, -30.159999999999712, 136.64000000000027, 9.919999999999959, -91.56999999999982, -39.40000000000002, -69.87999999999943, -14.050000000000006, -55.21000000000002, 138.5600000000002, -73.62999999999981, -115.80999999999992, 6.829999999999844, -94.74999999999937, 15.499999999999982, -122.80000000000013, 15.470000000000013, -98.76999999999987, -21.189999999999724, -278.8300000000001, -296.95, -3.790000000000026, -50.980000000000004, -118.26999999999975, -88.83999999999993, -86.6799999999999, -15.370000000000086, -59.97999999999948, -65.28999999999964, -22.63000000000003, -134.1999999999996, -205.96000000000004, 2.0000000000000013, -94.44999999999973, 18.259999999999984, -2.020000000000042, 2.0000000000000013, -282.46000000000026, -321.8500000000001, -55.959999999999496, -14.080000000000041, -28.14999999999971, -37.21000000000033, 71.24000000000001, -22.570000000000054, -169.51000000000045, 15.41000000000001, -48.25000000000035, 86.75000000000006, -25.26999999999975, 2.0000000000000013, -12.070000000000041, 74.21000000000004, -133.29999999999993, 4.909999999999962, -6.040000000000042, 42.59000000000002, 22.73000000000025, -113.29000000000002, -312.7000000000002, -40.21000000000035, -18.099999999999707, -64.32999999999925, -16.450000000000003, -27.159999999999734, -314.6500000000003, -316.84000000000015, -50.260000000000346, -42.220000000000354, -251.80000000000013, -165.52, -8.050000000000042, -167.5900000000002, -209.0800000000001, -168.85000000000008, -4.030000000000041, 24.169999999999998, -15.189999999999863, -259.72, -78.22000000000008, 2.0000000000000013, -126.63999999999993, -121.53999999999981, -347.74000000000024, -364.9000000000001, 2.0000000000000013, -156.85000000000008, -177.66999999999996, -18.099999999999703, -344.74000000000024, -207.04000000000087, -266.5000000000004, -332.8300000000001, -109.80999999999996, -96.39999999999978, -54.280000000000335, -86.73999999999998, -214.81000000000017, -210.22000000000065, -279.79000000000013, -231.8200000000001, -76.53999999999996, 2.0000000000000013, -26.139999999999713, 2.0000000000000013], "policy_predator_policy_reward": [89.0, 63.0, 145.0, 166.0, 86.0, 59.0, 155.0, 39.0, 50.0, 138.0, 62.0, 96.0, 46.0, 97.0, 133.0, 134.0, 70.0, 146.0, 131.0, 89.0, 119.0, 129.0, 190.0, 79.0, 88.0, 54.0, 84.0, 5.0, 146.0, 89.0, 30.0, 38.0, 13.0, 65.0, 70.0, 80.0, 155.0, 87.0, 56.0, 44.0, 133.0, 111.0, 143.0, 51.0, 56.0, 55.0, 29.0, 15.0, 4.0, 5.0, 111.0, 112.0, 150.0, 131.0, 115.0, 4.0, 65.0, 58.0, 8.0, 32.0, 125.0, 133.0, 128.0, 121.0, 31.0, 38.0, 143.0, 110.0, 124.0, 146.0, 175.0, 180.0, 106.0, 111.0, 24.0, 21.0, 124.0, 127.0, 173.0, 167.0, 11.0, 40.0, 97.0, 78.0, 60.0, 44.0, 112.0, 98.0, 38.0, 82.0, 118.0, 161.0, 42.0, 77.0, 46.0, 60.0, 24.0, 38.0, 129.0, 122.0, 87.0, 90.0, 90.0, 96.0, 104.0, 144.0, 136.0, 130.0, 129.0, 105.0, 143.0, 191.0, 79.0, 101.0, 149.0, 200.0, 127.0, 144.0, 156.0, 189.0, 128.0, 174.0, 138.0, 122.0, 117.0, 131.0, 136.0, 198.0, 51.0, 144.0, 15.0, 2.0, 188.0, 200.0, 18.0, 60.0, 32.0, 47.0, 128.0, 97.0, 128.0, 108.0, 60.0, 38.0, 2.0, 37.0, 135.0, 28.0, 114.0, 166.0, 9.0, 13.0, 140.0, 102.0, 191.0, 193.0, 16.0, 48.0, 74.0, 44.0, 177.0, 197.0, 38.0, 32.0, 196.0, 169.0, 128.0, 149.0, 153.0, 162.0, 83.0, 145.0, 198.0, 153.0, 67.0, 165.0, 158.0, 168.0, 200.0, 157.0, 132.0, 62.0, 176.0, 113.0, 180.0, 181.0, 193.0, 195.0, 171.0, 128.0, 126.0, 122.0, 173.0, 153.0, 186.0, 197.0, 91.0, 175.0, 2.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7951393480730781, "mean_inference_ms": 2.077386334788394, "mean_action_processing_ms": 0.30762569025080694, "mean_env_wait_ms": 0.27944579619045595, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0040438175201416016, "StateBufferConnector_ms": 0.0033197402954101562, "ViewRequirementAgentConnector_ms": 0.1191939115524292}, "num_episodes": 23, "episode_return_max": 396.13999999999993, "episode_return_min": -355.6400000000003, "episode_return_mean": 111.20549999999992, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.77494561352364, "num_env_steps_trained_throughput_per_sec": 341.77494561352364, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 11961.461, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11961.404, "sample_time_ms": 1315.667, "learn_time_ms": 10628.374, "learn_throughput": 376.351, "synch_weights_time_ms": 13.759}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "0e60f_00000", "date": "2024-08-15_01-00-20", "timestamp": 1723663820, "time_this_iter_s": 11.759883880615234, "time_total_s": 239.75877165794373, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2af9a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 239.75877165794373, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 61.681250000000006, "ram_util_percent": 83.53125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8585157662472398, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.365931031060597, "policy_loss": -0.011129988168573215, "vf_loss": 6.374387042736881, "vf_explained_var": -0.04912800681654108, "kl": 0.013369883434210977, "entropy": 1.4153273747711586, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3285271907924976, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.317132340789472, "policy_loss": -0.004033089062277838, "vf_loss": 8.319418900353568, "vf_explained_var": 0.007468827344753124, "kl": 0.008732674023296937, "entropy": 1.4876145518015302, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 371.1899999999998, "episode_reward_min": -355.6400000000003, "episode_reward_mean": 65.81629999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -381.9100000000001, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 138.5600000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -80.69184999999999, "predator_policy": 113.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [200.88, 205.27999999999943, 213.5299999999998, 192.05999999999966, 93.88000000000017, 9.809999999999924, 12.999999999999915, 138.3800000000001, 371.1899999999998, 52.98000000000001, 173.28999999999985, -7.270000000000076, 164.11000000000024, 133.2400000000004, 137.9199999999999, 200.08999999999992, 258.6699999999998, 197.11999999999995, 150.19999999999965, -9.29000000000006, 191.33999999999995, 142.16000000000057, -65.59999999999832, 150.0800000000005, 186.2699999999997, 369.00999999999914, 163.7199999999986, 364.5699999999996, 164.54999999999944, 25.55000000000043, 168.48000000000053, 169.35, 67.72000000000013, 116.7400000000002, 312.92999999999995, 157.01999999999987, 154.75000000000023, 226.66999999999987, 60.03999999999988, -226.7800000000001, 216.22999999999945, 137.88999999999996, 199.94999999999976, 134.73000000000047, 91.17000000000014, 130.04000000000036, 118.81000000000033, 16.98000000000009, -216.3100000000004, 7.959999999999792, 13.639999999999924, 273.6699999999996, 81.90000000000002, 136.50000000000026, 15.729999999999928, 225.13999999999916, 151.6099999999995, 58.550000000000026, 151.4399999999992, 31.090000000000078, -18.429999999999474, 74.38999999999999, -257.49, -22.479999999999535, -52.319999999999965, 101.360000000001, -62.93000000000002, 248.13999999999953, 76.09000000000019, 155.78000000000026, 77.81999999999998, -355.6400000000003, 39.150000000000254, 93.23000000000086, -190.7800000000011, -211.3300000000002, 92.79000000000002, 106.9800000000007, -99.03000000000031, -128.6100000000001, 191.4599999999998, -0.14000000000004098, -28.9900000000001, -45.67999999999991, 57.39000000000002, 40.22000000000016, -129.07000000000016, -282.4400000000004, -9.210000000000115, 29.880000000000308, -10.20000000000006, -34.38000000000021, -276.49000000000046, -74.93000000000004, -3.1300000000000594, -105.69, -297.68999999999994, 50.849999999999355, 34.70999999999957, 44.10999999999977], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-27.730000000000004, -13.3899999999998, 103.43000000000006, 1.8500000000000014, -14.080000000000041, -16.390000000000114, -3.939999999999994, 2.0000000000000013, -19.120000000000122, 2.0000000000000013, 2.0000000000000013, -36.19000000000036, 2.0000000000000013, 2.0000000000000013, -29.07999999999992, -55.539999999999765, 96.08000000000001, -5.890000000000004, -68.02, 2.0000000000000013, 2.0000000000000013, 48.290000000000035, 2.0000000000000013, -49.27000000000034, -53.68000000000001, -40.210000000000356, 4.969999999999958, -120.7299999999999, 11.659999999999965, 57.259999999999955, 10.910000000000002, -63.820000000000036, -57.85000000000001, 46.51999999999997, -189.49000000000004, 31.609999999999978, -76.71999999999987, 9.919999999999959, -34.180000000000355, -20.109999999999705, -41.94999999999999, -17.710000000000043, -199.83999999999992, 2.0000000000000013, -52.27000000000034, -64.32999999999916, -14.500000000000057, -10.419999999999945, 67.03999999999992, 15.230000000000157, 73.91000000000041, 85.10000000000002, -4.539999999999955, 48.259999999999806, 20.240000000000013, 65.33000000000011, -20.10999999999971, 65.66000000000001, -82.44999999999925, 2.0000000000000013, -30.159999999999712, 136.64000000000027, 9.919999999999959, -91.56999999999982, -39.40000000000002, -69.87999999999943, -14.050000000000006, -55.21000000000002, 138.5600000000002, -73.62999999999981, -115.80999999999992, 6.829999999999844, -94.74999999999937, 15.499999999999982, -122.80000000000013, 15.470000000000013, -98.76999999999987, -21.189999999999724, -278.8300000000001, -296.95, -3.790000000000026, -50.980000000000004, -118.26999999999975, -88.83999999999993, -86.6799999999999, -15.370000000000086, -59.97999999999948, -65.28999999999964, -22.63000000000003, -134.1999999999996, -205.96000000000004, 2.0000000000000013, -94.44999999999973, 18.259999999999984, -2.020000000000042, 2.0000000000000013, -282.46000000000026, -321.8500000000001, -55.959999999999496, -14.080000000000041, -28.14999999999971, -37.21000000000033, 71.24000000000001, -22.570000000000054, -169.51000000000045, 15.41000000000001, -48.25000000000035, 86.75000000000006, -25.26999999999975, 2.0000000000000013, -12.070000000000041, 74.21000000000004, -133.29999999999993, 4.909999999999962, -6.040000000000042, 42.59000000000002, 22.73000000000025, -113.29000000000002, -312.7000000000002, -40.21000000000035, -18.099999999999707, -64.32999999999925, -16.450000000000003, -27.159999999999734, -314.6500000000003, -316.84000000000015, -50.260000000000346, -42.220000000000354, -251.80000000000013, -165.52, -8.050000000000042, -167.5900000000002, -209.0800000000001, -168.85000000000008, -4.030000000000041, 24.169999999999998, -15.189999999999863, -259.72, -78.22000000000008, 2.0000000000000013, -126.63999999999993, -121.53999999999981, -347.74000000000024, -364.9000000000001, 2.0000000000000013, -156.85000000000008, -177.66999999999996, -18.099999999999703, -344.74000000000024, -207.04000000000087, -266.5000000000004, -332.8300000000001, -109.80999999999996, -96.39999999999978, -54.280000000000335, -86.73999999999998, -214.81000000000017, -210.22000000000065, -279.79000000000013, -231.8200000000001, -76.53999999999996, 2.0000000000000013, -26.139999999999713, 2.0000000000000013, -42.220000000000354, -314.7700000000001, -9.070000000000018, -321.6099999999998, -11.080000000000041, -263.5300000000002, 2.0000000000000013, -346.7800000000001, -30.159999999999712, -381.9100000000001, -294.5500000000004, -377.89000000000004, -80.43999999999983, -299.77000000000004, -218.1100000000008, -0.009999999999998581, -229.1499999999999, -8.050000000000011, -279.54999999999995, -104.82999999999942, -299.50000000000045, -376.99, -291.4599999999997, -92.47, -225.1300000000008, 2.0000000000000013, -274.39, -163.3, -301.81, -375.88000000000005, -6.040000000000042, -20.10999999999974, -5.290000000000026, 2.0000000000000013, -167.86000000000075, -4.030000000000014], "policy_predator_policy_reward": [155.0, 87.0, 56.0, 44.0, 133.0, 111.0, 143.0, 51.0, 56.0, 55.0, 29.0, 15.0, 4.0, 5.0, 111.0, 112.0, 150.0, 131.0, 115.0, 4.0, 65.0, 58.0, 8.0, 32.0, 125.0, 133.0, 128.0, 121.0, 31.0, 38.0, 143.0, 110.0, 124.0, 146.0, 175.0, 180.0, 106.0, 111.0, 24.0, 21.0, 124.0, 127.0, 173.0, 167.0, 11.0, 40.0, 97.0, 78.0, 60.0, 44.0, 112.0, 98.0, 38.0, 82.0, 118.0, 161.0, 42.0, 77.0, 46.0, 60.0, 24.0, 38.0, 129.0, 122.0, 87.0, 90.0, 90.0, 96.0, 104.0, 144.0, 136.0, 130.0, 129.0, 105.0, 143.0, 191.0, 79.0, 101.0, 149.0, 200.0, 127.0, 144.0, 156.0, 189.0, 128.0, 174.0, 138.0, 122.0, 117.0, 131.0, 136.0, 198.0, 51.0, 144.0, 15.0, 2.0, 188.0, 200.0, 18.0, 60.0, 32.0, 47.0, 128.0, 97.0, 128.0, 108.0, 60.0, 38.0, 2.0, 37.0, 135.0, 28.0, 114.0, 166.0, 9.0, 13.0, 140.0, 102.0, 191.0, 193.0, 16.0, 48.0, 74.0, 44.0, 177.0, 197.0, 38.0, 32.0, 196.0, 169.0, 128.0, 149.0, 153.0, 162.0, 83.0, 145.0, 198.0, 153.0, 67.0, 165.0, 158.0, 168.0, 200.0, 157.0, 132.0, 62.0, 176.0, 113.0, 180.0, 181.0, 193.0, 195.0, 171.0, 128.0, 126.0, 122.0, 173.0, 153.0, 186.0, 197.0, 91.0, 175.0, 2.0, 22.0, 136.0, 192.0, 173.0, 112.0, 170.0, 162.0, 194.0, 191.0, 197.0, 86.0, 200.0, 190.0, 187.0, 184.0, 104.0, 144.0, 122.0, 105.0, 183.0, 167.0, 200.0, 200.0, 152.0, 157.0, 100.0, 120.0, 146.0, 186.0, 180.0, 200.0, 36.0, 41.0, 16.0, 22.0, 92.0, 124.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7873142272219437, "mean_inference_ms": 2.0547373089991785, "mean_action_processing_ms": 0.304913123761605, "mean_env_wait_ms": 0.2761943121268056, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004101991653442383, "StateBufferConnector_ms": 0.003358125686645508, "ViewRequirementAgentConnector_ms": 0.1188666820526123}, "num_episodes": 18, "episode_return_max": 371.1899999999998, "episode_return_min": -355.6400000000003, "episode_return_mean": 65.81629999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 328.7680617531227, "num_env_steps_trained_throughput_per_sec": 328.7680617531227, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 12000.62, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12000.563, "sample_time_ms": 1313.622, "learn_time_ms": 10668.99, "learn_throughput": 374.918, "synch_weights_time_ms": 14.28}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "0e60f_00000", "date": "2024-08-15_01-00-32", "timestamp": 1723663832, "time_this_iter_s": 12.220722913742065, "time_total_s": 251.9794945716858, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fcb430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 251.9794945716858, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 62.60555555555555, "ram_util_percent": 83.6611111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5170209564859904, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.111427403631664, "policy_loss": -0.015281969206604771, "vf_loss": 5.123679061163039, "vf_explained_var": -0.007546282382238479, "kl": 0.015151614047331523, "entropy": 1.4400746940304994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.92540453603028, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.253676789652103, "policy_loss": -0.009790478132310368, "vf_loss": 7.261145638158082, "vf_explained_var": 0.05112773148471086, "kl": 0.011608125372284893, "entropy": 1.4849496290166542, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 369.00999999999914, "episode_reward_min": -355.6400000000003, "episode_reward_mean": 41.23230000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -381.9100000000001, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 138.5600000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -94.06884999999998, "predator_policy": 114.685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.19999999999965, -9.29000000000006, 191.33999999999995, 142.16000000000057, -65.59999999999832, 150.0800000000005, 186.2699999999997, 369.00999999999914, 163.7199999999986, 364.5699999999996, 164.54999999999944, 25.55000000000043, 168.48000000000053, 169.35, 67.72000000000013, 116.7400000000002, 312.92999999999995, 157.01999999999987, 154.75000000000023, 226.66999999999987, 60.03999999999988, -226.7800000000001, 216.22999999999945, 137.88999999999996, 199.94999999999976, 134.73000000000047, 91.17000000000014, 130.04000000000036, 118.81000000000033, 16.98000000000009, -216.3100000000004, 7.959999999999792, 13.639999999999924, 273.6699999999996, 81.90000000000002, 136.50000000000026, 15.729999999999928, 225.13999999999916, 151.6099999999995, 58.550000000000026, 151.4399999999992, 31.090000000000078, -18.429999999999474, 74.38999999999999, -257.49, -22.479999999999535, -52.319999999999965, 101.360000000001, -62.93000000000002, 248.13999999999953, 76.09000000000019, 155.78000000000026, 77.81999999999998, -355.6400000000003, 39.150000000000254, 93.23000000000086, -190.7800000000011, -211.3300000000002, 92.79000000000002, 106.9800000000007, -99.03000000000031, -128.6100000000001, 191.4599999999998, -0.14000000000004098, -28.9900000000001, -45.67999999999991, 57.39000000000002, 40.22000000000016, -129.07000000000016, -282.4400000000004, -9.210000000000115, 29.880000000000308, -10.20000000000006, -34.38000000000021, -276.49000000000046, -74.93000000000004, -3.1300000000000594, -105.69, -297.68999999999994, 50.849999999999355, 34.70999999999957, 44.10999999999977, 23.870000000000076, 79.27000000000102, 77.5600000000005, -28.919999999999995, -30.420000000000627, -4.800000000000388, -45.57999999999915, 18.75999999999999, 2.5000000000000737, 23.190000000000197, 48.98999999999976, 24.06000000000015, 67.19000000000044, 10.889999999999919, 113.66000000000136, -85.12999999999859, -1.2099999999998996, -4.12000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-76.71999999999987, 9.919999999999959, -34.180000000000355, -20.109999999999705, -41.94999999999999, -17.710000000000043, -199.83999999999992, 2.0000000000000013, -52.27000000000034, -64.32999999999916, -14.500000000000057, -10.419999999999945, 67.03999999999992, 15.230000000000157, 73.91000000000041, 85.10000000000002, -4.539999999999955, 48.259999999999806, 20.240000000000013, 65.33000000000011, -20.10999999999971, 65.66000000000001, -82.44999999999925, 2.0000000000000013, -30.159999999999712, 136.64000000000027, 9.919999999999959, -91.56999999999982, -39.40000000000002, -69.87999999999943, -14.050000000000006, -55.21000000000002, 138.5600000000002, -73.62999999999981, -115.80999999999992, 6.829999999999844, -94.74999999999937, 15.499999999999982, -122.80000000000013, 15.470000000000013, -98.76999999999987, -21.189999999999724, -278.8300000000001, -296.95, -3.790000000000026, -50.980000000000004, -118.26999999999975, -88.83999999999993, -86.6799999999999, -15.370000000000086, -59.97999999999948, -65.28999999999964, -22.63000000000003, -134.1999999999996, -205.96000000000004, 2.0000000000000013, -94.44999999999973, 18.259999999999984, -2.020000000000042, 2.0000000000000013, -282.46000000000026, -321.8500000000001, -55.959999999999496, -14.080000000000041, -28.14999999999971, -37.21000000000033, 71.24000000000001, -22.570000000000054, -169.51000000000045, 15.41000000000001, -48.25000000000035, 86.75000000000006, -25.26999999999975, 2.0000000000000013, -12.070000000000041, 74.21000000000004, -133.29999999999993, 4.909999999999962, -6.040000000000042, 42.59000000000002, 22.73000000000025, -113.29000000000002, -312.7000000000002, -40.21000000000035, -18.099999999999707, -64.32999999999925, -16.450000000000003, -27.159999999999734, -314.6500000000003, -316.84000000000015, -50.260000000000346, -42.220000000000354, -251.80000000000013, -165.52, -8.050000000000042, -167.5900000000002, -209.0800000000001, -168.85000000000008, -4.030000000000041, 24.169999999999998, -15.189999999999863, -259.72, -78.22000000000008, 2.0000000000000013, -126.63999999999993, -121.53999999999981, -347.74000000000024, -364.9000000000001, 2.0000000000000013, -156.85000000000008, -177.66999999999996, -18.099999999999703, -344.74000000000024, -207.04000000000087, -266.5000000000004, -332.8300000000001, -109.80999999999996, -96.39999999999978, -54.280000000000335, -86.73999999999998, -214.81000000000017, -210.22000000000065, -279.79000000000013, -231.8200000000001, -76.53999999999996, 2.0000000000000013, -26.139999999999713, 2.0000000000000013, -42.220000000000354, -314.7700000000001, -9.070000000000018, -321.6099999999998, -11.080000000000041, -263.5300000000002, 2.0000000000000013, -346.7800000000001, -30.159999999999712, -381.9100000000001, -294.5500000000004, -377.89000000000004, -80.43999999999983, -299.77000000000004, -218.1100000000008, -0.009999999999998581, -229.1499999999999, -8.050000000000011, -279.54999999999995, -104.82999999999942, -299.50000000000045, -376.99, -291.4599999999997, -92.47, -225.1300000000008, 2.0000000000000013, -274.39, -163.3, -301.81, -375.88000000000005, -6.040000000000042, -20.10999999999974, -5.290000000000026, 2.0000000000000013, -167.86000000000075, -4.030000000000014, -86.4399999999992, -133.68999999999986, 2.0000000000000013, -90.72999999999948, -70.35999999999916, -143.07999999999998, -305.5300000000004, -76.38999999999984, -38.20000000000036, -42.220000000000354, -68.34999999999916, -88.45000000000019, -190.95999999999964, -113.61999999999931, -10.060000000000041, -34.179999999999964, -221.2000000000007, -58.30000000000033, -32.17000000000036, -294.64, -199.0000000000009, -0.009999999999998581, -86.43999999999951, -86.49999999999935, -8.05000000000004, -135.76000000000073, 2.0000000000000013, -20.109999999999705, -1.3000000000000271, -6.040000000000008, -100.50999999999924, -116.61999999999931, -21.12999999999971, -14.080000000000041, -78.3999999999997, -142.72000000000048], "policy_predator_policy_reward": [106.0, 111.0, 24.0, 21.0, 124.0, 127.0, 173.0, 167.0, 11.0, 40.0, 97.0, 78.0, 60.0, 44.0, 112.0, 98.0, 38.0, 82.0, 118.0, 161.0, 42.0, 77.0, 46.0, 60.0, 24.0, 38.0, 129.0, 122.0, 87.0, 90.0, 90.0, 96.0, 104.0, 144.0, 136.0, 130.0, 129.0, 105.0, 143.0, 191.0, 79.0, 101.0, 149.0, 200.0, 127.0, 144.0, 156.0, 189.0, 128.0, 174.0, 138.0, 122.0, 117.0, 131.0, 136.0, 198.0, 51.0, 144.0, 15.0, 2.0, 188.0, 200.0, 18.0, 60.0, 32.0, 47.0, 128.0, 97.0, 128.0, 108.0, 60.0, 38.0, 2.0, 37.0, 135.0, 28.0, 114.0, 166.0, 9.0, 13.0, 140.0, 102.0, 191.0, 193.0, 16.0, 48.0, 74.0, 44.0, 177.0, 197.0, 38.0, 32.0, 196.0, 169.0, 128.0, 149.0, 153.0, 162.0, 83.0, 145.0, 198.0, 153.0, 67.0, 165.0, 158.0, 168.0, 200.0, 157.0, 132.0, 62.0, 176.0, 113.0, 180.0, 181.0, 193.0, 195.0, 171.0, 128.0, 126.0, 122.0, 173.0, 153.0, 186.0, 197.0, 91.0, 175.0, 2.0, 22.0, 136.0, 192.0, 173.0, 112.0, 170.0, 162.0, 194.0, 191.0, 197.0, 86.0, 200.0, 190.0, 187.0, 184.0, 104.0, 144.0, 122.0, 105.0, 183.0, 167.0, 200.0, 200.0, 152.0, 157.0, 100.0, 120.0, 146.0, 186.0, 180.0, 200.0, 36.0, 41.0, 16.0, 22.0, 92.0, 124.0, 126.0, 118.0, 83.0, 85.0, 134.0, 157.0, 187.0, 166.0, 26.0, 24.0, 98.0, 54.0, 133.0, 126.0, 16.0, 47.0, 160.0, 122.0, 185.0, 165.0, 110.0, 138.0, 121.0, 76.0, 110.0, 101.0, 16.0, 13.0, 79.0, 42.0, 76.0, 56.0, 10.0, 24.0, 135.0, 82.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7793858914305579, "mean_inference_ms": 2.0343808597898474, "mean_action_processing_ms": 0.30231816742583445, "mean_env_wait_ms": 0.27305306618753894, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004015445709228516, "StateBufferConnector_ms": 0.0033309459686279297, "ViewRequirementAgentConnector_ms": 0.10072338581085205}, "num_episodes": 18, "episode_return_max": 369.00999999999914, "episode_return_min": -355.6400000000003, "episode_return_mean": 41.23230000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.0611342065045, "num_env_steps_trained_throughput_per_sec": 347.0611342065045, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 12000.194, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12000.138, "sample_time_ms": 1308.082, "learn_time_ms": 10674.383, "learn_throughput": 374.729, "synch_weights_time_ms": 14.147}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "0e60f_00000", "date": "2024-08-15_01-00-44", "timestamp": 1723663844, "time_this_iter_s": 11.572968006134033, "time_total_s": 263.5524625778198, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2b01700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 263.5524625778198, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 59.943749999999994, "ram_util_percent": 83.5125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6960457298490736, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.724087402051088, "policy_loss": -0.010293724192257122, "vf_loss": 5.73225325226153, "vf_explained_var": 0.014495827912022828, "kl": 0.010639445303556505, "entropy": 1.444590532905841, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.784688021487029, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.32580850994776, "policy_loss": -0.012168998455027582, "vf_loss": 8.334774250202077, "vf_explained_var": 0.06152511652184542, "kl": 0.016016294159516217, "entropy": 1.4435613012187696, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 273.6699999999996, "episode_reward_min": -355.6400000000003, "episode_reward_mean": 12.92180000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -381.9100000000001, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 86.75000000000006, "predator_policy": 217.0}, "policy_reward_mean": {"prey_policy": -113.14910000000002, "predator_policy": 119.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [154.75000000000023, 226.66999999999987, 60.03999999999988, -226.7800000000001, 216.22999999999945, 137.88999999999996, 199.94999999999976, 134.73000000000047, 91.17000000000014, 130.04000000000036, 118.81000000000033, 16.98000000000009, -216.3100000000004, 7.959999999999792, 13.639999999999924, 273.6699999999996, 81.90000000000002, 136.50000000000026, 15.729999999999928, 225.13999999999916, 151.6099999999995, 58.550000000000026, 151.4399999999992, 31.090000000000078, -18.429999999999474, 74.38999999999999, -257.49, -22.479999999999535, -52.319999999999965, 101.360000000001, -62.93000000000002, 248.13999999999953, 76.09000000000019, 155.78000000000026, 77.81999999999998, -355.6400000000003, 39.150000000000254, 93.23000000000086, -190.7800000000011, -211.3300000000002, 92.79000000000002, 106.9800000000007, -99.03000000000031, -128.6100000000001, 191.4599999999998, -0.14000000000004098, -28.9900000000001, -45.67999999999991, 57.39000000000002, 40.22000000000016, -129.07000000000016, -282.4400000000004, -9.210000000000115, 29.880000000000308, -10.20000000000006, -34.38000000000021, -276.49000000000046, -74.93000000000004, -3.1300000000000594, -105.69, -297.68999999999994, 50.849999999999355, 34.70999999999957, 44.10999999999977, 23.870000000000076, 79.27000000000102, 77.5600000000005, -28.919999999999995, -30.420000000000627, -4.800000000000388, -45.57999999999915, 18.75999999999999, 2.5000000000000737, 23.190000000000197, 48.98999999999976, 24.06000000000015, 67.19000000000044, 10.889999999999919, 113.66000000000136, -85.12999999999859, -1.2099999999998996, -4.12000000000015, -207.41000000000037, -219.22999999999985, 68.08000000000061, 41.29000000000024, 88.12000000000069, 14.199999999999985, 150.28000000000006, 42.64999999999986, -40.53999999999916, 151.35000000000025, -158.88999999999993, 42.53999999999979, 22.59000000000008, -91.87999999999994, 47.41000000000014, 1.6899999999999942, -74.27999999999953, 115.78000000000067], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-94.74999999999937, 15.499999999999982, -122.80000000000013, 15.470000000000013, -98.76999999999987, -21.189999999999724, -278.8300000000001, -296.95, -3.790000000000026, -50.980000000000004, -118.26999999999975, -88.83999999999993, -86.6799999999999, -15.370000000000086, -59.97999999999948, -65.28999999999964, -22.63000000000003, -134.1999999999996, -205.96000000000004, 2.0000000000000013, -94.44999999999973, 18.259999999999984, -2.020000000000042, 2.0000000000000013, -282.46000000000026, -321.8500000000001, -55.959999999999496, -14.080000000000041, -28.14999999999971, -37.21000000000033, 71.24000000000001, -22.570000000000054, -169.51000000000045, 15.41000000000001, -48.25000000000035, 86.75000000000006, -25.26999999999975, 2.0000000000000013, -12.070000000000041, 74.21000000000004, -133.29999999999993, 4.909999999999962, -6.040000000000042, 42.59000000000002, 22.73000000000025, -113.29000000000002, -312.7000000000002, -40.21000000000035, -18.099999999999707, -64.32999999999925, -16.450000000000003, -27.159999999999734, -314.6500000000003, -316.84000000000015, -50.260000000000346, -42.220000000000354, -251.80000000000013, -165.52, -8.050000000000042, -167.5900000000002, -209.0800000000001, -168.85000000000008, -4.030000000000041, 24.169999999999998, -15.189999999999863, -259.72, -78.22000000000008, 2.0000000000000013, -126.63999999999993, -121.53999999999981, -347.74000000000024, -364.9000000000001, 2.0000000000000013, -156.85000000000008, -177.66999999999996, -18.099999999999703, -344.74000000000024, -207.04000000000087, -266.5000000000004, -332.8300000000001, -109.80999999999996, -96.39999999999978, -54.280000000000335, -86.73999999999998, -214.81000000000017, -210.22000000000065, -279.79000000000013, -231.8200000000001, -76.53999999999996, 2.0000000000000013, -26.139999999999713, 2.0000000000000013, -42.220000000000354, -314.7700000000001, -9.070000000000018, -321.6099999999998, -11.080000000000041, -263.5300000000002, 2.0000000000000013, -346.7800000000001, -30.159999999999712, -381.9100000000001, -294.5500000000004, -377.89000000000004, -80.43999999999983, -299.77000000000004, -218.1100000000008, -0.009999999999998581, -229.1499999999999, -8.050000000000011, -279.54999999999995, -104.82999999999942, -299.50000000000045, -376.99, -291.4599999999997, -92.47, -225.1300000000008, 2.0000000000000013, -274.39, -163.3, -301.81, -375.88000000000005, -6.040000000000042, -20.10999999999974, -5.290000000000026, 2.0000000000000013, -167.86000000000075, -4.030000000000014, -86.4399999999992, -133.68999999999986, 2.0000000000000013, -90.72999999999948, -70.35999999999916, -143.07999999999998, -305.5300000000004, -76.38999999999984, -38.20000000000036, -42.220000000000354, -68.34999999999916, -88.45000000000019, -190.95999999999964, -113.61999999999931, -10.060000000000041, -34.179999999999964, -221.2000000000007, -58.30000000000033, -32.17000000000036, -294.64, -199.0000000000009, -0.009999999999998581, -86.43999999999951, -86.49999999999935, -8.05000000000004, -135.76000000000073, 2.0000000000000013, -20.109999999999705, -1.3000000000000271, -6.040000000000008, -100.50999999999924, -116.61999999999931, -21.12999999999971, -14.080000000000041, -78.3999999999997, -142.72000000000048, -341.92, -234.49000000000038, -310.72, -301.51, -54.61000000000028, -60.31000000000001, -45.460000000000285, -48.25000000000035, -82.83999999999946, -6.040000000000042, -8.049999999999999, -334.7500000000002, 2.0000000000000013, -142.71999999999946, -243.14000000000053, -1.2100000000000348, -148.7500000000011, -156.79000000000107, -19.179999999999715, -41.46999999999986, -233.08999999999992, -314.80000000000007, -11.080000000000037, -74.37999999999974, -6.040000000000042, -72.37000000000002, -215.11000000000007, -152.76999999999987, -22.119999999999706, -89.47, -15.099999999999865, -40.210000000000356, -154.11999999999978, -201.16000000000054, 3.8899999999999597, -20.10999999999987], "policy_predator_policy_reward": [129.0, 105.0, 143.0, 191.0, 79.0, 101.0, 149.0, 200.0, 127.0, 144.0, 156.0, 189.0, 128.0, 174.0, 138.0, 122.0, 117.0, 131.0, 136.0, 198.0, 51.0, 144.0, 15.0, 2.0, 188.0, 200.0, 18.0, 60.0, 32.0, 47.0, 128.0, 97.0, 128.0, 108.0, 60.0, 38.0, 2.0, 37.0, 135.0, 28.0, 114.0, 166.0, 9.0, 13.0, 140.0, 102.0, 191.0, 193.0, 16.0, 48.0, 74.0, 44.0, 177.0, 197.0, 38.0, 32.0, 196.0, 169.0, 128.0, 149.0, 153.0, 162.0, 83.0, 145.0, 198.0, 153.0, 67.0, 165.0, 158.0, 168.0, 200.0, 157.0, 132.0, 62.0, 176.0, 113.0, 180.0, 181.0, 193.0, 195.0, 171.0, 128.0, 126.0, 122.0, 173.0, 153.0, 186.0, 197.0, 91.0, 175.0, 2.0, 22.0, 136.0, 192.0, 173.0, 112.0, 170.0, 162.0, 194.0, 191.0, 197.0, 86.0, 200.0, 190.0, 187.0, 184.0, 104.0, 144.0, 122.0, 105.0, 183.0, 167.0, 200.0, 200.0, 152.0, 157.0, 100.0, 120.0, 146.0, 186.0, 180.0, 200.0, 36.0, 41.0, 16.0, 22.0, 92.0, 124.0, 126.0, 118.0, 83.0, 85.0, 134.0, 157.0, 187.0, 166.0, 26.0, 24.0, 98.0, 54.0, 133.0, 126.0, 16.0, 47.0, 160.0, 122.0, 185.0, 165.0, 110.0, 138.0, 121.0, 76.0, 110.0, 101.0, 16.0, 13.0, 79.0, 42.0, 76.0, 56.0, 10.0, 24.0, 135.0, 82.0, 200.0, 169.0, 197.0, 196.0, 63.0, 120.0, 63.0, 72.0, 75.0, 102.0, 168.0, 189.0, 191.0, 100.0, 156.0, 131.0, 151.0, 114.0, 106.0, 106.0, 172.0, 217.0, 79.0, 49.0, 39.0, 62.0, 147.0, 129.0, 100.0, 59.0, 27.0, 30.0, 167.0, 114.0, 91.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7731755890747758, "mean_inference_ms": 2.0170879443871375, "mean_action_processing_ms": 0.3001563345864415, "mean_env_wait_ms": 0.27036403112117713, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003983974456787109, "StateBufferConnector_ms": 0.003296375274658203, "ViewRequirementAgentConnector_ms": 0.10347986221313477}, "num_episodes": 18, "episode_return_max": 273.6699999999996, "episode_return_min": -355.6400000000003, "episode_return_mean": 12.92180000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 341.5868339628594, "num_env_steps_trained_throughput_per_sec": 341.5868339628594, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 11946.498, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11946.441, "sample_time_ms": 1334.201, "learn_time_ms": 10594.254, "learn_throughput": 377.563, "synch_weights_time_ms": 14.397}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "0e60f_00000", "date": "2024-08-15_01-00-56", "timestamp": 1723663856, "time_this_iter_s": 11.752110004425049, "time_total_s": 275.3045725822449, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a29d6af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 275.3045725822449, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 55.811764705882354, "ram_util_percent": 83.62941176470588}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.261521070848697, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.045568822174476, "policy_loss": -0.008907684355619408, "vf_loss": 6.053107777600566, "vf_explained_var": 0.016960217555363973, "kl": 0.006843581810993522, "entropy": 1.4593608098686057, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1436706959255156, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.739533203367204, "policy_loss": -0.0059913404257573855, "vf_loss": 8.743536043167115, "vf_explained_var": 0.04114442988047524, "kl": 0.009942443198881129, "entropy": 1.3994048023350025, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 248.13999999999953, "episode_reward_min": -355.6400000000003, "episode_reward_mean": -10.015599999999882, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -467.94000000000005, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 24.169999999999998, "predator_policy": 290.0}, "policy_reward_mean": {"prey_policy": -129.81280000000004, "predator_policy": 124.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.479999999999535, -52.319999999999965, 101.360000000001, -62.93000000000002, 248.13999999999953, 76.09000000000019, 155.78000000000026, 77.81999999999998, -355.6400000000003, 39.150000000000254, 93.23000000000086, -190.7800000000011, -211.3300000000002, 92.79000000000002, 106.9800000000007, -99.03000000000031, -128.6100000000001, 191.4599999999998, -0.14000000000004098, -28.9900000000001, -45.67999999999991, 57.39000000000002, 40.22000000000016, -129.07000000000016, -282.4400000000004, -9.210000000000115, 29.880000000000308, -10.20000000000006, -34.38000000000021, -276.49000000000046, -74.93000000000004, -3.1300000000000594, -105.69, -297.68999999999994, 50.849999999999355, 34.70999999999957, 44.10999999999977, 23.870000000000076, 79.27000000000102, 77.5600000000005, -28.919999999999995, -30.420000000000627, -4.800000000000388, -45.57999999999915, 18.75999999999999, 2.5000000000000737, 23.190000000000197, 48.98999999999976, 24.06000000000015, 67.19000000000044, 10.889999999999919, 113.66000000000136, -85.12999999999859, -1.2099999999998996, -4.12000000000015, -207.41000000000037, -219.22999999999985, 68.08000000000061, 41.29000000000024, 88.12000000000069, 14.199999999999985, 150.28000000000006, 42.64999999999986, -40.53999999999916, 151.35000000000025, -158.88999999999993, 42.53999999999979, 22.59000000000008, -91.87999999999994, 47.41000000000014, 1.6899999999999942, -74.27999999999953, 115.78000000000067, 23.919999999999973, -63.88999999999855, 43.51000000000001, -127.44999999999965, -16.28999999999943, -13.68999999999994, -69.08000000000004, -162.70000000000027, 33.459999999999965, 75.83, 110.2400000000002, -126.63999999999986, 57.4899999999999, 13.130000000000011, 118.30000000000051, 15.899999999999824, 93.15000000000055, -238.11000000000016, 55.70999999999988, 8.839999999999918, 62.75999999999972, 20.690000000000424, 8.40999999999994, -69.51999999999994, -83.74999999999844, -140.79, 66.7000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-50.260000000000346, -42.220000000000354, -251.80000000000013, -165.52, -8.050000000000042, -167.5900000000002, -209.0800000000001, -168.85000000000008, -4.030000000000041, 24.169999999999998, -15.189999999999863, -259.72, -78.22000000000008, 2.0000000000000013, -126.63999999999993, -121.53999999999981, -347.74000000000024, -364.9000000000001, 2.0000000000000013, -156.85000000000008, -177.66999999999996, -18.099999999999703, -344.74000000000024, -207.04000000000087, -266.5000000000004, -332.8300000000001, -109.80999999999996, -96.39999999999978, -54.280000000000335, -86.73999999999998, -214.81000000000017, -210.22000000000065, -279.79000000000013, -231.8200000000001, -76.53999999999996, 2.0000000000000013, -26.139999999999713, 2.0000000000000013, -42.220000000000354, -314.7700000000001, -9.070000000000018, -321.6099999999998, -11.080000000000041, -263.5300000000002, 2.0000000000000013, -346.7800000000001, -30.159999999999712, -381.9100000000001, -294.5500000000004, -377.89000000000004, -80.43999999999983, -299.77000000000004, -218.1100000000008, -0.009999999999998581, -229.1499999999999, -8.050000000000011, -279.54999999999995, -104.82999999999942, -299.50000000000045, -376.99, -291.4599999999997, -92.47, -225.1300000000008, 2.0000000000000013, -274.39, -163.3, -301.81, -375.88000000000005, -6.040000000000042, -20.10999999999974, -5.290000000000026, 2.0000000000000013, -167.86000000000075, -4.030000000000014, -86.4399999999992, -133.68999999999986, 2.0000000000000013, -90.72999999999948, -70.35999999999916, -143.07999999999998, -305.5300000000004, -76.38999999999984, -38.20000000000036, -42.220000000000354, -68.34999999999916, -88.45000000000019, -190.95999999999964, -113.61999999999931, -10.060000000000041, -34.179999999999964, -221.2000000000007, -58.30000000000033, -32.17000000000036, -294.64, -199.0000000000009, -0.009999999999998581, -86.43999999999951, -86.49999999999935, -8.05000000000004, -135.76000000000073, 2.0000000000000013, -20.109999999999705, -1.3000000000000271, -6.040000000000008, -100.50999999999924, -116.61999999999931, -21.12999999999971, -14.080000000000041, -78.3999999999997, -142.72000000000048, -341.92, -234.49000000000038, -310.72, -301.51, -54.61000000000028, -60.31000000000001, -45.460000000000285, -48.25000000000035, -82.83999999999946, -6.040000000000042, -8.049999999999999, -334.7500000000002, 2.0000000000000013, -142.71999999999946, -243.14000000000053, -1.2100000000000348, -148.7500000000011, -156.79000000000107, -19.179999999999715, -41.46999999999986, -233.08999999999992, -314.80000000000007, -11.080000000000037, -74.37999999999974, -6.040000000000042, -72.37000000000002, -215.11000000000007, -152.76999999999987, -22.119999999999706, -89.47, -15.099999999999865, -40.210000000000356, -154.11999999999978, -201.16000000000054, 3.8899999999999597, -20.10999999999987, -14.080000000000041, 2.0000000000000013, -55.33000000000029, -110.55999999999935, -321.49000000000035, 2.0000000000000013, -277.39000000000055, -211.06000000000012, -14.080000000000041, -40.210000000000356, -154.77999999999997, -188.91000000000037, -324.73000000000013, -68.34999999999975, -319.60000000000025, -219.10000000000014, -301.3500000000001, -0.1899999999999984, -2.020000000000004, -28.14999999999971, -146.74000000000035, -2.020000000000042, -29.170000000000037, -357.4699999999999, 2.0000000000000013, -298.51000000000045, -431.75999999999993, -20.109999999999708, 2.0000000000000013, -138.69999999999993, -66.34, -150.76000000000016, 2.0000000000000013, -168.8499999999998, -339.58, -305.5300000000001, -0.009999999999998484, -36.28000000000003, -15.159999999999863, 2.0000000000000013, -114.57999999999974, -130.65999999999988, -20.109999999999715, -38.199999999999754, -217.18, -80.40999999999933, -341.63000000000017, -83.88999999999982, -54.280000000000335, -92.46999999999927, -159.84999999999997, -467.94000000000005, -6.040000000000042, -248.25999999999993], "policy_predator_policy_reward": [38.0, 32.0, 196.0, 169.0, 128.0, 149.0, 153.0, 162.0, 83.0, 145.0, 198.0, 153.0, 67.0, 165.0, 158.0, 168.0, 200.0, 157.0, 132.0, 62.0, 176.0, 113.0, 180.0, 181.0, 193.0, 195.0, 171.0, 128.0, 126.0, 122.0, 173.0, 153.0, 186.0, 197.0, 91.0, 175.0, 2.0, 22.0, 136.0, 192.0, 173.0, 112.0, 170.0, 162.0, 194.0, 191.0, 197.0, 86.0, 200.0, 190.0, 187.0, 184.0, 104.0, 144.0, 122.0, 105.0, 183.0, 167.0, 200.0, 200.0, 152.0, 157.0, 100.0, 120.0, 146.0, 186.0, 180.0, 200.0, 36.0, 41.0, 16.0, 22.0, 92.0, 124.0, 126.0, 118.0, 83.0, 85.0, 134.0, 157.0, 187.0, 166.0, 26.0, 24.0, 98.0, 54.0, 133.0, 126.0, 16.0, 47.0, 160.0, 122.0, 185.0, 165.0, 110.0, 138.0, 121.0, 76.0, 110.0, 101.0, 16.0, 13.0, 79.0, 42.0, 76.0, 56.0, 10.0, 24.0, 135.0, 82.0, 200.0, 169.0, 197.0, 196.0, 63.0, 120.0, 63.0, 72.0, 75.0, 102.0, 168.0, 189.0, 191.0, 100.0, 156.0, 131.0, 151.0, 114.0, 106.0, 106.0, 172.0, 217.0, 79.0, 49.0, 39.0, 62.0, 147.0, 129.0, 100.0, 59.0, 27.0, 30.0, 167.0, 114.0, 91.0, 41.0, 35.0, 1.0, 8.0, 94.0, 210.0, 153.0, 166.0, 195.0, 10.0, 28.0, 151.0, 179.0, 181.0, 143.0, 194.0, 182.0, 200.0, 135.0, 62.0, 44.0, 99.0, 160.0, 11.0, 249.0, 187.0, 167.0, 265.0, 200.0, 94.0, 161.0, 118.0, 115.0, 123.0, 137.0, 180.0, 227.0, 42.0, 50.0, 10.0, 12.0, 163.0, 145.0, 33.0, 46.0, 140.0, 166.0, 199.0, 157.0, 62.0, 1.0, 197.0, 290.0, 167.0, 154.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7692476377337958, "mean_inference_ms": 2.0078560914261474, "mean_action_processing_ms": 0.2989070396383799, "mean_env_wait_ms": 0.26879856271159863, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004760265350341797, "StateBufferConnector_ms": 0.0035227537155151367, "ViewRequirementAgentConnector_ms": 0.12850117683410645}, "num_episodes": 27, "episode_return_max": 248.13999999999953, "episode_return_min": -355.6400000000003, "episode_return_mean": -10.015599999999882, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.2299182549488, "num_env_steps_trained_throughput_per_sec": 333.2299182549488, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 11934.012, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11933.96, "sample_time_ms": 1405.758, "learn_time_ms": 10510.561, "learn_throughput": 380.57, "synch_weights_time_ms": 14.203}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "0e60f_00000", "date": "2024-08-15_01-01-08", "timestamp": 1723663868, "time_this_iter_s": 12.09261703491211, "time_total_s": 287.397189617157, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fe0dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 287.397189617157, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 52.29411764705882, "ram_util_percent": 82.77058823529413}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0075687761659975, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6736977083973152, "policy_loss": -0.011469307283392896, "vf_loss": 3.6829789590583277, "vf_explained_var": 0.025589401602114318, "kl": 0.010940231735119517, "entropy": 1.4580088906817965, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.861487842047656, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.356846390073262, "policy_loss": -0.0032715518281317105, "vf_loss": 7.358300757281994, "vf_explained_var": 0.0007293893546654434, "kl": 0.009085958848327271, "entropy": 1.403094785617142, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 151.35000000000025, "episode_reward_min": -297.68999999999994, "episode_reward_mean": -5.77999999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -473.93, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 3.8899999999999597, "predator_policy": 290.0}, "policy_reward_mean": {"prey_policy": -117.325, "predator_policy": 114.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-0.14000000000004098, -28.9900000000001, -45.67999999999991, 57.39000000000002, 40.22000000000016, -129.07000000000016, -282.4400000000004, -9.210000000000115, 29.880000000000308, -10.20000000000006, -34.38000000000021, -276.49000000000046, -74.93000000000004, -3.1300000000000594, -105.69, -297.68999999999994, 50.849999999999355, 34.70999999999957, 44.10999999999977, 23.870000000000076, 79.27000000000102, 77.5600000000005, -28.919999999999995, -30.420000000000627, -4.800000000000388, -45.57999999999915, 18.75999999999999, 2.5000000000000737, 23.190000000000197, 48.98999999999976, 24.06000000000015, 67.19000000000044, 10.889999999999919, 113.66000000000136, -85.12999999999859, -1.2099999999998996, -4.12000000000015, -207.41000000000037, -219.22999999999985, 68.08000000000061, 41.29000000000024, 88.12000000000069, 14.199999999999985, 150.28000000000006, 42.64999999999986, -40.53999999999916, 151.35000000000025, -158.88999999999993, 42.53999999999979, 22.59000000000008, -91.87999999999994, 47.41000000000014, 1.6899999999999942, -74.27999999999953, 115.78000000000067, 23.919999999999973, -63.88999999999855, 43.51000000000001, -127.44999999999965, -16.28999999999943, -13.68999999999994, -69.08000000000004, -162.70000000000027, 33.459999999999965, 75.83, 110.2400000000002, -126.63999999999986, 57.4899999999999, 13.130000000000011, 118.30000000000051, 15.899999999999824, 93.15000000000055, -238.11000000000016, 55.70999999999988, 8.839999999999918, 62.75999999999972, 20.690000000000424, 8.40999999999994, -69.51999999999994, -83.74999999999844, -140.79, 66.7000000000004, 24.490000000000347, 0.949999999999981, 72.79999999999997, 59.439999999999806, 51.09999999999985, -4.409999999999968, 4.999999999999937, 93.2900000000002, 17.88000000000025, -9.669999999999902, 13.069999999999974, 44.75999999999994, 115.35000000000106, -0.12000000000004098, 0.8199999999999835, -85.19999999999983, 89.85000000000068, -6.160000000000082], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-26.139999999999713, 2.0000000000000013, -42.220000000000354, -314.7700000000001, -9.070000000000018, -321.6099999999998, -11.080000000000041, -263.5300000000002, 2.0000000000000013, -346.7800000000001, -30.159999999999712, -381.9100000000001, -294.5500000000004, -377.89000000000004, -80.43999999999983, -299.77000000000004, -218.1100000000008, -0.009999999999998581, -229.1499999999999, -8.050000000000011, -279.54999999999995, -104.82999999999942, -299.50000000000045, -376.99, -291.4599999999997, -92.47, -225.1300000000008, 2.0000000000000013, -274.39, -163.3, -301.81, -375.88000000000005, -6.040000000000042, -20.10999999999974, -5.290000000000026, 2.0000000000000013, -167.86000000000075, -4.030000000000014, -86.4399999999992, -133.68999999999986, 2.0000000000000013, -90.72999999999948, -70.35999999999916, -143.07999999999998, -305.5300000000004, -76.38999999999984, -38.20000000000036, -42.220000000000354, -68.34999999999916, -88.45000000000019, -190.95999999999964, -113.61999999999931, -10.060000000000041, -34.179999999999964, -221.2000000000007, -58.30000000000033, -32.17000000000036, -294.64, -199.0000000000009, -0.009999999999998581, -86.43999999999951, -86.49999999999935, -8.05000000000004, -135.76000000000073, 2.0000000000000013, -20.109999999999705, -1.3000000000000271, -6.040000000000008, -100.50999999999924, -116.61999999999931, -21.12999999999971, -14.080000000000041, -78.3999999999997, -142.72000000000048, -341.92, -234.49000000000038, -310.72, -301.51, -54.61000000000028, -60.31000000000001, -45.460000000000285, -48.25000000000035, -82.83999999999946, -6.040000000000042, -8.049999999999999, -334.7500000000002, 2.0000000000000013, -142.71999999999946, -243.14000000000053, -1.2100000000000348, -148.7500000000011, -156.79000000000107, -19.179999999999715, -41.46999999999986, -233.08999999999992, -314.80000000000007, -11.080000000000037, -74.37999999999974, -6.040000000000042, -72.37000000000002, -215.11000000000007, -152.76999999999987, -22.119999999999706, -89.47, -15.099999999999865, -40.210000000000356, -154.11999999999978, -201.16000000000054, 3.8899999999999597, -20.10999999999987, -14.080000000000041, 2.0000000000000013, -55.33000000000029, -110.55999999999935, -321.49000000000035, 2.0000000000000013, -277.39000000000055, -211.06000000000012, -14.080000000000041, -40.210000000000356, -154.77999999999997, -188.91000000000037, -324.73000000000013, -68.34999999999975, -319.60000000000025, -219.10000000000014, -301.3500000000001, -0.1899999999999984, -2.020000000000004, -28.14999999999971, -146.74000000000035, -2.020000000000042, -29.170000000000037, -357.4699999999999, 2.0000000000000013, -298.51000000000045, -431.75999999999993, -20.109999999999708, 2.0000000000000013, -138.69999999999993, -66.34, -150.76000000000016, 2.0000000000000013, -168.8499999999998, -339.58, -305.5300000000001, -0.009999999999998484, -36.28000000000003, -15.159999999999863, 2.0000000000000013, -114.57999999999974, -130.65999999999988, -20.109999999999715, -38.199999999999754, -217.18, -80.40999999999933, -341.63000000000017, -83.88999999999982, -54.280000000000335, -92.46999999999927, -159.84999999999997, -467.94000000000005, -6.040000000000042, -248.25999999999993, -18.09999999999971, -80.40999999999929, -8.050000000000042, 2.0000000000000013, -130.66000000000054, -106.53999999999999, -146.5, -1.0600000000000205, 2.0000000000000013, -178.89999999999978, -54.28, -238.12999999999988, 2.0000000000000013, 2.0000000000000013, -105.67000000000017, -6.040000000000042, -18.099999999999703, 0.9800000000000014, -284.4400000000003, -14.230000000000032, 2.0000000000000013, -473.93, -4.030000000000042, -34.210000000000036, -6.040000000000042, -87.60999999999932, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -34.18000000000036, -273.3700000000003, -164.83000000000015, -0.00999999999999836, -213.14, -10.060000000000041, -18.099999999999707], "policy_predator_policy_reward": [2.0, 22.0, 136.0, 192.0, 173.0, 112.0, 170.0, 162.0, 194.0, 191.0, 197.0, 86.0, 200.0, 190.0, 187.0, 184.0, 104.0, 144.0, 122.0, 105.0, 183.0, 167.0, 200.0, 200.0, 152.0, 157.0, 100.0, 120.0, 146.0, 186.0, 180.0, 200.0, 36.0, 41.0, 16.0, 22.0, 92.0, 124.0, 126.0, 118.0, 83.0, 85.0, 134.0, 157.0, 187.0, 166.0, 26.0, 24.0, 98.0, 54.0, 133.0, 126.0, 16.0, 47.0, 160.0, 122.0, 185.0, 165.0, 110.0, 138.0, 121.0, 76.0, 110.0, 101.0, 16.0, 13.0, 79.0, 42.0, 76.0, 56.0, 10.0, 24.0, 135.0, 82.0, 200.0, 169.0, 197.0, 196.0, 63.0, 120.0, 63.0, 72.0, 75.0, 102.0, 168.0, 189.0, 191.0, 100.0, 156.0, 131.0, 151.0, 114.0, 106.0, 106.0, 172.0, 217.0, 79.0, 49.0, 39.0, 62.0, 147.0, 129.0, 100.0, 59.0, 27.0, 30.0, 167.0, 114.0, 91.0, 41.0, 35.0, 1.0, 8.0, 94.0, 210.0, 153.0, 166.0, 195.0, 10.0, 28.0, 151.0, 179.0, 181.0, 143.0, 194.0, 182.0, 200.0, 135.0, 62.0, 44.0, 99.0, 160.0, 11.0, 249.0, 187.0, 167.0, 265.0, 200.0, 94.0, 161.0, 118.0, 115.0, 123.0, 137.0, 180.0, 227.0, 42.0, 50.0, 10.0, 12.0, 163.0, 145.0, 33.0, 46.0, 140.0, 166.0, 199.0, 157.0, 62.0, 1.0, 197.0, 290.0, 167.0, 154.0, 58.0, 65.0, 7.0, 0.0, 158.0, 152.0, 72.0, 135.0, 151.0, 77.0, 113.0, 175.0, 1.0, 0.0, 88.0, 117.0, 27.0, 8.0, 119.0, 170.0, 236.0, 249.0, 40.0, 43.0, 107.0, 102.0, 14.0, 6.0, 23.0, 10.0, 161.0, 192.0, 175.0, 128.0, 8.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7714680089717167, "mean_inference_ms": 2.0096313585664567, "mean_action_processing_ms": 0.3002017801534667, "mean_env_wait_ms": 0.267298934321064, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004861593246459961, "StateBufferConnector_ms": 0.003342270851135254, "ViewRequirementAgentConnector_ms": 0.1569204330444336}, "num_episodes": 18, "episode_return_max": 151.35000000000025, "episode_return_min": -297.68999999999994, "episode_return_mean": -5.77999999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 326.7372481704644, "num_env_steps_trained_throughput_per_sec": 326.7372481704644, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 11990.503, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11990.449, "sample_time_ms": 1495.729, "learn_time_ms": 10475.867, "learn_throughput": 381.83, "synch_weights_time_ms": 15.744}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "0e60f_00000", "date": "2024-08-15_01-01-20", "timestamp": 1723663880, "time_this_iter_s": 12.287687301635742, "time_total_s": 299.6848769187927, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2af9f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 299.6848769187927, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 50.017647058823535, "ram_util_percent": 82.68823529411765}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9691997947831633, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.753416598726202, "policy_loss": -0.011673724449426921, "vf_loss": 2.763245786182464, "vf_explained_var": 0.026392271279027223, "kl": 0.00922269312432684, "entropy": 1.4667614331951848, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.755313534679867, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.76291279338655, "policy_loss": -0.0027490334949953846, "vf_loss": 5.764615658351353, "vf_explained_var": 0.002012030125925781, "kl": 0.005230878765332686, "entropy": 1.3933117998970879, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 151.35000000000025, "episode_reward_min": -238.11000000000016, "episode_reward_mean": 12.135300000000154, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -473.93, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 8.929999999999959, "predator_policy": 290.0}, "policy_reward_mean": {"prey_policy": -98.33235, "predator_policy": 104.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.10999999999977, 23.870000000000076, 79.27000000000102, 77.5600000000005, -28.919999999999995, -30.420000000000627, -4.800000000000388, -45.57999999999915, 18.75999999999999, 2.5000000000000737, 23.190000000000197, 48.98999999999976, 24.06000000000015, 67.19000000000044, 10.889999999999919, 113.66000000000136, -85.12999999999859, -1.2099999999998996, -4.12000000000015, -207.41000000000037, -219.22999999999985, 68.08000000000061, 41.29000000000024, 88.12000000000069, 14.199999999999985, 150.28000000000006, 42.64999999999986, -40.53999999999916, 151.35000000000025, -158.88999999999993, 42.53999999999979, 22.59000000000008, -91.87999999999994, 47.41000000000014, 1.6899999999999942, -74.27999999999953, 115.78000000000067, 23.919999999999973, -63.88999999999855, 43.51000000000001, -127.44999999999965, -16.28999999999943, -13.68999999999994, -69.08000000000004, -162.70000000000027, 33.459999999999965, 75.83, 110.2400000000002, -126.63999999999986, 57.4899999999999, 13.130000000000011, 118.30000000000051, 15.899999999999824, 93.15000000000055, -238.11000000000016, 55.70999999999988, 8.839999999999918, 62.75999999999972, 20.690000000000424, 8.40999999999994, -69.51999999999994, -83.74999999999844, -140.79, 66.7000000000004, 24.490000000000347, 0.949999999999981, 72.79999999999997, 59.439999999999806, 51.09999999999985, -4.409999999999968, 4.999999999999937, 93.2900000000002, 17.88000000000025, -9.669999999999902, 13.069999999999974, 44.75999999999994, 115.35000000000106, -0.12000000000004098, 0.8199999999999835, -85.19999999999983, 89.85000000000068, -6.160000000000082, 78.58999999999999, -1.3100000000000722, 69.42999999999981, 56.889999999999624, -35.79999999999986, 114.4500000000008, 131.6700000000002, 21.32999999999999, -29.269999999999772, 38.51999999999998, 64.49000000000004, 6.9399999999999284, 12.889999999999919, 10.88999999999992, 11.809999999999919, 10.999999999999922, 134.15999999999997, 9.859999999999918], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-167.86000000000075, -4.030000000000014, -86.4399999999992, -133.68999999999986, 2.0000000000000013, -90.72999999999948, -70.35999999999916, -143.07999999999998, -305.5300000000004, -76.38999999999984, -38.20000000000036, -42.220000000000354, -68.34999999999916, -88.45000000000019, -190.95999999999964, -113.61999999999931, -10.060000000000041, -34.179999999999964, -221.2000000000007, -58.30000000000033, -32.17000000000036, -294.64, -199.0000000000009, -0.009999999999998581, -86.43999999999951, -86.49999999999935, -8.05000000000004, -135.76000000000073, 2.0000000000000013, -20.109999999999705, -1.3000000000000271, -6.040000000000008, -100.50999999999924, -116.61999999999931, -21.12999999999971, -14.080000000000041, -78.3999999999997, -142.72000000000048, -341.92, -234.49000000000038, -310.72, -301.51, -54.61000000000028, -60.31000000000001, -45.460000000000285, -48.25000000000035, -82.83999999999946, -6.040000000000042, -8.049999999999999, -334.7500000000002, 2.0000000000000013, -142.71999999999946, -243.14000000000053, -1.2100000000000348, -148.7500000000011, -156.79000000000107, -19.179999999999715, -41.46999999999986, -233.08999999999992, -314.80000000000007, -11.080000000000037, -74.37999999999974, -6.040000000000042, -72.37000000000002, -215.11000000000007, -152.76999999999987, -22.119999999999706, -89.47, -15.099999999999865, -40.210000000000356, -154.11999999999978, -201.16000000000054, 3.8899999999999597, -20.10999999999987, -14.080000000000041, 2.0000000000000013, -55.33000000000029, -110.55999999999935, -321.49000000000035, 2.0000000000000013, -277.39000000000055, -211.06000000000012, -14.080000000000041, -40.210000000000356, -154.77999999999997, -188.91000000000037, -324.73000000000013, -68.34999999999975, -319.60000000000025, -219.10000000000014, -301.3500000000001, -0.1899999999999984, -2.020000000000004, -28.14999999999971, -146.74000000000035, -2.020000000000042, -29.170000000000037, -357.4699999999999, 2.0000000000000013, -298.51000000000045, -431.75999999999993, -20.109999999999708, 2.0000000000000013, -138.69999999999993, -66.34, -150.76000000000016, 2.0000000000000013, -168.8499999999998, -339.58, -305.5300000000001, -0.009999999999998484, -36.28000000000003, -15.159999999999863, 2.0000000000000013, -114.57999999999974, -130.65999999999988, -20.109999999999715, -38.199999999999754, -217.18, -80.40999999999933, -341.63000000000017, -83.88999999999982, -54.280000000000335, -92.46999999999927, -159.84999999999997, -467.94000000000005, -6.040000000000042, -248.25999999999993, -18.09999999999971, -80.40999999999929, -8.050000000000042, 2.0000000000000013, -130.66000000000054, -106.53999999999999, -146.5, -1.0600000000000205, 2.0000000000000013, -178.89999999999978, -54.28, -238.12999999999988, 2.0000000000000013, 2.0000000000000013, -105.67000000000017, -6.040000000000042, -18.099999999999703, 0.9800000000000014, -284.4400000000003, -14.230000000000032, 2.0000000000000013, -473.93, -4.030000000000042, -34.210000000000036, -6.040000000000042, -87.60999999999932, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -34.18000000000036, -273.3700000000003, -164.83000000000015, -0.00999999999999836, -213.14, -10.060000000000041, -18.099999999999707, -70.36000000000001, -8.050000000000042, -13.12000000000004, -30.189999999999717, -369.5700000000003, 2.0000000000000013, -12.070000000000041, -6.040000000000022, -233.17000000000024, -124.62999999999977, -108.5499999999996, 2.0000000000000013, 2.0000000000000013, -273.3300000000004, -28.14999999999971, -300.52000000000015, -26.13999999999971, -24.129999999999708, -76.38999999999936, -16.0899999999997, 4.849999999999961, -327.35999999999984, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -6.040000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -6.190000000000039, 2.0000000000000013, 2.0000000000000013, -178.82000000000068, -2.020000000000042, -12.070000000000041, 8.929999999999959], "policy_predator_policy_reward": [92.0, 124.0, 126.0, 118.0, 83.0, 85.0, 134.0, 157.0, 187.0, 166.0, 26.0, 24.0, 98.0, 54.0, 133.0, 126.0, 16.0, 47.0, 160.0, 122.0, 185.0, 165.0, 110.0, 138.0, 121.0, 76.0, 110.0, 101.0, 16.0, 13.0, 79.0, 42.0, 76.0, 56.0, 10.0, 24.0, 135.0, 82.0, 200.0, 169.0, 197.0, 196.0, 63.0, 120.0, 63.0, 72.0, 75.0, 102.0, 168.0, 189.0, 191.0, 100.0, 156.0, 131.0, 151.0, 114.0, 106.0, 106.0, 172.0, 217.0, 79.0, 49.0, 39.0, 62.0, 147.0, 129.0, 100.0, 59.0, 27.0, 30.0, 167.0, 114.0, 91.0, 41.0, 35.0, 1.0, 8.0, 94.0, 210.0, 153.0, 166.0, 195.0, 10.0, 28.0, 151.0, 179.0, 181.0, 143.0, 194.0, 182.0, 200.0, 135.0, 62.0, 44.0, 99.0, 160.0, 11.0, 249.0, 187.0, 167.0, 265.0, 200.0, 94.0, 161.0, 118.0, 115.0, 123.0, 137.0, 180.0, 227.0, 42.0, 50.0, 10.0, 12.0, 163.0, 145.0, 33.0, 46.0, 140.0, 166.0, 199.0, 157.0, 62.0, 1.0, 197.0, 290.0, 167.0, 154.0, 58.0, 65.0, 7.0, 0.0, 158.0, 152.0, 72.0, 135.0, 151.0, 77.0, 113.0, 175.0, 1.0, 0.0, 88.0, 117.0, 27.0, 8.0, 119.0, 170.0, 236.0, 249.0, 40.0, 43.0, 107.0, 102.0, 14.0, 6.0, 23.0, 10.0, 161.0, 192.0, 175.0, 128.0, 8.0, 14.0, 71.0, 86.0, 20.0, 22.0, 220.0, 217.0, 50.0, 25.0, 159.0, 163.0, 133.0, 88.0, 208.0, 195.0, 168.0, 182.0, 0.0, 21.0, 48.0, 83.0, 183.0, 204.0, 2.0, 13.0, 20.0, 11.0, 16.0, 13.0, 15.0, 1.0, 0.0, 7.0, 123.0, 192.0, 2.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7744972386235908, "mean_inference_ms": 2.015478796426643, "mean_action_processing_ms": 0.301595381283481, "mean_env_wait_ms": 0.26736931979441253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01767587661743164, "StateBufferConnector_ms": 0.0032972097396850586, "ViewRequirementAgentConnector_ms": 0.16836082935333252}, "num_episodes": 18, "episode_return_max": 151.35000000000025, "episode_return_min": -238.11000000000016, "episode_return_mean": 12.135300000000154, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.6330758428795, "num_env_steps_trained_throughput_per_sec": 323.6330758428795, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 12014.592, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12014.537, "sample_time_ms": 1524.695, "learn_time_ms": 10470.495, "learn_throughput": 382.026, "synch_weights_time_ms": 16.091}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "0e60f_00000", "date": "2024-08-15_01-01-32", "timestamp": 1723663892, "time_this_iter_s": 12.403663158416748, "time_total_s": 312.0885400772095, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bd41f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 312.0885400772095, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 55.83888888888889, "ram_util_percent": 83.10555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0703838735424653, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9080544294907696, "policy_loss": -0.009834150386057675, "vf_loss": 0.9162196210413067, "vf_explained_var": -0.006977190132494326, "kl": 0.008344791611004456, "entropy": 1.4497290270669119, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5573578340666634, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.044857721353965, "policy_loss": -0.00384182017345829, "vf_loss": 2.0471137167915465, "vf_explained_var": 0.005289617858866535, "kl": 0.007929156094226859, "entropy": 1.4431320474892066, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 151.35000000000025, "episode_reward_min": -238.11000000000016, "episode_reward_mean": 12.361900000000121, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -473.93, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 26.750000000000266, "predator_policy": 290.0}, "policy_reward_mean": {"prey_policy": -88.93905000000001, "predator_policy": 95.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.12000000000015, -207.41000000000037, -219.22999999999985, 68.08000000000061, 41.29000000000024, 88.12000000000069, 14.199999999999985, 150.28000000000006, 42.64999999999986, -40.53999999999916, 151.35000000000025, -158.88999999999993, 42.53999999999979, 22.59000000000008, -91.87999999999994, 47.41000000000014, 1.6899999999999942, -74.27999999999953, 115.78000000000067, 23.919999999999973, -63.88999999999855, 43.51000000000001, -127.44999999999965, -16.28999999999943, -13.68999999999994, -69.08000000000004, -162.70000000000027, 33.459999999999965, 75.83, 110.2400000000002, -126.63999999999986, 57.4899999999999, 13.130000000000011, 118.30000000000051, 15.899999999999824, 93.15000000000055, -238.11000000000016, 55.70999999999988, 8.839999999999918, 62.75999999999972, 20.690000000000424, 8.40999999999994, -69.51999999999994, -83.74999999999844, -140.79, 66.7000000000004, 24.490000000000347, 0.949999999999981, 72.79999999999997, 59.439999999999806, 51.09999999999985, -4.409999999999968, 4.999999999999937, 93.2900000000002, 17.88000000000025, -9.669999999999902, 13.069999999999974, 44.75999999999994, 115.35000000000106, -0.12000000000004098, 0.8199999999999835, -85.19999999999983, 89.85000000000068, -6.160000000000082, 78.58999999999999, -1.3100000000000722, 69.42999999999981, 56.889999999999624, -35.79999999999986, 114.4500000000008, 131.6700000000002, 21.32999999999999, -29.269999999999772, 38.51999999999998, 64.49000000000004, 6.9399999999999284, 12.889999999999919, 10.88999999999992, 11.809999999999919, 10.999999999999922, 134.15999999999997, 9.859999999999918, 18.390000000000352, -4.230000000000063, 6.230000000000052, 30.83000000000039, -22.609999999999495, -0.30000000000003757, 74.22000000000062, 6.539999999999926, 16.930000000000085, 16.93000000000008, 61.4299999999996, -0.2500000000000411, 44.430000000000014, 8.92999999999993, 38.70999999999934, -1.1500000000000632, 79.7700000000003, -14.149999999999732], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-78.3999999999997, -142.72000000000048, -341.92, -234.49000000000038, -310.72, -301.51, -54.61000000000028, -60.31000000000001, -45.460000000000285, -48.25000000000035, -82.83999999999946, -6.040000000000042, -8.049999999999999, -334.7500000000002, 2.0000000000000013, -142.71999999999946, -243.14000000000053, -1.2100000000000348, -148.7500000000011, -156.79000000000107, -19.179999999999715, -41.46999999999986, -233.08999999999992, -314.80000000000007, -11.080000000000037, -74.37999999999974, -6.040000000000042, -72.37000000000002, -215.11000000000007, -152.76999999999987, -22.119999999999706, -89.47, -15.099999999999865, -40.210000000000356, -154.11999999999978, -201.16000000000054, 3.8899999999999597, -20.10999999999987, -14.080000000000041, 2.0000000000000013, -55.33000000000029, -110.55999999999935, -321.49000000000035, 2.0000000000000013, -277.39000000000055, -211.06000000000012, -14.080000000000041, -40.210000000000356, -154.77999999999997, -188.91000000000037, -324.73000000000013, -68.34999999999975, -319.60000000000025, -219.10000000000014, -301.3500000000001, -0.1899999999999984, -2.020000000000004, -28.14999999999971, -146.74000000000035, -2.020000000000042, -29.170000000000037, -357.4699999999999, 2.0000000000000013, -298.51000000000045, -431.75999999999993, -20.109999999999708, 2.0000000000000013, -138.69999999999993, -66.34, -150.76000000000016, 2.0000000000000013, -168.8499999999998, -339.58, -305.5300000000001, -0.009999999999998484, -36.28000000000003, -15.159999999999863, 2.0000000000000013, -114.57999999999974, -130.65999999999988, -20.109999999999715, -38.199999999999754, -217.18, -80.40999999999933, -341.63000000000017, -83.88999999999982, -54.280000000000335, -92.46999999999927, -159.84999999999997, -467.94000000000005, -6.040000000000042, -248.25999999999993, -18.09999999999971, -80.40999999999929, -8.050000000000042, 2.0000000000000013, -130.66000000000054, -106.53999999999999, -146.5, -1.0600000000000205, 2.0000000000000013, -178.89999999999978, -54.28, -238.12999999999988, 2.0000000000000013, 2.0000000000000013, -105.67000000000017, -6.040000000000042, -18.099999999999703, 0.9800000000000014, -284.4400000000003, -14.230000000000032, 2.0000000000000013, -473.93, -4.030000000000042, -34.210000000000036, -6.040000000000042, -87.60999999999932, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -34.18000000000036, -273.3700000000003, -164.83000000000015, -0.00999999999999836, -213.14, -10.060000000000041, -18.099999999999707, -70.36000000000001, -8.050000000000042, -13.12000000000004, -30.189999999999717, -369.5700000000003, 2.0000000000000013, -12.070000000000041, -6.040000000000022, -233.17000000000024, -124.62999999999977, -108.5499999999996, 2.0000000000000013, 2.0000000000000013, -273.3300000000004, -28.14999999999971, -300.52000000000015, -26.13999999999971, -24.129999999999708, -76.38999999999936, -16.0899999999997, 4.849999999999961, -327.35999999999984, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -6.040000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -6.190000000000039, 2.0000000000000013, 2.0000000000000013, -178.82000000000068, -2.020000000000042, -12.070000000000041, 8.929999999999959, -44.29000000000034, -2.320000000000036, -22.119999999999706, -20.109999999999737, -116.5899999999994, -34.180000000000355, -14.080000000000041, -16.08999999999979, -33.34000000000031, -52.270000000000344, -42.22000000000031, -14.080000000000041, 2.0000000000000013, -154.78000000000105, -8.050000000000042, -56.410000000000316, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, -10.060000000000041, -106.53999999999958, -4.030000000000042, -30.249999999999726, 2.0000000000000013, -110.5599999999995, -0.00999999999999836, -6.040000000000042, -4.030000000000036, 26.750000000000266, -6.040000000000042, -12.070000000000041, -14.080000000000041, -16.0899999999997, -227.14000000000036, -14.080000000000041, -12.070000000000041], "policy_predator_policy_reward": [135.0, 82.0, 200.0, 169.0, 197.0, 196.0, 63.0, 120.0, 63.0, 72.0, 75.0, 102.0, 168.0, 189.0, 191.0, 100.0, 156.0, 131.0, 151.0, 114.0, 106.0, 106.0, 172.0, 217.0, 79.0, 49.0, 39.0, 62.0, 147.0, 129.0, 100.0, 59.0, 27.0, 30.0, 167.0, 114.0, 91.0, 41.0, 35.0, 1.0, 8.0, 94.0, 210.0, 153.0, 166.0, 195.0, 10.0, 28.0, 151.0, 179.0, 181.0, 143.0, 194.0, 182.0, 200.0, 135.0, 62.0, 44.0, 99.0, 160.0, 11.0, 249.0, 187.0, 167.0, 265.0, 200.0, 94.0, 161.0, 118.0, 115.0, 123.0, 137.0, 180.0, 227.0, 42.0, 50.0, 10.0, 12.0, 163.0, 145.0, 33.0, 46.0, 140.0, 166.0, 199.0, 157.0, 62.0, 1.0, 197.0, 290.0, 167.0, 154.0, 58.0, 65.0, 7.0, 0.0, 158.0, 152.0, 72.0, 135.0, 151.0, 77.0, 113.0, 175.0, 1.0, 0.0, 88.0, 117.0, 27.0, 8.0, 119.0, 170.0, 236.0, 249.0, 40.0, 43.0, 107.0, 102.0, 14.0, 6.0, 23.0, 10.0, 161.0, 192.0, 175.0, 128.0, 8.0, 14.0, 71.0, 86.0, 20.0, 22.0, 220.0, 217.0, 50.0, 25.0, 159.0, 163.0, 133.0, 88.0, 208.0, 195.0, 168.0, 182.0, 0.0, 21.0, 48.0, 83.0, 183.0, 204.0, 2.0, 13.0, 20.0, 11.0, 16.0, 13.0, 15.0, 1.0, 0.0, 7.0, 123.0, 192.0, 2.0, 11.0, 28.0, 37.0, 9.0, 29.0, 53.0, 104.0, 34.0, 27.0, 17.0, 46.0, 9.0, 47.0, 130.0, 97.0, 34.0, 37.0, 23.0, 4.0, 13.0, 14.0, 93.0, 79.0, 28.0, 0.0, 61.0, 94.0, 19.0, 0.0, 10.0, 8.0, 8.0, 17.0, 176.0, 147.0, 2.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7776316140295042, "mean_inference_ms": 2.021520114568942, "mean_action_processing_ms": 0.3030585131785441, "mean_env_wait_ms": 0.26748369251521015, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018166542053222656, "StateBufferConnector_ms": 0.0033148527145385742, "ViewRequirementAgentConnector_ms": 0.16949701309204102}, "num_episodes": 18, "episode_return_max": 151.35000000000025, "episode_return_min": -238.11000000000016, "episode_return_mean": 12.361900000000121, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.97367147985346, "num_env_steps_trained_throughput_per_sec": 349.97367147985346, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 12002.538, "restore_workers_time_ms": 0.013, "training_step_time_ms": 12002.484, "sample_time_ms": 1518.783, "learn_time_ms": 10464.346, "learn_throughput": 382.25, "synch_weights_time_ms": 15.951}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "0e60f_00000", "date": "2024-08-15_01-01-44", "timestamp": 1723663904, "time_this_iter_s": 11.469326257705688, "time_total_s": 323.55786633491516, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fe0550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 323.55786633491516, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 49.318749999999994, "ram_util_percent": 83.09375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8944932806586462, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8212725694290062, "policy_loss": -0.012946347828964314, "vf_loss": 0.8333803727020505, "vf_explained_var": 0.05346187778881618, "kl": 0.004192729498230795, "entropy": 1.4676152803910472, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2655225033797914, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5413983930355657, "policy_loss": -0.006374029598257963, "vf_loss": 1.5469503589723477, "vf_explained_var": -0.004049003565752948, "kl": 0.004110304823159725, "entropy": 1.4284700350155906, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 134.15999999999997, "episode_reward_min": -238.11000000000016, "episode_reward_mean": 14.395500000000043, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -473.93, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 26.750000000000266, "predator_policy": 290.0}, "policy_reward_mean": {"prey_policy": -68.04724999999999, "predator_policy": 75.245}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-127.44999999999965, -16.28999999999943, -13.68999999999994, -69.08000000000004, -162.70000000000027, 33.459999999999965, 75.83, 110.2400000000002, -126.63999999999986, 57.4899999999999, 13.130000000000011, 118.30000000000051, 15.899999999999824, 93.15000000000055, -238.11000000000016, 55.70999999999988, 8.839999999999918, 62.75999999999972, 20.690000000000424, 8.40999999999994, -69.51999999999994, -83.74999999999844, -140.79, 66.7000000000004, 24.490000000000347, 0.949999999999981, 72.79999999999997, 59.439999999999806, 51.09999999999985, -4.409999999999968, 4.999999999999937, 93.2900000000002, 17.88000000000025, -9.669999999999902, 13.069999999999974, 44.75999999999994, 115.35000000000106, -0.12000000000004098, 0.8199999999999835, -85.19999999999983, 89.85000000000068, -6.160000000000082, 78.58999999999999, -1.3100000000000722, 69.42999999999981, 56.889999999999624, -35.79999999999986, 114.4500000000008, 131.6700000000002, 21.32999999999999, -29.269999999999772, 38.51999999999998, 64.49000000000004, 6.9399999999999284, 12.889999999999919, 10.88999999999992, 11.809999999999919, 10.999999999999922, 134.15999999999997, 9.859999999999918, 18.390000000000352, -4.230000000000063, 6.230000000000052, 30.83000000000039, -22.609999999999495, -0.30000000000003757, 74.22000000000062, 6.539999999999926, 16.930000000000085, 16.93000000000008, 61.4299999999996, -0.2500000000000411, 44.430000000000014, 8.92999999999993, 38.70999999999934, -1.1500000000000632, 79.7700000000003, -14.149999999999732, 16.80000000000006, 12.909999999999918, -3.419999999999966, 14.549999999999924, 2.9099999999999806, 60.99999999999958, 40.859999999999545, 0.7999999999999808, -43.65000000000066, -9.410000000000077, 8.859999999999921, -3.390000000000077, 1.9300000000000002, 1.9300000000000015, 6.929999999999919, -2.0700000000000838, 4.999999999999937, 10.859999999999918, 26.88000000000011, -12.320000000000068, 5.989999999999917, 52.57999999999933], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-277.39000000000055, -211.06000000000012, -14.080000000000041, -40.210000000000356, -154.77999999999997, -188.91000000000037, -324.73000000000013, -68.34999999999975, -319.60000000000025, -219.10000000000014, -301.3500000000001, -0.1899999999999984, -2.020000000000004, -28.14999999999971, -146.74000000000035, -2.020000000000042, -29.170000000000037, -357.4699999999999, 2.0000000000000013, -298.51000000000045, -431.75999999999993, -20.109999999999708, 2.0000000000000013, -138.69999999999993, -66.34, -150.76000000000016, 2.0000000000000013, -168.8499999999998, -339.58, -305.5300000000001, -0.009999999999998484, -36.28000000000003, -15.159999999999863, 2.0000000000000013, -114.57999999999974, -130.65999999999988, -20.109999999999715, -38.199999999999754, -217.18, -80.40999999999933, -341.63000000000017, -83.88999999999982, -54.280000000000335, -92.46999999999927, -159.84999999999997, -467.94000000000005, -6.040000000000042, -248.25999999999993, -18.09999999999971, -80.40999999999929, -8.050000000000042, 2.0000000000000013, -130.66000000000054, -106.53999999999999, -146.5, -1.0600000000000205, 2.0000000000000013, -178.89999999999978, -54.28, -238.12999999999988, 2.0000000000000013, 2.0000000000000013, -105.67000000000017, -6.040000000000042, -18.099999999999703, 0.9800000000000014, -284.4400000000003, -14.230000000000032, 2.0000000000000013, -473.93, -4.030000000000042, -34.210000000000036, -6.040000000000042, -87.60999999999932, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -34.18000000000036, -273.3700000000003, -164.83000000000015, -0.00999999999999836, -213.14, -10.060000000000041, -18.099999999999707, -70.36000000000001, -8.050000000000042, -13.12000000000004, -30.189999999999717, -369.5700000000003, 2.0000000000000013, -12.070000000000041, -6.040000000000022, -233.17000000000024, -124.62999999999977, -108.5499999999996, 2.0000000000000013, 2.0000000000000013, -273.3300000000004, -28.14999999999971, -300.52000000000015, -26.13999999999971, -24.129999999999708, -76.38999999999936, -16.0899999999997, 4.849999999999961, -327.35999999999984, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -6.040000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -6.190000000000039, 2.0000000000000013, 2.0000000000000013, -178.82000000000068, -2.020000000000042, -12.070000000000041, 8.929999999999959, -44.29000000000034, -2.320000000000036, -22.119999999999706, -20.109999999999737, -116.5899999999994, -34.180000000000355, -14.080000000000041, -16.08999999999979, -33.34000000000031, -52.270000000000344, -42.22000000000031, -14.080000000000041, 2.0000000000000013, -154.78000000000105, -8.050000000000042, -56.410000000000316, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, -10.060000000000041, -106.53999999999958, -4.030000000000042, -30.249999999999726, 2.0000000000000013, -110.5599999999995, -0.00999999999999836, -6.040000000000042, -4.030000000000036, 26.750000000000266, -6.040000000000042, -12.070000000000041, -14.080000000000041, -16.0899999999997, -227.14000000000036, -14.080000000000041, -12.070000000000041, 2.0000000000000013, -14.200000000000038, -12.070000000000041, -2.020000000000042, -4.030000000000042, -76.38999999999925, -23.259999999999728, 2.8099999999999836, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -66.99999999999957, -10.060000000000036, -14.080000000000041, -13.12000000000004, -14.080000000000041, -74.37999999999917, -52.27000000000034, -24.129999999999708, -33.280000000000335, 2.0000000000000013, -17.13999999999971, -54.34000000000033, -8.050000000000042, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -12.070000000000041, -12.070000000000041, 2.0000000000000013, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -3.1000000000000405, -6.040000000000042, 2.0000000000000013, -181.1200000000006, -15.129999999999864, -21.189999999999717, -0.00999999999999836, 2.0000000000000013, 24.710000000000253, 14.86999999999996], "policy_predator_policy_reward": [166.0, 195.0, 10.0, 28.0, 151.0, 179.0, 181.0, 143.0, 194.0, 182.0, 200.0, 135.0, 62.0, 44.0, 99.0, 160.0, 11.0, 249.0, 187.0, 167.0, 265.0, 200.0, 94.0, 161.0, 118.0, 115.0, 123.0, 137.0, 180.0, 227.0, 42.0, 50.0, 10.0, 12.0, 163.0, 145.0, 33.0, 46.0, 140.0, 166.0, 199.0, 157.0, 62.0, 1.0, 197.0, 290.0, 167.0, 154.0, 58.0, 65.0, 7.0, 0.0, 158.0, 152.0, 72.0, 135.0, 151.0, 77.0, 113.0, 175.0, 1.0, 0.0, 88.0, 117.0, 27.0, 8.0, 119.0, 170.0, 236.0, 249.0, 40.0, 43.0, 107.0, 102.0, 14.0, 6.0, 23.0, 10.0, 161.0, 192.0, 175.0, 128.0, 8.0, 14.0, 71.0, 86.0, 20.0, 22.0, 220.0, 217.0, 50.0, 25.0, 159.0, 163.0, 133.0, 88.0, 208.0, 195.0, 168.0, 182.0, 0.0, 21.0, 48.0, 83.0, 183.0, 204.0, 2.0, 13.0, 20.0, 11.0, 16.0, 13.0, 15.0, 1.0, 0.0, 7.0, 123.0, 192.0, 2.0, 11.0, 28.0, 37.0, 9.0, 29.0, 53.0, 104.0, 34.0, 27.0, 17.0, 46.0, 9.0, 47.0, 130.0, 97.0, 34.0, 37.0, 23.0, 4.0, 13.0, 14.0, 93.0, 79.0, 28.0, 0.0, 61.0, 94.0, 19.0, 0.0, 10.0, 8.0, 8.0, 17.0, 176.0, 147.0, 2.0, 10.0, 15.0, 14.0, 11.0, 16.0, 36.0, 41.0, 22.0, 13.0, 4.0, 13.0, 65.0, 61.0, 15.0, 50.0, 8.0, 20.0, 45.0, 38.0, 31.0, 17.0, 13.0, 11.0, 32.0, 27.0, 0.0, 12.0, 9.0, 3.0, 8.0, 9.0, 8.0, 0.0, 0.0, 1.0, 7.0, 13.0, 93.0, 113.0, 17.0, 7.0, 0.0, 4.0, 1.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7800723386071234, "mean_inference_ms": 2.026205732903368, "mean_action_processing_ms": 0.3044994913477308, "mean_env_wait_ms": 0.26765661707069716, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01907491683959961, "StateBufferConnector_ms": 0.003306746482849121, "ViewRequirementAgentConnector_ms": 0.16647064685821533}, "num_episodes": 22, "episode_return_max": 134.15999999999997, "episode_return_min": -238.11000000000016, "episode_return_mean": 14.395500000000043, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.19898853273554, "num_env_steps_trained_throughput_per_sec": 356.19898853273554, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 11841.554, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11841.5, "sample_time_ms": 1510.466, "learn_time_ms": 10312.261, "learn_throughput": 387.888, "synch_weights_time_ms": 15.535}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "0e60f_00000", "date": "2024-08-15_01-01-55", "timestamp": 1723663915, "time_this_iter_s": 11.275657892227173, "time_total_s": 334.83352422714233, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fe0670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 334.83352422714233, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 47.825, "ram_util_percent": 83.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0734883015117949, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.174964722107958, "policy_loss": -0.014079442401983278, "vf_loss": 1.1880240350488633, "vf_explained_var": 0.10776945519699621, "kl": 0.010201278086861132, "entropy": 1.4563270230772634, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8418471162596708, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.459082483866858, "policy_loss": -0.00809247497439621, "vf_loss": 2.465504517504778, "vf_explained_var": -0.011900917373637044, "kl": 0.016704388696750887, "entropy": 1.3697676202607534, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 134.15999999999997, "episode_reward_min": -85.19999999999983, "episode_reward_mean": 21.507, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -473.93, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 26.750000000000266, "predator_policy": 249.0}, "policy_reward_mean": {"prey_policy": -41.71649999999997, "predator_policy": 52.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [66.7000000000004, 24.490000000000347, 0.949999999999981, 72.79999999999997, 59.439999999999806, 51.09999999999985, -4.409999999999968, 4.999999999999937, 93.2900000000002, 17.88000000000025, -9.669999999999902, 13.069999999999974, 44.75999999999994, 115.35000000000106, -0.12000000000004098, 0.8199999999999835, -85.19999999999983, 89.85000000000068, -6.160000000000082, 78.58999999999999, -1.3100000000000722, 69.42999999999981, 56.889999999999624, -35.79999999999986, 114.4500000000008, 131.6700000000002, 21.32999999999999, -29.269999999999772, 38.51999999999998, 64.49000000000004, 6.9399999999999284, 12.889999999999919, 10.88999999999992, 11.809999999999919, 10.999999999999922, 134.15999999999997, 9.859999999999918, 18.390000000000352, -4.230000000000063, 6.230000000000052, 30.83000000000039, -22.609999999999495, -0.30000000000003757, 74.22000000000062, 6.539999999999926, 16.930000000000085, 16.93000000000008, 61.4299999999996, -0.2500000000000411, 44.430000000000014, 8.92999999999993, 38.70999999999934, -1.1500000000000632, 79.7700000000003, -14.149999999999732, 16.80000000000006, 12.909999999999918, -3.419999999999966, 14.549999999999924, 2.9099999999999806, 60.99999999999958, 40.859999999999545, 0.7999999999999808, -43.65000000000066, -9.410000000000077, 8.859999999999921, -3.390000000000077, 1.9300000000000002, 1.9300000000000015, 6.929999999999919, -2.0700000000000838, 4.999999999999937, 10.859999999999918, 26.88000000000011, -12.320000000000068, 5.989999999999917, 52.57999999999933, 35.45999999999967, 40.74999999999949, 0.9399999999999819, 73.69000000000075, 4.939999999999937, -36.520000000000685, 29.340000000000355, 25.770000000000575, -6.670000000000071, -14.649999999999782, 30.390000000000402, 3.9699999999999593, -5.200000000000081, 52.229999999999585, -0.6800000000000415, -7.140000000000079, 8.489999999999938, -5.150000000000082, 31.760000000000588, 4.639999999999971, 6.859999999999922, 51.82999999999965, 11.989999999999917], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-6.040000000000042, -248.25999999999993, -18.09999999999971, -80.40999999999929, -8.050000000000042, 2.0000000000000013, -130.66000000000054, -106.53999999999999, -146.5, -1.0600000000000205, 2.0000000000000013, -178.89999999999978, -54.28, -238.12999999999988, 2.0000000000000013, 2.0000000000000013, -105.67000000000017, -6.040000000000042, -18.099999999999703, 0.9800000000000014, -284.4400000000003, -14.230000000000032, 2.0000000000000013, -473.93, -4.030000000000042, -34.210000000000036, -6.040000000000042, -87.60999999999932, -8.050000000000042, -12.070000000000041, 2.0000000000000013, -34.18000000000036, -273.3700000000003, -164.83000000000015, -0.00999999999999836, -213.14, -10.060000000000041, -18.099999999999707, -70.36000000000001, -8.050000000000042, -13.12000000000004, -30.189999999999717, -369.5700000000003, 2.0000000000000013, -12.070000000000041, -6.040000000000022, -233.17000000000024, -124.62999999999977, -108.5499999999996, 2.0000000000000013, 2.0000000000000013, -273.3300000000004, -28.14999999999971, -300.52000000000015, -26.13999999999971, -24.129999999999708, -76.38999999999936, -16.0899999999997, 4.849999999999961, -327.35999999999984, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -6.040000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -6.190000000000039, 2.0000000000000013, 2.0000000000000013, -178.82000000000068, -2.020000000000042, -12.070000000000041, 8.929999999999959, -44.29000000000034, -2.320000000000036, -22.119999999999706, -20.109999999999737, -116.5899999999994, -34.180000000000355, -14.080000000000041, -16.08999999999979, -33.34000000000031, -52.270000000000344, -42.22000000000031, -14.080000000000041, 2.0000000000000013, -154.78000000000105, -8.050000000000042, -56.410000000000316, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, -10.060000000000041, -106.53999999999958, -4.030000000000042, -30.249999999999726, 2.0000000000000013, -110.5599999999995, -0.00999999999999836, -6.040000000000042, -4.030000000000036, 26.750000000000266, -6.040000000000042, -12.070000000000041, -14.080000000000041, -16.0899999999997, -227.14000000000036, -14.080000000000041, -12.070000000000041, 2.0000000000000013, -14.200000000000038, -12.070000000000041, -2.020000000000042, -4.030000000000042, -76.38999999999925, -23.259999999999728, 2.8099999999999836, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -66.99999999999957, -10.060000000000036, -14.080000000000041, -13.12000000000004, -14.080000000000041, -74.37999999999917, -52.27000000000034, -24.129999999999708, -33.280000000000335, 2.0000000000000013, -17.13999999999971, -54.34000000000033, -8.050000000000042, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -12.070000000000041, -12.070000000000041, 2.0000000000000013, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -3.1000000000000405, -6.040000000000042, 2.0000000000000013, -181.1200000000006, -15.129999999999864, -21.189999999999717, -0.00999999999999836, 2.0000000000000013, 24.710000000000253, 14.86999999999996, -84.42999999999921, -20.109999999999705, -48.25000000000035, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -39.31000000000021, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -40.210000000000356, -60.31000000000033, -130.66000000000105, 2.0000000000000013, 16.85000000000011, -14.080000000000041, -14.080000000000041, -113.58999999999929, 9.919999999999959, -112.56999999999928, -120.60999999999929, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -28.14999999999971, 20.810000000000283, -114.57999999999929, -79.41999999999922, -17.259999999999742, -12.070000000000041, -12.070000000000041, -22.119999999999706, -1.3900000000000208, -26.13999999999971, -0.00999999999999836, -6.190000000000039, 6.949999999999958, -52.27000000000032, -16.089999999999712, -20.109999999999708, -4.030000000000042, -0.00999999999999836, -12.16000000000004, 2.0000000000000013, -0.00999999999999836], "policy_predator_policy_reward": [167.0, 154.0, 58.0, 65.0, 7.0, 0.0, 158.0, 152.0, 72.0, 135.0, 151.0, 77.0, 113.0, 175.0, 1.0, 0.0, 88.0, 117.0, 27.0, 8.0, 119.0, 170.0, 236.0, 249.0, 40.0, 43.0, 107.0, 102.0, 14.0, 6.0, 23.0, 10.0, 161.0, 192.0, 175.0, 128.0, 8.0, 14.0, 71.0, 86.0, 20.0, 22.0, 220.0, 217.0, 50.0, 25.0, 159.0, 163.0, 133.0, 88.0, 208.0, 195.0, 168.0, 182.0, 0.0, 21.0, 48.0, 83.0, 183.0, 204.0, 2.0, 13.0, 20.0, 11.0, 16.0, 13.0, 15.0, 1.0, 0.0, 7.0, 123.0, 192.0, 2.0, 11.0, 28.0, 37.0, 9.0, 29.0, 53.0, 104.0, 34.0, 27.0, 17.0, 46.0, 9.0, 47.0, 130.0, 97.0, 34.0, 37.0, 23.0, 4.0, 13.0, 14.0, 93.0, 79.0, 28.0, 0.0, 61.0, 94.0, 19.0, 0.0, 10.0, 8.0, 8.0, 17.0, 176.0, 147.0, 2.0, 10.0, 15.0, 14.0, 11.0, 16.0, 36.0, 41.0, 22.0, 13.0, 4.0, 13.0, 65.0, 61.0, 15.0, 50.0, 8.0, 20.0, 45.0, 38.0, 31.0, 17.0, 13.0, 11.0, 32.0, 27.0, 0.0, 12.0, 9.0, 3.0, 8.0, 9.0, 8.0, 0.0, 0.0, 1.0, 7.0, 13.0, 93.0, 113.0, 17.0, 7.0, 0.0, 4.0, 1.0, 12.0, 45.0, 95.0, 35.0, 52.0, 0.0, 9.0, 21.0, 90.0, 3.0, 10.0, 24.0, 40.0, 80.0, 78.0, 11.0, 12.0, 57.0, 64.0, 66.0, 22.0, 79.0, 70.0, 5.0, 1.0, 21.0, 10.0, 84.0, 62.0, 55.0, 41.0, 4.0, 13.0, 15.0, 17.0, 5.0, 16.0, 5.0, 26.0, 50.0, 23.0, 11.0, 20.0, 24.0, 40.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7810532337043408, "mean_inference_ms": 2.028248497721544, "mean_action_processing_ms": 0.31301048797234343, "mean_env_wait_ms": 0.2670150236593527, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01900184154510498, "StateBufferConnector_ms": 0.0035982131958007812, "ViewRequirementAgentConnector_ms": 0.14495670795440674}, "num_episodes": 23, "episode_return_max": 134.15999999999997, "episode_return_min": -85.19999999999983, "episode_return_mean": 21.507, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 325.59022584399355, "num_env_steps_trained_throughput_per_sec": 325.59022584399355, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 11865.59, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11865.537, "sample_time_ms": 1597.111, "learn_time_ms": 10249.734, "learn_throughput": 390.254, "synch_weights_time_ms": 15.519}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "0e60f_00000", "date": "2024-08-15_01-02-08", "timestamp": 1723663928, "time_this_iter_s": 12.322535991668701, "time_total_s": 347.15606021881104, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2abd280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 347.15606021881104, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 52.53888888888889, "ram_util_percent": 83.75000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8721089214874954, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4484048439507008, "policy_loss": -0.01212938108318855, "vf_loss": 0.45954736137600055, "vf_explained_var": 0.07065700418734677, "kl": 0.009868623522452461, "entropy": 1.4705055594444274, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6073865226336888, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.957802101638582, "policy_loss": -0.010775151568533922, "vf_loss": 0.9670127978400579, "vf_explained_var": 0.01874342712145003, "kl": 0.01564456821189362, "entropy": 1.3174866594965495, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 134.15999999999997, "episode_reward_min": -43.65000000000066, "episode_reward_mean": 17.6715, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -369.5700000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 26.750000000000266, "predator_policy": 220.0}, "policy_reward_mean": {"prey_policy": -29.669249999999966, "predator_policy": 38.505}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.160000000000082, 78.58999999999999, -1.3100000000000722, 69.42999999999981, 56.889999999999624, -35.79999999999986, 114.4500000000008, 131.6700000000002, 21.32999999999999, -29.269999999999772, 38.51999999999998, 64.49000000000004, 6.9399999999999284, 12.889999999999919, 10.88999999999992, 11.809999999999919, 10.999999999999922, 134.15999999999997, 9.859999999999918, 18.390000000000352, -4.230000000000063, 6.230000000000052, 30.83000000000039, -22.609999999999495, -0.30000000000003757, 74.22000000000062, 6.539999999999926, 16.930000000000085, 16.93000000000008, 61.4299999999996, -0.2500000000000411, 44.430000000000014, 8.92999999999993, 38.70999999999934, -1.1500000000000632, 79.7700000000003, -14.149999999999732, 16.80000000000006, 12.909999999999918, -3.419999999999966, 14.549999999999924, 2.9099999999999806, 60.99999999999958, 40.859999999999545, 0.7999999999999808, -43.65000000000066, -9.410000000000077, 8.859999999999921, -3.390000000000077, 1.9300000000000002, 1.9300000000000015, 6.929999999999919, -2.0700000000000838, 4.999999999999937, 10.859999999999918, 26.88000000000011, -12.320000000000068, 5.989999999999917, 52.57999999999933, 35.45999999999967, 40.74999999999949, 0.9399999999999819, 73.69000000000075, 4.939999999999937, -36.520000000000685, 29.340000000000355, 25.770000000000575, -6.670000000000071, -14.649999999999782, 30.390000000000402, 3.9699999999999593, -5.200000000000081, 52.229999999999585, -0.6800000000000415, -7.140000000000079, 8.489999999999938, -5.150000000000082, 31.760000000000588, 4.639999999999971, 6.859999999999922, 51.82999999999965, 11.989999999999917, 11.839999999999922, 11.929999999999918, 9.999999999999915, 3.9999999999999587, 16.84000000000007, -0.10000000000003921, 41.75999999999957, -17.439999999999486, 23.580000000000446, -0.1500000000000392, 30.61000000000056, -11.240000000000052, 7.889999999999921, -10.430000000000046, 19.95000000000055, -3.329999999999991, 12.989999999999917, 23.850000000000477], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.060000000000041, -18.099999999999707, -70.36000000000001, -8.050000000000042, -13.12000000000004, -30.189999999999717, -369.5700000000003, 2.0000000000000013, -12.070000000000041, -6.040000000000022, -233.17000000000024, -124.62999999999977, -108.5499999999996, 2.0000000000000013, 2.0000000000000013, -273.3300000000004, -28.14999999999971, -300.52000000000015, -26.13999999999971, -24.129999999999708, -76.38999999999936, -16.0899999999997, 4.849999999999961, -327.35999999999984, 2.0000000000000013, -10.060000000000041, -12.070000000000041, -6.040000000000042, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -6.190000000000039, 2.0000000000000013, 2.0000000000000013, -178.82000000000068, -2.020000000000042, -12.070000000000041, 8.929999999999959, -44.29000000000034, -2.320000000000036, -22.119999999999706, -20.109999999999737, -116.5899999999994, -34.180000000000355, -14.080000000000041, -16.08999999999979, -33.34000000000031, -52.270000000000344, -42.22000000000031, -14.080000000000041, 2.0000000000000013, -154.78000000000105, -8.050000000000042, -56.410000000000316, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, -10.060000000000041, -106.53999999999958, -4.030000000000042, -30.249999999999726, 2.0000000000000013, -110.5599999999995, -0.00999999999999836, -6.040000000000042, -4.030000000000036, 26.750000000000266, -6.040000000000042, -12.070000000000041, -14.080000000000041, -16.0899999999997, -227.14000000000036, -14.080000000000041, -12.070000000000041, 2.0000000000000013, -14.200000000000038, -12.070000000000041, -2.020000000000042, -4.030000000000042, -76.38999999999925, -23.259999999999728, 2.8099999999999836, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -66.99999999999957, -10.060000000000036, -14.080000000000041, -13.12000000000004, -14.080000000000041, -74.37999999999917, -52.27000000000034, -24.129999999999708, -33.280000000000335, 2.0000000000000013, -17.13999999999971, -54.34000000000033, -8.050000000000042, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -12.070000000000041, -12.070000000000041, 2.0000000000000013, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -3.1000000000000405, -6.040000000000042, 2.0000000000000013, -181.1200000000006, -15.129999999999864, -21.189999999999717, -0.00999999999999836, 2.0000000000000013, 24.710000000000253, 14.86999999999996, -84.42999999999921, -20.109999999999705, -48.25000000000035, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -39.31000000000021, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -40.210000000000356, -60.31000000000033, -130.66000000000105, 2.0000000000000013, 16.85000000000011, -14.080000000000041, -14.080000000000041, -113.58999999999929, 9.919999999999959, -112.56999999999928, -120.60999999999929, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -28.14999999999971, 20.810000000000283, -114.57999999999929, -79.41999999999922, -17.259999999999742, -12.070000000000041, -12.070000000000041, -22.119999999999706, -1.3900000000000208, -26.13999999999971, -0.00999999999999836, -6.190000000000039, 6.949999999999958, -52.27000000000032, -16.089999999999712, -20.109999999999708, -4.030000000000042, -0.00999999999999836, -12.16000000000004, 2.0000000000000013, -0.00999999999999836, -21.159999999999712, 2.0000000000000013, -9.070000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -26.139999999999716, -2.020000000000042, -18.099999999999703, 2.0000000000000013, -43.24000000000035, 2.0000000000000013, -42.220000000000354, -42.220000000000354, -82.41999999999919, 2.0000000000000013, -24.12999999999971, -2.020000000000042, -25.239999999999725, 16.85000000000011, -4.030000000000042, -40.21000000000035, 2.0000000000000013, -20.109999999999705, -32.170000000000364, -44.26000000000034, -4.030000000000039, -2.0200000000000413, 2.0000000000000013, -64.32999999999926, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, -16.08999999999976], "policy_predator_policy_reward": [8.0, 14.0, 71.0, 86.0, 20.0, 22.0, 220.0, 217.0, 50.0, 25.0, 159.0, 163.0, 133.0, 88.0, 208.0, 195.0, 168.0, 182.0, 0.0, 21.0, 48.0, 83.0, 183.0, 204.0, 2.0, 13.0, 20.0, 11.0, 16.0, 13.0, 15.0, 1.0, 0.0, 7.0, 123.0, 192.0, 2.0, 11.0, 28.0, 37.0, 9.0, 29.0, 53.0, 104.0, 34.0, 27.0, 17.0, 46.0, 9.0, 47.0, 130.0, 97.0, 34.0, 37.0, 23.0, 4.0, 13.0, 14.0, 93.0, 79.0, 28.0, 0.0, 61.0, 94.0, 19.0, 0.0, 10.0, 8.0, 8.0, 17.0, 176.0, 147.0, 2.0, 10.0, 15.0, 14.0, 11.0, 16.0, 36.0, 41.0, 22.0, 13.0, 4.0, 13.0, 65.0, 61.0, 15.0, 50.0, 8.0, 20.0, 45.0, 38.0, 31.0, 17.0, 13.0, 11.0, 32.0, 27.0, 0.0, 12.0, 9.0, 3.0, 8.0, 9.0, 8.0, 0.0, 0.0, 1.0, 7.0, 13.0, 93.0, 113.0, 17.0, 7.0, 0.0, 4.0, 1.0, 12.0, 45.0, 95.0, 35.0, 52.0, 0.0, 9.0, 21.0, 90.0, 3.0, 10.0, 24.0, 40.0, 80.0, 78.0, 11.0, 12.0, 57.0, 64.0, 66.0, 22.0, 79.0, 70.0, 5.0, 1.0, 21.0, 10.0, 84.0, 62.0, 55.0, 41.0, 4.0, 13.0, 15.0, 17.0, 5.0, 16.0, 5.0, 26.0, 50.0, 23.0, 11.0, 20.0, 24.0, 40.0, 10.0, 0.0, 13.0, 18.0, 9.0, 10.0, 3.0, 3.0, 0.0, 0.0, 31.0, 14.0, 2.0, 14.0, 44.0, 39.0, 39.0, 28.0, 55.0, 49.0, 24.0, 2.0, 18.0, 21.0, 27.0, 6.0, 23.0, 3.0, 33.0, 33.0, 9.0, 17.0, 22.0, 37.0, 5.0, 6.0, 17.0, 33.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7779286460023818, "mean_inference_ms": 2.0230908477597196, "mean_action_processing_ms": 0.31728681948452164, "mean_env_wait_ms": 0.265862671755448, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018845438957214355, "StateBufferConnector_ms": 0.003684401512145996, "ViewRequirementAgentConnector_ms": 0.11350023746490479}, "num_episodes": 18, "episode_return_max": 134.15999999999997, "episode_return_min": -43.65000000000066, "episode_return_mean": 17.6715, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.75296127499723, "num_env_steps_trained_throughput_per_sec": 353.75296127499723, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 11825.962, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11825.909, "sample_time_ms": 1599.389, "learn_time_ms": 10208.385, "learn_throughput": 391.835, "synch_weights_time_ms": 15.359}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "0e60f_00000", "date": "2024-08-15_01-02-19", "timestamp": 1723663939, "time_this_iter_s": 11.362837076187134, "time_total_s": 358.51889729499817, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb0790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 358.51889729499817, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 47.4875, "ram_util_percent": 83.61250000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8734581194699756, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6364342076291217, "policy_loss": -0.018219644202303792, "vf_loss": 0.6533777695129472, "vf_explained_var": 0.15818576692904113, "kl": 0.01276082866230235, "entropy": 1.4292785729680741, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5766401170895843, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1763028588875262, "policy_loss": -0.009218535080759063, "vf_loss": 1.184141732082165, "vf_explained_var": 0.019798824459156664, "kl": 0.013796594311276732, "entropy": 1.3419839096447779, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 79.7700000000003, "episode_reward_min": -43.65000000000066, "episode_reward_mean": 12.002200000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -227.14000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 26.750000000000266, "predator_policy": 176.0}, "policy_reward_mean": {"prey_policy": -21.748899999999967, "predator_policy": 27.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.859999999999918, 18.390000000000352, -4.230000000000063, 6.230000000000052, 30.83000000000039, -22.609999999999495, -0.30000000000003757, 74.22000000000062, 6.539999999999926, 16.930000000000085, 16.93000000000008, 61.4299999999996, -0.2500000000000411, 44.430000000000014, 8.92999999999993, 38.70999999999934, -1.1500000000000632, 79.7700000000003, -14.149999999999732, 16.80000000000006, 12.909999999999918, -3.419999999999966, 14.549999999999924, 2.9099999999999806, 60.99999999999958, 40.859999999999545, 0.7999999999999808, -43.65000000000066, -9.410000000000077, 8.859999999999921, -3.390000000000077, 1.9300000000000002, 1.9300000000000015, 6.929999999999919, -2.0700000000000838, 4.999999999999937, 10.859999999999918, 26.88000000000011, -12.320000000000068, 5.989999999999917, 52.57999999999933, 35.45999999999967, 40.74999999999949, 0.9399999999999819, 73.69000000000075, 4.939999999999937, -36.520000000000685, 29.340000000000355, 25.770000000000575, -6.670000000000071, -14.649999999999782, 30.390000000000402, 3.9699999999999593, -5.200000000000081, 52.229999999999585, -0.6800000000000415, -7.140000000000079, 8.489999999999938, -5.150000000000082, 31.760000000000588, 4.639999999999971, 6.859999999999922, 51.82999999999965, 11.989999999999917, 11.839999999999922, 11.929999999999918, 9.999999999999915, 3.9999999999999587, 16.84000000000007, -0.10000000000003921, 41.75999999999957, -17.439999999999486, 23.580000000000446, -0.1500000000000392, 30.61000000000056, -11.240000000000052, 7.889999999999921, -10.430000000000046, 19.95000000000055, -3.329999999999991, 12.989999999999917, 23.850000000000477, -0.4500000000000395, 22.47000000000045, 5.979999999999918, 37.809999999999434, -11.270000000000078, -8.26000000000004, -12.310000000000056, 21.330000000000354, 16.970000000000088, 10.959999999999917, 21.840000000000586, 12.689999999999921, 12.989999999999917, -5.230000000000068, -14.259999999999769, 3.929999999999959, 6.929999999999918, 1.4699999999999593], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-12.070000000000041, 8.929999999999959, -44.29000000000034, -2.320000000000036, -22.119999999999706, -20.109999999999737, -116.5899999999994, -34.180000000000355, -14.080000000000041, -16.08999999999979, -33.34000000000031, -52.270000000000344, -42.22000000000031, -14.080000000000041, 2.0000000000000013, -154.78000000000105, -8.050000000000042, -56.410000000000316, 2.0000000000000013, -12.070000000000041, -0.00999999999999836, -10.060000000000041, -106.53999999999958, -4.030000000000042, -30.249999999999726, 2.0000000000000013, -110.5599999999995, -0.00999999999999836, -6.040000000000042, -4.030000000000036, 26.750000000000266, -6.040000000000042, -12.070000000000041, -14.080000000000041, -16.0899999999997, -227.14000000000036, -14.080000000000041, -12.070000000000041, 2.0000000000000013, -14.200000000000038, -12.070000000000041, -2.020000000000042, -4.030000000000042, -76.38999999999925, -23.259999999999728, 2.8099999999999836, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -66.99999999999957, -10.060000000000036, -14.080000000000041, -13.12000000000004, -14.080000000000041, -74.37999999999917, -52.27000000000034, -24.129999999999708, -33.280000000000335, 2.0000000000000013, -17.13999999999971, -54.34000000000033, -8.050000000000042, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -12.070000000000041, -12.070000000000041, 2.0000000000000013, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -3.1000000000000405, -6.040000000000042, 2.0000000000000013, -181.1200000000006, -15.129999999999864, -21.189999999999717, -0.00999999999999836, 2.0000000000000013, 24.710000000000253, 14.86999999999996, -84.42999999999921, -20.109999999999705, -48.25000000000035, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -39.31000000000021, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -40.210000000000356, -60.31000000000033, -130.66000000000105, 2.0000000000000013, 16.85000000000011, -14.080000000000041, -14.080000000000041, -113.58999999999929, 9.919999999999959, -112.56999999999928, -120.60999999999929, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -28.14999999999971, 20.810000000000283, -114.57999999999929, -79.41999999999922, -17.259999999999742, -12.070000000000041, -12.070000000000041, -22.119999999999706, -1.3900000000000208, -26.13999999999971, -0.00999999999999836, -6.190000000000039, 6.949999999999958, -52.27000000000032, -16.089999999999712, -20.109999999999708, -4.030000000000042, -0.00999999999999836, -12.16000000000004, 2.0000000000000013, -0.00999999999999836, -21.159999999999712, 2.0000000000000013, -9.070000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -26.139999999999716, -2.020000000000042, -18.099999999999703, 2.0000000000000013, -43.24000000000035, 2.0000000000000013, -42.220000000000354, -42.220000000000354, -82.41999999999919, 2.0000000000000013, -24.12999999999971, -2.020000000000042, -25.239999999999725, 16.85000000000011, -4.030000000000042, -40.21000000000035, 2.0000000000000013, -20.109999999999705, -32.170000000000364, -44.26000000000034, -4.030000000000039, -2.0200000000000413, 2.0000000000000013, -64.32999999999926, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, -16.08999999999976, -85.4499999999992, 2.0000000000000013, -57.4300000000003, -18.099999999999703, 2.0000000000000013, -2.020000000000042, -28.14999999999971, -6.040000000000042, -40.210000000000356, -10.060000000000041, -26.13999999999971, -22.119999999999706, -34.18000000000036, -21.129999999999708, 2.0000000000000013, -132.67000000000118, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -6.13000000000004, 4.969999999999958, -5.200000000000038, -20.109999999999705, 2.0000000000000013, -0.00999999999999836, -20.109999999999705, -22.119999999999706, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -2.020000000000042, -8.050000000000042, -13.150000000000038, -74.37999999999917], "policy_predator_policy_reward": [2.0, 11.0, 28.0, 37.0, 9.0, 29.0, 53.0, 104.0, 34.0, 27.0, 17.0, 46.0, 9.0, 47.0, 130.0, 97.0, 34.0, 37.0, 23.0, 4.0, 13.0, 14.0, 93.0, 79.0, 28.0, 0.0, 61.0, 94.0, 19.0, 0.0, 10.0, 8.0, 8.0, 17.0, 176.0, 147.0, 2.0, 10.0, 15.0, 14.0, 11.0, 16.0, 36.0, 41.0, 22.0, 13.0, 4.0, 13.0, 65.0, 61.0, 15.0, 50.0, 8.0, 20.0, 45.0, 38.0, 31.0, 17.0, 13.0, 11.0, 32.0, 27.0, 0.0, 12.0, 9.0, 3.0, 8.0, 9.0, 8.0, 0.0, 0.0, 1.0, 7.0, 13.0, 93.0, 113.0, 17.0, 7.0, 0.0, 4.0, 1.0, 12.0, 45.0, 95.0, 35.0, 52.0, 0.0, 9.0, 21.0, 90.0, 3.0, 10.0, 24.0, 40.0, 80.0, 78.0, 11.0, 12.0, 57.0, 64.0, 66.0, 22.0, 79.0, 70.0, 5.0, 1.0, 21.0, 10.0, 84.0, 62.0, 55.0, 41.0, 4.0, 13.0, 15.0, 17.0, 5.0, 16.0, 5.0, 26.0, 50.0, 23.0, 11.0, 20.0, 24.0, 40.0, 10.0, 0.0, 13.0, 18.0, 9.0, 10.0, 3.0, 3.0, 0.0, 0.0, 31.0, 14.0, 2.0, 14.0, 44.0, 39.0, 39.0, 28.0, 55.0, 49.0, 24.0, 2.0, 18.0, 21.0, 27.0, 6.0, 23.0, 3.0, 33.0, 33.0, 9.0, 17.0, 22.0, 37.0, 5.0, 6.0, 17.0, 33.0, 48.0, 35.0, 46.0, 52.0, 0.0, 6.0, 25.0, 47.0, 22.0, 17.0, 16.0, 24.0, 22.0, 21.0, 81.0, 71.0, 12.0, 7.0, 9.0, 6.0, 12.0, 11.0, 17.0, 21.0, 3.0, 8.0, 19.0, 18.0, 6.0, 28.0, 11.0, 3.0, 4.0, 13.0, 48.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7737439268294619, "mean_inference_ms": 2.0152027808188784, "mean_action_processing_ms": 0.32103679254213624, "mean_env_wait_ms": 0.26428569241594096, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005951404571533203, "StateBufferConnector_ms": 0.003615736961364746, "ViewRequirementAgentConnector_ms": 0.10036611557006836}, "num_episodes": 18, "episode_return_max": 79.7700000000003, "episode_return_min": -43.65000000000066, "episode_return_mean": 12.002200000000002, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.5091387695378, "num_env_steps_trained_throughput_per_sec": 348.5091387695378, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 11757.045, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11756.992, "sample_time_ms": 1597.391, "learn_time_ms": 10141.77, "learn_throughput": 394.408, "synch_weights_time_ms": 15.062}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "0e60f_00000", "date": "2024-08-15_01-02-31", "timestamp": 1723663951, "time_this_iter_s": 11.525672912597656, "time_total_s": 370.0445702075958, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb8310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 370.0445702075958, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 49.83125, "ram_util_percent": 83.6375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9780462383593201, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.035703836773675, "policy_loss": -0.010469215477092399, "vf_loss": 1.0452669950389357, "vf_explained_var": 0.19716864817987675, "kl": 0.009060566922871858, "entropy": 1.3858474054033794, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4413062010334914, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7770382621300915, "policy_loss": -0.004187459924144956, "vf_loss": 1.7804869551822622, "vf_explained_var": 0.0040806236721220475, "kl": 0.0073877224257838945, "entropy": 1.335688717213888, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 73.69000000000075, "episode_reward_min": -70.7799999999989, "episode_reward_mean": 9.745000000000013, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -265.3300000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 24.710000000000253, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -20.417499999999965, "predator_policy": 25.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-14.149999999999732, 16.80000000000006, 12.909999999999918, -3.419999999999966, 14.549999999999924, 2.9099999999999806, 60.99999999999958, 40.859999999999545, 0.7999999999999808, -43.65000000000066, -9.410000000000077, 8.859999999999921, -3.390000000000077, 1.9300000000000002, 1.9300000000000015, 6.929999999999919, -2.0700000000000838, 4.999999999999937, 10.859999999999918, 26.88000000000011, -12.320000000000068, 5.989999999999917, 52.57999999999933, 35.45999999999967, 40.74999999999949, 0.9399999999999819, 73.69000000000075, 4.939999999999937, -36.520000000000685, 29.340000000000355, 25.770000000000575, -6.670000000000071, -14.649999999999782, 30.390000000000402, 3.9699999999999593, -5.200000000000081, 52.229999999999585, -0.6800000000000415, -7.140000000000079, 8.489999999999938, -5.150000000000082, 31.760000000000588, 4.639999999999971, 6.859999999999922, 51.82999999999965, 11.989999999999917, 11.839999999999922, 11.929999999999918, 9.999999999999915, 3.9999999999999587, 16.84000000000007, -0.10000000000003921, 41.75999999999957, -17.439999999999486, 23.580000000000446, -0.1500000000000392, 30.61000000000056, -11.240000000000052, 7.889999999999921, -10.430000000000046, 19.95000000000055, -3.329999999999991, 12.989999999999917, 23.850000000000477, -0.4500000000000395, 22.47000000000045, 5.979999999999918, 37.809999999999434, -11.270000000000078, -8.26000000000004, -12.310000000000056, 21.330000000000354, 16.970000000000088, 10.959999999999917, 21.840000000000586, 12.689999999999921, 12.989999999999917, -5.230000000000068, -14.259999999999769, 3.929999999999959, 6.929999999999918, 1.4699999999999593, -8.709999999999916, -2.2600000000000797, 31.860000000000593, 33.789999999999864, -7.140000000000079, -70.7799999999989, 30.70000000000058, -21.509999999999476, 8.889999999999919, -0.06000000000004011, -2.1400000000000823, 43.719999999999445, 1.8899999999999881, 54.12999999999977, 13.919999999999916, 18.00000000000027, 20.640000000000544, 13.999999999999915], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-14.080000000000041, -12.070000000000041, 2.0000000000000013, -14.200000000000038, -12.070000000000041, -2.020000000000042, -4.030000000000042, -76.38999999999925, -23.259999999999728, 2.8099999999999836, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -66.99999999999957, -10.060000000000036, -14.080000000000041, -13.12000000000004, -14.080000000000041, -74.37999999999917, -52.27000000000034, -24.129999999999708, -33.280000000000335, 2.0000000000000013, -17.13999999999971, -54.34000000000033, -8.050000000000042, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -12.070000000000041, -12.070000000000041, 2.0000000000000013, -0.00999999999999836, -10.060000000000041, 2.0000000000000013, 2.0000000000000013, -3.1000000000000405, -6.040000000000042, 2.0000000000000013, -181.1200000000006, -15.129999999999864, -21.189999999999717, -0.00999999999999836, 2.0000000000000013, 24.710000000000253, 14.86999999999996, -84.42999999999921, -20.109999999999705, -48.25000000000035, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -39.31000000000021, 2.0000000000000013, -10.060000000000041, 2.0000000000000013, -40.210000000000356, -60.31000000000033, -130.66000000000105, 2.0000000000000013, 16.85000000000011, -14.080000000000041, -14.080000000000041, -113.58999999999929, 9.919999999999959, -112.56999999999928, -120.60999999999929, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -28.14999999999971, 20.810000000000283, -114.57999999999929, -79.41999999999922, -17.259999999999742, -12.070000000000041, -12.070000000000041, -22.119999999999706, -1.3900000000000208, -26.13999999999971, -0.00999999999999836, -6.190000000000039, 6.949999999999958, -52.27000000000032, -16.089999999999712, -20.109999999999708, -4.030000000000042, -0.00999999999999836, -12.16000000000004, 2.0000000000000013, -0.00999999999999836, -21.159999999999712, 2.0000000000000013, -9.070000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -26.139999999999716, -2.020000000000042, -18.099999999999703, 2.0000000000000013, -43.24000000000035, 2.0000000000000013, -42.220000000000354, -42.220000000000354, -82.41999999999919, 2.0000000000000013, -24.12999999999971, -2.020000000000042, -25.239999999999725, 16.85000000000011, -4.030000000000042, -40.21000000000035, 2.0000000000000013, -20.109999999999705, -32.170000000000364, -44.26000000000034, -4.030000000000039, -2.0200000000000413, 2.0000000000000013, -64.32999999999926, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, -16.08999999999976, -85.4499999999992, 2.0000000000000013, -57.4300000000003, -18.099999999999703, 2.0000000000000013, -2.020000000000042, -28.14999999999971, -6.040000000000042, -40.210000000000356, -10.060000000000041, -26.13999999999971, -22.119999999999706, -34.18000000000036, -21.129999999999708, 2.0000000000000013, -132.67000000000118, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -6.13000000000004, 4.969999999999958, -5.200000000000038, -20.109999999999705, 2.0000000000000013, -0.00999999999999836, -20.109999999999705, -22.119999999999706, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -2.020000000000042, -8.050000000000042, -13.150000000000038, -74.37999999999917, 2.0000000000000013, -140.71000000000106, -50.260000000000346, 2.0000000000000013, -4.030000000000042, 12.88999999999996, -26.13999999999971, -12.070000000000041, -10.060000000000041, -11.080000000000041, -265.3300000000005, -88.4499999999992, 7.849999999999961, 16.85000000000011, -39.220000000000354, -35.29000000000034, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -13.09000000000004, 20.810000000000247, -16.0899999999997, 2.0000000000000013, -17.109999999999705, 3.979999999999958, -168.85000000000014, -4.030000000000042, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -13.120000000000035, -13.240000000000036, 2.0000000000000013, 2.0000000000000013], "policy_predator_policy_reward": [2.0, 10.0, 15.0, 14.0, 11.0, 16.0, 36.0, 41.0, 22.0, 13.0, 4.0, 13.0, 65.0, 61.0, 15.0, 50.0, 8.0, 20.0, 45.0, 38.0, 31.0, 17.0, 13.0, 11.0, 32.0, 27.0, 0.0, 12.0, 9.0, 3.0, 8.0, 9.0, 8.0, 0.0, 0.0, 1.0, 7.0, 13.0, 93.0, 113.0, 17.0, 7.0, 0.0, 4.0, 1.0, 12.0, 45.0, 95.0, 35.0, 52.0, 0.0, 9.0, 21.0, 90.0, 3.0, 10.0, 24.0, 40.0, 80.0, 78.0, 11.0, 12.0, 57.0, 64.0, 66.0, 22.0, 79.0, 70.0, 5.0, 1.0, 21.0, 10.0, 84.0, 62.0, 55.0, 41.0, 4.0, 13.0, 15.0, 17.0, 5.0, 16.0, 5.0, 26.0, 50.0, 23.0, 11.0, 20.0, 24.0, 40.0, 10.0, 0.0, 13.0, 18.0, 9.0, 10.0, 3.0, 3.0, 0.0, 0.0, 31.0, 14.0, 2.0, 14.0, 44.0, 39.0, 39.0, 28.0, 55.0, 49.0, 24.0, 2.0, 18.0, 21.0, 27.0, 6.0, 23.0, 3.0, 33.0, 33.0, 9.0, 17.0, 22.0, 37.0, 5.0, 6.0, 17.0, 33.0, 48.0, 35.0, 46.0, 52.0, 0.0, 6.0, 25.0, 47.0, 22.0, 17.0, 16.0, 24.0, 22.0, 21.0, 81.0, 71.0, 12.0, 7.0, 9.0, 6.0, 12.0, 11.0, 17.0, 21.0, 3.0, 8.0, 19.0, 18.0, 6.0, 28.0, 11.0, 3.0, 4.0, 13.0, 48.0, 41.0, 88.0, 42.0, 24.0, 22.0, 9.0, 14.0, 48.0, 24.0, 13.0, 1.0, 146.0, 137.0, 0.0, 6.0, 23.0, 30.0, 14.0, 13.0, 8.0, 0.0, 9.0, 10.0, 8.0, 31.0, 14.0, 3.0, 109.0, 110.0, 19.0, 7.0, 6.0, 8.0, 34.0, 13.0, 2.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7698207771307767, "mean_inference_ms": 2.00785721576879, "mean_action_processing_ms": 0.3246495787460639, "mean_env_wait_ms": 0.26284611362642385, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005483150482177734, "StateBufferConnector_ms": 0.0036721229553222656, "ViewRequirementAgentConnector_ms": 0.10258722305297852}, "num_episodes": 18, "episode_return_max": 73.69000000000075, "episode_return_min": -70.7799999999989, "episode_return_mean": 9.745000000000013, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 332.06012599834224, "num_env_steps_trained_throughput_per_sec": 332.06012599834224, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 11809.112, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11809.059, "sample_time_ms": 1597.552, "learn_time_ms": 10193.28, "learn_throughput": 392.415, "synch_weights_time_ms": 15.262}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "0e60f_00000", "date": "2024-08-15_01-02-43", "timestamp": 1723663963, "time_this_iter_s": 12.1091890335083, "time_total_s": 382.1537592411041, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb8550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 382.1537592411041, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 53.09411764705882, "ram_util_percent": 83.65294117647059}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1378005342902962, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7438858483578005, "policy_loss": -0.007012088912682086, "vf_loss": 0.750542796454417, "vf_explained_var": 0.1230109811144531, "kl": 0.0035514239755981836, "entropy": 1.374638339892897, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5291313558343858, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0882919933430102, "policy_loss": -0.008829816983933881, "vf_loss": 1.096101520190794, "vf_explained_var": 0.09572855341371406, "kl": 0.010202910599940562, "entropy": 1.2933249082514848, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 54.12999999999977, "episode_reward_min": -70.7799999999989, "episode_reward_mean": 8.993300000000048, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -265.3300000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 20.810000000000283, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -19.523349999999958, "predator_policy": 24.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.939999999999937, -36.520000000000685, 29.340000000000355, 25.770000000000575, -6.670000000000071, -14.649999999999782, 30.390000000000402, 3.9699999999999593, -5.200000000000081, 52.229999999999585, -0.6800000000000415, -7.140000000000079, 8.489999999999938, -5.150000000000082, 31.760000000000588, 4.639999999999971, 6.859999999999922, 51.82999999999965, 11.989999999999917, 11.839999999999922, 11.929999999999918, 9.999999999999915, 3.9999999999999587, 16.84000000000007, -0.10000000000003921, 41.75999999999957, -17.439999999999486, 23.580000000000446, -0.1500000000000392, 30.61000000000056, -11.240000000000052, 7.889999999999921, -10.430000000000046, 19.95000000000055, -3.329999999999991, 12.989999999999917, 23.850000000000477, -0.4500000000000395, 22.47000000000045, 5.979999999999918, 37.809999999999434, -11.270000000000078, -8.26000000000004, -12.310000000000056, 21.330000000000354, 16.970000000000088, 10.959999999999917, 21.840000000000586, 12.689999999999921, 12.989999999999917, -5.230000000000068, -14.259999999999769, 3.929999999999959, 6.929999999999918, 1.4699999999999593, -8.709999999999916, -2.2600000000000797, 31.860000000000593, 33.789999999999864, -7.140000000000079, -70.7799999999989, 30.70000000000058, -21.509999999999476, 8.889999999999919, -0.06000000000004011, -2.1400000000000823, 43.719999999999445, 1.8899999999999881, 54.12999999999977, 13.919999999999916, 18.00000000000027, 20.640000000000544, 13.999999999999915, 18.87000000000043, 21.680000000000494, -0.24000000000004107, -31.45000000000042, -11.450000000000067, 0.5899999999999807, 8.729999999999922, -7.4300000000000725, 13.929999999999918, 12.839999999999918, 20.910000000000586, 14.77999999999992, 9.969999999999915, -6.23000000000008, 38.709999999999326, 19.76000000000052, 29.90000000000054, 20.930000000000557, 27.920000000000563, -2.0900000000000833, 20.78000000000052, 5.859999999999921, 33.48, -48.74000000000065, 3.5399999999999343, 36.51999999999935, 5.979999999999916], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.060000000000041, 2.0000000000000013, -40.210000000000356, -60.31000000000033, -130.66000000000105, 2.0000000000000013, 16.85000000000011, -14.080000000000041, -14.080000000000041, -113.58999999999929, 9.919999999999959, -112.56999999999928, -120.60999999999929, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -28.14999999999971, 20.810000000000283, -114.57999999999929, -79.41999999999922, -17.259999999999742, -12.070000000000041, -12.070000000000041, -22.119999999999706, -1.3900000000000208, -26.13999999999971, -0.00999999999999836, -6.190000000000039, 6.949999999999958, -52.27000000000032, -16.089999999999712, -20.109999999999708, -4.030000000000042, -0.00999999999999836, -12.16000000000004, 2.0000000000000013, -0.00999999999999836, -21.159999999999712, 2.0000000000000013, -9.070000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -26.139999999999716, -2.020000000000042, -18.099999999999703, 2.0000000000000013, -43.24000000000035, 2.0000000000000013, -42.220000000000354, -42.220000000000354, -82.41999999999919, 2.0000000000000013, -24.12999999999971, -2.020000000000042, -25.239999999999725, 16.85000000000011, -4.030000000000042, -40.21000000000035, 2.0000000000000013, -20.109999999999705, -32.170000000000364, -44.26000000000034, -4.030000000000039, -2.0200000000000413, 2.0000000000000013, -64.32999999999926, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, -16.08999999999976, -85.4499999999992, 2.0000000000000013, -57.4300000000003, -18.099999999999703, 2.0000000000000013, -2.020000000000042, -28.14999999999971, -6.040000000000042, -40.210000000000356, -10.060000000000041, -26.13999999999971, -22.119999999999706, -34.18000000000036, -21.129999999999708, 2.0000000000000013, -132.67000000000118, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -6.13000000000004, 4.969999999999958, -5.200000000000038, -20.109999999999705, 2.0000000000000013, -0.00999999999999836, -20.109999999999705, -22.119999999999706, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -2.020000000000042, -8.050000000000042, -13.150000000000038, -74.37999999999917, 2.0000000000000013, -140.71000000000106, -50.260000000000346, 2.0000000000000013, -4.030000000000042, 12.88999999999996, -26.13999999999971, -12.070000000000041, -10.060000000000041, -11.080000000000041, -265.3300000000005, -88.4499999999992, 7.849999999999961, 16.85000000000011, -39.220000000000354, -35.29000000000034, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -13.09000000000004, 20.810000000000247, -16.0899999999997, 2.0000000000000013, -17.109999999999705, 3.979999999999958, -168.85000000000014, -4.030000000000042, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -13.120000000000035, -13.240000000000036, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -18.09999999999971, -27.27999999999973, -6.040000000000042, -26.169999999999714, -12.070000000000041, 2.0000000000000013, -88.4499999999992, -8.050000000000042, -78.39999999999924, -25.20999999999972, -8.200000000000038, -14.230000000000038, -6.040000000000042, -17.109999999999705, -41.32000000000032, 2.0000000000000013, -12.070000000000041, 7.939999999999959, -9.10000000000004, 2.0000000000000013, 1.9100000000000015, 11.89999999999996, -22.119999999999706, 2.0000000000000013, 4.969999999999958, -6.040000000000042, -36.19000000000035, 3.7099999999999635, 2.0000000000000013, -16.239999999999725, 2.0000000000000013, 8.899999999999967, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -6.040000000000042, -24.129999999999708, 1.9100000000000015, -23.13999999999971, 2.0000000000000013, -58.360000000000305, 17.840000000000288, -50.260000000000346, -94.47999999999922, -64.3299999999997, -24.129999999999708, 15.829999999999961, -15.30999999999986, -2.020000000000042, 2.0000000000000013], "policy_predator_policy_reward": [3.0, 10.0, 24.0, 40.0, 80.0, 78.0, 11.0, 12.0, 57.0, 64.0, 66.0, 22.0, 79.0, 70.0, 5.0, 1.0, 21.0, 10.0, 84.0, 62.0, 55.0, 41.0, 4.0, 13.0, 15.0, 17.0, 5.0, 16.0, 5.0, 26.0, 50.0, 23.0, 11.0, 20.0, 24.0, 40.0, 10.0, 0.0, 13.0, 18.0, 9.0, 10.0, 3.0, 3.0, 0.0, 0.0, 31.0, 14.0, 2.0, 14.0, 44.0, 39.0, 39.0, 28.0, 55.0, 49.0, 24.0, 2.0, 18.0, 21.0, 27.0, 6.0, 23.0, 3.0, 33.0, 33.0, 9.0, 17.0, 22.0, 37.0, 5.0, 6.0, 17.0, 33.0, 48.0, 35.0, 46.0, 52.0, 0.0, 6.0, 25.0, 47.0, 22.0, 17.0, 16.0, 24.0, 22.0, 21.0, 81.0, 71.0, 12.0, 7.0, 9.0, 6.0, 12.0, 11.0, 17.0, 21.0, 3.0, 8.0, 19.0, 18.0, 6.0, 28.0, 11.0, 3.0, 4.0, 13.0, 48.0, 41.0, 88.0, 42.0, 24.0, 22.0, 9.0, 14.0, 48.0, 24.0, 13.0, 1.0, 146.0, 137.0, 0.0, 6.0, 23.0, 30.0, 14.0, 13.0, 8.0, 0.0, 9.0, 10.0, 8.0, 31.0, 14.0, 3.0, 109.0, 110.0, 19.0, 7.0, 6.0, 8.0, 34.0, 13.0, 2.0, 8.0, 14.0, 27.0, 30.0, 25.0, 21.0, 17.0, 55.0, 0.0, 21.0, 54.0, 17.0, 17.0, 7.0, 22.0, 8.0, 43.0, 14.0, 10.0, 8.0, 6.0, 6.0, 11.0, 20.0, 5.0, 0.0, 3.0, 10.0, 26.0, 12.0, 21.0, 16.0, 18.0, 3.0, 16.0, 10.0, 21.0, 13.0, 27.0, 3.0, 9.0, 27.0, 16.0, 19.0, 8.0, 36.0, 38.0, 54.0, 42.0, 38.0, 54.0, 18.0, 18.0, 3.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7647892561510683, "mean_inference_ms": 1.9986153366247859, "mean_action_processing_ms": 0.32896710819493896, "mean_env_wait_ms": 0.26183891699721823, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005446076393127441, "StateBufferConnector_ms": 0.0038194656372070312, "ViewRequirementAgentConnector_ms": 0.11317098140716553}, "num_episodes": 27, "episode_return_max": 54.12999999999977, "episode_return_min": -70.7799999999989, "episode_return_mean": 8.993300000000048, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.14422997163234, "num_env_steps_trained_throughput_per_sec": 352.14422997163234, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 11774.005, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11773.954, "sample_time_ms": 1585.109, "learn_time_ms": 10170.747, "learn_throughput": 393.285, "synch_weights_time_ms": 15.383}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "0e60f_00000", "date": "2024-08-15_01-02-54", "timestamp": 1723663974, "time_this_iter_s": 11.42908525466919, "time_total_s": 393.5828444957733, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb8f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 393.5828444957733, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 46.864705882352936, "ram_util_percent": 83.74117647058824}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.025468449436483, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6407765139080953, "policy_loss": -0.009570448151075099, "vf_loss": 0.6499871678739076, "vf_explained_var": 0.13841862467230942, "kl": 0.007195875408585798, "entropy": 1.3931568826317156, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.438487907503017, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8360358170731358, "policy_loss": -0.0046889671462060755, "vf_loss": 0.8398628896585217, "vf_explained_var": 0.05219616795343066, "kl": 0.008618951382755645, "entropy": 1.2807627633135155, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 54.12999999999977, "episode_reward_min": -70.7799999999989, "episode_reward_mean": 8.652700000000056, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -265.3300000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 20.810000000000247, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -16.898649999999986, "predator_policy": 21.225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.989999999999917, 11.839999999999922, 11.929999999999918, 9.999999999999915, 3.9999999999999587, 16.84000000000007, -0.10000000000003921, 41.75999999999957, -17.439999999999486, 23.580000000000446, -0.1500000000000392, 30.61000000000056, -11.240000000000052, 7.889999999999921, -10.430000000000046, 19.95000000000055, -3.329999999999991, 12.989999999999917, 23.850000000000477, -0.4500000000000395, 22.47000000000045, 5.979999999999918, 37.809999999999434, -11.270000000000078, -8.26000000000004, -12.310000000000056, 21.330000000000354, 16.970000000000088, 10.959999999999917, 21.840000000000586, 12.689999999999921, 12.989999999999917, -5.230000000000068, -14.259999999999769, 3.929999999999959, 6.929999999999918, 1.4699999999999593, -8.709999999999916, -2.2600000000000797, 31.860000000000593, 33.789999999999864, -7.140000000000079, -70.7799999999989, 30.70000000000058, -21.509999999999476, 8.889999999999919, -0.06000000000004011, -2.1400000000000823, 43.719999999999445, 1.8899999999999881, 54.12999999999977, 13.919999999999916, 18.00000000000027, 20.640000000000544, 13.999999999999915, 18.87000000000043, 21.680000000000494, -0.24000000000004107, -31.45000000000042, -11.450000000000067, 0.5899999999999807, 8.729999999999922, -7.4300000000000725, 13.929999999999918, 12.839999999999918, 20.910000000000586, 14.77999999999992, 9.969999999999915, -6.23000000000008, 38.709999999999326, 19.76000000000052, 29.90000000000054, 20.930000000000557, 27.920000000000563, -2.0900000000000833, 20.78000000000052, 5.859999999999921, 33.48, -48.74000000000065, 3.5399999999999343, 36.51999999999935, 5.979999999999916, 20.77000000000049, 10.789999999999923, 21.560000000000556, 13.919999999999918, 18.840000000000423, -2.4800000000000715, 46.94999999999958, 11.75999999999992, 8.899999999999917, -1.2000000000000632, 3.959999999999958, 13.85999999999992, -35.510000000000595, 24.880000000000553, -1.3600000000000456, 3.92999999999996, -17.31999999999947, -2.100000000000083], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -0.00999999999999836, -21.159999999999712, 2.0000000000000013, -9.070000000000041, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -26.139999999999716, -2.020000000000042, -18.099999999999703, 2.0000000000000013, -43.24000000000035, 2.0000000000000013, -42.220000000000354, -42.220000000000354, -82.41999999999919, 2.0000000000000013, -24.12999999999971, -2.020000000000042, -25.239999999999725, 16.85000000000011, -4.030000000000042, -40.21000000000035, 2.0000000000000013, -20.109999999999705, -32.170000000000364, -44.26000000000034, -4.030000000000039, -2.0200000000000413, 2.0000000000000013, -64.32999999999926, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, -16.08999999999976, -85.4499999999992, 2.0000000000000013, -57.4300000000003, -18.099999999999703, 2.0000000000000013, -2.020000000000042, -28.14999999999971, -6.040000000000042, -40.210000000000356, -10.060000000000041, -26.13999999999971, -22.119999999999706, -34.18000000000036, -21.129999999999708, 2.0000000000000013, -132.67000000000118, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -6.13000000000004, 4.969999999999958, -5.200000000000038, -20.109999999999705, 2.0000000000000013, -0.00999999999999836, -20.109999999999705, -22.119999999999706, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -2.020000000000042, -8.050000000000042, -13.150000000000038, -74.37999999999917, 2.0000000000000013, -140.71000000000106, -50.260000000000346, 2.0000000000000013, -4.030000000000042, 12.88999999999996, -26.13999999999971, -12.070000000000041, -10.060000000000041, -11.080000000000041, -265.3300000000005, -88.4499999999992, 7.849999999999961, 16.85000000000011, -39.220000000000354, -35.29000000000034, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -13.09000000000004, 20.810000000000247, -16.0899999999997, 2.0000000000000013, -17.109999999999705, 3.979999999999958, -168.85000000000014, -4.030000000000042, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -13.120000000000035, -13.240000000000036, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -18.09999999999971, -27.27999999999973, -6.040000000000042, -26.169999999999714, -12.070000000000041, 2.0000000000000013, -88.4499999999992, -8.050000000000042, -78.39999999999924, -25.20999999999972, -8.200000000000038, -14.230000000000038, -6.040000000000042, -17.109999999999705, -41.32000000000032, 2.0000000000000013, -12.070000000000041, 7.939999999999959, -9.10000000000004, 2.0000000000000013, 1.9100000000000015, 11.89999999999996, -22.119999999999706, 2.0000000000000013, 4.969999999999958, -6.040000000000042, -36.19000000000035, 3.7099999999999635, 2.0000000000000013, -16.239999999999725, 2.0000000000000013, 8.899999999999967, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -6.040000000000042, -24.129999999999708, 1.9100000000000015, -23.13999999999971, 2.0000000000000013, -58.360000000000305, 17.840000000000288, -50.260000000000346, -94.47999999999922, -64.3299999999997, -24.129999999999708, 15.829999999999961, -15.30999999999986, -2.020000000000042, 2.0000000000000013, -44.23000000000035, 2.0000000000000013, 2.0000000000000013, -37.210000000000356, -5.230000000000038, 4.789999999999962, -14.080000000000041, 2.0000000000000013, -6.160000000000039, 2.0000000000000013, -26.13999999999971, -42.34000000000033, -6.0400000000000285, -0.009999999999998581, 7.939999999999959, -34.18000000000036, -8.050000000000042, 6.949999999999958, -4.030000000000042, -32.170000000000364, -6.040000000000042, 2.0000000000000013, -2.1400000000000396, 2.0000000000000013, -98.49999999999923, -0.00999999999999836, 5.929999999999962, 6.949999999999958, -32.23000000000035, -24.129999999999708, -12.070000000000041, 2.0000000000000013, 2.0000000000000013, -62.320000000000334, -14.080000000000041, -2.020000000000042], "policy_predator_policy_reward": [10.0, 0.0, 13.0, 18.0, 9.0, 10.0, 3.0, 3.0, 0.0, 0.0, 31.0, 14.0, 2.0, 14.0, 44.0, 39.0, 39.0, 28.0, 55.0, 49.0, 24.0, 2.0, 18.0, 21.0, 27.0, 6.0, 23.0, 3.0, 33.0, 33.0, 9.0, 17.0, 22.0, 37.0, 5.0, 6.0, 17.0, 33.0, 48.0, 35.0, 46.0, 52.0, 0.0, 6.0, 25.0, 47.0, 22.0, 17.0, 16.0, 24.0, 22.0, 21.0, 81.0, 71.0, 12.0, 7.0, 9.0, 6.0, 12.0, 11.0, 17.0, 21.0, 3.0, 8.0, 19.0, 18.0, 6.0, 28.0, 11.0, 3.0, 4.0, 13.0, 48.0, 41.0, 88.0, 42.0, 24.0, 22.0, 9.0, 14.0, 48.0, 24.0, 13.0, 1.0, 146.0, 137.0, 0.0, 6.0, 23.0, 30.0, 14.0, 13.0, 8.0, 0.0, 9.0, 10.0, 8.0, 31.0, 14.0, 3.0, 109.0, 110.0, 19.0, 7.0, 6.0, 8.0, 34.0, 13.0, 2.0, 8.0, 14.0, 27.0, 30.0, 25.0, 21.0, 17.0, 55.0, 0.0, 21.0, 54.0, 17.0, 17.0, 7.0, 22.0, 8.0, 43.0, 14.0, 10.0, 8.0, 6.0, 6.0, 11.0, 20.0, 5.0, 0.0, 3.0, 10.0, 26.0, 12.0, 21.0, 16.0, 18.0, 3.0, 16.0, 10.0, 21.0, 13.0, 27.0, 3.0, 9.0, 27.0, 16.0, 19.0, 8.0, 36.0, 38.0, 54.0, 42.0, 38.0, 54.0, 18.0, 18.0, 3.0, 3.0, 25.0, 38.0, 26.0, 20.0, 12.0, 10.0, 13.0, 13.0, 19.0, 4.0, 27.0, 39.0, 12.0, 41.0, 17.0, 21.0, 7.0, 3.0, 16.0, 19.0, 8.0, 0.0, 12.0, 2.0, 52.0, 11.0, 10.0, 2.0, 23.0, 32.0, 5.0, 9.0, 16.0, 27.0, 14.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7609963760935265, "mean_inference_ms": 1.9905039797939086, "mean_action_processing_ms": 0.3263598194027289, "mean_env_wait_ms": 0.2598463883444298, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005088925361633301, "StateBufferConnector_ms": 0.003557920455932617, "ViewRequirementAgentConnector_ms": 0.1124117374420166}, "num_episodes": 18, "episode_return_max": 54.12999999999977, "episode_return_min": -70.7799999999989, "episode_return_mean": 8.652700000000056, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.2575958753148, "num_env_steps_trained_throughput_per_sec": 348.2575958753148, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 11722.207, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11722.156, "sample_time_ms": 1519.661, "learn_time_ms": 10184.189, "learn_throughput": 392.766, "synch_weights_time_ms": 15.514}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "0e60f_00000", "date": "2024-08-15_01-03-06", "timestamp": 1723663986, "time_this_iter_s": 11.519317150115967, "time_total_s": 405.1021616458893, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bd4280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 405.1021616458893, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 51.6375, "ram_util_percent": 83.66875000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1826327181051648, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6281677127643316, "policy_loss": -0.008064333144969568, "vf_loss": 0.6358416594259402, "vf_explained_var": 0.014190308126822981, "kl": 0.0078076921328848175, "entropy": 1.4025137731007167, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3844429551608979, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9868882202439838, "policy_loss": -0.008949472464709764, "vf_loss": 0.9950672122378829, "vf_explained_var": 0.03651694604959437, "kl": 0.007704795964379569, "entropy": 1.3142700722608616, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 54.12999999999977, "episode_reward_min": -70.7799999999989, "episode_reward_mean": 9.004700000000035, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -265.3300000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 21.80000000000028, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -17.01264999999999, "predator_policy": 21.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [23.850000000000477, -0.4500000000000395, 22.47000000000045, 5.979999999999918, 37.809999999999434, -11.270000000000078, -8.26000000000004, -12.310000000000056, 21.330000000000354, 16.970000000000088, 10.959999999999917, 21.840000000000586, 12.689999999999921, 12.989999999999917, -5.230000000000068, -14.259999999999769, 3.929999999999959, 6.929999999999918, 1.4699999999999593, -8.709999999999916, -2.2600000000000797, 31.860000000000593, 33.789999999999864, -7.140000000000079, -70.7799999999989, 30.70000000000058, -21.509999999999476, 8.889999999999919, -0.06000000000004011, -2.1400000000000823, 43.719999999999445, 1.8899999999999881, 54.12999999999977, 13.919999999999916, 18.00000000000027, 20.640000000000544, 13.999999999999915, 18.87000000000043, 21.680000000000494, -0.24000000000004107, -31.45000000000042, -11.450000000000067, 0.5899999999999807, 8.729999999999922, -7.4300000000000725, 13.929999999999918, 12.839999999999918, 20.910000000000586, 14.77999999999992, 9.969999999999915, -6.23000000000008, 38.709999999999326, 19.76000000000052, 29.90000000000054, 20.930000000000557, 27.920000000000563, -2.0900000000000833, 20.78000000000052, 5.859999999999921, 33.48, -48.74000000000065, 3.5399999999999343, 36.51999999999935, 5.979999999999916, 20.77000000000049, 10.789999999999923, 21.560000000000556, 13.919999999999918, 18.840000000000423, -2.4800000000000715, 46.94999999999958, 11.75999999999992, 8.899999999999917, -1.2000000000000632, 3.959999999999958, 13.85999999999992, -35.510000000000595, 24.880000000000553, -1.3600000000000456, 3.92999999999996, -17.31999999999947, -2.100000000000083, 6.999999999999916, 20.840000000000565, -6.510000000000069, 37.689999999999486, -48.700000000000514, 28.540000000000447, 12.829999999999918, 18.74000000000042, -1.0600000000000622, 16.80000000000006, 41.7199999999993, 3.9999999999999587, 3.8499999999999557, 36.72999999999959, 8.929999999999918, 10.949999999999918, 10.819999999999922, -7.280000000000058], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-10.060000000000041, -16.08999999999976, -85.4499999999992, 2.0000000000000013, -57.4300000000003, -18.099999999999703, 2.0000000000000013, -2.020000000000042, -28.14999999999971, -6.040000000000042, -40.210000000000356, -10.060000000000041, -26.13999999999971, -22.119999999999706, -34.18000000000036, -21.129999999999708, 2.0000000000000013, -132.67000000000118, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, -6.13000000000004, 4.969999999999958, -5.200000000000038, -20.109999999999705, 2.0000000000000013, -0.00999999999999836, -20.109999999999705, -22.119999999999706, -50.260000000000346, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -2.020000000000042, -8.050000000000042, -13.150000000000038, -74.37999999999917, 2.0000000000000013, -140.71000000000106, -50.260000000000346, 2.0000000000000013, -4.030000000000042, 12.88999999999996, -26.13999999999971, -12.070000000000041, -10.060000000000041, -11.080000000000041, -265.3300000000005, -88.4499999999992, 7.849999999999961, 16.85000000000011, -39.220000000000354, -35.29000000000034, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -13.09000000000004, 20.810000000000247, -16.0899999999997, 2.0000000000000013, -17.109999999999705, 3.979999999999958, -168.85000000000014, -4.030000000000042, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -13.120000000000035, -13.240000000000036, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -18.09999999999971, -27.27999999999973, -6.040000000000042, -26.169999999999714, -12.070000000000041, 2.0000000000000013, -88.4499999999992, -8.050000000000042, -78.39999999999924, -25.20999999999972, -8.200000000000038, -14.230000000000038, -6.040000000000042, -17.109999999999705, -41.32000000000032, 2.0000000000000013, -12.070000000000041, 7.939999999999959, -9.10000000000004, 2.0000000000000013, 1.9100000000000015, 11.89999999999996, -22.119999999999706, 2.0000000000000013, 4.969999999999958, -6.040000000000042, -36.19000000000035, 3.7099999999999635, 2.0000000000000013, -16.239999999999725, 2.0000000000000013, 8.899999999999967, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -6.040000000000042, -24.129999999999708, 1.9100000000000015, -23.13999999999971, 2.0000000000000013, -58.360000000000305, 17.840000000000288, -50.260000000000346, -94.47999999999922, -64.3299999999997, -24.129999999999708, 15.829999999999961, -15.30999999999986, -2.020000000000042, 2.0000000000000013, -44.23000000000035, 2.0000000000000013, 2.0000000000000013, -37.210000000000356, -5.230000000000038, 4.789999999999962, -14.080000000000041, 2.0000000000000013, -6.160000000000039, 2.0000000000000013, -26.13999999999971, -42.34000000000033, -6.0400000000000285, -0.009999999999998581, 7.939999999999959, -34.18000000000036, -8.050000000000042, 6.949999999999958, -4.030000000000042, -32.170000000000364, -6.040000000000042, 2.0000000000000013, -2.1400000000000396, 2.0000000000000013, -98.49999999999923, -0.00999999999999836, 5.929999999999962, 6.949999999999958, -32.23000000000035, -24.129999999999708, -12.070000000000041, 2.0000000000000013, 2.0000000000000013, -62.320000000000334, -14.080000000000041, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -12.16000000000004, 2.0000000000000013, -26.13999999999971, -36.370000000000324, -6.040000000000042, -52.270000000000316, 2.0000000000000013, -138.70000000000095, -58.30000000000025, -21.159999999999716, 0.8600000000000013, -4.030000000000042, -6.040000000000042, -6.220000000000038, 2.0000000000000013, -10.060000000000041, -17.199999999999722, 2.0000000000000013, 21.80000000000028, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -4.03000000000004, -22.119999999999706, -0.00999999999999836, -50.26000000000032, -12.070000000000041, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, 2.0000000000000013, -16.179999999999715, -22.119999999999706, -30.15999999999972], "policy_predator_policy_reward": [17.0, 33.0, 48.0, 35.0, 46.0, 52.0, 0.0, 6.0, 25.0, 47.0, 22.0, 17.0, 16.0, 24.0, 22.0, 21.0, 81.0, 71.0, 12.0, 7.0, 9.0, 6.0, 12.0, 11.0, 17.0, 21.0, 3.0, 8.0, 19.0, 18.0, 6.0, 28.0, 11.0, 3.0, 4.0, 13.0, 48.0, 41.0, 88.0, 42.0, 24.0, 22.0, 9.0, 14.0, 48.0, 24.0, 13.0, 1.0, 146.0, 137.0, 0.0, 6.0, 23.0, 30.0, 14.0, 13.0, 8.0, 0.0, 9.0, 10.0, 8.0, 31.0, 14.0, 3.0, 109.0, 110.0, 19.0, 7.0, 6.0, 8.0, 34.0, 13.0, 2.0, 8.0, 14.0, 27.0, 30.0, 25.0, 21.0, 17.0, 55.0, 0.0, 21.0, 54.0, 17.0, 17.0, 7.0, 22.0, 8.0, 43.0, 14.0, 10.0, 8.0, 6.0, 6.0, 11.0, 20.0, 5.0, 0.0, 3.0, 10.0, 26.0, 12.0, 21.0, 16.0, 18.0, 3.0, 16.0, 10.0, 21.0, 13.0, 27.0, 3.0, 9.0, 27.0, 16.0, 19.0, 8.0, 36.0, 38.0, 54.0, 42.0, 38.0, 54.0, 18.0, 18.0, 3.0, 3.0, 25.0, 38.0, 26.0, 20.0, 12.0, 10.0, 13.0, 13.0, 19.0, 4.0, 27.0, 39.0, 12.0, 41.0, 17.0, 21.0, 7.0, 3.0, 16.0, 19.0, 8.0, 0.0, 12.0, 2.0, 52.0, 11.0, 10.0, 2.0, 23.0, 32.0, 5.0, 9.0, 16.0, 27.0, 14.0, 0.0, 0.0, 3.0, 19.0, 12.0, 40.0, 16.0, 47.0, 49.0, 87.0, 1.0, 27.0, 81.0, 8.0, 8.0, 25.0, 6.0, 7.0, 0.0, 16.0, 16.0, 28.0, 6.0, 0.0, 0.0, 13.0, 17.0, 83.0, 4.0, 6.0, 13.0, 9.0, 8.0, 15.0, 10.0, 18.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7573620611973504, "mean_inference_ms": 1.9812891607602854, "mean_action_processing_ms": 0.32436696311009333, "mean_env_wait_ms": 0.2587079664342245, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004891753196716309, "StateBufferConnector_ms": 0.003518819808959961, "ViewRequirementAgentConnector_ms": 0.11378812789916992}, "num_episodes": 18, "episode_return_max": 54.12999999999977, "episode_return_min": -70.7799999999989, "episode_return_mean": 9.004700000000035, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 362.75635757089174, "num_env_steps_trained_throughput_per_sec": 362.75635757089174, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 11600.65, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11600.601, "sample_time_ms": 1427.238, "learn_time_ms": 10156.857, "learn_throughput": 393.823, "synch_weights_time_ms": 13.858}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "0e60f_00000", "date": "2024-08-15_01-03-17", "timestamp": 1723663997, "time_this_iter_s": 11.077651023864746, "time_total_s": 416.179812669754, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb0f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 416.179812669754, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 46.29375, "ram_util_percent": 83.3375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2155158384136422, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7175916267770512, "policy_loss": -0.009989448404925131, "vf_loss": 0.7268248069762848, "vf_explained_var": 0.21391679881111023, "kl": 0.015125335975978966, "entropy": 1.3461201572544361, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3579772690616587, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0350248231143548, "policy_loss": -0.006365166708245558, "vf_loss": 1.0410038225076816, "vf_explained_var": 0.0610275908121987, "kl": 0.003861674609999219, "entropy": 1.2951718045920921, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 62.809999999999604, "episode_reward_min": -70.7799999999989, "episode_reward_mean": 10.051400000000031, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -265.3300000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 21.80000000000028, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -15.754299999999992, "predator_policy": 20.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.4699999999999593, -8.709999999999916, -2.2600000000000797, 31.860000000000593, 33.789999999999864, -7.140000000000079, -70.7799999999989, 30.70000000000058, -21.509999999999476, 8.889999999999919, -0.06000000000004011, -2.1400000000000823, 43.719999999999445, 1.8899999999999881, 54.12999999999977, 13.919999999999916, 18.00000000000027, 20.640000000000544, 13.999999999999915, 18.87000000000043, 21.680000000000494, -0.24000000000004107, -31.45000000000042, -11.450000000000067, 0.5899999999999807, 8.729999999999922, -7.4300000000000725, 13.929999999999918, 12.839999999999918, 20.910000000000586, 14.77999999999992, 9.969999999999915, -6.23000000000008, 38.709999999999326, 19.76000000000052, 29.90000000000054, 20.930000000000557, 27.920000000000563, -2.0900000000000833, 20.78000000000052, 5.859999999999921, 33.48, -48.74000000000065, 3.5399999999999343, 36.51999999999935, 5.979999999999916, 20.77000000000049, 10.789999999999923, 21.560000000000556, 13.919999999999918, 18.840000000000423, -2.4800000000000715, 46.94999999999958, 11.75999999999992, 8.899999999999917, -1.2000000000000632, 3.959999999999958, 13.85999999999992, -35.510000000000595, 24.880000000000553, -1.3600000000000456, 3.92999999999996, -17.31999999999947, -2.100000000000083, 6.999999999999916, 20.840000000000565, -6.510000000000069, 37.689999999999486, -48.700000000000514, 28.540000000000447, 12.829999999999918, 18.74000000000042, -1.0600000000000622, 16.80000000000006, 41.7199999999993, 3.9999999999999587, 3.8499999999999557, 36.72999999999959, 8.929999999999918, 10.949999999999918, 10.819999999999922, -7.280000000000058, 48.63999999999951, 10.679999999999922, 5.499999999999926, 20.630000000000507, 25.840000000000583, 2.5200000000000014, 18.76000000000041, -6.170000000000082, 3.7899999999999614, -2.0900000000000833, 3.9499999999999598, -8.420000000000051, 62.809999999999604, 22.540000000000482, 11.879999999999919, 4.909999999999939, 6.969999999999932, 17.900000000000254], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-13.150000000000038, -74.37999999999917, 2.0000000000000013, -140.71000000000106, -50.260000000000346, 2.0000000000000013, -4.030000000000042, 12.88999999999996, -26.13999999999971, -12.070000000000041, -10.060000000000041, -11.080000000000041, -265.3300000000005, -88.4499999999992, 7.849999999999961, 16.85000000000011, -39.220000000000354, -35.29000000000034, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, -10.060000000000041, -8.050000000000042, -13.09000000000004, 20.810000000000247, -16.0899999999997, 2.0000000000000013, -17.109999999999705, 3.979999999999958, -168.85000000000014, -4.030000000000042, -8.050000000000042, 2.0000000000000013, 2.0000000000000013, -13.120000000000035, -13.240000000000036, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, -18.09999999999971, -27.27999999999973, -6.040000000000042, -26.169999999999714, -12.070000000000041, 2.0000000000000013, -88.4499999999992, -8.050000000000042, -78.39999999999924, -25.20999999999972, -8.200000000000038, -14.230000000000038, -6.040000000000042, -17.109999999999705, -41.32000000000032, 2.0000000000000013, -12.070000000000041, 7.939999999999959, -9.10000000000004, 2.0000000000000013, 1.9100000000000015, 11.89999999999996, -22.119999999999706, 2.0000000000000013, 4.969999999999958, -6.040000000000042, -36.19000000000035, 3.7099999999999635, 2.0000000000000013, -16.239999999999725, 2.0000000000000013, 8.899999999999967, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -6.040000000000042, -24.129999999999708, 1.9100000000000015, -23.13999999999971, 2.0000000000000013, -58.360000000000305, 17.840000000000288, -50.260000000000346, -94.47999999999922, -64.3299999999997, -24.129999999999708, 15.829999999999961, -15.30999999999986, -2.020000000000042, 2.0000000000000013, -44.23000000000035, 2.0000000000000013, 2.0000000000000013, -37.210000000000356, -5.230000000000038, 4.789999999999962, -14.080000000000041, 2.0000000000000013, -6.160000000000039, 2.0000000000000013, -26.13999999999971, -42.34000000000033, -6.0400000000000285, -0.009999999999998581, 7.939999999999959, -34.18000000000036, -8.050000000000042, 6.949999999999958, -4.030000000000042, -32.170000000000364, -6.040000000000042, 2.0000000000000013, -2.1400000000000396, 2.0000000000000013, -98.49999999999923, -0.00999999999999836, 5.929999999999962, 6.949999999999958, -32.23000000000035, -24.129999999999708, -12.070000000000041, 2.0000000000000013, 2.0000000000000013, -62.320000000000334, -14.080000000000041, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -12.16000000000004, 2.0000000000000013, -26.13999999999971, -36.370000000000324, -6.040000000000042, -52.270000000000316, 2.0000000000000013, -138.70000000000095, -58.30000000000025, -21.159999999999716, 0.8600000000000013, -4.030000000000042, -6.040000000000042, -6.220000000000038, 2.0000000000000013, -10.060000000000041, -17.199999999999722, 2.0000000000000013, 21.80000000000028, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -4.03000000000004, -22.119999999999706, -0.00999999999999836, -50.26000000000032, -12.070000000000041, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, 2.0000000000000013, -16.179999999999715, -22.119999999999706, -30.15999999999972, -8.14000000000004, -36.22000000000035, -20.289999999999733, -4.030000000000042, -37.30000000000034, -2.2000000000000384, -16.0899999999997, -9.280000000000037, 17.840000000000288, 2.0000000000000013, -18.36999999999975, -20.109999999999708, -4.030000000000042, -10.210000000000038, -8.050000000000042, -22.119999999999706, 2.0000000000000013, -13.210000000000038, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -52.270000000000344, -7.150000000000039, 2.0000000000000013, -36.19000000000036, -33.37000000000031, -16.089999999999705, -22.11999999999972, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, 11.89999999999996], "policy_predator_policy_reward": [48.0, 41.0, 88.0, 42.0, 24.0, 22.0, 9.0, 14.0, 48.0, 24.0, 13.0, 1.0, 146.0, 137.0, 0.0, 6.0, 23.0, 30.0, 14.0, 13.0, 8.0, 0.0, 9.0, 10.0, 8.0, 31.0, 14.0, 3.0, 109.0, 110.0, 19.0, 7.0, 6.0, 8.0, 34.0, 13.0, 2.0, 8.0, 14.0, 27.0, 30.0, 25.0, 21.0, 17.0, 55.0, 0.0, 21.0, 54.0, 17.0, 17.0, 7.0, 22.0, 8.0, 43.0, 14.0, 10.0, 8.0, 6.0, 6.0, 11.0, 20.0, 5.0, 0.0, 3.0, 10.0, 26.0, 12.0, 21.0, 16.0, 18.0, 3.0, 16.0, 10.0, 21.0, 13.0, 27.0, 3.0, 9.0, 27.0, 16.0, 19.0, 8.0, 36.0, 38.0, 54.0, 42.0, 38.0, 54.0, 18.0, 18.0, 3.0, 3.0, 25.0, 38.0, 26.0, 20.0, 12.0, 10.0, 13.0, 13.0, 19.0, 4.0, 27.0, 39.0, 12.0, 41.0, 17.0, 21.0, 7.0, 3.0, 16.0, 19.0, 8.0, 0.0, 12.0, 2.0, 52.0, 11.0, 10.0, 2.0, 23.0, 32.0, 5.0, 9.0, 16.0, 27.0, 14.0, 0.0, 0.0, 3.0, 19.0, 12.0, 40.0, 16.0, 47.0, 49.0, 87.0, 1.0, 27.0, 81.0, 8.0, 8.0, 25.0, 6.0, 7.0, 0.0, 16.0, 16.0, 28.0, 6.0, 0.0, 0.0, 13.0, 17.0, 83.0, 4.0, 6.0, 13.0, 9.0, 8.0, 15.0, 10.0, 18.0, 27.0, 15.0, 78.0, 15.0, 20.0, 26.0, 19.0, 25.0, 21.0, 4.0, 2.0, 23.0, 18.0, 21.0, 12.0, 9.0, 15.0, 14.0, 1.0, 7.0, 5.0, 4.0, 6.0, 34.0, 17.0, 3.0, 94.0, 39.0, 33.0, 12.0, 20.0, 8.0, 11.0, 1.0, 8.0, 4.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7538478063968376, "mean_inference_ms": 1.9723634224976667, "mean_action_processing_ms": 0.32251235972807185, "mean_env_wait_ms": 0.25757248238017355, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004986286163330078, "StateBufferConnector_ms": 0.0036836862564086914, "ViewRequirementAgentConnector_ms": 0.11633086204528809}, "num_episodes": 18, "episode_return_max": 62.809999999999604, "episode_return_min": -70.7799999999989, "episode_return_mean": 10.051400000000031, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.3299417712027, "num_env_steps_trained_throughput_per_sec": 346.3299417712027, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 11519.65, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11519.602, "sample_time_ms": 1386.258, "learn_time_ms": 10116.974, "learn_throughput": 395.375, "synch_weights_time_ms": 13.612}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "0e60f_00000", "date": "2024-08-15_01-03-28", "timestamp": 1723664008, "time_this_iter_s": 11.612596035003662, "time_total_s": 427.7924087047577, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fc7b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 427.7924087047577, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 51.4125, "ram_util_percent": 83.55}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.123700028910208, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8694755789582376, "policy_loss": -0.006234750103589798, "vf_loss": 0.8752095264811365, "vf_explained_var": 0.028097235052673905, "kl": 0.01001607589329478, "entropy": 1.3026767842984073, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.572671756542549, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0931799671952687, "policy_loss": -0.008885657298501838, "vf_loss": 1.1017818289695593, "vf_explained_var": 0.08233161445647952, "kl": 0.00567595282165674, "entropy": 1.312057410598432, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 62.809999999999604, "episode_reward_min": -48.74000000000065, "episode_reward_mean": 11.096700000000023, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -138.70000000000095, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 21.80000000000028, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": -14.14164999999998, "predator_policy": 19.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-31.45000000000042, -11.450000000000067, 0.5899999999999807, 8.729999999999922, -7.4300000000000725, 13.929999999999918, 12.839999999999918, 20.910000000000586, 14.77999999999992, 9.969999999999915, -6.23000000000008, 38.709999999999326, 19.76000000000052, 29.90000000000054, 20.930000000000557, 27.920000000000563, -2.0900000000000833, 20.78000000000052, 5.859999999999921, 33.48, -48.74000000000065, 3.5399999999999343, 36.51999999999935, 5.979999999999916, 20.77000000000049, 10.789999999999923, 21.560000000000556, 13.919999999999918, 18.840000000000423, -2.4800000000000715, 46.94999999999958, 11.75999999999992, 8.899999999999917, -1.2000000000000632, 3.959999999999958, 13.85999999999992, -35.510000000000595, 24.880000000000553, -1.3600000000000456, 3.92999999999996, -17.31999999999947, -2.100000000000083, 6.999999999999916, 20.840000000000565, -6.510000000000069, 37.689999999999486, -48.700000000000514, 28.540000000000447, 12.829999999999918, 18.74000000000042, -1.0600000000000622, 16.80000000000006, 41.7199999999993, 3.9999999999999587, 3.8499999999999557, 36.72999999999959, 8.929999999999918, 10.949999999999918, 10.819999999999922, -7.280000000000058, 48.63999999999951, 10.679999999999922, 5.499999999999926, 20.630000000000507, 25.840000000000583, 2.5200000000000014, 18.76000000000041, -6.170000000000082, 3.7899999999999614, -2.0900000000000833, 3.9499999999999598, -8.420000000000051, 62.809999999999604, 22.540000000000482, 11.879999999999919, 4.909999999999939, 6.969999999999932, 17.900000000000254, 3.6699999999999577, 12.769999999999925, 15.909999999999918, 26.760000000000282, 57.290000000000326, 17.94000000000026, -0.3400000000000287, 5.919999999999918, 28.320000000000185, 2.8599999999999794, 21.750000000000576, -27.419999999999526, -11.580000000000048, 28.84000000000059, 21.880000000000546, 8.869999999999937, 44.7499999999993, -6.160000000000082, 29.470000000000486, 11.979999999999917, 9.909999999999918, 1.859999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -88.4499999999992, -8.050000000000042, -78.39999999999924, -25.20999999999972, -8.200000000000038, -14.230000000000038, -6.040000000000042, -17.109999999999705, -41.32000000000032, 2.0000000000000013, -12.070000000000041, 7.939999999999959, -9.10000000000004, 2.0000000000000013, 1.9100000000000015, 11.89999999999996, -22.119999999999706, 2.0000000000000013, 4.969999999999958, -6.040000000000042, -36.19000000000035, 3.7099999999999635, 2.0000000000000013, -16.239999999999725, 2.0000000000000013, 8.899999999999967, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -14.080000000000041, 2.0000000000000013, -8.050000000000042, -6.040000000000042, -24.129999999999708, 1.9100000000000015, -23.13999999999971, 2.0000000000000013, -58.360000000000305, 17.840000000000288, -50.260000000000346, -94.47999999999922, -64.3299999999997, -24.129999999999708, 15.829999999999961, -15.30999999999986, -2.020000000000042, 2.0000000000000013, -44.23000000000035, 2.0000000000000013, 2.0000000000000013, -37.210000000000356, -5.230000000000038, 4.789999999999962, -14.080000000000041, 2.0000000000000013, -6.160000000000039, 2.0000000000000013, -26.13999999999971, -42.34000000000033, -6.0400000000000285, -0.009999999999998581, 7.939999999999959, -34.18000000000036, -8.050000000000042, 6.949999999999958, -4.030000000000042, -32.170000000000364, -6.040000000000042, 2.0000000000000013, -2.1400000000000396, 2.0000000000000013, -98.49999999999923, -0.00999999999999836, 5.929999999999962, 6.949999999999958, -32.23000000000035, -24.129999999999708, -12.070000000000041, 2.0000000000000013, 2.0000000000000013, -62.320000000000334, -14.080000000000041, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -12.16000000000004, 2.0000000000000013, -26.13999999999971, -36.370000000000324, -6.040000000000042, -52.270000000000316, 2.0000000000000013, -138.70000000000095, -58.30000000000025, -21.159999999999716, 0.8600000000000013, -4.030000000000042, -6.040000000000042, -6.220000000000038, 2.0000000000000013, -10.060000000000041, -17.199999999999722, 2.0000000000000013, 21.80000000000028, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -4.03000000000004, -22.119999999999706, -0.00999999999999836, -50.26000000000032, -12.070000000000041, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, 2.0000000000000013, -16.179999999999715, -22.119999999999706, -30.15999999999972, -8.14000000000004, -36.22000000000035, -20.289999999999733, -4.030000000000042, -37.30000000000034, -2.2000000000000384, -16.0899999999997, -9.280000000000037, 17.840000000000288, 2.0000000000000013, -18.36999999999975, -20.109999999999708, -4.030000000000042, -10.210000000000038, -8.050000000000042, -22.119999999999706, 2.0000000000000013, -13.210000000000038, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -52.270000000000344, -7.150000000000039, 2.0000000000000013, -36.19000000000036, -33.37000000000031, -16.089999999999705, -22.11999999999972, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, 11.89999999999996, -54.28000000000034, -8.050000000000042, 2.0000000000000013, -44.230000000000345, 2.0000000000000013, -16.0899999999997, -46.24000000000015, 2.0000000000000013, -126.66999999999932, -6.040000000000042, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -18.249999999999726, -8.050000000000042, -4.030000000000042, -134.68000000000012, 2.0000000000000013, -17.139999999999713, 2.0000000000000013, -14.080000000000041, 18.830000000000286, -38.20000000000036, -42.220000000000354, -80.4099999999993, -11.170000000000039, 14.86999999999996, -4.030000000000042, -22.11999999999971, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, 20.750000000000274, 2.0000000000000013, -20.109999999999708, -8.050000000000042, -10.480000000000032, -8.050000000000042, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -16.089999999999705, 2.0000000000000013, -20.139999999999713], "policy_predator_policy_reward": [55.0, 0.0, 21.0, 54.0, 17.0, 17.0, 7.0, 22.0, 8.0, 43.0, 14.0, 10.0, 8.0, 6.0, 6.0, 11.0, 20.0, 5.0, 0.0, 3.0, 10.0, 26.0, 12.0, 21.0, 16.0, 18.0, 3.0, 16.0, 10.0, 21.0, 13.0, 27.0, 3.0, 9.0, 27.0, 16.0, 19.0, 8.0, 36.0, 38.0, 54.0, 42.0, 38.0, 54.0, 18.0, 18.0, 3.0, 3.0, 25.0, 38.0, 26.0, 20.0, 12.0, 10.0, 13.0, 13.0, 19.0, 4.0, 27.0, 39.0, 12.0, 41.0, 17.0, 21.0, 7.0, 3.0, 16.0, 19.0, 8.0, 0.0, 12.0, 2.0, 52.0, 11.0, 10.0, 2.0, 23.0, 32.0, 5.0, 9.0, 16.0, 27.0, 14.0, 0.0, 0.0, 3.0, 19.0, 12.0, 40.0, 16.0, 47.0, 49.0, 87.0, 1.0, 27.0, 81.0, 8.0, 8.0, 25.0, 6.0, 7.0, 0.0, 16.0, 16.0, 28.0, 6.0, 0.0, 0.0, 13.0, 17.0, 83.0, 4.0, 6.0, 13.0, 9.0, 8.0, 15.0, 10.0, 18.0, 27.0, 15.0, 78.0, 15.0, 20.0, 26.0, 19.0, 25.0, 21.0, 4.0, 2.0, 23.0, 18.0, 21.0, 12.0, 9.0, 15.0, 14.0, 1.0, 7.0, 5.0, 4.0, 6.0, 34.0, 17.0, 3.0, 94.0, 39.0, 33.0, 12.0, 20.0, 8.0, 11.0, 1.0, 8.0, 4.0, 0.0, 28.0, 38.0, 26.0, 29.0, 14.0, 16.0, 0.0, 71.0, 21.0, 169.0, 16.0, 10.0, 16.0, 18.0, 10.0, 8.0, 152.0, 9.0, 2.0, 16.0, 14.0, 3.0, 34.0, 19.0, 44.0, 36.0, 10.0, 8.0, 17.0, 25.0, 31.0, 0.0, 10.0, 12.0, 15.0, 7.0, 22.0, 26.0, 10.0, 2.0, 13.0, 11.0, 20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7496896710009563, "mean_inference_ms": 1.9633711634022597, "mean_action_processing_ms": 0.31902859473669104, "mean_env_wait_ms": 0.2566281015559971, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047397613525390625, "StateBufferConnector_ms": 0.0038655996322631836, "ViewRequirementAgentConnector_ms": 0.11178207397460938}, "num_episodes": 22, "episode_return_max": 62.809999999999604, "episode_return_min": -48.74000000000065, "episode_return_mean": 11.096700000000023, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.9404842906324, "num_env_steps_trained_throughput_per_sec": 357.9404842906324, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 11494.211, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11494.163, "sample_time_ms": 1386.592, "learn_time_ms": 10091.455, "learn_throughput": 396.375, "synch_weights_time_ms": 13.631}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "0e60f_00000", "date": "2024-08-15_01-03-40", "timestamp": 1723664020, "time_this_iter_s": 11.232409238815308, "time_total_s": 439.024817943573, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2af9e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 439.024817943573, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 48.006249999999994, "ram_util_percent": 82.88125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2678417092120207, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1993503537758317, "policy_loss": -0.0067801013707168515, "vf_loss": 1.2053687761700342, "vf_explained_var": 0.020113446346666446, "kl": 0.015233604613001302, "entropy": 1.3544575262952734, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7541787995547844, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.429419243114966, "policy_loss": -0.008115304987532672, "vf_loss": 1.4367969228161706, "vf_explained_var": 0.05029308909461612, "kl": 0.014752376471765033, "entropy": 1.311056955844637, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 92.36000000000074, "episode_reward_min": -48.700000000000514, "episode_reward_mean": 11.708600000000025, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -138.70000000000095, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 32.69000000000002, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": -14.74569999999999, "predator_policy": 20.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.979999999999916, 20.77000000000049, 10.789999999999923, 21.560000000000556, 13.919999999999918, 18.840000000000423, -2.4800000000000715, 46.94999999999958, 11.75999999999992, 8.899999999999917, -1.2000000000000632, 3.959999999999958, 13.85999999999992, -35.510000000000595, 24.880000000000553, -1.3600000000000456, 3.92999999999996, -17.31999999999947, -2.100000000000083, 6.999999999999916, 20.840000000000565, -6.510000000000069, 37.689999999999486, -48.700000000000514, 28.540000000000447, 12.829999999999918, 18.74000000000042, -1.0600000000000622, 16.80000000000006, 41.7199999999993, 3.9999999999999587, 3.8499999999999557, 36.72999999999959, 8.929999999999918, 10.949999999999918, 10.819999999999922, -7.280000000000058, 48.63999999999951, 10.679999999999922, 5.499999999999926, 20.630000000000507, 25.840000000000583, 2.5200000000000014, 18.76000000000041, -6.170000000000082, 3.7899999999999614, -2.0900000000000833, 3.9499999999999598, -8.420000000000051, 62.809999999999604, 22.540000000000482, 11.879999999999919, 4.909999999999939, 6.969999999999932, 17.900000000000254, 3.6699999999999577, 12.769999999999925, 15.909999999999918, 26.760000000000282, 57.290000000000326, 17.94000000000026, -0.3400000000000287, 5.919999999999918, 28.320000000000185, 2.8599999999999794, 21.750000000000576, -27.419999999999526, -11.580000000000048, 28.84000000000059, 21.880000000000546, 8.869999999999937, 44.7499999999993, -6.160000000000082, 29.470000000000486, 11.979999999999917, 9.909999999999918, 1.859999999999998, -17.449999999999445, 37.409999999999336, 7.919999999999918, 9.569999999999927, 92.36000000000074, 12.939999999999918, -29.92000000000003, 10.88999999999992, -2.2300000000000804, 28.600000000000474, 3.9499999999999584, 5.919999999999917, -38.410000000000714, 16.92000000000008, -5.120000000000081, 15.709999999999921, 31.32000000000038, 31.61000000000054, -8.25000000000008, -5.220000000000081, 21.82000000000057, 14.79999999999992, 37.80999999999928], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-2.020000000000042, 2.0000000000000013, -44.23000000000035, 2.0000000000000013, 2.0000000000000013, -37.210000000000356, -5.230000000000038, 4.789999999999962, -14.080000000000041, 2.0000000000000013, -6.160000000000039, 2.0000000000000013, -26.13999999999971, -42.34000000000033, -6.0400000000000285, -0.009999999999998581, 7.939999999999959, -34.18000000000036, -8.050000000000042, 6.949999999999958, -4.030000000000042, -32.170000000000364, -6.040000000000042, 2.0000000000000013, -2.1400000000000396, 2.0000000000000013, -98.49999999999923, -0.00999999999999836, 5.929999999999962, 6.949999999999958, -32.23000000000035, -24.129999999999708, -12.070000000000041, 2.0000000000000013, 2.0000000000000013, -62.320000000000334, -14.080000000000041, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -12.16000000000004, 2.0000000000000013, -26.13999999999971, -36.370000000000324, -6.040000000000042, -52.270000000000316, 2.0000000000000013, -138.70000000000095, -58.30000000000025, -21.159999999999716, 0.8600000000000013, -4.030000000000042, -6.040000000000042, -6.220000000000038, 2.0000000000000013, -10.060000000000041, -17.199999999999722, 2.0000000000000013, 21.80000000000028, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -4.03000000000004, -22.119999999999706, -0.00999999999999836, -50.26000000000032, -12.070000000000041, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, 2.0000000000000013, -16.179999999999715, -22.119999999999706, -30.15999999999972, -8.14000000000004, -36.22000000000035, -20.289999999999733, -4.030000000000042, -37.30000000000034, -2.2000000000000384, -16.0899999999997, -9.280000000000037, 17.840000000000288, 2.0000000000000013, -18.36999999999975, -20.109999999999708, -4.030000000000042, -10.210000000000038, -8.050000000000042, -22.119999999999706, 2.0000000000000013, -13.210000000000038, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -52.270000000000344, -7.150000000000039, 2.0000000000000013, -36.19000000000036, -33.37000000000031, -16.089999999999705, -22.11999999999972, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, 11.89999999999996, -54.28000000000034, -8.050000000000042, 2.0000000000000013, -44.230000000000345, 2.0000000000000013, -16.0899999999997, -46.24000000000015, 2.0000000000000013, -126.66999999999932, -6.040000000000042, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -18.249999999999726, -8.050000000000042, -4.030000000000042, -134.68000000000012, 2.0000000000000013, -17.139999999999713, 2.0000000000000013, -14.080000000000041, 18.830000000000286, -38.20000000000036, -42.220000000000354, -80.4099999999993, -11.170000000000039, 14.86999999999996, -4.030000000000042, -22.11999999999971, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, 20.750000000000274, 2.0000000000000013, -20.109999999999708, -8.050000000000042, -10.480000000000032, -8.050000000000042, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -16.089999999999705, 2.0000000000000013, -20.139999999999713, -29.25999999999973, -27.189999999999717, -54.28000000000034, 32.69000000000002, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -48.430000000000305, -103.56999999999992, -12.070000000000041, 2.0000000000000013, -10.06000000000004, -102.51999999999924, -78.40000000000012, -20.109999999999705, 2.0000000000000013, -35.23000000000035, 2.0000000000000013, 2.0000000000000013, -78.39999999999918, -2.020000000000042, -4.030000000000042, -6.040000000000042, 2.9599999999999804, -48.25000000000035, -30.159999999999712, 3.9199999999999617, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, 4.789999999999962, -14.080000000000041, -42.220000000000326, -36.4600000000002, -13.120000000000031, 28.73000000000026, -14.11000000000004, -20.13999999999971, -32.170000000000364, -8.050000000000042, 2.0000000000000013, 10.819999999999961, -23.19999999999972, 2.0000000000000013, 4.96999999999996, 11.83999999999996], "policy_predator_policy_reward": [3.0, 3.0, 25.0, 38.0, 26.0, 20.0, 12.0, 10.0, 13.0, 13.0, 19.0, 4.0, 27.0, 39.0, 12.0, 41.0, 17.0, 21.0, 7.0, 3.0, 16.0, 19.0, 8.0, 0.0, 12.0, 2.0, 52.0, 11.0, 10.0, 2.0, 23.0, 32.0, 5.0, 9.0, 16.0, 27.0, 14.0, 0.0, 0.0, 3.0, 19.0, 12.0, 40.0, 16.0, 47.0, 49.0, 87.0, 1.0, 27.0, 81.0, 8.0, 8.0, 25.0, 6.0, 7.0, 0.0, 16.0, 16.0, 28.0, 6.0, 0.0, 0.0, 13.0, 17.0, 83.0, 4.0, 6.0, 13.0, 9.0, 8.0, 15.0, 10.0, 18.0, 27.0, 15.0, 78.0, 15.0, 20.0, 26.0, 19.0, 25.0, 21.0, 4.0, 2.0, 23.0, 18.0, 21.0, 12.0, 9.0, 15.0, 14.0, 1.0, 7.0, 5.0, 4.0, 6.0, 34.0, 17.0, 3.0, 94.0, 39.0, 33.0, 12.0, 20.0, 8.0, 11.0, 1.0, 8.0, 4.0, 0.0, 28.0, 38.0, 26.0, 29.0, 14.0, 16.0, 0.0, 71.0, 21.0, 169.0, 16.0, 10.0, 16.0, 18.0, 10.0, 8.0, 152.0, 9.0, 2.0, 16.0, 14.0, 3.0, 34.0, 19.0, 44.0, 36.0, 10.0, 8.0, 17.0, 25.0, 31.0, 0.0, 10.0, 12.0, 15.0, 7.0, 22.0, 26.0, 10.0, 2.0, 13.0, 11.0, 20.0, 0.0, 22.0, 17.0, 34.0, 25.0, 11.0, 9.0, 32.0, 24.0, 188.0, 20.0, 8.0, 13.0, 7.0, 144.0, 15.0, 14.0, 15.0, 16.0, 56.0, 49.0, 2.0, 8.0, 3.0, 6.0, 12.0, 28.0, 5.0, 6.0, 2.0, 13.0, 0.0, 25.0, 14.0, 96.0, 13.0, 3.0, 11.0, 15.0, 20.0, 15.0, 8.0, 1.0, 17.0, 19.0, 6.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7456053583816674, "mean_inference_ms": 1.9508770806192774, "mean_action_processing_ms": 0.31817097573864517, "mean_env_wait_ms": 0.25489731947233635, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004067659378051758, "StateBufferConnector_ms": 0.0037485361099243164, "ViewRequirementAgentConnector_ms": 0.1007922887802124}, "num_episodes": 23, "episode_return_max": 92.36000000000074, "episode_return_min": -48.700000000000514, "episode_return_mean": 11.708600000000025, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.587999389983, "num_env_steps_trained_throughput_per_sec": 361.587999389983, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 11477.475, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11477.426, "sample_time_ms": 1391.933, "learn_time_ms": 10069.448, "learn_throughput": 397.241, "synch_weights_time_ms": 13.576}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "0e60f_00000", "date": "2024-08-15_01-03-51", "timestamp": 1723664031, "time_this_iter_s": 11.10730791091919, "time_total_s": 450.1321258544922, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2af9af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 450.1321258544922, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 46.425000000000004, "ram_util_percent": 82.73125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.417453856206445, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1901675421646032, "policy_loss": -0.005991584253706846, "vf_loss": 1.1954227977959568, "vf_explained_var": -0.05109174724609133, "kl": 0.0147266190793812, "entropy": 1.341273502571873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4123847392185656, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5074402667857982, "policy_loss": -0.005893950462932625, "vf_loss": 1.512333148150217, "vf_explained_var": 0.08572043937350077, "kl": 0.020021458848560138, "entropy": 1.3300420352390834, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 92.36000000000074, "episode_reward_min": -48.700000000000514, "episode_reward_mean": 12.694800000000033, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -138.70000000000095, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 32.69000000000002, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": -14.962599999999979, "predator_policy": 21.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-2.100000000000083, 6.999999999999916, 20.840000000000565, -6.510000000000069, 37.689999999999486, -48.700000000000514, 28.540000000000447, 12.829999999999918, 18.74000000000042, -1.0600000000000622, 16.80000000000006, 41.7199999999993, 3.9999999999999587, 3.8499999999999557, 36.72999999999959, 8.929999999999918, 10.949999999999918, 10.819999999999922, -7.280000000000058, 48.63999999999951, 10.679999999999922, 5.499999999999926, 20.630000000000507, 25.840000000000583, 2.5200000000000014, 18.76000000000041, -6.170000000000082, 3.7899999999999614, -2.0900000000000833, 3.9499999999999598, -8.420000000000051, 62.809999999999604, 22.540000000000482, 11.879999999999919, 4.909999999999939, 6.969999999999932, 17.900000000000254, 3.6699999999999577, 12.769999999999925, 15.909999999999918, 26.760000000000282, 57.290000000000326, 17.94000000000026, -0.3400000000000287, 5.919999999999918, 28.320000000000185, 2.8599999999999794, 21.750000000000576, -27.419999999999526, -11.580000000000048, 28.84000000000059, 21.880000000000546, 8.869999999999937, 44.7499999999993, -6.160000000000082, 29.470000000000486, 11.979999999999917, 9.909999999999918, 1.859999999999998, -17.449999999999445, 37.409999999999336, 7.919999999999918, 9.569999999999927, 92.36000000000074, 12.939999999999918, -29.92000000000003, 10.88999999999992, -2.2300000000000804, 28.600000000000474, 3.9499999999999584, 5.919999999999917, -38.410000000000714, 16.92000000000008, -5.120000000000081, 15.709999999999921, 31.32000000000038, 31.61000000000054, -8.25000000000008, -5.220000000000081, 21.82000000000057, 14.79999999999992, 37.80999999999928, -12.230000000000064, 5.989999999999917, 14.929999999999916, 5.799999999999923, 1.970000000000002, -13.24999999999957, 25.620000000000516, 19.800000000000537, -10.280000000000065, 23.770000000000557, 4.919999999999936, 22.66000000000052, 22.86000000000002, 40.32000000000006, -4.190000000000081, 8.949999999999916, 44.59999999999977, 44.60999999999938], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-14.080000000000041, -2.020000000000042, 2.0000000000000013, 2.0000000000000013, -12.16000000000004, 2.0000000000000013, -26.13999999999971, -36.370000000000324, -6.040000000000042, -52.270000000000316, 2.0000000000000013, -138.70000000000095, -58.30000000000025, -21.159999999999716, 0.8600000000000013, -4.030000000000042, -6.040000000000042, -6.220000000000038, 2.0000000000000013, -10.060000000000041, -17.199999999999722, 2.0000000000000013, 21.80000000000028, -14.080000000000041, 2.0000000000000013, 2.0000000000000013, -4.03000000000004, -22.119999999999706, -0.00999999999999836, -50.26000000000032, -12.070000000000041, 2.0000000000000013, -6.040000000000042, -0.00999999999999836, 2.0000000000000013, -16.179999999999715, -22.119999999999706, -30.15999999999972, -8.14000000000004, -36.22000000000035, -20.289999999999733, -4.030000000000042, -37.30000000000034, -2.2000000000000384, -16.0899999999997, -9.280000000000037, 17.840000000000288, 2.0000000000000013, -18.36999999999975, -20.109999999999708, -4.030000000000042, -10.210000000000038, -8.050000000000042, -22.119999999999706, 2.0000000000000013, -13.210000000000038, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -52.270000000000344, -7.150000000000039, 2.0000000000000013, -36.19000000000036, -33.37000000000031, -16.089999999999705, -22.11999999999972, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, 11.89999999999996, -54.28000000000034, -8.050000000000042, 2.0000000000000013, -44.230000000000345, 2.0000000000000013, -16.0899999999997, -46.24000000000015, 2.0000000000000013, -126.66999999999932, -6.040000000000042, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -18.249999999999726, -8.050000000000042, -4.030000000000042, -134.68000000000012, 2.0000000000000013, -17.139999999999713, 2.0000000000000013, -14.080000000000041, 18.830000000000286, -38.20000000000036, -42.220000000000354, -80.4099999999993, -11.170000000000039, 14.86999999999996, -4.030000000000042, -22.11999999999971, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, 20.750000000000274, 2.0000000000000013, -20.109999999999708, -8.050000000000042, -10.480000000000032, -8.050000000000042, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -16.089999999999705, 2.0000000000000013, -20.139999999999713, -29.25999999999973, -27.189999999999717, -54.28000000000034, 32.69000000000002, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -48.430000000000305, -103.56999999999992, -12.070000000000041, 2.0000000000000013, -10.06000000000004, -102.51999999999924, -78.40000000000012, -20.109999999999705, 2.0000000000000013, -35.23000000000035, 2.0000000000000013, 2.0000000000000013, -78.39999999999918, -2.020000000000042, -4.030000000000042, -6.040000000000042, 2.9599999999999804, -48.25000000000035, -30.159999999999712, 3.9199999999999617, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, 4.789999999999962, -14.080000000000041, -42.220000000000326, -36.4600000000002, -13.120000000000031, 28.73000000000026, -14.11000000000004, -20.13999999999971, -32.170000000000364, -8.050000000000042, 2.0000000000000013, 10.819999999999961, -23.19999999999972, 2.0000000000000013, 4.96999999999996, 11.83999999999996, -22.119999999999706, -20.109999999999705, -0.00999999999999836, 2.0000000000000013, 8.929999999999959, 2.0000000000000013, 2.0000000000000013, -32.20000000000036, -0.00999999999999836, -2.020000000000042, -40.21000000000032, -6.040000000000042, 5.629999999999965, -0.00999999999999836, 2.0000000000000013, -26.19999999999972, -32.170000000000364, -20.109999999999708, 2.0000000000000013, -5.230000000000038, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -12.340000000000035, -26.14, 2.0000000000000013, -126.6399999999994, -6.040000000000007, -28.14999999999971, -6.040000000000042, 0.9500000000000014, 2.0000000000000013, -14.08000000000002, -62.32000000000025, -4.030000000000042, -19.359999999999744], "policy_predator_policy_reward": [14.0, 0.0, 0.0, 3.0, 19.0, 12.0, 40.0, 16.0, 47.0, 49.0, 87.0, 1.0, 27.0, 81.0, 8.0, 8.0, 25.0, 6.0, 7.0, 0.0, 16.0, 16.0, 28.0, 6.0, 0.0, 0.0, 13.0, 17.0, 83.0, 4.0, 6.0, 13.0, 9.0, 8.0, 15.0, 10.0, 18.0, 27.0, 15.0, 78.0, 15.0, 20.0, 26.0, 19.0, 25.0, 21.0, 4.0, 2.0, 23.0, 18.0, 21.0, 12.0, 9.0, 15.0, 14.0, 1.0, 7.0, 5.0, 4.0, 6.0, 34.0, 17.0, 3.0, 94.0, 39.0, 33.0, 12.0, 20.0, 8.0, 11.0, 1.0, 8.0, 4.0, 0.0, 28.0, 38.0, 26.0, 29.0, 14.0, 16.0, 0.0, 71.0, 21.0, 169.0, 16.0, 10.0, 16.0, 18.0, 10.0, 8.0, 152.0, 9.0, 2.0, 16.0, 14.0, 3.0, 34.0, 19.0, 44.0, 36.0, 10.0, 8.0, 17.0, 25.0, 31.0, 0.0, 10.0, 12.0, 15.0, 7.0, 22.0, 26.0, 10.0, 2.0, 13.0, 11.0, 20.0, 0.0, 22.0, 17.0, 34.0, 25.0, 11.0, 9.0, 32.0, 24.0, 188.0, 20.0, 8.0, 13.0, 7.0, 144.0, 15.0, 14.0, 15.0, 16.0, 56.0, 49.0, 2.0, 8.0, 3.0, 6.0, 12.0, 28.0, 5.0, 6.0, 2.0, 13.0, 0.0, 25.0, 14.0, 96.0, 13.0, 3.0, 11.0, 15.0, 20.0, 15.0, 8.0, 1.0, 17.0, 19.0, 6.0, 15.0, 15.0, 15.0, 0.0, 4.0, 4.0, 0.0, 14.0, 22.0, 4.0, 0.0, 1.0, 32.0, 12.0, 8.0, 25.0, 19.0, 22.0, 20.0, 13.0, 14.0, 13.0, 4.0, 20.0, 13.0, 40.0, 7.0, 103.0, 70.0, 19.0, 11.0, 6.0, 0.0, 96.0, 25.0, 35.0, 33.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7422272779317808, "mean_inference_ms": 1.941855555293273, "mean_action_processing_ms": 0.31640073600344903, "mean_env_wait_ms": 0.25367183245950575, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004105091094970703, "StateBufferConnector_ms": 0.005371689796447754, "ViewRequirementAgentConnector_ms": 0.10319137573242188}, "num_episodes": 18, "episode_return_max": 92.36000000000074, "episode_return_min": -48.700000000000514, "episode_return_mean": 12.694800000000033, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.48413809021525, "num_env_steps_trained_throughput_per_sec": 354.48413809021525, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 11377.339, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11377.284, "sample_time_ms": 1308.426, "learn_time_ms": 10052.579, "learn_throughput": 397.908, "synch_weights_time_ms": 13.525}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "0e60f_00000", "date": "2024-08-15_01-04-02", "timestamp": 1723664042, "time_this_iter_s": 11.340361833572388, "time_total_s": 461.4724876880646, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2af9160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 461.4724876880646, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 48.44375000000001, "ram_util_percent": 82.61875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3750763876255228, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0359342684772201, "policy_loss": -0.00967726438656134, "vf_loss": 1.0448915900928633, "vf_explained_var": -0.11248574676337066, "kl": 0.014398828639733253, "entropy": 1.3434739681778762, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4014472889994818, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5138435566551471, "policy_loss": -0.008414830278023762, "vf_loss": 1.521230722892852, "vf_explained_var": 0.07374155190255907, "kl": 0.013702210317186774, "entropy": 1.2373918107577733, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 218.56999999999863, "episode_reward_min": -38.410000000000714, "episode_reward_mean": 14.964000000000034, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -134.68000000000012, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 32.69000000000002, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": -14.75799999999996, "predator_policy": 22.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-7.280000000000058, 48.63999999999951, 10.679999999999922, 5.499999999999926, 20.630000000000507, 25.840000000000583, 2.5200000000000014, 18.76000000000041, -6.170000000000082, 3.7899999999999614, -2.0900000000000833, 3.9499999999999598, -8.420000000000051, 62.809999999999604, 22.540000000000482, 11.879999999999919, 4.909999999999939, 6.969999999999932, 17.900000000000254, 3.6699999999999577, 12.769999999999925, 15.909999999999918, 26.760000000000282, 57.290000000000326, 17.94000000000026, -0.3400000000000287, 5.919999999999918, 28.320000000000185, 2.8599999999999794, 21.750000000000576, -27.419999999999526, -11.580000000000048, 28.84000000000059, 21.880000000000546, 8.869999999999937, 44.7499999999993, -6.160000000000082, 29.470000000000486, 11.979999999999917, 9.909999999999918, 1.859999999999998, -17.449999999999445, 37.409999999999336, 7.919999999999918, 9.569999999999927, 92.36000000000074, 12.939999999999918, -29.92000000000003, 10.88999999999992, -2.2300000000000804, 28.600000000000474, 3.9499999999999584, 5.919999999999917, -38.410000000000714, 16.92000000000008, -5.120000000000081, 15.709999999999921, 31.32000000000038, 31.61000000000054, -8.25000000000008, -5.220000000000081, 21.82000000000057, 14.79999999999992, 37.80999999999928, -12.230000000000064, 5.989999999999917, 14.929999999999916, 5.799999999999923, 1.970000000000002, -13.24999999999957, 25.620000000000516, 19.800000000000537, -10.280000000000065, 23.770000000000557, 4.919999999999936, 22.66000000000052, 22.86000000000002, 40.32000000000006, -4.190000000000081, 8.949999999999916, 44.59999999999977, 44.60999999999938, 218.56999999999863, 2.819999999999984, -12.230000000000054, 35.36999999999943, 11.969999999999917, -3.2800000000000793, -7.120000000000083, 18.780000000000413, 12.919999999999916, 1.8299999999999996, 27.780000000000474, 7.679999999999927, 11.969999999999917, 31.880000000000514, 18.6900000000004, -2.150000000000082, 2.96999999999998, 49.53999999999942], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-22.119999999999706, -30.15999999999972, -8.14000000000004, -36.22000000000035, -20.289999999999733, -4.030000000000042, -37.30000000000034, -2.2000000000000384, -16.0899999999997, -9.280000000000037, 17.840000000000288, 2.0000000000000013, -18.36999999999975, -20.109999999999708, -4.030000000000042, -10.210000000000038, -8.050000000000042, -22.119999999999706, 2.0000000000000013, -13.210000000000038, -6.040000000000042, -8.050000000000042, 2.0000000000000013, -8.050000000000042, -52.270000000000344, -7.150000000000039, 2.0000000000000013, -36.19000000000036, -33.37000000000031, -16.089999999999705, -22.11999999999972, 2.0000000000000013, 2.0000000000000013, -16.0899999999997, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, 11.89999999999996, -54.28000000000034, -8.050000000000042, 2.0000000000000013, -44.230000000000345, 2.0000000000000013, -16.0899999999997, -46.24000000000015, 2.0000000000000013, -126.66999999999932, -6.040000000000042, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -18.249999999999726, -8.050000000000042, -4.030000000000042, -134.68000000000012, 2.0000000000000013, -17.139999999999713, 2.0000000000000013, -14.080000000000041, 18.830000000000286, -38.20000000000036, -42.220000000000354, -80.4099999999993, -11.170000000000039, 14.86999999999996, -4.030000000000042, -22.11999999999971, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, 20.750000000000274, 2.0000000000000013, -20.109999999999708, -8.050000000000042, -10.480000000000032, -8.050000000000042, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -16.089999999999705, 2.0000000000000013, -20.139999999999713, -29.25999999999973, -27.189999999999717, -54.28000000000034, 32.69000000000002, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -48.430000000000305, -103.56999999999992, -12.070000000000041, 2.0000000000000013, -10.06000000000004, -102.51999999999924, -78.40000000000012, -20.109999999999705, 2.0000000000000013, -35.23000000000035, 2.0000000000000013, 2.0000000000000013, -78.39999999999918, -2.020000000000042, -4.030000000000042, -6.040000000000042, 2.9599999999999804, -48.25000000000035, -30.159999999999712, 3.9199999999999617, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, 4.789999999999962, -14.080000000000041, -42.220000000000326, -36.4600000000002, -13.120000000000031, 28.73000000000026, -14.11000000000004, -20.13999999999971, -32.170000000000364, -8.050000000000042, 2.0000000000000013, 10.819999999999961, -23.19999999999972, 2.0000000000000013, 4.96999999999996, 11.83999999999996, -22.119999999999706, -20.109999999999705, -0.00999999999999836, 2.0000000000000013, 8.929999999999959, 2.0000000000000013, 2.0000000000000013, -32.20000000000036, -0.00999999999999836, -2.020000000000042, -40.21000000000032, -6.040000000000042, 5.629999999999965, -0.00999999999999836, 2.0000000000000013, -26.19999999999972, -32.170000000000364, -20.109999999999708, 2.0000000000000013, -5.230000000000038, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -12.340000000000035, -26.14, 2.0000000000000013, -126.6399999999994, -6.040000000000007, -28.14999999999971, -6.040000000000042, 0.9500000000000014, 2.0000000000000013, -14.08000000000002, -62.32000000000025, -4.030000000000042, -19.359999999999744, -6.040000000000042, -70.38999999999955, -34.18000000000036, 2.0000000000000013, -26.13999999999971, -16.0899999999997, -74.37999999999919, 26.750000000000274, -4.030000000000042, 2.0000000000000013, -43.270000000000344, -0.00999999999999836, -16.0899999999997, -4.030000000000042, -12.070000000000041, 16.85000000000011, 5.959999999999959, -6.040000000000042, -18.099999999999707, -12.070000000000041, -27.21999999999972, 2.0000000000000013, -6.040000000000042, -24.27999999999973, 2.0000000000000013, -4.030000000000042, -22.11999999999976, 2.0000000000000013, 2.0000000000000013, -21.309999999999736, -28.14999999999971, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -31.42000000000003, -6.040000000000042], "policy_predator_policy_reward": [18.0, 27.0, 15.0, 78.0, 15.0, 20.0, 26.0, 19.0, 25.0, 21.0, 4.0, 2.0, 23.0, 18.0, 21.0, 12.0, 9.0, 15.0, 14.0, 1.0, 7.0, 5.0, 4.0, 6.0, 34.0, 17.0, 3.0, 94.0, 39.0, 33.0, 12.0, 20.0, 8.0, 11.0, 1.0, 8.0, 4.0, 0.0, 28.0, 38.0, 26.0, 29.0, 14.0, 16.0, 0.0, 71.0, 21.0, 169.0, 16.0, 10.0, 16.0, 18.0, 10.0, 8.0, 152.0, 9.0, 2.0, 16.0, 14.0, 3.0, 34.0, 19.0, 44.0, 36.0, 10.0, 8.0, 17.0, 25.0, 31.0, 0.0, 10.0, 12.0, 15.0, 7.0, 22.0, 26.0, 10.0, 2.0, 13.0, 11.0, 20.0, 0.0, 22.0, 17.0, 34.0, 25.0, 11.0, 9.0, 32.0, 24.0, 188.0, 20.0, 8.0, 13.0, 7.0, 144.0, 15.0, 14.0, 15.0, 16.0, 56.0, 49.0, 2.0, 8.0, 3.0, 6.0, 12.0, 28.0, 5.0, 6.0, 2.0, 13.0, 0.0, 25.0, 14.0, 96.0, 13.0, 3.0, 11.0, 15.0, 20.0, 15.0, 8.0, 1.0, 17.0, 19.0, 6.0, 15.0, 15.0, 15.0, 0.0, 4.0, 4.0, 0.0, 14.0, 22.0, 4.0, 0.0, 1.0, 32.0, 12.0, 8.0, 25.0, 19.0, 22.0, 20.0, 13.0, 14.0, 13.0, 4.0, 20.0, 13.0, 40.0, 7.0, 103.0, 70.0, 19.0, 11.0, 6.0, 0.0, 96.0, 25.0, 35.0, 33.0, 145.0, 150.0, 20.0, 15.0, 11.0, 19.0, 43.0, 40.0, 7.0, 7.0, 9.0, 31.0, 11.0, 2.0, 13.0, 1.0, 6.0, 7.0, 20.0, 12.0, 6.0, 47.0, 30.0, 8.0, 7.0, 7.0, 51.0, 1.0, 30.0, 8.0, 8.0, 16.0, 5.0, 0.0, 28.0, 59.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7392860587868129, "mean_inference_ms": 1.9337270228691366, "mean_action_processing_ms": 0.31482642589601845, "mean_env_wait_ms": 0.2525059834328867, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0040901899337768555, "StateBufferConnector_ms": 0.005381345748901367, "ViewRequirementAgentConnector_ms": 0.10228621959686279}, "num_episodes": 18, "episode_return_max": 218.56999999999863, "episode_return_min": -38.410000000000714, "episode_return_mean": 14.964000000000034, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.223254951968, "num_env_steps_trained_throughput_per_sec": 355.223254951968, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 11372.659, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11372.603, "sample_time_ms": 1309.609, "learn_time_ms": 10045.849, "learn_throughput": 398.174, "synch_weights_time_ms": 14.398}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "0e60f_00000", "date": "2024-08-15_01-04-14", "timestamp": 1723664054, "time_this_iter_s": 11.303175926208496, "time_total_s": 472.77566361427307, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a29d6af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 472.77566361427307, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 59.525000000000006, "ram_util_percent": 83.45625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1728013436314921, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0689200598726827, "policy_loss": -0.00470188786004665, "vf_loss": 1.0731333398787433, "vf_explained_var": 0.03409232885118515, "kl": 0.00977210526726762, "entropy": 1.297757383187612, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6602528236215077, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6662066264758035, "policy_loss": -0.009587234993361764, "vf_loss": 1.675131668520983, "vf_explained_var": 0.03795320202433874, "kl": 0.00882925900917848, "entropy": 1.1866852744546517, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 218.56999999999863, "episode_reward_min": -51.70000000000022, "episode_reward_mean": 16.532100000000028, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -134.68000000000012, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.36999999999999, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": -16.25394999999995, "predator_policy": 24.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.760000000000282, 57.290000000000326, 17.94000000000026, -0.3400000000000287, 5.919999999999918, 28.320000000000185, 2.8599999999999794, 21.750000000000576, -27.419999999999526, -11.580000000000048, 28.84000000000059, 21.880000000000546, 8.869999999999937, 44.7499999999993, -6.160000000000082, 29.470000000000486, 11.979999999999917, 9.909999999999918, 1.859999999999998, -17.449999999999445, 37.409999999999336, 7.919999999999918, 9.569999999999927, 92.36000000000074, 12.939999999999918, -29.92000000000003, 10.88999999999992, -2.2300000000000804, 28.600000000000474, 3.9499999999999584, 5.919999999999917, -38.410000000000714, 16.92000000000008, -5.120000000000081, 15.709999999999921, 31.32000000000038, 31.61000000000054, -8.25000000000008, -5.220000000000081, 21.82000000000057, 14.79999999999992, 37.80999999999928, -12.230000000000064, 5.989999999999917, 14.929999999999916, 5.799999999999923, 1.970000000000002, -13.24999999999957, 25.620000000000516, 19.800000000000537, -10.280000000000065, 23.770000000000557, 4.919999999999936, 22.66000000000052, 22.86000000000002, 40.32000000000006, -4.190000000000081, 8.949999999999916, 44.59999999999977, 44.60999999999938, 218.56999999999863, 2.819999999999984, -12.230000000000054, 35.36999999999943, 11.969999999999917, -3.2800000000000793, -7.120000000000083, 18.780000000000413, 12.919999999999916, 1.8299999999999996, 27.780000000000474, 7.679999999999927, 11.969999999999917, 31.880000000000514, 18.6900000000004, -2.150000000000082, 2.96999999999998, 49.53999999999942, 48.889999999999795, 81.88000000000025, -51.70000000000022, 4.8799999999999395, 36.82999999999934, 3.3600000000000296, 15.639999999999922, 52.45999999999937, 7.979999999999917, 33.43999999999999, 84.15000000000146, 37.96999999999947, 18.930000000000437, 22.600000000000463, -8.640000000000072, 19.97000000000056, -34.62000000000048, 17.770000000000255, 42.759999999999735, 8.959999999999917, -18.45999999999957, 7.469999999999928], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-46.24000000000015, 2.0000000000000013, -126.66999999999932, -6.040000000000042, 2.0000000000000013, -10.060000000000041, -16.0899999999997, -18.249999999999726, -8.050000000000042, -4.030000000000042, -134.68000000000012, 2.0000000000000013, -17.139999999999713, 2.0000000000000013, -14.080000000000041, 18.830000000000286, -38.20000000000036, -42.220000000000354, -80.4099999999993, -11.170000000000039, 14.86999999999996, -4.030000000000042, -22.11999999999971, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, 20.750000000000274, 2.0000000000000013, -20.109999999999708, -8.050000000000042, -10.480000000000032, -8.050000000000042, 2.0000000000000013, -2.020000000000042, 2.0000000000000013, -16.089999999999705, 2.0000000000000013, -20.139999999999713, -29.25999999999973, -27.189999999999717, -54.28000000000034, 32.69000000000002, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, -48.430000000000305, -103.56999999999992, -12.070000000000041, 2.0000000000000013, -10.06000000000004, -102.51999999999924, -78.40000000000012, -20.109999999999705, 2.0000000000000013, -35.23000000000035, 2.0000000000000013, 2.0000000000000013, -78.39999999999918, -2.020000000000042, -4.030000000000042, -6.040000000000042, 2.9599999999999804, -48.25000000000035, -30.159999999999712, 3.9199999999999617, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, 4.789999999999962, -14.080000000000041, -42.220000000000326, -36.4600000000002, -13.120000000000031, 28.73000000000026, -14.11000000000004, -20.13999999999971, -32.170000000000364, -8.050000000000042, 2.0000000000000013, 10.819999999999961, -23.19999999999972, 2.0000000000000013, 4.96999999999996, 11.83999999999996, -22.119999999999706, -20.109999999999705, -0.00999999999999836, 2.0000000000000013, 8.929999999999959, 2.0000000000000013, 2.0000000000000013, -32.20000000000036, -0.00999999999999836, -2.020000000000042, -40.21000000000032, -6.040000000000042, 5.629999999999965, -0.00999999999999836, 2.0000000000000013, -26.19999999999972, -32.170000000000364, -20.109999999999708, 2.0000000000000013, -5.230000000000038, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -12.340000000000035, -26.14, 2.0000000000000013, -126.6399999999994, -6.040000000000007, -28.14999999999971, -6.040000000000042, 0.9500000000000014, 2.0000000000000013, -14.08000000000002, -62.32000000000025, -4.030000000000042, -19.359999999999744, -6.040000000000042, -70.38999999999955, -34.18000000000036, 2.0000000000000013, -26.13999999999971, -16.0899999999997, -74.37999999999919, 26.750000000000274, -4.030000000000042, 2.0000000000000013, -43.270000000000344, -0.00999999999999836, -16.0899999999997, -4.030000000000042, -12.070000000000041, 16.85000000000011, 5.959999999999959, -6.040000000000042, -18.099999999999707, -12.070000000000041, -27.21999999999972, 2.0000000000000013, -6.040000000000042, -24.27999999999973, 2.0000000000000013, -4.030000000000042, -22.11999999999976, 2.0000000000000013, 2.0000000000000013, -21.309999999999736, -28.14999999999971, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -31.42000000000003, -6.040000000000042, 2.0000000000000013, -20.109999999999943, -22.119999999999944, 2.0000000000000013, -16.089999999999712, -120.60999999999964, -22.119999999999706, 2.0000000000000013, -4.030000000000042, 9.85999999999996, -108.54999999999954, -16.089999999999723, -2.020000000000042, -57.34000000000033, -23.439999999999756, 11.89999999999996, 2.0000000000000013, -2.020000000000042, -12.460000000000027, -18.099999999999703, 64.36999999999999, -42.220000000000354, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -2.020000000000042, 2.0000000000000013, -48.400000000000226, -14.080000000000041, -86.55999999999926, 2.0000000000000013, -4.030000000000041, -122.6199999999994, 2.0000000000000013, 2.0000000000000013, -11.230000000000036, -8.050000000000042, -36.19000000000011, 2.0000000000000013, -6.040000000000042, -90.45999999999923, 2.0000000000000013, 15.85999999999996, -58.39000000000032], "policy_predator_policy_reward": [0.0, 71.0, 21.0, 169.0, 16.0, 10.0, 16.0, 18.0, 10.0, 8.0, 152.0, 9.0, 2.0, 16.0, 14.0, 3.0, 34.0, 19.0, 44.0, 36.0, 10.0, 8.0, 17.0, 25.0, 31.0, 0.0, 10.0, 12.0, 15.0, 7.0, 22.0, 26.0, 10.0, 2.0, 13.0, 11.0, 20.0, 0.0, 22.0, 17.0, 34.0, 25.0, 11.0, 9.0, 32.0, 24.0, 188.0, 20.0, 8.0, 13.0, 7.0, 144.0, 15.0, 14.0, 15.0, 16.0, 56.0, 49.0, 2.0, 8.0, 3.0, 6.0, 12.0, 28.0, 5.0, 6.0, 2.0, 13.0, 0.0, 25.0, 14.0, 96.0, 13.0, 3.0, 11.0, 15.0, 20.0, 15.0, 8.0, 1.0, 17.0, 19.0, 6.0, 15.0, 15.0, 15.0, 0.0, 4.0, 4.0, 0.0, 14.0, 22.0, 4.0, 0.0, 1.0, 32.0, 12.0, 8.0, 25.0, 19.0, 22.0, 20.0, 13.0, 14.0, 13.0, 4.0, 20.0, 13.0, 40.0, 7.0, 103.0, 70.0, 19.0, 11.0, 6.0, 0.0, 96.0, 25.0, 35.0, 33.0, 145.0, 150.0, 20.0, 15.0, 11.0, 19.0, 43.0, 40.0, 7.0, 7.0, 9.0, 31.0, 11.0, 2.0, 13.0, 1.0, 6.0, 7.0, 20.0, 12.0, 6.0, 47.0, 30.0, 8.0, 7.0, 7.0, 51.0, 1.0, 30.0, 8.0, 8.0, 16.0, 5.0, 0.0, 28.0, 59.0, 0.0, 67.0, 54.0, 48.0, 7.0, 78.0, 15.0, 10.0, 7.0, 24.0, 127.0, 1.0, 37.0, 38.0, 39.0, 25.0, 6.0, 2.0, 20.0, 44.0, 33.0, 29.0, 36.0, 4.0, 12.0, 17.0, 45.0, 24.0, 58.0, 34.0, 17.0, 5.0, 5.0, 81.0, 0.0, 27.0, 79.0, 8.0, 7.0, 6.0, 67.0, 3.0, 14.0, 36.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7358024246314523, "mean_inference_ms": 1.925377847622065, "mean_action_processing_ms": 0.31165665313156543, "mean_env_wait_ms": 0.25145471061328567, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004151701927185059, "StateBufferConnector_ms": 0.005315661430358887, "ViewRequirementAgentConnector_ms": 0.11500108242034912}, "num_episodes": 22, "episode_return_max": 218.56999999999863, "episode_return_min": -51.70000000000022, "episode_return_mean": 16.532100000000028, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 356.2192647531149, "num_env_steps_trained_throughput_per_sec": 356.2192647531149, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 11347.817, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11347.76, "sample_time_ms": 1307.28, "learn_time_ms": 10023.375, "learn_throughput": 399.067, "synch_weights_time_ms": 14.399}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "0e60f_00000", "date": "2024-08-15_01-04-25", "timestamp": 1723664065, "time_this_iter_s": 11.301239013671875, "time_total_s": 484.07690262794495, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb0a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 484.07690262794495, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 56.71875, "ram_util_percent": 83.09375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3735252092597345, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.684631488531355, "policy_loss": -0.0126363429272912, "vf_loss": 1.6966332779359565, "vf_explained_var": -0.06439226859461063, "kl": 0.012690958103379843, "entropy": 1.269614305824199, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.091092666116341, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8047314041506044, "policy_loss": -0.0059084908612979156, "vf_loss": 2.810130244588095, "vf_explained_var": 0.0236603474490857, "kl": 0.006795373846763166, "entropy": 1.0940933304488973, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 218.56999999999863, "episode_reward_min": -51.70000000000022, "episode_reward_mean": 17.90050000000002, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -130.66000000000122, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.36999999999999, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": -18.45474999999997, "predator_policy": 27.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [92.36000000000074, 12.939999999999918, -29.92000000000003, 10.88999999999992, -2.2300000000000804, 28.600000000000474, 3.9499999999999584, 5.919999999999917, -38.410000000000714, 16.92000000000008, -5.120000000000081, 15.709999999999921, 31.32000000000038, 31.61000000000054, -8.25000000000008, -5.220000000000081, 21.82000000000057, 14.79999999999992, 37.80999999999928, -12.230000000000064, 5.989999999999917, 14.929999999999916, 5.799999999999923, 1.970000000000002, -13.24999999999957, 25.620000000000516, 19.800000000000537, -10.280000000000065, 23.770000000000557, 4.919999999999936, 22.66000000000052, 22.86000000000002, 40.32000000000006, -4.190000000000081, 8.949999999999916, 44.59999999999977, 44.60999999999938, 218.56999999999863, 2.819999999999984, -12.230000000000054, 35.36999999999943, 11.969999999999917, -3.2800000000000793, -7.120000000000083, 18.780000000000413, 12.919999999999916, 1.8299999999999996, 27.780000000000474, 7.679999999999927, 11.969999999999917, 31.880000000000514, 18.6900000000004, -2.150000000000082, 2.96999999999998, 49.53999999999942, 48.889999999999795, 81.88000000000025, -51.70000000000022, 4.8799999999999395, 36.82999999999934, 3.3600000000000296, 15.639999999999922, 52.45999999999937, 7.979999999999917, 33.43999999999999, 84.15000000000146, 37.96999999999947, 18.930000000000437, 22.600000000000463, -8.640000000000072, 19.97000000000056, -34.62000000000048, 17.770000000000255, 42.759999999999735, 8.959999999999917, -18.45999999999957, 7.469999999999928, 43.36999999999959, 1.8999999999999972, 7.819999999999919, 14.88999999999992, -23.709999999999653, 8.359999999999932, 57.24999999999989, 0.8999999999999818, 4.879999999999938, 18.96000000000029, 4.689999999999935, 3.89999999999996, 42.13999999999956, 71.97000000000017, 18.96000000000044, 71.60000000000028, -2.0900000000000833, 34.64999999999954, 67.15000000000123, -2.16000000000008, -19.30999999999945, 9.729999999999928, 11.339999999999943], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-103.56999999999992, -12.070000000000041, 2.0000000000000013, -10.06000000000004, -102.51999999999924, -78.40000000000012, -20.109999999999705, 2.0000000000000013, -35.23000000000035, 2.0000000000000013, 2.0000000000000013, -78.39999999999918, -2.020000000000042, -4.030000000000042, -6.040000000000042, 2.9599999999999804, -48.25000000000035, -30.159999999999712, 3.9199999999999617, 2.0000000000000013, -22.119999999999706, 2.0000000000000013, 4.789999999999962, -14.080000000000041, -42.220000000000326, -36.4600000000002, -13.120000000000031, 28.73000000000026, -14.11000000000004, -20.13999999999971, -32.170000000000364, -8.050000000000042, 2.0000000000000013, 10.819999999999961, -23.19999999999972, 2.0000000000000013, 4.96999999999996, 11.83999999999996, -22.119999999999706, -20.109999999999705, -0.00999999999999836, 2.0000000000000013, 8.929999999999959, 2.0000000000000013, 2.0000000000000013, -32.20000000000036, -0.00999999999999836, -2.020000000000042, -40.21000000000032, -6.040000000000042, 5.629999999999965, -0.00999999999999836, 2.0000000000000013, -26.19999999999972, -32.170000000000364, -20.109999999999708, 2.0000000000000013, -5.230000000000038, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -12.340000000000035, -26.14, 2.0000000000000013, -126.6399999999994, -6.040000000000007, -28.14999999999971, -6.040000000000042, 0.9500000000000014, 2.0000000000000013, -14.08000000000002, -62.32000000000025, -4.030000000000042, -19.359999999999744, -6.040000000000042, -70.38999999999955, -34.18000000000036, 2.0000000000000013, -26.13999999999971, -16.0899999999997, -74.37999999999919, 26.750000000000274, -4.030000000000042, 2.0000000000000013, -43.270000000000344, -0.00999999999999836, -16.0899999999997, -4.030000000000042, -12.070000000000041, 16.85000000000011, 5.959999999999959, -6.040000000000042, -18.099999999999707, -12.070000000000041, -27.21999999999972, 2.0000000000000013, -6.040000000000042, -24.27999999999973, 2.0000000000000013, -4.030000000000042, -22.11999999999976, 2.0000000000000013, 2.0000000000000013, -21.309999999999736, -28.14999999999971, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -31.42000000000003, -6.040000000000042, 2.0000000000000013, -20.109999999999943, -22.119999999999944, 2.0000000000000013, -16.089999999999712, -120.60999999999964, -22.119999999999706, 2.0000000000000013, -4.030000000000042, 9.85999999999996, -108.54999999999954, -16.089999999999723, -2.020000000000042, -57.34000000000033, -23.439999999999756, 11.89999999999996, 2.0000000000000013, -2.020000000000042, -12.460000000000027, -18.099999999999703, 64.36999999999999, -42.220000000000354, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -2.020000000000042, 2.0000000000000013, -48.400000000000226, -14.080000000000041, -86.55999999999926, 2.0000000000000013, -4.030000000000041, -122.6199999999994, 2.0000000000000013, 2.0000000000000013, -11.230000000000036, -8.050000000000042, -36.19000000000011, 2.0000000000000013, -6.040000000000042, -90.45999999999923, 2.0000000000000013, 15.85999999999996, -58.39000000000032, -20.109999999999992, -21.51999999999977, -18.099999999999703, 2.0000000000000013, -20.109999999999705, 8.929999999999959, 2.0000000000000013, -20.109999999999705, -10.060000000000041, -128.65000000000094, -102.5799999999993, -4.060000000000041, -34.18000000000036, -112.5699999999996, 2.0000000000000013, -15.099999999999865, -18.099999999999707, -2.020000000000041, 2.0000000000000013, -6.040000000000042, -10.060000000000041, -42.25000000000034, -18.099999999999703, 2.0000000000000013, -4.030000000000042, -128.83000000000106, -86.7699999999994, 27.740000000000272, -2.0200000000000413, 3.979999999999958, -56.28999999999985, -20.109999999999705, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -47.35000000000028, -48.25000000000035, 13.399999999999975, 2.0000000000000013, -30.159999999999712, -52.27000000000034, -6.040000000000042, -0.00999999999999836, -50.26000000000032, 2.0000000000000013, -130.66000000000122], "policy_predator_policy_reward": [188.0, 20.0, 8.0, 13.0, 7.0, 144.0, 15.0, 14.0, 15.0, 16.0, 56.0, 49.0, 2.0, 8.0, 3.0, 6.0, 12.0, 28.0, 5.0, 6.0, 2.0, 13.0, 0.0, 25.0, 14.0, 96.0, 13.0, 3.0, 11.0, 15.0, 20.0, 15.0, 8.0, 1.0, 17.0, 19.0, 6.0, 15.0, 15.0, 15.0, 0.0, 4.0, 4.0, 0.0, 14.0, 22.0, 4.0, 0.0, 1.0, 32.0, 12.0, 8.0, 25.0, 19.0, 22.0, 20.0, 13.0, 14.0, 13.0, 4.0, 20.0, 13.0, 40.0, 7.0, 103.0, 70.0, 19.0, 11.0, 6.0, 0.0, 96.0, 25.0, 35.0, 33.0, 145.0, 150.0, 20.0, 15.0, 11.0, 19.0, 43.0, 40.0, 7.0, 7.0, 9.0, 31.0, 11.0, 2.0, 13.0, 1.0, 6.0, 7.0, 20.0, 12.0, 6.0, 47.0, 30.0, 8.0, 7.0, 7.0, 51.0, 1.0, 30.0, 8.0, 8.0, 16.0, 5.0, 0.0, 28.0, 59.0, 0.0, 67.0, 54.0, 48.0, 7.0, 78.0, 15.0, 10.0, 7.0, 24.0, 127.0, 1.0, 37.0, 38.0, 39.0, 25.0, 6.0, 2.0, 20.0, 44.0, 33.0, 29.0, 36.0, 4.0, 12.0, 17.0, 45.0, 24.0, 58.0, 34.0, 17.0, 5.0, 5.0, 81.0, 0.0, 27.0, 79.0, 8.0, 7.0, 6.0, 67.0, 3.0, 14.0, 36.0, 32.0, 53.0, 1.0, 17.0, 13.0, 6.0, 14.0, 19.0, 5.0, 110.0, 55.0, 60.0, 173.0, 31.0, 11.0, 3.0, 11.0, 14.0, 17.0, 6.0, 20.0, 37.0, 12.0, 8.0, 89.0, 86.0, 45.0, 86.0, 15.0, 2.0, 74.0, 74.0, 1.0, 11.0, 46.0, 34.0, 69.0, 33.0, 3.0, 23.0, 34.0, 5.0, 50.0, 10.0, 71.0, 69.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7335717154037663, "mean_inference_ms": 1.9170631759032366, "mean_action_processing_ms": 0.31201022938138007, "mean_env_wait_ms": 0.25093701969082777, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004055976867675781, "StateBufferConnector_ms": 0.005082130432128906, "ViewRequirementAgentConnector_ms": 0.11626267433166504}, "num_episodes": 23, "episode_return_max": 218.56999999999863, "episode_return_min": -51.70000000000022, "episode_return_mean": 17.90050000000002, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 346.99043806187706, "num_env_steps_trained_throughput_per_sec": 346.99043806187706, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 11295.986, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11295.923, "sample_time_ms": 1336.078, "learn_time_ms": 9942.641, "learn_throughput": 402.308, "synch_weights_time_ms": 14.608}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "0e60f_00000", "date": "2024-08-15_01-04-37", "timestamp": 1723664077, "time_this_iter_s": 11.574544191360474, "time_total_s": 495.6514468193054, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb8670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 495.6514468193054, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 57.076470588235296, "ram_util_percent": 83.11176470588235}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5266934931908966, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1818616330071732, "policy_loss": -0.004509524084016602, "vf_loss": 1.1859275370205522, "vf_explained_var": -0.06823772945732036, "kl": 0.008872441670301202, "entropy": 1.2507701536335012, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8151185898553757, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5522591035202065, "policy_loss": -0.004525786283963099, "vf_loss": 2.5563214987043352, "vf_explained_var": 0.02742418918029341, "kl": 0.0061784273632994845, "entropy": 1.0662843117638239, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 218.56999999999863, "episode_reward_min": -51.70000000000022, "episode_reward_mean": 18.75720000000004, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -198.04000000000082, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.36999999999999, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -19.02639999999998, "predator_policy": 28.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.80999999999928, -12.230000000000064, 5.989999999999917, 14.929999999999916, 5.799999999999923, 1.970000000000002, -13.24999999999957, 25.620000000000516, 19.800000000000537, -10.280000000000065, 23.770000000000557, 4.919999999999936, 22.66000000000052, 22.86000000000002, 40.32000000000006, -4.190000000000081, 8.949999999999916, 44.59999999999977, 44.60999999999938, 218.56999999999863, 2.819999999999984, -12.230000000000054, 35.36999999999943, 11.969999999999917, -3.2800000000000793, -7.120000000000083, 18.780000000000413, 12.919999999999916, 1.8299999999999996, 27.780000000000474, 7.679999999999927, 11.969999999999917, 31.880000000000514, 18.6900000000004, -2.150000000000082, 2.96999999999998, 49.53999999999942, 48.889999999999795, 81.88000000000025, -51.70000000000022, 4.8799999999999395, 36.82999999999934, 3.3600000000000296, 15.639999999999922, 52.45999999999937, 7.979999999999917, 33.43999999999999, 84.15000000000146, 37.96999999999947, 18.930000000000437, 22.600000000000463, -8.640000000000072, 19.97000000000056, -34.62000000000048, 17.770000000000255, 42.759999999999735, 8.959999999999917, -18.45999999999957, 7.469999999999928, 43.36999999999959, 1.8999999999999972, 7.819999999999919, 14.88999999999992, -23.709999999999653, 8.359999999999932, 57.24999999999989, 0.8999999999999818, 4.879999999999938, 18.96000000000029, 4.689999999999935, 3.89999999999996, 42.13999999999956, 71.97000000000017, 18.96000000000044, 71.60000000000028, -2.0900000000000833, 34.64999999999954, 67.15000000000123, -2.16000000000008, -19.30999999999945, 9.729999999999928, 11.339999999999943, 1.950000000000002, 19.680000000000533, -17.23999999999943, 17.640000000000214, -10.420000000000044, 70.05000000000024, -9.260000000000062, 114.29000000000123, -18.269999999999417, 37.86000000000003, 7.809999999999924, -17.059999999999803, 31.970000000000443, 45.84999999999954, -8.33000000000003, -0.11000000000004098, 8.999999999999917, 7.949999999999919], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [4.96999999999996, 11.83999999999996, -22.119999999999706, -20.109999999999705, -0.00999999999999836, 2.0000000000000013, 8.929999999999959, 2.0000000000000013, 2.0000000000000013, -32.20000000000036, -0.00999999999999836, -2.020000000000042, -40.21000000000032, -6.040000000000042, 5.629999999999965, -0.00999999999999836, 2.0000000000000013, -26.19999999999972, -32.170000000000364, -20.109999999999708, 2.0000000000000013, -5.230000000000038, -12.070000000000041, -0.00999999999999836, 2.0000000000000013, -12.340000000000035, -26.14, 2.0000000000000013, -126.6399999999994, -6.040000000000007, -28.14999999999971, -6.040000000000042, 0.9500000000000014, 2.0000000000000013, -14.08000000000002, -62.32000000000025, -4.030000000000042, -19.359999999999744, -6.040000000000042, -70.38999999999955, -34.18000000000036, 2.0000000000000013, -26.13999999999971, -16.0899999999997, -74.37999999999919, 26.750000000000274, -4.030000000000042, 2.0000000000000013, -43.270000000000344, -0.00999999999999836, -16.0899999999997, -4.030000000000042, -12.070000000000041, 16.85000000000011, 5.959999999999959, -6.040000000000042, -18.099999999999707, -12.070000000000041, -27.21999999999972, 2.0000000000000013, -6.040000000000042, -24.27999999999973, 2.0000000000000013, -4.030000000000042, -22.11999999999976, 2.0000000000000013, 2.0000000000000013, -21.309999999999736, -28.14999999999971, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -31.42000000000003, -6.040000000000042, 2.0000000000000013, -20.109999999999943, -22.119999999999944, 2.0000000000000013, -16.089999999999712, -120.60999999999964, -22.119999999999706, 2.0000000000000013, -4.030000000000042, 9.85999999999996, -108.54999999999954, -16.089999999999723, -2.020000000000042, -57.34000000000033, -23.439999999999756, 11.89999999999996, 2.0000000000000013, -2.020000000000042, -12.460000000000027, -18.099999999999703, 64.36999999999999, -42.220000000000354, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -2.020000000000042, 2.0000000000000013, -48.400000000000226, -14.080000000000041, -86.55999999999926, 2.0000000000000013, -4.030000000000041, -122.6199999999994, 2.0000000000000013, 2.0000000000000013, -11.230000000000036, -8.050000000000042, -36.19000000000011, 2.0000000000000013, -6.040000000000042, -90.45999999999923, 2.0000000000000013, 15.85999999999996, -58.39000000000032, -20.109999999999992, -21.51999999999977, -18.099999999999703, 2.0000000000000013, -20.109999999999705, 8.929999999999959, 2.0000000000000013, -20.109999999999705, -10.060000000000041, -128.65000000000094, -102.5799999999993, -4.060000000000041, -34.18000000000036, -112.5699999999996, 2.0000000000000013, -15.099999999999865, -18.099999999999707, -2.020000000000041, 2.0000000000000013, -6.040000000000042, -10.060000000000041, -42.25000000000034, -18.099999999999703, 2.0000000000000013, -4.030000000000042, -128.83000000000106, -86.7699999999994, 27.740000000000272, -2.0200000000000413, 3.979999999999958, -56.28999999999985, -20.109999999999705, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -47.35000000000028, -48.25000000000035, 13.399999999999975, 2.0000000000000013, -30.159999999999712, -52.27000000000034, -6.040000000000042, -0.00999999999999836, -50.26000000000032, 2.0000000000000013, -130.66000000000122, 2.0000000000000013, -8.050000000000042, 11.89999999999996, -42.220000000000354, -40.210000000000356, -4.030000000000042, 2.0000000000000013, -52.360000000000326, -32.170000000000364, -48.25000000000035, -29.169999999999714, -82.77999999999983, -24.129999999999708, -24.129999999999708, -38.71000000000026, 2.0000000000000013, -26.13999999999971, -24.129999999999708, 9.91999999999996, -10.060000000000041, 2.0000000000000013, -36.19000000000036, -2.020000000000042, -198.04000000000082, -4.030000000000036, 2.0000000000000013, -14.080000000000041, -12.070000000000041, -34.18000000000036, -28.14999999999971, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042], "policy_predator_policy_reward": [6.0, 15.0, 15.0, 15.0, 0.0, 4.0, 4.0, 0.0, 14.0, 22.0, 4.0, 0.0, 1.0, 32.0, 12.0, 8.0, 25.0, 19.0, 22.0, 20.0, 13.0, 14.0, 13.0, 4.0, 20.0, 13.0, 40.0, 7.0, 103.0, 70.0, 19.0, 11.0, 6.0, 0.0, 96.0, 25.0, 35.0, 33.0, 145.0, 150.0, 20.0, 15.0, 11.0, 19.0, 43.0, 40.0, 7.0, 7.0, 9.0, 31.0, 11.0, 2.0, 13.0, 1.0, 6.0, 7.0, 20.0, 12.0, 6.0, 47.0, 30.0, 8.0, 7.0, 7.0, 51.0, 1.0, 30.0, 8.0, 8.0, 16.0, 5.0, 0.0, 28.0, 59.0, 0.0, 67.0, 54.0, 48.0, 7.0, 78.0, 15.0, 10.0, 7.0, 24.0, 127.0, 1.0, 37.0, 38.0, 39.0, 25.0, 6.0, 2.0, 20.0, 44.0, 33.0, 29.0, 36.0, 4.0, 12.0, 17.0, 45.0, 24.0, 58.0, 34.0, 17.0, 5.0, 5.0, 81.0, 0.0, 27.0, 79.0, 8.0, 7.0, 6.0, 67.0, 3.0, 14.0, 36.0, 32.0, 53.0, 1.0, 17.0, 13.0, 6.0, 14.0, 19.0, 5.0, 110.0, 55.0, 60.0, 173.0, 31.0, 11.0, 3.0, 11.0, 14.0, 17.0, 6.0, 20.0, 37.0, 12.0, 8.0, 89.0, 86.0, 45.0, 86.0, 15.0, 2.0, 74.0, 74.0, 1.0, 11.0, 46.0, 34.0, 69.0, 33.0, 3.0, 23.0, 34.0, 5.0, 50.0, 10.0, 71.0, 69.0, 7.0, 1.0, 22.0, 28.0, 4.0, 23.0, 28.0, 40.0, 32.0, 38.0, 138.0, 44.0, 20.0, 19.0, 38.0, 113.0, 15.0, 17.0, 8.0, 30.0, 20.0, 22.0, 119.0, 64.0, 8.0, 26.0, 61.0, 11.0, 25.0, 29.0, 5.0, 13.0, 0.0, 5.0, 0.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7316105335367874, "mean_inference_ms": 1.9123812094300647, "mean_action_processing_ms": 0.31043841676804146, "mean_env_wait_ms": 0.24950044430295976, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004392385482788086, "StateBufferConnector_ms": 0.00522923469543457, "ViewRequirementAgentConnector_ms": 0.123726487159729}, "num_episodes": 18, "episode_return_max": 218.56999999999863, "episode_return_min": -51.70000000000022, "episode_return_mean": 18.75720000000004, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.9184045157863, "num_env_steps_trained_throughput_per_sec": 353.9184045157863, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 11290.292, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11290.228, "sample_time_ms": 1328.373, "learn_time_ms": 9945.051, "learn_throughput": 402.21, "synch_weights_time_ms": 14.159}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "0e60f_00000", "date": "2024-08-15_01-04-48", "timestamp": 1723664088, "time_this_iter_s": 11.352382898330688, "time_total_s": 507.0038297176361, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a30a23a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 507.0038297176361, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 55.2625, "ram_util_percent": 82.7875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9917251434275713, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.309827721008548, "policy_loss": -0.01060261197028455, "vf_loss": 1.3199048603337908, "vf_explained_var": -0.07582925425635444, "kl": 0.010509412924393393, "entropy": 1.1618579676542333, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5845901126110995, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9597817624687517, "policy_loss": -0.005180641964925502, "vf_loss": 1.964322549640817, "vf_explained_var": 0.013501272157386498, "kl": 0.008531428298788222, "entropy": 1.0201945166739206, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 218.56999999999863, "episode_reward_min": -51.70000000000022, "episode_reward_mean": 24.308199999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -198.04000000000082, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.45999999999987, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -18.28089999999999, "predator_policy": 30.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [44.60999999999938, 218.56999999999863, 2.819999999999984, -12.230000000000054, 35.36999999999943, 11.969999999999917, -3.2800000000000793, -7.120000000000083, 18.780000000000413, 12.919999999999916, 1.8299999999999996, 27.780000000000474, 7.679999999999927, 11.969999999999917, 31.880000000000514, 18.6900000000004, -2.150000000000082, 2.96999999999998, 49.53999999999942, 48.889999999999795, 81.88000000000025, -51.70000000000022, 4.8799999999999395, 36.82999999999934, 3.3600000000000296, 15.639999999999922, 52.45999999999937, 7.979999999999917, 33.43999999999999, 84.15000000000146, 37.96999999999947, 18.930000000000437, 22.600000000000463, -8.640000000000072, 19.97000000000056, -34.62000000000048, 17.770000000000255, 42.759999999999735, 8.959999999999917, -18.45999999999957, 7.469999999999928, 43.36999999999959, 1.8999999999999972, 7.819999999999919, 14.88999999999992, -23.709999999999653, 8.359999999999932, 57.24999999999989, 0.8999999999999818, 4.879999999999938, 18.96000000000029, 4.689999999999935, 3.89999999999996, 42.13999999999956, 71.97000000000017, 18.96000000000044, 71.60000000000028, -2.0900000000000833, 34.64999999999954, 67.15000000000123, -2.16000000000008, -19.30999999999945, 9.729999999999928, 11.339999999999943, 1.950000000000002, 19.680000000000533, -17.23999999999943, 17.640000000000214, -10.420000000000044, 70.05000000000024, -9.260000000000062, 114.29000000000123, -18.269999999999417, 37.86000000000003, 7.809999999999924, -17.059999999999803, 31.970000000000443, 45.84999999999954, -8.33000000000003, -0.11000000000004098, 8.999999999999917, 7.949999999999919, 49.529999999999546, 113.43000000000063, -0.18000000000003924, 5.829999999999922, 51.19999999999947, 42.639999999999354, 7.879999999999918, -7.190000000000081, 14.909999999999918, 34.77999999999953, 44.76999999999937, 14.630000000000033, 53.41999999999942, 82.10000000000058, 159.4199999999997, 68.31000000000046, 53.66999999999933, 5.999999999999916], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-4.030000000000042, -19.359999999999744, -6.040000000000042, -70.38999999999955, -34.18000000000036, 2.0000000000000013, -26.13999999999971, -16.0899999999997, -74.37999999999919, 26.750000000000274, -4.030000000000042, 2.0000000000000013, -43.270000000000344, -0.00999999999999836, -16.0899999999997, -4.030000000000042, -12.070000000000041, 16.85000000000011, 5.959999999999959, -6.040000000000042, -18.099999999999707, -12.070000000000041, -27.21999999999972, 2.0000000000000013, -6.040000000000042, -24.27999999999973, 2.0000000000000013, -4.030000000000042, -22.11999999999976, 2.0000000000000013, 2.0000000000000013, -21.309999999999736, -28.14999999999971, 2.0000000000000013, -4.030000000000042, 2.0000000000000013, -31.42000000000003, -6.040000000000042, 2.0000000000000013, -20.109999999999943, -22.119999999999944, 2.0000000000000013, -16.089999999999712, -120.60999999999964, -22.119999999999706, 2.0000000000000013, -4.030000000000042, 9.85999999999996, -108.54999999999954, -16.089999999999723, -2.020000000000042, -57.34000000000033, -23.439999999999756, 11.89999999999996, 2.0000000000000013, -2.020000000000042, -12.460000000000027, -18.099999999999703, 64.36999999999999, -42.220000000000354, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -2.020000000000042, 2.0000000000000013, -48.400000000000226, -14.080000000000041, -86.55999999999926, 2.0000000000000013, -4.030000000000041, -122.6199999999994, 2.0000000000000013, 2.0000000000000013, -11.230000000000036, -8.050000000000042, -36.19000000000011, 2.0000000000000013, -6.040000000000042, -90.45999999999923, 2.0000000000000013, 15.85999999999996, -58.39000000000032, -20.109999999999992, -21.51999999999977, -18.099999999999703, 2.0000000000000013, -20.109999999999705, 8.929999999999959, 2.0000000000000013, -20.109999999999705, -10.060000000000041, -128.65000000000094, -102.5799999999993, -4.060000000000041, -34.18000000000036, -112.5699999999996, 2.0000000000000013, -15.099999999999865, -18.099999999999707, -2.020000000000041, 2.0000000000000013, -6.040000000000042, -10.060000000000041, -42.25000000000034, -18.099999999999703, 2.0000000000000013, -4.030000000000042, -128.83000000000106, -86.7699999999994, 27.740000000000272, -2.0200000000000413, 3.979999999999958, -56.28999999999985, -20.109999999999705, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -47.35000000000028, -48.25000000000035, 13.399999999999975, 2.0000000000000013, -30.159999999999712, -52.27000000000034, -6.040000000000042, -0.00999999999999836, -50.26000000000032, 2.0000000000000013, -130.66000000000122, 2.0000000000000013, -8.050000000000042, 11.89999999999996, -42.220000000000354, -40.210000000000356, -4.030000000000042, 2.0000000000000013, -52.360000000000326, -32.170000000000364, -48.25000000000035, -29.169999999999714, -82.77999999999983, -24.129999999999708, -24.129999999999708, -38.71000000000026, 2.0000000000000013, -26.13999999999971, -24.129999999999708, 9.91999999999996, -10.060000000000041, 2.0000000000000013, -36.19000000000036, -2.020000000000042, -198.04000000000082, -4.030000000000036, 2.0000000000000013, -14.080000000000041, -12.070000000000041, -34.18000000000036, -28.14999999999971, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -17.469999999999857, -34.18000000000036, 88.61000000000017, 2.0000000000000013, -34.18000000000036, -4.030000000000041, -26.13999999999971, -24.7299999999998, -12.070000000000041, -6.040000000000042, 9.679999999999964, -20.109999999999705, -0.00999999999999836, -12.070000000000041, -22.11999999999971, -4.03000000000004, -10.060000000000041, -42.22000000000031, 2.0000000000000013, -28.14999999999971, -14.080000000000041, -38.20000000000036, -32.170000000000215, 2.0000000000000013, -24.579999999999778, -40.90000000000004, 2.0000000000000013, 145.45999999999987, -6.040000000000042, 2.0000000000000013, -136.6900000000005, 25.67000000000026, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013], "policy_predator_policy_reward": [35.0, 33.0, 145.0, 150.0, 20.0, 15.0, 11.0, 19.0, 43.0, 40.0, 7.0, 7.0, 9.0, 31.0, 11.0, 2.0, 13.0, 1.0, 6.0, 7.0, 20.0, 12.0, 6.0, 47.0, 30.0, 8.0, 7.0, 7.0, 51.0, 1.0, 30.0, 8.0, 8.0, 16.0, 5.0, 0.0, 28.0, 59.0, 0.0, 67.0, 54.0, 48.0, 7.0, 78.0, 15.0, 10.0, 7.0, 24.0, 127.0, 1.0, 37.0, 38.0, 39.0, 25.0, 6.0, 2.0, 20.0, 44.0, 33.0, 29.0, 36.0, 4.0, 12.0, 17.0, 45.0, 24.0, 58.0, 34.0, 17.0, 5.0, 5.0, 81.0, 0.0, 27.0, 79.0, 8.0, 7.0, 6.0, 67.0, 3.0, 14.0, 36.0, 32.0, 53.0, 1.0, 17.0, 13.0, 6.0, 14.0, 19.0, 5.0, 110.0, 55.0, 60.0, 173.0, 31.0, 11.0, 3.0, 11.0, 14.0, 17.0, 6.0, 20.0, 37.0, 12.0, 8.0, 89.0, 86.0, 45.0, 86.0, 15.0, 2.0, 74.0, 74.0, 1.0, 11.0, 46.0, 34.0, 69.0, 33.0, 3.0, 23.0, 34.0, 5.0, 50.0, 10.0, 71.0, 69.0, 7.0, 1.0, 22.0, 28.0, 4.0, 23.0, 28.0, 40.0, 32.0, 38.0, 138.0, 44.0, 20.0, 19.0, 38.0, 113.0, 15.0, 17.0, 8.0, 30.0, 20.0, 22.0, 119.0, 64.0, 8.0, 26.0, 61.0, 11.0, 25.0, 29.0, 5.0, 13.0, 0.0, 5.0, 0.0, 14.0, 31.0, 34.0, 10.0, 49.0, 22.0, 10.0, 8.0, 28.0, 58.0, 30.0, 12.0, 27.0, 13.0, 15.0, 12.0, 15.0, 17.0, 12.0, 39.0, 36.0, 46.0, 41.0, 46.0, 39.0, 47.0, 29.0, 34.0, 87.0, 10.0, 10.0, 146.0, 57.0, 21.0, 5.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7297415745677788, "mean_inference_ms": 1.9078774307447677, "mean_action_processing_ms": 0.3093969798665339, "mean_env_wait_ms": 0.24882934267658477, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004273533821105957, "StateBufferConnector_ms": 0.0035272836685180664, "ViewRequirementAgentConnector_ms": 0.12257242202758789}, "num_episodes": 18, "episode_return_max": 218.56999999999863, "episode_return_min": -51.70000000000022, "episode_return_mean": 24.308199999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.3252133767759, "num_env_steps_trained_throughput_per_sec": 350.3252133767759, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 11283.513, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11283.449, "sample_time_ms": 1323.33, "learn_time_ms": 9943.387, "learn_throughput": 402.277, "synch_weights_time_ms": 14.047}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "0e60f_00000", "date": "2024-08-15_01-04-59", "timestamp": 1723664099, "time_this_iter_s": 11.476696729660034, "time_total_s": 518.4805264472961, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a30a2dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 518.4805264472961, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 56.8875, "ram_util_percent": 82.85624999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1839768467441438, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8316926532321507, "policy_loss": -0.006192712993336418, "vf_loss": 1.8373516126915261, "vf_explained_var": 0.09384397958952283, "kl": 0.010675113832225904, "entropy": 1.0372688800884933, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9578239069729255, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4058772927554195, "policy_loss": -0.005941881789584403, "vf_loss": 1.4111308890360372, "vf_explained_var": 0.03714436459793616, "kl": 0.009177142693214778, "entropy": 1.0305786712459786, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 212.33999999999864, "episode_reward_min": -51.70000000000022, "episode_reward_mean": 28.452999999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -198.04000000000082, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.45999999999987, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -14.918499999999996, "predator_policy": 29.145}, "custom_metrics": {}, "hist_stats": {"episode_reward": [49.53999999999942, 48.889999999999795, 81.88000000000025, -51.70000000000022, 4.8799999999999395, 36.82999999999934, 3.3600000000000296, 15.639999999999922, 52.45999999999937, 7.979999999999917, 33.43999999999999, 84.15000000000146, 37.96999999999947, 18.930000000000437, 22.600000000000463, -8.640000000000072, 19.97000000000056, -34.62000000000048, 17.770000000000255, 42.759999999999735, 8.959999999999917, -18.45999999999957, 7.469999999999928, 43.36999999999959, 1.8999999999999972, 7.819999999999919, 14.88999999999992, -23.709999999999653, 8.359999999999932, 57.24999999999989, 0.8999999999999818, 4.879999999999938, 18.96000000000029, 4.689999999999935, 3.89999999999996, 42.13999999999956, 71.97000000000017, 18.96000000000044, 71.60000000000028, -2.0900000000000833, 34.64999999999954, 67.15000000000123, -2.16000000000008, -19.30999999999945, 9.729999999999928, 11.339999999999943, 1.950000000000002, 19.680000000000533, -17.23999999999943, 17.640000000000214, -10.420000000000044, 70.05000000000024, -9.260000000000062, 114.29000000000123, -18.269999999999417, 37.86000000000003, 7.809999999999924, -17.059999999999803, 31.970000000000443, 45.84999999999954, -8.33000000000003, -0.11000000000004098, 8.999999999999917, 7.949999999999919, 49.529999999999546, 113.43000000000063, -0.18000000000003924, 5.829999999999922, 51.19999999999947, 42.639999999999354, 7.879999999999918, -7.190000000000081, 14.909999999999918, 34.77999999999953, 44.76999999999937, 14.630000000000033, 53.41999999999942, 82.10000000000058, 159.4199999999997, 68.31000000000046, 53.66999999999933, 5.999999999999916, 14.999999999999915, 212.33999999999864, 10.88999999999992, 36.849999999999454, 0.9099999999999818, 88.03000000000019, 3.540000000000197, 31.880000000000027, 44.98999999999933, 10.869999999999918, 2.9799999999999813, 4.989999999999937, 12.94999999999992, 110.90000000000038, 41.499999999999346, 168.3200000000002, 39.91999999999932, 0.6800000000000342], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-31.42000000000003, -6.040000000000042, 2.0000000000000013, -20.109999999999943, -22.119999999999944, 2.0000000000000013, -16.089999999999712, -120.60999999999964, -22.119999999999706, 2.0000000000000013, -4.030000000000042, 9.85999999999996, -108.54999999999954, -16.089999999999723, -2.020000000000042, -57.34000000000033, -23.439999999999756, 11.89999999999996, 2.0000000000000013, -2.020000000000042, -12.460000000000027, -18.099999999999703, 64.36999999999999, -42.220000000000354, -4.030000000000042, 2.0000000000000013, -8.050000000000042, -2.020000000000042, 2.0000000000000013, -48.400000000000226, -14.080000000000041, -86.55999999999926, 2.0000000000000013, -4.030000000000041, -122.6199999999994, 2.0000000000000013, 2.0000000000000013, -11.230000000000036, -8.050000000000042, -36.19000000000011, 2.0000000000000013, -6.040000000000042, -90.45999999999923, 2.0000000000000013, 15.85999999999996, -58.39000000000032, -20.109999999999992, -21.51999999999977, -18.099999999999703, 2.0000000000000013, -20.109999999999705, 8.929999999999959, 2.0000000000000013, -20.109999999999705, -10.060000000000041, -128.65000000000094, -102.5799999999993, -4.060000000000041, -34.18000000000036, -112.5699999999996, 2.0000000000000013, -15.099999999999865, -18.099999999999707, -2.020000000000041, 2.0000000000000013, -6.040000000000042, -10.060000000000041, -42.25000000000034, -18.099999999999703, 2.0000000000000013, -4.030000000000042, -128.83000000000106, -86.7699999999994, 27.740000000000272, -2.0200000000000413, 3.979999999999958, -56.28999999999985, -20.109999999999705, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -47.35000000000028, -48.25000000000035, 13.399999999999975, 2.0000000000000013, -30.159999999999712, -52.27000000000034, -6.040000000000042, -0.00999999999999836, -50.26000000000032, 2.0000000000000013, -130.66000000000122, 2.0000000000000013, -8.050000000000042, 11.89999999999996, -42.220000000000354, -40.210000000000356, -4.030000000000042, 2.0000000000000013, -52.360000000000326, -32.170000000000364, -48.25000000000035, -29.169999999999714, -82.77999999999983, -24.129999999999708, -24.129999999999708, -38.71000000000026, 2.0000000000000013, -26.13999999999971, -24.129999999999708, 9.91999999999996, -10.060000000000041, 2.0000000000000013, -36.19000000000036, -2.020000000000042, -198.04000000000082, -4.030000000000036, 2.0000000000000013, -14.080000000000041, -12.070000000000041, -34.18000000000036, -28.14999999999971, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -17.469999999999857, -34.18000000000036, 88.61000000000017, 2.0000000000000013, -34.18000000000036, -4.030000000000041, -26.13999999999971, -24.7299999999998, -12.070000000000041, -6.040000000000042, 9.679999999999964, -20.109999999999705, -0.00999999999999836, -12.070000000000041, -22.11999999999971, -4.03000000000004, -10.060000000000041, -42.22000000000031, 2.0000000000000013, -28.14999999999971, -14.080000000000041, -38.20000000000036, -32.170000000000215, 2.0000000000000013, -24.579999999999778, -40.90000000000004, 2.0000000000000013, 145.45999999999987, -6.040000000000042, 2.0000000000000013, -136.6900000000005, 25.67000000000026, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 61.40000000000012, 103.94000000000045, -11.11000000000004, 2.0000000000000013, 2.0000000000000013, -28.14999999999972, -16.0899999999997, 2.0000000000000013, 28.580000000000247, 35.4499999999999, -30.159999999999712, -58.30000000000034, 2.0000000000000013, 13.879999999999995, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -24.12999999999972, 2.0000000000000013, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000038, 85.94000000000025, -8.050000000000042, -19.44999999999977, 141.31999999999994, 2.0000000000000013, 9.919999999999959, 2.0000000000000013, -6.040000000000042, -54.28000000000034], "policy_predator_policy_reward": [28.0, 59.0, 0.0, 67.0, 54.0, 48.0, 7.0, 78.0, 15.0, 10.0, 7.0, 24.0, 127.0, 1.0, 37.0, 38.0, 39.0, 25.0, 6.0, 2.0, 20.0, 44.0, 33.0, 29.0, 36.0, 4.0, 12.0, 17.0, 45.0, 24.0, 58.0, 34.0, 17.0, 5.0, 5.0, 81.0, 0.0, 27.0, 79.0, 8.0, 7.0, 6.0, 67.0, 3.0, 14.0, 36.0, 32.0, 53.0, 1.0, 17.0, 13.0, 6.0, 14.0, 19.0, 5.0, 110.0, 55.0, 60.0, 173.0, 31.0, 11.0, 3.0, 11.0, 14.0, 17.0, 6.0, 20.0, 37.0, 12.0, 8.0, 89.0, 86.0, 45.0, 86.0, 15.0, 2.0, 74.0, 74.0, 1.0, 11.0, 46.0, 34.0, 69.0, 33.0, 3.0, 23.0, 34.0, 5.0, 50.0, 10.0, 71.0, 69.0, 7.0, 1.0, 22.0, 28.0, 4.0, 23.0, 28.0, 40.0, 32.0, 38.0, 138.0, 44.0, 20.0, 19.0, 38.0, 113.0, 15.0, 17.0, 8.0, 30.0, 20.0, 22.0, 119.0, 64.0, 8.0, 26.0, 61.0, 11.0, 25.0, 29.0, 5.0, 13.0, 0.0, 5.0, 0.0, 14.0, 31.0, 34.0, 10.0, 49.0, 22.0, 10.0, 8.0, 28.0, 58.0, 30.0, 12.0, 27.0, 13.0, 15.0, 12.0, 15.0, 17.0, 12.0, 39.0, 36.0, 46.0, 41.0, 46.0, 39.0, 47.0, 29.0, 34.0, 87.0, 10.0, 10.0, 146.0, 57.0, 21.0, 5.0, 1.0, 1.0, 8.0, 3.0, 22.0, 25.0, 6.0, 14.0, 10.0, 53.0, 11.0, 4.0, 12.0, 12.0, 55.0, 37.0, 7.0, 9.0, 14.0, 29.0, 10.0, 23.0, 0.0, 3.0, 3.0, 0.0, 16.0, 3.0, 21.0, 10.0, 39.0, 30.0, 16.0, 9.0, 20.0, 8.0, 51.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7278196858750619, "mean_inference_ms": 1.9033929366887967, "mean_action_processing_ms": 0.30840986227491657, "mean_env_wait_ms": 0.248203284466174, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0042629241943359375, "StateBufferConnector_ms": 0.0036340951919555664, "ViewRequirementAgentConnector_ms": 0.12096631526947021}, "num_episodes": 18, "episode_return_max": 212.33999999999864, "episode_return_min": -51.70000000000022, "episode_return_mean": 28.452999999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 355.89816449958437, "num_env_steps_trained_throughput_per_sec": 355.89816449958437, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 11304.762, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11304.698, "sample_time_ms": 1327.658, "learn_time_ms": 9960.234, "learn_throughput": 401.597, "synch_weights_time_ms": 14.28}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "0e60f_00000", "date": "2024-08-15_01-05-11", "timestamp": 1723664111, "time_this_iter_s": 11.276594161987305, "time_total_s": 529.7571206092834, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb8700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 529.7571206092834, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 56.025000000000006, "ram_util_percent": 83.28125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4002629218751161, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7574195789281652, "policy_loss": -0.008088723763271615, "vf_loss": 1.7650452083065395, "vf_explained_var": 0.030954766368109083, "kl": 0.00926195075662606, "entropy": 1.023091185092926, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.887739130681154, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3181629456224895, "policy_loss": -0.0050288316029956735, "vf_loss": 1.3226141103991755, "vf_explained_var": 0.02654908778806212, "kl": 0.007702213561627961, "entropy": 1.0174435753355582, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 212.33999999999864, "episode_reward_min": -43.54000000000062, "episode_reward_mean": 28.77499999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -198.04000000000082, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.45999999999987, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -12.767500000000002, "predator_policy": 27.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.469999999999928, 43.36999999999959, 1.8999999999999972, 7.819999999999919, 14.88999999999992, -23.709999999999653, 8.359999999999932, 57.24999999999989, 0.8999999999999818, 4.879999999999938, 18.96000000000029, 4.689999999999935, 3.89999999999996, 42.13999999999956, 71.97000000000017, 18.96000000000044, 71.60000000000028, -2.0900000000000833, 34.64999999999954, 67.15000000000123, -2.16000000000008, -19.30999999999945, 9.729999999999928, 11.339999999999943, 1.950000000000002, 19.680000000000533, -17.23999999999943, 17.640000000000214, -10.420000000000044, 70.05000000000024, -9.260000000000062, 114.29000000000123, -18.269999999999417, 37.86000000000003, 7.809999999999924, -17.059999999999803, 31.970000000000443, 45.84999999999954, -8.33000000000003, -0.11000000000004098, 8.999999999999917, 7.949999999999919, 49.529999999999546, 113.43000000000063, -0.18000000000003924, 5.829999999999922, 51.19999999999947, 42.639999999999354, 7.879999999999918, -7.190000000000081, 14.909999999999918, 34.77999999999953, 44.76999999999937, 14.630000000000033, 53.41999999999942, 82.10000000000058, 159.4199999999997, 68.31000000000046, 53.66999999999933, 5.999999999999916, 14.999999999999915, 212.33999999999864, 10.88999999999992, 36.849999999999454, 0.9099999999999818, 88.03000000000019, 3.540000000000197, 31.880000000000027, 44.98999999999933, 10.869999999999918, 2.9799999999999813, 4.989999999999937, 12.94999999999992, 110.90000000000038, 41.499999999999346, 168.3200000000002, 39.91999999999932, 0.6800000000000342, 6.919999999999919, -28.349999999999454, -1.0700000000000622, -16.899999999999753, 4.909999999999935, -3.25000000000008, 11.869999999999921, 15.929999999999936, 12.819999999999922, 4.979999999999937, 8.919999999999918, 77.15000000000013, 27.770000000000557, 103.0200000000001, -8.090000000000083, 49.29999999999935, 150.72999999999985, 87.91000000000074, 10.659999999999924, -43.54000000000062, -26.379999999999463, 61.47999999999934], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.85999999999996, -58.39000000000032, -20.109999999999992, -21.51999999999977, -18.099999999999703, 2.0000000000000013, -20.109999999999705, 8.929999999999959, 2.0000000000000013, -20.109999999999705, -10.060000000000041, -128.65000000000094, -102.5799999999993, -4.060000000000041, -34.18000000000036, -112.5699999999996, 2.0000000000000013, -15.099999999999865, -18.099999999999707, -2.020000000000041, 2.0000000000000013, -6.040000000000042, -10.060000000000041, -42.25000000000034, -18.099999999999703, 2.0000000000000013, -4.030000000000042, -128.83000000000106, -86.7699999999994, 27.740000000000272, -2.0200000000000413, 3.979999999999958, -56.28999999999985, -20.109999999999705, -16.0899999999997, 2.0000000000000013, 2.0000000000000013, -47.35000000000028, -48.25000000000035, 13.399999999999975, 2.0000000000000013, -30.159999999999712, -52.27000000000034, -6.040000000000042, -0.00999999999999836, -50.26000000000032, 2.0000000000000013, -130.66000000000122, 2.0000000000000013, -8.050000000000042, 11.89999999999996, -42.220000000000354, -40.210000000000356, -4.030000000000042, 2.0000000000000013, -52.360000000000326, -32.170000000000364, -48.25000000000035, -29.169999999999714, -82.77999999999983, -24.129999999999708, -24.129999999999708, -38.71000000000026, 2.0000000000000013, -26.13999999999971, -24.129999999999708, 9.91999999999996, -10.060000000000041, 2.0000000000000013, -36.19000000000036, -2.020000000000042, -198.04000000000082, -4.030000000000036, 2.0000000000000013, -14.080000000000041, -12.070000000000041, -34.18000000000036, -28.14999999999971, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -17.469999999999857, -34.18000000000036, 88.61000000000017, 2.0000000000000013, -34.18000000000036, -4.030000000000041, -26.13999999999971, -24.7299999999998, -12.070000000000041, -6.040000000000042, 9.679999999999964, -20.109999999999705, -0.00999999999999836, -12.070000000000041, -22.11999999999971, -4.03000000000004, -10.060000000000041, -42.22000000000031, 2.0000000000000013, -28.14999999999971, -14.080000000000041, -38.20000000000036, -32.170000000000215, 2.0000000000000013, -24.579999999999778, -40.90000000000004, 2.0000000000000013, 145.45999999999987, -6.040000000000042, 2.0000000000000013, -136.6900000000005, 25.67000000000026, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 61.40000000000012, 103.94000000000045, -11.11000000000004, 2.0000000000000013, 2.0000000000000013, -28.14999999999972, -16.0899999999997, 2.0000000000000013, 28.580000000000247, 35.4499999999999, -30.159999999999712, -58.30000000000034, 2.0000000000000013, 13.879999999999995, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -24.12999999999972, 2.0000000000000013, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000038, 85.94000000000025, -8.050000000000042, -19.44999999999977, 141.31999999999994, 2.0000000000000013, 9.919999999999959, 2.0000000000000013, -6.040000000000042, -54.28000000000034, 2.0000000000000013, -14.080000000000041, -2.020000000000042, -64.32999999999915, 2.0000000000000013, -12.070000000000041, -16.0899999999997, -145.81000000000066, -2.020000000000042, -12.070000000000041, -30.249999999999726, 2.0000000000000013, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -6.040000000000042, 77.24000000000005, -16.0899999999997, 2.0000000000000013, -14.230000000000038, 84.01999999999998, 2.0000000000000013, -8.050000000000042, -6.040000000000042, 44.56999999999969, -52.270000000000344, 110.89999999999998, -2.170000000000039, 2.0000000000000013, -43.089999999999996, -8.050000000000042, -56.29000000000034, -94.47999999999924, -10.060000000000041, -74.37999999999917, 2.0000000000000013, 3.499999999999968, -2.0200000000000418], "policy_predator_policy_reward": [14.0, 36.0, 32.0, 53.0, 1.0, 17.0, 13.0, 6.0, 14.0, 19.0, 5.0, 110.0, 55.0, 60.0, 173.0, 31.0, 11.0, 3.0, 11.0, 14.0, 17.0, 6.0, 20.0, 37.0, 12.0, 8.0, 89.0, 86.0, 45.0, 86.0, 15.0, 2.0, 74.0, 74.0, 1.0, 11.0, 46.0, 34.0, 69.0, 33.0, 3.0, 23.0, 34.0, 5.0, 50.0, 10.0, 71.0, 69.0, 7.0, 1.0, 22.0, 28.0, 4.0, 23.0, 28.0, 40.0, 32.0, 38.0, 138.0, 44.0, 20.0, 19.0, 38.0, 113.0, 15.0, 17.0, 8.0, 30.0, 20.0, 22.0, 119.0, 64.0, 8.0, 26.0, 61.0, 11.0, 25.0, 29.0, 5.0, 13.0, 0.0, 5.0, 0.0, 14.0, 31.0, 34.0, 10.0, 49.0, 22.0, 10.0, 8.0, 28.0, 58.0, 30.0, 12.0, 27.0, 13.0, 15.0, 12.0, 15.0, 17.0, 12.0, 39.0, 36.0, 46.0, 41.0, 46.0, 39.0, 47.0, 29.0, 34.0, 87.0, 10.0, 10.0, 146.0, 57.0, 21.0, 5.0, 1.0, 1.0, 8.0, 3.0, 22.0, 25.0, 6.0, 14.0, 10.0, 53.0, 11.0, 4.0, 12.0, 12.0, 55.0, 37.0, 7.0, 9.0, 14.0, 29.0, 10.0, 23.0, 0.0, 3.0, 3.0, 0.0, 16.0, 3.0, 21.0, 10.0, 39.0, 30.0, 16.0, 9.0, 20.0, 8.0, 51.0, 10.0, 10.0, 9.0, 4.0, 34.0, 0.0, 9.0, 16.0, 129.0, 3.0, 16.0, 0.0, 25.0, 18.0, 16.0, 1.0, 25.0, 25.0, 20.0, 1.0, 4.0, 4.0, 17.0, 12.0, 4.0, 18.0, 22.0, 11.0, 6.0, 0.0, 6.0, 28.0, 29.0, 29.0, 13.0, 44.0, 85.0, 29.0, 46.0, 8.0, 53.0, 7.0, 39.0, 19.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7256455000719028, "mean_inference_ms": 1.8985201718641935, "mean_action_processing_ms": 0.3073814586982671, "mean_env_wait_ms": 0.24750341159559264, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004338860511779785, "StateBufferConnector_ms": 0.0037201642990112305, "ViewRequirementAgentConnector_ms": 0.10940039157867432}, "num_episodes": 22, "episode_return_max": 212.33999999999864, "episode_return_min": -43.54000000000062, "episode_return_mean": 28.77499999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.84170883735425, "num_env_steps_trained_throughput_per_sec": 357.84170883735425, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 11267.607, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11267.543, "sample_time_ms": 1333.609, "learn_time_ms": 9916.366, "learn_throughput": 403.374, "synch_weights_time_ms": 14.366}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "0e60f_00000", "date": "2024-08-15_01-05-22", "timestamp": 1723664122, "time_this_iter_s": 11.219299793243408, "time_total_s": 540.9764204025269, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb0ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 540.9764204025269, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 56.125, "ram_util_percent": 83.33125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.093078113911013, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7564284421464122, "policy_loss": -0.0063461631355393264, "vf_loss": 1.7623917411244105, "vf_explained_var": 0.044694252304299166, "kl": 0.0076572969509011305, "entropy": 1.1576810468441594, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6238783701544717, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4975411937665688, "policy_loss": -0.005002865744951778, "vf_loss": 1.502091997704178, "vf_explained_var": 0.05048517379811201, "kl": 0.006027465720371026, "entropy": 1.0044892206709222, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 212.33999999999864, "episode_reward_min": -43.54000000000062, "episode_reward_mean": 32.971899999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -198.04000000000082, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 167.33000000000015, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -7.634049999999999, "predator_policy": 24.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.339999999999943, 1.950000000000002, 19.680000000000533, -17.23999999999943, 17.640000000000214, -10.420000000000044, 70.05000000000024, -9.260000000000062, 114.29000000000123, -18.269999999999417, 37.86000000000003, 7.809999999999924, -17.059999999999803, 31.970000000000443, 45.84999999999954, -8.33000000000003, -0.11000000000004098, 8.999999999999917, 7.949999999999919, 49.529999999999546, 113.43000000000063, -0.18000000000003924, 5.829999999999922, 51.19999999999947, 42.639999999999354, 7.879999999999918, -7.190000000000081, 14.909999999999918, 34.77999999999953, 44.76999999999937, 14.630000000000033, 53.41999999999942, 82.10000000000058, 159.4199999999997, 68.31000000000046, 53.66999999999933, 5.999999999999916, 14.999999999999915, 212.33999999999864, 10.88999999999992, 36.849999999999454, 0.9099999999999818, 88.03000000000019, 3.540000000000197, 31.880000000000027, 44.98999999999933, 10.869999999999918, 2.9799999999999813, 4.989999999999937, 12.94999999999992, 110.90000000000038, 41.499999999999346, 168.3200000000002, 39.91999999999932, 0.6800000000000342, 6.919999999999919, -28.349999999999454, -1.0700000000000622, -16.899999999999753, 4.909999999999935, -3.25000000000008, 11.869999999999921, 15.929999999999936, 12.819999999999922, 4.979999999999937, 8.919999999999918, 77.15000000000013, 27.770000000000557, 103.0200000000001, -8.090000000000083, 49.29999999999935, 150.72999999999985, 87.91000000000074, 10.659999999999924, -43.54000000000062, -26.379999999999463, 61.47999999999934, 2.9099999999999815, 31.649999999999974, 34.77999999999992, -6.26000000000008, 22.710000000000566, 19.5700000000005, 4.969999999999938, 15.999999999999915, 13.959999999999917, 11.78999999999992, 4.999999999999937, 52.44999999999996, 93.8800000000012, 0.8199999999999844, 160.37999999999926, -1.2000000000000615, 14.629999999999923, 14.749999999999925, 5.799999999999925, 181.92000000000013, 23.70000000000056, 137.57000000000016, 21.229999999999826], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -130.66000000000122, 2.0000000000000013, -8.050000000000042, 11.89999999999996, -42.220000000000354, -40.210000000000356, -4.030000000000042, 2.0000000000000013, -52.360000000000326, -32.170000000000364, -48.25000000000035, -29.169999999999714, -82.77999999999983, -24.129999999999708, -24.129999999999708, -38.71000000000026, 2.0000000000000013, -26.13999999999971, -24.129999999999708, 9.91999999999996, -10.060000000000041, 2.0000000000000013, -36.19000000000036, -2.020000000000042, -198.04000000000082, -4.030000000000036, 2.0000000000000013, -14.080000000000041, -12.070000000000041, -34.18000000000036, -28.14999999999971, -20.109999999999705, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -17.469999999999857, -34.18000000000036, 88.61000000000017, 2.0000000000000013, -34.18000000000036, -4.030000000000041, -26.13999999999971, -24.7299999999998, -12.070000000000041, -6.040000000000042, 9.679999999999964, -20.109999999999705, -0.00999999999999836, -12.070000000000041, -22.11999999999971, -4.03000000000004, -10.060000000000041, -42.22000000000031, 2.0000000000000013, -28.14999999999971, -14.080000000000041, -38.20000000000036, -32.170000000000215, 2.0000000000000013, -24.579999999999778, -40.90000000000004, 2.0000000000000013, 145.45999999999987, -6.040000000000042, 2.0000000000000013, -136.6900000000005, 25.67000000000026, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 61.40000000000012, 103.94000000000045, -11.11000000000004, 2.0000000000000013, 2.0000000000000013, -28.14999999999972, -16.0899999999997, 2.0000000000000013, 28.580000000000247, 35.4499999999999, -30.159999999999712, -58.30000000000034, 2.0000000000000013, 13.879999999999995, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -24.12999999999972, 2.0000000000000013, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000038, 85.94000000000025, -8.050000000000042, -19.44999999999977, 141.31999999999994, 2.0000000000000013, 9.919999999999959, 2.0000000000000013, -6.040000000000042, -54.28000000000034, 2.0000000000000013, -14.080000000000041, -2.020000000000042, -64.32999999999915, 2.0000000000000013, -12.070000000000041, -16.0899999999997, -145.81000000000066, -2.020000000000042, -12.070000000000041, -30.249999999999726, 2.0000000000000013, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -6.040000000000042, 77.24000000000005, -16.0899999999997, 2.0000000000000013, -14.230000000000038, 84.01999999999998, 2.0000000000000013, -8.050000000000042, -6.040000000000042, 44.56999999999969, -52.270000000000344, 110.89999999999998, -2.170000000000039, 2.0000000000000013, -43.089999999999996, -8.050000000000042, -56.29000000000034, -94.47999999999924, -10.060000000000041, -74.37999999999917, 2.0000000000000013, 3.499999999999968, -2.0200000000000418, 2.0000000000000013, -16.0899999999997, 8.66000000000024, -0.00999999999999836, -9.220000000000038, 2.0000000000000013, -4.030000000000042, -44.23000000000035, -16.0899999999997, 21.80000000000028, -6.040000000000042, -31.390000000000104, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -25.20999999999972, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 38.44999999999997, -6.040000000000035, -14.080000000000041, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, 99.3800000000002, -38.20000000000036, 2.0000000000000013, -2.020000000000042, -11.350000000000035, 2.0000000000000013, -48.25000000000035, -38.20000000000036, 2.0000000000000013, 167.33000000000015, -80.40999999999923, 11.779999999999962, -14.080000000000041, -16.149999999999714, 128.72, -26.13999999999992, -112.6299999999993], "policy_predator_policy_reward": [71.0, 69.0, 7.0, 1.0, 22.0, 28.0, 4.0, 23.0, 28.0, 40.0, 32.0, 38.0, 138.0, 44.0, 20.0, 19.0, 38.0, 113.0, 15.0, 17.0, 8.0, 30.0, 20.0, 22.0, 119.0, 64.0, 8.0, 26.0, 61.0, 11.0, 25.0, 29.0, 5.0, 13.0, 0.0, 5.0, 0.0, 14.0, 31.0, 34.0, 10.0, 49.0, 22.0, 10.0, 8.0, 28.0, 58.0, 30.0, 12.0, 27.0, 13.0, 15.0, 12.0, 15.0, 17.0, 12.0, 39.0, 36.0, 46.0, 41.0, 46.0, 39.0, 47.0, 29.0, 34.0, 87.0, 10.0, 10.0, 146.0, 57.0, 21.0, 5.0, 1.0, 1.0, 8.0, 3.0, 22.0, 25.0, 6.0, 14.0, 10.0, 53.0, 11.0, 4.0, 12.0, 12.0, 55.0, 37.0, 7.0, 9.0, 14.0, 29.0, 10.0, 23.0, 0.0, 3.0, 3.0, 0.0, 16.0, 3.0, 21.0, 10.0, 39.0, 30.0, 16.0, 9.0, 20.0, 8.0, 51.0, 10.0, 10.0, 9.0, 4.0, 34.0, 0.0, 9.0, 16.0, 129.0, 3.0, 16.0, 0.0, 25.0, 18.0, 16.0, 1.0, 25.0, 25.0, 20.0, 1.0, 4.0, 4.0, 17.0, 12.0, 4.0, 18.0, 22.0, 11.0, 6.0, 0.0, 6.0, 28.0, 29.0, 29.0, 13.0, 44.0, 85.0, 29.0, 46.0, 8.0, 53.0, 7.0, 39.0, 19.0, 41.0, 5.0, 12.0, 10.0, 13.0, 14.0, 28.0, 17.0, 25.0, 7.0, 10.0, 42.0, 15.0, 6.0, 1.0, 2.0, 10.0, 11.0, 7.0, 23.0, 12.0, 0.0, 1.0, 5.0, 7.0, 52.0, 62.0, 20.0, 13.0, 50.0, 9.0, 8.0, 27.0, 7.0, 21.0, 35.0, 26.0, 19.0, 23.0, 43.0, 52.0, 8.0, 18.0, 5.0, 20.0, 64.0, 96.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7234416512330103, "mean_inference_ms": 1.8938892174049888, "mean_action_processing_ms": 0.3061946031507972, "mean_env_wait_ms": 0.24662199551230754, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004693388938903809, "StateBufferConnector_ms": 0.003751993179321289, "ViewRequirementAgentConnector_ms": 0.10700178146362305}, "num_episodes": 23, "episode_return_max": 212.33999999999864, "episode_return_min": -43.54000000000062, "episode_return_mean": 32.971899999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.9979118512563, "num_env_steps_trained_throughput_per_sec": 322.9979118512563, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 11388.501, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11388.437, "sample_time_ms": 1353.889, "learn_time_ms": 10017.065, "learn_throughput": 399.319, "synch_weights_time_ms": 14.309}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "0e60f_00000", "date": "2024-08-15_01-05-34", "timestamp": 1723664134, "time_this_iter_s": 12.440515756607056, "time_total_s": 553.4169361591339, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fcb820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 553.4169361591339, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 61.35882352941177, "ram_util_percent": 83.62352941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.483702891875827, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7915063898399393, "policy_loss": -0.005743690641232269, "vf_loss": 1.7967048282030398, "vf_explained_var": 0.2052213169594921, "kl": 0.010904948291679543, "entropy": 1.1282182398927274, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7427464780353366, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4467796448046568, "policy_loss": -0.007936434366705793, "vf_loss": 1.4539910446399102, "vf_explained_var": 0.052909092959903536, "kl": 0.009667072672281684, "entropy": 0.963447195953793, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 212.33999999999864, "episode_reward_min": -43.54000000000062, "episode_reward_mean": 38.328399999999945, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -145.81000000000066, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 175.25, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -2.5557999999999885, "predator_policy": 21.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.949999999999919, 49.529999999999546, 113.43000000000063, -0.18000000000003924, 5.829999999999922, 51.19999999999947, 42.639999999999354, 7.879999999999918, -7.190000000000081, 14.909999999999918, 34.77999999999953, 44.76999999999937, 14.630000000000033, 53.41999999999942, 82.10000000000058, 159.4199999999997, 68.31000000000046, 53.66999999999933, 5.999999999999916, 14.999999999999915, 212.33999999999864, 10.88999999999992, 36.849999999999454, 0.9099999999999818, 88.03000000000019, 3.540000000000197, 31.880000000000027, 44.98999999999933, 10.869999999999918, 2.9799999999999813, 4.989999999999937, 12.94999999999992, 110.90000000000038, 41.499999999999346, 168.3200000000002, 39.91999999999932, 0.6800000000000342, 6.919999999999919, -28.349999999999454, -1.0700000000000622, -16.899999999999753, 4.909999999999935, -3.25000000000008, 11.869999999999921, 15.929999999999936, 12.819999999999922, 4.979999999999937, 8.919999999999918, 77.15000000000013, 27.770000000000557, 103.0200000000001, -8.090000000000083, 49.29999999999935, 150.72999999999985, 87.91000000000074, 10.659999999999924, -43.54000000000062, -26.379999999999463, 61.47999999999934, 2.9099999999999815, 31.649999999999974, 34.77999999999992, -6.26000000000008, 22.710000000000566, 19.5700000000005, 4.969999999999938, 15.999999999999915, 13.959999999999917, 11.78999999999992, 4.999999999999937, 52.44999999999996, 93.8800000000012, 0.8199999999999844, 160.37999999999926, -1.2000000000000615, 14.629999999999923, 14.749999999999925, 5.799999999999925, 181.92000000000013, 23.70000000000056, 137.57000000000016, 21.229999999999826, 183.24999999999977, 17.68000000000022, -40.65000000000067, 79.10000000000012, -7.230000000000079, 15.919999999999916, 18.770000000000216, 19.690000000000406, 77.87000000000008, 158.14000000000004, 141.33000000000033, 10.989999999999917, 10.889999999999919, -7.230000000000079, 36.829999999999814, 14.889999999999917, 12.979999999999915, 79.18], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -8.050000000000042, 2.0000000000000013, -17.469999999999857, -34.18000000000036, 88.61000000000017, 2.0000000000000013, -34.18000000000036, -4.030000000000041, -26.13999999999971, -24.7299999999998, -12.070000000000041, -6.040000000000042, 9.679999999999964, -20.109999999999705, -0.00999999999999836, -12.070000000000041, -22.11999999999971, -4.03000000000004, -10.060000000000041, -42.22000000000031, 2.0000000000000013, -28.14999999999971, -14.080000000000041, -38.20000000000036, -32.170000000000215, 2.0000000000000013, -24.579999999999778, -40.90000000000004, 2.0000000000000013, 145.45999999999987, -6.040000000000042, 2.0000000000000013, -136.6900000000005, 25.67000000000026, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 61.40000000000012, 103.94000000000045, -11.11000000000004, 2.0000000000000013, 2.0000000000000013, -28.14999999999972, -16.0899999999997, 2.0000000000000013, 28.580000000000247, 35.4499999999999, -30.159999999999712, -58.30000000000034, 2.0000000000000013, 13.879999999999995, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -24.12999999999972, 2.0000000000000013, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000038, 85.94000000000025, -8.050000000000042, -19.44999999999977, 141.31999999999994, 2.0000000000000013, 9.919999999999959, 2.0000000000000013, -6.040000000000042, -54.28000000000034, 2.0000000000000013, -14.080000000000041, -2.020000000000042, -64.32999999999915, 2.0000000000000013, -12.070000000000041, -16.0899999999997, -145.81000000000066, -2.020000000000042, -12.070000000000041, -30.249999999999726, 2.0000000000000013, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -6.040000000000042, 77.24000000000005, -16.0899999999997, 2.0000000000000013, -14.230000000000038, 84.01999999999998, 2.0000000000000013, -8.050000000000042, -6.040000000000042, 44.56999999999969, -52.270000000000344, 110.89999999999998, -2.170000000000039, 2.0000000000000013, -43.089999999999996, -8.050000000000042, -56.29000000000034, -94.47999999999924, -10.060000000000041, -74.37999999999917, 2.0000000000000013, 3.499999999999968, -2.0200000000000418, 2.0000000000000013, -16.0899999999997, 8.66000000000024, -0.00999999999999836, -9.220000000000038, 2.0000000000000013, -4.030000000000042, -44.23000000000035, -16.0899999999997, 21.80000000000028, -6.040000000000042, -31.390000000000104, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -25.20999999999972, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 38.44999999999997, -6.040000000000035, -14.080000000000041, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, 99.3800000000002, -38.20000000000036, 2.0000000000000013, -2.020000000000042, -11.350000000000035, 2.0000000000000013, -48.25000000000035, -38.20000000000036, 2.0000000000000013, 167.33000000000015, -80.40999999999923, 11.779999999999962, -14.080000000000041, -16.149999999999714, 128.72, -26.13999999999992, -112.6299999999993, 2.0000000000000013, 175.25, 7.819999999999961, -26.13999999999971, -54.28000000000034, -60.370000000000324, 65.18000000000002, -14.080000000000041, -14.080000000000041, -28.14999999999971, -14.080000000000041, 2.0000000000000013, -23.229999999999897, 2.0000000000000013, -60.310000000000336, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, -0.00999999999999836, 95.15, -59.410000000000316, 126.74000000000017, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, 6.949999999999958, -44.23000000000035, 2.0000000000000013, -20.109999999999722, -10.060000000000041, -5.11000000000004, 2.0000000000000013, -2.0200000000000413, 2.0000000000000013, 62.17999999999998, 2.0000000000000013], "policy_predator_policy_reward": [0.0, 14.0, 31.0, 34.0, 10.0, 49.0, 22.0, 10.0, 8.0, 28.0, 58.0, 30.0, 12.0, 27.0, 13.0, 15.0, 12.0, 15.0, 17.0, 12.0, 39.0, 36.0, 46.0, 41.0, 46.0, 39.0, 47.0, 29.0, 34.0, 87.0, 10.0, 10.0, 146.0, 57.0, 21.0, 5.0, 1.0, 1.0, 8.0, 3.0, 22.0, 25.0, 6.0, 14.0, 10.0, 53.0, 11.0, 4.0, 12.0, 12.0, 55.0, 37.0, 7.0, 9.0, 14.0, 29.0, 10.0, 23.0, 0.0, 3.0, 3.0, 0.0, 16.0, 3.0, 21.0, 10.0, 39.0, 30.0, 16.0, 9.0, 20.0, 8.0, 51.0, 10.0, 10.0, 9.0, 4.0, 34.0, 0.0, 9.0, 16.0, 129.0, 3.0, 16.0, 0.0, 25.0, 18.0, 16.0, 1.0, 25.0, 25.0, 20.0, 1.0, 4.0, 4.0, 17.0, 12.0, 4.0, 18.0, 22.0, 11.0, 6.0, 0.0, 6.0, 28.0, 29.0, 29.0, 13.0, 44.0, 85.0, 29.0, 46.0, 8.0, 53.0, 7.0, 39.0, 19.0, 41.0, 5.0, 12.0, 10.0, 13.0, 14.0, 28.0, 17.0, 25.0, 7.0, 10.0, 42.0, 15.0, 6.0, 1.0, 2.0, 10.0, 11.0, 7.0, 23.0, 12.0, 0.0, 1.0, 5.0, 7.0, 52.0, 62.0, 20.0, 13.0, 50.0, 9.0, 8.0, 27.0, 7.0, 21.0, 35.0, 26.0, 19.0, 23.0, 43.0, 52.0, 8.0, 18.0, 5.0, 20.0, 64.0, 96.0, 4.0, 2.0, 28.0, 8.0, 44.0, 30.0, 17.0, 11.0, 16.0, 19.0, 12.0, 16.0, 30.0, 10.0, 44.0, 34.0, 22.0, 78.0, 25.0, 38.0, 37.0, 37.0, 1.0, 8.0, 1.0, 13.0, 9.0, 26.0, 54.0, 13.0, 1.0, 17.0, 8.0, 5.0, 14.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7216044740252017, "mean_inference_ms": 1.8902332057585869, "mean_action_processing_ms": 0.3053063703939175, "mean_env_wait_ms": 0.24600242841982223, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004947543144226074, "StateBufferConnector_ms": 0.0036045312881469727, "ViewRequirementAgentConnector_ms": 0.10402476787567139}, "num_episodes": 18, "episode_return_max": 212.33999999999864, "episode_return_min": -43.54000000000062, "episode_return_mean": 38.328399999999945, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.5860349821562, "num_env_steps_trained_throughput_per_sec": 347.5860349821562, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 11433.064, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11433.001, "sample_time_ms": 1355.875, "learn_time_ms": 10059.634, "learn_throughput": 397.629, "synch_weights_time_ms": 14.433}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "0e60f_00000", "date": "2024-08-15_01-05-46", "timestamp": 1723664146, "time_this_iter_s": 11.56216812133789, "time_total_s": 564.9791042804718, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2af99d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 564.9791042804718, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 54.747058823529414, "ram_util_percent": 83.24705882352941}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3970451744933607, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8488362583533797, "policy_loss": -0.005857532530303591, "vf_loss": 1.854292470879025, "vf_explained_var": 0.23802014687073925, "kl": 0.008026496153297515, "entropy": 1.1071816030002775, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0347251550545766, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5729751001905512, "policy_loss": -0.005225648058248221, "vf_loss": 1.5776247305844826, "vf_explained_var": 0.03726578872039835, "kl": 0.007680253683398988, "entropy": 0.9737801392873128, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 251.0199999999992, "episode_reward_min": -43.54000000000062, "episode_reward_mean": 39.00649999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -145.81000000000066, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.01999999999998, "predator_policy": 132.0}, "policy_reward_mean": {"prey_policy": -0.676749999999976, "predator_policy": 20.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.999999999999916, 14.999999999999915, 212.33999999999864, 10.88999999999992, 36.849999999999454, 0.9099999999999818, 88.03000000000019, 3.540000000000197, 31.880000000000027, 44.98999999999933, 10.869999999999918, 2.9799999999999813, 4.989999999999937, 12.94999999999992, 110.90000000000038, 41.499999999999346, 168.3200000000002, 39.91999999999932, 0.6800000000000342, 6.919999999999919, -28.349999999999454, -1.0700000000000622, -16.899999999999753, 4.909999999999935, -3.25000000000008, 11.869999999999921, 15.929999999999936, 12.819999999999922, 4.979999999999937, 8.919999999999918, 77.15000000000013, 27.770000000000557, 103.0200000000001, -8.090000000000083, 49.29999999999935, 150.72999999999985, 87.91000000000074, 10.659999999999924, -43.54000000000062, -26.379999999999463, 61.47999999999934, 2.9099999999999815, 31.649999999999974, 34.77999999999992, -6.26000000000008, 22.710000000000566, 19.5700000000005, 4.969999999999938, 15.999999999999915, 13.959999999999917, 11.78999999999992, 4.999999999999937, 52.44999999999996, 93.8800000000012, 0.8199999999999844, 160.37999999999926, -1.2000000000000615, 14.629999999999923, 14.749999999999925, 5.799999999999925, 181.92000000000013, 23.70000000000056, 137.57000000000016, 21.229999999999826, 183.24999999999977, 17.68000000000022, -40.65000000000067, 79.10000000000012, -7.230000000000079, 15.919999999999916, 18.770000000000216, 19.690000000000406, 77.87000000000008, 158.14000000000004, 141.33000000000033, 10.989999999999917, 10.889999999999919, -7.230000000000079, 36.829999999999814, 14.889999999999917, 12.979999999999915, 79.18, 16.760000000000097, 146.22000000000037, 14.969999999999917, 72.90999999999995, 4.809999999999938, 166.0799999999997, 83.47999999999988, -1.1300000000000614, 3.929999999999998, 11.749999999999929, 47.28999999999938, 0.9099999999999818, -7.399999999999768, 251.0199999999992, 17.80000000000024, 9.71999999999992, 9.929999999999918, 15.859999999999921], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 61.40000000000012, 103.94000000000045, -11.11000000000004, 2.0000000000000013, 2.0000000000000013, -28.14999999999972, -16.0899999999997, 2.0000000000000013, 28.580000000000247, 35.4499999999999, -30.159999999999712, -58.30000000000034, 2.0000000000000013, 13.879999999999995, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, -24.12999999999972, 2.0000000000000013, -2.020000000000042, -0.00999999999999836, 2.0000000000000013, -8.050000000000042, 2.0000000000000013, -6.040000000000038, 85.94000000000025, -8.050000000000042, -19.44999999999977, 141.31999999999994, 2.0000000000000013, 9.919999999999959, 2.0000000000000013, -6.040000000000042, -54.28000000000034, 2.0000000000000013, -14.080000000000041, -2.020000000000042, -64.32999999999915, 2.0000000000000013, -12.070000000000041, -16.0899999999997, -145.81000000000066, -2.020000000000042, -12.070000000000041, -30.249999999999726, 2.0000000000000013, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -6.040000000000042, 77.24000000000005, -16.0899999999997, 2.0000000000000013, -14.230000000000038, 84.01999999999998, 2.0000000000000013, -8.050000000000042, -6.040000000000042, 44.56999999999969, -52.270000000000344, 110.89999999999998, -2.170000000000039, 2.0000000000000013, -43.089999999999996, -8.050000000000042, -56.29000000000034, -94.47999999999924, -10.060000000000041, -74.37999999999917, 2.0000000000000013, 3.499999999999968, -2.0200000000000418, 2.0000000000000013, -16.0899999999997, 8.66000000000024, -0.00999999999999836, -9.220000000000038, 2.0000000000000013, -4.030000000000042, -44.23000000000035, -16.0899999999997, 21.80000000000028, -6.040000000000042, -31.390000000000104, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -25.20999999999972, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 38.44999999999997, -6.040000000000035, -14.080000000000041, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, 99.3800000000002, -38.20000000000036, 2.0000000000000013, -2.020000000000042, -11.350000000000035, 2.0000000000000013, -48.25000000000035, -38.20000000000036, 2.0000000000000013, 167.33000000000015, -80.40999999999923, 11.779999999999962, -14.080000000000041, -16.149999999999714, 128.72, -26.13999999999992, -112.6299999999993, 2.0000000000000013, 175.25, 7.819999999999961, -26.13999999999971, -54.28000000000034, -60.370000000000324, 65.18000000000002, -14.080000000000041, -14.080000000000041, -28.14999999999971, -14.080000000000041, 2.0000000000000013, -23.229999999999897, 2.0000000000000013, -60.310000000000336, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, -0.00999999999999836, 95.15, -59.410000000000316, 126.74000000000017, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, 6.949999999999958, -44.23000000000035, 2.0000000000000013, -20.109999999999722, -10.060000000000041, -5.11000000000004, 2.0000000000000013, -2.0200000000000413, 2.0000000000000013, 62.17999999999998, 2.0000000000000013, -43.24000000000025, 2.0000000000000013, -50.26000000000016, 53.48000000000007, -4.030000000000042, 2.0000000000000013, -14.470000000000033, 51.37999999999997, -26.13999999999972, -8.050000000000042, 139.12999999999988, -8.050000000000042, -2.0199999999999987, 0.5000000000000014, -24.129999999999708, 2.0000000000000013, 2.0000000000000013, -6.070000000000041, 11.89999999999996, -28.14999999999971, 36.64999999999968, -70.35999999999916, 2.0000000000000013, -16.089999999999705, -68.34999999999916, -8.050000000000042, 192.01999999999998, 2.0000000000000013, 2.0000000000000013, 0.8000000000000013, -12.070000000000041, -13.210000000000038, -12.070000000000041, 2.0000000000000013, -26.13999999999971, 2.0000000000000013], "policy_predator_policy_reward": [1.0, 1.0, 8.0, 3.0, 22.0, 25.0, 6.0, 14.0, 10.0, 53.0, 11.0, 4.0, 12.0, 12.0, 55.0, 37.0, 7.0, 9.0, 14.0, 29.0, 10.0, 23.0, 0.0, 3.0, 3.0, 0.0, 16.0, 3.0, 21.0, 10.0, 39.0, 30.0, 16.0, 9.0, 20.0, 8.0, 51.0, 10.0, 10.0, 9.0, 4.0, 34.0, 0.0, 9.0, 16.0, 129.0, 3.0, 16.0, 0.0, 25.0, 18.0, 16.0, 1.0, 25.0, 25.0, 20.0, 1.0, 4.0, 4.0, 17.0, 12.0, 4.0, 18.0, 22.0, 11.0, 6.0, 0.0, 6.0, 28.0, 29.0, 29.0, 13.0, 44.0, 85.0, 29.0, 46.0, 8.0, 53.0, 7.0, 39.0, 19.0, 41.0, 5.0, 12.0, 10.0, 13.0, 14.0, 28.0, 17.0, 25.0, 7.0, 10.0, 42.0, 15.0, 6.0, 1.0, 2.0, 10.0, 11.0, 7.0, 23.0, 12.0, 0.0, 1.0, 5.0, 7.0, 52.0, 62.0, 20.0, 13.0, 50.0, 9.0, 8.0, 27.0, 7.0, 21.0, 35.0, 26.0, 19.0, 23.0, 43.0, 52.0, 8.0, 18.0, 5.0, 20.0, 64.0, 96.0, 4.0, 2.0, 28.0, 8.0, 44.0, 30.0, 17.0, 11.0, 16.0, 19.0, 12.0, 16.0, 30.0, 10.0, 44.0, 34.0, 22.0, 78.0, 25.0, 38.0, 37.0, 37.0, 1.0, 8.0, 1.0, 13.0, 9.0, 26.0, 54.0, 13.0, 1.0, 17.0, 8.0, 5.0, 14.0, 1.0, 14.0, 44.0, 11.0, 132.0, 15.0, 2.0, 13.0, 23.0, 18.0, 21.0, 15.0, 20.0, 42.0, 43.0, 16.0, 5.0, 6.0, 2.0, 4.0, 24.0, 42.0, 39.0, 1.0, 14.0, 61.0, 8.0, 12.0, 45.0, 8.0, 7.0, 26.0, 9.0, 11.0, 9.0, 33.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7197937298048079, "mean_inference_ms": 1.8865704791534734, "mean_action_processing_ms": 0.3044119370619454, "mean_env_wait_ms": 0.2454724660694153, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0052258968353271484, "StateBufferConnector_ms": 0.0035784244537353516, "ViewRequirementAgentConnector_ms": 0.102577805519104}, "num_episodes": 18, "episode_return_max": 251.0199999999992, "episode_return_min": -43.54000000000062, "episode_return_mean": 39.00649999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 353.0297196190611, "num_env_steps_trained_throughput_per_sec": 353.0297196190611, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 11437.711, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11437.654, "sample_time_ms": 1356.909, "learn_time_ms": 10063.584, "learn_throughput": 397.473, "synch_weights_time_ms": 14.359}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "0e60f_00000", "date": "2024-08-15_01-05-57", "timestamp": 1723664157, "time_this_iter_s": 11.401140928268433, "time_total_s": 576.3802452087402, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a301a790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 576.3802452087402, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 55.73125, "ram_util_percent": 83.39375000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0231377133616695, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2103000422634147, "policy_loss": -0.005130880127695424, "vf_loss": 2.215010135451322, "vf_explained_var": 0.23941788525177687, "kl": 0.008415766646669832, "entropy": 1.0552965675712263, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7962003178382047, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4844972519332138, "policy_loss": -0.006038331975002413, "vf_loss": 1.489915204395062, "vf_explained_var": 0.018222653897351056, "kl": 0.008271723598386536, "entropy": 1.0137166520590504, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 251.0199999999992, "episode_reward_min": -43.54000000000062, "episode_reward_mean": 42.375999999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -145.81000000000066, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.01999999999998, "predator_policy": 132.0}, "policy_reward_mean": {"prey_policy": 0.4880000000000146, "predator_policy": 20.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-16.899999999999753, 4.909999999999935, -3.25000000000008, 11.869999999999921, 15.929999999999936, 12.819999999999922, 4.979999999999937, 8.919999999999918, 77.15000000000013, 27.770000000000557, 103.0200000000001, -8.090000000000083, 49.29999999999935, 150.72999999999985, 87.91000000000074, 10.659999999999924, -43.54000000000062, -26.379999999999463, 61.47999999999934, 2.9099999999999815, 31.649999999999974, 34.77999999999992, -6.26000000000008, 22.710000000000566, 19.5700000000005, 4.969999999999938, 15.999999999999915, 13.959999999999917, 11.78999999999992, 4.999999999999937, 52.44999999999996, 93.8800000000012, 0.8199999999999844, 160.37999999999926, -1.2000000000000615, 14.629999999999923, 14.749999999999925, 5.799999999999925, 181.92000000000013, 23.70000000000056, 137.57000000000016, 21.229999999999826, 183.24999999999977, 17.68000000000022, -40.65000000000067, 79.10000000000012, -7.230000000000079, 15.919999999999916, 18.770000000000216, 19.690000000000406, 77.87000000000008, 158.14000000000004, 141.33000000000033, 10.989999999999917, 10.889999999999919, -7.230000000000079, 36.829999999999814, 14.889999999999917, 12.979999999999915, 79.18, 16.760000000000097, 146.22000000000037, 14.969999999999917, 72.90999999999995, 4.809999999999938, 166.0799999999997, 83.47999999999988, -1.1300000000000614, 3.929999999999998, 11.749999999999929, 47.28999999999938, 0.9099999999999818, -7.399999999999768, 251.0199999999992, 17.80000000000024, 9.71999999999992, 9.929999999999918, 15.859999999999921, 47.95999999999931, 40.629999999999335, 21.940000000000545, 15.719999999999922, 156.13000000000002, 230.1999999999989, 19.910000000000593, 3.959999999999959, 81.3199999999998, 52.639999999999304, 6.8999999999999195, 2.8999999999999786, 7.929999999999918, 113.8400000000002, 0.9499999999999819, 144.81000000000012, 20.960000000000583, 17.99000000000027, 144.2299999999999, 8.949999999999918, 9.27999999999993, 8.839999999999922], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.0899999999997, -145.81000000000066, -2.020000000000042, -12.070000000000041, -30.249999999999726, 2.0000000000000013, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, -12.070000000000041, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, -2.020000000000042, -6.040000000000042, -6.040000000000042, 77.24000000000005, -16.0899999999997, 2.0000000000000013, -14.230000000000038, 84.01999999999998, 2.0000000000000013, -8.050000000000042, -6.040000000000042, 44.56999999999969, -52.270000000000344, 110.89999999999998, -2.170000000000039, 2.0000000000000013, -43.089999999999996, -8.050000000000042, -56.29000000000034, -94.47999999999924, -10.060000000000041, -74.37999999999917, 2.0000000000000013, 3.499999999999968, -2.0200000000000418, 2.0000000000000013, -16.0899999999997, 8.66000000000024, -0.00999999999999836, -9.220000000000038, 2.0000000000000013, -4.030000000000042, -44.23000000000035, -16.0899999999997, 21.80000000000028, -6.040000000000042, -31.390000000000104, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -25.20999999999972, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 38.44999999999997, -6.040000000000035, -14.080000000000041, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, 99.3800000000002, -38.20000000000036, 2.0000000000000013, -2.020000000000042, -11.350000000000035, 2.0000000000000013, -48.25000000000035, -38.20000000000036, 2.0000000000000013, 167.33000000000015, -80.40999999999923, 11.779999999999962, -14.080000000000041, -16.149999999999714, 128.72, -26.13999999999992, -112.6299999999993, 2.0000000000000013, 175.25, 7.819999999999961, -26.13999999999971, -54.28000000000034, -60.370000000000324, 65.18000000000002, -14.080000000000041, -14.080000000000041, -28.14999999999971, -14.080000000000041, 2.0000000000000013, -23.229999999999897, 2.0000000000000013, -60.310000000000336, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, -0.00999999999999836, 95.15, -59.410000000000316, 126.74000000000017, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, 6.949999999999958, -44.23000000000035, 2.0000000000000013, -20.109999999999722, -10.060000000000041, -5.11000000000004, 2.0000000000000013, -2.0200000000000413, 2.0000000000000013, 62.17999999999998, 2.0000000000000013, -43.24000000000025, 2.0000000000000013, -50.26000000000016, 53.48000000000007, -4.030000000000042, 2.0000000000000013, -14.470000000000033, 51.37999999999997, -26.13999999999972, -8.050000000000042, 139.12999999999988, -8.050000000000042, -2.0199999999999987, 0.5000000000000014, -24.129999999999708, 2.0000000000000013, 2.0000000000000013, -6.070000000000041, 11.89999999999996, -28.14999999999971, 36.64999999999968, -70.35999999999916, 2.0000000000000013, -16.089999999999705, -68.34999999999916, -8.050000000000042, 192.01999999999998, 2.0000000000000013, 2.0000000000000013, 0.8000000000000013, -12.070000000000041, -13.210000000000038, -12.070000000000041, 2.0000000000000013, -26.13999999999971, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -12.070000000000041, 31.700000000000266, -8.050000000000042, -0.009999999999998581, -54.28000000000034, 2.0000000000000013, -44.23000000000035, 143.35999999999999, 162.19999999999982, 2.0000000000000013, -2.020000000000042, 8.929999999999959, -6.040000000000042, 2.0000000000000013, 64.36999999999988, -8.050000000000042, 2.0000000000000013, -19.359999999999744, 3.9799999999999587, -14.080000000000041, -12.070000000000041, -4.030000000000042, -12.070000000000041, 2.0000000000000013, -28.149999999999714, 98.99000000000001, 2.0000000000000013, -8.050000000000042, 119.81, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, 2.98999999999998, 105.23000000000006, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 11.89999999999996, -122.61999999999931, 2.0000000000000013, -21.159999999999712], "policy_predator_policy_reward": [16.0, 129.0, 3.0, 16.0, 0.0, 25.0, 18.0, 16.0, 1.0, 25.0, 25.0, 20.0, 1.0, 4.0, 4.0, 17.0, 12.0, 4.0, 18.0, 22.0, 11.0, 6.0, 0.0, 6.0, 28.0, 29.0, 29.0, 13.0, 44.0, 85.0, 29.0, 46.0, 8.0, 53.0, 7.0, 39.0, 19.0, 41.0, 5.0, 12.0, 10.0, 13.0, 14.0, 28.0, 17.0, 25.0, 7.0, 10.0, 42.0, 15.0, 6.0, 1.0, 2.0, 10.0, 11.0, 7.0, 23.0, 12.0, 0.0, 1.0, 5.0, 7.0, 52.0, 62.0, 20.0, 13.0, 50.0, 9.0, 8.0, 27.0, 7.0, 21.0, 35.0, 26.0, 19.0, 23.0, 43.0, 52.0, 8.0, 18.0, 5.0, 20.0, 64.0, 96.0, 4.0, 2.0, 28.0, 8.0, 44.0, 30.0, 17.0, 11.0, 16.0, 19.0, 12.0, 16.0, 30.0, 10.0, 44.0, 34.0, 22.0, 78.0, 25.0, 38.0, 37.0, 37.0, 1.0, 8.0, 1.0, 13.0, 9.0, 26.0, 54.0, 13.0, 1.0, 17.0, 8.0, 5.0, 14.0, 1.0, 14.0, 44.0, 11.0, 132.0, 15.0, 2.0, 13.0, 23.0, 18.0, 21.0, 15.0, 20.0, 42.0, 43.0, 16.0, 5.0, 6.0, 2.0, 4.0, 24.0, 42.0, 39.0, 1.0, 14.0, 61.0, 8.0, 12.0, 45.0, 8.0, 7.0, 26.0, 9.0, 11.0, 9.0, 33.0, 7.0, 24.0, 28.0, 10.0, 11.0, 18.0, 12.0, 38.0, 30.0, 26.0, 31.0, 5.0, 61.0, 3.0, 10.0, 5.0, 3.0, 19.0, 6.0, 39.0, 31.0, 0.0, 17.0, 6.0, 13.0, 9.0, 9.0, 18.0, 25.0, 7.0, 0.0, 1.0, 22.0, 12.0, 13.0, 7.0, 6.0, 37.0, 0.0, 8.0, 7.0, 70.0, 50.0, 13.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7176894710226165, "mean_inference_ms": 1.8846056233293813, "mean_action_processing_ms": 0.30244561217515686, "mean_env_wait_ms": 0.24519413257137812, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0058242082595825195, "StateBufferConnector_ms": 0.003503084182739258, "ViewRequirementAgentConnector_ms": 0.10461461544036865}, "num_episodes": 22, "episode_return_max": 251.0199999999992, "episode_return_min": -43.54000000000062, "episode_return_mean": 42.375999999999976, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 317.395739528322, "num_env_steps_trained_throughput_per_sec": 317.395739528322, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 11571.915, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11571.859, "sample_time_ms": 1365.527, "learn_time_ms": 10189.685, "learn_throughput": 392.554, "synch_weights_time_ms": 13.882}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "0e60f_00000", "date": "2024-08-15_01-06-10", "timestamp": 1723664170, "time_this_iter_s": 12.65051007270813, "time_total_s": 589.0307552814484, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a301aee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 589.0307552814484, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 64.87222222222222, "ram_util_percent": 83.58333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3610492089280375, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9662919456996617, "policy_loss": -0.006248063413997885, "vf_loss": 2.972195208135736, "vf_explained_var": 0.2831615460297418, "kl": 0.006895926976203863, "entropy": 0.9796897402516118, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.090693864557478, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.809524592678383, "policy_loss": -0.0033723205486903825, "vf_loss": 1.8124749451402633, "vf_explained_var": 0.010436539706729708, "kl": 0.005626163189921224, "entropy": 1.0252360817931947, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 291.0599999999998, "episode_reward_min": -40.65000000000067, "episode_reward_mean": 50.49599999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -122.61999999999931, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.01999999999998, "predator_policy": 182.0}, "policy_reward_mean": {"prey_policy": 2.423000000000032, "predator_policy": 22.825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.710000000000566, 19.5700000000005, 4.969999999999938, 15.999999999999915, 13.959999999999917, 11.78999999999992, 4.999999999999937, 52.44999999999996, 93.8800000000012, 0.8199999999999844, 160.37999999999926, -1.2000000000000615, 14.629999999999923, 14.749999999999925, 5.799999999999925, 181.92000000000013, 23.70000000000056, 137.57000000000016, 21.229999999999826, 183.24999999999977, 17.68000000000022, -40.65000000000067, 79.10000000000012, -7.230000000000079, 15.919999999999916, 18.770000000000216, 19.690000000000406, 77.87000000000008, 158.14000000000004, 141.33000000000033, 10.989999999999917, 10.889999999999919, -7.230000000000079, 36.829999999999814, 14.889999999999917, 12.979999999999915, 79.18, 16.760000000000097, 146.22000000000037, 14.969999999999917, 72.90999999999995, 4.809999999999938, 166.0799999999997, 83.47999999999988, -1.1300000000000614, 3.929999999999998, 11.749999999999929, 47.28999999999938, 0.9099999999999818, -7.399999999999768, 251.0199999999992, 17.80000000000024, 9.71999999999992, 9.929999999999918, 15.859999999999921, 47.95999999999931, 40.629999999999335, 21.940000000000545, 15.719999999999922, 156.13000000000002, 230.1999999999989, 19.910000000000593, 3.959999999999959, 81.3199999999998, 52.639999999999304, 6.8999999999999195, 2.8999999999999786, 7.929999999999918, 113.8400000000002, 0.9499999999999819, 144.81000000000012, 20.960000000000583, 17.99000000000027, 144.2299999999999, 8.949999999999918, 9.27999999999993, 8.839999999999922, 162.30999999999983, 2.889999999999983, 8.919999999999918, 1.8299999999999663, 29.339999999999975, 204.00999999999954, 25.650000000000013, 87.15999999999988, -25.879999999999384, 163.43000000000006, 53.649999999999785, 7.999999999999915, 181.03999999999948, 3.859999999999957, -3.0900000000000833, 36.259999999999565, 18.900000000000432, 80.6600000000008, 1.9400000000000008, 291.0599999999998, 56.540000000000006, 2.9099999999999455, 12.979999999999917], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-16.0899999999997, 21.80000000000028, -6.040000000000042, -31.390000000000104, -4.030000000000042, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -25.20999999999972, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 2.0000000000000013, 38.44999999999997, -6.040000000000035, -14.080000000000041, 2.0000000000000013, -34.18000000000036, 2.0000000000000013, 99.3800000000002, -38.20000000000036, 2.0000000000000013, -2.020000000000042, -11.350000000000035, 2.0000000000000013, -48.25000000000035, -38.20000000000036, 2.0000000000000013, 167.33000000000015, -80.40999999999923, 11.779999999999962, -14.080000000000041, -16.149999999999714, 128.72, -26.13999999999992, -112.6299999999993, 2.0000000000000013, 175.25, 7.819999999999961, -26.13999999999971, -54.28000000000034, -60.370000000000324, 65.18000000000002, -14.080000000000041, -14.080000000000041, -28.14999999999971, -14.080000000000041, 2.0000000000000013, -23.229999999999897, 2.0000000000000013, -60.310000000000336, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, -0.00999999999999836, 95.15, -59.410000000000316, 126.74000000000017, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, 6.949999999999958, -44.23000000000035, 2.0000000000000013, -20.109999999999722, -10.060000000000041, -5.11000000000004, 2.0000000000000013, -2.0200000000000413, 2.0000000000000013, 62.17999999999998, 2.0000000000000013, -43.24000000000025, 2.0000000000000013, -50.26000000000016, 53.48000000000007, -4.030000000000042, 2.0000000000000013, -14.470000000000033, 51.37999999999997, -26.13999999999972, -8.050000000000042, 139.12999999999988, -8.050000000000042, -2.0199999999999987, 0.5000000000000014, -24.129999999999708, 2.0000000000000013, 2.0000000000000013, -6.070000000000041, 11.89999999999996, -28.14999999999971, 36.64999999999968, -70.35999999999916, 2.0000000000000013, -16.089999999999705, -68.34999999999916, -8.050000000000042, 192.01999999999998, 2.0000000000000013, 2.0000000000000013, 0.8000000000000013, -12.070000000000041, -13.210000000000038, -12.070000000000041, 2.0000000000000013, -26.13999999999971, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -12.070000000000041, 31.700000000000266, -8.050000000000042, -0.009999999999998581, -54.28000000000034, 2.0000000000000013, -44.23000000000035, 143.35999999999999, 162.19999999999982, 2.0000000000000013, -2.020000000000042, 8.929999999999959, -6.040000000000042, 2.0000000000000013, 64.36999999999988, -8.050000000000042, 2.0000000000000013, -19.359999999999744, 3.9799999999999587, -14.080000000000041, -12.070000000000041, -4.030000000000042, -12.070000000000041, 2.0000000000000013, -28.149999999999714, 98.99000000000001, 2.0000000000000013, -8.050000000000042, 119.81, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, 2.98999999999998, 105.23000000000006, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 11.89999999999996, -122.61999999999931, 2.0000000000000013, -21.159999999999712, -20.109999999999705, 158.4199999999999, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -14.080000000000041, -22.119999999999706, -8.050000000000042, -20.109999999999705, 11.450000000000227, 21.710000000000267, 143.30000000000004, -64.32999999999915, -2.020000000000005, -84.42999999999988, -110.41, -50.260000000000346, -122.6199999999993, 155.45000000000005, -2.020000000000042, 2.0000000000000013, -41.350000000000044, 2.0000000000000013, 2.0000000000000013, 15.85999999999996, 131.1800000000001, -2.020000000000042, -22.11999999999971, -8.050000000000042, -6.040000000000042, -101.73999999999936, 2.0000000000000013, 11.89999999999996, 2.0000000000000013, 2.0000000000000013, -99.33999999999968, 2.0000000000000013, -10.060000000000041, 172.24999999999977, 95.81, -12.070000000000041, -91.39000000000027, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -2.020000000000041], "policy_predator_policy_reward": [7.0, 10.0, 42.0, 15.0, 6.0, 1.0, 2.0, 10.0, 11.0, 7.0, 23.0, 12.0, 0.0, 1.0, 5.0, 7.0, 52.0, 62.0, 20.0, 13.0, 50.0, 9.0, 8.0, 27.0, 7.0, 21.0, 35.0, 26.0, 19.0, 23.0, 43.0, 52.0, 8.0, 18.0, 5.0, 20.0, 64.0, 96.0, 4.0, 2.0, 28.0, 8.0, 44.0, 30.0, 17.0, 11.0, 16.0, 19.0, 12.0, 16.0, 30.0, 10.0, 44.0, 34.0, 22.0, 78.0, 25.0, 38.0, 37.0, 37.0, 1.0, 8.0, 1.0, 13.0, 9.0, 26.0, 54.0, 13.0, 1.0, 17.0, 8.0, 5.0, 14.0, 1.0, 14.0, 44.0, 11.0, 132.0, 15.0, 2.0, 13.0, 23.0, 18.0, 21.0, 15.0, 20.0, 42.0, 43.0, 16.0, 5.0, 6.0, 2.0, 4.0, 24.0, 42.0, 39.0, 1.0, 14.0, 61.0, 8.0, 12.0, 45.0, 8.0, 7.0, 26.0, 9.0, 11.0, 9.0, 33.0, 7.0, 24.0, 28.0, 10.0, 11.0, 18.0, 12.0, 38.0, 30.0, 26.0, 31.0, 5.0, 61.0, 3.0, 10.0, 5.0, 3.0, 19.0, 6.0, 39.0, 31.0, 0.0, 17.0, 6.0, 13.0, 9.0, 9.0, 18.0, 25.0, 7.0, 0.0, 1.0, 22.0, 12.0, 13.0, 7.0, 6.0, 37.0, 0.0, 8.0, 7.0, 70.0, 50.0, 13.0, 15.0, 13.0, 11.0, 13.0, 8.0, 12.0, 9.0, 10.0, 22.0, 19.0, 19.0, 11.0, 28.0, 52.0, 40.0, 100.0, 182.0, 145.0, 2.0, 1.0, 9.0, 7.0, 86.0, 1.0, 3.0, 20.0, 14.0, 3.0, 25.0, 5.0, 6.0, 61.0, 75.0, 2.0, 3.0, 123.0, 55.0, 0.0, 10.0, 3.0, 20.0, 137.0, 23.0, 12.0, 5.0, 8.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7160841796819885, "mean_inference_ms": 1.8808847230269898, "mean_action_processing_ms": 0.3029874256825915, "mean_env_wait_ms": 0.24521351969521696, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009091019630432129, "StateBufferConnector_ms": 0.0034728050231933594, "ViewRequirementAgentConnector_ms": 0.10384654998779297}, "num_episodes": 23, "episode_return_max": 291.0599999999998, "episode_return_min": -40.65000000000067, "episode_return_mean": 50.49599999999996, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.16066366007726, "num_env_steps_trained_throughput_per_sec": 359.16066366007726, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 11562.718, "restore_workers_time_ms": 0.017, "training_step_time_ms": 11562.663, "sample_time_ms": 1370.489, "learn_time_ms": 10175.6, "learn_throughput": 393.097, "synch_weights_time_ms": 13.812}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "0e60f_00000", "date": "2024-08-15_01-06-21", "timestamp": 1723664181, "time_this_iter_s": 11.192015886306763, "time_total_s": 600.2227711677551, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a301ac10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 600.2227711677551, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 57.13333333333333, "ram_util_percent": 83.23333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6680785142555439, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0406429490084372, "policy_loss": -0.007413446907170866, "vf_loss": 3.0476080562071823, "vf_explained_var": 0.361419356121588, "kl": 0.008966818052413908, "entropy": 0.9801022435622241, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.22715499256023, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4476924946699192, "policy_loss": -0.0058739527545021795, "vf_loss": 3.4529658759081805, "vf_explained_var": 0.009766170682099761, "kl": 0.008007604453508085, "entropy": 1.078743594348746, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 448.0, "episode_reward_min": -40.65000000000067, "episode_reward_mean": 56.57659999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -146.7400000000011, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 192.01999999999998, "predator_policy": 182.0}, "policy_reward_mean": {"prey_policy": 2.2883000000000306, "predator_policy": 26.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.229999999999826, 183.24999999999977, 17.68000000000022, -40.65000000000067, 79.10000000000012, -7.230000000000079, 15.919999999999916, 18.770000000000216, 19.690000000000406, 77.87000000000008, 158.14000000000004, 141.33000000000033, 10.989999999999917, 10.889999999999919, -7.230000000000079, 36.829999999999814, 14.889999999999917, 12.979999999999915, 79.18, 16.760000000000097, 146.22000000000037, 14.969999999999917, 72.90999999999995, 4.809999999999938, 166.0799999999997, 83.47999999999988, -1.1300000000000614, 3.929999999999998, 11.749999999999929, 47.28999999999938, 0.9099999999999818, -7.399999999999768, 251.0199999999992, 17.80000000000024, 9.71999999999992, 9.929999999999918, 15.859999999999921, 47.95999999999931, 40.629999999999335, 21.940000000000545, 15.719999999999922, 156.13000000000002, 230.1999999999989, 19.910000000000593, 3.959999999999959, 81.3199999999998, 52.639999999999304, 6.8999999999999195, 2.8999999999999786, 7.929999999999918, 113.8400000000002, 0.9499999999999819, 144.81000000000012, 20.960000000000583, 17.99000000000027, 144.2299999999999, 8.949999999999918, 9.27999999999993, 8.839999999999922, 162.30999999999983, 2.889999999999983, 8.919999999999918, 1.8299999999999663, 29.339999999999975, 204.00999999999954, 25.650000000000013, 87.15999999999988, -25.879999999999384, 163.43000000000006, 53.649999999999785, 7.999999999999915, 181.03999999999948, 3.859999999999957, -3.0900000000000833, 36.259999999999565, 18.900000000000432, 80.6600000000008, 1.9400000000000008, 291.0599999999998, 56.540000000000006, 2.9099999999999455, 12.979999999999917, 37.8300000000003, 9.909999999999918, 211.6699999999998, 48.75999999999932, 32.97999999999992, -1.4200000000000634, -1.1100000000000632, 448.0, 44.479999999999634, 186.25999999999996, 2.929999999999979, -8.370000000000077, -3.200000000000081, 31.700000000000106, 31.880000000000503, 171.59999999999985, 3.4899999999999674, 139.37000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-26.13999999999992, -112.6299999999993, 2.0000000000000013, 175.25, 7.819999999999961, -26.13999999999971, -54.28000000000034, -60.370000000000324, 65.18000000000002, -14.080000000000041, -14.080000000000041, -28.14999999999971, -14.080000000000041, 2.0000000000000013, -23.229999999999897, 2.0000000000000013, -60.310000000000336, 2.0000000000000013, -24.129999999999708, 2.0000000000000013, -0.00999999999999836, 95.15, -59.410000000000316, 126.74000000000017, -0.00999999999999836, 2.0000000000000013, -10.060000000000041, 6.949999999999958, -44.23000000000035, 2.0000000000000013, -20.109999999999722, -10.060000000000041, -5.11000000000004, 2.0000000000000013, -2.0200000000000413, 2.0000000000000013, 62.17999999999998, 2.0000000000000013, -43.24000000000025, 2.0000000000000013, -50.26000000000016, 53.48000000000007, -4.030000000000042, 2.0000000000000013, -14.470000000000033, 51.37999999999997, -26.13999999999972, -8.050000000000042, 139.12999999999988, -8.050000000000042, -2.0199999999999987, 0.5000000000000014, -24.129999999999708, 2.0000000000000013, 2.0000000000000013, -6.070000000000041, 11.89999999999996, -28.14999999999971, 36.64999999999968, -70.35999999999916, 2.0000000000000013, -16.089999999999705, -68.34999999999916, -8.050000000000042, 192.01999999999998, 2.0000000000000013, 2.0000000000000013, 0.8000000000000013, -12.070000000000041, -13.210000000000038, -12.070000000000041, 2.0000000000000013, -26.13999999999971, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -12.070000000000041, 31.700000000000266, -8.050000000000042, -0.009999999999998581, -54.28000000000034, 2.0000000000000013, -44.23000000000035, 143.35999999999999, 162.19999999999982, 2.0000000000000013, -2.020000000000042, 8.929999999999959, -6.040000000000042, 2.0000000000000013, 64.36999999999988, -8.050000000000042, 2.0000000000000013, -19.359999999999744, 3.9799999999999587, -14.080000000000041, -12.070000000000041, -4.030000000000042, -12.070000000000041, 2.0000000000000013, -28.149999999999714, 98.99000000000001, 2.0000000000000013, -8.050000000000042, 119.81, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, 2.98999999999998, 105.23000000000006, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 11.89999999999996, -122.61999999999931, 2.0000000000000013, -21.159999999999712, -20.109999999999705, 158.4199999999999, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -14.080000000000041, -22.119999999999706, -8.050000000000042, -20.109999999999705, 11.450000000000227, 21.710000000000267, 143.30000000000004, -64.32999999999915, -2.020000000000005, -84.42999999999988, -110.41, -50.260000000000346, -122.6199999999993, 155.45000000000005, -2.020000000000042, 2.0000000000000013, -41.350000000000044, 2.0000000000000013, 2.0000000000000013, 15.85999999999996, 131.1800000000001, -2.020000000000042, -22.11999999999971, -8.050000000000042, -6.040000000000042, -101.73999999999936, 2.0000000000000013, 11.89999999999996, 2.0000000000000013, 2.0000000000000013, -99.33999999999968, 2.0000000000000013, -10.060000000000041, 172.24999999999977, 95.81, -12.070000000000041, -91.39000000000027, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -2.020000000000041, -14.080000000000041, -16.089999999999705, -16.0899999999997, 2.0000000000000013, 179.0, -64.32999999999981, -20.109999999999708, 14.86999999999996, -2.0200000000000173, 2.0000000000000013, -74.37999999999917, -6.040000000000042, -16.0899999999997, -2.020000000000042, 149.0, 137.0, -62.32000000000033, -26.199999999999836, 68.0, -146.7400000000011, -10.060000000000041, -0.00999999999999836, -54.28000000000034, 10.90999999999996, -28.14999999999971, -8.050000000000042, 13.87999999999996, -1.1800000000000388, -5.050000000000042, -12.07000000000004, 73.91000000000014, -15.309999999999961, -44.410000000000316, -18.099999999999703, -32.320000000000334, 119.68999999999998], "policy_predator_policy_reward": [64.0, 96.0, 4.0, 2.0, 28.0, 8.0, 44.0, 30.0, 17.0, 11.0, 16.0, 19.0, 12.0, 16.0, 30.0, 10.0, 44.0, 34.0, 22.0, 78.0, 25.0, 38.0, 37.0, 37.0, 1.0, 8.0, 1.0, 13.0, 9.0, 26.0, 54.0, 13.0, 1.0, 17.0, 8.0, 5.0, 14.0, 1.0, 14.0, 44.0, 11.0, 132.0, 15.0, 2.0, 13.0, 23.0, 18.0, 21.0, 15.0, 20.0, 42.0, 43.0, 16.0, 5.0, 6.0, 2.0, 4.0, 24.0, 42.0, 39.0, 1.0, 14.0, 61.0, 8.0, 12.0, 45.0, 8.0, 7.0, 26.0, 9.0, 11.0, 9.0, 33.0, 7.0, 24.0, 28.0, 10.0, 11.0, 18.0, 12.0, 38.0, 30.0, 26.0, 31.0, 5.0, 61.0, 3.0, 10.0, 5.0, 3.0, 19.0, 6.0, 39.0, 31.0, 0.0, 17.0, 6.0, 13.0, 9.0, 9.0, 18.0, 25.0, 7.0, 0.0, 1.0, 22.0, 12.0, 13.0, 7.0, 6.0, 37.0, 0.0, 8.0, 7.0, 70.0, 50.0, 13.0, 15.0, 13.0, 11.0, 13.0, 8.0, 12.0, 9.0, 10.0, 22.0, 19.0, 19.0, 11.0, 28.0, 52.0, 40.0, 100.0, 182.0, 145.0, 2.0, 1.0, 9.0, 7.0, 86.0, 1.0, 3.0, 20.0, 14.0, 3.0, 25.0, 5.0, 6.0, 61.0, 75.0, 2.0, 3.0, 123.0, 55.0, 0.0, 10.0, 3.0, 20.0, 137.0, 23.0, 12.0, 5.0, 8.0, 5.0, 27.0, 41.0, 15.0, 9.0, 12.0, 85.0, 24.0, 30.0, 20.0, 13.0, 40.0, 39.0, 0.0, 17.0, 69.0, 93.0, 52.0, 81.0, 172.0, 93.0, 0.0, 13.0, 1.0, 34.0, 21.0, 12.0, 11.0, 8.0, 35.0, 14.0, 38.0, 75.0, 26.0, 40.0, 27.0, 25.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7140292114226878, "mean_inference_ms": 1.8775585732649491, "mean_action_processing_ms": 0.3016426910565716, "mean_env_wait_ms": 0.24420404194516865, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008721351623535156, "StateBufferConnector_ms": 0.0033158063888549805, "ViewRequirementAgentConnector_ms": 0.10135233402252197}, "num_episodes": 18, "episode_return_max": 448.0, "episode_return_min": -40.65000000000067, "episode_return_mean": 56.57659999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.8800519289936, "num_env_steps_trained_throughput_per_sec": 334.8800519289936, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 11604.405, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11604.357, "sample_time_ms": 1340.52, "learn_time_ms": 10247.2, "learn_throughput": 390.351, "synch_weights_time_ms": 13.668}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "0e60f_00000", "date": "2024-08-15_01-06-33", "timestamp": 1723664193, "time_this_iter_s": 11.976139068603516, "time_total_s": 612.1989102363586, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb0f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 612.1989102363586, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 60.811764705882354, "ram_util_percent": 83.38823529411764}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.835829936559238, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.139618064676012, "policy_loss": -0.004280816190370984, "vf_loss": 3.143673600406243, "vf_explained_var": 0.3567407346591748, "kl": 0.004505499115166038, "entropy": 0.9118327424639747, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8380458003629452, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6038479937447443, "policy_loss": -0.005693509616820073, "vf_loss": 3.608876403803548, "vf_explained_var": 0.013606597317589654, "kl": 0.008868106100428897, "entropy": 1.1027050068138768, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 448.0, "episode_reward_min": -25.879999999999384, "episode_reward_mean": 66.23839999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -146.7400000000011, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 182.0}, "policy_reward_mean": {"prey_policy": 4.749200000000048, "predator_policy": 28.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [79.18, 16.760000000000097, 146.22000000000037, 14.969999999999917, 72.90999999999995, 4.809999999999938, 166.0799999999997, 83.47999999999988, -1.1300000000000614, 3.929999999999998, 11.749999999999929, 47.28999999999938, 0.9099999999999818, -7.399999999999768, 251.0199999999992, 17.80000000000024, 9.71999999999992, 9.929999999999918, 15.859999999999921, 47.95999999999931, 40.629999999999335, 21.940000000000545, 15.719999999999922, 156.13000000000002, 230.1999999999989, 19.910000000000593, 3.959999999999959, 81.3199999999998, 52.639999999999304, 6.8999999999999195, 2.8999999999999786, 7.929999999999918, 113.8400000000002, 0.9499999999999819, 144.81000000000012, 20.960000000000583, 17.99000000000027, 144.2299999999999, 8.949999999999918, 9.27999999999993, 8.839999999999922, 162.30999999999983, 2.889999999999983, 8.919999999999918, 1.8299999999999663, 29.339999999999975, 204.00999999999954, 25.650000000000013, 87.15999999999988, -25.879999999999384, 163.43000000000006, 53.649999999999785, 7.999999999999915, 181.03999999999948, 3.859999999999957, -3.0900000000000833, 36.259999999999565, 18.900000000000432, 80.6600000000008, 1.9400000000000008, 291.0599999999998, 56.540000000000006, 2.9099999999999455, 12.979999999999917, 37.8300000000003, 9.909999999999918, 211.6699999999998, 48.75999999999932, 32.97999999999992, -1.4200000000000634, -1.1100000000000632, 448.0, 44.479999999999634, 186.25999999999996, 2.929999999999979, -8.370000000000077, -3.200000000000081, 31.700000000000106, 31.880000000000503, 171.59999999999985, 3.4899999999999674, 139.37000000000018, -1.3600000000000616, 31.730000000000576, 152.04000000000008, -18.20999999999941, 271.99999999999915, 261.00999999999965, 32.97000000000024, 140.5500000000001, -19.60999999999951, 27.490000000000524, -4.110000000000083, 219.87999999999948, 29.84000000000058, 1.8800000000000008, 17.900000000000013, 244.06999999999948, 132.62000000000063, 209.9399999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [62.17999999999998, 2.0000000000000013, -43.24000000000025, 2.0000000000000013, -50.26000000000016, 53.48000000000007, -4.030000000000042, 2.0000000000000013, -14.470000000000033, 51.37999999999997, -26.13999999999972, -8.050000000000042, 139.12999999999988, -8.050000000000042, -2.0199999999999987, 0.5000000000000014, -24.129999999999708, 2.0000000000000013, 2.0000000000000013, -6.070000000000041, 11.89999999999996, -28.14999999999971, 36.64999999999968, -70.35999999999916, 2.0000000000000013, -16.089999999999705, -68.34999999999916, -8.050000000000042, 192.01999999999998, 2.0000000000000013, 2.0000000000000013, 0.8000000000000013, -12.070000000000041, -13.210000000000038, -12.070000000000041, 2.0000000000000013, -26.13999999999971, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -12.070000000000041, 31.700000000000266, -8.050000000000042, -0.009999999999998581, -54.28000000000034, 2.0000000000000013, -44.23000000000035, 143.35999999999999, 162.19999999999982, 2.0000000000000013, -2.020000000000042, 8.929999999999959, -6.040000000000042, 2.0000000000000013, 64.36999999999988, -8.050000000000042, 2.0000000000000013, -19.359999999999744, 3.9799999999999587, -14.080000000000041, -12.070000000000041, -4.030000000000042, -12.070000000000041, 2.0000000000000013, -28.149999999999714, 98.99000000000001, 2.0000000000000013, -8.050000000000042, 119.81, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, 2.98999999999998, 105.23000000000006, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 11.89999999999996, -122.61999999999931, 2.0000000000000013, -21.159999999999712, -20.109999999999705, 158.4199999999999, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -14.080000000000041, -22.119999999999706, -8.050000000000042, -20.109999999999705, 11.450000000000227, 21.710000000000267, 143.30000000000004, -64.32999999999915, -2.020000000000005, -84.42999999999988, -110.41, -50.260000000000346, -122.6199999999993, 155.45000000000005, -2.020000000000042, 2.0000000000000013, -41.350000000000044, 2.0000000000000013, 2.0000000000000013, 15.85999999999996, 131.1800000000001, -2.020000000000042, -22.11999999999971, -8.050000000000042, -6.040000000000042, -101.73999999999936, 2.0000000000000013, 11.89999999999996, 2.0000000000000013, 2.0000000000000013, -99.33999999999968, 2.0000000000000013, -10.060000000000041, 172.24999999999977, 95.81, -12.070000000000041, -91.39000000000027, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -2.020000000000041, -14.080000000000041, -16.089999999999705, -16.0899999999997, 2.0000000000000013, 179.0, -64.32999999999981, -20.109999999999708, 14.86999999999996, -2.0200000000000173, 2.0000000000000013, -74.37999999999917, -6.040000000000042, -16.0899999999997, -2.020000000000042, 149.0, 137.0, -62.32000000000033, -26.199999999999836, 68.0, -146.7400000000011, -10.060000000000041, -0.00999999999999836, -54.28000000000034, 10.90999999999996, -28.14999999999971, -8.050000000000042, 13.87999999999996, -1.1800000000000388, -5.050000000000042, -12.07000000000004, 73.91000000000014, -15.309999999999961, -44.410000000000316, -18.099999999999703, -32.320000000000334, 119.68999999999998, -18.099999999999703, -29.259999999999728, 12.88999999999996, -30.15999999999972, -81.79000000000002, -11.170000000000016, -18.099999999999707, -20.109999999999705, 2.0000000000000013, 152.0, 76.00999999999998, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, 133.03999999999996, -96.48999999999923, 4.969999999999958, -90.57999999999927, -34.18000000000033, -10.330000000000036, 2.0000000000000013, -20.109999999999705, 101.0, -10.12000000000004, 2.0000000000000013, 8.83999999999996, -22.119999999999706, 2.0000000000000013, -4.030000000000042, -12.070000000000041, 107.27, -20.19999999999972, 108.92000000000027, 4.700000000000239, 200.0, -10.060000000000041], "policy_predator_policy_reward": [14.0, 1.0, 14.0, 44.0, 11.0, 132.0, 15.0, 2.0, 13.0, 23.0, 18.0, 21.0, 15.0, 20.0, 42.0, 43.0, 16.0, 5.0, 6.0, 2.0, 4.0, 24.0, 42.0, 39.0, 1.0, 14.0, 61.0, 8.0, 12.0, 45.0, 8.0, 7.0, 26.0, 9.0, 11.0, 9.0, 33.0, 7.0, 24.0, 28.0, 10.0, 11.0, 18.0, 12.0, 38.0, 30.0, 26.0, 31.0, 5.0, 61.0, 3.0, 10.0, 5.0, 3.0, 19.0, 6.0, 39.0, 31.0, 0.0, 17.0, 6.0, 13.0, 9.0, 9.0, 18.0, 25.0, 7.0, 0.0, 1.0, 22.0, 12.0, 13.0, 7.0, 6.0, 37.0, 0.0, 8.0, 7.0, 70.0, 50.0, 13.0, 15.0, 13.0, 11.0, 13.0, 8.0, 12.0, 9.0, 10.0, 22.0, 19.0, 19.0, 11.0, 28.0, 52.0, 40.0, 100.0, 182.0, 145.0, 2.0, 1.0, 9.0, 7.0, 86.0, 1.0, 3.0, 20.0, 14.0, 3.0, 25.0, 5.0, 6.0, 61.0, 75.0, 2.0, 3.0, 123.0, 55.0, 0.0, 10.0, 3.0, 20.0, 137.0, 23.0, 12.0, 5.0, 8.0, 5.0, 27.0, 41.0, 15.0, 9.0, 12.0, 85.0, 24.0, 30.0, 20.0, 13.0, 40.0, 39.0, 0.0, 17.0, 69.0, 93.0, 52.0, 81.0, 172.0, 93.0, 0.0, 13.0, 1.0, 34.0, 21.0, 12.0, 11.0, 8.0, 35.0, 14.0, 38.0, 75.0, 26.0, 40.0, 27.0, 25.0, 29.0, 17.0, 25.0, 24.0, 117.0, 128.0, 20.0, 0.0, 59.0, 59.0, 106.0, 77.0, 25.0, 10.0, 44.0, 60.0, 2.0, 64.0, 33.0, 39.0, 14.0, 0.0, 109.0, 20.0, 5.0, 14.0, 7.0, 15.0, 11.0, 23.0, 129.0, 28.0, 4.0, 15.0, 12.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.712363489419385, "mean_inference_ms": 1.8742872678032665, "mean_action_processing_ms": 0.3007789414754388, "mean_env_wait_ms": 0.24378894847897506, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00812375545501709, "StateBufferConnector_ms": 0.003143906593322754, "ViewRequirementAgentConnector_ms": 0.09810316562652588}, "num_episodes": 18, "episode_return_max": 448.0, "episode_return_min": -25.879999999999384, "episode_return_mean": 66.23839999999997, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.11131835759556, "num_env_steps_trained_throughput_per_sec": 354.11131835759556, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 11603.79, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11603.741, "sample_time_ms": 1337.581, "learn_time_ms": 10249.313, "learn_throughput": 390.27, "synch_weights_time_ms": 13.93}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "0e60f_00000", "date": "2024-08-15_01-06-45", "timestamp": 1723664205, "time_this_iter_s": 11.31694507598877, "time_total_s": 623.5158553123474, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb0820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 623.5158553123474, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 58.931250000000006, "ram_util_percent": 82.78125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2591520167217052, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.400991280873616, "policy_loss": -0.006291150310318227, "vf_loss": 4.407087539743494, "vf_explained_var": 0.42201937840729165, "kl": 0.007795832687313157, "entropy": 0.7756572122296328, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9425601322499533, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1074018068414517, "policy_loss": -0.004048262353710554, "vf_loss": 3.110830943798893, "vf_explained_var": 0.0030873166190253363, "kl": 0.008255073782913814, "entropy": 1.0907907138425836, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 448.0, "episode_reward_min": -25.879999999999384, "episode_reward_mean": 88.81119999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -178.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 9.335600000000039, "predator_policy": 35.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.859999999999921, 47.95999999999931, 40.629999999999335, 21.940000000000545, 15.719999999999922, 156.13000000000002, 230.1999999999989, 19.910000000000593, 3.959999999999959, 81.3199999999998, 52.639999999999304, 6.8999999999999195, 2.8999999999999786, 7.929999999999918, 113.8400000000002, 0.9499999999999819, 144.81000000000012, 20.960000000000583, 17.99000000000027, 144.2299999999999, 8.949999999999918, 9.27999999999993, 8.839999999999922, 162.30999999999983, 2.889999999999983, 8.919999999999918, 1.8299999999999663, 29.339999999999975, 204.00999999999954, 25.650000000000013, 87.15999999999988, -25.879999999999384, 163.43000000000006, 53.649999999999785, 7.999999999999915, 181.03999999999948, 3.859999999999957, -3.0900000000000833, 36.259999999999565, 18.900000000000432, 80.6600000000008, 1.9400000000000008, 291.0599999999998, 56.540000000000006, 2.9099999999999455, 12.979999999999917, 37.8300000000003, 9.909999999999918, 211.6699999999998, 48.75999999999932, 32.97999999999992, -1.4200000000000634, -1.1100000000000632, 448.0, 44.479999999999634, 186.25999999999996, 2.929999999999979, -8.370000000000077, -3.200000000000081, 31.700000000000106, 31.880000000000503, 171.59999999999985, 3.4899999999999674, 139.37000000000018, -1.3600000000000616, 31.730000000000576, 152.04000000000008, -18.20999999999941, 271.99999999999915, 261.00999999999965, 32.97000000000024, 140.5500000000001, -19.60999999999951, 27.490000000000524, -4.110000000000083, 219.87999999999948, 29.84000000000058, 1.8800000000000008, 17.900000000000013, 244.06999999999948, 132.62000000000063, 209.9399999999996, 16.890000000000075, 48.739999999999874, 262.9999999999991, 190.99999999999972, 284.8699999999993, 9.95999999999992, 140.2999999999999, 272.4799999999992, 170.17000000000007, 15.899999999999919, 157.00000000000006, 290.8899999999999, 295.53, 228.23000000000002, 364.95999999999907, 183.89999999999975, 9.779999999999921, 241.90999999999954], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-26.13999999999971, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, -12.070000000000041, 31.700000000000266, -8.050000000000042, -0.009999999999998581, -54.28000000000034, 2.0000000000000013, -44.23000000000035, 143.35999999999999, 162.19999999999982, 2.0000000000000013, -2.020000000000042, 8.929999999999959, -6.040000000000042, 2.0000000000000013, 64.36999999999988, -8.050000000000042, 2.0000000000000013, -19.359999999999744, 3.9799999999999587, -14.080000000000041, -12.070000000000041, -4.030000000000042, -12.070000000000041, 2.0000000000000013, -28.149999999999714, 98.99000000000001, 2.0000000000000013, -8.050000000000042, 119.81, 2.0000000000000013, 2.0000000000000013, -6.040000000000042, 2.0000000000000013, 2.98999999999998, 105.23000000000006, 2.0000000000000013, 2.0000000000000013, -8.050000000000042, 11.89999999999996, -122.61999999999931, 2.0000000000000013, -21.159999999999712, -20.109999999999705, 158.4199999999999, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -14.080000000000041, -22.119999999999706, -8.050000000000042, -20.109999999999705, 11.450000000000227, 21.710000000000267, 143.30000000000004, -64.32999999999915, -2.020000000000005, -84.42999999999988, -110.41, -50.260000000000346, -122.6199999999993, 155.45000000000005, -2.020000000000042, 2.0000000000000013, -41.350000000000044, 2.0000000000000013, 2.0000000000000013, 15.85999999999996, 131.1800000000001, -2.020000000000042, -22.11999999999971, -8.050000000000042, -6.040000000000042, -101.73999999999936, 2.0000000000000013, 11.89999999999996, 2.0000000000000013, 2.0000000000000013, -99.33999999999968, 2.0000000000000013, -10.060000000000041, 172.24999999999977, 95.81, -12.070000000000041, -91.39000000000027, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -2.020000000000041, -14.080000000000041, -16.089999999999705, -16.0899999999997, 2.0000000000000013, 179.0, -64.32999999999981, -20.109999999999708, 14.86999999999996, -2.0200000000000173, 2.0000000000000013, -74.37999999999917, -6.040000000000042, -16.0899999999997, -2.020000000000042, 149.0, 137.0, -62.32000000000033, -26.199999999999836, 68.0, -146.7400000000011, -10.060000000000041, -0.00999999999999836, -54.28000000000034, 10.90999999999996, -28.14999999999971, -8.050000000000042, 13.87999999999996, -1.1800000000000388, -5.050000000000042, -12.07000000000004, 73.91000000000014, -15.309999999999961, -44.410000000000316, -18.099999999999703, -32.320000000000334, 119.68999999999998, -18.099999999999703, -29.259999999999728, 12.88999999999996, -30.15999999999972, -81.79000000000002, -11.170000000000016, -18.099999999999707, -20.109999999999705, 2.0000000000000013, 152.0, 76.00999999999998, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, 133.03999999999996, -96.48999999999923, 4.969999999999958, -90.57999999999927, -34.18000000000033, -10.330000000000036, 2.0000000000000013, -20.109999999999705, 101.0, -10.12000000000004, 2.0000000000000013, 8.83999999999996, -22.119999999999706, 2.0000000000000013, -4.030000000000042, -12.070000000000041, 107.27, -20.19999999999972, 108.92000000000027, 4.700000000000239, 200.0, -10.060000000000041, 12.88999999999996, 2.0000000000000013, 4.789999999999962, -8.050000000000042, 2.0000000000000013, 152.0, 2.0000000000000013, 155.0, -77.89, -7.239999999999725, -6.040000000000041, 2.0000000000000013, -35.29000000000034, 33.59, 2.8699999999999806, 139.61, 2.0000000000000013, 135.17000000000007, -10.06000000000004, -6.040000000000042, 2.0000000000000013, -178.0, 131.0, 105.89, -136.0, 48.53, 72.86000000000013, 109.36999999999999, 182.0, 5.959999999999958, 176.0, -18.099999999999703, -0.00999999999999836, -40.210000000000356, 128.0, -16.0899999999997], "policy_predator_policy_reward": [33.0, 7.0, 24.0, 28.0, 10.0, 11.0, 18.0, 12.0, 38.0, 30.0, 26.0, 31.0, 5.0, 61.0, 3.0, 10.0, 5.0, 3.0, 19.0, 6.0, 39.0, 31.0, 0.0, 17.0, 6.0, 13.0, 9.0, 9.0, 18.0, 25.0, 7.0, 0.0, 1.0, 22.0, 12.0, 13.0, 7.0, 6.0, 37.0, 0.0, 8.0, 7.0, 70.0, 50.0, 13.0, 15.0, 13.0, 11.0, 13.0, 8.0, 12.0, 9.0, 10.0, 22.0, 19.0, 19.0, 11.0, 28.0, 52.0, 40.0, 100.0, 182.0, 145.0, 2.0, 1.0, 9.0, 7.0, 86.0, 1.0, 3.0, 20.0, 14.0, 3.0, 25.0, 5.0, 6.0, 61.0, 75.0, 2.0, 3.0, 123.0, 55.0, 0.0, 10.0, 3.0, 20.0, 137.0, 23.0, 12.0, 5.0, 8.0, 5.0, 27.0, 41.0, 15.0, 9.0, 12.0, 85.0, 24.0, 30.0, 20.0, 13.0, 40.0, 39.0, 0.0, 17.0, 69.0, 93.0, 52.0, 81.0, 172.0, 93.0, 0.0, 13.0, 1.0, 34.0, 21.0, 12.0, 11.0, 8.0, 35.0, 14.0, 38.0, 75.0, 26.0, 40.0, 27.0, 25.0, 29.0, 17.0, 25.0, 24.0, 117.0, 128.0, 20.0, 0.0, 59.0, 59.0, 106.0, 77.0, 25.0, 10.0, 44.0, 60.0, 2.0, 64.0, 33.0, 39.0, 14.0, 0.0, 109.0, 20.0, 5.0, 14.0, 7.0, 15.0, 11.0, 23.0, 129.0, 28.0, 4.0, 15.0, 12.0, 8.0, 0.0, 2.0, 45.0, 7.0, 51.0, 58.0, 17.0, 17.0, 198.0, 172.0, 2.0, 12.0, 49.0, 93.0, 106.0, 24.0, 25.0, 8.0, 25.0, 7.0, 189.0, 144.0, 24.0, 30.0, 183.0, 200.0, 26.0, 20.0, 98.0, 79.0, 13.0, 13.0, 26.0, 24.0, 119.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7106944129857595, "mean_inference_ms": 1.8707878602917793, "mean_action_processing_ms": 0.2999365481130387, "mean_env_wait_ms": 0.24337072932043644, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007854580879211426, "StateBufferConnector_ms": 0.0032095909118652344, "ViewRequirementAgentConnector_ms": 0.10056591033935547}, "num_episodes": 18, "episode_return_max": 448.0, "episode_return_min": -25.879999999999384, "episode_return_mean": 88.81119999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.3010762981082, "num_env_steps_trained_throughput_per_sec": 361.3010762981082, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 11569.104, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11569.055, "sample_time_ms": 1326.636, "learn_time_ms": 10225.962, "learn_throughput": 391.161, "synch_weights_time_ms": 13.809}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "0e60f_00000", "date": "2024-08-15_01-06-56", "timestamp": 1723664216, "time_this_iter_s": 11.119793891906738, "time_total_s": 634.6356492042542, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a30a2e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 634.6356492042542, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 55.45, "ram_util_percent": 82.28125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.25119956684491, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.193447608544083, "policy_loss": -0.008021791768876255, "vf_loss": 4.201205090870933, "vf_explained_var": 0.5206591619385613, "kl": 0.01057292818491484, "entropy": 0.8101385559669878, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8103532795868222, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4077768194612372, "policy_loss": -0.006680496490102202, "vf_loss": 2.413651676783486, "vf_explained_var": 0.0031710037163325717, "kl": 0.010741822612721916, "entropy": 1.0611451516391108, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 448.0, "episode_reward_min": -25.879999999999384, "episode_reward_mean": 104.55129999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -178.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 11.94065000000004, "predator_policy": 40.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.839999999999922, 162.30999999999983, 2.889999999999983, 8.919999999999918, 1.8299999999999663, 29.339999999999975, 204.00999999999954, 25.650000000000013, 87.15999999999988, -25.879999999999384, 163.43000000000006, 53.649999999999785, 7.999999999999915, 181.03999999999948, 3.859999999999957, -3.0900000000000833, 36.259999999999565, 18.900000000000432, 80.6600000000008, 1.9400000000000008, 291.0599999999998, 56.540000000000006, 2.9099999999999455, 12.979999999999917, 37.8300000000003, 9.909999999999918, 211.6699999999998, 48.75999999999932, 32.97999999999992, -1.4200000000000634, -1.1100000000000632, 448.0, 44.479999999999634, 186.25999999999996, 2.929999999999979, -8.370000000000077, -3.200000000000081, 31.700000000000106, 31.880000000000503, 171.59999999999985, 3.4899999999999674, 139.37000000000018, -1.3600000000000616, 31.730000000000576, 152.04000000000008, -18.20999999999941, 271.99999999999915, 261.00999999999965, 32.97000000000024, 140.5500000000001, -19.60999999999951, 27.490000000000524, -4.110000000000083, 219.87999999999948, 29.84000000000058, 1.8800000000000008, 17.900000000000013, 244.06999999999948, 132.62000000000063, 209.9399999999996, 16.890000000000075, 48.739999999999874, 262.9999999999991, 190.99999999999972, 284.8699999999993, 9.95999999999992, 140.2999999999999, 272.4799999999992, 170.17000000000007, 15.899999999999919, 157.00000000000006, 290.8899999999999, 295.53, 228.23000000000002, 364.95999999999907, 183.89999999999975, 9.779999999999921, 241.90999999999954, 17.720000000000226, 306.99999999999926, 33.92999999999991, 1.8699999999999988, 22.960000000000175, 23.93000000000048, 250.65999999999943, 135.3400000000002, 3.9999999999999587, 390.9099999999999, 207.7699999999994, 342.36, -1.4100000000000616, 326.1999999999992, 10.869999999999921, 75.17000000000016, 158.27000000000027, 160.40999999999997, 139.35999999999933, 37.68999999999994, -1.0800000000000622, 95.09000000000067], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -21.159999999999712, -20.109999999999705, 158.4199999999999, 2.0000000000000013, -20.109999999999705, 2.0000000000000013, -14.080000000000041, -22.119999999999706, -8.050000000000042, -20.109999999999705, 11.450000000000227, 21.710000000000267, 143.30000000000004, -64.32999999999915, -2.020000000000005, -84.42999999999988, -110.41, -50.260000000000346, -122.6199999999993, 155.45000000000005, -2.020000000000042, 2.0000000000000013, -41.350000000000044, 2.0000000000000013, 2.0000000000000013, 15.85999999999996, 131.1800000000001, -2.020000000000042, -22.11999999999971, -8.050000000000042, -6.040000000000042, -101.73999999999936, 2.0000000000000013, 11.89999999999996, 2.0000000000000013, 2.0000000000000013, -99.33999999999968, 2.0000000000000013, -10.060000000000041, 172.24999999999977, 95.81, -12.070000000000041, -91.39000000000027, 2.0000000000000013, -16.0899999999997, 2.0000000000000013, -2.020000000000041, -14.080000000000041, -16.089999999999705, -16.0899999999997, 2.0000000000000013, 179.0, -64.32999999999981, -20.109999999999708, 14.86999999999996, -2.0200000000000173, 2.0000000000000013, -74.37999999999917, -6.040000000000042, -16.0899999999997, -2.020000000000042, 149.0, 137.0, -62.32000000000033, -26.199999999999836, 68.0, -146.7400000000011, -10.060000000000041, -0.00999999999999836, -54.28000000000034, 10.90999999999996, -28.14999999999971, -8.050000000000042, 13.87999999999996, -1.1800000000000388, -5.050000000000042, -12.07000000000004, 73.91000000000014, -15.309999999999961, -44.410000000000316, -18.099999999999703, -32.320000000000334, 119.68999999999998, -18.099999999999703, -29.259999999999728, 12.88999999999996, -30.15999999999972, -81.79000000000002, -11.170000000000016, -18.099999999999707, -20.109999999999705, 2.0000000000000013, 152.0, 76.00999999999998, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, 133.03999999999996, -96.48999999999923, 4.969999999999958, -90.57999999999927, -34.18000000000033, -10.330000000000036, 2.0000000000000013, -20.109999999999705, 101.0, -10.12000000000004, 2.0000000000000013, 8.83999999999996, -22.119999999999706, 2.0000000000000013, -4.030000000000042, -12.070000000000041, 107.27, -20.19999999999972, 108.92000000000027, 4.700000000000239, 200.0, -10.060000000000041, 12.88999999999996, 2.0000000000000013, 4.789999999999962, -8.050000000000042, 2.0000000000000013, 152.0, 2.0000000000000013, 155.0, -77.89, -7.239999999999725, -6.040000000000041, 2.0000000000000013, -35.29000000000034, 33.59, 2.8699999999999806, 139.61, 2.0000000000000013, 135.17000000000007, -10.06000000000004, -6.040000000000042, 2.0000000000000013, -178.0, 131.0, 105.89, -136.0, 48.53, 72.86000000000013, 109.36999999999999, 182.0, 5.959999999999958, 176.0, -18.099999999999703, -0.00999999999999836, -40.210000000000356, 128.0, -16.0899999999997, -32.170000000000364, 12.88999999999996, 83.0, 2.0000000000000013, -4.030000000000037, 5.959999999999958, -24.129999999999708, 2.0000000000000013, 5.959999999999958, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -40.360000000000326, -59.980000000000004, 142.55, -40.210000000000356, 2.0000000000000013, 2.0000000000000013, 103.90999999999997, -46.0, -16.20999999999972, 0.9800000000000014, 149.35999999999999, 167.0, -74.40999999999919, 2.0000000000000013, 106.25000000000013, -8.050000000000042, -24.129999999999708, 2.0000000000000013, 53.35999999999997, -36.19000000000036, 122.27000000000014, 2.0000000000000013, -0.00999999999999836, 158.42000000000002, 125.54000000000028, -34.180000000000106, 2.0000000000000013, 11.689999999999964, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, 92.09000000000029], "policy_predator_policy_reward": [13.0, 15.0, 13.0, 11.0, 13.0, 8.0, 12.0, 9.0, 10.0, 22.0, 19.0, 19.0, 11.0, 28.0, 52.0, 40.0, 100.0, 182.0, 145.0, 2.0, 1.0, 9.0, 7.0, 86.0, 1.0, 3.0, 20.0, 14.0, 3.0, 25.0, 5.0, 6.0, 61.0, 75.0, 2.0, 3.0, 123.0, 55.0, 0.0, 10.0, 3.0, 20.0, 137.0, 23.0, 12.0, 5.0, 8.0, 5.0, 27.0, 41.0, 15.0, 9.0, 12.0, 85.0, 24.0, 30.0, 20.0, 13.0, 40.0, 39.0, 0.0, 17.0, 69.0, 93.0, 52.0, 81.0, 172.0, 93.0, 0.0, 13.0, 1.0, 34.0, 21.0, 12.0, 11.0, 8.0, 35.0, 14.0, 38.0, 75.0, 26.0, 40.0, 27.0, 25.0, 29.0, 17.0, 25.0, 24.0, 117.0, 128.0, 20.0, 0.0, 59.0, 59.0, 106.0, 77.0, 25.0, 10.0, 44.0, 60.0, 2.0, 64.0, 33.0, 39.0, 14.0, 0.0, 109.0, 20.0, 5.0, 14.0, 7.0, 15.0, 11.0, 23.0, 129.0, 28.0, 4.0, 15.0, 12.0, 8.0, 0.0, 2.0, 45.0, 7.0, 51.0, 58.0, 17.0, 17.0, 198.0, 172.0, 2.0, 12.0, 49.0, 93.0, 106.0, 24.0, 25.0, 8.0, 25.0, 7.0, 189.0, 144.0, 24.0, 30.0, 183.0, 200.0, 26.0, 20.0, 98.0, 79.0, 13.0, 13.0, 26.0, 24.0, 119.0, 11.0, 19.0, 18.0, 83.0, 139.0, 29.0, 3.0, 16.0, 8.0, 2.0, 13.0, 6.0, 28.0, 163.0, 188.0, 6.0, 27.0, 0.0, 0.0, 195.0, 138.0, 99.0, 124.0, 20.0, 6.0, 30.0, 41.0, 122.0, 106.0, 15.0, 18.0, 50.0, 8.0, 13.0, 21.0, 2.0, 0.0, 9.0, 39.0, 10.0, 14.0, 1.0, 10.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7093934596286704, "mean_inference_ms": 1.8665937077171784, "mean_action_processing_ms": 0.2989959845284189, "mean_env_wait_ms": 0.2428435967851829, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0071800947189331055, "StateBufferConnector_ms": 0.0031876564025878906, "ViewRequirementAgentConnector_ms": 0.09736096858978271}, "num_episodes": 22, "episode_return_max": 448.0, "episode_return_min": -25.879999999999384, "episode_return_mean": 104.55129999999991, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 348.30071527469244, "num_env_steps_trained_throughput_per_sec": 348.30071527469244, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 11593.619, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11593.572, "sample_time_ms": 1351.683, "learn_time_ms": 10225.622, "learn_throughput": 391.174, "synch_weights_time_ms": 13.605}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "0e60f_00000", "date": "2024-08-15_01-07-07", "timestamp": 1723664227, "time_this_iter_s": 11.549674034118652, "time_total_s": 646.1853232383728, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a30301f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 646.1853232383728, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 55.811764705882354, "ram_util_percent": 82.50588235294117}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0565464233122173, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.998016231400626, "policy_loss": -0.0049554487728518705, "vf_loss": 4.002707474572318, "vf_explained_var": 0.569166591116991, "kl": 0.01056773028957513, "entropy": 0.6894238564072462, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2032306692272265, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.064272657336381, "policy_loss": -0.007612526168425878, "vf_loss": 2.0711737152129883, "vf_explained_var": 0.10324923443415808, "kl": 0.009486263687108035, "entropy": 1.0261364161022126, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 448.0, "episode_reward_min": -19.60999999999951, "episode_reward_mean": 123.09849999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -178.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 23.389250000000015, "predator_policy": 38.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.979999999999917, 37.8300000000003, 9.909999999999918, 211.6699999999998, 48.75999999999932, 32.97999999999992, -1.4200000000000634, -1.1100000000000632, 448.0, 44.479999999999634, 186.25999999999996, 2.929999999999979, -8.370000000000077, -3.200000000000081, 31.700000000000106, 31.880000000000503, 171.59999999999985, 3.4899999999999674, 139.37000000000018, -1.3600000000000616, 31.730000000000576, 152.04000000000008, -18.20999999999941, 271.99999999999915, 261.00999999999965, 32.97000000000024, 140.5500000000001, -19.60999999999951, 27.490000000000524, -4.110000000000083, 219.87999999999948, 29.84000000000058, 1.8800000000000008, 17.900000000000013, 244.06999999999948, 132.62000000000063, 209.9399999999996, 16.890000000000075, 48.739999999999874, 262.9999999999991, 190.99999999999972, 284.8699999999993, 9.95999999999992, 140.2999999999999, 272.4799999999992, 170.17000000000007, 15.899999999999919, 157.00000000000006, 290.8899999999999, 295.53, 228.23000000000002, 364.95999999999907, 183.89999999999975, 9.779999999999921, 241.90999999999954, 17.720000000000226, 306.99999999999926, 33.92999999999991, 1.8699999999999988, 22.960000000000175, 23.93000000000048, 250.65999999999943, 135.3400000000002, 3.9999999999999587, 390.9099999999999, 207.7699999999994, 342.36, -1.4100000000000616, 326.1999999999992, 10.869999999999921, 75.17000000000016, 158.27000000000027, 160.40999999999997, 139.35999999999933, 37.68999999999994, -1.0800000000000622, 95.09000000000067, 5.559999999999905, 135.91000000000088, 8.969999999999917, 135.64000000000019, 4.939999999999937, 206.08999999999958, -7.4400000000000475, 30.920000000000563, 200.02999999999963, 439.0, 3.8999999999999595, 288.0299999999992, 37.55999999999999, -3.3100000000000787, 121.6200000000002, 197.33999999999952, 246.64, 182.9699999999998, 350.27, 11.87999999999992, 273.27999999999963, 127.76000000000022, 257.39], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, -2.020000000000041, -14.080000000000041, -16.089999999999705, -16.0899999999997, 2.0000000000000013, 179.0, -64.32999999999981, -20.109999999999708, 14.86999999999996, -2.0200000000000173, 2.0000000000000013, -74.37999999999917, -6.040000000000042, -16.0899999999997, -2.020000000000042, 149.0, 137.0, -62.32000000000033, -26.199999999999836, 68.0, -146.7400000000011, -10.060000000000041, -0.00999999999999836, -54.28000000000034, 10.90999999999996, -28.14999999999971, -8.050000000000042, 13.87999999999996, -1.1800000000000388, -5.050000000000042, -12.07000000000004, 73.91000000000014, -15.309999999999961, -44.410000000000316, -18.099999999999703, -32.320000000000334, 119.68999999999998, -18.099999999999703, -29.259999999999728, 12.88999999999996, -30.15999999999972, -81.79000000000002, -11.170000000000016, -18.099999999999707, -20.109999999999705, 2.0000000000000013, 152.0, 76.00999999999998, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, 133.03999999999996, -96.48999999999923, 4.969999999999958, -90.57999999999927, -34.18000000000033, -10.330000000000036, 2.0000000000000013, -20.109999999999705, 101.0, -10.12000000000004, 2.0000000000000013, 8.83999999999996, -22.119999999999706, 2.0000000000000013, -4.030000000000042, -12.070000000000041, 107.27, -20.19999999999972, 108.92000000000027, 4.700000000000239, 200.0, -10.060000000000041, 12.88999999999996, 2.0000000000000013, 4.789999999999962, -8.050000000000042, 2.0000000000000013, 152.0, 2.0000000000000013, 155.0, -77.89, -7.239999999999725, -6.040000000000041, 2.0000000000000013, -35.29000000000034, 33.59, 2.8699999999999806, 139.61, 2.0000000000000013, 135.17000000000007, -10.06000000000004, -6.040000000000042, 2.0000000000000013, -178.0, 131.0, 105.89, -136.0, 48.53, 72.86000000000013, 109.36999999999999, 182.0, 5.959999999999958, 176.0, -18.099999999999703, -0.00999999999999836, -40.210000000000356, 128.0, -16.0899999999997, -32.170000000000364, 12.88999999999996, 83.0, 2.0000000000000013, -4.030000000000037, 5.959999999999958, -24.129999999999708, 2.0000000000000013, 5.959999999999958, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -40.360000000000326, -59.980000000000004, 142.55, -40.210000000000356, 2.0000000000000013, 2.0000000000000013, 103.90999999999997, -46.0, -16.20999999999972, 0.9800000000000014, 149.35999999999999, 167.0, -74.40999999999919, 2.0000000000000013, 106.25000000000013, -8.050000000000042, -24.129999999999708, 2.0000000000000013, 53.35999999999997, -36.19000000000036, 122.27000000000014, 2.0000000000000013, -0.00999999999999836, 158.42000000000002, 125.54000000000028, -34.180000000000106, 2.0000000000000013, 11.689999999999964, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, 92.09000000000029, -42.220000000000354, -42.220000000000354, 3.9799999999999587, 89.93000000000004, 2.0000000000000013, -4.030000000000042, 120.64999999999998, -0.00999999999999836, -8.050000000000042, -0.00999999999999836, -2.020000000000042, 189.11, -52.270000000000344, -32.170000000000364, -4.030000000000041, -8.050000000000042, -4.030000000000042, 191.06, 107.0, 200.0, -18.099999999999707, 2.0000000000000013, 95.03, 2.0000000000000013, 2.0000000000000013, 21.559999999999967, -4.030000000000042, -54.28000000000034, 101.66000000000008, -6.040000000000042, 157.34000000000003, 2.0000000000000013, 72.89000000000013, 119.74999999999999, -4.030000000000042, 158.0, 155.26999999999998, 176.0, -2.0200000000000378, -18.099999999999703, 144.56000000000017, 119.71999999999998, -20.13999999999971, 110.9, 113.87, 124.51999999999998], "policy_predator_policy_reward": [8.0, 5.0, 27.0, 41.0, 15.0, 9.0, 12.0, 85.0, 24.0, 30.0, 20.0, 13.0, 40.0, 39.0, 0.0, 17.0, 69.0, 93.0, 52.0, 81.0, 172.0, 93.0, 0.0, 13.0, 1.0, 34.0, 21.0, 12.0, 11.0, 8.0, 35.0, 14.0, 38.0, 75.0, 26.0, 40.0, 27.0, 25.0, 29.0, 17.0, 25.0, 24.0, 117.0, 128.0, 20.0, 0.0, 59.0, 59.0, 106.0, 77.0, 25.0, 10.0, 44.0, 60.0, 2.0, 64.0, 33.0, 39.0, 14.0, 0.0, 109.0, 20.0, 5.0, 14.0, 7.0, 15.0, 11.0, 23.0, 129.0, 28.0, 4.0, 15.0, 12.0, 8.0, 0.0, 2.0, 45.0, 7.0, 51.0, 58.0, 17.0, 17.0, 198.0, 172.0, 2.0, 12.0, 49.0, 93.0, 106.0, 24.0, 25.0, 8.0, 25.0, 7.0, 189.0, 144.0, 24.0, 30.0, 183.0, 200.0, 26.0, 20.0, 98.0, 79.0, 13.0, 13.0, 26.0, 24.0, 119.0, 11.0, 19.0, 18.0, 83.0, 139.0, 29.0, 3.0, 16.0, 8.0, 2.0, 13.0, 6.0, 28.0, 163.0, 188.0, 6.0, 27.0, 0.0, 0.0, 195.0, 138.0, 99.0, 124.0, 20.0, 6.0, 30.0, 41.0, 122.0, 106.0, 15.0, 18.0, 50.0, 8.0, 13.0, 21.0, 2.0, 0.0, 9.0, 39.0, 10.0, 14.0, 1.0, 10.0, 1.0, 0.0, 78.0, 12.0, 25.0, 17.0, 7.0, 4.0, 9.0, 6.0, 2.0, 11.0, 1.0, 18.0, 26.0, 51.0, 29.0, 14.0, 3.0, 10.0, 58.0, 74.0, 15.0, 5.0, 14.0, 177.0, 3.0, 11.0, 20.0, 35.0, 14.0, 12.0, 18.0, 20.0, 36.0, 18.0, 22.0, 7.0, 10.0, 9.0, 3.0, 29.0, 4.0, 5.0, 18.0, 19.0, 13.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7095846069598825, "mean_inference_ms": 1.8661395925103752, "mean_action_processing_ms": 0.298298122077987, "mean_env_wait_ms": 0.24263403919006557, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003818035125732422, "StateBufferConnector_ms": 0.003083467483520508, "ViewRequirementAgentConnector_ms": 0.10593020915985107}, "num_episodes": 23, "episode_return_max": 448.0, "episode_return_min": -19.60999999999951, "episode_return_mean": 123.09849999999992, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.92533444115526, "num_env_steps_trained_throughput_per_sec": 349.92533444115526, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 11618.908, "restore_workers_time_ms": 0.013, "training_step_time_ms": 11618.86, "sample_time_ms": 1424.477, "learn_time_ms": 10179.225, "learn_throughput": 392.957, "synch_weights_time_ms": 13.42}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "0e60f_00000", "date": "2024-08-15_01-07-19", "timestamp": 1723664239, "time_this_iter_s": 11.483429193496704, "time_total_s": 657.6687524318695, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a3030dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 657.6687524318695, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 54.58125, "ram_util_percent": 82.54375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6705564092076013, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7152767507487505, "policy_loss": -0.009157303405836934, "vf_loss": 2.723497098022037, "vf_explained_var": 0.6341263420682736, "kl": 0.03747801088285305, "entropy": 0.9605237818899609, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5055404954959475, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1094588841080035, "policy_loss": -0.005087432742769283, "vf_loss": 1.1137668160376726, "vf_explained_var": 0.06328884419940767, "kl": 0.010393347224481885, "entropy": 1.0211687899140454, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 439.0, "episode_reward_min": -32.32000000000071, "episode_reward_mean": 128.98119999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -178.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 29.090600000000013, "predator_policy": 35.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [139.37000000000018, -1.3600000000000616, 31.730000000000576, 152.04000000000008, -18.20999999999941, 271.99999999999915, 261.00999999999965, 32.97000000000024, 140.5500000000001, -19.60999999999951, 27.490000000000524, -4.110000000000083, 219.87999999999948, 29.84000000000058, 1.8800000000000008, 17.900000000000013, 244.06999999999948, 132.62000000000063, 209.9399999999996, 16.890000000000075, 48.739999999999874, 262.9999999999991, 190.99999999999972, 284.8699999999993, 9.95999999999992, 140.2999999999999, 272.4799999999992, 170.17000000000007, 15.899999999999919, 157.00000000000006, 290.8899999999999, 295.53, 228.23000000000002, 364.95999999999907, 183.89999999999975, 9.779999999999921, 241.90999999999954, 17.720000000000226, 306.99999999999926, 33.92999999999991, 1.8699999999999988, 22.960000000000175, 23.93000000000048, 250.65999999999943, 135.3400000000002, 3.9999999999999587, 390.9099999999999, 207.7699999999994, 342.36, -1.4100000000000616, 326.1999999999992, 10.869999999999921, 75.17000000000016, 158.27000000000027, 160.40999999999997, 139.35999999999933, 37.68999999999994, -1.0800000000000622, 95.09000000000067, 5.559999999999905, 135.91000000000088, 8.969999999999917, 135.64000000000019, 4.939999999999937, 206.08999999999958, -7.4400000000000475, 30.920000000000563, 200.02999999999963, 439.0, 3.8999999999999595, 288.0299999999992, 37.55999999999999, -3.3100000000000787, 121.6200000000002, 197.33999999999952, 246.64, 182.9699999999998, 350.27, 11.87999999999992, 273.27999999999963, 127.76000000000022, 257.39, 170.5, 4.909999999999938, 26.970000000000557, -32.32000000000071, 231.86999999999915, 5.939999999999919, 200.89999999999964, -10.230000000000079, 208.05999999999972, 230.00999999999948, 6.919999999999918, -1.1600000000000632, 55.17999999999969, 169.28999999999994, 301.79, 164.31999999999994, 89.80000000000005, 25.890000000000597], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-32.320000000000334, 119.68999999999998, -18.099999999999703, -29.259999999999728, 12.88999999999996, -30.15999999999972, -81.79000000000002, -11.170000000000016, -18.099999999999707, -20.109999999999705, 2.0000000000000013, 152.0, 76.00999999999998, 2.0000000000000013, 2.0000000000000013, -4.030000000000042, 133.03999999999996, -96.48999999999923, 4.969999999999958, -90.57999999999927, -34.18000000000033, -10.330000000000036, 2.0000000000000013, -20.109999999999705, 101.0, -10.12000000000004, 2.0000000000000013, 8.83999999999996, -22.119999999999706, 2.0000000000000013, -4.030000000000042, -12.070000000000041, 107.27, -20.19999999999972, 108.92000000000027, 4.700000000000239, 200.0, -10.060000000000041, 12.88999999999996, 2.0000000000000013, 4.789999999999962, -8.050000000000042, 2.0000000000000013, 152.0, 2.0000000000000013, 155.0, -77.89, -7.239999999999725, -6.040000000000041, 2.0000000000000013, -35.29000000000034, 33.59, 2.8699999999999806, 139.61, 2.0000000000000013, 135.17000000000007, -10.06000000000004, -6.040000000000042, 2.0000000000000013, -178.0, 131.0, 105.89, -136.0, 48.53, 72.86000000000013, 109.36999999999999, 182.0, 5.959999999999958, 176.0, -18.099999999999703, -0.00999999999999836, -40.210000000000356, 128.0, -16.0899999999997, -32.170000000000364, 12.88999999999996, 83.0, 2.0000000000000013, -4.030000000000037, 5.959999999999958, -24.129999999999708, 2.0000000000000013, 5.959999999999958, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -40.360000000000326, -59.980000000000004, 142.55, -40.210000000000356, 2.0000000000000013, 2.0000000000000013, 103.90999999999997, -46.0, -16.20999999999972, 0.9800000000000014, 149.35999999999999, 167.0, -74.40999999999919, 2.0000000000000013, 106.25000000000013, -8.050000000000042, -24.129999999999708, 2.0000000000000013, 53.35999999999997, -36.19000000000036, 122.27000000000014, 2.0000000000000013, -0.00999999999999836, 158.42000000000002, 125.54000000000028, -34.180000000000106, 2.0000000000000013, 11.689999999999964, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, 92.09000000000029, -42.220000000000354, -42.220000000000354, 3.9799999999999587, 89.93000000000004, 2.0000000000000013, -4.030000000000042, 120.64999999999998, -0.00999999999999836, -8.050000000000042, -0.00999999999999836, -2.020000000000042, 189.11, -52.270000000000344, -32.170000000000364, -4.030000000000041, -8.050000000000042, -4.030000000000042, 191.06, 107.0, 200.0, -18.099999999999707, 2.0000000000000013, 95.03, 2.0000000000000013, 2.0000000000000013, 21.559999999999967, -4.030000000000042, -54.28000000000034, 101.66000000000008, -6.040000000000042, 157.34000000000003, 2.0000000000000013, 72.89000000000013, 119.74999999999999, -4.030000000000042, 158.0, 155.26999999999998, 176.0, -2.0200000000000378, -18.099999999999703, 144.56000000000017, 119.71999999999998, -20.13999999999971, 110.9, 113.87, 124.51999999999998, 144.5, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, 2.0000000000000013, -4.03000000000004, -28.14999999999971, -32.17000000000036, 135.65, 58.21999999999976, 2.0000000000000013, -10.060000000000041, 200.0, -18.099999999999703, -44.230000000000345, 2.0000000000000013, -0.00999999999999836, 79.06999999999998, 115.01, 2.0000000000000013, -2.020000000000041, -10.060000000000041, -20.109999999999705, -8.050000000000042, 20.810000000000283, -76.6299999999995, -8.050000000000042, 166.34, 124.60999999999999, 143.18, 147.32, 2.0000000000000013, 95.06, -50.260000000000346, 11.89999999999996, -0.00999999999999836], "policy_predator_policy_reward": [27.0, 25.0, 29.0, 17.0, 25.0, 24.0, 117.0, 128.0, 20.0, 0.0, 59.0, 59.0, 106.0, 77.0, 25.0, 10.0, 44.0, 60.0, 2.0, 64.0, 33.0, 39.0, 14.0, 0.0, 109.0, 20.0, 5.0, 14.0, 7.0, 15.0, 11.0, 23.0, 129.0, 28.0, 4.0, 15.0, 12.0, 8.0, 0.0, 2.0, 45.0, 7.0, 51.0, 58.0, 17.0, 17.0, 198.0, 172.0, 2.0, 12.0, 49.0, 93.0, 106.0, 24.0, 25.0, 8.0, 25.0, 7.0, 189.0, 144.0, 24.0, 30.0, 183.0, 200.0, 26.0, 20.0, 98.0, 79.0, 13.0, 13.0, 26.0, 24.0, 119.0, 11.0, 19.0, 18.0, 83.0, 139.0, 29.0, 3.0, 16.0, 8.0, 2.0, 13.0, 6.0, 28.0, 163.0, 188.0, 6.0, 27.0, 0.0, 0.0, 195.0, 138.0, 99.0, 124.0, 20.0, 6.0, 30.0, 41.0, 122.0, 106.0, 15.0, 18.0, 50.0, 8.0, 13.0, 21.0, 2.0, 0.0, 9.0, 39.0, 10.0, 14.0, 1.0, 10.0, 1.0, 0.0, 78.0, 12.0, 25.0, 17.0, 7.0, 4.0, 9.0, 6.0, 2.0, 11.0, 1.0, 18.0, 26.0, 51.0, 29.0, 14.0, 3.0, 10.0, 58.0, 74.0, 15.0, 5.0, 14.0, 177.0, 3.0, 11.0, 20.0, 35.0, 14.0, 12.0, 18.0, 20.0, 36.0, 18.0, 22.0, 7.0, 10.0, 9.0, 3.0, 29.0, 4.0, 5.0, 18.0, 19.0, 13.0, 6.0, 4.0, 20.0, 8.0, 11.0, 2.0, 27.0, 4.0, 24.0, 6.0, 32.0, 8.0, 6.0, 6.0, 13.0, 17.0, 15.0, 122.0, 7.0, 108.0, 5.0, 9.0, 10.0, 14.0, 13.0, 50.0, 61.0, 9.0, 2.0, 22.0, 12.0, 10.0, 5.0, 27.0, 18.0, 3.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7111858931962967, "mean_inference_ms": 1.8689407675414091, "mean_action_processing_ms": 0.2983950663955994, "mean_env_wait_ms": 0.24296673315286216, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01046907901763916, "StateBufferConnector_ms": 0.009026885032653809, "ViewRequirementAgentConnector_ms": 0.13194358348846436}, "num_episodes": 18, "episode_return_max": 439.0, "episode_return_min": -32.32000000000071, "episode_return_mean": 128.98119999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 325.50009660886116, "num_env_steps_trained_throughput_per_sec": 325.50009660886116, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 11609.388, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11609.338, "sample_time_ms": 1488.038, "learn_time_ms": 10103.712, "learn_throughput": 395.894, "synch_weights_time_ms": 15.619}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "0e60f_00000", "date": "2024-08-15_01-07-31", "timestamp": 1723664251, "time_this_iter_s": 12.353420972824097, "time_total_s": 670.0221734046936, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a30a2280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 670.0221734046936, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 56.58823529411764, "ram_util_percent": 83.22352941176472}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4661578823965065, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.895420842700535, "policy_loss": -0.007534689723548514, "vf_loss": 5.901813719259999, "vf_explained_var": 0.4468838223073848, "kl": 0.03044807518637906, "entropy": 0.8196950612560151, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6232295835144306, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8925433319081706, "policy_loss": -0.005071015102621266, "vf_loss": 3.897031552703292, "vf_explained_var": 0.007079040278833379, "kl": 0.007770556355479464, "entropy": 1.025717544145685, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 467.39, "episode_reward_min": -32.32000000000071, "episode_reward_mean": 143.1001999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -243.22000000000023, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 32.4551, "predator_policy": 39.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [209.9399999999996, 16.890000000000075, 48.739999999999874, 262.9999999999991, 190.99999999999972, 284.8699999999993, 9.95999999999992, 140.2999999999999, 272.4799999999992, 170.17000000000007, 15.899999999999919, 157.00000000000006, 290.8899999999999, 295.53, 228.23000000000002, 364.95999999999907, 183.89999999999975, 9.779999999999921, 241.90999999999954, 17.720000000000226, 306.99999999999926, 33.92999999999991, 1.8699999999999988, 22.960000000000175, 23.93000000000048, 250.65999999999943, 135.3400000000002, 3.9999999999999587, 390.9099999999999, 207.7699999999994, 342.36, -1.4100000000000616, 326.1999999999992, 10.869999999999921, 75.17000000000016, 158.27000000000027, 160.40999999999997, 139.35999999999933, 37.68999999999994, -1.0800000000000622, 95.09000000000067, 5.559999999999905, 135.91000000000088, 8.969999999999917, 135.64000000000019, 4.939999999999937, 206.08999999999958, -7.4400000000000475, 30.920000000000563, 200.02999999999963, 439.0, 3.8999999999999595, 288.0299999999992, 37.55999999999999, -3.3100000000000787, 121.6200000000002, 197.33999999999952, 246.64, 182.9699999999998, 350.27, 11.87999999999992, 273.27999999999963, 127.76000000000022, 257.39, 170.5, 4.909999999999938, 26.970000000000557, -32.32000000000071, 231.86999999999915, 5.939999999999919, 200.89999999999964, -10.230000000000079, 208.05999999999972, 230.00999999999948, 6.919999999999918, -1.1600000000000632, 55.17999999999969, 169.28999999999994, 301.79, 164.31999999999994, 89.80000000000005, 25.890000000000597, 22.860000000000532, 446.0, -7.23000000000008, 95.78000000000007, 175.01999999999987, 446.09999999999997, 20.659999999999936, 467.39, 58.290000000000084, 375.90999999999997, 202.9999999999996, 18.95000000000044, 93.91000000000031, 204.98999999999958, 7.989999999999915, 228.62999999999948, 45.92999999999945, 167.77999999999986], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, -10.060000000000041, 12.88999999999996, 2.0000000000000013, 4.789999999999962, -8.050000000000042, 2.0000000000000013, 152.0, 2.0000000000000013, 155.0, -77.89, -7.239999999999725, -6.040000000000041, 2.0000000000000013, -35.29000000000034, 33.59, 2.8699999999999806, 139.61, 2.0000000000000013, 135.17000000000007, -10.06000000000004, -6.040000000000042, 2.0000000000000013, -178.0, 131.0, 105.89, -136.0, 48.53, 72.86000000000013, 109.36999999999999, 182.0, 5.959999999999958, 176.0, -18.099999999999703, -0.00999999999999836, -40.210000000000356, 128.0, -16.0899999999997, -32.170000000000364, 12.88999999999996, 83.0, 2.0000000000000013, -4.030000000000037, 5.959999999999958, -24.129999999999708, 2.0000000000000013, 5.959999999999958, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -40.360000000000326, -59.980000000000004, 142.55, -40.210000000000356, 2.0000000000000013, 2.0000000000000013, 103.90999999999997, -46.0, -16.20999999999972, 0.9800000000000014, 149.35999999999999, 167.0, -74.40999999999919, 2.0000000000000013, 106.25000000000013, -8.050000000000042, -24.129999999999708, 2.0000000000000013, 53.35999999999997, -36.19000000000036, 122.27000000000014, 2.0000000000000013, -0.00999999999999836, 158.42000000000002, 125.54000000000028, -34.180000000000106, 2.0000000000000013, 11.689999999999964, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, 92.09000000000029, -42.220000000000354, -42.220000000000354, 3.9799999999999587, 89.93000000000004, 2.0000000000000013, -4.030000000000042, 120.64999999999998, -0.00999999999999836, -8.050000000000042, -0.00999999999999836, -2.020000000000042, 189.11, -52.270000000000344, -32.170000000000364, -4.030000000000041, -8.050000000000042, -4.030000000000042, 191.06, 107.0, 200.0, -18.099999999999707, 2.0000000000000013, 95.03, 2.0000000000000013, 2.0000000000000013, 21.559999999999967, -4.030000000000042, -54.28000000000034, 101.66000000000008, -6.040000000000042, 157.34000000000003, 2.0000000000000013, 72.89000000000013, 119.74999999999999, -4.030000000000042, 158.0, 155.26999999999998, 176.0, -2.0200000000000378, -18.099999999999703, 144.56000000000017, 119.71999999999998, -20.13999999999971, 110.9, 113.87, 124.51999999999998, 144.5, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, 2.0000000000000013, -4.03000000000004, -28.14999999999971, -32.17000000000036, 135.65, 58.21999999999976, 2.0000000000000013, -10.060000000000041, 200.0, -18.099999999999703, -44.230000000000345, 2.0000000000000013, -0.00999999999999836, 79.06999999999998, 115.01, 2.0000000000000013, -2.020000000000041, -10.060000000000041, -20.109999999999705, -8.050000000000042, 20.810000000000283, -76.6299999999995, -8.050000000000042, 166.34, 124.60999999999999, 143.18, 147.32, 2.0000000000000013, 95.06, -50.260000000000346, 11.89999999999996, -0.00999999999999836, 2.0000000000000013, -26.13999999999971, 32.0, 131.0, -9.070000000000041, -30.159999999999712, 85.90999999999998, -24.129999999999708, 155.03, -0.00999999999999836, 59.06, 196.04000000000002, 16.85, -36.19000000000036, 173.0, -33.61, -140.71000000000024, 2.0000000000000013, -46.0, 94.90999999999998, 2.0000000000000013, 173.0, -4.030000000000042, -2.020000000000042, -16.090000000000032, 2.0000000000000013, -0.00999999999999836, 176.0, 2.0000000000000013, 2.98999999999998, -120.60999999999929, 173.24, -0.06999999999999948, 2.0000000000000013, 200.0, -243.22000000000023], "policy_predator_policy_reward": [12.0, 8.0, 0.0, 2.0, 45.0, 7.0, 51.0, 58.0, 17.0, 17.0, 198.0, 172.0, 2.0, 12.0, 49.0, 93.0, 106.0, 24.0, 25.0, 8.0, 25.0, 7.0, 189.0, 144.0, 24.0, 30.0, 183.0, 200.0, 26.0, 20.0, 98.0, 79.0, 13.0, 13.0, 26.0, 24.0, 119.0, 11.0, 19.0, 18.0, 83.0, 139.0, 29.0, 3.0, 16.0, 8.0, 2.0, 13.0, 6.0, 28.0, 163.0, 188.0, 6.0, 27.0, 0.0, 0.0, 195.0, 138.0, 99.0, 124.0, 20.0, 6.0, 30.0, 41.0, 122.0, 106.0, 15.0, 18.0, 50.0, 8.0, 13.0, 21.0, 2.0, 0.0, 9.0, 39.0, 10.0, 14.0, 1.0, 10.0, 1.0, 0.0, 78.0, 12.0, 25.0, 17.0, 7.0, 4.0, 9.0, 6.0, 2.0, 11.0, 1.0, 18.0, 26.0, 51.0, 29.0, 14.0, 3.0, 10.0, 58.0, 74.0, 15.0, 5.0, 14.0, 177.0, 3.0, 11.0, 20.0, 35.0, 14.0, 12.0, 18.0, 20.0, 36.0, 18.0, 22.0, 7.0, 10.0, 9.0, 3.0, 29.0, 4.0, 5.0, 18.0, 19.0, 13.0, 6.0, 4.0, 20.0, 8.0, 11.0, 2.0, 27.0, 4.0, 24.0, 6.0, 32.0, 8.0, 6.0, 6.0, 13.0, 17.0, 15.0, 122.0, 7.0, 108.0, 5.0, 9.0, 10.0, 14.0, 13.0, 50.0, 61.0, 9.0, 2.0, 22.0, 12.0, 10.0, 5.0, 27.0, 18.0, 3.0, 11.0, 16.0, 31.0, 153.0, 130.0, 18.0, 14.0, 13.0, 21.0, 19.0, 1.0, 189.0, 2.0, 28.0, 12.0, 177.0, 151.0, 81.0, 116.0, 176.0, 151.0, 14.0, 14.0, 10.0, 15.0, 0.0, 108.0, 15.0, 14.0, 3.0, 0.0, 23.0, 153.0, 24.0, 20.0, 160.0, 51.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7136802217595231, "mean_inference_ms": 1.8744906897649576, "mean_action_processing_ms": 0.29899000202119463, "mean_env_wait_ms": 0.2436149246235596, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012178897857666016, "StateBufferConnector_ms": 0.009083867073059082, "ViewRequirementAgentConnector_ms": 0.1433577537536621}, "num_episodes": 18, "episode_return_max": 467.39, "episode_return_min": -32.32000000000071, "episode_return_mean": 143.1001999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.45420778701816, "num_env_steps_trained_throughput_per_sec": 343.45420778701816, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 11623.237, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11623.182, "sample_time_ms": 1550.397, "learn_time_ms": 10054.224, "learn_throughput": 397.843, "synch_weights_time_ms": 16.645}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "0e60f_00000", "date": "2024-08-15_01-07-43", "timestamp": 1723664263, "time_this_iter_s": 11.723381042480469, "time_total_s": 681.7455544471741, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bb0af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 681.7455544471741, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 57.125, "ram_util_percent": 82.975}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.801734983589914, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.757173774355934, "policy_loss": -0.004603805922577897, "vf_loss": 6.761432516511786, "vf_explained_var": 0.46059160740287214, "kl": 0.006134087401153043, "entropy": 0.5967038391443787, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7971498498840937, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.384509358456526, "policy_loss": -0.008832494899995191, "vf_loss": 2.3922973304198534, "vf_explained_var": 0.016723288367034267, "kl": 0.013926968384479047, "entropy": 1.1172129744575137, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 467.39, "episode_reward_min": -71.60999999999915, "episode_reward_mean": 161.8824999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -337.5700000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 44.55125, "predator_policy": 36.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.8699999999999988, 22.960000000000175, 23.93000000000048, 250.65999999999943, 135.3400000000002, 3.9999999999999587, 390.9099999999999, 207.7699999999994, 342.36, -1.4100000000000616, 326.1999999999992, 10.869999999999921, 75.17000000000016, 158.27000000000027, 160.40999999999997, 139.35999999999933, 37.68999999999994, -1.0800000000000622, 95.09000000000067, 5.559999999999905, 135.91000000000088, 8.969999999999917, 135.64000000000019, 4.939999999999937, 206.08999999999958, -7.4400000000000475, 30.920000000000563, 200.02999999999963, 439.0, 3.8999999999999595, 288.0299999999992, 37.55999999999999, -3.3100000000000787, 121.6200000000002, 197.33999999999952, 246.64, 182.9699999999998, 350.27, 11.87999999999992, 273.27999999999963, 127.76000000000022, 257.39, 170.5, 4.909999999999938, 26.970000000000557, -32.32000000000071, 231.86999999999915, 5.939999999999919, 200.89999999999964, -10.230000000000079, 208.05999999999972, 230.00999999999948, 6.919999999999918, -1.1600000000000632, 55.17999999999969, 169.28999999999994, 301.79, 164.31999999999994, 89.80000000000005, 25.890000000000597, 22.860000000000532, 446.0, -7.23000000000008, 95.78000000000007, 175.01999999999987, 446.09999999999997, 20.659999999999936, 467.39, 58.290000000000084, 375.90999999999997, 202.9999999999996, 18.95000000000044, 93.91000000000031, 204.98999999999958, 7.989999999999915, 228.62999999999948, 45.92999999999945, 167.77999999999986, 10.989999999999917, 211.84999999999962, 192.1299999999997, 347.9999999999989, 178.0799999999998, 229.74000000000012, 218.9399999999995, 393.0, 405.33, -71.60999999999915, 165.85999999999993, 466.37, 347.48, 277.0399999999997, 378.01, 404.25, 228.6500000000001, 115.00000000000009, 370.19, 360.14, 198.92999999999964, 203.95999999999958], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.129999999999708, 2.0000000000000013, 5.959999999999958, 2.0000000000000013, 2.0000000000000013, -12.070000000000041, -40.360000000000326, -59.980000000000004, 142.55, -40.210000000000356, 2.0000000000000013, 2.0000000000000013, 103.90999999999997, -46.0, -16.20999999999972, 0.9800000000000014, 149.35999999999999, 167.0, -74.40999999999919, 2.0000000000000013, 106.25000000000013, -8.050000000000042, -24.129999999999708, 2.0000000000000013, 53.35999999999997, -36.19000000000036, 122.27000000000014, 2.0000000000000013, -0.00999999999999836, 158.42000000000002, 125.54000000000028, -34.180000000000106, 2.0000000000000013, 11.689999999999964, 2.0000000000000013, -14.080000000000041, 2.0000000000000013, 92.09000000000029, -42.220000000000354, -42.220000000000354, 3.9799999999999587, 89.93000000000004, 2.0000000000000013, -4.030000000000042, 120.64999999999998, -0.00999999999999836, -8.050000000000042, -0.00999999999999836, -2.020000000000042, 189.11, -52.270000000000344, -32.170000000000364, -4.030000000000041, -8.050000000000042, -4.030000000000042, 191.06, 107.0, 200.0, -18.099999999999707, 2.0000000000000013, 95.03, 2.0000000000000013, 2.0000000000000013, 21.559999999999967, -4.030000000000042, -54.28000000000034, 101.66000000000008, -6.040000000000042, 157.34000000000003, 2.0000000000000013, 72.89000000000013, 119.74999999999999, -4.030000000000042, 158.0, 155.26999999999998, 176.0, -2.0200000000000378, -18.099999999999703, 144.56000000000017, 119.71999999999998, -20.13999999999971, 110.9, 113.87, 124.51999999999998, 144.5, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, 2.0000000000000013, -4.03000000000004, -28.14999999999971, -32.17000000000036, 135.65, 58.21999999999976, 2.0000000000000013, -10.060000000000041, 200.0, -18.099999999999703, -44.230000000000345, 2.0000000000000013, -0.00999999999999836, 79.06999999999998, 115.01, 2.0000000000000013, -2.020000000000041, -10.060000000000041, -20.109999999999705, -8.050000000000042, 20.810000000000283, -76.6299999999995, -8.050000000000042, 166.34, 124.60999999999999, 143.18, 147.32, 2.0000000000000013, 95.06, -50.260000000000346, 11.89999999999996, -0.00999999999999836, 2.0000000000000013, -26.13999999999971, 32.0, 131.0, -9.070000000000041, -30.159999999999712, 85.90999999999998, -24.129999999999708, 155.03, -0.00999999999999836, 59.06, 196.04000000000002, 16.85, -36.19000000000036, 173.0, -33.61, -140.71000000000024, 2.0000000000000013, -46.0, 94.90999999999998, 2.0000000000000013, 173.0, -4.030000000000042, -2.020000000000042, -16.090000000000032, 2.0000000000000013, -0.00999999999999836, 176.0, 2.0000000000000013, 2.98999999999998, -120.60999999999929, 173.24, -0.06999999999999948, 2.0000000000000013, 200.0, -243.22000000000023, -0.00999999999999836, 2.0000000000000013, -9.430000000000032, 139.28000000000003, 2.0000000000000013, 184.13, 44.0, 2.0000000000000013, -40.210000000000356, 171.29, 52.24999999999997, 151.49, -12.070000000000041, 199.01, 164.0, 176.0, 174.2, 187.13, -337.5700000000004, 5.960000000000002, 152.12, -50.26000000000033, 174.23000000000002, 156.14000000000001, 175.04, 147.44, 106.43000000000006, 133.60999999999973, 149.0, 115.00999999999999, -64.0, 175.25, 41.6, 165.05, 2.0000000000000013, -94.0, 182.0, 163.19, 175.07, 160.07, 173.06, -0.12999999999999834, -34.18000000000036, 186.14], "policy_predator_policy_reward": [16.0, 8.0, 2.0, 13.0, 6.0, 28.0, 163.0, 188.0, 6.0, 27.0, 0.0, 0.0, 195.0, 138.0, 99.0, 124.0, 20.0, 6.0, 30.0, 41.0, 122.0, 106.0, 15.0, 18.0, 50.0, 8.0, 13.0, 21.0, 2.0, 0.0, 9.0, 39.0, 10.0, 14.0, 1.0, 10.0, 1.0, 0.0, 78.0, 12.0, 25.0, 17.0, 7.0, 4.0, 9.0, 6.0, 2.0, 11.0, 1.0, 18.0, 26.0, 51.0, 29.0, 14.0, 3.0, 10.0, 58.0, 74.0, 15.0, 5.0, 14.0, 177.0, 3.0, 11.0, 20.0, 35.0, 14.0, 12.0, 18.0, 20.0, 36.0, 18.0, 22.0, 7.0, 10.0, 9.0, 3.0, 29.0, 4.0, 5.0, 18.0, 19.0, 13.0, 6.0, 4.0, 20.0, 8.0, 11.0, 2.0, 27.0, 4.0, 24.0, 6.0, 32.0, 8.0, 6.0, 6.0, 13.0, 17.0, 15.0, 122.0, 7.0, 108.0, 5.0, 9.0, 10.0, 14.0, 13.0, 50.0, 61.0, 9.0, 2.0, 22.0, 12.0, 10.0, 5.0, 27.0, 18.0, 3.0, 11.0, 16.0, 31.0, 153.0, 130.0, 18.0, 14.0, 13.0, 21.0, 19.0, 1.0, 189.0, 2.0, 28.0, 12.0, 177.0, 151.0, 81.0, 116.0, 176.0, 151.0, 14.0, 14.0, 10.0, 15.0, 0.0, 108.0, 15.0, 14.0, 3.0, 0.0, 23.0, 153.0, 24.0, 20.0, 160.0, 51.0, 3.0, 6.0, 39.0, 43.0, 3.0, 3.0, 154.0, 148.0, 29.0, 18.0, 19.0, 7.0, 31.0, 1.0, 29.0, 24.0, 0.0, 44.0, 199.0, 61.0, 23.0, 41.0, 83.0, 53.0, 16.0, 9.0, 21.0, 16.0, 64.0, 50.0, 136.0, 157.0, 14.0, 8.0, 54.0, 153.0, 12.0, 13.0, 8.0, 17.0, 11.0, 15.0, 29.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7170113284930147, "mean_inference_ms": 1.883498616680697, "mean_action_processing_ms": 0.2991790048655876, "mean_env_wait_ms": 0.24474604533893488, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012093305587768555, "StateBufferConnector_ms": 0.00902092456817627, "ViewRequirementAgentConnector_ms": 0.1411421298980713}, "num_episodes": 22, "episode_return_max": 467.39, "episode_return_min": -71.60999999999915, "episode_return_mean": 161.8824999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 347.0762835383716, "num_env_steps_trained_throughput_per_sec": 347.0762835383716, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 11642.672, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11642.617, "sample_time_ms": 1568.179, "learn_time_ms": 10055.82, "learn_throughput": 397.78, "synch_weights_time_ms": 16.706}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "0e60f_00000", "date": "2024-08-15_01-07-55", "timestamp": 1723664275, "time_this_iter_s": 11.566198110580444, "time_total_s": 693.3117525577545, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fe0670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 693.3117525577545, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 57.39411764705882, "ram_util_percent": 82.88235294117646}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.891250665414901, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.123518844634767, "policy_loss": -0.006187666920334022, "vf_loss": 6.1288955050170735, "vf_explained_var": 0.6024660442241285, "kl": 0.014417837246030876, "entropy": 0.6891002576187174, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9874677110285985, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4748855814101205, "policy_loss": -0.0046390399099056605, "vf_loss": 3.4788994972667995, "vf_explained_var": 0.019335933904799204, "kl": 0.008335010562724132, "entropy": 1.0564741990553639, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 478.07, "episode_reward_min": -71.60999999999915, "episode_reward_mean": 182.1160999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -337.5700000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 52.00804999999998, "predator_policy": 39.05}, "custom_metrics": {}, "hist_stats": {"episode_reward": [95.09000000000067, 5.559999999999905, 135.91000000000088, 8.969999999999917, 135.64000000000019, 4.939999999999937, 206.08999999999958, -7.4400000000000475, 30.920000000000563, 200.02999999999963, 439.0, 3.8999999999999595, 288.0299999999992, 37.55999999999999, -3.3100000000000787, 121.6200000000002, 197.33999999999952, 246.64, 182.9699999999998, 350.27, 11.87999999999992, 273.27999999999963, 127.76000000000022, 257.39, 170.5, 4.909999999999938, 26.970000000000557, -32.32000000000071, 231.86999999999915, 5.939999999999919, 200.89999999999964, -10.230000000000079, 208.05999999999972, 230.00999999999948, 6.919999999999918, -1.1600000000000632, 55.17999999999969, 169.28999999999994, 301.79, 164.31999999999994, 89.80000000000005, 25.890000000000597, 22.860000000000532, 446.0, -7.23000000000008, 95.78000000000007, 175.01999999999987, 446.09999999999997, 20.659999999999936, 467.39, 58.290000000000084, 375.90999999999997, 202.9999999999996, 18.95000000000044, 93.91000000000031, 204.98999999999958, 7.989999999999915, 228.62999999999948, 45.92999999999945, 167.77999999999986, 10.989999999999917, 211.84999999999962, 192.1299999999997, 347.9999999999989, 178.0799999999998, 229.74000000000012, 218.9399999999995, 393.0, 405.33, -71.60999999999915, 165.85999999999993, 466.37, 347.48, 277.0399999999997, 378.01, 404.25, 228.6500000000001, 115.00000000000009, 370.19, 360.14, 198.92999999999964, 203.95999999999958, 116.69000000000021, 151.08999999999997, 336.3699999999998, 237.2199999999994, 299.0099999999993, 249.60000000000005, 383.08000000000004, 453.38, 14.91999999999992, 340.7899999999988, 222.9799999999995, 28.95000000000053, 199.88999999999965, 478.07, 280.97999999999917, 294.97999999999956, 181.2399999999998, 39.399999999999395], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, 92.09000000000029, -42.220000000000354, -42.220000000000354, 3.9799999999999587, 89.93000000000004, 2.0000000000000013, -4.030000000000042, 120.64999999999998, -0.00999999999999836, -8.050000000000042, -0.00999999999999836, -2.020000000000042, 189.11, -52.270000000000344, -32.170000000000364, -4.030000000000041, -8.050000000000042, -4.030000000000042, 191.06, 107.0, 200.0, -18.099999999999707, 2.0000000000000013, 95.03, 2.0000000000000013, 2.0000000000000013, 21.559999999999967, -4.030000000000042, -54.28000000000034, 101.66000000000008, -6.040000000000042, 157.34000000000003, 2.0000000000000013, 72.89000000000013, 119.74999999999999, -4.030000000000042, 158.0, 155.26999999999998, 176.0, -2.0200000000000378, -18.099999999999703, 144.56000000000017, 119.71999999999998, -20.13999999999971, 110.9, 113.87, 124.51999999999998, 144.5, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, 2.0000000000000013, -4.03000000000004, -28.14999999999971, -32.17000000000036, 135.65, 58.21999999999976, 2.0000000000000013, -10.060000000000041, 200.0, -18.099999999999703, -44.230000000000345, 2.0000000000000013, -0.00999999999999836, 79.06999999999998, 115.01, 2.0000000000000013, -2.020000000000041, -10.060000000000041, -20.109999999999705, -8.050000000000042, 20.810000000000283, -76.6299999999995, -8.050000000000042, 166.34, 124.60999999999999, 143.18, 147.32, 2.0000000000000013, 95.06, -50.260000000000346, 11.89999999999996, -0.00999999999999836, 2.0000000000000013, -26.13999999999971, 32.0, 131.0, -9.070000000000041, -30.159999999999712, 85.90999999999998, -24.129999999999708, 155.03, -0.00999999999999836, 59.06, 196.04000000000002, 16.85, -36.19000000000036, 173.0, -33.61, -140.71000000000024, 2.0000000000000013, -46.0, 94.90999999999998, 2.0000000000000013, 173.0, -4.030000000000042, -2.020000000000042, -16.090000000000032, 2.0000000000000013, -0.00999999999999836, 176.0, 2.0000000000000013, 2.98999999999998, -120.60999999999929, 173.24, -0.06999999999999948, 2.0000000000000013, 200.0, -243.22000000000023, -0.00999999999999836, 2.0000000000000013, -9.430000000000032, 139.28000000000003, 2.0000000000000013, 184.13, 44.0, 2.0000000000000013, -40.210000000000356, 171.29, 52.24999999999997, 151.49, -12.070000000000041, 199.01, 164.0, 176.0, 174.2, 187.13, -337.5700000000004, 5.960000000000002, 152.12, -50.26000000000033, 174.23000000000002, 156.14000000000001, 175.04, 147.44, 106.43000000000006, 133.60999999999973, 149.0, 115.00999999999999, -64.0, 175.25, 41.6, 165.05, 2.0000000000000013, -94.0, 182.0, 163.19, 175.07, 160.07, 173.06, -0.12999999999999834, -34.18000000000036, 186.14, 86.78000000000006, -16.0899999999997, -213.07000000000085, 184.15999999999997, 149.29999999999973, 154.07, 163.22, 2.0000000000000013, 158.18, -32.17000000000033, 144.26000000000005, 43.339999999999975, 153.08, 200.0, 101.0, 162.38, -11.080000000000041, 2.0000000000000013, 68.0, -16.20999999999972, -76.0, -2.0200000000000395, -8.050000000000042, 2.0000000000000013, -22.11999999999971, 199.01, 116.0, 31.070000000000007, -2.020000000000042, 128.0, 118.04000000000002, 103.93999999999991, 172.28, -6.040000000000042, -30.159999999999712, 21.560000000000244], "policy_predator_policy_reward": [1.0, 0.0, 78.0, 12.0, 25.0, 17.0, 7.0, 4.0, 9.0, 6.0, 2.0, 11.0, 1.0, 18.0, 26.0, 51.0, 29.0, 14.0, 3.0, 10.0, 58.0, 74.0, 15.0, 5.0, 14.0, 177.0, 3.0, 11.0, 20.0, 35.0, 14.0, 12.0, 18.0, 20.0, 36.0, 18.0, 22.0, 7.0, 10.0, 9.0, 3.0, 29.0, 4.0, 5.0, 18.0, 19.0, 13.0, 6.0, 4.0, 20.0, 8.0, 11.0, 2.0, 27.0, 4.0, 24.0, 6.0, 32.0, 8.0, 6.0, 6.0, 13.0, 17.0, 15.0, 122.0, 7.0, 108.0, 5.0, 9.0, 10.0, 14.0, 13.0, 50.0, 61.0, 9.0, 2.0, 22.0, 12.0, 10.0, 5.0, 27.0, 18.0, 3.0, 11.0, 16.0, 31.0, 153.0, 130.0, 18.0, 14.0, 13.0, 21.0, 19.0, 1.0, 189.0, 2.0, 28.0, 12.0, 177.0, 151.0, 81.0, 116.0, 176.0, 151.0, 14.0, 14.0, 10.0, 15.0, 0.0, 108.0, 15.0, 14.0, 3.0, 0.0, 23.0, 153.0, 24.0, 20.0, 160.0, 51.0, 3.0, 6.0, 39.0, 43.0, 3.0, 3.0, 154.0, 148.0, 29.0, 18.0, 19.0, 7.0, 31.0, 1.0, 29.0, 24.0, 0.0, 44.0, 199.0, 61.0, 23.0, 41.0, 83.0, 53.0, 16.0, 9.0, 21.0, 16.0, 64.0, 50.0, 136.0, 157.0, 14.0, 8.0, 54.0, 153.0, 12.0, 13.0, 8.0, 17.0, 11.0, 15.0, 29.0, 23.0, 13.0, 33.0, 48.0, 132.0, 15.0, 18.0, 64.0, 8.0, 138.0, 35.0, 21.0, 41.0, 15.0, 15.0, 141.0, 49.0, 12.0, 12.0, 152.0, 137.0, 136.0, 165.0, 22.0, 13.0, 20.0, 3.0, 166.0, 165.0, 147.0, 8.0, 47.0, 26.0, 1.0, 14.0, 23.0, 25.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7192668121206068, "mean_inference_ms": 1.8881120737214012, "mean_action_processing_ms": 0.30074107225223246, "mean_env_wait_ms": 0.24530301518297662, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012143969535827637, "StateBufferConnector_ms": 0.009046554565429688, "ViewRequirementAgentConnector_ms": 0.14278936386108398}, "num_episodes": 18, "episode_return_max": 478.07, "episode_return_min": -71.60999999999915, "episode_return_mean": 182.1160999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 352.6345488836056, "num_env_steps_trained_throughput_per_sec": 352.6345488836056, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 11516.734, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11516.679, "sample_time_ms": 1550.781, "learn_time_ms": 9947.857, "learn_throughput": 402.097, "synch_weights_time_ms": 16.133}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "0e60f_00000", "date": "2024-08-15_01-08-06", "timestamp": 1723664286, "time_this_iter_s": 11.385497093200684, "time_total_s": 704.6972496509552, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a301aca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 704.6972496509552, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 57.043749999999996, "ram_util_percent": 83.30000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.395988381161261, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.136573439300376, "policy_loss": -0.005637596393861468, "vf_loss": 5.141716683226288, "vf_explained_var": 0.6753610677504666, "kl": 0.008788497533611111, "entropy": 0.7570117278704568, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9687963289558572, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1901404317093904, "policy_loss": -0.0045791275725975905, "vf_loss": 3.194129248775502, "vf_explained_var": 0.10144890805400869, "kl": 0.007870658460202707, "entropy": 0.9373470529992745, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 478.07, "episode_reward_min": -71.60999999999915, "episode_reward_mean": 197.38159999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -337.5700000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 53.430799999999984, "predator_policy": 45.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [257.39, 170.5, 4.909999999999938, 26.970000000000557, -32.32000000000071, 231.86999999999915, 5.939999999999919, 200.89999999999964, -10.230000000000079, 208.05999999999972, 230.00999999999948, 6.919999999999918, -1.1600000000000632, 55.17999999999969, 169.28999999999994, 301.79, 164.31999999999994, 89.80000000000005, 25.890000000000597, 22.860000000000532, 446.0, -7.23000000000008, 95.78000000000007, 175.01999999999987, 446.09999999999997, 20.659999999999936, 467.39, 58.290000000000084, 375.90999999999997, 202.9999999999996, 18.95000000000044, 93.91000000000031, 204.98999999999958, 7.989999999999915, 228.62999999999948, 45.92999999999945, 167.77999999999986, 10.989999999999917, 211.84999999999962, 192.1299999999997, 347.9999999999989, 178.0799999999998, 229.74000000000012, 218.9399999999995, 393.0, 405.33, -71.60999999999915, 165.85999999999993, 466.37, 347.48, 277.0399999999997, 378.01, 404.25, 228.6500000000001, 115.00000000000009, 370.19, 360.14, 198.92999999999964, 203.95999999999958, 116.69000000000021, 151.08999999999997, 336.3699999999998, 237.2199999999994, 299.0099999999993, 249.60000000000005, 383.08000000000004, 453.38, 14.91999999999992, 340.7899999999988, 222.9799999999995, 28.95000000000053, 199.88999999999965, 478.07, 280.97999999999917, 294.97999999999956, 181.2399999999998, 39.399999999999395, 329.7199999999992, 172.26999999999964, 32.67000000000031, 134.20000000000041, 190.1299999999997, 148.45000000000027, 299.8999999999992, 449.46, 190.93999999999977, 6.639999999999928, 6.819999999999924, 340.23, 411.6100000000001, 35.68999999999995, 196.24999999999955, 206.96999999999946, 381.07, 164.92999999999995, 138.51999999999973, 395.85999999999973, 164.16999999999996, 27.7000000000005, 194.99999999999957], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [113.87, 124.51999999999998, 144.5, 2.0000000000000013, -14.080000000000041, -0.00999999999999836, 2.0000000000000013, -4.03000000000004, -28.14999999999971, -32.17000000000036, 135.65, 58.21999999999976, 2.0000000000000013, -10.060000000000041, 200.0, -18.099999999999703, -44.230000000000345, 2.0000000000000013, -0.00999999999999836, 79.06999999999998, 115.01, 2.0000000000000013, -2.020000000000041, -10.060000000000041, -20.109999999999705, -8.050000000000042, 20.810000000000283, -76.6299999999995, -8.050000000000042, 166.34, 124.60999999999999, 143.18, 147.32, 2.0000000000000013, 95.06, -50.260000000000346, 11.89999999999996, -0.00999999999999836, 2.0000000000000013, -26.13999999999971, 32.0, 131.0, -9.070000000000041, -30.159999999999712, 85.90999999999998, -24.129999999999708, 155.03, -0.00999999999999836, 59.06, 196.04000000000002, 16.85, -36.19000000000036, 173.0, -33.61, -140.71000000000024, 2.0000000000000013, -46.0, 94.90999999999998, 2.0000000000000013, 173.0, -4.030000000000042, -2.020000000000042, -16.090000000000032, 2.0000000000000013, -0.00999999999999836, 176.0, 2.0000000000000013, 2.98999999999998, -120.60999999999929, 173.24, -0.06999999999999948, 2.0000000000000013, 200.0, -243.22000000000023, -0.00999999999999836, 2.0000000000000013, -9.430000000000032, 139.28000000000003, 2.0000000000000013, 184.13, 44.0, 2.0000000000000013, -40.210000000000356, 171.29, 52.24999999999997, 151.49, -12.070000000000041, 199.01, 164.0, 176.0, 174.2, 187.13, -337.5700000000004, 5.960000000000002, 152.12, -50.26000000000033, 174.23000000000002, 156.14000000000001, 175.04, 147.44, 106.43000000000006, 133.60999999999973, 149.0, 115.00999999999999, -64.0, 175.25, 41.6, 165.05, 2.0000000000000013, -94.0, 182.0, 163.19, 175.07, 160.07, 173.06, -0.12999999999999834, -34.18000000000036, 186.14, 86.78000000000006, -16.0899999999997, -213.07000000000085, 184.15999999999997, 149.29999999999973, 154.07, 163.22, 2.0000000000000013, 158.18, -32.17000000000033, 144.26000000000005, 43.339999999999975, 153.08, 200.0, 101.0, 162.38, -11.080000000000041, 2.0000000000000013, 68.0, -16.20999999999972, -76.0, -2.0200000000000395, -8.050000000000042, 2.0000000000000013, -22.11999999999971, 199.01, 116.0, 31.070000000000007, -2.020000000000042, 128.0, 118.04000000000002, 103.93999999999991, 172.28, -6.040000000000042, -30.159999999999712, 21.560000000000244, 159.40999999999997, -136.690000000001, 152.2699999999999, 2.0000000000000013, -10.060000000000041, -4.270000000000037, -10.540000000000068, -50.26000000000029, 187.13, 2.0000000000000013, 2.0000000000000013, 119.45000000000012, -18.099999999999703, 77.0, 134.42, 1.039999999999992, 22.79000000000028, 131.14999999999998, -54.280000000000314, -14.08000000000003, 2.0000000000000013, -34.18000000000036, 153.20000000000002, 170.03, 167.0, 133.60999999999999, 2.0000000000000013, -0.3099999999997358, 1.6400000000000012, 136.61, 56.0, -4.030000000000042, 158.0, 184.07, -26.13999999999971, 160.07, 114.53000000000013, -0.00999999999999836, 98.50999999999999, 144.35000000000008, 159.41, -43.24000000000035, -49.30000000000034, 2.0000000000000013, 2.0000000000000013, 17.0], "policy_predator_policy_reward": [13.0, 6.0, 4.0, 20.0, 8.0, 11.0, 2.0, 27.0, 4.0, 24.0, 6.0, 32.0, 8.0, 6.0, 6.0, 13.0, 17.0, 15.0, 122.0, 7.0, 108.0, 5.0, 9.0, 10.0, 14.0, 13.0, 50.0, 61.0, 9.0, 2.0, 22.0, 12.0, 10.0, 5.0, 27.0, 18.0, 3.0, 11.0, 16.0, 31.0, 153.0, 130.0, 18.0, 14.0, 13.0, 21.0, 19.0, 1.0, 189.0, 2.0, 28.0, 12.0, 177.0, 151.0, 81.0, 116.0, 176.0, 151.0, 14.0, 14.0, 10.0, 15.0, 0.0, 108.0, 15.0, 14.0, 3.0, 0.0, 23.0, 153.0, 24.0, 20.0, 160.0, 51.0, 3.0, 6.0, 39.0, 43.0, 3.0, 3.0, 154.0, 148.0, 29.0, 18.0, 19.0, 7.0, 31.0, 1.0, 29.0, 24.0, 0.0, 44.0, 199.0, 61.0, 23.0, 41.0, 83.0, 53.0, 16.0, 9.0, 21.0, 16.0, 64.0, 50.0, 136.0, 157.0, 14.0, 8.0, 54.0, 153.0, 12.0, 13.0, 8.0, 17.0, 11.0, 15.0, 29.0, 23.0, 13.0, 33.0, 48.0, 132.0, 15.0, 18.0, 64.0, 8.0, 138.0, 35.0, 21.0, 41.0, 15.0, 15.0, 141.0, 49.0, 12.0, 12.0, 152.0, 137.0, 136.0, 165.0, 22.0, 13.0, 20.0, 3.0, 166.0, 165.0, 147.0, 8.0, 47.0, 26.0, 1.0, 14.0, 23.0, 25.0, 118.0, 189.0, 9.0, 9.0, 28.0, 19.0, 18.0, 177.0, 1.0, 0.0, 24.0, 3.0, 123.0, 118.0, 142.0, 172.0, 21.0, 16.0, 64.0, 11.0, 21.0, 18.0, 11.0, 6.0, 54.0, 57.0, 24.0, 10.0, 24.0, 34.0, 74.0, 81.0, 22.0, 17.0, 12.0, 19.0, 9.0, 15.0, 77.0, 76.0, 21.0, 27.0, 46.0, 29.0, 87.0, 89.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7206439821093804, "mean_inference_ms": 1.8908821614211033, "mean_action_processing_ms": 0.30121425460553086, "mean_env_wait_ms": 0.24571992257854075, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013084173202514648, "StateBufferConnector_ms": 0.00985252857208252, "ViewRequirementAgentConnector_ms": 0.14713895320892334}, "num_episodes": 23, "episode_return_max": 478.07, "episode_return_min": -71.60999999999915, "episode_return_mean": 197.38159999999985, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 361.80490903226337, "num_env_steps_trained_throughput_per_sec": 361.80490903226337, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 11508.595, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11508.539, "sample_time_ms": 1544.42, "learn_time_ms": 9946.207, "learn_throughput": 402.163, "synch_weights_time_ms": 16.053}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "0e60f_00000", "date": "2024-08-15_01-08-17", "timestamp": 1723664297, "time_this_iter_s": 11.113624095916748, "time_total_s": 715.810873746872, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a303b670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 715.810873746872, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 55.46875, "ram_util_percent": 83.5625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7505428633677265, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.090787807848088, "policy_loss": -0.005255665325328077, "vf_loss": 6.095425689283502, "vf_explained_var": 0.7142130527862165, "kl": 0.010982802085303438, "entropy": 0.6422194701023203, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7903870398720736, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5440802839697985, "policy_loss": -0.0076283384890606, "vf_loss": 1.5507113274758455, "vf_explained_var": 0.039169658996440745, "kl": 0.013297181645912638, "entropy": 0.9044059387275151, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 478.07, "episode_reward_min": -71.60999999999915, "episode_reward_mean": 218.2937999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -337.5700000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 63.37189999999999, "predator_policy": 45.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.890000000000597, 22.860000000000532, 446.0, -7.23000000000008, 95.78000000000007, 175.01999999999987, 446.09999999999997, 20.659999999999936, 467.39, 58.290000000000084, 375.90999999999997, 202.9999999999996, 18.95000000000044, 93.91000000000031, 204.98999999999958, 7.989999999999915, 228.62999999999948, 45.92999999999945, 167.77999999999986, 10.989999999999917, 211.84999999999962, 192.1299999999997, 347.9999999999989, 178.0799999999998, 229.74000000000012, 218.9399999999995, 393.0, 405.33, -71.60999999999915, 165.85999999999993, 466.37, 347.48, 277.0399999999997, 378.01, 404.25, 228.6500000000001, 115.00000000000009, 370.19, 360.14, 198.92999999999964, 203.95999999999958, 116.69000000000021, 151.08999999999997, 336.3699999999998, 237.2199999999994, 299.0099999999993, 249.60000000000005, 383.08000000000004, 453.38, 14.91999999999992, 340.7899999999988, 222.9799999999995, 28.95000000000053, 199.88999999999965, 478.07, 280.97999999999917, 294.97999999999956, 181.2399999999998, 39.399999999999395, 329.7199999999992, 172.26999999999964, 32.67000000000031, 134.20000000000041, 190.1299999999997, 148.45000000000027, 299.8999999999992, 449.46, 190.93999999999977, 6.639999999999928, 6.819999999999924, 340.23, 411.6100000000001, 35.68999999999995, 196.24999999999955, 206.96999999999946, 381.07, 164.92999999999995, 138.51999999999973, 395.85999999999973, 164.16999999999996, 27.7000000000005, 194.99999999999957, 176.3999999999999, 144.59000000000032, 193.22999999999928, -28.37999999999947, 370.4500000000001, 414.01, 247.57999999999984, 435.14, 202.92999999999955, 204.90999999999954, 156.42000000000002, 178.36999999999983, 177.95999999999975, 185.89999999999972, 178.0799999999998, 393.19, 323.72999999999973, 216.84999999999943], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.89999999999996, -0.00999999999999836, 2.0000000000000013, -26.13999999999971, 32.0, 131.0, -9.070000000000041, -30.159999999999712, 85.90999999999998, -24.129999999999708, 155.03, -0.00999999999999836, 59.06, 196.04000000000002, 16.85, -36.19000000000036, 173.0, -33.61, -140.71000000000024, 2.0000000000000013, -46.0, 94.90999999999998, 2.0000000000000013, 173.0, -4.030000000000042, -2.020000000000042, -16.090000000000032, 2.0000000000000013, -0.00999999999999836, 176.0, 2.0000000000000013, 2.98999999999998, -120.60999999999929, 173.24, -0.06999999999999948, 2.0000000000000013, 200.0, -243.22000000000023, -0.00999999999999836, 2.0000000000000013, -9.430000000000032, 139.28000000000003, 2.0000000000000013, 184.13, 44.0, 2.0000000000000013, -40.210000000000356, 171.29, 52.24999999999997, 151.49, -12.070000000000041, 199.01, 164.0, 176.0, 174.2, 187.13, -337.5700000000004, 5.960000000000002, 152.12, -50.26000000000033, 174.23000000000002, 156.14000000000001, 175.04, 147.44, 106.43000000000006, 133.60999999999973, 149.0, 115.00999999999999, -64.0, 175.25, 41.6, 165.05, 2.0000000000000013, -94.0, 182.0, 163.19, 175.07, 160.07, 173.06, -0.12999999999999834, -34.18000000000036, 186.14, 86.78000000000006, -16.0899999999997, -213.07000000000085, 184.15999999999997, 149.29999999999973, 154.07, 163.22, 2.0000000000000013, 158.18, -32.17000000000033, 144.26000000000005, 43.339999999999975, 153.08, 200.0, 101.0, 162.38, -11.080000000000041, 2.0000000000000013, 68.0, -16.20999999999972, -76.0, -2.0200000000000395, -8.050000000000042, 2.0000000000000013, -22.11999999999971, 199.01, 116.0, 31.070000000000007, -2.020000000000042, 128.0, 118.04000000000002, 103.93999999999991, 172.28, -6.040000000000042, -30.159999999999712, 21.560000000000244, 159.40999999999997, -136.690000000001, 152.2699999999999, 2.0000000000000013, -10.060000000000041, -4.270000000000037, -10.540000000000068, -50.26000000000029, 187.13, 2.0000000000000013, 2.0000000000000013, 119.45000000000012, -18.099999999999703, 77.0, 134.42, 1.039999999999992, 22.79000000000028, 131.14999999999998, -54.280000000000314, -14.08000000000003, 2.0000000000000013, -34.18000000000036, 153.20000000000002, 170.03, 167.0, 133.60999999999999, 2.0000000000000013, -0.3099999999997358, 1.6400000000000012, 136.61, 56.0, -4.030000000000042, 158.0, 184.07, -26.13999999999971, 160.07, 114.53000000000013, -0.00999999999999836, 98.50999999999999, 144.35000000000008, 159.41, -43.24000000000035, -49.30000000000034, 2.0000000000000013, 2.0000000000000013, 17.0, 152.42, -2.020000000000042, 8.929999999999959, 110.65999999999998, 168.23000000000013, 2.0000000000000013, -12.070000000000041, -60.310000000000336, 176.06, 149.39000000000007, 194.0, 199.01, 115.49000000000011, 92.09, 152.0, 165.14, 196.03999999999996, -20.109999999999705, 133.07, -30.159999999999712, 131.42000000000007, 2.0000000000000013, -2.020000000000042, 161.39, 177.22999999999996, -52.27000000000034, 65.89999999999998, 2.0000000000000013, 150.08, 2.0000000000000013, 183.17000000000002, 171.01999999999998, 123.56000000000017, 183.17000000000002, 194.06000000000003, -40.21000000000035], "policy_predator_policy_reward": [3.0, 11.0, 16.0, 31.0, 153.0, 130.0, 18.0, 14.0, 13.0, 21.0, 19.0, 1.0, 189.0, 2.0, 28.0, 12.0, 177.0, 151.0, 81.0, 116.0, 176.0, 151.0, 14.0, 14.0, 10.0, 15.0, 0.0, 108.0, 15.0, 14.0, 3.0, 0.0, 23.0, 153.0, 24.0, 20.0, 160.0, 51.0, 3.0, 6.0, 39.0, 43.0, 3.0, 3.0, 154.0, 148.0, 29.0, 18.0, 19.0, 7.0, 31.0, 1.0, 29.0, 24.0, 0.0, 44.0, 199.0, 61.0, 23.0, 41.0, 83.0, 53.0, 16.0, 9.0, 21.0, 16.0, 64.0, 50.0, 136.0, 157.0, 14.0, 8.0, 54.0, 153.0, 12.0, 13.0, 8.0, 17.0, 11.0, 15.0, 29.0, 23.0, 13.0, 33.0, 48.0, 132.0, 15.0, 18.0, 64.0, 8.0, 138.0, 35.0, 21.0, 41.0, 15.0, 15.0, 141.0, 49.0, 12.0, 12.0, 152.0, 137.0, 136.0, 165.0, 22.0, 13.0, 20.0, 3.0, 166.0, 165.0, 147.0, 8.0, 47.0, 26.0, 1.0, 14.0, 23.0, 25.0, 118.0, 189.0, 9.0, 9.0, 28.0, 19.0, 18.0, 177.0, 1.0, 0.0, 24.0, 3.0, 123.0, 118.0, 142.0, 172.0, 21.0, 16.0, 64.0, 11.0, 21.0, 18.0, 11.0, 6.0, 54.0, 57.0, 24.0, 10.0, 24.0, 34.0, 74.0, 81.0, 22.0, 17.0, 12.0, 19.0, 9.0, 15.0, 77.0, 76.0, 21.0, 27.0, 46.0, 29.0, 87.0, 89.0, 16.0, 10.0, 12.0, 13.0, 23.0, 0.0, 34.0, 10.0, 27.0, 18.0, 7.0, 14.0, 3.0, 37.0, 54.0, 64.0, 13.0, 14.0, 75.0, 27.0, 9.0, 14.0, 11.0, 8.0, 3.0, 50.0, 118.0, 0.0, 8.0, 18.0, 17.0, 22.0, 10.0, 7.0, 31.0, 32.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7207443277631014, "mean_inference_ms": 1.8920464784852138, "mean_action_processing_ms": 0.3012818941899487, "mean_env_wait_ms": 0.2458317474770355, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006662726402282715, "StateBufferConnector_ms": 0.0050811767578125, "ViewRequirementAgentConnector_ms": 0.13057732582092285}, "num_episodes": 18, "episode_return_max": 478.07, "episode_return_min": -71.60999999999915, "episode_return_mean": 218.2937999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 264.38395588726104, "num_env_steps_trained_throughput_per_sec": 264.38395588726104, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 11827.089, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11827.032, "sample_time_ms": 1589.373, "learn_time_ms": 10218.532, "learn_throughput": 391.446, "synch_weights_time_ms": 17.555}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "0e60f_00000", "date": "2024-08-15_01-08-33", "timestamp": 1723664313, "time_this_iter_s": 15.189576864242554, "time_total_s": 731.0004506111145, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fe0670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 731.0004506111145, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 79.94285714285715, "ram_util_percent": 83.12380952380953}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.785146085515855, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.517581391712976, "policy_loss": -0.0020213658408946775, "vf_loss": 5.51801063572919, "vf_explained_var": 0.8063213915421219, "kl": 0.02830428320814761, "entropy": 0.6872433281764783, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.665152346267902, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6377858041455506, "policy_loss": -0.003217775183951571, "vf_loss": 1.6405518974892046, "vf_explained_var": 0.12489745055556928, "kl": 0.006022426546794654, "entropy": 0.8215958159751993, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 478.07, "episode_reward_min": -71.60999999999915, "episode_reward_mean": 228.9003999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -337.5700000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 75.87019999999998, "predator_policy": 38.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [167.77999999999986, 10.989999999999917, 211.84999999999962, 192.1299999999997, 347.9999999999989, 178.0799999999998, 229.74000000000012, 218.9399999999995, 393.0, 405.33, -71.60999999999915, 165.85999999999993, 466.37, 347.48, 277.0399999999997, 378.01, 404.25, 228.6500000000001, 115.00000000000009, 370.19, 360.14, 198.92999999999964, 203.95999999999958, 116.69000000000021, 151.08999999999997, 336.3699999999998, 237.2199999999994, 299.0099999999993, 249.60000000000005, 383.08000000000004, 453.38, 14.91999999999992, 340.7899999999988, 222.9799999999995, 28.95000000000053, 199.88999999999965, 478.07, 280.97999999999917, 294.97999999999956, 181.2399999999998, 39.399999999999395, 329.7199999999992, 172.26999999999964, 32.67000000000031, 134.20000000000041, 190.1299999999997, 148.45000000000027, 299.8999999999992, 449.46, 190.93999999999977, 6.639999999999928, 6.819999999999924, 340.23, 411.6100000000001, 35.68999999999995, 196.24999999999955, 206.96999999999946, 381.07, 164.92999999999995, 138.51999999999973, 395.85999999999973, 164.16999999999996, 27.7000000000005, 194.99999999999957, 176.3999999999999, 144.59000000000032, 193.22999999999928, -28.37999999999947, 370.4500000000001, 414.01, 247.57999999999984, 435.14, 202.92999999999955, 204.90999999999954, 156.42000000000002, 178.36999999999983, 177.95999999999975, 185.89999999999972, 178.0799999999998, 393.19, 323.72999999999973, 216.84999999999943, 133.42000000000064, 173.4699999999998, 326.83, 5.989999999999917, 151.73999999999887, 333.28999999999985, 179.2699999999998, 94.95000000000012, 359.39999999999986, 189.01999999999973, 255.2199999999998, 419.04, 148.3800000000004, 357.3699999999999, 147.42000000000007, 181.1099999999998, 181.4599999999998, 353.3499999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, -243.22000000000023, -0.00999999999999836, 2.0000000000000013, -9.430000000000032, 139.28000000000003, 2.0000000000000013, 184.13, 44.0, 2.0000000000000013, -40.210000000000356, 171.29, 52.24999999999997, 151.49, -12.070000000000041, 199.01, 164.0, 176.0, 174.2, 187.13, -337.5700000000004, 5.960000000000002, 152.12, -50.26000000000033, 174.23000000000002, 156.14000000000001, 175.04, 147.44, 106.43000000000006, 133.60999999999973, 149.0, 115.00999999999999, -64.0, 175.25, 41.6, 165.05, 2.0000000000000013, -94.0, 182.0, 163.19, 175.07, 160.07, 173.06, -0.12999999999999834, -34.18000000000036, 186.14, 86.78000000000006, -16.0899999999997, -213.07000000000085, 184.15999999999997, 149.29999999999973, 154.07, 163.22, 2.0000000000000013, 158.18, -32.17000000000033, 144.26000000000005, 43.339999999999975, 153.08, 200.0, 101.0, 162.38, -11.080000000000041, 2.0000000000000013, 68.0, -16.20999999999972, -76.0, -2.0200000000000395, -8.050000000000042, 2.0000000000000013, -22.11999999999971, 199.01, 116.0, 31.070000000000007, -2.020000000000042, 128.0, 118.04000000000002, 103.93999999999991, 172.28, -6.040000000000042, -30.159999999999712, 21.560000000000244, 159.40999999999997, -136.690000000001, 152.2699999999999, 2.0000000000000013, -10.060000000000041, -4.270000000000037, -10.540000000000068, -50.26000000000029, 187.13, 2.0000000000000013, 2.0000000000000013, 119.45000000000012, -18.099999999999703, 77.0, 134.42, 1.039999999999992, 22.79000000000028, 131.14999999999998, -54.280000000000314, -14.08000000000003, 2.0000000000000013, -34.18000000000036, 153.20000000000002, 170.03, 167.0, 133.60999999999999, 2.0000000000000013, -0.3099999999997358, 1.6400000000000012, 136.61, 56.0, -4.030000000000042, 158.0, 184.07, -26.13999999999971, 160.07, 114.53000000000013, -0.00999999999999836, 98.50999999999999, 144.35000000000008, 159.41, -43.24000000000035, -49.30000000000034, 2.0000000000000013, 2.0000000000000013, 17.0, 152.42, -2.020000000000042, 8.929999999999959, 110.65999999999998, 168.23000000000013, 2.0000000000000013, -12.070000000000041, -60.310000000000336, 176.06, 149.39000000000007, 194.0, 199.01, 115.49000000000011, 92.09, 152.0, 165.14, 196.03999999999996, -20.109999999999705, 133.07, -30.159999999999712, 131.42000000000007, 2.0000000000000013, -2.020000000000042, 161.39, 177.22999999999996, -52.27000000000034, 65.89999999999998, 2.0000000000000013, 150.08, 2.0000000000000013, 183.17000000000002, 171.01999999999998, 123.56000000000017, 183.17000000000002, 194.06000000000003, -40.21000000000035, 20.719999999999963, 85.70000000000036, 2.0000000000000013, 132.47000000000014, 162.38, 155.45, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, 57.739999999999874, 176.0, 117.29, 167.26999999999998, 2.0000000000000013, -20.109999999999705, 95.06, 172.2500000000001, 182.15, -12.070000000000041, 155.09, 143.57000000000016, 81.65000000000006, 200.0, 196.04, 2.0000000000000013, 135.38000000000017, 169.25000000000003, 167.12000000000003, 121.52000000000004, -18.099999999999703, 175.22, -20.109999999999705, 154.46, 2.0000000000000013, 173.0, 165.34999999999997], "policy_predator_policy_reward": [160.0, 51.0, 3.0, 6.0, 39.0, 43.0, 3.0, 3.0, 154.0, 148.0, 29.0, 18.0, 19.0, 7.0, 31.0, 1.0, 29.0, 24.0, 0.0, 44.0, 199.0, 61.0, 23.0, 41.0, 83.0, 53.0, 16.0, 9.0, 21.0, 16.0, 64.0, 50.0, 136.0, 157.0, 14.0, 8.0, 54.0, 153.0, 12.0, 13.0, 8.0, 17.0, 11.0, 15.0, 29.0, 23.0, 13.0, 33.0, 48.0, 132.0, 15.0, 18.0, 64.0, 8.0, 138.0, 35.0, 21.0, 41.0, 15.0, 15.0, 141.0, 49.0, 12.0, 12.0, 152.0, 137.0, 136.0, 165.0, 22.0, 13.0, 20.0, 3.0, 166.0, 165.0, 147.0, 8.0, 47.0, 26.0, 1.0, 14.0, 23.0, 25.0, 118.0, 189.0, 9.0, 9.0, 28.0, 19.0, 18.0, 177.0, 1.0, 0.0, 24.0, 3.0, 123.0, 118.0, 142.0, 172.0, 21.0, 16.0, 64.0, 11.0, 21.0, 18.0, 11.0, 6.0, 54.0, 57.0, 24.0, 10.0, 24.0, 34.0, 74.0, 81.0, 22.0, 17.0, 12.0, 19.0, 9.0, 15.0, 77.0, 76.0, 21.0, 27.0, 46.0, 29.0, 87.0, 89.0, 16.0, 10.0, 12.0, 13.0, 23.0, 0.0, 34.0, 10.0, 27.0, 18.0, 7.0, 14.0, 3.0, 37.0, 54.0, 64.0, 13.0, 14.0, 75.0, 27.0, 9.0, 14.0, 11.0, 8.0, 3.0, 50.0, 118.0, 0.0, 8.0, 18.0, 17.0, 22.0, 10.0, 7.0, 31.0, 32.0, 17.0, 10.0, 32.0, 7.0, 7.0, 2.0, 4.0, 0.0, 38.0, 54.0, 23.0, 17.0, 5.0, 5.0, 7.0, 13.0, 1.0, 4.0, 17.0, 29.0, 4.0, 26.0, 17.0, 6.0, 11.0, 0.0, 12.0, 9.0, 20.0, 24.0, 23.0, 3.0, 11.0, 14.0, 4.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7211164496069403, "mean_inference_ms": 1.8939620788597182, "mean_action_processing_ms": 0.3014926083325024, "mean_env_wait_ms": 0.24600971109188915, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005135059356689453, "StateBufferConnector_ms": 0.005120038986206055, "ViewRequirementAgentConnector_ms": 0.1424185037612915}, "num_episodes": 18, "episode_return_max": 478.07, "episode_return_min": -71.60999999999915, "episode_return_mean": 228.9003999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 306.3499312953799, "num_env_steps_trained_throughput_per_sec": 306.3499312953799, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 12003.197, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12003.14, "sample_time_ms": 1675.478, "learn_time_ms": 10308.393, "learn_throughput": 388.033, "synch_weights_time_ms": 17.548}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "0e60f_00000", "date": "2024-08-15_01-08-46", "timestamp": 1723664326, "time_this_iter_s": 13.091771841049194, "time_total_s": 744.0922224521637, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a301aee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 744.0922224521637, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 75.73157894736842, "ram_util_percent": 83.10526315789474}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2724306150718974, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.260633646495759, "policy_loss": -0.012635880040261087, "vf_loss": 5.269679386149008, "vf_explained_var": 0.5366785889580137, "kl": 0.042549869267235925, "entropy": 0.740427557217381, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8621649032862728, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.096731391123363, "policy_loss": -0.0045810105045025465, "vf_loss": 2.1007856504311637, "vf_explained_var": 0.18385004486356463, "kl": 0.007023374048282024, "entropy": 0.8037755530347269, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 478.07, "episode_reward_min": -575.9300000000001, "episode_reward_mean": 203.7654999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 63.85775, "predator_policy": 38.025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [203.95999999999958, 116.69000000000021, 151.08999999999997, 336.3699999999998, 237.2199999999994, 299.0099999999993, 249.60000000000005, 383.08000000000004, 453.38, 14.91999999999992, 340.7899999999988, 222.9799999999995, 28.95000000000053, 199.88999999999965, 478.07, 280.97999999999917, 294.97999999999956, 181.2399999999998, 39.399999999999395, 329.7199999999992, 172.26999999999964, 32.67000000000031, 134.20000000000041, 190.1299999999997, 148.45000000000027, 299.8999999999992, 449.46, 190.93999999999977, 6.639999999999928, 6.819999999999924, 340.23, 411.6100000000001, 35.68999999999995, 196.24999999999955, 206.96999999999946, 381.07, 164.92999999999995, 138.51999999999973, 395.85999999999973, 164.16999999999996, 27.7000000000005, 194.99999999999957, 176.3999999999999, 144.59000000000032, 193.22999999999928, -28.37999999999947, 370.4500000000001, 414.01, 247.57999999999984, 435.14, 202.92999999999955, 204.90999999999954, 156.42000000000002, 178.36999999999983, 177.95999999999975, 185.89999999999972, 178.0799999999998, 393.19, 323.72999999999973, 216.84999999999943, 133.42000000000064, 173.4699999999998, 326.83, 5.989999999999917, 151.73999999999887, 333.28999999999985, 179.2699999999998, 94.95000000000012, 359.39999999999986, 189.01999999999973, 255.2199999999998, 419.04, 148.3800000000004, 357.3699999999999, 147.42000000000007, 181.1099999999998, 181.4599999999998, 353.3499999999999, 148.52000000000055, 200.91999999999962, 11.799999999999919, 365.1299999999999, 21.31000000000009, 164.43999999999994, 165.81999999999974, 176.18999999999988, 183.14999999999992, 233.9999999999995, 165.2599999999996, 162.48999999999995, 30.98000000000058, -575.9300000000001, -3.200000000000081, 17.910000000000256, 399.98999999999893, 175.23999999999987, 210.02999999999963, 347.47999999999996, 209.95999999999952, 271.16999999999933], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-34.18000000000036, 186.14, 86.78000000000006, -16.0899999999997, -213.07000000000085, 184.15999999999997, 149.29999999999973, 154.07, 163.22, 2.0000000000000013, 158.18, -32.17000000000033, 144.26000000000005, 43.339999999999975, 153.08, 200.0, 101.0, 162.38, -11.080000000000041, 2.0000000000000013, 68.0, -16.20999999999972, -76.0, -2.0200000000000395, -8.050000000000042, 2.0000000000000013, -22.11999999999971, 199.01, 116.0, 31.070000000000007, -2.020000000000042, 128.0, 118.04000000000002, 103.93999999999991, 172.28, -6.040000000000042, -30.159999999999712, 21.560000000000244, 159.40999999999997, -136.690000000001, 152.2699999999999, 2.0000000000000013, -10.060000000000041, -4.270000000000037, -10.540000000000068, -50.26000000000029, 187.13, 2.0000000000000013, 2.0000000000000013, 119.45000000000012, -18.099999999999703, 77.0, 134.42, 1.039999999999992, 22.79000000000028, 131.14999999999998, -54.280000000000314, -14.08000000000003, 2.0000000000000013, -34.18000000000036, 153.20000000000002, 170.03, 167.0, 133.60999999999999, 2.0000000000000013, -0.3099999999997358, 1.6400000000000012, 136.61, 56.0, -4.030000000000042, 158.0, 184.07, -26.13999999999971, 160.07, 114.53000000000013, -0.00999999999999836, 98.50999999999999, 144.35000000000008, 159.41, -43.24000000000035, -49.30000000000034, 2.0000000000000013, 2.0000000000000013, 17.0, 152.42, -2.020000000000042, 8.929999999999959, 110.65999999999998, 168.23000000000013, 2.0000000000000013, -12.070000000000041, -60.310000000000336, 176.06, 149.39000000000007, 194.0, 199.01, 115.49000000000011, 92.09, 152.0, 165.14, 196.03999999999996, -20.109999999999705, 133.07, -30.159999999999712, 131.42000000000007, 2.0000000000000013, -2.020000000000042, 161.39, 177.22999999999996, -52.27000000000034, 65.89999999999998, 2.0000000000000013, 150.08, 2.0000000000000013, 183.17000000000002, 171.01999999999998, 123.56000000000017, 183.17000000000002, 194.06000000000003, -40.21000000000035, 20.719999999999963, 85.70000000000036, 2.0000000000000013, 132.47000000000014, 162.38, 155.45, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, 57.739999999999874, 176.0, 117.29, 167.26999999999998, 2.0000000000000013, -20.109999999999705, 95.06, 172.2500000000001, 182.15, -12.070000000000041, 155.09, 143.57000000000016, 81.65000000000006, 200.0, 196.04, 2.0000000000000013, 135.38000000000017, 169.25000000000003, 167.12000000000003, 121.52000000000004, -18.099999999999703, 175.22, -20.109999999999705, 154.46, 2.0000000000000013, 173.0, 165.34999999999997, 118.61, -16.0899999999997, -14.080000000000041, 200.0, -24.129999999999715, -12.070000000000041, 127.13000000000005, -7.0, -96.48999999999928, -38.20000000000035, 143.45, -0.00999999999999836, -0.00999999999999836, -32.16999999999986, 2.0000000000000013, 136.19, 2.0000000000000013, 173.1500000000001, 2.0, 2.0000000000000013, 2.0000000000000013, -128.7400000000002, 2.0000000000000013, 148.49, -2.0200000000000395, 2.0000000000000013, -385.93, -400.0, -6.040000000000042, -30.159999999999712, 8.929999999999959, -2.020000000000042, -0.00999999999999836, 200.0, 2.0000000000000013, 161.24, -14.080000000000041, 189.11000000000007, 199.01, 129.47, -8.050000000000042, 169.01, 84.17000000000039, 161.0], "policy_predator_policy_reward": [29.0, 23.0, 13.0, 33.0, 48.0, 132.0, 15.0, 18.0, 64.0, 8.0, 138.0, 35.0, 21.0, 41.0, 15.0, 15.0, 141.0, 49.0, 12.0, 12.0, 152.0, 137.0, 136.0, 165.0, 22.0, 13.0, 20.0, 3.0, 166.0, 165.0, 147.0, 8.0, 47.0, 26.0, 1.0, 14.0, 23.0, 25.0, 118.0, 189.0, 9.0, 9.0, 28.0, 19.0, 18.0, 177.0, 1.0, 0.0, 24.0, 3.0, 123.0, 118.0, 142.0, 172.0, 21.0, 16.0, 64.0, 11.0, 21.0, 18.0, 11.0, 6.0, 54.0, 57.0, 24.0, 10.0, 24.0, 34.0, 74.0, 81.0, 22.0, 17.0, 12.0, 19.0, 9.0, 15.0, 77.0, 76.0, 21.0, 27.0, 46.0, 29.0, 87.0, 89.0, 16.0, 10.0, 12.0, 13.0, 23.0, 0.0, 34.0, 10.0, 27.0, 18.0, 7.0, 14.0, 3.0, 37.0, 54.0, 64.0, 13.0, 14.0, 75.0, 27.0, 9.0, 14.0, 11.0, 8.0, 3.0, 50.0, 118.0, 0.0, 8.0, 18.0, 17.0, 22.0, 10.0, 7.0, 31.0, 32.0, 17.0, 10.0, 32.0, 7.0, 7.0, 2.0, 4.0, 0.0, 38.0, 54.0, 23.0, 17.0, 5.0, 5.0, 7.0, 13.0, 1.0, 4.0, 17.0, 29.0, 4.0, 26.0, 17.0, 6.0, 11.0, 0.0, 12.0, 9.0, 20.0, 24.0, 23.0, 3.0, 11.0, 14.0, 4.0, 11.0, 22.0, 24.0, 4.0, 11.0, 24.0, 24.0, 121.0, 124.0, 61.0, 95.0, 13.0, 8.0, 5.0, 193.0, 29.0, 9.0, 6.0, 2.0, 122.0, 108.0, 148.0, 144.0, 0.0, 12.0, 16.0, 15.0, 10.0, 200.0, 18.0, 15.0, 3.0, 8.0, 0.0, 200.0, 4.0, 8.0, 18.0, 17.0, 16.0, 3.0, 41.0, 8.0, 15.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7211317622256798, "mean_inference_ms": 1.8953151678876319, "mean_action_processing_ms": 0.30149424190244917, "mean_env_wait_ms": 0.24606624972551658, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006269335746765137, "StateBufferConnector_ms": 0.005948305130004883, "ViewRequirementAgentConnector_ms": 0.1494966745376587}, "num_episodes": 22, "episode_return_max": 478.07, "episode_return_min": -575.9300000000001, "episode_return_mean": 203.7654999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 343.0263980737282, "num_env_steps_trained_throughput_per_sec": 343.0263980737282, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 12062.178, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12062.114, "sample_time_ms": 1679.6, "learn_time_ms": 10363.184, "learn_throughput": 385.982, "synch_weights_time_ms": 17.54}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "0e60f_00000", "date": "2024-08-15_01-08-57", "timestamp": 1723664337, "time_this_iter_s": 11.724366903305054, "time_total_s": 755.8165893554688, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2af99d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 755.8165893554688, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 60.787499999999994, "ram_util_percent": 83.6375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.3761623968523016, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.1241781471898316, "policy_loss": -0.0025230477620704623, "vf_loss": 7.124349758107826, "vf_explained_var": 0.5390911522050383, "kl": 0.01857924210062139, "entropy": 0.5812614341103841, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.09364770136813, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4773063356283482, "policy_loss": -0.002879715816576093, "vf_loss": 2.4797105215844653, "vf_explained_var": 0.015085868293015415, "kl": 0.006340449146444448, "entropy": 0.8501122894110503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 545.1299999999999, "episode_reward_min": -575.9300000000001, "episode_reward_mean": 220.03389999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 77.93195000000001, "predator_policy": 32.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [190.1299999999997, 148.45000000000027, 299.8999999999992, 449.46, 190.93999999999977, 6.639999999999928, 6.819999999999924, 340.23, 411.6100000000001, 35.68999999999995, 196.24999999999955, 206.96999999999946, 381.07, 164.92999999999995, 138.51999999999973, 395.85999999999973, 164.16999999999996, 27.7000000000005, 194.99999999999957, 176.3999999999999, 144.59000000000032, 193.22999999999928, -28.37999999999947, 370.4500000000001, 414.01, 247.57999999999984, 435.14, 202.92999999999955, 204.90999999999954, 156.42000000000002, 178.36999999999983, 177.95999999999975, 185.89999999999972, 178.0799999999998, 393.19, 323.72999999999973, 216.84999999999943, 133.42000000000064, 173.4699999999998, 326.83, 5.989999999999917, 151.73999999999887, 333.28999999999985, 179.2699999999998, 94.95000000000012, 359.39999999999986, 189.01999999999973, 255.2199999999998, 419.04, 148.3800000000004, 357.3699999999999, 147.42000000000007, 181.1099999999998, 181.4599999999998, 353.3499999999999, 148.52000000000055, 200.91999999999962, 11.799999999999919, 365.1299999999999, 21.31000000000009, 164.43999999999994, 165.81999999999974, 176.18999999999988, 183.14999999999992, 233.9999999999995, 165.2599999999996, 162.48999999999995, 30.98000000000058, -575.9300000000001, -3.200000000000081, 17.910000000000256, 399.98999999999893, 175.23999999999987, 210.02999999999963, 347.47999999999996, 209.95999999999952, 271.16999999999933, 284.89999999999986, 367.2, 173.90999999999985, 160.89, 303.98, 370.03, 126.91000000000025, 348.47999999999996, 176.00999999999988, 329.65, 378.2399999999999, 371.2799999999999, 434.50999999999976, 157.36, 293.0799999999998, 545.1299999999999, 382.2499999999999, 346.5799999999998, 247.9399999999998, 339.37, 356.85999999999984, 223.9999999999994, 89.74000000000008], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [187.13, 2.0000000000000013, 2.0000000000000013, 119.45000000000012, -18.099999999999703, 77.0, 134.42, 1.039999999999992, 22.79000000000028, 131.14999999999998, -54.280000000000314, -14.08000000000003, 2.0000000000000013, -34.18000000000036, 153.20000000000002, 170.03, 167.0, 133.60999999999999, 2.0000000000000013, -0.3099999999997358, 1.6400000000000012, 136.61, 56.0, -4.030000000000042, 158.0, 184.07, -26.13999999999971, 160.07, 114.53000000000013, -0.00999999999999836, 98.50999999999999, 144.35000000000008, 159.41, -43.24000000000035, -49.30000000000034, 2.0000000000000013, 2.0000000000000013, 17.0, 152.42, -2.020000000000042, 8.929999999999959, 110.65999999999998, 168.23000000000013, 2.0000000000000013, -12.070000000000041, -60.310000000000336, 176.06, 149.39000000000007, 194.0, 199.01, 115.49000000000011, 92.09, 152.0, 165.14, 196.03999999999996, -20.109999999999705, 133.07, -30.159999999999712, 131.42000000000007, 2.0000000000000013, -2.020000000000042, 161.39, 177.22999999999996, -52.27000000000034, 65.89999999999998, 2.0000000000000013, 150.08, 2.0000000000000013, 183.17000000000002, 171.01999999999998, 123.56000000000017, 183.17000000000002, 194.06000000000003, -40.21000000000035, 20.719999999999963, 85.70000000000036, 2.0000000000000013, 132.47000000000014, 162.38, 155.45, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, 57.739999999999874, 176.0, 117.29, 167.26999999999998, 2.0000000000000013, -20.109999999999705, 95.06, 172.2500000000001, 182.15, -12.070000000000041, 155.09, 143.57000000000016, 81.65000000000006, 200.0, 196.04, 2.0000000000000013, 135.38000000000017, 169.25000000000003, 167.12000000000003, 121.52000000000004, -18.099999999999703, 175.22, -20.109999999999705, 154.46, 2.0000000000000013, 173.0, 165.34999999999997, 118.61, -16.0899999999997, -14.080000000000041, 200.0, -24.129999999999715, -12.070000000000041, 127.13000000000005, -7.0, -96.48999999999928, -38.20000000000035, 143.45, -0.00999999999999836, -0.00999999999999836, -32.16999999999986, 2.0000000000000013, 136.19, 2.0000000000000013, 173.1500000000001, 2.0, 2.0000000000000013, 2.0000000000000013, -128.7400000000002, 2.0000000000000013, 148.49, -2.0200000000000395, 2.0000000000000013, -385.93, -400.0, -6.040000000000042, -30.159999999999712, 8.929999999999959, -2.020000000000042, -0.00999999999999836, 200.0, 2.0000000000000013, 161.24, -14.080000000000041, 189.11000000000007, 199.01, 129.47, -8.050000000000042, 169.01, 84.17000000000039, 161.0, 167.32999999999998, 71.56999999999988, 165.02, 173.18, -16.0899999999997, 161.0, -58.30000000000034, 181.19, 140.42, 141.56, 147.01999999999998, 181.01, 2.0000000000000013, 103.91, 153.47, 181.01, -2.020000000000042, 155.03000000000003, 170.3, 147.35, 146.24000000000007, 200.0, 163.19, 143.08999999999992, 127.36999999999995, 177.14, 111.44000000000007, -14.080000000000041, 151.49000000000004, 132.59000000000003, 122.05999999999999, 193.07, 166.25000000000006, 179.0, 167.3299999999998, 166.25, -124.0, -7.060000000000041, 171.2, 147.17000000000002, 161.0, 87.86000000000007, 2.0000000000000013, 116.0, 62.83999999999984, -18.099999999999707], "policy_predator_policy_reward": [1.0, 0.0, 24.0, 3.0, 123.0, 118.0, 142.0, 172.0, 21.0, 16.0, 64.0, 11.0, 21.0, 18.0, 11.0, 6.0, 54.0, 57.0, 24.0, 10.0, 24.0, 34.0, 74.0, 81.0, 22.0, 17.0, 12.0, 19.0, 9.0, 15.0, 77.0, 76.0, 21.0, 27.0, 46.0, 29.0, 87.0, 89.0, 16.0, 10.0, 12.0, 13.0, 23.0, 0.0, 34.0, 10.0, 27.0, 18.0, 7.0, 14.0, 3.0, 37.0, 54.0, 64.0, 13.0, 14.0, 75.0, 27.0, 9.0, 14.0, 11.0, 8.0, 3.0, 50.0, 118.0, 0.0, 8.0, 18.0, 17.0, 22.0, 10.0, 7.0, 31.0, 32.0, 17.0, 10.0, 32.0, 7.0, 7.0, 2.0, 4.0, 0.0, 38.0, 54.0, 23.0, 17.0, 5.0, 5.0, 7.0, 13.0, 1.0, 4.0, 17.0, 29.0, 4.0, 26.0, 17.0, 6.0, 11.0, 0.0, 12.0, 9.0, 20.0, 24.0, 23.0, 3.0, 11.0, 14.0, 4.0, 11.0, 22.0, 24.0, 4.0, 11.0, 24.0, 24.0, 121.0, 124.0, 61.0, 95.0, 13.0, 8.0, 5.0, 193.0, 29.0, 9.0, 6.0, 2.0, 122.0, 108.0, 148.0, 144.0, 0.0, 12.0, 16.0, 15.0, 10.0, 200.0, 18.0, 15.0, 3.0, 8.0, 0.0, 200.0, 4.0, 8.0, 18.0, 17.0, 16.0, 3.0, 41.0, 8.0, 15.0, 11.0, 20.0, 26.0, 9.0, 20.0, 13.0, 16.0, 3.0, 35.0, 17.0, 5.0, 20.0, 22.0, 10.0, 11.0, 3.0, 11.0, 5.0, 18.0, 8.0, 4.0, 16.0, 16.0, 42.0, 23.0, 52.0, 78.0, 32.0, 28.0, 6.0, 3.0, 177.0, 53.0, 27.0, 10.0, 5.0, 8.0, 200.0, 179.0, 17.0, 4.0, 67.0, 41.0, 56.0, 50.0, 16.0, 29.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7223222559223088, "mean_inference_ms": 1.897914127684121, "mean_action_processing_ms": 0.30206319320595826, "mean_env_wait_ms": 0.24658825767528356, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006295561790466309, "StateBufferConnector_ms": 0.006028652191162109, "ViewRequirementAgentConnector_ms": 0.15441393852233887}, "num_episodes": 23, "episode_return_max": 545.1299999999999, "episode_return_min": -575.9300000000001, "episode_return_mean": 220.03389999999987, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.07665300897725, "num_env_steps_trained_throughput_per_sec": 350.07665300897725, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 12056.352, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12056.286, "sample_time_ms": 1679.214, "learn_time_ms": 10357.737, "learn_throughput": 386.185, "synch_weights_time_ms": 17.568}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "0e60f_00000", "date": "2024-08-15_01-09-09", "timestamp": 1723664349, "time_this_iter_s": 11.514505863189697, "time_total_s": 767.3310952186584, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a30a23a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 767.3310952186584, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 58.23529411764706, "ram_util_percent": 83.61764705882354}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.635987341025519, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.1162530994919875, "policy_loss": -0.006294194880932097, "vf_loss": 7.121146470024472, "vf_explained_var": 0.7062237083281159, "kl": 0.011068359824888055, "entropy": 0.6821112670595684, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7795631129274923, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8089702720679934, "policy_loss": -0.00294923154617507, "vf_loss": 1.811391425227362, "vf_explained_var": 0.05861018634347058, "kl": 0.0070411190754165265, "entropy": 0.7943097022160021, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 545.1299999999999, "episode_reward_min": -575.9300000000001, "episode_reward_mean": 229.3681999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 83.73410000000004, "predator_policy": 30.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [194.99999999999957, 176.3999999999999, 144.59000000000032, 193.22999999999928, -28.37999999999947, 370.4500000000001, 414.01, 247.57999999999984, 435.14, 202.92999999999955, 204.90999999999954, 156.42000000000002, 178.36999999999983, 177.95999999999975, 185.89999999999972, 178.0799999999998, 393.19, 323.72999999999973, 216.84999999999943, 133.42000000000064, 173.4699999999998, 326.83, 5.989999999999917, 151.73999999999887, 333.28999999999985, 179.2699999999998, 94.95000000000012, 359.39999999999986, 189.01999999999973, 255.2199999999998, 419.04, 148.3800000000004, 357.3699999999999, 147.42000000000007, 181.1099999999998, 181.4599999999998, 353.3499999999999, 148.52000000000055, 200.91999999999962, 11.799999999999919, 365.1299999999999, 21.31000000000009, 164.43999999999994, 165.81999999999974, 176.18999999999988, 183.14999999999992, 233.9999999999995, 165.2599999999996, 162.48999999999995, 30.98000000000058, -575.9300000000001, -3.200000000000081, 17.910000000000256, 399.98999999999893, 175.23999999999987, 210.02999999999963, 347.47999999999996, 209.95999999999952, 271.16999999999933, 284.89999999999986, 367.2, 173.90999999999985, 160.89, 303.98, 370.03, 126.91000000000025, 348.47999999999996, 176.00999999999988, 329.65, 378.2399999999999, 371.2799999999999, 434.50999999999976, 157.36, 293.0799999999998, 545.1299999999999, 382.2499999999999, 346.5799999999998, 247.9399999999998, 339.37, 356.85999999999984, 223.9999999999994, 89.74000000000008, 112.66000000000065, 273.7399999999993, 330.59999999999985, 48.27999999999986, 136.84999999999903, 252.3700000000003, 410.0999999999997, 233.3899999999994, 384.89999999999964, 347.3799999999997, 216.76999999999936, 304.48999999999984, 284.89, 242.51999999999992, 34.90000000000022, 334.59999999999974, 345.9399999999995, 394.38999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.0000000000000013, 17.0, 152.42, -2.020000000000042, 8.929999999999959, 110.65999999999998, 168.23000000000013, 2.0000000000000013, -12.070000000000041, -60.310000000000336, 176.06, 149.39000000000007, 194.0, 199.01, 115.49000000000011, 92.09, 152.0, 165.14, 196.03999999999996, -20.109999999999705, 133.07, -30.159999999999712, 131.42000000000007, 2.0000000000000013, -2.020000000000042, 161.39, 177.22999999999996, -52.27000000000034, 65.89999999999998, 2.0000000000000013, 150.08, 2.0000000000000013, 183.17000000000002, 171.01999999999998, 123.56000000000017, 183.17000000000002, 194.06000000000003, -40.21000000000035, 20.719999999999963, 85.70000000000036, 2.0000000000000013, 132.47000000000014, 162.38, 155.45, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, 57.739999999999874, 176.0, 117.29, 167.26999999999998, 2.0000000000000013, -20.109999999999705, 95.06, 172.2500000000001, 182.15, -12.070000000000041, 155.09, 143.57000000000016, 81.65000000000006, 200.0, 196.04, 2.0000000000000013, 135.38000000000017, 169.25000000000003, 167.12000000000003, 121.52000000000004, -18.099999999999703, 175.22, -20.109999999999705, 154.46, 2.0000000000000013, 173.0, 165.34999999999997, 118.61, -16.0899999999997, -14.080000000000041, 200.0, -24.129999999999715, -12.070000000000041, 127.13000000000005, -7.0, -96.48999999999928, -38.20000000000035, 143.45, -0.00999999999999836, -0.00999999999999836, -32.16999999999986, 2.0000000000000013, 136.19, 2.0000000000000013, 173.1500000000001, 2.0, 2.0000000000000013, 2.0000000000000013, -128.7400000000002, 2.0000000000000013, 148.49, -2.0200000000000395, 2.0000000000000013, -385.93, -400.0, -6.040000000000042, -30.159999999999712, 8.929999999999959, -2.020000000000042, -0.00999999999999836, 200.0, 2.0000000000000013, 161.24, -14.080000000000041, 189.11000000000007, 199.01, 129.47, -8.050000000000042, 169.01, 84.17000000000039, 161.0, 167.32999999999998, 71.56999999999988, 165.02, 173.18, -16.0899999999997, 161.0, -58.30000000000034, 181.19, 140.42, 141.56, 147.01999999999998, 181.01, 2.0000000000000013, 103.91, 153.47, 181.01, -2.020000000000042, 155.03000000000003, 170.3, 147.35, 146.24000000000007, 200.0, 163.19, 143.08999999999992, 127.36999999999995, 177.14, 111.44000000000007, -14.080000000000041, 151.49000000000004, 132.59000000000003, 122.05999999999999, 193.07, 166.25000000000006, 179.0, 167.3299999999998, 166.25, -124.0, -7.060000000000041, 171.2, 147.17000000000002, 161.0, 87.86000000000007, 2.0000000000000013, 116.0, 62.83999999999984, -18.099999999999707, 29.809999999999924, -28.149999999999714, 127.37000000000013, 121.37000000000019, 147.23000000000008, 163.37, -74.38000000000001, -66.3400000000001, 100.85000000000032, 2.0000000000000013, 113.50999999999999, 108.85999999999989, 111.5900000000002, 98.50999999999996, 82.64000000000033, 113.74999999999999, 148.52000000000004, 150.3800000000001, 178.01, 154.36999999999992, -0.009999999999998581, -42.22000000000009, 120.41000000000008, 153.07999999999998, 100.78999999999999, 160.1, 107.87, 117.65000000000012, -18.099999999999728, 2.0000000000000013, 188.06, 131.54000000000002, 117.52999999999992, 153.41000000000008, 187.12999999999997, 174.25999999999976], "policy_predator_policy_reward": [87.0, 89.0, 16.0, 10.0, 12.0, 13.0, 23.0, 0.0, 34.0, 10.0, 27.0, 18.0, 7.0, 14.0, 3.0, 37.0, 54.0, 64.0, 13.0, 14.0, 75.0, 27.0, 9.0, 14.0, 11.0, 8.0, 3.0, 50.0, 118.0, 0.0, 8.0, 18.0, 17.0, 22.0, 10.0, 7.0, 31.0, 32.0, 17.0, 10.0, 32.0, 7.0, 7.0, 2.0, 4.0, 0.0, 38.0, 54.0, 23.0, 17.0, 5.0, 5.0, 7.0, 13.0, 1.0, 4.0, 17.0, 29.0, 4.0, 26.0, 17.0, 6.0, 11.0, 0.0, 12.0, 9.0, 20.0, 24.0, 23.0, 3.0, 11.0, 14.0, 4.0, 11.0, 22.0, 24.0, 4.0, 11.0, 24.0, 24.0, 121.0, 124.0, 61.0, 95.0, 13.0, 8.0, 5.0, 193.0, 29.0, 9.0, 6.0, 2.0, 122.0, 108.0, 148.0, 144.0, 0.0, 12.0, 16.0, 15.0, 10.0, 200.0, 18.0, 15.0, 3.0, 8.0, 0.0, 200.0, 4.0, 8.0, 18.0, 17.0, 16.0, 3.0, 41.0, 8.0, 15.0, 11.0, 20.0, 26.0, 9.0, 20.0, 13.0, 16.0, 3.0, 35.0, 17.0, 5.0, 20.0, 22.0, 10.0, 11.0, 3.0, 11.0, 5.0, 18.0, 8.0, 4.0, 16.0, 16.0, 42.0, 23.0, 52.0, 78.0, 32.0, 28.0, 6.0, 3.0, 177.0, 53.0, 27.0, 10.0, 5.0, 8.0, 200.0, 179.0, 17.0, 4.0, 67.0, 41.0, 56.0, 50.0, 16.0, 29.0, 66.0, 45.0, 8.0, 17.0, 7.0, 13.0, 10.0, 179.0, 28.0, 6.0, 18.0, 12.0, 101.0, 99.0, 16.0, 21.0, 29.0, 57.0, 8.0, 7.0, 98.0, 161.0, 11.0, 20.0, 10.0, 14.0, 7.0, 10.0, 13.0, 38.0, 13.0, 2.0, 63.0, 12.0, 2.0, 31.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7227920691474853, "mean_inference_ms": 1.9004668913530987, "mean_action_processing_ms": 0.3017642009497803, "mean_env_wait_ms": 0.24641755169898402, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005211830139160156, "StateBufferConnector_ms": 0.006291866302490234, "ViewRequirementAgentConnector_ms": 0.14527833461761475}, "num_episodes": 18, "episode_return_max": 545.1299999999999, "episode_return_min": -575.9300000000001, "episode_return_mean": 229.3681999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.7754480391974, "num_env_steps_trained_throughput_per_sec": 340.7754480391974, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 12087.045, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12086.978, "sample_time_ms": 1608.025, "learn_time_ms": 10459.182, "learn_throughput": 382.439, "synch_weights_time_ms": 17.753}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "0e60f_00000", "date": "2024-08-15_01-09-21", "timestamp": 1723664361, "time_this_iter_s": 11.792309045791626, "time_total_s": 779.1234042644501, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a3030c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 779.1234042644501, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 61.45625, "ram_util_percent": 83.53125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.416687867439613, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.313795377085449, "policy_loss": 0.004805200997611912, "vf_loss": 6.304321671289111, "vf_explained_var": 0.7681142250066081, "kl": 0.03688702076780525, "entropy": 0.8185541180706529, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9467888729597527, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.747752075409763, "policy_loss": -0.0031886702105304392, "vf_loss": 1.7505258033515285, "vf_explained_var": 0.250563750065193, "kl": 0.005532632593012746, "entropy": 0.8581143323075835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 545.1299999999999, "episode_reward_min": -575.9300000000001, "episode_reward_mean": 237.56679999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 87.38840000000003, "predator_policy": 31.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [216.84999999999943, 133.42000000000064, 173.4699999999998, 326.83, 5.989999999999917, 151.73999999999887, 333.28999999999985, 179.2699999999998, 94.95000000000012, 359.39999999999986, 189.01999999999973, 255.2199999999998, 419.04, 148.3800000000004, 357.3699999999999, 147.42000000000007, 181.1099999999998, 181.4599999999998, 353.3499999999999, 148.52000000000055, 200.91999999999962, 11.799999999999919, 365.1299999999999, 21.31000000000009, 164.43999999999994, 165.81999999999974, 176.18999999999988, 183.14999999999992, 233.9999999999995, 165.2599999999996, 162.48999999999995, 30.98000000000058, -575.9300000000001, -3.200000000000081, 17.910000000000256, 399.98999999999893, 175.23999999999987, 210.02999999999963, 347.47999999999996, 209.95999999999952, 271.16999999999933, 284.89999999999986, 367.2, 173.90999999999985, 160.89, 303.98, 370.03, 126.91000000000025, 348.47999999999996, 176.00999999999988, 329.65, 378.2399999999999, 371.2799999999999, 434.50999999999976, 157.36, 293.0799999999998, 545.1299999999999, 382.2499999999999, 346.5799999999998, 247.9399999999998, 339.37, 356.85999999999984, 223.9999999999994, 89.74000000000008, 112.66000000000065, 273.7399999999993, 330.59999999999985, 48.27999999999986, 136.84999999999903, 252.3700000000003, 410.0999999999997, 233.3899999999994, 384.89999999999964, 347.3799999999997, 216.76999999999936, 304.48999999999984, 284.89, 242.51999999999992, 34.90000000000022, 334.59999999999974, 345.9399999999995, 394.38999999999976, 126.78000000000065, 362.17999999999984, 317.7399999999996, 351.2999999999997, 146.50000000000048, 318.82999999999987, 231.12000000000018, -26.579999999999607, 190.02999999999966, 330.91999999999905, 359.17999999999995, 236.8299999999993, 320.46999999999963, 310.5499999999997, 325.42999999999984, 349.4899999999997, 321.5899999999999, 397.01], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [194.06000000000003, -40.21000000000035, 20.719999999999963, 85.70000000000036, 2.0000000000000013, 132.47000000000014, 162.38, 155.45, 2.0000000000000013, -0.00999999999999836, 2.0000000000000013, 57.739999999999874, 176.0, 117.29, 167.26999999999998, 2.0000000000000013, -20.109999999999705, 95.06, 172.2500000000001, 182.15, -12.070000000000041, 155.09, 143.57000000000016, 81.65000000000006, 200.0, 196.04, 2.0000000000000013, 135.38000000000017, 169.25000000000003, 167.12000000000003, 121.52000000000004, -18.099999999999703, 175.22, -20.109999999999705, 154.46, 2.0000000000000013, 173.0, 165.34999999999997, 118.61, -16.0899999999997, -14.080000000000041, 200.0, -24.129999999999715, -12.070000000000041, 127.13000000000005, -7.0, -96.48999999999928, -38.20000000000035, 143.45, -0.00999999999999836, -0.00999999999999836, -32.16999999999986, 2.0000000000000013, 136.19, 2.0000000000000013, 173.1500000000001, 2.0, 2.0000000000000013, 2.0000000000000013, -128.7400000000002, 2.0000000000000013, 148.49, -2.0200000000000395, 2.0000000000000013, -385.93, -400.0, -6.040000000000042, -30.159999999999712, 8.929999999999959, -2.020000000000042, -0.00999999999999836, 200.0, 2.0000000000000013, 161.24, -14.080000000000041, 189.11000000000007, 199.01, 129.47, -8.050000000000042, 169.01, 84.17000000000039, 161.0, 167.32999999999998, 71.56999999999988, 165.02, 173.18, -16.0899999999997, 161.0, -58.30000000000034, 181.19, 140.42, 141.56, 147.01999999999998, 181.01, 2.0000000000000013, 103.91, 153.47, 181.01, -2.020000000000042, 155.03000000000003, 170.3, 147.35, 146.24000000000007, 200.0, 163.19, 143.08999999999992, 127.36999999999995, 177.14, 111.44000000000007, -14.080000000000041, 151.49000000000004, 132.59000000000003, 122.05999999999999, 193.07, 166.25000000000006, 179.0, 167.3299999999998, 166.25, -124.0, -7.060000000000041, 171.2, 147.17000000000002, 161.0, 87.86000000000007, 2.0000000000000013, 116.0, 62.83999999999984, -18.099999999999707, 29.809999999999924, -28.149999999999714, 127.37000000000013, 121.37000000000019, 147.23000000000008, 163.37, -74.38000000000001, -66.3400000000001, 100.85000000000032, 2.0000000000000013, 113.50999999999999, 108.85999999999989, 111.5900000000002, 98.50999999999996, 82.64000000000033, 113.74999999999999, 148.52000000000004, 150.3800000000001, 178.01, 154.36999999999992, -0.009999999999998581, -42.22000000000009, 120.41000000000008, 153.07999999999998, 100.78999999999999, 160.1, 107.87, 117.65000000000012, -18.099999999999728, 2.0000000000000013, 188.06, 131.54000000000002, 117.52999999999992, 153.41000000000008, 187.12999999999997, 174.25999999999976, 2.0000000000000013, -42.220000000000354, 164.1500000000001, 176.03, 175.24999999999994, 88.49000000000021, 176.0, 158.30000000000013, 2.0000000000000013, 135.50000000000026, 187.04, 121.79000000000006, -22.029999999999518, 185.15, -36.19000000000036, -76.38999999999918, 167.02999999999997, 2.0000000000000013, -18.0999999999998, 198.02, 170.14999999999998, 170.03, 140.0, -32.170000000000364, 108.47000000000006, 182.0, 121.31000000000016, 167.24, 144.20000000000002, 159.2299999999998, 122.39000000000009, 121.1, 145.19, 94.39999999999993, 197.0, 184.01], "policy_predator_policy_reward": [31.0, 32.0, 17.0, 10.0, 32.0, 7.0, 7.0, 2.0, 4.0, 0.0, 38.0, 54.0, 23.0, 17.0, 5.0, 5.0, 7.0, 13.0, 1.0, 4.0, 17.0, 29.0, 4.0, 26.0, 17.0, 6.0, 11.0, 0.0, 12.0, 9.0, 20.0, 24.0, 23.0, 3.0, 11.0, 14.0, 4.0, 11.0, 22.0, 24.0, 4.0, 11.0, 24.0, 24.0, 121.0, 124.0, 61.0, 95.0, 13.0, 8.0, 5.0, 193.0, 29.0, 9.0, 6.0, 2.0, 122.0, 108.0, 148.0, 144.0, 0.0, 12.0, 16.0, 15.0, 10.0, 200.0, 18.0, 15.0, 3.0, 8.0, 0.0, 200.0, 4.0, 8.0, 18.0, 17.0, 16.0, 3.0, 41.0, 8.0, 15.0, 11.0, 20.0, 26.0, 9.0, 20.0, 13.0, 16.0, 3.0, 35.0, 17.0, 5.0, 20.0, 22.0, 10.0, 11.0, 3.0, 11.0, 5.0, 18.0, 8.0, 4.0, 16.0, 16.0, 42.0, 23.0, 52.0, 78.0, 32.0, 28.0, 6.0, 3.0, 177.0, 53.0, 27.0, 10.0, 5.0, 8.0, 200.0, 179.0, 17.0, 4.0, 67.0, 41.0, 56.0, 50.0, 16.0, 29.0, 66.0, 45.0, 8.0, 17.0, 7.0, 13.0, 10.0, 179.0, 28.0, 6.0, 18.0, 12.0, 101.0, 99.0, 16.0, 21.0, 29.0, 57.0, 8.0, 7.0, 98.0, 161.0, 11.0, 20.0, 10.0, 14.0, 7.0, 10.0, 13.0, 38.0, 13.0, 2.0, 63.0, 12.0, 2.0, 31.0, 0.0, 167.0, 11.0, 11.0, 26.0, 28.0, 5.0, 12.0, 6.0, 3.0, 5.0, 5.0, 60.0, 8.0, 38.0, 48.0, 11.0, 10.0, 144.0, 7.0, 10.0, 9.0, 84.0, 45.0, 18.0, 12.0, 17.0, 5.0, 3.0, 19.0, 61.0, 45.0, 32.0, 50.0, 8.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7231491829481905, "mean_inference_ms": 1.9013386966269445, "mean_action_processing_ms": 0.30177763752304804, "mean_env_wait_ms": 0.24644773478406062, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005069851875305176, "StateBufferConnector_ms": 0.005285143852233887, "ViewRequirementAgentConnector_ms": 0.1379169225692749}, "num_episodes": 18, "episode_return_max": 545.1299999999999, "episode_return_min": -575.9300000000001, "episode_return_mean": 237.56679999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.54985911533026, "num_env_steps_trained_throughput_per_sec": 350.54985911533026, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 11999.231, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11999.166, "sample_time_ms": 1528.225, "learn_time_ms": 10453.531, "learn_throughput": 382.646, "synch_weights_time_ms": 15.568}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "0e60f_00000", "date": "2024-08-15_01-09-32", "timestamp": 1723664372, "time_this_iter_s": 11.454181909561157, "time_total_s": 790.5775861740112, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bc01f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 790.5775861740112, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 60.529411764705884, "ram_util_percent": 83.34705882352942}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.262846987619602, "cur_kl_coeff": 0.18984375000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.323154533224762, "policy_loss": -0.0008786930345373337, "vf_loss": 6.3195277274601045, "vf_explained_var": 0.7885800048157021, "kl": 0.02373271606858134, "entropy": 0.826158935083914, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.580022718382891, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2031678270410606, "policy_loss": -0.004224454604394774, "vf_loss": 3.206707146811107, "vf_explained_var": 0.13904380022533355, "kl": 0.009135158471400078, "entropy": 0.8024171980915877, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 561.0699999999999, "episode_reward_min": -575.9300000000001, "episode_reward_mean": 262.5803999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 94.4852, "predator_policy": 36.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [365.1299999999999, 21.31000000000009, 164.43999999999994, 165.81999999999974, 176.18999999999988, 183.14999999999992, 233.9999999999995, 165.2599999999996, 162.48999999999995, 30.98000000000058, -575.9300000000001, -3.200000000000081, 17.910000000000256, 399.98999999999893, 175.23999999999987, 210.02999999999963, 347.47999999999996, 209.95999999999952, 271.16999999999933, 284.89999999999986, 367.2, 173.90999999999985, 160.89, 303.98, 370.03, 126.91000000000025, 348.47999999999996, 176.00999999999988, 329.65, 378.2399999999999, 371.2799999999999, 434.50999999999976, 157.36, 293.0799999999998, 545.1299999999999, 382.2499999999999, 346.5799999999998, 247.9399999999998, 339.37, 356.85999999999984, 223.9999999999994, 89.74000000000008, 112.66000000000065, 273.7399999999993, 330.59999999999985, 48.27999999999986, 136.84999999999903, 252.3700000000003, 410.0999999999997, 233.3899999999994, 384.89999999999964, 347.3799999999997, 216.76999999999936, 304.48999999999984, 284.89, 242.51999999999992, 34.90000000000022, 334.59999999999974, 345.9399999999995, 394.38999999999976, 126.78000000000065, 362.17999999999984, 317.7399999999996, 351.2999999999997, 146.50000000000048, 318.82999999999987, 231.12000000000018, -26.579999999999607, 190.02999999999966, 330.91999999999905, 359.17999999999995, 236.8299999999993, 320.46999999999963, 310.5499999999997, 325.42999999999984, 349.4899999999997, 321.5899999999999, 397.01, 271.9599999999991, 561.0699999999999, 386.34999999999985, 288.76, 411.23, 186.8799999999997, 436.18, 478.3499999999998, 418.3999999999999, 183.43999999999994, 265.37999999999965, 411.19, 360.6, 181.17999999999984, 366.26, 387.03, 212.06999999999928, 153.64000000000016, 155.70999999999998, 406.12, 172.35999999999967, 376.02], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [127.13000000000005, -7.0, -96.48999999999928, -38.20000000000035, 143.45, -0.00999999999999836, -0.00999999999999836, -32.16999999999986, 2.0000000000000013, 136.19, 2.0000000000000013, 173.1500000000001, 2.0, 2.0000000000000013, 2.0000000000000013, -128.7400000000002, 2.0000000000000013, 148.49, -2.0200000000000395, 2.0000000000000013, -385.93, -400.0, -6.040000000000042, -30.159999999999712, 8.929999999999959, -2.020000000000042, -0.00999999999999836, 200.0, 2.0000000000000013, 161.24, -14.080000000000041, 189.11000000000007, 199.01, 129.47, -8.050000000000042, 169.01, 84.17000000000039, 161.0, 167.32999999999998, 71.56999999999988, 165.02, 173.18, -16.0899999999997, 161.0, -58.30000000000034, 181.19, 140.42, 141.56, 147.01999999999998, 181.01, 2.0000000000000013, 103.91, 153.47, 181.01, -2.020000000000042, 155.03000000000003, 170.3, 147.35, 146.24000000000007, 200.0, 163.19, 143.08999999999992, 127.36999999999995, 177.14, 111.44000000000007, -14.080000000000041, 151.49000000000004, 132.59000000000003, 122.05999999999999, 193.07, 166.25000000000006, 179.0, 167.3299999999998, 166.25, -124.0, -7.060000000000041, 171.2, 147.17000000000002, 161.0, 87.86000000000007, 2.0000000000000013, 116.0, 62.83999999999984, -18.099999999999707, 29.809999999999924, -28.149999999999714, 127.37000000000013, 121.37000000000019, 147.23000000000008, 163.37, -74.38000000000001, -66.3400000000001, 100.85000000000032, 2.0000000000000013, 113.50999999999999, 108.85999999999989, 111.5900000000002, 98.50999999999996, 82.64000000000033, 113.74999999999999, 148.52000000000004, 150.3800000000001, 178.01, 154.36999999999992, -0.009999999999998581, -42.22000000000009, 120.41000000000008, 153.07999999999998, 100.78999999999999, 160.1, 107.87, 117.65000000000012, -18.099999999999728, 2.0000000000000013, 188.06, 131.54000000000002, 117.52999999999992, 153.41000000000008, 187.12999999999997, 174.25999999999976, 2.0000000000000013, -42.220000000000354, 164.1500000000001, 176.03, 175.24999999999994, 88.49000000000021, 176.0, 158.30000000000013, 2.0000000000000013, 135.50000000000026, 187.04, 121.79000000000006, -22.029999999999518, 185.15, -36.19000000000036, -76.38999999999918, 167.02999999999997, 2.0000000000000013, -18.0999999999998, 198.02, 170.14999999999998, 170.03, 140.0, -32.170000000000364, 108.47000000000006, 182.0, 121.31000000000016, 167.24, 144.20000000000002, 159.2299999999998, 122.39000000000009, 121.1, 145.19, 94.39999999999993, 197.0, 184.01, -18.099999999999795, 167.06, 184.01, 122.06, 158.09, 174.25999999999988, 132.35000000000005, 132.41000000000005, 159.23, 164.0, 165.01999999999998, -26.13999999999971, 185.15, 161.03, 142.16, 178.1900000000001, 109.37000000000005, 182.02999999999997, 153.47000000000003, -4.030000000000003, -62.32000000000033, 58.69999999999986, 193.03999999999996, 179.15, 170.3, 170.3, 2.0000000000000013, 173.18, 174.26, 176.0, 191.0, 170.02999999999997, -18.099999999999728, 180.16999999999985, 160.22, -87.57999999999979, 79.79000000000006, -14.080000000000005, 175.1, 195.01999999999998, 2.0000000000000013, 164.3599999999999, 83.0, 192.02], "policy_predator_policy_reward": [121.0, 124.0, 61.0, 95.0, 13.0, 8.0, 5.0, 193.0, 29.0, 9.0, 6.0, 2.0, 122.0, 108.0, 148.0, 144.0, 0.0, 12.0, 16.0, 15.0, 10.0, 200.0, 18.0, 15.0, 3.0, 8.0, 0.0, 200.0, 4.0, 8.0, 18.0, 17.0, 16.0, 3.0, 41.0, 8.0, 15.0, 11.0, 20.0, 26.0, 9.0, 20.0, 13.0, 16.0, 3.0, 35.0, 17.0, 5.0, 20.0, 22.0, 10.0, 11.0, 3.0, 11.0, 5.0, 18.0, 8.0, 4.0, 16.0, 16.0, 42.0, 23.0, 52.0, 78.0, 32.0, 28.0, 6.0, 3.0, 177.0, 53.0, 27.0, 10.0, 5.0, 8.0, 200.0, 179.0, 17.0, 4.0, 67.0, 41.0, 56.0, 50.0, 16.0, 29.0, 66.0, 45.0, 8.0, 17.0, 7.0, 13.0, 10.0, 179.0, 28.0, 6.0, 18.0, 12.0, 101.0, 99.0, 16.0, 21.0, 29.0, 57.0, 8.0, 7.0, 98.0, 161.0, 11.0, 20.0, 10.0, 14.0, 7.0, 10.0, 13.0, 38.0, 13.0, 2.0, 63.0, 12.0, 2.0, 31.0, 0.0, 167.0, 11.0, 11.0, 26.0, 28.0, 5.0, 12.0, 6.0, 3.0, 5.0, 5.0, 60.0, 8.0, 38.0, 48.0, 11.0, 10.0, 144.0, 7.0, 10.0, 9.0, 84.0, 45.0, 18.0, 12.0, 17.0, 5.0, 3.0, 19.0, 61.0, 45.0, 32.0, 50.0, 8.0, 8.0, 13.0, 110.0, 133.0, 122.0, 43.0, 11.0, 13.0, 11.0, 37.0, 51.0, 34.0, 14.0, 39.0, 51.0, 141.0, 17.0, 54.0, 73.0, 23.0, 11.0, 200.0, 69.0, 33.0, 6.0, 7.0, 13.0, 2.0, 4.0, 6.0, 10.0, 15.0, 11.0, 19.0, 31.0, 0.0, 81.0, 70.0, 20.0, 28.0, 8.0, 4.0, 2.0, 43.0, 58.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7224044031758207, "mean_inference_ms": 1.8995372735279332, "mean_action_processing_ms": 0.3006068845049407, "mean_env_wait_ms": 0.2461891817249421, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004656553268432617, "StateBufferConnector_ms": 0.0052443742752075195, "ViewRequirementAgentConnector_ms": 0.11782896518707275}, "num_episodes": 22, "episode_return_max": 561.0699999999999, "episode_return_min": -575.9300000000001, "episode_return_mean": 262.5803999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 358.97807103797203, "num_env_steps_trained_throughput_per_sec": 358.97807103797203, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 11948.863, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11948.803, "sample_time_ms": 1470.406, "learn_time_ms": 10462.075, "learn_throughput": 382.333, "synch_weights_time_ms": 14.469}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "0e60f_00000", "date": "2024-08-15_01-09-44", "timestamp": 1723664384, "time_this_iter_s": 11.188533067703247, "time_total_s": 801.7661192417145, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a3119e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 801.7661192417145, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 59.66, "ram_util_percent": 83.34}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.650158442580511, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.197454929856396, "policy_loss": -0.004433928104733467, "vf_loss": 6.198092540105184, "vf_explained_var": -0.29878802271116345, "kl": 0.013331415798105883, "entropy": 0.7760545493749084, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.30615901921792, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.981460362641269, "policy_loss": -0.00612399277878462, "vf_loss": 3.9870068639674514, "vf_explained_var": 0.028192735096764943, "kl": 0.007699857994936698, "entropy": 0.8325120156088834, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 561.0699999999999, "episode_reward_min": -26.579999999999607, "episode_reward_mean": 296.70119999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -124.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 112.46060000000001, "predator_policy": 35.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [271.16999999999933, 284.89999999999986, 367.2, 173.90999999999985, 160.89, 303.98, 370.03, 126.91000000000025, 348.47999999999996, 176.00999999999988, 329.65, 378.2399999999999, 371.2799999999999, 434.50999999999976, 157.36, 293.0799999999998, 545.1299999999999, 382.2499999999999, 346.5799999999998, 247.9399999999998, 339.37, 356.85999999999984, 223.9999999999994, 89.74000000000008, 112.66000000000065, 273.7399999999993, 330.59999999999985, 48.27999999999986, 136.84999999999903, 252.3700000000003, 410.0999999999997, 233.3899999999994, 384.89999999999964, 347.3799999999997, 216.76999999999936, 304.48999999999984, 284.89, 242.51999999999992, 34.90000000000022, 334.59999999999974, 345.9399999999995, 394.38999999999976, 126.78000000000065, 362.17999999999984, 317.7399999999996, 351.2999999999997, 146.50000000000048, 318.82999999999987, 231.12000000000018, -26.579999999999607, 190.02999999999966, 330.91999999999905, 359.17999999999995, 236.8299999999993, 320.46999999999963, 310.5499999999997, 325.42999999999984, 349.4899999999997, 321.5899999999999, 397.01, 271.9599999999991, 561.0699999999999, 386.34999999999985, 288.76, 411.23, 186.8799999999997, 436.18, 478.3499999999998, 418.3999999999999, 183.43999999999994, 265.37999999999965, 411.19, 360.6, 181.17999999999984, 366.26, 387.03, 212.06999999999928, 153.64000000000016, 155.70999999999998, 406.12, 172.35999999999967, 376.02, 439.0, 340.52, 214.12000000000018, 453.4599999999999, 372.3099999999997, 310.1, 348.4099999999999, 413.5999999999998, 216.05999999999938, 315.43999999999977, 235.10999999999973, 242.25000000000026, 204.8499999999999, 431.3299999999999, 385.3899999999999, 379.2199999999998, 251.5699999999993, 309.5899999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [84.17000000000039, 161.0, 167.32999999999998, 71.56999999999988, 165.02, 173.18, -16.0899999999997, 161.0, -58.30000000000034, 181.19, 140.42, 141.56, 147.01999999999998, 181.01, 2.0000000000000013, 103.91, 153.47, 181.01, -2.020000000000042, 155.03000000000003, 170.3, 147.35, 146.24000000000007, 200.0, 163.19, 143.08999999999992, 127.36999999999995, 177.14, 111.44000000000007, -14.080000000000041, 151.49000000000004, 132.59000000000003, 122.05999999999999, 193.07, 166.25000000000006, 179.0, 167.3299999999998, 166.25, -124.0, -7.060000000000041, 171.2, 147.17000000000002, 161.0, 87.86000000000007, 2.0000000000000013, 116.0, 62.83999999999984, -18.099999999999707, 29.809999999999924, -28.149999999999714, 127.37000000000013, 121.37000000000019, 147.23000000000008, 163.37, -74.38000000000001, -66.3400000000001, 100.85000000000032, 2.0000000000000013, 113.50999999999999, 108.85999999999989, 111.5900000000002, 98.50999999999996, 82.64000000000033, 113.74999999999999, 148.52000000000004, 150.3800000000001, 178.01, 154.36999999999992, -0.009999999999998581, -42.22000000000009, 120.41000000000008, 153.07999999999998, 100.78999999999999, 160.1, 107.87, 117.65000000000012, -18.099999999999728, 2.0000000000000013, 188.06, 131.54000000000002, 117.52999999999992, 153.41000000000008, 187.12999999999997, 174.25999999999976, 2.0000000000000013, -42.220000000000354, 164.1500000000001, 176.03, 175.24999999999994, 88.49000000000021, 176.0, 158.30000000000013, 2.0000000000000013, 135.50000000000026, 187.04, 121.79000000000006, -22.029999999999518, 185.15, -36.19000000000036, -76.38999999999918, 167.02999999999997, 2.0000000000000013, -18.0999999999998, 198.02, 170.14999999999998, 170.03, 140.0, -32.170000000000364, 108.47000000000006, 182.0, 121.31000000000016, 167.24, 144.20000000000002, 159.2299999999998, 122.39000000000009, 121.1, 145.19, 94.39999999999993, 197.0, 184.01, -18.099999999999795, 167.06, 184.01, 122.06, 158.09, 174.25999999999988, 132.35000000000005, 132.41000000000005, 159.23, 164.0, 165.01999999999998, -26.13999999999971, 185.15, 161.03, 142.16, 178.1900000000001, 109.37000000000005, 182.02999999999997, 153.47000000000003, -4.030000000000003, -62.32000000000033, 58.69999999999986, 193.03999999999996, 179.15, 170.3, 170.3, 2.0000000000000013, 173.18, 174.26, 176.0, 191.0, 170.02999999999997, -18.099999999999728, 180.16999999999985, 160.22, -87.57999999999979, 79.79000000000006, -14.080000000000005, 175.1, 195.01999999999998, 2.0000000000000013, 164.3599999999999, 83.0, 192.02, 68.0, 188.0, 151.37, 173.15, -1.90000000000021, 165.02, 179.20999999999998, 112.25000000000001, 126.02000000000001, 153.29000000000013, 58.100000000000016, 100.99999999999999, 156.4099999999999, 179.0, 127.19000000000001, 159.41, 185.05999999999995, 2.0000000000000013, 140.18000000000006, 63.25999999999995, -8.830000000000027, 79.94000000000007, 23.89999999999982, 162.35000000000002, 1.6100000000002517, 176.23999999999995, 160.25, 156.08, 173.21000000000004, 167.18, 136.2199999999998, 179.0, 181.07, -98.49999999999973, 195.04999999999995, 74.53999999999989], "policy_predator_policy_reward": [15.0, 11.0, 20.0, 26.0, 9.0, 20.0, 13.0, 16.0, 3.0, 35.0, 17.0, 5.0, 20.0, 22.0, 10.0, 11.0, 3.0, 11.0, 5.0, 18.0, 8.0, 4.0, 16.0, 16.0, 42.0, 23.0, 52.0, 78.0, 32.0, 28.0, 6.0, 3.0, 177.0, 53.0, 27.0, 10.0, 5.0, 8.0, 200.0, 179.0, 17.0, 4.0, 67.0, 41.0, 56.0, 50.0, 16.0, 29.0, 66.0, 45.0, 8.0, 17.0, 7.0, 13.0, 10.0, 179.0, 28.0, 6.0, 18.0, 12.0, 101.0, 99.0, 16.0, 21.0, 29.0, 57.0, 8.0, 7.0, 98.0, 161.0, 11.0, 20.0, 10.0, 14.0, 7.0, 10.0, 13.0, 38.0, 13.0, 2.0, 63.0, 12.0, 2.0, 31.0, 0.0, 167.0, 11.0, 11.0, 26.0, 28.0, 5.0, 12.0, 6.0, 3.0, 5.0, 5.0, 60.0, 8.0, 38.0, 48.0, 11.0, 10.0, 144.0, 7.0, 10.0, 9.0, 84.0, 45.0, 18.0, 12.0, 17.0, 5.0, 3.0, 19.0, 61.0, 45.0, 32.0, 50.0, 8.0, 8.0, 13.0, 110.0, 133.0, 122.0, 43.0, 11.0, 13.0, 11.0, 37.0, 51.0, 34.0, 14.0, 39.0, 51.0, 141.0, 17.0, 54.0, 73.0, 23.0, 11.0, 200.0, 69.0, 33.0, 6.0, 7.0, 13.0, 2.0, 4.0, 6.0, 10.0, 15.0, 11.0, 19.0, 31.0, 0.0, 81.0, 70.0, 20.0, 28.0, 8.0, 4.0, 2.0, 43.0, 58.0, 98.0, 85.0, 8.0, 8.0, 15.0, 36.0, 7.0, 155.0, 45.0, 48.0, 70.0, 81.0, 10.0, 3.0, 65.0, 62.0, 9.0, 20.0, 56.0, 56.0, 130.0, 34.0, 32.0, 24.0, 8.0, 19.0, 68.0, 47.0, 36.0, 9.0, 55.0, 9.0, 160.0, 9.0, 30.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7219105437916808, "mean_inference_ms": 1.896274600547108, "mean_action_processing_ms": 0.3006855457284166, "mean_env_wait_ms": 0.2457998702312836, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004217982292175293, "StateBufferConnector_ms": 0.005135297775268555, "ViewRequirementAgentConnector_ms": 0.11739635467529297}, "num_episodes": 18, "episode_return_max": 561.0699999999999, "episode_return_min": -26.579999999999607, "episode_return_mean": 296.70119999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 359.8624187990033, "num_env_steps_trained_throughput_per_sec": 359.8624187990033, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 11907.914, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11907.853, "sample_time_ms": 1455.014, "learn_time_ms": 10436.62, "learn_throughput": 383.266, "synch_weights_time_ms": 14.334}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "0e60f_00000", "date": "2024-08-15_01-09-55", "timestamp": 1723664395, "time_this_iter_s": 11.15195894241333, "time_total_s": 812.9180781841278, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bc0c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 812.9180781841278, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 55.68749999999999, "ram_util_percent": 82.9}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7200259140874974, "cur_kl_coeff": 0.28476562499999986, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.323351427360818, "policy_loss": 0.0028411501060146348, "vf_loss": 5.313798929522277, "vf_explained_var": -0.08947249237822477, "kl": 0.023567929240971976, "entropy": 0.7977920073996145, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.218351260947172, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5398849689140524, "policy_loss": -0.005735749280001357, "vf_loss": 3.545027920051857, "vf_explained_var": 0.002678118212513192, "kl": 0.007904149544444291, "entropy": 0.737296053940657, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 613.1899999999998, "episode_reward_min": -26.579999999999607, "episode_reward_mean": 309.2728999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -98.49999999999973, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 115.43645000000001, "predator_policy": 39.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [89.74000000000008, 112.66000000000065, 273.7399999999993, 330.59999999999985, 48.27999999999986, 136.84999999999903, 252.3700000000003, 410.0999999999997, 233.3899999999994, 384.89999999999964, 347.3799999999997, 216.76999999999936, 304.48999999999984, 284.89, 242.51999999999992, 34.90000000000022, 334.59999999999974, 345.9399999999995, 394.38999999999976, 126.78000000000065, 362.17999999999984, 317.7399999999996, 351.2999999999997, 146.50000000000048, 318.82999999999987, 231.12000000000018, -26.579999999999607, 190.02999999999966, 330.91999999999905, 359.17999999999995, 236.8299999999993, 320.46999999999963, 310.5499999999997, 325.42999999999984, 349.4899999999997, 321.5899999999999, 397.01, 271.9599999999991, 561.0699999999999, 386.34999999999985, 288.76, 411.23, 186.8799999999997, 436.18, 478.3499999999998, 418.3999999999999, 183.43999999999994, 265.37999999999965, 411.19, 360.6, 181.17999999999984, 366.26, 387.03, 212.06999999999928, 153.64000000000016, 155.70999999999998, 406.12, 172.35999999999967, 376.02, 439.0, 340.52, 214.12000000000018, 453.4599999999999, 372.3099999999997, 310.1, 348.4099999999999, 413.5999999999998, 216.05999999999938, 315.43999999999977, 235.10999999999973, 242.25000000000026, 204.8499999999999, 431.3299999999999, 385.3899999999999, 379.2199999999998, 251.5699999999993, 309.5899999999999, 333.4299999999997, 376.10999999999996, 259.67999999999995, 312.57000000000005, 613.1899999999998, 251.78000000000006, 431.16999999999996, 357.13, 398.3699999999998, 362.21, 296.44, 395.6599999999998, 232.78, 345.54, 338.7300000000001, 384.07000000000005, 378.7000000000001, 465.13, 361.36, 368.23, 292.93, 400.52, 291.1699999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [62.83999999999984, -18.099999999999707, 29.809999999999924, -28.149999999999714, 127.37000000000013, 121.37000000000019, 147.23000000000008, 163.37, -74.38000000000001, -66.3400000000001, 100.85000000000032, 2.0000000000000013, 113.50999999999999, 108.85999999999989, 111.5900000000002, 98.50999999999996, 82.64000000000033, 113.74999999999999, 148.52000000000004, 150.3800000000001, 178.01, 154.36999999999992, -0.009999999999998581, -42.22000000000009, 120.41000000000008, 153.07999999999998, 100.78999999999999, 160.1, 107.87, 117.65000000000012, -18.099999999999728, 2.0000000000000013, 188.06, 131.54000000000002, 117.52999999999992, 153.41000000000008, 187.12999999999997, 174.25999999999976, 2.0000000000000013, -42.220000000000354, 164.1500000000001, 176.03, 175.24999999999994, 88.49000000000021, 176.0, 158.30000000000013, 2.0000000000000013, 135.50000000000026, 187.04, 121.79000000000006, -22.029999999999518, 185.15, -36.19000000000036, -76.38999999999918, 167.02999999999997, 2.0000000000000013, -18.0999999999998, 198.02, 170.14999999999998, 170.03, 140.0, -32.170000000000364, 108.47000000000006, 182.0, 121.31000000000016, 167.24, 144.20000000000002, 159.2299999999998, 122.39000000000009, 121.1, 145.19, 94.39999999999993, 197.0, 184.01, -18.099999999999795, 167.06, 184.01, 122.06, 158.09, 174.25999999999988, 132.35000000000005, 132.41000000000005, 159.23, 164.0, 165.01999999999998, -26.13999999999971, 185.15, 161.03, 142.16, 178.1900000000001, 109.37000000000005, 182.02999999999997, 153.47000000000003, -4.030000000000003, -62.32000000000033, 58.69999999999986, 193.03999999999996, 179.15, 170.3, 170.3, 2.0000000000000013, 173.18, 174.26, 176.0, 191.0, 170.02999999999997, -18.099999999999728, 180.16999999999985, 160.22, -87.57999999999979, 79.79000000000006, -14.080000000000005, 175.1, 195.01999999999998, 2.0000000000000013, 164.3599999999999, 83.0, 192.02, 68.0, 188.0, 151.37, 173.15, -1.90000000000021, 165.02, 179.20999999999998, 112.25000000000001, 126.02000000000001, 153.29000000000013, 58.100000000000016, 100.99999999999999, 156.4099999999999, 179.0, 127.19000000000001, 159.41, 185.05999999999995, 2.0000000000000013, 140.18000000000006, 63.25999999999995, -8.830000000000027, 79.94000000000007, 23.89999999999982, 162.35000000000002, 1.6100000000002517, 176.23999999999995, 160.25, 156.08, 173.21000000000004, 167.18, 136.2199999999998, 179.0, 181.07, -98.49999999999973, 195.04999999999995, 74.53999999999989, 87.05000000000001, 141.37999999999988, 173.0, 183.10999999999999, 36.679999999999886, 176.0, 78.23000000000005, 166.34, 193.04, 104.14999999999999, -58.0, 122.78, 177.01999999999998, 53.15, 152.12, 184.01, 187.13, 137.24, 143.12, 173.09, 66.29000000000015, 185.15000000000003, 125.56999999999996, 128.08999999999992, 11.480000000000203, 131.3, 174.07999999999998, 124.46000000000006, 176.0, 127.73, 154.07, 200.0, 122.0, 94.7000000000001, 112.13, 152.0, 176.0, 164.36, 160.01, 106.22, 143.35999999999999, 113.57000000000008, 175.01, 125.51000000000003, 118.8200000000001, 114.35], "policy_predator_policy_reward": [16.0, 29.0, 66.0, 45.0, 8.0, 17.0, 7.0, 13.0, 10.0, 179.0, 28.0, 6.0, 18.0, 12.0, 101.0, 99.0, 16.0, 21.0, 29.0, 57.0, 8.0, 7.0, 98.0, 161.0, 11.0, 20.0, 10.0, 14.0, 7.0, 10.0, 13.0, 38.0, 13.0, 2.0, 63.0, 12.0, 2.0, 31.0, 0.0, 167.0, 11.0, 11.0, 26.0, 28.0, 5.0, 12.0, 6.0, 3.0, 5.0, 5.0, 60.0, 8.0, 38.0, 48.0, 11.0, 10.0, 144.0, 7.0, 10.0, 9.0, 84.0, 45.0, 18.0, 12.0, 17.0, 5.0, 3.0, 19.0, 61.0, 45.0, 32.0, 50.0, 8.0, 8.0, 13.0, 110.0, 133.0, 122.0, 43.0, 11.0, 13.0, 11.0, 37.0, 51.0, 34.0, 14.0, 39.0, 51.0, 141.0, 17.0, 54.0, 73.0, 23.0, 11.0, 200.0, 69.0, 33.0, 6.0, 7.0, 13.0, 2.0, 4.0, 6.0, 10.0, 15.0, 11.0, 19.0, 31.0, 0.0, 81.0, 70.0, 20.0, 28.0, 8.0, 4.0, 2.0, 43.0, 58.0, 98.0, 85.0, 8.0, 8.0, 15.0, 36.0, 7.0, 155.0, 45.0, 48.0, 70.0, 81.0, 10.0, 3.0, 65.0, 62.0, 9.0, 20.0, 56.0, 56.0, 130.0, 34.0, 32.0, 24.0, 8.0, 19.0, 68.0, 47.0, 36.0, 9.0, 55.0, 9.0, 160.0, 9.0, 30.0, 10.0, 9.0, 96.0, 9.0, 11.0, 13.0, 34.0, 37.0, 31.0, 169.0, 147.0, 186.0, 1.0, 75.0, 126.0, 3.0, 18.0, 38.0, 36.0, 23.0, 23.0, 7.0, 38.0, 78.0, 64.0, 58.0, 32.0, 31.0, 16.0, 35.0, 0.0, 15.0, 15.0, 146.0, 16.0, 107.0, 94.0, 9.0, 12.0, 62.0, 40.0, 21.0, 15.0, 90.0, 10.0, 17.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7206310977011806, "mean_inference_ms": 1.8926136763642247, "mean_action_processing_ms": 0.2999219199135819, "mean_env_wait_ms": 0.24530146146414894, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007086515426635742, "StateBufferConnector_ms": 0.006712079048156738, "ViewRequirementAgentConnector_ms": 0.13676810264587402}, "num_episodes": 23, "episode_return_max": 613.1899999999998, "episode_return_min": -26.579999999999607, "episode_return_mean": 309.2728999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 354.4538816372943, "num_env_steps_trained_throughput_per_sec": 354.4538816372943, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 11902.092, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11902.032, "sample_time_ms": 1455.799, "learn_time_ms": 10429.221, "learn_throughput": 383.538, "synch_weights_time_ms": 14.824}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "0e60f_00000", "date": "2024-08-15_01-10-06", "timestamp": 1723664406, "time_this_iter_s": 11.328643083572388, "time_total_s": 824.2467212677002, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2bc0280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 824.2467212677002, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 55.8875, "ram_util_percent": 82.8875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7105610232819957, "cur_kl_coeff": 0.42714843749999987, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.761545673501555, "policy_loss": 0.002029615815201646, "vf_loss": 4.754128750922188, "vf_explained_var": -0.2821187540021523, "kl": 0.012612238796300704, "entropy": 0.8483041346388519, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.055328658365068, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9969719150709726, "policy_loss": -0.0010401940288603622, "vf_loss": 2.9977403490631667, "vf_explained_var": 0.01326774380825184, "kl": 0.003623367222731889, "entropy": 0.8068409826389696, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 613.1899999999998, "episode_reward_min": -26.579999999999607, "episode_reward_mean": 329.4496999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -98.49999999999973, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 124.32485000000001, "predator_policy": 40.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [394.38999999999976, 126.78000000000065, 362.17999999999984, 317.7399999999996, 351.2999999999997, 146.50000000000048, 318.82999999999987, 231.12000000000018, -26.579999999999607, 190.02999999999966, 330.91999999999905, 359.17999999999995, 236.8299999999993, 320.46999999999963, 310.5499999999997, 325.42999999999984, 349.4899999999997, 321.5899999999999, 397.01, 271.9599999999991, 561.0699999999999, 386.34999999999985, 288.76, 411.23, 186.8799999999997, 436.18, 478.3499999999998, 418.3999999999999, 183.43999999999994, 265.37999999999965, 411.19, 360.6, 181.17999999999984, 366.26, 387.03, 212.06999999999928, 153.64000000000016, 155.70999999999998, 406.12, 172.35999999999967, 376.02, 439.0, 340.52, 214.12000000000018, 453.4599999999999, 372.3099999999997, 310.1, 348.4099999999999, 413.5999999999998, 216.05999999999938, 315.43999999999977, 235.10999999999973, 242.25000000000026, 204.8499999999999, 431.3299999999999, 385.3899999999999, 379.2199999999998, 251.5699999999993, 309.5899999999999, 333.4299999999997, 376.10999999999996, 259.67999999999995, 312.57000000000005, 613.1899999999998, 251.78000000000006, 431.16999999999996, 357.13, 398.3699999999998, 362.21, 296.44, 395.6599999999998, 232.78, 345.54, 338.7300000000001, 384.07000000000005, 378.7000000000001, 465.13, 361.36, 368.23, 292.93, 400.52, 291.1699999999999, 471.25999999999976, 399.16999999999996, 336.7800000000001, 357.28999999999996, 270.0699999999996, 401.05, 340.47999999999996, 326.4099999999998, 401.79, 362.99999999999994, 292.9699999999996, 349.3999999999998, 518.6599999999996, 334.50999999999954, 322.7099999999998, 331.72999999999996, 281.8299999999999, 302.6899999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [187.12999999999997, 174.25999999999976, 2.0000000000000013, -42.220000000000354, 164.1500000000001, 176.03, 175.24999999999994, 88.49000000000021, 176.0, 158.30000000000013, 2.0000000000000013, 135.50000000000026, 187.04, 121.79000000000006, -22.029999999999518, 185.15, -36.19000000000036, -76.38999999999918, 167.02999999999997, 2.0000000000000013, -18.0999999999998, 198.02, 170.14999999999998, 170.03, 140.0, -32.170000000000364, 108.47000000000006, 182.0, 121.31000000000016, 167.24, 144.20000000000002, 159.2299999999998, 122.39000000000009, 121.1, 145.19, 94.39999999999993, 197.0, 184.01, -18.099999999999795, 167.06, 184.01, 122.06, 158.09, 174.25999999999988, 132.35000000000005, 132.41000000000005, 159.23, 164.0, 165.01999999999998, -26.13999999999971, 185.15, 161.03, 142.16, 178.1900000000001, 109.37000000000005, 182.02999999999997, 153.47000000000003, -4.030000000000003, -62.32000000000033, 58.69999999999986, 193.03999999999996, 179.15, 170.3, 170.3, 2.0000000000000013, 173.18, 174.26, 176.0, 191.0, 170.02999999999997, -18.099999999999728, 180.16999999999985, 160.22, -87.57999999999979, 79.79000000000006, -14.080000000000005, 175.1, 195.01999999999998, 2.0000000000000013, 164.3599999999999, 83.0, 192.02, 68.0, 188.0, 151.37, 173.15, -1.90000000000021, 165.02, 179.20999999999998, 112.25000000000001, 126.02000000000001, 153.29000000000013, 58.100000000000016, 100.99999999999999, 156.4099999999999, 179.0, 127.19000000000001, 159.41, 185.05999999999995, 2.0000000000000013, 140.18000000000006, 63.25999999999995, -8.830000000000027, 79.94000000000007, 23.89999999999982, 162.35000000000002, 1.6100000000002517, 176.23999999999995, 160.25, 156.08, 173.21000000000004, 167.18, 136.2199999999998, 179.0, 181.07, -98.49999999999973, 195.04999999999995, 74.53999999999989, 87.05000000000001, 141.37999999999988, 173.0, 183.10999999999999, 36.679999999999886, 176.0, 78.23000000000005, 166.34, 193.04, 104.14999999999999, -58.0, 122.78, 177.01999999999998, 53.15, 152.12, 184.01, 187.13, 137.24, 143.12, 173.09, 66.29000000000015, 185.15000000000003, 125.56999999999996, 128.08999999999992, 11.480000000000203, 131.3, 174.07999999999998, 124.46000000000006, 176.0, 127.73, 154.07, 200.0, 122.0, 94.7000000000001, 112.13, 152.0, 176.0, 164.36, 160.01, 106.22, 143.35999999999999, 113.57000000000008, 175.01, 125.51000000000003, 118.8200000000001, 114.35, 162.2600000000001, 71.0, 180.14, 140.03, 93.77000000000012, 145.01, 147.01999999999998, 149.27000000000004, 99.41000000000021, 134.66, -19.99000000000001, 142.04000000000002, 119.39000000000006, 191.08999999999997, 174.26000000000005, 74.15000000000002, 151.16000000000005, 137.63, 123.46999999999997, 135.52999999999997, 185.12, 85.85000000000011, 142.3700000000001, 176.02999999999997, 135.6500000000002, 175.01, 155.15000000000006, 164.35999999999996, 194.05999999999997, 102.6500000000001, 141.59000000000003, 186.14000000000001, 47.59999999999988, 177.22999999999996, 86.69000000000014, 191.0], "policy_predator_policy_reward": [2.0, 31.0, 0.0, 167.0, 11.0, 11.0, 26.0, 28.0, 5.0, 12.0, 6.0, 3.0, 5.0, 5.0, 60.0, 8.0, 38.0, 48.0, 11.0, 10.0, 144.0, 7.0, 10.0, 9.0, 84.0, 45.0, 18.0, 12.0, 17.0, 5.0, 3.0, 19.0, 61.0, 45.0, 32.0, 50.0, 8.0, 8.0, 13.0, 110.0, 133.0, 122.0, 43.0, 11.0, 13.0, 11.0, 37.0, 51.0, 34.0, 14.0, 39.0, 51.0, 141.0, 17.0, 54.0, 73.0, 23.0, 11.0, 200.0, 69.0, 33.0, 6.0, 7.0, 13.0, 2.0, 4.0, 6.0, 10.0, 15.0, 11.0, 19.0, 31.0, 0.0, 81.0, 70.0, 20.0, 28.0, 8.0, 4.0, 2.0, 43.0, 58.0, 98.0, 85.0, 8.0, 8.0, 15.0, 36.0, 7.0, 155.0, 45.0, 48.0, 70.0, 81.0, 10.0, 3.0, 65.0, 62.0, 9.0, 20.0, 56.0, 56.0, 130.0, 34.0, 32.0, 24.0, 8.0, 19.0, 68.0, 47.0, 36.0, 9.0, 55.0, 9.0, 160.0, 9.0, 30.0, 10.0, 9.0, 96.0, 9.0, 11.0, 13.0, 34.0, 37.0, 31.0, 169.0, 147.0, 186.0, 1.0, 75.0, 126.0, 3.0, 18.0, 38.0, 36.0, 23.0, 23.0, 7.0, 38.0, 78.0, 64.0, 58.0, 32.0, 31.0, 16.0, 35.0, 0.0, 15.0, 15.0, 146.0, 16.0, 107.0, 94.0, 9.0, 12.0, 62.0, 40.0, 21.0, 15.0, 90.0, 10.0, 17.0, 41.0, 121.0, 117.0, 32.0, 47.0, 46.0, 52.0, 7.0, 54.0, 13.0, 23.0, 129.0, 150.0, 16.0, 14.0, 38.0, 40.0, 51.0, 62.0, 51.0, 53.0, 12.0, 10.0, 18.0, 13.0, 198.0, 10.0, 3.0, 12.0, 14.0, 12.0, 3.0, 1.0, 34.0, 23.0, 6.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7195948889806139, "mean_inference_ms": 1.8896809610692633, "mean_action_processing_ms": 0.2993226672076783, "mean_env_wait_ms": 0.2448485943634277, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007418274879455566, "StateBufferConnector_ms": 0.00578153133392334, "ViewRequirementAgentConnector_ms": 0.13715577125549316}, "num_episodes": 18, "episode_return_max": 613.1899999999998, "episode_return_min": -26.579999999999607, "episode_return_mean": 329.4496999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 357.95494101500395, "num_env_steps_trained_throughput_per_sec": 357.95494101500395, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 11913.983, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11913.903, "sample_time_ms": 1457.405, "learn_time_ms": 10439.309, "learn_throughput": 383.167, "synch_weights_time_ms": 14.966}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "0e60f_00000", "date": "2024-08-15_01-10-17", "timestamp": 1723664417, "time_this_iter_s": 11.207796096801758, "time_total_s": 835.454517364502, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a3030e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 835.454517364502, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 55.743750000000006, "ram_util_percent": 83.19375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.476546477167695, "cur_kl_coeff": 0.42714843749999987, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.427237372423606, "policy_loss": -0.002424121040003325, "vf_loss": 4.425434745808758, "vf_explained_var": 0.3215212605302296, "kl": 0.00989526048466614, "entropy": 0.789888380255018, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1686256009434897, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.551464012880174, "policy_loss": -0.003998202129104544, "vf_loss": 2.5551997564457083, "vf_explained_var": 0.026513372653375857, "kl": 0.006998837033694034, "entropy": 0.8314066441601546, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 613.1899999999998, "episode_reward_min": 20.72000000000022, "episode_reward_mean": 335.48539999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -98.49999999999973, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 126.7427, "predator_policy": 41.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [397.01, 271.9599999999991, 561.0699999999999, 386.34999999999985, 288.76, 411.23, 186.8799999999997, 436.18, 478.3499999999998, 418.3999999999999, 183.43999999999994, 265.37999999999965, 411.19, 360.6, 181.17999999999984, 366.26, 387.03, 212.06999999999928, 153.64000000000016, 155.70999999999998, 406.12, 172.35999999999967, 376.02, 439.0, 340.52, 214.12000000000018, 453.4599999999999, 372.3099999999997, 310.1, 348.4099999999999, 413.5999999999998, 216.05999999999938, 315.43999999999977, 235.10999999999973, 242.25000000000026, 204.8499999999999, 431.3299999999999, 385.3899999999999, 379.2199999999998, 251.5699999999993, 309.5899999999999, 333.4299999999997, 376.10999999999996, 259.67999999999995, 312.57000000000005, 613.1899999999998, 251.78000000000006, 431.16999999999996, 357.13, 398.3699999999998, 362.21, 296.44, 395.6599999999998, 232.78, 345.54, 338.7300000000001, 384.07000000000005, 378.7000000000001, 465.13, 361.36, 368.23, 292.93, 400.52, 291.1699999999999, 471.25999999999976, 399.16999999999996, 336.7800000000001, 357.28999999999996, 270.0699999999996, 401.05, 340.47999999999996, 326.4099999999998, 401.79, 362.99999999999994, 292.9699999999996, 349.3999999999998, 518.6599999999996, 334.50999999999954, 322.7099999999998, 331.72999999999996, 281.8299999999999, 302.6899999999999, 254.41999999999976, 300.7799999999997, 229.66999999999848, 291.15999999999997, 410.29999999999984, 382.18999999999994, 318.28999999999985, 392.5700000000001, 390.03, 20.72000000000022, 305.78999999999985, 372.06, 340.5999999999996, 336.6700000000001, 370.7499999999999, 337.51, 230.6399999999993, 286.1700000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [197.0, 184.01, -18.099999999999795, 167.06, 184.01, 122.06, 158.09, 174.25999999999988, 132.35000000000005, 132.41000000000005, 159.23, 164.0, 165.01999999999998, -26.13999999999971, 185.15, 161.03, 142.16, 178.1900000000001, 109.37000000000005, 182.02999999999997, 153.47000000000003, -4.030000000000003, -62.32000000000033, 58.69999999999986, 193.03999999999996, 179.15, 170.3, 170.3, 2.0000000000000013, 173.18, 174.26, 176.0, 191.0, 170.02999999999997, -18.099999999999728, 180.16999999999985, 160.22, -87.57999999999979, 79.79000000000006, -14.080000000000005, 175.1, 195.01999999999998, 2.0000000000000013, 164.3599999999999, 83.0, 192.02, 68.0, 188.0, 151.37, 173.15, -1.90000000000021, 165.02, 179.20999999999998, 112.25000000000001, 126.02000000000001, 153.29000000000013, 58.100000000000016, 100.99999999999999, 156.4099999999999, 179.0, 127.19000000000001, 159.41, 185.05999999999995, 2.0000000000000013, 140.18000000000006, 63.25999999999995, -8.830000000000027, 79.94000000000007, 23.89999999999982, 162.35000000000002, 1.6100000000002517, 176.23999999999995, 160.25, 156.08, 173.21000000000004, 167.18, 136.2199999999998, 179.0, 181.07, -98.49999999999973, 195.04999999999995, 74.53999999999989, 87.05000000000001, 141.37999999999988, 173.0, 183.10999999999999, 36.679999999999886, 176.0, 78.23000000000005, 166.34, 193.04, 104.14999999999999, -58.0, 122.78, 177.01999999999998, 53.15, 152.12, 184.01, 187.13, 137.24, 143.12, 173.09, 66.29000000000015, 185.15000000000003, 125.56999999999996, 128.08999999999992, 11.480000000000203, 131.3, 174.07999999999998, 124.46000000000006, 176.0, 127.73, 154.07, 200.0, 122.0, 94.7000000000001, 112.13, 152.0, 176.0, 164.36, 160.01, 106.22, 143.35999999999999, 113.57000000000008, 175.01, 125.51000000000003, 118.8200000000001, 114.35, 162.2600000000001, 71.0, 180.14, 140.03, 93.77000000000012, 145.01, 147.01999999999998, 149.27000000000004, 99.41000000000021, 134.66, -19.99000000000001, 142.04000000000002, 119.39000000000006, 191.08999999999997, 174.26000000000005, 74.15000000000002, 151.16000000000005, 137.63, 123.46999999999997, 135.52999999999997, 185.12, 85.85000000000011, 142.3700000000001, 176.02999999999997, 135.6500000000002, 175.01, 155.15000000000006, 164.35999999999996, 194.05999999999997, 102.6500000000001, 141.59000000000003, 186.14000000000001, 47.59999999999988, 177.22999999999996, 86.69000000000014, 191.0, 89.59999999999997, 118.82000000000002, 67.72999999999992, 189.05, 80.90000000000046, 102.77000000000024, 120.80000000000008, 164.35999999999999, 93.08, 178.21999999999997, 180.17000000000002, 153.02, 81.14000000000013, 38.15000000000001, 185.0, 104.57000000000009, 119.03, 200.0, -24.129999999999708, 7.8499999999999615, 139.28000000000006, 122.5100000000001, 181.01, 174.05, 140.59999999999962, 176.0, 162.05, 33.61999999999992, 170.26999999999992, 110.48000000000008, 149.32999999999998, 170.18, 140.45000000000002, 46.19000000000003, 91.61000000000007, 144.55999999999995], "policy_predator_policy_reward": [8.0, 8.0, 13.0, 110.0, 133.0, 122.0, 43.0, 11.0, 13.0, 11.0, 37.0, 51.0, 34.0, 14.0, 39.0, 51.0, 141.0, 17.0, 54.0, 73.0, 23.0, 11.0, 200.0, 69.0, 33.0, 6.0, 7.0, 13.0, 2.0, 4.0, 6.0, 10.0, 15.0, 11.0, 19.0, 31.0, 0.0, 81.0, 70.0, 20.0, 28.0, 8.0, 4.0, 2.0, 43.0, 58.0, 98.0, 85.0, 8.0, 8.0, 15.0, 36.0, 7.0, 155.0, 45.0, 48.0, 70.0, 81.0, 10.0, 3.0, 65.0, 62.0, 9.0, 20.0, 56.0, 56.0, 130.0, 34.0, 32.0, 24.0, 8.0, 19.0, 68.0, 47.0, 36.0, 9.0, 55.0, 9.0, 160.0, 9.0, 30.0, 10.0, 9.0, 96.0, 9.0, 11.0, 13.0, 34.0, 37.0, 31.0, 169.0, 147.0, 186.0, 1.0, 75.0, 126.0, 3.0, 18.0, 38.0, 36.0, 23.0, 23.0, 7.0, 38.0, 78.0, 64.0, 58.0, 32.0, 31.0, 16.0, 35.0, 0.0, 15.0, 15.0, 146.0, 16.0, 107.0, 94.0, 9.0, 12.0, 62.0, 40.0, 21.0, 15.0, 90.0, 10.0, 17.0, 41.0, 121.0, 117.0, 32.0, 47.0, 46.0, 52.0, 7.0, 54.0, 13.0, 23.0, 129.0, 150.0, 16.0, 14.0, 38.0, 40.0, 51.0, 62.0, 51.0, 53.0, 12.0, 10.0, 18.0, 13.0, 198.0, 10.0, 3.0, 12.0, 14.0, 12.0, 3.0, 1.0, 34.0, 23.0, 6.0, 19.0, 23.0, 23.0, 17.0, 27.0, 23.0, 23.0, 0.0, 6.0, 99.0, 40.0, 29.0, 20.0, 1.0, 198.0, 51.0, 52.0, 50.0, 21.0, 20.0, 17.0, 32.0, 12.0, 10.0, 7.0, 12.0, 12.0, 41.0, 100.0, 70.0, 20.0, 10.0, 8.0, 15.0, 29.0, 28.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7185562472786168, "mean_inference_ms": 1.886544926732801, "mean_action_processing_ms": 0.29868094938246714, "mean_env_wait_ms": 0.24437764233413653, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008671998977661133, "StateBufferConnector_ms": 0.005713701248168945, "ViewRequirementAgentConnector_ms": 0.13423395156860352}, "num_episodes": 18, "episode_return_max": 613.1899999999998, "episode_return_min": 20.72000000000022, "episode_return_mean": 335.48539999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.4307322423856, "num_env_steps_trained_throughput_per_sec": 349.4307322423856, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 11545.751, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11545.671, "sample_time_ms": 1413.563, "learn_time_ms": 10116.705, "learn_throughput": 395.386, "synch_weights_time_ms": 13.217}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "0e60f_00000", "date": "2024-08-15_01-10-29", "timestamp": 1723664429, "time_this_iter_s": 11.480005979537964, "time_total_s": 846.9345233440399, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2af9c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 846.9345233440399, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 57.25, "ram_util_percent": 83.05}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.859855772925433, "cur_kl_coeff": 0.42714843749999987, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.754383822849818, "policy_loss": -0.004530555816495387, "vf_loss": 5.7562646515154965, "vf_explained_var": 0.11098489578438814, "kl": 0.006203278120077415, "entropy": 0.824658290261314, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4864014782602823, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.529837923705893, "policy_loss": -0.005502367229570472, "vf_loss": 5.534952134051651, "vf_explained_var": 0.012788111791408882, "kl": 0.010350548781410254, "entropy": 0.7896664210097499, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 613.1899999999998, "episode_reward_min": 20.72000000000022, "episode_reward_mean": 334.4363999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -157.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": 121.45820000000002, "predator_policy": 45.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [376.02, 439.0, 340.52, 214.12000000000018, 453.4599999999999, 372.3099999999997, 310.1, 348.4099999999999, 413.5999999999998, 216.05999999999938, 315.43999999999977, 235.10999999999973, 242.25000000000026, 204.8499999999999, 431.3299999999999, 385.3899999999999, 379.2199999999998, 251.5699999999993, 309.5899999999999, 333.4299999999997, 376.10999999999996, 259.67999999999995, 312.57000000000005, 613.1899999999998, 251.78000000000006, 431.16999999999996, 357.13, 398.3699999999998, 362.21, 296.44, 395.6599999999998, 232.78, 345.54, 338.7300000000001, 384.07000000000005, 378.7000000000001, 465.13, 361.36, 368.23, 292.93, 400.52, 291.1699999999999, 471.25999999999976, 399.16999999999996, 336.7800000000001, 357.28999999999996, 270.0699999999996, 401.05, 340.47999999999996, 326.4099999999998, 401.79, 362.99999999999994, 292.9699999999996, 349.3999999999998, 518.6599999999996, 334.50999999999954, 322.7099999999998, 331.72999999999996, 281.8299999999999, 302.6899999999999, 254.41999999999976, 300.7799999999997, 229.66999999999848, 291.15999999999997, 410.29999999999984, 382.18999999999994, 318.28999999999985, 392.5700000000001, 390.03, 20.72000000000022, 305.78999999999985, 372.06, 340.5999999999996, 336.6700000000001, 370.7499999999999, 337.51, 230.6399999999993, 286.1700000000001, 372.03, 235.42999999999986, 325.54999999999995, 203.90000000000015, 276.74000000000007, 373.08, 272.2399999999997, 236.84999999999997, 294.89999999999986, 294.8999999999992, 385.0999999999999, 204.34000000000015, 275.4099999999999, 405.5299999999998, 423.0799999999999, 308.5699999999998, 299.33999999999975, 357.20999999999987, 379.4499999999997, 313.8999999999995, 357.22, 391.49999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [83.0, 192.02, 68.0, 188.0, 151.37, 173.15, -1.90000000000021, 165.02, 179.20999999999998, 112.25000000000001, 126.02000000000001, 153.29000000000013, 58.100000000000016, 100.99999999999999, 156.4099999999999, 179.0, 127.19000000000001, 159.41, 185.05999999999995, 2.0000000000000013, 140.18000000000006, 63.25999999999995, -8.830000000000027, 79.94000000000007, 23.89999999999982, 162.35000000000002, 1.6100000000002517, 176.23999999999995, 160.25, 156.08, 173.21000000000004, 167.18, 136.2199999999998, 179.0, 181.07, -98.49999999999973, 195.04999999999995, 74.53999999999989, 87.05000000000001, 141.37999999999988, 173.0, 183.10999999999999, 36.679999999999886, 176.0, 78.23000000000005, 166.34, 193.04, 104.14999999999999, -58.0, 122.78, 177.01999999999998, 53.15, 152.12, 184.01, 187.13, 137.24, 143.12, 173.09, 66.29000000000015, 185.15000000000003, 125.56999999999996, 128.08999999999992, 11.480000000000203, 131.3, 174.07999999999998, 124.46000000000006, 176.0, 127.73, 154.07, 200.0, 122.0, 94.7000000000001, 112.13, 152.0, 176.0, 164.36, 160.01, 106.22, 143.35999999999999, 113.57000000000008, 175.01, 125.51000000000003, 118.8200000000001, 114.35, 162.2600000000001, 71.0, 180.14, 140.03, 93.77000000000012, 145.01, 147.01999999999998, 149.27000000000004, 99.41000000000021, 134.66, -19.99000000000001, 142.04000000000002, 119.39000000000006, 191.08999999999997, 174.26000000000005, 74.15000000000002, 151.16000000000005, 137.63, 123.46999999999997, 135.52999999999997, 185.12, 85.85000000000011, 142.3700000000001, 176.02999999999997, 135.6500000000002, 175.01, 155.15000000000006, 164.35999999999996, 194.05999999999997, 102.6500000000001, 141.59000000000003, 186.14000000000001, 47.59999999999988, 177.22999999999996, 86.69000000000014, 191.0, 89.59999999999997, 118.82000000000002, 67.72999999999992, 189.05, 80.90000000000046, 102.77000000000024, 120.80000000000008, 164.35999999999999, 93.08, 178.21999999999997, 180.17000000000002, 153.02, 81.14000000000013, 38.15000000000001, 185.0, 104.57000000000009, 119.03, 200.0, -24.129999999999708, 7.8499999999999615, 139.28000000000006, 122.5100000000001, 181.01, 174.05, 140.59999999999962, 176.0, 162.05, 33.61999999999992, 170.26999999999992, 110.48000000000008, 149.32999999999998, 170.18, 140.45000000000002, 46.19000000000003, 91.61000000000007, 144.55999999999995, 183.02, 94.00999999999999, 64.88000000000008, 142.55000000000007, 98.0, 145.55000000000004, 66.32, 25.579999999999973, 56.0, 126.73999999999994, 138.05, 53.03, 90.11000000000014, 163.13, 92.57, 73.27999999999999, 134.66000000000008, 119.24000000000001, -26.259999999999852, 184.16, 149.0, 70.10000000000001, 58.07000000000004, 104.26999999999995, 151.36999999999995, 67.03999999999999, 36.109999999999985, 158.42000000000002, 141.08000000000004, 200.0, 113.57000000000018, -157.0, 43.340000000000025, 110.0, 5.149999999999963, 62.06000000000001, 154.39999999999986, 24.049999999999997, 89.66000000000025, 140.24, 157.22, 161.0, 129.5, 185.0], "policy_predator_policy_reward": [43.0, 58.0, 98.0, 85.0, 8.0, 8.0, 15.0, 36.0, 7.0, 155.0, 45.0, 48.0, 70.0, 81.0, 10.0, 3.0, 65.0, 62.0, 9.0, 20.0, 56.0, 56.0, 130.0, 34.0, 32.0, 24.0, 8.0, 19.0, 68.0, 47.0, 36.0, 9.0, 55.0, 9.0, 160.0, 9.0, 30.0, 10.0, 9.0, 96.0, 9.0, 11.0, 13.0, 34.0, 37.0, 31.0, 169.0, 147.0, 186.0, 1.0, 75.0, 126.0, 3.0, 18.0, 38.0, 36.0, 23.0, 23.0, 7.0, 38.0, 78.0, 64.0, 58.0, 32.0, 31.0, 16.0, 35.0, 0.0, 15.0, 15.0, 146.0, 16.0, 107.0, 94.0, 9.0, 12.0, 62.0, 40.0, 21.0, 15.0, 90.0, 10.0, 17.0, 41.0, 121.0, 117.0, 32.0, 47.0, 46.0, 52.0, 7.0, 54.0, 13.0, 23.0, 129.0, 150.0, 16.0, 14.0, 38.0, 40.0, 51.0, 62.0, 51.0, 53.0, 12.0, 10.0, 18.0, 13.0, 198.0, 10.0, 3.0, 12.0, 14.0, 12.0, 3.0, 1.0, 34.0, 23.0, 6.0, 19.0, 23.0, 23.0, 17.0, 27.0, 23.0, 23.0, 0.0, 6.0, 99.0, 40.0, 29.0, 20.0, 1.0, 198.0, 51.0, 52.0, 50.0, 21.0, 20.0, 17.0, 32.0, 12.0, 10.0, 7.0, 12.0, 12.0, 41.0, 100.0, 70.0, 20.0, 10.0, 8.0, 15.0, 29.0, 28.0, 22.0, 43.0, 52.0, 22.0, 6.0, 76.0, 6.0, 47.0, 65.0, 76.0, 18.0, 94.0, 88.0, 11.0, 8.0, 14.0, 57.0, 37.0, 4.0, 124.0, 13.0, 77.0, 89.0, 26.0, 16.0, 52.0, 5.0, 145.0, 66.0, 44.0, 38.0, 180.0, 172.0, 62.0, 84.0, 102.0, 188.0, 101.0, 100.0, 38.0, 46.0, 17.0, 22.0, 26.0, 51.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7172691604408412, "mean_inference_ms": 1.883343767073513, "mean_action_processing_ms": 0.2980647883055253, "mean_env_wait_ms": 0.24398211864035965, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00945746898651123, "StateBufferConnector_ms": 0.009761571884155273, "ViewRequirementAgentConnector_ms": 0.1429157257080078}, "num_episodes": 22, "episode_return_max": 613.1899999999998, "episode_return_min": 20.72000000000022, "episode_return_mean": 334.4363999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 350.437361167328, "num_env_steps_trained_throughput_per_sec": 350.437361167328, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 11381.485, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11381.406, "sample_time_ms": 1342.546, "learn_time_ms": 10023.454, "learn_throughput": 399.064, "synch_weights_time_ms": 13.234}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "0e60f_00000", "date": "2024-08-15_01-10-40", "timestamp": 1723664440, "time_this_iter_s": 11.468025922775269, "time_total_s": 858.4025492668152, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a303b940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 858.4025492668152, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 56.46470588235294, "ram_util_percent": 82.88823529411765}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.755348216856598, "cur_kl_coeff": 0.42714843749999987, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.577415463028761, "policy_loss": -0.0014995537265869124, "vf_loss": 4.576329379233103, "vf_explained_var": 0.0631854788651542, "kl": 0.006053244706758337, "entropy": 0.8932875953338765, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4963673793134236, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.1715463937275, "policy_loss": -0.00525133409389546, "vf_loss": 4.176434546551376, "vf_explained_var": 0.05034437053418033, "kl": 0.0096848010727867, "entropy": 0.7745666055767625, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 613.1899999999998, "episode_reward_min": -183.94, "episode_reward_mean": 336.7529999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -307.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": 116.85650000000001, "predator_policy": 51.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [613.1899999999998, 251.78000000000006, 431.16999999999996, 357.13, 398.3699999999998, 362.21, 296.44, 395.6599999999998, 232.78, 345.54, 338.7300000000001, 384.07000000000005, 378.7000000000001, 465.13, 361.36, 368.23, 292.93, 400.52, 291.1699999999999, 471.25999999999976, 399.16999999999996, 336.7800000000001, 357.28999999999996, 270.0699999999996, 401.05, 340.47999999999996, 326.4099999999998, 401.79, 362.99999999999994, 292.9699999999996, 349.3999999999998, 518.6599999999996, 334.50999999999954, 322.7099999999998, 331.72999999999996, 281.8299999999999, 302.6899999999999, 254.41999999999976, 300.7799999999997, 229.66999999999848, 291.15999999999997, 410.29999999999984, 382.18999999999994, 318.28999999999985, 392.5700000000001, 390.03, 20.72000000000022, 305.78999999999985, 372.06, 340.5999999999996, 336.6700000000001, 370.7499999999999, 337.51, 230.6399999999993, 286.1700000000001, 372.03, 235.42999999999986, 325.54999999999995, 203.90000000000015, 276.74000000000007, 373.08, 272.2399999999997, 236.84999999999997, 294.89999999999986, 294.8999999999992, 385.0999999999999, 204.34000000000015, 275.4099999999999, 405.5299999999998, 423.0799999999999, 308.5699999999998, 299.33999999999975, 357.20999999999987, 379.4499999999997, 313.8999999999995, 357.22, 391.49999999999994, 343.0, 357.69999999999965, 294.9799999999999, 452.56, 323.5499999999999, 415.30999999999995, 272.01, -183.94, 440.78999999999996, 288.85999999999973, 389.39, 409.3699999999999, 372.25, 340.14999999999986, 376.07, 361.37999999999994, 322.29, 155.32000000000005, 365.43999999999994, 344.77, 459.02, 362.14999999999964, 489.38], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [193.04, 104.14999999999999, -58.0, 122.78, 177.01999999999998, 53.15, 152.12, 184.01, 187.13, 137.24, 143.12, 173.09, 66.29000000000015, 185.15000000000003, 125.56999999999996, 128.08999999999992, 11.480000000000203, 131.3, 174.07999999999998, 124.46000000000006, 176.0, 127.73, 154.07, 200.0, 122.0, 94.7000000000001, 112.13, 152.0, 176.0, 164.36, 160.01, 106.22, 143.35999999999999, 113.57000000000008, 175.01, 125.51000000000003, 118.8200000000001, 114.35, 162.2600000000001, 71.0, 180.14, 140.03, 93.77000000000012, 145.01, 147.01999999999998, 149.27000000000004, 99.41000000000021, 134.66, -19.99000000000001, 142.04000000000002, 119.39000000000006, 191.08999999999997, 174.26000000000005, 74.15000000000002, 151.16000000000005, 137.63, 123.46999999999997, 135.52999999999997, 185.12, 85.85000000000011, 142.3700000000001, 176.02999999999997, 135.6500000000002, 175.01, 155.15000000000006, 164.35999999999996, 194.05999999999997, 102.6500000000001, 141.59000000000003, 186.14000000000001, 47.59999999999988, 177.22999999999996, 86.69000000000014, 191.0, 89.59999999999997, 118.82000000000002, 67.72999999999992, 189.05, 80.90000000000046, 102.77000000000024, 120.80000000000008, 164.35999999999999, 93.08, 178.21999999999997, 180.17000000000002, 153.02, 81.14000000000013, 38.15000000000001, 185.0, 104.57000000000009, 119.03, 200.0, -24.129999999999708, 7.8499999999999615, 139.28000000000006, 122.5100000000001, 181.01, 174.05, 140.59999999999962, 176.0, 162.05, 33.61999999999992, 170.26999999999992, 110.48000000000008, 149.32999999999998, 170.18, 140.45000000000002, 46.19000000000003, 91.61000000000007, 144.55999999999995, 183.02, 94.00999999999999, 64.88000000000008, 142.55000000000007, 98.0, 145.55000000000004, 66.32, 25.579999999999973, 56.0, 126.73999999999994, 138.05, 53.03, 90.11000000000014, 163.13, 92.57, 73.27999999999999, 134.66000000000008, 119.24000000000001, -26.259999999999852, 184.16, 149.0, 70.10000000000001, 58.07000000000004, 104.26999999999995, 151.36999999999995, 67.03999999999999, 36.109999999999985, 158.42000000000002, 141.08000000000004, 200.0, 113.57000000000018, -157.0, 43.340000000000025, 110.0, 5.149999999999963, 62.06000000000001, 154.39999999999986, 24.049999999999997, 89.66000000000025, 140.24, 157.22, 161.0, 129.5, 185.0, 128.0, 155.0, 134.65999999999968, 106.04, 155.4199999999999, 129.56000000000006, 144.56000000000006, 68.0, 124.40000000000006, 185.14999999999992, 171.29000000000002, 84.02000000000001, 37.010000000000005, -16.0, -96.94, -307.0, -21.310000000000002, 157.1, 112.5500000000001, 148.31000000000017, 137.39000000000001, 179.0, 174.26, 162.11, 160.25, 146.0, 116.15000000000008, 143.0, 56.059999999999995, 109.00999999999999, 180.07999999999998, 167.3, 157.19, 85.1, -255.52, 116.84000000000006, 171.28999999999996, 149.15000000000006, 92.0, 30.769999999999982, 101.0, 189.01999999999998, 36.35000000000001, 102.80000000000018, 192.07999999999998, 143.30000000000007], "policy_predator_policy_reward": [169.0, 147.0, 186.0, 1.0, 75.0, 126.0, 3.0, 18.0, 38.0, 36.0, 23.0, 23.0, 7.0, 38.0, 78.0, 64.0, 58.0, 32.0, 31.0, 16.0, 35.0, 0.0, 15.0, 15.0, 146.0, 16.0, 107.0, 94.0, 9.0, 12.0, 62.0, 40.0, 21.0, 15.0, 90.0, 10.0, 17.0, 41.0, 121.0, 117.0, 32.0, 47.0, 46.0, 52.0, 7.0, 54.0, 13.0, 23.0, 129.0, 150.0, 16.0, 14.0, 38.0, 40.0, 51.0, 62.0, 51.0, 53.0, 12.0, 10.0, 18.0, 13.0, 198.0, 10.0, 3.0, 12.0, 14.0, 12.0, 3.0, 1.0, 34.0, 23.0, 6.0, 19.0, 23.0, 23.0, 17.0, 27.0, 23.0, 23.0, 0.0, 6.0, 99.0, 40.0, 29.0, 20.0, 1.0, 198.0, 51.0, 52.0, 50.0, 21.0, 20.0, 17.0, 32.0, 12.0, 10.0, 7.0, 12.0, 12.0, 41.0, 100.0, 70.0, 20.0, 10.0, 8.0, 15.0, 29.0, 28.0, 22.0, 43.0, 52.0, 22.0, 6.0, 76.0, 6.0, 47.0, 65.0, 76.0, 18.0, 94.0, 88.0, 11.0, 8.0, 14.0, 57.0, 37.0, 4.0, 124.0, 13.0, 77.0, 89.0, 26.0, 16.0, 52.0, 5.0, 145.0, 66.0, 44.0, 38.0, 180.0, 172.0, 62.0, 84.0, 102.0, 188.0, 101.0, 100.0, 38.0, 46.0, 17.0, 22.0, 26.0, 51.0, 25.0, 35.0, 51.0, 66.0, 3.0, 7.0, 112.0, 128.0, 13.0, 1.0, 81.0, 79.0, 122.0, 129.0, 22.0, 198.0, 139.0, 166.0, 17.0, 11.0, 27.0, 46.0, 45.0, 28.0, 5.0, 61.0, 49.0, 32.0, 105.0, 106.0, 4.0, 10.0, 11.0, 69.0, 180.0, 114.0, 28.0, 17.0, 115.0, 107.0, 64.0, 105.0, 107.0, 116.0, 82.0, 72.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7162430114861182, "mean_inference_ms": 1.880214690889735, "mean_action_processing_ms": 0.29777703096359476, "mean_env_wait_ms": 0.24389068784980147, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009259343147277832, "StateBufferConnector_ms": 0.009054064750671387, "ViewRequirementAgentConnector_ms": 0.13281917572021484}, "num_episodes": 23, "episode_return_max": 613.1899999999998, "episode_return_min": -183.94, "episode_return_mean": 336.7529999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 333.58688552961394, "num_env_steps_trained_throughput_per_sec": 333.58688552961394, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 11414.481, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11414.407, "sample_time_ms": 1339.367, "learn_time_ms": 10058.82, "learn_throughput": 397.661, "synch_weights_time_ms": 13.754}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "0e60f_00000", "date": "2024-08-15_01-10-52", "timestamp": 1723664452, "time_this_iter_s": 12.020738124847412, "time_total_s": 870.4232873916626, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a31275e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 870.4232873916626, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 55.22941176470588, "ram_util_percent": 83.47058823529412}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.007862997118127, "cur_kl_coeff": 0.42714843749999987, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.94203412747257, "policy_loss": -0.0016047304910090235, "vf_loss": 5.94208846243601, "vf_explained_var": -0.09170268997944221, "kl": 0.003629588341742759, "entropy": 0.9284868779636565, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8604130688167753, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.767626284922241, "policy_loss": -0.0022681406439188376, "vf_loss": 4.769704010120775, "vf_explained_var": 0.08677612574642928, "kl": 0.005077460451798637, "entropy": 0.5639374032537773, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 518.6599999999996, "episode_reward_min": -183.94, "episode_reward_mean": 331.4005999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -307.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": 113.93030000000003, "predator_policy": 51.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [291.1699999999999, 471.25999999999976, 399.16999999999996, 336.7800000000001, 357.28999999999996, 270.0699999999996, 401.05, 340.47999999999996, 326.4099999999998, 401.79, 362.99999999999994, 292.9699999999996, 349.3999999999998, 518.6599999999996, 334.50999999999954, 322.7099999999998, 331.72999999999996, 281.8299999999999, 302.6899999999999, 254.41999999999976, 300.7799999999997, 229.66999999999848, 291.15999999999997, 410.29999999999984, 382.18999999999994, 318.28999999999985, 392.5700000000001, 390.03, 20.72000000000022, 305.78999999999985, 372.06, 340.5999999999996, 336.6700000000001, 370.7499999999999, 337.51, 230.6399999999993, 286.1700000000001, 372.03, 235.42999999999986, 325.54999999999995, 203.90000000000015, 276.74000000000007, 373.08, 272.2399999999997, 236.84999999999997, 294.89999999999986, 294.8999999999992, 385.0999999999999, 204.34000000000015, 275.4099999999999, 405.5299999999998, 423.0799999999999, 308.5699999999998, 299.33999999999975, 357.20999999999987, 379.4499999999997, 313.8999999999995, 357.22, 391.49999999999994, 343.0, 357.69999999999965, 294.9799999999999, 452.56, 323.5499999999999, 415.30999999999995, 272.01, -183.94, 440.78999999999996, 288.85999999999973, 389.39, 409.3699999999999, 372.25, 340.14999999999986, 376.07, 361.37999999999994, 322.29, 155.32000000000005, 365.43999999999994, 344.77, 459.02, 362.14999999999964, 489.38, 246.56999999999923, 380.5999999999996, 290.2499999999999, 433.50999999999976, 310.8399999999996, 447.28999999999974, 358.55999999999955, 283.0199999999999, 485.01, 367.5, 215.02999999999983, 342.6999999999998, 234.49999999999983, 271.0899999999996, 428.03, 358.28999999999996, 306.4099999999997, 379.4999999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [118.8200000000001, 114.35, 162.2600000000001, 71.0, 180.14, 140.03, 93.77000000000012, 145.01, 147.01999999999998, 149.27000000000004, 99.41000000000021, 134.66, -19.99000000000001, 142.04000000000002, 119.39000000000006, 191.08999999999997, 174.26000000000005, 74.15000000000002, 151.16000000000005, 137.63, 123.46999999999997, 135.52999999999997, 185.12, 85.85000000000011, 142.3700000000001, 176.02999999999997, 135.6500000000002, 175.01, 155.15000000000006, 164.35999999999996, 194.05999999999997, 102.6500000000001, 141.59000000000003, 186.14000000000001, 47.59999999999988, 177.22999999999996, 86.69000000000014, 191.0, 89.59999999999997, 118.82000000000002, 67.72999999999992, 189.05, 80.90000000000046, 102.77000000000024, 120.80000000000008, 164.35999999999999, 93.08, 178.21999999999997, 180.17000000000002, 153.02, 81.14000000000013, 38.15000000000001, 185.0, 104.57000000000009, 119.03, 200.0, -24.129999999999708, 7.8499999999999615, 139.28000000000006, 122.5100000000001, 181.01, 174.05, 140.59999999999962, 176.0, 162.05, 33.61999999999992, 170.26999999999992, 110.48000000000008, 149.32999999999998, 170.18, 140.45000000000002, 46.19000000000003, 91.61000000000007, 144.55999999999995, 183.02, 94.00999999999999, 64.88000000000008, 142.55000000000007, 98.0, 145.55000000000004, 66.32, 25.579999999999973, 56.0, 126.73999999999994, 138.05, 53.03, 90.11000000000014, 163.13, 92.57, 73.27999999999999, 134.66000000000008, 119.24000000000001, -26.259999999999852, 184.16, 149.0, 70.10000000000001, 58.07000000000004, 104.26999999999995, 151.36999999999995, 67.03999999999999, 36.109999999999985, 158.42000000000002, 141.08000000000004, 200.0, 113.57000000000018, -157.0, 43.340000000000025, 110.0, 5.149999999999963, 62.06000000000001, 154.39999999999986, 24.049999999999997, 89.66000000000025, 140.24, 157.22, 161.0, 129.5, 185.0, 128.0, 155.0, 134.65999999999968, 106.04, 155.4199999999999, 129.56000000000006, 144.56000000000006, 68.0, 124.40000000000006, 185.14999999999992, 171.29000000000002, 84.02000000000001, 37.010000000000005, -16.0, -96.94, -307.0, -21.310000000000002, 157.1, 112.5500000000001, 148.31000000000017, 137.39000000000001, 179.0, 174.26, 162.11, 160.25, 146.0, 116.15000000000008, 143.0, 56.059999999999995, 109.00999999999999, 180.07999999999998, 167.3, 157.19, 85.1, -255.52, 116.84000000000006, 171.28999999999996, 149.15000000000006, 92.0, 30.769999999999982, 101.0, 189.01999999999998, 36.35000000000001, 102.80000000000018, 192.07999999999998, 143.30000000000007, 117.14000000000003, 58.42999999999984, 115.16000000000008, 156.43999999999997, 129.17000000000007, -26.919999999999987, 176.24, 77.2700000000001, 85.51999999999992, 165.32, 171.28999999999996, 62.0, 185.12000000000003, 141.44000000000005, 116.32999999999997, 131.69, 200.0, 199.01, 160.4, 109.10000000000002, 96.65000000000003, -59.6199999999999, 149.32999999999998, 163.37000000000006, 108.59000000000015, 109.91000000000001, 85.94000000000013, 149.15000000000003, 164.03000000000003, 176.0, 175.25000000000003, -61.95999999999998, 119.39000000000019, 81.02000000000001, 122.12000000000005, 123.38000000000005], "policy_predator_policy_reward": [17.0, 41.0, 121.0, 117.0, 32.0, 47.0, 46.0, 52.0, 7.0, 54.0, 13.0, 23.0, 129.0, 150.0, 16.0, 14.0, 38.0, 40.0, 51.0, 62.0, 51.0, 53.0, 12.0, 10.0, 18.0, 13.0, 198.0, 10.0, 3.0, 12.0, 14.0, 12.0, 3.0, 1.0, 34.0, 23.0, 6.0, 19.0, 23.0, 23.0, 17.0, 27.0, 23.0, 23.0, 0.0, 6.0, 99.0, 40.0, 29.0, 20.0, 1.0, 198.0, 51.0, 52.0, 50.0, 21.0, 20.0, 17.0, 32.0, 12.0, 10.0, 7.0, 12.0, 12.0, 41.0, 100.0, 70.0, 20.0, 10.0, 8.0, 15.0, 29.0, 28.0, 22.0, 43.0, 52.0, 22.0, 6.0, 76.0, 6.0, 47.0, 65.0, 76.0, 18.0, 94.0, 88.0, 11.0, 8.0, 14.0, 57.0, 37.0, 4.0, 124.0, 13.0, 77.0, 89.0, 26.0, 16.0, 52.0, 5.0, 145.0, 66.0, 44.0, 38.0, 180.0, 172.0, 62.0, 84.0, 102.0, 188.0, 101.0, 100.0, 38.0, 46.0, 17.0, 22.0, 26.0, 51.0, 25.0, 35.0, 51.0, 66.0, 3.0, 7.0, 112.0, 128.0, 13.0, 1.0, 81.0, 79.0, 122.0, 129.0, 22.0, 198.0, 139.0, 166.0, 17.0, 11.0, 27.0, 46.0, 45.0, 28.0, 5.0, 61.0, 49.0, 32.0, 105.0, 106.0, 4.0, 10.0, 11.0, 69.0, 180.0, 114.0, 28.0, 17.0, 115.0, 107.0, 64.0, 105.0, 107.0, 116.0, 82.0, 72.0, 34.0, 37.0, 53.0, 56.0, 90.0, 98.0, 88.0, 92.0, 31.0, 29.0, 160.0, 54.0, 14.0, 18.0, 15.0, 20.0, 51.0, 35.0, 44.0, 54.0, 170.0, 8.0, 22.0, 8.0, 0.0, 16.0, 9.0, 27.0, 38.0, 50.0, 84.0, 161.0, 46.0, 60.0, 86.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7149319552160991, "mean_inference_ms": 1.8788258722600641, "mean_action_processing_ms": 0.29697019202762837, "mean_env_wait_ms": 0.24334635847173872, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006523609161376953, "StateBufferConnector_ms": 0.007390737533569336, "ViewRequirementAgentConnector_ms": 0.10999715328216553}, "num_episodes": 18, "episode_return_max": 518.6599999999996, "episode_return_min": -183.94, "episode_return_mean": 331.4005999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 312.8887175444611, "num_env_steps_trained_throughput_per_sec": 312.8887175444611, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 11550.284, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11550.21, "sample_time_ms": 1345.447, "learn_time_ms": 10187.946, "learn_throughput": 392.621, "synch_weights_time_ms": 14.3}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "0e60f_00000", "date": "2024-08-15_01-11-05", "timestamp": 1723664465, "time_this_iter_s": 12.831891059875488, "time_total_s": 883.2551784515381, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a303baf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 883.2551784515381, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 58.044444444444444, "ram_util_percent": 83.71111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.042559092259281, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.639156318341613, "policy_loss": -0.0009423492864395181, "vf_loss": 5.638275410384728, "vf_explained_var": -0.08953049081973928, "kl": 0.00853687146631533, "entropy": 0.8965759622987616, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.524344419234644, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.636968598794685, "policy_loss": -0.002569641290902697, "vf_loss": 2.6394095654840823, "vf_explained_var": 0.05395564430605167, "kl": 0.00343157318214147, "entropy": 0.5153588637473091, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 489.38, "episode_reward_min": -183.94, "episode_reward_mean": 326.5083999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -307.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": 109.92920000000002, "predator_policy": 53.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [302.6899999999999, 254.41999999999976, 300.7799999999997, 229.66999999999848, 291.15999999999997, 410.29999999999984, 382.18999999999994, 318.28999999999985, 392.5700000000001, 390.03, 20.72000000000022, 305.78999999999985, 372.06, 340.5999999999996, 336.6700000000001, 370.7499999999999, 337.51, 230.6399999999993, 286.1700000000001, 372.03, 235.42999999999986, 325.54999999999995, 203.90000000000015, 276.74000000000007, 373.08, 272.2399999999997, 236.84999999999997, 294.89999999999986, 294.8999999999992, 385.0999999999999, 204.34000000000015, 275.4099999999999, 405.5299999999998, 423.0799999999999, 308.5699999999998, 299.33999999999975, 357.20999999999987, 379.4499999999997, 313.8999999999995, 357.22, 391.49999999999994, 343.0, 357.69999999999965, 294.9799999999999, 452.56, 323.5499999999999, 415.30999999999995, 272.01, -183.94, 440.78999999999996, 288.85999999999973, 389.39, 409.3699999999999, 372.25, 340.14999999999986, 376.07, 361.37999999999994, 322.29, 155.32000000000005, 365.43999999999994, 344.77, 459.02, 362.14999999999964, 489.38, 246.56999999999923, 380.5999999999996, 290.2499999999999, 433.50999999999976, 310.8399999999996, 447.28999999999974, 358.55999999999955, 283.0199999999999, 485.01, 367.5, 215.02999999999983, 342.6999999999998, 234.49999999999983, 271.0899999999996, 428.03, 358.28999999999996, 306.4099999999997, 379.4999999999998, 359.3699999999999, 276.7299999999999, 202.7399999999993, 428.50999999999965, 351.17999999999984, 253.45000000000022, 210.27999999999997, 356.9700000000001, 440.4899999999997, 280.2099999999997, 345.4299999999989, 217.84999999999985, 245.91999999999973, 371.1099999999999, 313.7600000000001, 295.03999999999985, 481.40999999999985, 470.6099999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [86.69000000000014, 191.0, 89.59999999999997, 118.82000000000002, 67.72999999999992, 189.05, 80.90000000000046, 102.77000000000024, 120.80000000000008, 164.35999999999999, 93.08, 178.21999999999997, 180.17000000000002, 153.02, 81.14000000000013, 38.15000000000001, 185.0, 104.57000000000009, 119.03, 200.0, -24.129999999999708, 7.8499999999999615, 139.28000000000006, 122.5100000000001, 181.01, 174.05, 140.59999999999962, 176.0, 162.05, 33.61999999999992, 170.26999999999992, 110.48000000000008, 149.32999999999998, 170.18, 140.45000000000002, 46.19000000000003, 91.61000000000007, 144.55999999999995, 183.02, 94.00999999999999, 64.88000000000008, 142.55000000000007, 98.0, 145.55000000000004, 66.32, 25.579999999999973, 56.0, 126.73999999999994, 138.05, 53.03, 90.11000000000014, 163.13, 92.57, 73.27999999999999, 134.66000000000008, 119.24000000000001, -26.259999999999852, 184.16, 149.0, 70.10000000000001, 58.07000000000004, 104.26999999999995, 151.36999999999995, 67.03999999999999, 36.109999999999985, 158.42000000000002, 141.08000000000004, 200.0, 113.57000000000018, -157.0, 43.340000000000025, 110.0, 5.149999999999963, 62.06000000000001, 154.39999999999986, 24.049999999999997, 89.66000000000025, 140.24, 157.22, 161.0, 129.5, 185.0, 128.0, 155.0, 134.65999999999968, 106.04, 155.4199999999999, 129.56000000000006, 144.56000000000006, 68.0, 124.40000000000006, 185.14999999999992, 171.29000000000002, 84.02000000000001, 37.010000000000005, -16.0, -96.94, -307.0, -21.310000000000002, 157.1, 112.5500000000001, 148.31000000000017, 137.39000000000001, 179.0, 174.26, 162.11, 160.25, 146.0, 116.15000000000008, 143.0, 56.059999999999995, 109.00999999999999, 180.07999999999998, 167.3, 157.19, 85.1, -255.52, 116.84000000000006, 171.28999999999996, 149.15000000000006, 92.0, 30.769999999999982, 101.0, 189.01999999999998, 36.35000000000001, 102.80000000000018, 192.07999999999998, 143.30000000000007, 117.14000000000003, 58.42999999999984, 115.16000000000008, 156.43999999999997, 129.17000000000007, -26.919999999999987, 176.24, 77.2700000000001, 85.51999999999992, 165.32, 171.28999999999996, 62.0, 185.12000000000003, 141.44000000000005, 116.32999999999997, 131.69, 200.0, 199.01, 160.4, 109.10000000000002, 96.65000000000003, -59.6199999999999, 149.32999999999998, 163.37000000000006, 108.59000000000015, 109.91000000000001, 85.94000000000013, 149.15000000000003, 164.03000000000003, 176.0, 175.25000000000003, -61.95999999999998, 119.39000000000019, 81.02000000000001, 122.12000000000005, 123.38000000000005, 158.27, 175.09999999999997, 98.66000000000014, -19.930000000000007, 103.72999999999998, 73.00999999999982, 155.44999999999993, -6.939999999999998, 155.0, 83.18000000000002, 162.38, 79.07, 139.27999999999994, -286.0, 146.48000000000008, 151.48999999999992, 145.31, 170.18, 143.57000000000008, 133.64000000000007, 90.10999999999987, 162.32, 89.9299999999999, 108.92000000000002, 134.57, 42.35000000000001, 128.0, 144.11000000000004, 146.54, 154.22000000000003, 162.38, 128.66000000000008, 180.20000000000007, 143.21000000000004, 181.19, 95.41999999999997], "policy_predator_policy_reward": [6.0, 19.0, 23.0, 23.0, 17.0, 27.0, 23.0, 23.0, 0.0, 6.0, 99.0, 40.0, 29.0, 20.0, 1.0, 198.0, 51.0, 52.0, 50.0, 21.0, 20.0, 17.0, 32.0, 12.0, 10.0, 7.0, 12.0, 12.0, 41.0, 100.0, 70.0, 20.0, 10.0, 8.0, 15.0, 29.0, 28.0, 22.0, 43.0, 52.0, 22.0, 6.0, 76.0, 6.0, 47.0, 65.0, 76.0, 18.0, 94.0, 88.0, 11.0, 8.0, 14.0, 57.0, 37.0, 4.0, 124.0, 13.0, 77.0, 89.0, 26.0, 16.0, 52.0, 5.0, 145.0, 66.0, 44.0, 38.0, 180.0, 172.0, 62.0, 84.0, 102.0, 188.0, 101.0, 100.0, 38.0, 46.0, 17.0, 22.0, 26.0, 51.0, 25.0, 35.0, 51.0, 66.0, 3.0, 7.0, 112.0, 128.0, 13.0, 1.0, 81.0, 79.0, 122.0, 129.0, 22.0, 198.0, 139.0, 166.0, 17.0, 11.0, 27.0, 46.0, 45.0, 28.0, 5.0, 61.0, 49.0, 32.0, 105.0, 106.0, 4.0, 10.0, 11.0, 69.0, 180.0, 114.0, 28.0, 17.0, 115.0, 107.0, 64.0, 105.0, 107.0, 116.0, 82.0, 72.0, 34.0, 37.0, 53.0, 56.0, 90.0, 98.0, 88.0, 92.0, 31.0, 29.0, 160.0, 54.0, 14.0, 18.0, 15.0, 20.0, 51.0, 35.0, 44.0, 54.0, 170.0, 8.0, 22.0, 8.0, 0.0, 16.0, 9.0, 27.0, 38.0, 50.0, 84.0, 161.0, 46.0, 60.0, 86.0, 48.0, 16.0, 10.0, 96.0, 102.0, 16.0, 10.0, 146.0, 134.0, 52.0, 61.0, 7.0, 5.0, 186.0, 171.0, 34.0, 25.0, 66.0, 59.0, 3.0, 0.0, 91.0, 2.0, 11.0, 8.0, 5.0, 64.0, 58.0, 41.0, 0.0, 13.0, 4.0, 0.0, 138.0, 20.0, 90.0, 104.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7141347664338693, "mean_inference_ms": 1.8788627021784572, "mean_action_processing_ms": 0.29666640612077055, "mean_env_wait_ms": 0.2432061499988505, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006609439849853516, "StateBufferConnector_ms": 0.007433295249938965, "ViewRequirementAgentConnector_ms": 0.12066590785980225}, "num_episodes": 18, "episode_return_max": 489.38, "episode_return_min": -183.94, "episode_return_mean": 326.5083999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 304.46122227130667, "num_env_steps_trained_throughput_per_sec": 304.46122227130667, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 11690.287, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11690.213, "sample_time_ms": 1379.944, "learn_time_ms": 10293.469, "learn_throughput": 388.596, "synch_weights_time_ms": 14.556}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "0e60f_00000", "date": "2024-08-15_01-11-18", "timestamp": 1723664478, "time_this_iter_s": 13.172684907913208, "time_total_s": 896.4278633594513, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a303b820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 896.4278633594513, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 60.71666666666666, "ram_util_percent": 83.55000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5094922507566118, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.356919413268882, "policy_loss": -0.004588129366230633, "vf_loss": 5.35947453080031, "vf_explained_var": 0.047578206074931635, "kl": 0.009518993002355317, "entropy": 0.9639298039454001, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.230204819529145, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8906243862929166, "policy_loss": -0.003866505916304295, "vf_loss": 3.894403802150141, "vf_explained_var": 0.03515037733411032, "kl": 0.004645001032686078, "entropy": 0.6848660732703234, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 489.38, "episode_reward_min": -183.94, "episode_reward_mean": 329.36739999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -307.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 105.91369999999999, "predator_policy": 58.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [203.90000000000015, 276.74000000000007, 373.08, 272.2399999999997, 236.84999999999997, 294.89999999999986, 294.8999999999992, 385.0999999999999, 204.34000000000015, 275.4099999999999, 405.5299999999998, 423.0799999999999, 308.5699999999998, 299.33999999999975, 357.20999999999987, 379.4499999999997, 313.8999999999995, 357.22, 391.49999999999994, 343.0, 357.69999999999965, 294.9799999999999, 452.56, 323.5499999999999, 415.30999999999995, 272.01, -183.94, 440.78999999999996, 288.85999999999973, 389.39, 409.3699999999999, 372.25, 340.14999999999986, 376.07, 361.37999999999994, 322.29, 155.32000000000005, 365.43999999999994, 344.77, 459.02, 362.14999999999964, 489.38, 246.56999999999923, 380.5999999999996, 290.2499999999999, 433.50999999999976, 310.8399999999996, 447.28999999999974, 358.55999999999955, 283.0199999999999, 485.01, 367.5, 215.02999999999983, 342.6999999999998, 234.49999999999983, 271.0899999999996, 428.03, 358.28999999999996, 306.4099999999997, 379.4999999999998, 359.3699999999999, 276.7299999999999, 202.7399999999993, 428.50999999999965, 351.17999999999984, 253.45000000000022, 210.27999999999997, 356.9700000000001, 440.4899999999997, 280.2099999999997, 345.4299999999989, 217.84999999999985, 245.91999999999973, 371.1099999999999, 313.7600000000001, 295.03999999999985, 481.40999999999985, 470.6099999999998, 339.5999999999998, 392.15999999999997, 361.84, 338.74999999999966, 104.54, 288.7699999999992, 347.6899999999997, 313.5499999999999, 384.37999999999977, 303.5699999999999, 346.43, 290.21, 109.2800000000001, 324.6899999999998, 348.6099999999999, 399.3399999999997, 323.78999999999996, 450.15999999999997, 454.13, 211.01, 325.7499999999998, 333.66999999999985], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [66.32, 25.579999999999973, 56.0, 126.73999999999994, 138.05, 53.03, 90.11000000000014, 163.13, 92.57, 73.27999999999999, 134.66000000000008, 119.24000000000001, -26.259999999999852, 184.16, 149.0, 70.10000000000001, 58.07000000000004, 104.26999999999995, 151.36999999999995, 67.03999999999999, 36.109999999999985, 158.42000000000002, 141.08000000000004, 200.0, 113.57000000000018, -157.0, 43.340000000000025, 110.0, 5.149999999999963, 62.06000000000001, 154.39999999999986, 24.049999999999997, 89.66000000000025, 140.24, 157.22, 161.0, 129.5, 185.0, 128.0, 155.0, 134.65999999999968, 106.04, 155.4199999999999, 129.56000000000006, 144.56000000000006, 68.0, 124.40000000000006, 185.14999999999992, 171.29000000000002, 84.02000000000001, 37.010000000000005, -16.0, -96.94, -307.0, -21.310000000000002, 157.1, 112.5500000000001, 148.31000000000017, 137.39000000000001, 179.0, 174.26, 162.11, 160.25, 146.0, 116.15000000000008, 143.0, 56.059999999999995, 109.00999999999999, 180.07999999999998, 167.3, 157.19, 85.1, -255.52, 116.84000000000006, 171.28999999999996, 149.15000000000006, 92.0, 30.769999999999982, 101.0, 189.01999999999998, 36.35000000000001, 102.80000000000018, 192.07999999999998, 143.30000000000007, 117.14000000000003, 58.42999999999984, 115.16000000000008, 156.43999999999997, 129.17000000000007, -26.919999999999987, 176.24, 77.2700000000001, 85.51999999999992, 165.32, 171.28999999999996, 62.0, 185.12000000000003, 141.44000000000005, 116.32999999999997, 131.69, 200.0, 199.01, 160.4, 109.10000000000002, 96.65000000000003, -59.6199999999999, 149.32999999999998, 163.37000000000006, 108.59000000000015, 109.91000000000001, 85.94000000000013, 149.15000000000003, 164.03000000000003, 176.0, 175.25000000000003, -61.95999999999998, 119.39000000000019, 81.02000000000001, 122.12000000000005, 123.38000000000005, 158.27, 175.09999999999997, 98.66000000000014, -19.930000000000007, 103.72999999999998, 73.00999999999982, 155.44999999999993, -6.939999999999998, 155.0, 83.18000000000002, 162.38, 79.07, 139.27999999999994, -286.0, 146.48000000000008, 151.48999999999992, 145.31, 170.18, 143.57000000000008, 133.64000000000007, 90.10999999999987, 162.32, 89.9299999999999, 108.92000000000002, 134.57, 42.35000000000001, 128.0, 144.11000000000004, 146.54, 154.22000000000003, 162.38, 128.66000000000008, 180.20000000000007, 143.21000000000004, 181.19, 95.41999999999997, 173.1799999999999, 155.42000000000007, 62.0, 91.16000000000001, 134.09, 110.74999999999999, 155.38999999999993, 125.35999999999994, 23.540000000000006, -196.0, 28.730000000000015, 193.04000000000002, 114.65000000000003, 196.03999999999996, 128.06, 151.49, 131.03, 165.35000000000014, 11.0, 143.57000000000005, 135.35000000000005, 174.07999999999996, 181.19, -128.98000000000002, 159.23000000000002, -266.95, 170.3, 140.39, 182.17999999999995, 157.43, 107.24000000000005, 103.10000000000001, 158.41999999999996, 142.37000000000006, 167.0, 184.15999999999997, 116.03000000000002, 190.1, 67.00999999999999, -235.0, 150.35000000000005, 160.40000000000003, 136.64000000000001, 155.03], "policy_predator_policy_reward": [47.0, 65.0, 76.0, 18.0, 94.0, 88.0, 11.0, 8.0, 14.0, 57.0, 37.0, 4.0, 124.0, 13.0, 77.0, 89.0, 26.0, 16.0, 52.0, 5.0, 145.0, 66.0, 44.0, 38.0, 180.0, 172.0, 62.0, 84.0, 102.0, 188.0, 101.0, 100.0, 38.0, 46.0, 17.0, 22.0, 26.0, 51.0, 25.0, 35.0, 51.0, 66.0, 3.0, 7.0, 112.0, 128.0, 13.0, 1.0, 81.0, 79.0, 122.0, 129.0, 22.0, 198.0, 139.0, 166.0, 17.0, 11.0, 27.0, 46.0, 45.0, 28.0, 5.0, 61.0, 49.0, 32.0, 105.0, 106.0, 4.0, 10.0, 11.0, 69.0, 180.0, 114.0, 28.0, 17.0, 115.0, 107.0, 64.0, 105.0, 107.0, 116.0, 82.0, 72.0, 34.0, 37.0, 53.0, 56.0, 90.0, 98.0, 88.0, 92.0, 31.0, 29.0, 160.0, 54.0, 14.0, 18.0, 15.0, 20.0, 51.0, 35.0, 44.0, 54.0, 170.0, 8.0, 22.0, 8.0, 0.0, 16.0, 9.0, 27.0, 38.0, 50.0, 84.0, 161.0, 46.0, 60.0, 86.0, 48.0, 16.0, 10.0, 96.0, 102.0, 16.0, 10.0, 146.0, 134.0, 52.0, 61.0, 7.0, 5.0, 186.0, 171.0, 34.0, 25.0, 66.0, 59.0, 3.0, 0.0, 91.0, 2.0, 11.0, 8.0, 5.0, 64.0, 58.0, 41.0, 0.0, 13.0, 4.0, 0.0, 138.0, 20.0, 90.0, 104.0, 5.0, 6.0, 125.0, 114.0, 54.0, 63.0, 4.0, 54.0, 85.0, 192.0, 31.0, 36.0, 9.0, 28.0, 9.0, 25.0, 46.0, 42.0, 71.0, 78.0, 12.0, 25.0, 122.0, 116.0, 17.0, 200.0, 4.0, 10.0, 8.0, 1.0, 93.0, 96.0, 5.0, 18.0, 38.0, 61.0, 74.0, 74.0, 183.0, 196.0, 7.0, 8.0, 14.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7132005288520656, "mean_inference_ms": 1.8813385169850902, "mean_action_processing_ms": 0.2958638423913319, "mean_env_wait_ms": 0.243156983359279, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005286812782287598, "StateBufferConnector_ms": 0.007450461387634277, "ViewRequirementAgentConnector_ms": 0.12114441394805908}, "num_episodes": 22, "episode_return_max": 489.38, "episode_return_min": -183.94, "episode_return_mean": 329.36739999999986, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.5860077025257, "num_env_steps_trained_throughput_per_sec": 320.5860077025257, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 11796.937, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11796.864, "sample_time_ms": 1399.92, "learn_time_ms": 10379.76, "learn_throughput": 385.365, "synch_weights_time_ms": 14.861}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "0e60f_00000", "date": "2024-08-15_01-11-31", "timestamp": 1723664491, "time_this_iter_s": 12.534930229187012, "time_total_s": 908.9627935886383, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a30a2f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 908.9627935886383, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 60.483333333333334, "ram_util_percent": 83.52222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.103492440243877, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.1636809795621845, "policy_loss": -0.004609863624646865, "vf_loss": 6.166368614176593, "vf_explained_var": 0.0608515131725836, "kl": 0.009000243451682403, "entropy": 0.9366081466119757, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.6302046617818258, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.888160251498853, "policy_loss": -0.005083748889180324, "vf_loss": 2.893176256601142, "vf_explained_var": 0.11879510456922823, "kl": 0.0072253449925281325, "entropy": 0.6135726577548123, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 489.38, "episode_reward_min": -183.94, "episode_reward_mean": 330.7187999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -307.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 109.65439999999998, "predator_policy": 55.705}, "custom_metrics": {}, "hist_stats": {"episode_reward": [391.49999999999994, 343.0, 357.69999999999965, 294.9799999999999, 452.56, 323.5499999999999, 415.30999999999995, 272.01, -183.94, 440.78999999999996, 288.85999999999973, 389.39, 409.3699999999999, 372.25, 340.14999999999986, 376.07, 361.37999999999994, 322.29, 155.32000000000005, 365.43999999999994, 344.77, 459.02, 362.14999999999964, 489.38, 246.56999999999923, 380.5999999999996, 290.2499999999999, 433.50999999999976, 310.8399999999996, 447.28999999999974, 358.55999999999955, 283.0199999999999, 485.01, 367.5, 215.02999999999983, 342.6999999999998, 234.49999999999983, 271.0899999999996, 428.03, 358.28999999999996, 306.4099999999997, 379.4999999999998, 359.3699999999999, 276.7299999999999, 202.7399999999993, 428.50999999999965, 351.17999999999984, 253.45000000000022, 210.27999999999997, 356.9700000000001, 440.4899999999997, 280.2099999999997, 345.4299999999989, 217.84999999999985, 245.91999999999973, 371.1099999999999, 313.7600000000001, 295.03999999999985, 481.40999999999985, 470.6099999999998, 339.5999999999998, 392.15999999999997, 361.84, 338.74999999999966, 104.54, 288.7699999999992, 347.6899999999997, 313.5499999999999, 384.37999999999977, 303.5699999999999, 346.43, 290.21, 109.2800000000001, 324.6899999999998, 348.6099999999999, 399.3399999999997, 323.78999999999996, 450.15999999999997, 454.13, 211.01, 325.7499999999998, 333.66999999999985, 271.6600000000001, 321.92999999999984, 188.64999999999978, 371.66999999999985, 304.5599999999998, 424.59999999999997, 247.25999999999937, 324.40999999999985, 323.79999999999956, 294.6899999999996, 372.16999999999985, 308.64, 375.1899999999999, 305.3799999999994, 282.83999999999986, 361.2999999999996, 344.61999999999983, 373.5299999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [129.5, 185.0, 128.0, 155.0, 134.65999999999968, 106.04, 155.4199999999999, 129.56000000000006, 144.56000000000006, 68.0, 124.40000000000006, 185.14999999999992, 171.29000000000002, 84.02000000000001, 37.010000000000005, -16.0, -96.94, -307.0, -21.310000000000002, 157.1, 112.5500000000001, 148.31000000000017, 137.39000000000001, 179.0, 174.26, 162.11, 160.25, 146.0, 116.15000000000008, 143.0, 56.059999999999995, 109.00999999999999, 180.07999999999998, 167.3, 157.19, 85.1, -255.52, 116.84000000000006, 171.28999999999996, 149.15000000000006, 92.0, 30.769999999999982, 101.0, 189.01999999999998, 36.35000000000001, 102.80000000000018, 192.07999999999998, 143.30000000000007, 117.14000000000003, 58.42999999999984, 115.16000000000008, 156.43999999999997, 129.17000000000007, -26.919999999999987, 176.24, 77.2700000000001, 85.51999999999992, 165.32, 171.28999999999996, 62.0, 185.12000000000003, 141.44000000000005, 116.32999999999997, 131.69, 200.0, 199.01, 160.4, 109.10000000000002, 96.65000000000003, -59.6199999999999, 149.32999999999998, 163.37000000000006, 108.59000000000015, 109.91000000000001, 85.94000000000013, 149.15000000000003, 164.03000000000003, 176.0, 175.25000000000003, -61.95999999999998, 119.39000000000019, 81.02000000000001, 122.12000000000005, 123.38000000000005, 158.27, 175.09999999999997, 98.66000000000014, -19.930000000000007, 103.72999999999998, 73.00999999999982, 155.44999999999993, -6.939999999999998, 155.0, 83.18000000000002, 162.38, 79.07, 139.27999999999994, -286.0, 146.48000000000008, 151.48999999999992, 145.31, 170.18, 143.57000000000008, 133.64000000000007, 90.10999999999987, 162.32, 89.9299999999999, 108.92000000000002, 134.57, 42.35000000000001, 128.0, 144.11000000000004, 146.54, 154.22000000000003, 162.38, 128.66000000000008, 180.20000000000007, 143.21000000000004, 181.19, 95.41999999999997, 173.1799999999999, 155.42000000000007, 62.0, 91.16000000000001, 134.09, 110.74999999999999, 155.38999999999993, 125.35999999999994, 23.540000000000006, -196.0, 28.730000000000015, 193.04000000000002, 114.65000000000003, 196.03999999999996, 128.06, 151.49, 131.03, 165.35000000000014, 11.0, 143.57000000000005, 135.35000000000005, 174.07999999999996, 181.19, -128.98000000000002, 159.23000000000002, -266.95, 170.3, 140.39, 182.17999999999995, 157.43, 107.24000000000005, 103.10000000000001, 158.41999999999996, 142.37000000000006, 167.0, 184.15999999999997, 116.03000000000002, 190.1, 67.00999999999999, -235.0, 150.35000000000005, 160.40000000000003, 136.64000000000001, 155.03, 93.08000000000001, 106.58000000000004, 151.42999999999992, 123.50000000000003, 28.220000000000002, -28.570000000000064, 161.39000000000004, 124.28000000000007, 34.25000000000001, 148.31000000000003, 133.28000000000003, 126.32000000000005, 86.95999999999991, 71.29999999999995, 136.39999999999998, 82.00999999999999, 164.08999999999992, 129.7100000000002, 148.24999999999994, 129.43999999999988, 86.0, 183.17000000000007, 101.54000000000008, 145.10000000000002, 124.1, 32.09000000000002, 56.47999999999994, 110.90000000000008, 147.04999999999995, 85.79000000000005, 134.57, 112.73000000000005, 167.08999999999995, 147.53000000000006, 145.43, 154.10000000000002], "policy_predator_policy_reward": [26.0, 51.0, 25.0, 35.0, 51.0, 66.0, 3.0, 7.0, 112.0, 128.0, 13.0, 1.0, 81.0, 79.0, 122.0, 129.0, 22.0, 198.0, 139.0, 166.0, 17.0, 11.0, 27.0, 46.0, 45.0, 28.0, 5.0, 61.0, 49.0, 32.0, 105.0, 106.0, 4.0, 10.0, 11.0, 69.0, 180.0, 114.0, 28.0, 17.0, 115.0, 107.0, 64.0, 105.0, 107.0, 116.0, 82.0, 72.0, 34.0, 37.0, 53.0, 56.0, 90.0, 98.0, 88.0, 92.0, 31.0, 29.0, 160.0, 54.0, 14.0, 18.0, 15.0, 20.0, 51.0, 35.0, 44.0, 54.0, 170.0, 8.0, 22.0, 8.0, 0.0, 16.0, 9.0, 27.0, 38.0, 50.0, 84.0, 161.0, 46.0, 60.0, 86.0, 48.0, 16.0, 10.0, 96.0, 102.0, 16.0, 10.0, 146.0, 134.0, 52.0, 61.0, 7.0, 5.0, 186.0, 171.0, 34.0, 25.0, 66.0, 59.0, 3.0, 0.0, 91.0, 2.0, 11.0, 8.0, 5.0, 64.0, 58.0, 41.0, 0.0, 13.0, 4.0, 0.0, 138.0, 20.0, 90.0, 104.0, 5.0, 6.0, 125.0, 114.0, 54.0, 63.0, 4.0, 54.0, 85.0, 192.0, 31.0, 36.0, 9.0, 28.0, 9.0, 25.0, 46.0, 42.0, 71.0, 78.0, 12.0, 25.0, 122.0, 116.0, 17.0, 200.0, 4.0, 10.0, 8.0, 1.0, 93.0, 96.0, 5.0, 18.0, 38.0, 61.0, 74.0, 74.0, 183.0, 196.0, 7.0, 8.0, 14.0, 28.0, 9.0, 63.0, 42.0, 5.0, 50.0, 139.0, 14.0, 72.0, 79.0, 43.0, 13.0, 152.0, 45.0, 44.0, 56.0, 50.0, 16.0, 14.0, 13.0, 4.0, 46.0, 57.0, 18.0, 44.0, 137.0, 82.0, 67.0, 71.0, 25.0, 25.0, 53.0, 61.0, 15.0, 15.0, 30.0, 44.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7126152424853294, "mean_inference_ms": 1.8821437762908642, "mean_action_processing_ms": 0.2960700660696522, "mean_env_wait_ms": 0.24285644625732167, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00469660758972168, "StateBufferConnector_ms": 0.003412008285522461, "ViewRequirementAgentConnector_ms": 0.11723470687866211}, "num_episodes": 18, "episode_return_max": 489.38, "episode_return_min": -183.94, "episode_return_mean": 330.7187999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.5038101608787, "num_env_steps_trained_throughput_per_sec": 307.5038101608787, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 11983.459, "restore_workers_time_ms": 0.014, "training_step_time_ms": 11983.387, "sample_time_ms": 1424.374, "learn_time_ms": 10541.481, "learn_throughput": 379.453, "synch_weights_time_ms": 15.173}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "0e60f_00000", "date": "2024-08-15_01-11-44", "timestamp": 1723664504, "time_this_iter_s": 13.059863090515137, "time_total_s": 922.0226566791534, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a3119430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 922.0226566791534, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 60.26842105263159, "ram_util_percent": 83.55263157894738}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7354264906159154, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8403761880107656, "policy_loss": -0.00019461145112044596, "vf_loss": 3.8383684935393156, "vf_explained_var": 0.0242643121058348, "kl": 0.010311645018021495, "entropy": 0.8948301977896816, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9549726210889364, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.6635031046690765, "policy_loss": -0.004249025233553121, "vf_loss": 4.667688729649498, "vf_explained_var": 0.05705904039756331, "kl": 0.006762038357108693, "entropy": 0.6606557629411183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 503.34000000000003, "episode_reward_min": 88.2100000000001, "episode_reward_mean": 331.88639999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -348.82000000000016, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 112.39820000000002, "predator_policy": 53.545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [489.38, 246.56999999999923, 380.5999999999996, 290.2499999999999, 433.50999999999976, 310.8399999999996, 447.28999999999974, 358.55999999999955, 283.0199999999999, 485.01, 367.5, 215.02999999999983, 342.6999999999998, 234.49999999999983, 271.0899999999996, 428.03, 358.28999999999996, 306.4099999999997, 379.4999999999998, 359.3699999999999, 276.7299999999999, 202.7399999999993, 428.50999999999965, 351.17999999999984, 253.45000000000022, 210.27999999999997, 356.9700000000001, 440.4899999999997, 280.2099999999997, 345.4299999999989, 217.84999999999985, 245.91999999999973, 371.1099999999999, 313.7600000000001, 295.03999999999985, 481.40999999999985, 470.6099999999998, 339.5999999999998, 392.15999999999997, 361.84, 338.74999999999966, 104.54, 288.7699999999992, 347.6899999999997, 313.5499999999999, 384.37999999999977, 303.5699999999999, 346.43, 290.21, 109.2800000000001, 324.6899999999998, 348.6099999999999, 399.3399999999997, 323.78999999999996, 450.15999999999997, 454.13, 211.01, 325.7499999999998, 333.66999999999985, 271.6600000000001, 321.92999999999984, 188.64999999999978, 371.66999999999985, 304.5599999999998, 424.59999999999997, 247.25999999999937, 324.40999999999985, 323.79999999999956, 294.6899999999996, 372.16999999999985, 308.64, 375.1899999999999, 305.3799999999994, 282.83999999999986, 361.2999999999996, 344.61999999999983, 373.5299999999996, 379.04999999999995, 294.43999999999994, 287.15999999999997, 312.75000000000006, 231.38999999999967, 339.5899999999999, 305.1999999999999, 331.38999999999965, 276.15999999999985, 299.13, 420.12, 339.8099999999994, 395.24, 350.03000000000003, 337.62999999999965, 503.34000000000003, 88.2100000000001, 298.02999999999986, 478.24999999999994, 396.18, 436.4799999999997, 365.46, 305.63999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [192.07999999999998, 143.30000000000007, 117.14000000000003, 58.42999999999984, 115.16000000000008, 156.43999999999997, 129.17000000000007, -26.919999999999987, 176.24, 77.2700000000001, 85.51999999999992, 165.32, 171.28999999999996, 62.0, 185.12000000000003, 141.44000000000005, 116.32999999999997, 131.69, 200.0, 199.01, 160.4, 109.10000000000002, 96.65000000000003, -59.6199999999999, 149.32999999999998, 163.37000000000006, 108.59000000000015, 109.91000000000001, 85.94000000000013, 149.15000000000003, 164.03000000000003, 176.0, 175.25000000000003, -61.95999999999998, 119.39000000000019, 81.02000000000001, 122.12000000000005, 123.38000000000005, 158.27, 175.09999999999997, 98.66000000000014, -19.930000000000007, 103.72999999999998, 73.00999999999982, 155.44999999999993, -6.939999999999998, 155.0, 83.18000000000002, 162.38, 79.07, 139.27999999999994, -286.0, 146.48000000000008, 151.48999999999992, 145.31, 170.18, 143.57000000000008, 133.64000000000007, 90.10999999999987, 162.32, 89.9299999999999, 108.92000000000002, 134.57, 42.35000000000001, 128.0, 144.11000000000004, 146.54, 154.22000000000003, 162.38, 128.66000000000008, 180.20000000000007, 143.21000000000004, 181.19, 95.41999999999997, 173.1799999999999, 155.42000000000007, 62.0, 91.16000000000001, 134.09, 110.74999999999999, 155.38999999999993, 125.35999999999994, 23.540000000000006, -196.0, 28.730000000000015, 193.04000000000002, 114.65000000000003, 196.03999999999996, 128.06, 151.49, 131.03, 165.35000000000014, 11.0, 143.57000000000005, 135.35000000000005, 174.07999999999996, 181.19, -128.98000000000002, 159.23000000000002, -266.95, 170.3, 140.39, 182.17999999999995, 157.43, 107.24000000000005, 103.10000000000001, 158.41999999999996, 142.37000000000006, 167.0, 184.15999999999997, 116.03000000000002, 190.1, 67.00999999999999, -235.0, 150.35000000000005, 160.40000000000003, 136.64000000000001, 155.03, 93.08000000000001, 106.58000000000004, 151.42999999999992, 123.50000000000003, 28.220000000000002, -28.570000000000064, 161.39000000000004, 124.28000000000007, 34.25000000000001, 148.31000000000003, 133.28000000000003, 126.32000000000005, 86.95999999999991, 71.29999999999995, 136.39999999999998, 82.00999999999999, 164.08999999999992, 129.7100000000002, 148.24999999999994, 129.43999999999988, 86.0, 183.17000000000007, 101.54000000000008, 145.10000000000002, 124.1, 32.09000000000002, 56.47999999999994, 110.90000000000008, 147.04999999999995, 85.79000000000005, 134.57, 112.73000000000005, 167.08999999999995, 147.53000000000006, 145.43, 154.10000000000002, 177.05, 173.0, 189.11, -156.67000000000007, 110.08999999999999, 121.07, 158.42, 128.33000000000004, 106.73, 98.66000000000015, 142.13000000000005, 76.46, -10.0, 180.1999999999999, 114.32000000000015, 139.07, 145.34000000000006, 118.81999999999996, -199.87, 113.0, 160.07, 168.05, 83.69000000000003, 188.11999999999995, 17.0, 176.23999999999998, 98.03, 182.0, 146.35999999999996, 173.2700000000001, 166.34, 104.0, -348.82000000000016, 197.02999999999997, 114.23000000000002, 120.80000000000013, 171.07999999999998, 183.17000000000002, 173.0, 80.18, 128.48000000000008, 200.0, 124.00999999999999, 155.45, 176.24, 106.39999999999995], "policy_predator_policy_reward": [82.0, 72.0, 34.0, 37.0, 53.0, 56.0, 90.0, 98.0, 88.0, 92.0, 31.0, 29.0, 160.0, 54.0, 14.0, 18.0, 15.0, 20.0, 51.0, 35.0, 44.0, 54.0, 170.0, 8.0, 22.0, 8.0, 0.0, 16.0, 9.0, 27.0, 38.0, 50.0, 84.0, 161.0, 46.0, 60.0, 86.0, 48.0, 16.0, 10.0, 96.0, 102.0, 16.0, 10.0, 146.0, 134.0, 52.0, 61.0, 7.0, 5.0, 186.0, 171.0, 34.0, 25.0, 66.0, 59.0, 3.0, 0.0, 91.0, 2.0, 11.0, 8.0, 5.0, 64.0, 58.0, 41.0, 0.0, 13.0, 4.0, 0.0, 138.0, 20.0, 90.0, 104.0, 5.0, 6.0, 125.0, 114.0, 54.0, 63.0, 4.0, 54.0, 85.0, 192.0, 31.0, 36.0, 9.0, 28.0, 9.0, 25.0, 46.0, 42.0, 71.0, 78.0, 12.0, 25.0, 122.0, 116.0, 17.0, 200.0, 4.0, 10.0, 8.0, 1.0, 93.0, 96.0, 5.0, 18.0, 38.0, 61.0, 74.0, 74.0, 183.0, 196.0, 7.0, 8.0, 14.0, 28.0, 9.0, 63.0, 42.0, 5.0, 50.0, 139.0, 14.0, 72.0, 79.0, 43.0, 13.0, 152.0, 45.0, 44.0, 56.0, 50.0, 16.0, 14.0, 13.0, 4.0, 46.0, 57.0, 18.0, 44.0, 137.0, 82.0, 67.0, 71.0, 25.0, 25.0, 53.0, 61.0, 15.0, 15.0, 30.0, 44.0, 16.0, 13.0, 136.0, 126.0, 44.0, 12.0, 11.0, 15.0, 14.0, 12.0, 17.0, 104.0, 45.0, 90.0, 36.0, 42.0, 0.0, 12.0, 191.0, 195.0, 23.0, 69.0, 32.0, 36.0, 102.0, 100.0, 34.0, 36.0, 7.0, 11.0, 63.0, 170.0, 188.0, 52.0, 39.0, 24.0, 66.0, 58.0, 78.0, 65.0, 12.0, 96.0, 41.0, 45.0, 21.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7118741767149415, "mean_inference_ms": 1.8858332271059808, "mean_action_processing_ms": 0.29576655537111, "mean_env_wait_ms": 0.24260065351871535, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00443267822265625, "StateBufferConnector_ms": 0.0034602880477905273, "ViewRequirementAgentConnector_ms": 0.12192070484161377}, "num_episodes": 23, "episode_return_max": 503.34000000000003, "episode_return_min": 88.2100000000001, "episode_return_mean": 331.88639999999987, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.2268197235127, "num_env_steps_trained_throughput_per_sec": 324.2268197235127, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 12105.627, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12105.556, "sample_time_ms": 1443.257, "learn_time_ms": 10643.855, "learn_throughput": 375.804, "synch_weights_time_ms": 16.16}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "0e60f_00000", "date": "2024-08-15_01-11-57", "timestamp": 1723664517, "time_this_iter_s": 12.38769006729126, "time_total_s": 934.4103467464447, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2ff63a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 934.4103467464447, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 59.28235294117647, "ram_util_percent": 83.64117647058822}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.7701319801113593, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.488578617005121, "policy_loss": -0.003556835807357279, "vf_loss": 5.490405343827748, "vf_explained_var": 0.18373365039547915, "kl": 0.008100710687648513, "entropy": 0.8797923752239772, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2590003413182718, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.619825369592697, "policy_loss": -0.0055110465288014405, "vf_loss": 3.625253233960066, "vf_explained_var": 0.09301629476446323, "kl": 0.008872674352732675, "entropy": 0.7209862115837279, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 514.1199999999999, "episode_reward_min": 88.2100000000001, "episode_reward_mean": 334.7943999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -348.82000000000016, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 114.23720000000002, "predator_policy": 53.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [379.4999999999998, 359.3699999999999, 276.7299999999999, 202.7399999999993, 428.50999999999965, 351.17999999999984, 253.45000000000022, 210.27999999999997, 356.9700000000001, 440.4899999999997, 280.2099999999997, 345.4299999999989, 217.84999999999985, 245.91999999999973, 371.1099999999999, 313.7600000000001, 295.03999999999985, 481.40999999999985, 470.6099999999998, 339.5999999999998, 392.15999999999997, 361.84, 338.74999999999966, 104.54, 288.7699999999992, 347.6899999999997, 313.5499999999999, 384.37999999999977, 303.5699999999999, 346.43, 290.21, 109.2800000000001, 324.6899999999998, 348.6099999999999, 399.3399999999997, 323.78999999999996, 450.15999999999997, 454.13, 211.01, 325.7499999999998, 333.66999999999985, 271.6600000000001, 321.92999999999984, 188.64999999999978, 371.66999999999985, 304.5599999999998, 424.59999999999997, 247.25999999999937, 324.40999999999985, 323.79999999999956, 294.6899999999996, 372.16999999999985, 308.64, 375.1899999999999, 305.3799999999994, 282.83999999999986, 361.2999999999996, 344.61999999999983, 373.5299999999996, 379.04999999999995, 294.43999999999994, 287.15999999999997, 312.75000000000006, 231.38999999999967, 339.5899999999999, 305.1999999999999, 331.38999999999965, 276.15999999999985, 299.13, 420.12, 339.8099999999994, 395.24, 350.03000000000003, 337.62999999999965, 503.34000000000003, 88.2100000000001, 298.02999999999986, 478.24999999999994, 396.18, 436.4799999999997, 365.46, 305.63999999999993, 364.3099999999998, 256.9999999999995, 394.28, 346.23999999999984, 514.1199999999999, 370.50999999999993, 386.2399999999999, 335.38999999999993, 323.7099999999999, 302.68, 391.6499999999999, 314.0699999999999, 464.4999999999999, 411.6899999999997, 346.2199999999999, 339.48, 268.87, 408.4199999999998], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [122.12000000000005, 123.38000000000005, 158.27, 175.09999999999997, 98.66000000000014, -19.930000000000007, 103.72999999999998, 73.00999999999982, 155.44999999999993, -6.939999999999998, 155.0, 83.18000000000002, 162.38, 79.07, 139.27999999999994, -286.0, 146.48000000000008, 151.48999999999992, 145.31, 170.18, 143.57000000000008, 133.64000000000007, 90.10999999999987, 162.32, 89.9299999999999, 108.92000000000002, 134.57, 42.35000000000001, 128.0, 144.11000000000004, 146.54, 154.22000000000003, 162.38, 128.66000000000008, 180.20000000000007, 143.21000000000004, 181.19, 95.41999999999997, 173.1799999999999, 155.42000000000007, 62.0, 91.16000000000001, 134.09, 110.74999999999999, 155.38999999999993, 125.35999999999994, 23.540000000000006, -196.0, 28.730000000000015, 193.04000000000002, 114.65000000000003, 196.03999999999996, 128.06, 151.49, 131.03, 165.35000000000014, 11.0, 143.57000000000005, 135.35000000000005, 174.07999999999996, 181.19, -128.98000000000002, 159.23000000000002, -266.95, 170.3, 140.39, 182.17999999999995, 157.43, 107.24000000000005, 103.10000000000001, 158.41999999999996, 142.37000000000006, 167.0, 184.15999999999997, 116.03000000000002, 190.1, 67.00999999999999, -235.0, 150.35000000000005, 160.40000000000003, 136.64000000000001, 155.03, 93.08000000000001, 106.58000000000004, 151.42999999999992, 123.50000000000003, 28.220000000000002, -28.570000000000064, 161.39000000000004, 124.28000000000007, 34.25000000000001, 148.31000000000003, 133.28000000000003, 126.32000000000005, 86.95999999999991, 71.29999999999995, 136.39999999999998, 82.00999999999999, 164.08999999999992, 129.7100000000002, 148.24999999999994, 129.43999999999988, 86.0, 183.17000000000007, 101.54000000000008, 145.10000000000002, 124.1, 32.09000000000002, 56.47999999999994, 110.90000000000008, 147.04999999999995, 85.79000000000005, 134.57, 112.73000000000005, 167.08999999999995, 147.53000000000006, 145.43, 154.10000000000002, 177.05, 173.0, 189.11, -156.67000000000007, 110.08999999999999, 121.07, 158.42, 128.33000000000004, 106.73, 98.66000000000015, 142.13000000000005, 76.46, -10.0, 180.1999999999999, 114.32000000000015, 139.07, 145.34000000000006, 118.81999999999996, -199.87, 113.0, 160.07, 168.05, 83.69000000000003, 188.11999999999995, 17.0, 176.23999999999998, 98.03, 182.0, 146.35999999999996, 173.2700000000001, 166.34, 104.0, -348.82000000000016, 197.02999999999997, 114.23000000000002, 120.80000000000013, 171.07999999999998, 183.17000000000002, 173.0, 80.18, 128.48000000000008, 200.0, 124.00999999999999, 155.45, 176.24, 106.39999999999995, 108.2600000000001, 195.04999999999998, 79.64000000000026, 137.35999999999993, 103.07, 125.21000000000002, 139.1900000000001, 147.05, 122.06, 194.05999999999995, 153.05, 94.46000000000004, 160.04, 180.20000000000005, 114.76999999999992, 57.61999999999992, 111.23000000000005, 152.4800000000001, 139.27999999999997, 127.4, 117.5300000000001, 164.12, 112.88000000000011, 169.18999999999997, 132.5, 125.0, 67.57999999999991, 114.10999999999999, 160.22000000000003, 158.0, 77.21000000000001, 158.26999999999998, 129.52999999999997, 22.339999999999957, 178.19, 162.2299999999999], "policy_predator_policy_reward": [86.0, 48.0, 16.0, 10.0, 96.0, 102.0, 16.0, 10.0, 146.0, 134.0, 52.0, 61.0, 7.0, 5.0, 186.0, 171.0, 34.0, 25.0, 66.0, 59.0, 3.0, 0.0, 91.0, 2.0, 11.0, 8.0, 5.0, 64.0, 58.0, 41.0, 0.0, 13.0, 4.0, 0.0, 138.0, 20.0, 90.0, 104.0, 5.0, 6.0, 125.0, 114.0, 54.0, 63.0, 4.0, 54.0, 85.0, 192.0, 31.0, 36.0, 9.0, 28.0, 9.0, 25.0, 46.0, 42.0, 71.0, 78.0, 12.0, 25.0, 122.0, 116.0, 17.0, 200.0, 4.0, 10.0, 8.0, 1.0, 93.0, 96.0, 5.0, 18.0, 38.0, 61.0, 74.0, 74.0, 183.0, 196.0, 7.0, 8.0, 14.0, 28.0, 9.0, 63.0, 42.0, 5.0, 50.0, 139.0, 14.0, 72.0, 79.0, 43.0, 13.0, 152.0, 45.0, 44.0, 56.0, 50.0, 16.0, 14.0, 13.0, 4.0, 46.0, 57.0, 18.0, 44.0, 137.0, 82.0, 67.0, 71.0, 25.0, 25.0, 53.0, 61.0, 15.0, 15.0, 30.0, 44.0, 16.0, 13.0, 136.0, 126.0, 44.0, 12.0, 11.0, 15.0, 14.0, 12.0, 17.0, 104.0, 45.0, 90.0, 36.0, 42.0, 0.0, 12.0, 191.0, 195.0, 23.0, 69.0, 32.0, 36.0, 102.0, 100.0, 34.0, 36.0, 7.0, 11.0, 63.0, 170.0, 188.0, 52.0, 39.0, 24.0, 66.0, 58.0, 78.0, 65.0, 12.0, 96.0, 41.0, 45.0, 21.0, 2.0, 33.0, 28.0, 17.0, 23.0, 90.0, 76.0, 36.0, 24.0, 98.0, 100.0, 20.0, 103.0, 26.0, 20.0, 161.0, 2.0, 31.0, 29.0, 16.0, 20.0, 19.0, 91.0, 29.0, 3.0, 114.0, 93.0, 123.0, 107.0, 12.0, 16.0, 55.0, 49.0, 38.0, 79.0, 11.0, 57.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7112946381427588, "mean_inference_ms": 1.8887724282465377, "mean_action_processing_ms": 0.2954991261620136, "mean_env_wait_ms": 0.24244403064943845, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004513859748840332, "StateBufferConnector_ms": 0.003482341766357422, "ViewRequirementAgentConnector_ms": 0.12101852893829346}, "num_episodes": 18, "episode_return_max": 514.1199999999999, "episode_return_min": 88.2100000000001, "episode_return_mean": 334.7943999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.4796950460888, "num_env_steps_trained_throughput_per_sec": 307.4796950460888, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 12278.03, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12277.957, "sample_time_ms": 1480.437, "learn_time_ms": 10778.403, "learn_throughput": 371.113, "synch_weights_time_ms": 16.571}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "0e60f_00000", "date": "2024-08-15_01-12-10", "timestamp": 1723664530, "time_this_iter_s": 13.045323133468628, "time_total_s": 947.4556698799133, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2ff6d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 947.4556698799133, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 59.821052631578944, "ram_util_percent": 83.32631578947368}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.2493471079087133, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.810117829161347, "policy_loss": -0.0006627580072119753, "vf_loss": 4.808939957997156, "vf_explained_var": 0.08399208295282233, "kl": 0.008618186535410665, "entropy": 0.7952917376838664, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.418335754152328, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.108551277685418, "policy_loss": -0.0037563361116640624, "vf_loss": 5.1122445136781725, "vf_explained_var": 0.02428961998571164, "kl": 0.0067319865028033716, "entropy": 0.8094985961598694, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 603.3799999999997, "episode_reward_min": 88.2100000000001, "episode_reward_mean": 341.9981999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -348.82000000000016, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 113.71910000000001, "predator_policy": 57.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [338.74999999999966, 104.54, 288.7699999999992, 347.6899999999997, 313.5499999999999, 384.37999999999977, 303.5699999999999, 346.43, 290.21, 109.2800000000001, 324.6899999999998, 348.6099999999999, 399.3399999999997, 323.78999999999996, 450.15999999999997, 454.13, 211.01, 325.7499999999998, 333.66999999999985, 271.6600000000001, 321.92999999999984, 188.64999999999978, 371.66999999999985, 304.5599999999998, 424.59999999999997, 247.25999999999937, 324.40999999999985, 323.79999999999956, 294.6899999999996, 372.16999999999985, 308.64, 375.1899999999999, 305.3799999999994, 282.83999999999986, 361.2999999999996, 344.61999999999983, 373.5299999999996, 379.04999999999995, 294.43999999999994, 287.15999999999997, 312.75000000000006, 231.38999999999967, 339.5899999999999, 305.1999999999999, 331.38999999999965, 276.15999999999985, 299.13, 420.12, 339.8099999999994, 395.24, 350.03000000000003, 337.62999999999965, 503.34000000000003, 88.2100000000001, 298.02999999999986, 478.24999999999994, 396.18, 436.4799999999997, 365.46, 305.63999999999993, 364.3099999999998, 256.9999999999995, 394.28, 346.23999999999984, 514.1199999999999, 370.50999999999993, 386.2399999999999, 335.38999999999993, 323.7099999999999, 302.68, 391.6499999999999, 314.0699999999999, 464.4999999999999, 411.6899999999997, 346.2199999999999, 339.48, 268.87, 408.4199999999998, 444.40999999999997, 379.89999999999986, 338.53, 414.18999999999994, 411.10999999999996, 355.6399999999998, 334.39999999999986, 333.4899999999999, 336.33999999999975, 223.66999999999982, 296.7899999999999, 338.12, 424.5799999999995, 345.0999999999999, 347.40999999999985, 307.44, 341.6399999999999, 413.10999999999996, 404.08000000000004, 363.2399999999999, 603.3799999999997, 337.96999999999946], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [155.38999999999993, 125.35999999999994, 23.540000000000006, -196.0, 28.730000000000015, 193.04000000000002, 114.65000000000003, 196.03999999999996, 128.06, 151.49, 131.03, 165.35000000000014, 11.0, 143.57000000000005, 135.35000000000005, 174.07999999999996, 181.19, -128.98000000000002, 159.23000000000002, -266.95, 170.3, 140.39, 182.17999999999995, 157.43, 107.24000000000005, 103.10000000000001, 158.41999999999996, 142.37000000000006, 167.0, 184.15999999999997, 116.03000000000002, 190.1, 67.00999999999999, -235.0, 150.35000000000005, 160.40000000000003, 136.64000000000001, 155.03, 93.08000000000001, 106.58000000000004, 151.42999999999992, 123.50000000000003, 28.220000000000002, -28.570000000000064, 161.39000000000004, 124.28000000000007, 34.25000000000001, 148.31000000000003, 133.28000000000003, 126.32000000000005, 86.95999999999991, 71.29999999999995, 136.39999999999998, 82.00999999999999, 164.08999999999992, 129.7100000000002, 148.24999999999994, 129.43999999999988, 86.0, 183.17000000000007, 101.54000000000008, 145.10000000000002, 124.1, 32.09000000000002, 56.47999999999994, 110.90000000000008, 147.04999999999995, 85.79000000000005, 134.57, 112.73000000000005, 167.08999999999995, 147.53000000000006, 145.43, 154.10000000000002, 177.05, 173.0, 189.11, -156.67000000000007, 110.08999999999999, 121.07, 158.42, 128.33000000000004, 106.73, 98.66000000000015, 142.13000000000005, 76.46, -10.0, 180.1999999999999, 114.32000000000015, 139.07, 145.34000000000006, 118.81999999999996, -199.87, 113.0, 160.07, 168.05, 83.69000000000003, 188.11999999999995, 17.0, 176.23999999999998, 98.03, 182.0, 146.35999999999996, 173.2700000000001, 166.34, 104.0, -348.82000000000016, 197.02999999999997, 114.23000000000002, 120.80000000000013, 171.07999999999998, 183.17000000000002, 173.0, 80.18, 128.48000000000008, 200.0, 124.00999999999999, 155.45, 176.24, 106.39999999999995, 108.2600000000001, 195.04999999999998, 79.64000000000026, 137.35999999999993, 103.07, 125.21000000000002, 139.1900000000001, 147.05, 122.06, 194.05999999999995, 153.05, 94.46000000000004, 160.04, 180.20000000000005, 114.76999999999992, 57.61999999999992, 111.23000000000005, 152.4800000000001, 139.27999999999997, 127.4, 117.5300000000001, 164.12, 112.88000000000011, 169.18999999999997, 132.5, 125.0, 67.57999999999991, 114.10999999999999, 160.22000000000003, 158.0, 77.21000000000001, 158.26999999999998, 129.52999999999997, 22.339999999999957, 178.19, 162.2299999999999, 119.0, 159.41, 113.72, 53.17999999999997, 181.19, 145.33999999999997, 166.04000000000002, 167.15, 92.0, 168.10999999999996, 77.21000000000005, 106.43000000000009, 153.31999999999994, 27.08000000000001, 139.36999999999998, 50.11999999999998, 142.33999999999986, 26.0, 76.01, 134.66000000000003, 130.43000000000006, 149.36000000000004, 128.08999999999997, 44.03, 169.24999999999977, 155.33000000000015, 50.03, 76.07000000000004, -58.0, 126.41000000000012, 156.38, 32.06000000000002, 147.32, 141.31999999999996, 176.0, 132.11, 163.01, 148.07, 55.129999999999995, 144.11, 187.12999999999997, 118.24999999999999, -26.44000000000011, 78.41000000000005], "policy_predator_policy_reward": [4.0, 54.0, 85.0, 192.0, 31.0, 36.0, 9.0, 28.0, 9.0, 25.0, 46.0, 42.0, 71.0, 78.0, 12.0, 25.0, 122.0, 116.0, 17.0, 200.0, 4.0, 10.0, 8.0, 1.0, 93.0, 96.0, 5.0, 18.0, 38.0, 61.0, 74.0, 74.0, 183.0, 196.0, 7.0, 8.0, 14.0, 28.0, 9.0, 63.0, 42.0, 5.0, 50.0, 139.0, 14.0, 72.0, 79.0, 43.0, 13.0, 152.0, 45.0, 44.0, 56.0, 50.0, 16.0, 14.0, 13.0, 4.0, 46.0, 57.0, 18.0, 44.0, 137.0, 82.0, 67.0, 71.0, 25.0, 25.0, 53.0, 61.0, 15.0, 15.0, 30.0, 44.0, 16.0, 13.0, 136.0, 126.0, 44.0, 12.0, 11.0, 15.0, 14.0, 12.0, 17.0, 104.0, 45.0, 90.0, 36.0, 42.0, 0.0, 12.0, 191.0, 195.0, 23.0, 69.0, 32.0, 36.0, 102.0, 100.0, 34.0, 36.0, 7.0, 11.0, 63.0, 170.0, 188.0, 52.0, 39.0, 24.0, 66.0, 58.0, 78.0, 65.0, 12.0, 96.0, 41.0, 45.0, 21.0, 2.0, 33.0, 28.0, 17.0, 23.0, 90.0, 76.0, 36.0, 24.0, 98.0, 100.0, 20.0, 103.0, 26.0, 20.0, 161.0, 2.0, 31.0, 29.0, 16.0, 20.0, 19.0, 91.0, 29.0, 3.0, 114.0, 93.0, 123.0, 107.0, 12.0, 16.0, 55.0, 49.0, 38.0, 79.0, 11.0, 57.0, 78.0, 88.0, 122.0, 91.0, 3.0, 9.0, 34.0, 47.0, 78.0, 73.0, 79.0, 93.0, 89.0, 65.0, 74.0, 70.0, 100.0, 68.0, 0.0, 13.0, 11.0, 6.0, 82.0, 84.0, 39.0, 61.0, 110.0, 109.0, 79.0, 200.0, 115.0, 4.0, 49.0, 4.0, 52.0, 53.0, 60.0, 33.0, 23.0, 141.0, 157.0, 141.0, 123.0, 163.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7103825601763865, "mean_inference_ms": 1.8925142877629366, "mean_action_processing_ms": 0.2945922959253118, "mean_env_wait_ms": 0.24227972105383366, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004050016403198242, "StateBufferConnector_ms": 0.0033016204833984375, "ViewRequirementAgentConnector_ms": 0.10752522945404053}, "num_episodes": 22, "episode_return_max": 603.3799999999997, "episode_return_min": 88.2100000000001, "episode_return_mean": 341.9981999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.5161448711491, "num_env_steps_trained_throughput_per_sec": 322.5161448711491, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 12400.818, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12400.764, "sample_time_ms": 1501.568, "learn_time_ms": 10879.261, "learn_throughput": 367.672, "synch_weights_time_ms": 17.271}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "0e60f_00000", "date": "2024-08-15_01-12-22", "timestamp": 1723664542, "time_this_iter_s": 12.445496082305908, "time_total_s": 959.9011659622192, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2fe0550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 959.9011659622192, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 59.34117647058823, "ram_util_percent": 83.3}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0715963974831597, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.123588296976039, "policy_loss": -0.0007012773177059239, "vf_loss": 4.1231968045865415, "vf_explained_var": 0.1135553587050665, "kl": 0.005116629087817119, "entropy": 0.8435816561418866, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5688113307195994, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.838322087822768, "policy_loss": -0.00498390383242319, "vf_loss": 3.843240610632316, "vf_explained_var": 0.021402827993271843, "kl": 0.00697453742596596, "entropy": 0.6275935484934105, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 603.3799999999997, "episode_reward_min": 88.2100000000001, "episode_reward_mean": 354.9754999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -348.82000000000016, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 120.16775000000001, "predator_policy": 57.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [333.66999999999985, 271.6600000000001, 321.92999999999984, 188.64999999999978, 371.66999999999985, 304.5599999999998, 424.59999999999997, 247.25999999999937, 324.40999999999985, 323.79999999999956, 294.6899999999996, 372.16999999999985, 308.64, 375.1899999999999, 305.3799999999994, 282.83999999999986, 361.2999999999996, 344.61999999999983, 373.5299999999996, 379.04999999999995, 294.43999999999994, 287.15999999999997, 312.75000000000006, 231.38999999999967, 339.5899999999999, 305.1999999999999, 331.38999999999965, 276.15999999999985, 299.13, 420.12, 339.8099999999994, 395.24, 350.03000000000003, 337.62999999999965, 503.34000000000003, 88.2100000000001, 298.02999999999986, 478.24999999999994, 396.18, 436.4799999999997, 365.46, 305.63999999999993, 364.3099999999998, 256.9999999999995, 394.28, 346.23999999999984, 514.1199999999999, 370.50999999999993, 386.2399999999999, 335.38999999999993, 323.7099999999999, 302.68, 391.6499999999999, 314.0699999999999, 464.4999999999999, 411.6899999999997, 346.2199999999999, 339.48, 268.87, 408.4199999999998, 444.40999999999997, 379.89999999999986, 338.53, 414.18999999999994, 411.10999999999996, 355.6399999999998, 334.39999999999986, 333.4899999999999, 336.33999999999975, 223.66999999999982, 296.7899999999999, 338.12, 424.5799999999995, 345.0999999999999, 347.40999999999985, 307.44, 341.6399999999999, 413.10999999999996, 404.08000000000004, 363.2399999999999, 603.3799999999997, 337.96999999999946, 520.27, 458.16999999999985, 392.4499999999998, 365.55999999999983, 267.03000000000003, 421.7199999999999, 361.5100000000001, 386.54999999999984, 421.28, 379.2999999999998, 407.2499999999999, 362.5699999999999, 361.51999999999975, 448.07, 319.47999999999996, 337.51999999999987, 336.1099999999999, 416.02], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [136.64000000000001, 155.03, 93.08000000000001, 106.58000000000004, 151.42999999999992, 123.50000000000003, 28.220000000000002, -28.570000000000064, 161.39000000000004, 124.28000000000007, 34.25000000000001, 148.31000000000003, 133.28000000000003, 126.32000000000005, 86.95999999999991, 71.29999999999995, 136.39999999999998, 82.00999999999999, 164.08999999999992, 129.7100000000002, 148.24999999999994, 129.43999999999988, 86.0, 183.17000000000007, 101.54000000000008, 145.10000000000002, 124.1, 32.09000000000002, 56.47999999999994, 110.90000000000008, 147.04999999999995, 85.79000000000005, 134.57, 112.73000000000005, 167.08999999999995, 147.53000000000006, 145.43, 154.10000000000002, 177.05, 173.0, 189.11, -156.67000000000007, 110.08999999999999, 121.07, 158.42, 128.33000000000004, 106.73, 98.66000000000015, 142.13000000000005, 76.46, -10.0, 180.1999999999999, 114.32000000000015, 139.07, 145.34000000000006, 118.81999999999996, -199.87, 113.0, 160.07, 168.05, 83.69000000000003, 188.11999999999995, 17.0, 176.23999999999998, 98.03, 182.0, 146.35999999999996, 173.2700000000001, 166.34, 104.0, -348.82000000000016, 197.02999999999997, 114.23000000000002, 120.80000000000013, 171.07999999999998, 183.17000000000002, 173.0, 80.18, 128.48000000000008, 200.0, 124.00999999999999, 155.45, 176.24, 106.39999999999995, 108.2600000000001, 195.04999999999998, 79.64000000000026, 137.35999999999993, 103.07, 125.21000000000002, 139.1900000000001, 147.05, 122.06, 194.05999999999995, 153.05, 94.46000000000004, 160.04, 180.20000000000005, 114.76999999999992, 57.61999999999992, 111.23000000000005, 152.4800000000001, 139.27999999999997, 127.4, 117.5300000000001, 164.12, 112.88000000000011, 169.18999999999997, 132.5, 125.0, 67.57999999999991, 114.10999999999999, 160.22000000000003, 158.0, 77.21000000000001, 158.26999999999998, 129.52999999999997, 22.339999999999957, 178.19, 162.2299999999999, 119.0, 159.41, 113.72, 53.17999999999997, 181.19, 145.33999999999997, 166.04000000000002, 167.15, 92.0, 168.10999999999996, 77.21000000000005, 106.43000000000009, 153.31999999999994, 27.08000000000001, 139.36999999999998, 50.11999999999998, 142.33999999999986, 26.0, 76.01, 134.66000000000003, 130.43000000000006, 149.36000000000004, 128.08999999999997, 44.03, 169.24999999999977, 155.33000000000015, 50.03, 76.07000000000004, -58.0, 126.41000000000012, 156.38, 32.06000000000002, 147.32, 141.31999999999996, 176.0, 132.11, 163.01, 148.07, 55.129999999999995, 144.11, 187.12999999999997, 118.24999999999999, -26.44000000000011, 78.41000000000005, 173.26999999999995, 131.0, 173.0, 183.16999999999985, 168.31999999999994, 79.13000000000007, 129.44000000000003, 185.12, 65.03, -7.0, 190.1, 108.62000000000005, 168.32, 163.18999999999997, 125.0, 115.5500000000001, 175.25, 110.03000000000002, 184.15999999999994, 162.14, 135.11000000000007, 186.14000000000001, 151.31000000000003, 174.26000000000005, -6.910000000000011, 154.4300000000001, 149.0, 193.07, 157.43, -14.950000000000003, 169.19000000000005, 149.33, 189.10999999999996, -1.0, 168.01999999999998, 140.0], "policy_predator_policy_reward": [14.0, 28.0, 9.0, 63.0, 42.0, 5.0, 50.0, 139.0, 14.0, 72.0, 79.0, 43.0, 13.0, 152.0, 45.0, 44.0, 56.0, 50.0, 16.0, 14.0, 13.0, 4.0, 46.0, 57.0, 18.0, 44.0, 137.0, 82.0, 67.0, 71.0, 25.0, 25.0, 53.0, 61.0, 15.0, 15.0, 30.0, 44.0, 16.0, 13.0, 136.0, 126.0, 44.0, 12.0, 11.0, 15.0, 14.0, 12.0, 17.0, 104.0, 45.0, 90.0, 36.0, 42.0, 0.0, 12.0, 191.0, 195.0, 23.0, 69.0, 32.0, 36.0, 102.0, 100.0, 34.0, 36.0, 7.0, 11.0, 63.0, 170.0, 188.0, 52.0, 39.0, 24.0, 66.0, 58.0, 78.0, 65.0, 12.0, 96.0, 41.0, 45.0, 21.0, 2.0, 33.0, 28.0, 17.0, 23.0, 90.0, 76.0, 36.0, 24.0, 98.0, 100.0, 20.0, 103.0, 26.0, 20.0, 161.0, 2.0, 31.0, 29.0, 16.0, 20.0, 19.0, 91.0, 29.0, 3.0, 114.0, 93.0, 123.0, 107.0, 12.0, 16.0, 55.0, 49.0, 38.0, 79.0, 11.0, 57.0, 78.0, 88.0, 122.0, 91.0, 3.0, 9.0, 34.0, 47.0, 78.0, 73.0, 79.0, 93.0, 89.0, 65.0, 74.0, 70.0, 100.0, 68.0, 0.0, 13.0, 11.0, 6.0, 82.0, 84.0, 39.0, 61.0, 110.0, 109.0, 79.0, 200.0, 115.0, 4.0, 49.0, 4.0, 52.0, 53.0, 60.0, 33.0, 23.0, 141.0, 157.0, 141.0, 123.0, 163.0, 102.0, 114.0, 51.0, 51.0, 75.0, 70.0, 12.0, 39.0, 117.0, 92.0, 41.0, 82.0, 29.0, 1.0, 132.0, 14.0, 69.0, 67.0, 20.0, 13.0, 56.0, 30.0, 32.0, 5.0, 102.0, 112.0, 57.0, 49.0, 84.0, 93.0, 14.0, 5.0, 75.0, 73.0, 56.0, 52.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7098273952276817, "mean_inference_ms": 1.8937313255915607, "mean_action_processing_ms": 0.29473081086406816, "mean_env_wait_ms": 0.24199560449293395, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004065513610839844, "StateBufferConnector_ms": 0.003254532814025879, "ViewRequirementAgentConnector_ms": 0.10942816734313965}, "num_episodes": 18, "episode_return_max": 603.3799999999997, "episode_return_min": 88.2100000000001, "episode_return_mean": 354.9754999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 321.96801697601865, "num_env_steps_trained_throughput_per_sec": 321.96801697601865, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 12498.458, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12498.404, "sample_time_ms": 1525.171, "learn_time_ms": 10952.617, "learn_throughput": 365.21, "synch_weights_time_ms": 17.656}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "0e60f_00000", "date": "2024-08-15_01-12-35", "timestamp": 1723664555, "time_this_iter_s": 12.461041927337646, "time_total_s": 972.3622078895569, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a303bb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 972.3622078895569, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 59.17777777777777, "ram_util_percent": 83.00555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.716710467218722, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4763763897633426, "policy_loss": -0.0027465248050503235, "vf_loss": 3.477982408659799, "vf_explained_var": 0.10610315042828757, "kl": 0.005340108232244864, "entropy": 0.8490761461396696, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.296520395726754, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9509188018778643, "policy_loss": -0.0019106438794917373, "vf_loss": 3.952779599850771, "vf_explained_var": 0.036822083072056845, "kl": 0.005316566047035873, "entropy": 0.7910804641940606, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 603.3799999999997, "episode_reward_min": 88.2100000000001, "episode_reward_mean": 362.1841999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -348.82000000000016, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 123.7871, "predator_policy": 57.305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [231.38999999999967, 339.5899999999999, 305.1999999999999, 331.38999999999965, 276.15999999999985, 299.13, 420.12, 339.8099999999994, 395.24, 350.03000000000003, 337.62999999999965, 503.34000000000003, 88.2100000000001, 298.02999999999986, 478.24999999999994, 396.18, 436.4799999999997, 365.46, 305.63999999999993, 364.3099999999998, 256.9999999999995, 394.28, 346.23999999999984, 514.1199999999999, 370.50999999999993, 386.2399999999999, 335.38999999999993, 323.7099999999999, 302.68, 391.6499999999999, 314.0699999999999, 464.4999999999999, 411.6899999999997, 346.2199999999999, 339.48, 268.87, 408.4199999999998, 444.40999999999997, 379.89999999999986, 338.53, 414.18999999999994, 411.10999999999996, 355.6399999999998, 334.39999999999986, 333.4899999999999, 336.33999999999975, 223.66999999999982, 296.7899999999999, 338.12, 424.5799999999995, 345.0999999999999, 347.40999999999985, 307.44, 341.6399999999999, 413.10999999999996, 404.08000000000004, 363.2399999999999, 603.3799999999997, 337.96999999999946, 520.27, 458.16999999999985, 392.4499999999998, 365.55999999999983, 267.03000000000003, 421.7199999999999, 361.5100000000001, 386.54999999999984, 421.28, 379.2999999999998, 407.2499999999999, 362.5699999999999, 361.51999999999975, 448.07, 319.47999999999996, 337.51999999999987, 336.1099999999999, 416.02, 241.41000000000003, 392.4099999999997, 349.5399999999998, 388.2499999999999, 364.0999999999999, 364.4899999999999, 316.69999999999993, 386.1, 382.18999999999994, 381.17, 578.15, 357.42999999999995, 387.21, 101.31000000000003, 417.42999999999995, 450.3999999999999, 316.88, 430.03999999999996, 258.99, 407.19000000000005, 192.71000000000004, 324.13, 336.61000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [106.73, 98.66000000000015, 142.13000000000005, 76.46, -10.0, 180.1999999999999, 114.32000000000015, 139.07, 145.34000000000006, 118.81999999999996, -199.87, 113.0, 160.07, 168.05, 83.69000000000003, 188.11999999999995, 17.0, 176.23999999999998, 98.03, 182.0, 146.35999999999996, 173.2700000000001, 166.34, 104.0, -348.82000000000016, 197.02999999999997, 114.23000000000002, 120.80000000000013, 171.07999999999998, 183.17000000000002, 173.0, 80.18, 128.48000000000008, 200.0, 124.00999999999999, 155.45, 176.24, 106.39999999999995, 108.2600000000001, 195.04999999999998, 79.64000000000026, 137.35999999999993, 103.07, 125.21000000000002, 139.1900000000001, 147.05, 122.06, 194.05999999999995, 153.05, 94.46000000000004, 160.04, 180.20000000000005, 114.76999999999992, 57.61999999999992, 111.23000000000005, 152.4800000000001, 139.27999999999997, 127.4, 117.5300000000001, 164.12, 112.88000000000011, 169.18999999999997, 132.5, 125.0, 67.57999999999991, 114.10999999999999, 160.22000000000003, 158.0, 77.21000000000001, 158.26999999999998, 129.52999999999997, 22.339999999999957, 178.19, 162.2299999999999, 119.0, 159.41, 113.72, 53.17999999999997, 181.19, 145.33999999999997, 166.04000000000002, 167.15, 92.0, 168.10999999999996, 77.21000000000005, 106.43000000000009, 153.31999999999994, 27.08000000000001, 139.36999999999998, 50.11999999999998, 142.33999999999986, 26.0, 76.01, 134.66000000000003, 130.43000000000006, 149.36000000000004, 128.08999999999997, 44.03, 169.24999999999977, 155.33000000000015, 50.03, 76.07000000000004, -58.0, 126.41000000000012, 156.38, 32.06000000000002, 147.32, 141.31999999999996, 176.0, 132.11, 163.01, 148.07, 55.129999999999995, 144.11, 187.12999999999997, 118.24999999999999, -26.44000000000011, 78.41000000000005, 173.26999999999995, 131.0, 173.0, 183.16999999999985, 168.31999999999994, 79.13000000000007, 129.44000000000003, 185.12, 65.03, -7.0, 190.1, 108.62000000000005, 168.32, 163.18999999999997, 125.0, 115.5500000000001, 175.25, 110.03000000000002, 184.15999999999994, 162.14, 135.11000000000007, 186.14000000000001, 151.31000000000003, 174.26000000000005, -6.910000000000011, 154.4300000000001, 149.0, 193.07, 157.43, -14.950000000000003, 169.19000000000005, 149.33, 189.10999999999996, -1.0, 168.01999999999998, 140.0, 144.32, 11.089999999999986, 167.32999999999976, 147.08000000000004, 175.24999999999986, 171.29, 160.19, 50.06, 67.03999999999999, 176.06, 198.01999999999998, 111.47000000000011, 109.04, 134.66000000000005, 117.02, 192.07999999999998, 170.03000000000003, 169.16, 185.06, 177.11, 163.01, 96.14, 137.3, 160.13000000000005, 179.21, 179.0, -48.75999999999998, -52.929999999999964, 137.0, 157.43000000000004, 169.1, 134.29999999999993, 134.63, 157.25, 196.04000000000002, 98.0, 116.42000000000007, 104.57000000000009, 136.19000000000003, 119.0, 116.54000000000008, 45.17000000000017, 56.03, 190.1, 178.22, 107.38999999999997], "policy_predator_policy_reward": [14.0, 12.0, 17.0, 104.0, 45.0, 90.0, 36.0, 42.0, 0.0, 12.0, 191.0, 195.0, 23.0, 69.0, 32.0, 36.0, 102.0, 100.0, 34.0, 36.0, 7.0, 11.0, 63.0, 170.0, 188.0, 52.0, 39.0, 24.0, 66.0, 58.0, 78.0, 65.0, 12.0, 96.0, 41.0, 45.0, 21.0, 2.0, 33.0, 28.0, 17.0, 23.0, 90.0, 76.0, 36.0, 24.0, 98.0, 100.0, 20.0, 103.0, 26.0, 20.0, 161.0, 2.0, 31.0, 29.0, 16.0, 20.0, 19.0, 91.0, 29.0, 3.0, 114.0, 93.0, 123.0, 107.0, 12.0, 16.0, 55.0, 49.0, 38.0, 79.0, 11.0, 57.0, 78.0, 88.0, 122.0, 91.0, 3.0, 9.0, 34.0, 47.0, 78.0, 73.0, 79.0, 93.0, 89.0, 65.0, 74.0, 70.0, 100.0, 68.0, 0.0, 13.0, 11.0, 6.0, 82.0, 84.0, 39.0, 61.0, 110.0, 109.0, 79.0, 200.0, 115.0, 4.0, 49.0, 4.0, 52.0, 53.0, 60.0, 33.0, 23.0, 141.0, 157.0, 141.0, 123.0, 163.0, 102.0, 114.0, 51.0, 51.0, 75.0, 70.0, 12.0, 39.0, 117.0, 92.0, 41.0, 82.0, 29.0, 1.0, 132.0, 14.0, 69.0, 67.0, 20.0, 13.0, 56.0, 30.0, 32.0, 5.0, 102.0, 112.0, 57.0, 49.0, 84.0, 93.0, 14.0, 5.0, 75.0, 73.0, 56.0, 52.0, 75.0, 11.0, 23.0, 55.0, 3.0, 0.0, 97.0, 81.0, 60.0, 61.0, 32.0, 23.0, 40.0, 33.0, 40.0, 37.0, 30.0, 13.0, 6.0, 13.0, 144.0, 175.0, 50.0, 10.0, 24.0, 5.0, 181.0, 22.0, 64.0, 59.0, 56.0, 91.0, 13.0, 12.0, 70.0, 66.0, 16.0, 22.0, 76.0, 76.0, 12.0, 19.0, 50.0, 28.0, 28.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7092552090951869, "mean_inference_ms": 1.895976014006961, "mean_action_processing_ms": 0.2945499487475234, "mean_env_wait_ms": 0.24205018002663603, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0039615631103515625, "StateBufferConnector_ms": 0.00318300724029541, "ViewRequirementAgentConnector_ms": 0.10531067848205566}, "num_episodes": 23, "episode_return_max": 603.3799999999997, "episode_return_min": 88.2100000000001, "episode_return_mean": 362.1841999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.39525291874094, "num_env_steps_trained_throughput_per_sec": 323.39525291874094, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 12593.904, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12593.849, "sample_time_ms": 1536.02, "learn_time_ms": 11037.273, "learn_throughput": 362.408, "synch_weights_time_ms": 17.677}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "0e60f_00000", "date": "2024-08-15_01-12-47", "timestamp": 1723664567, "time_this_iter_s": 12.407224178314209, "time_total_s": 984.7694320678711, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2ff6d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 984.7694320678711, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 58.88333333333334, "ram_util_percent": 83.33333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4189549357329727, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.608005439352106, "policy_loss": -0.0020047615791015604, "vf_loss": 3.6081657721882774, "vf_explained_var": 0.012432515495037906, "kl": 0.00863604307544717, "entropy": 0.8926984656424749, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6041910416865477, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.09443101908164, "policy_loss": -0.004747612451612161, "vf_loss": 5.099084751820438, "vf_explained_var": 0.014884905461911803, "kl": 0.010014943174403096, "entropy": 0.7986314113808688, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 603.3799999999997, "episode_reward_min": -262.93, "episode_reward_mean": 362.28869999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -255.94000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.01999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 123.71435000000001, "predator_policy": 57.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [305.63999999999993, 364.3099999999998, 256.9999999999995, 394.28, 346.23999999999984, 514.1199999999999, 370.50999999999993, 386.2399999999999, 335.38999999999993, 323.7099999999999, 302.68, 391.6499999999999, 314.0699999999999, 464.4999999999999, 411.6899999999997, 346.2199999999999, 339.48, 268.87, 408.4199999999998, 444.40999999999997, 379.89999999999986, 338.53, 414.18999999999994, 411.10999999999996, 355.6399999999998, 334.39999999999986, 333.4899999999999, 336.33999999999975, 223.66999999999982, 296.7899999999999, 338.12, 424.5799999999995, 345.0999999999999, 347.40999999999985, 307.44, 341.6399999999999, 413.10999999999996, 404.08000000000004, 363.2399999999999, 603.3799999999997, 337.96999999999946, 520.27, 458.16999999999985, 392.4499999999998, 365.55999999999983, 267.03000000000003, 421.7199999999999, 361.5100000000001, 386.54999999999984, 421.28, 379.2999999999998, 407.2499999999999, 362.5699999999999, 361.51999999999975, 448.07, 319.47999999999996, 337.51999999999987, 336.1099999999999, 416.02, 241.41000000000003, 392.4099999999997, 349.5399999999998, 388.2499999999999, 364.0999999999999, 364.4899999999999, 316.69999999999993, 386.1, 382.18999999999994, 381.17, 578.15, 357.42999999999995, 387.21, 101.31000000000003, 417.42999999999995, 450.3999999999999, 316.88, 430.03999999999996, 258.99, 407.19000000000005, 192.71000000000004, 324.13, 336.61000000000007, 447.36999999999995, 360.3999999999999, 370.09, 392.32, 397.20999999999987, -262.93, 308.78000000000003, 441.17999999999995, 332.88, 393.2199999999999, 462.4599999999999, 441.26, 385.6500000000001, 153.05, 470.26000000000005, 444.15, 343.65999999999997, 321.08], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [176.24, 106.39999999999995, 108.2600000000001, 195.04999999999998, 79.64000000000026, 137.35999999999993, 103.07, 125.21000000000002, 139.1900000000001, 147.05, 122.06, 194.05999999999995, 153.05, 94.46000000000004, 160.04, 180.20000000000005, 114.76999999999992, 57.61999999999992, 111.23000000000005, 152.4800000000001, 139.27999999999997, 127.4, 117.5300000000001, 164.12, 112.88000000000011, 169.18999999999997, 132.5, 125.0, 67.57999999999991, 114.10999999999999, 160.22000000000003, 158.0, 77.21000000000001, 158.26999999999998, 129.52999999999997, 22.339999999999957, 178.19, 162.2299999999999, 119.0, 159.41, 113.72, 53.17999999999997, 181.19, 145.33999999999997, 166.04000000000002, 167.15, 92.0, 168.10999999999996, 77.21000000000005, 106.43000000000009, 153.31999999999994, 27.08000000000001, 139.36999999999998, 50.11999999999998, 142.33999999999986, 26.0, 76.01, 134.66000000000003, 130.43000000000006, 149.36000000000004, 128.08999999999997, 44.03, 169.24999999999977, 155.33000000000015, 50.03, 76.07000000000004, -58.0, 126.41000000000012, 156.38, 32.06000000000002, 147.32, 141.31999999999996, 176.0, 132.11, 163.01, 148.07, 55.129999999999995, 144.11, 187.12999999999997, 118.24999999999999, -26.44000000000011, 78.41000000000005, 173.26999999999995, 131.0, 173.0, 183.16999999999985, 168.31999999999994, 79.13000000000007, 129.44000000000003, 185.12, 65.03, -7.0, 190.1, 108.62000000000005, 168.32, 163.18999999999997, 125.0, 115.5500000000001, 175.25, 110.03000000000002, 184.15999999999994, 162.14, 135.11000000000007, 186.14000000000001, 151.31000000000003, 174.26000000000005, -6.910000000000011, 154.4300000000001, 149.0, 193.07, 157.43, -14.950000000000003, 169.19000000000005, 149.33, 189.10999999999996, -1.0, 168.01999999999998, 140.0, 144.32, 11.089999999999986, 167.32999999999976, 147.08000000000004, 175.24999999999986, 171.29, 160.19, 50.06, 67.03999999999999, 176.06, 198.01999999999998, 111.47000000000011, 109.04, 134.66000000000005, 117.02, 192.07999999999998, 170.03000000000003, 169.16, 185.06, 177.11, 163.01, 96.14, 137.3, 160.13000000000005, 179.21, 179.0, -48.75999999999998, -52.929999999999964, 137.0, 157.43000000000004, 169.1, 134.29999999999993, 134.63, 157.25, 196.04000000000002, 98.0, 116.42000000000007, 104.57000000000009, 136.19000000000003, 119.0, 116.54000000000008, 45.17000000000017, 56.03, 190.1, 178.22, 107.38999999999997, 174.23000000000002, 141.14000000000004, 164.36, 166.04000000000002, 92.09, 179.0, 169.30999999999997, 124.01, 193.07, 153.14, -255.94000000000003, -241.99, 112.46000000000006, 168.32, 189.11, 55.06999999999999, 175.25, 137.63, 163.07, 185.15000000000003, 154.45999999999998, 110.0, 109.03999999999999, 160.22, 165.35, 161.3, -239.95, 173.0, 158.12, 180.14, 143.0, 38.150000000000006, 128.32999999999998, 167.32999999999998, -55.0, 174.07999999999998], "policy_predator_policy_reward": [21.0, 2.0, 33.0, 28.0, 17.0, 23.0, 90.0, 76.0, 36.0, 24.0, 98.0, 100.0, 20.0, 103.0, 26.0, 20.0, 161.0, 2.0, 31.0, 29.0, 16.0, 20.0, 19.0, 91.0, 29.0, 3.0, 114.0, 93.0, 123.0, 107.0, 12.0, 16.0, 55.0, 49.0, 38.0, 79.0, 11.0, 57.0, 78.0, 88.0, 122.0, 91.0, 3.0, 9.0, 34.0, 47.0, 78.0, 73.0, 79.0, 93.0, 89.0, 65.0, 74.0, 70.0, 100.0, 68.0, 0.0, 13.0, 11.0, 6.0, 82.0, 84.0, 39.0, 61.0, 110.0, 109.0, 79.0, 200.0, 115.0, 4.0, 49.0, 4.0, 52.0, 53.0, 60.0, 33.0, 23.0, 141.0, 157.0, 141.0, 123.0, 163.0, 102.0, 114.0, 51.0, 51.0, 75.0, 70.0, 12.0, 39.0, 117.0, 92.0, 41.0, 82.0, 29.0, 1.0, 132.0, 14.0, 69.0, 67.0, 20.0, 13.0, 56.0, 30.0, 32.0, 5.0, 102.0, 112.0, 57.0, 49.0, 84.0, 93.0, 14.0, 5.0, 75.0, 73.0, 56.0, 52.0, 75.0, 11.0, 23.0, 55.0, 3.0, 0.0, 97.0, 81.0, 60.0, 61.0, 32.0, 23.0, 40.0, 33.0, 40.0, 37.0, 30.0, 13.0, 6.0, 13.0, 144.0, 175.0, 50.0, 10.0, 24.0, 5.0, 181.0, 22.0, 64.0, 59.0, 56.0, 91.0, 13.0, 12.0, 70.0, 66.0, 16.0, 22.0, 76.0, 76.0, 12.0, 19.0, 50.0, 28.0, 28.0, 23.0, 27.0, 105.0, 17.0, 13.0, 23.0, 76.0, 54.0, 45.0, 6.0, 45.0, 35.0, 200.0, 11.0, 17.0, 97.0, 100.0, 14.0, 6.0, 26.0, 19.0, 88.0, 110.0, 88.0, 84.0, 24.0, 35.0, 24.0, 196.0, 45.0, 87.0, 75.0, 188.0, 25.0, 23.0, 152.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7082116873466924, "mean_inference_ms": 1.8974272809568509, "mean_action_processing_ms": 0.2938897709426748, "mean_env_wait_ms": 0.2416086312687135, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004011392593383789, "StateBufferConnector_ms": 0.0035326480865478516, "ViewRequirementAgentConnector_ms": 0.10580658912658691}, "num_episodes": 18, "episode_return_max": 603.3799999999997, "episode_return_min": -262.93, "episode_return_mean": 362.28869999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.022441267407, "num_env_steps_trained_throughput_per_sec": 319.022441267407, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 12648.646, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12648.594, "sample_time_ms": 1561.364, "learn_time_ms": 11066.952, "learn_throughput": 361.436, "synch_weights_time_ms": 17.592}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "0e60f_00000", "date": "2024-08-15_01-13-00", "timestamp": 1723664580, "time_this_iter_s": 12.58765983581543, "time_total_s": 997.3570919036865, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2ff6310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 997.3570919036865, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 59.15882352941177, "ram_util_percent": 83.02352941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9675074495966474, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.835277529494472, "policy_loss": -0.009216129312429716, "vf_loss": 4.842468626032431, "vf_explained_var": 0.13175700420425052, "kl": 0.009481609842816248, "entropy": 0.8592777565988914, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.976177861892357, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.614162585344264, "policy_loss": -0.003971443513886283, "vf_loss": 3.6180764024219814, "vf_explained_var": 0.07891438464639049, "kl": 0.00614713868598044, "entropy": 0.8962419090762971, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 603.3799999999997, "episode_reward_min": -262.93, "episode_reward_mean": 360.5844999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -255.94000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.01999999999998, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 120.68224999999998, "predator_policy": 59.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [408.4199999999998, 444.40999999999997, 379.89999999999986, 338.53, 414.18999999999994, 411.10999999999996, 355.6399999999998, 334.39999999999986, 333.4899999999999, 336.33999999999975, 223.66999999999982, 296.7899999999999, 338.12, 424.5799999999995, 345.0999999999999, 347.40999999999985, 307.44, 341.6399999999999, 413.10999999999996, 404.08000000000004, 363.2399999999999, 603.3799999999997, 337.96999999999946, 520.27, 458.16999999999985, 392.4499999999998, 365.55999999999983, 267.03000000000003, 421.7199999999999, 361.5100000000001, 386.54999999999984, 421.28, 379.2999999999998, 407.2499999999999, 362.5699999999999, 361.51999999999975, 448.07, 319.47999999999996, 337.51999999999987, 336.1099999999999, 416.02, 241.41000000000003, 392.4099999999997, 349.5399999999998, 388.2499999999999, 364.0999999999999, 364.4899999999999, 316.69999999999993, 386.1, 382.18999999999994, 381.17, 578.15, 357.42999999999995, 387.21, 101.31000000000003, 417.42999999999995, 450.3999999999999, 316.88, 430.03999999999996, 258.99, 407.19000000000005, 192.71000000000004, 324.13, 336.61000000000007, 447.36999999999995, 360.3999999999999, 370.09, 392.32, 397.20999999999987, -262.93, 308.78000000000003, 441.17999999999995, 332.88, 393.2199999999999, 462.4599999999999, 441.26, 385.6500000000001, 153.05, 470.26000000000005, 444.15, 343.65999999999997, 321.08, 261.1400000000002, 346.6399999999997, 487.0899999999999, 342.3399999999997, 150.0, 334.43, 392.39, 293.16999999999996, 527.05, 390.11, 262.54999999999893, 346.4799999999999, 405.23, 374.2199999999998, 358.25999999999897, 303.03999999999996, 462.42999999999995, 229.60999999999981], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [178.19, 162.2299999999999, 119.0, 159.41, 113.72, 53.17999999999997, 181.19, 145.33999999999997, 166.04000000000002, 167.15, 92.0, 168.10999999999996, 77.21000000000005, 106.43000000000009, 153.31999999999994, 27.08000000000001, 139.36999999999998, 50.11999999999998, 142.33999999999986, 26.0, 76.01, 134.66000000000003, 130.43000000000006, 149.36000000000004, 128.08999999999997, 44.03, 169.24999999999977, 155.33000000000015, 50.03, 76.07000000000004, -58.0, 126.41000000000012, 156.38, 32.06000000000002, 147.32, 141.31999999999996, 176.0, 132.11, 163.01, 148.07, 55.129999999999995, 144.11, 187.12999999999997, 118.24999999999999, -26.44000000000011, 78.41000000000005, 173.26999999999995, 131.0, 173.0, 183.16999999999985, 168.31999999999994, 79.13000000000007, 129.44000000000003, 185.12, 65.03, -7.0, 190.1, 108.62000000000005, 168.32, 163.18999999999997, 125.0, 115.5500000000001, 175.25, 110.03000000000002, 184.15999999999994, 162.14, 135.11000000000007, 186.14000000000001, 151.31000000000003, 174.26000000000005, -6.910000000000011, 154.4300000000001, 149.0, 193.07, 157.43, -14.950000000000003, 169.19000000000005, 149.33, 189.10999999999996, -1.0, 168.01999999999998, 140.0, 144.32, 11.089999999999986, 167.32999999999976, 147.08000000000004, 175.24999999999986, 171.29, 160.19, 50.06, 67.03999999999999, 176.06, 198.01999999999998, 111.47000000000011, 109.04, 134.66000000000005, 117.02, 192.07999999999998, 170.03000000000003, 169.16, 185.06, 177.11, 163.01, 96.14, 137.3, 160.13000000000005, 179.21, 179.0, -48.75999999999998, -52.929999999999964, 137.0, 157.43000000000004, 169.1, 134.29999999999993, 134.63, 157.25, 196.04000000000002, 98.0, 116.42000000000007, 104.57000000000009, 136.19000000000003, 119.0, 116.54000000000008, 45.17000000000017, 56.03, 190.1, 178.22, 107.38999999999997, 174.23000000000002, 141.14000000000004, 164.36, 166.04000000000002, 92.09, 179.0, 169.30999999999997, 124.01, 193.07, 153.14, -255.94000000000003, -241.99, 112.46000000000006, 168.32, 189.11, 55.06999999999999, 175.25, 137.63, 163.07, 185.15000000000003, 154.45999999999998, 110.0, 109.03999999999999, 160.22, 165.35, 161.3, -239.95, 173.0, 158.12, 180.14, 143.0, 38.150000000000006, 128.32999999999998, 167.32999999999998, -55.0, 174.07999999999998, 108.56000000000009, 97.5800000000001, 137.0, 124.64000000000019, 180.07999999999993, 115.01, 62.20999999999999, 142.12999999999994, -241.0, 173.0, 158.42000000000002, -46.99000000000001, 163.10000000000002, 129.29000000000008, 58.129999999999995, 136.04, 188.0, 153.05, 101.0, 180.11, 95.60000000000024, 3.949999999999985, 194.06, 122.42000000000009, 185.03, 177.2, 176.0, 151.21999999999983, 25.010000000000137, 172.25000000000006, 64.00999999999999, 80.03, 137.21000000000004, 178.2199999999999, 125.4800000000001, 19.130000000000006], "policy_predator_policy_reward": [11.0, 57.0, 78.0, 88.0, 122.0, 91.0, 3.0, 9.0, 34.0, 47.0, 78.0, 73.0, 79.0, 93.0, 89.0, 65.0, 74.0, 70.0, 100.0, 68.0, 0.0, 13.0, 11.0, 6.0, 82.0, 84.0, 39.0, 61.0, 110.0, 109.0, 79.0, 200.0, 115.0, 4.0, 49.0, 4.0, 52.0, 53.0, 60.0, 33.0, 23.0, 141.0, 157.0, 141.0, 123.0, 163.0, 102.0, 114.0, 51.0, 51.0, 75.0, 70.0, 12.0, 39.0, 117.0, 92.0, 41.0, 82.0, 29.0, 1.0, 132.0, 14.0, 69.0, 67.0, 20.0, 13.0, 56.0, 30.0, 32.0, 5.0, 102.0, 112.0, 57.0, 49.0, 84.0, 93.0, 14.0, 5.0, 75.0, 73.0, 56.0, 52.0, 75.0, 11.0, 23.0, 55.0, 3.0, 0.0, 97.0, 81.0, 60.0, 61.0, 32.0, 23.0, 40.0, 33.0, 40.0, 37.0, 30.0, 13.0, 6.0, 13.0, 144.0, 175.0, 50.0, 10.0, 24.0, 5.0, 181.0, 22.0, 64.0, 59.0, 56.0, 91.0, 13.0, 12.0, 70.0, 66.0, 16.0, 22.0, 76.0, 76.0, 12.0, 19.0, 50.0, 28.0, 28.0, 23.0, 27.0, 105.0, 17.0, 13.0, 23.0, 76.0, 54.0, 45.0, 6.0, 45.0, 35.0, 200.0, 11.0, 17.0, 97.0, 100.0, 14.0, 6.0, 26.0, 19.0, 88.0, 110.0, 88.0, 84.0, 24.0, 35.0, 24.0, 196.0, 45.0, 87.0, 75.0, 188.0, 25.0, 23.0, 152.0, 50.0, 29.0, 26.0, 31.0, 54.0, 94.0, 98.0, 67.0, 71.0, 18.0, 200.0, 113.0, 110.0, 64.0, 36.0, 94.0, 5.0, 86.0, 100.0, 30.0, 79.0, 81.0, 82.0, 11.0, 19.0, 40.0, 3.0, 26.0, 21.0, 89.0, 72.0, 62.0, 97.0, 135.0, 12.0, 13.0, 72.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7076952308351397, "mean_inference_ms": 1.898952042064944, "mean_action_processing_ms": 0.2935795584937687, "mean_env_wait_ms": 0.2414455607964463, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00397491455078125, "StateBufferConnector_ms": 0.003522157669067383, "ViewRequirementAgentConnector_ms": 0.11332881450653076}, "num_episodes": 18, "episode_return_max": 603.3799999999997, "episode_return_min": -262.93, "episode_return_mean": 360.5844999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.6395820343317, "num_env_steps_trained_throughput_per_sec": 322.6395820343317, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 12610.01, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12609.957, "sample_time_ms": 1567.946, "learn_time_ms": 11021.53, "learn_throughput": 362.926, "synch_weights_time_ms": 17.44}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "0e60f_00000", "date": "2024-08-15_01-13-12", "timestamp": 1723664592, "time_this_iter_s": 12.428991079330444, "time_total_s": 1009.786082983017, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a3127f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1009.786082983017, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 59.06111111111112, "ram_util_percent": 83.58888888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.0345299872456404, "cur_kl_coeff": 0.21357421874999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.60341167702246, "policy_loss": -0.0017262145997611461, "vf_loss": 3.604362564238291, "vf_explained_var": 0.15401153662217357, "kl": 0.003630219942147151, "entropy": 0.7877638798857493, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.991990185730041, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8386518541467254, "policy_loss": -0.005572565381104747, "vf_loss": 2.8441193380053083, "vf_explained_var": 0.09356133512088231, "kl": 0.011208329472535795, "entropy": 0.9585319758407653, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 578.15, "episode_reward_min": -262.93, "episode_reward_mean": 357.8416999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -255.94000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.02, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 124.93084999999999, "predator_policy": 53.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [337.96999999999946, 520.27, 458.16999999999985, 392.4499999999998, 365.55999999999983, 267.03000000000003, 421.7199999999999, 361.5100000000001, 386.54999999999984, 421.28, 379.2999999999998, 407.2499999999999, 362.5699999999999, 361.51999999999975, 448.07, 319.47999999999996, 337.51999999999987, 336.1099999999999, 416.02, 241.41000000000003, 392.4099999999997, 349.5399999999998, 388.2499999999999, 364.0999999999999, 364.4899999999999, 316.69999999999993, 386.1, 382.18999999999994, 381.17, 578.15, 357.42999999999995, 387.21, 101.31000000000003, 417.42999999999995, 450.3999999999999, 316.88, 430.03999999999996, 258.99, 407.19000000000005, 192.71000000000004, 324.13, 336.61000000000007, 447.36999999999995, 360.3999999999999, 370.09, 392.32, 397.20999999999987, -262.93, 308.78000000000003, 441.17999999999995, 332.88, 393.2199999999999, 462.4599999999999, 441.26, 385.6500000000001, 153.05, 470.26000000000005, 444.15, 343.65999999999997, 321.08, 261.1400000000002, 346.6399999999997, 487.0899999999999, 342.3399999999997, 150.0, 334.43, 392.39, 293.16999999999996, 527.05, 390.11, 262.54999999999893, 346.4799999999999, 405.23, 374.2199999999998, 358.25999999999897, 303.03999999999996, 462.42999999999995, 229.60999999999981, 235.45, 322.1599999999999, 423.1399999999999, 324.66999999999973, 333.2499999999998, 322.1099999999999, 429.14, 365.08, 341.51999999999987, 271.7799999999997, 358.26, 544.14, 383.04999999999995, 385.46999999999986, 374.11999999999995, 318.65999999999974, 407.0799999999999, 341.34999999999974, 368.36, 369.30999999999995, 300.18, 372.43], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-26.44000000000011, 78.41000000000005, 173.26999999999995, 131.0, 173.0, 183.16999999999985, 168.31999999999994, 79.13000000000007, 129.44000000000003, 185.12, 65.03, -7.0, 190.1, 108.62000000000005, 168.32, 163.18999999999997, 125.0, 115.5500000000001, 175.25, 110.03000000000002, 184.15999999999994, 162.14, 135.11000000000007, 186.14000000000001, 151.31000000000003, 174.26000000000005, -6.910000000000011, 154.4300000000001, 149.0, 193.07, 157.43, -14.950000000000003, 169.19000000000005, 149.33, 189.10999999999996, -1.0, 168.01999999999998, 140.0, 144.32, 11.089999999999986, 167.32999999999976, 147.08000000000004, 175.24999999999986, 171.29, 160.19, 50.06, 67.03999999999999, 176.06, 198.01999999999998, 111.47000000000011, 109.04, 134.66000000000005, 117.02, 192.07999999999998, 170.03000000000003, 169.16, 185.06, 177.11, 163.01, 96.14, 137.3, 160.13000000000005, 179.21, 179.0, -48.75999999999998, -52.929999999999964, 137.0, 157.43000000000004, 169.1, 134.29999999999993, 134.63, 157.25, 196.04000000000002, 98.0, 116.42000000000007, 104.57000000000009, 136.19000000000003, 119.0, 116.54000000000008, 45.17000000000017, 56.03, 190.1, 178.22, 107.38999999999997, 174.23000000000002, 141.14000000000004, 164.36, 166.04000000000002, 92.09, 179.0, 169.30999999999997, 124.01, 193.07, 153.14, -255.94000000000003, -241.99, 112.46000000000006, 168.32, 189.11, 55.06999999999999, 175.25, 137.63, 163.07, 185.15000000000003, 154.45999999999998, 110.0, 109.03999999999999, 160.22, 165.35, 161.3, -239.95, 173.0, 158.12, 180.14, 143.0, 38.150000000000006, 128.32999999999998, 167.32999999999998, -55.0, 174.07999999999998, 108.56000000000009, 97.5800000000001, 137.0, 124.64000000000019, 180.07999999999993, 115.01, 62.20999999999999, 142.12999999999994, -241.0, 173.0, 158.42000000000002, -46.99000000000001, 163.10000000000002, 129.29000000000008, 58.129999999999995, 136.04, 188.0, 153.05, 101.0, 180.11, 95.60000000000024, 3.949999999999985, 194.06, 122.42000000000009, 185.03, 177.2, 176.0, 151.21999999999983, 25.010000000000137, 172.25000000000006, 64.00999999999999, 80.03, 137.21000000000004, 178.2199999999999, 125.4800000000001, 19.130000000000006, 96.50000000000003, 105.94999999999999, 118.16000000000005, 128.0, 161.12000000000006, 159.01999999999998, 160.39999999999995, 131.27000000000012, 110.0, 133.25000000000009, 144.07999999999998, 107.03000000000002, 186.14, 161.0, 133.07, 91.00999999999999, 167.03, 151.48999999999987, 104.68999999999993, 65.08999999999997, 163.01, 169.25, 166.13, 187.01, 137.03, 150.02, 122.03, 135.43999999999997, 197.0, 146.12000000000003, 96.29000000000015, 151.36999999999995, 198.02, 59.05999999999998, 143.06, 129.28999999999988, 98.0, 164.36, 171.29, 117.02, 169.1, 57.08, 157.04000000000002, 161.39], "policy_predator_policy_reward": [123.0, 163.0, 102.0, 114.0, 51.0, 51.0, 75.0, 70.0, 12.0, 39.0, 117.0, 92.0, 41.0, 82.0, 29.0, 1.0, 132.0, 14.0, 69.0, 67.0, 20.0, 13.0, 56.0, 30.0, 32.0, 5.0, 102.0, 112.0, 57.0, 49.0, 84.0, 93.0, 14.0, 5.0, 75.0, 73.0, 56.0, 52.0, 75.0, 11.0, 23.0, 55.0, 3.0, 0.0, 97.0, 81.0, 60.0, 61.0, 32.0, 23.0, 40.0, 33.0, 40.0, 37.0, 30.0, 13.0, 6.0, 13.0, 144.0, 175.0, 50.0, 10.0, 24.0, 5.0, 181.0, 22.0, 64.0, 59.0, 56.0, 91.0, 13.0, 12.0, 70.0, 66.0, 16.0, 22.0, 76.0, 76.0, 12.0, 19.0, 50.0, 28.0, 28.0, 23.0, 27.0, 105.0, 17.0, 13.0, 23.0, 76.0, 54.0, 45.0, 6.0, 45.0, 35.0, 200.0, 11.0, 17.0, 97.0, 100.0, 14.0, 6.0, 26.0, 19.0, 88.0, 110.0, 88.0, 84.0, 24.0, 35.0, 24.0, 196.0, 45.0, 87.0, 75.0, 188.0, 25.0, 23.0, 152.0, 50.0, 29.0, 26.0, 31.0, 54.0, 94.0, 98.0, 67.0, 71.0, 18.0, 200.0, 113.0, 110.0, 64.0, 36.0, 94.0, 5.0, 86.0, 100.0, 30.0, 79.0, 81.0, 82.0, 11.0, 19.0, 40.0, 3.0, 26.0, 21.0, 89.0, 72.0, 62.0, 97.0, 135.0, 12.0, 13.0, 72.0, 23.0, 10.0, 14.0, 62.0, 41.0, 62.0, 18.0, 15.0, 43.0, 47.0, 36.0, 35.0, 47.0, 35.0, 69.0, 72.0, 13.0, 10.0, 53.0, 49.0, 15.0, 11.0, 89.0, 102.0, 90.0, 6.0, 69.0, 59.0, 22.0, 9.0, 6.0, 65.0, 77.0, 73.0, 37.0, 32.0, 54.0, 52.0, 41.0, 40.0, 70.0, 4.0, 28.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7071704756999111, "mean_inference_ms": 1.9013302936310752, "mean_action_processing_ms": 0.29325525336217934, "mean_env_wait_ms": 0.2412695739576486, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004897475242614746, "StateBufferConnector_ms": 0.0036505460739135742, "ViewRequirementAgentConnector_ms": 0.11955475807189941}, "num_episodes": 22, "episode_return_max": 578.15, "episode_return_min": -262.93, "episode_return_mean": 357.8416999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 327.02168363455996, "num_env_steps_trained_throughput_per_sec": 327.02168363455996, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 12519.375, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12519.322, "sample_time_ms": 1560.267, "learn_time_ms": 10937.671, "learn_throughput": 365.709, "synch_weights_time_ms": 18.169}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "0e60f_00000", "date": "2024-08-15_01-13-24", "timestamp": 1723664604, "time_this_iter_s": 12.278513193130493, "time_total_s": 1022.0645961761475, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2ff6d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1022.0645961761475, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 58.73529411764706, "ram_util_percent": 82.80588235294118}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.1088386693644146, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5555692802030574, "policy_loss": -0.005571368698612171, "vf_loss": 3.5600010009039016, "vf_explained_var": 0.31383272261215894, "kl": 0.010672220356043344, "entropy": 0.8484359934847191, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8235951293082464, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8902454848011967, "policy_loss": -0.0018310628010935726, "vf_loss": 2.8920297139536135, "vf_explained_var": 0.15315240744560485, "kl": 0.0049948672963969236, "entropy": 0.6728031312347089, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 578.15, "episode_reward_min": -262.93, "episode_reward_mean": 351.93329999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -255.94000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 198.02, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 127.95665000000001, "predator_policy": 48.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [416.02, 241.41000000000003, 392.4099999999997, 349.5399999999998, 388.2499999999999, 364.0999999999999, 364.4899999999999, 316.69999999999993, 386.1, 382.18999999999994, 381.17, 578.15, 357.42999999999995, 387.21, 101.31000000000003, 417.42999999999995, 450.3999999999999, 316.88, 430.03999999999996, 258.99, 407.19000000000005, 192.71000000000004, 324.13, 336.61000000000007, 447.36999999999995, 360.3999999999999, 370.09, 392.32, 397.20999999999987, -262.93, 308.78000000000003, 441.17999999999995, 332.88, 393.2199999999999, 462.4599999999999, 441.26, 385.6500000000001, 153.05, 470.26000000000005, 444.15, 343.65999999999997, 321.08, 261.1400000000002, 346.6399999999997, 487.0899999999999, 342.3399999999997, 150.0, 334.43, 392.39, 293.16999999999996, 527.05, 390.11, 262.54999999999893, 346.4799999999999, 405.23, 374.2199999999998, 358.25999999999897, 303.03999999999996, 462.42999999999995, 229.60999999999981, 235.45, 322.1599999999999, 423.1399999999999, 324.66999999999973, 333.2499999999998, 322.1099999999999, 429.14, 365.08, 341.51999999999987, 271.7799999999997, 358.26, 544.14, 383.04999999999995, 385.46999999999986, 374.11999999999995, 318.65999999999974, 407.0799999999999, 341.34999999999974, 368.36, 369.30999999999995, 300.18, 372.43, 280.13000000000005, 350.54999999999995, 383.17999999999984, 360.14, 346.34000000000003, 463.81, 378.22, 355.50999999999976, 337.5199999999996, 401.1699999999999, 310.28999999999974, 333.3899999999999, 368.16999999999996, 373.29, 333.55999999999983, 319.82000000000005, 325.5599999999997, 272.8399999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [168.01999999999998, 140.0, 144.32, 11.089999999999986, 167.32999999999976, 147.08000000000004, 175.24999999999986, 171.29, 160.19, 50.06, 67.03999999999999, 176.06, 198.01999999999998, 111.47000000000011, 109.04, 134.66000000000005, 117.02, 192.07999999999998, 170.03000000000003, 169.16, 185.06, 177.11, 163.01, 96.14, 137.3, 160.13000000000005, 179.21, 179.0, -48.75999999999998, -52.929999999999964, 137.0, 157.43000000000004, 169.1, 134.29999999999993, 134.63, 157.25, 196.04000000000002, 98.0, 116.42000000000007, 104.57000000000009, 136.19000000000003, 119.0, 116.54000000000008, 45.17000000000017, 56.03, 190.1, 178.22, 107.38999999999997, 174.23000000000002, 141.14000000000004, 164.36, 166.04000000000002, 92.09, 179.0, 169.30999999999997, 124.01, 193.07, 153.14, -255.94000000000003, -241.99, 112.46000000000006, 168.32, 189.11, 55.06999999999999, 175.25, 137.63, 163.07, 185.15000000000003, 154.45999999999998, 110.0, 109.03999999999999, 160.22, 165.35, 161.3, -239.95, 173.0, 158.12, 180.14, 143.0, 38.150000000000006, 128.32999999999998, 167.32999999999998, -55.0, 174.07999999999998, 108.56000000000009, 97.5800000000001, 137.0, 124.64000000000019, 180.07999999999993, 115.01, 62.20999999999999, 142.12999999999994, -241.0, 173.0, 158.42000000000002, -46.99000000000001, 163.10000000000002, 129.29000000000008, 58.129999999999995, 136.04, 188.0, 153.05, 101.0, 180.11, 95.60000000000024, 3.949999999999985, 194.06, 122.42000000000009, 185.03, 177.2, 176.0, 151.21999999999983, 25.010000000000137, 172.25000000000006, 64.00999999999999, 80.03, 137.21000000000004, 178.2199999999999, 125.4800000000001, 19.130000000000006, 96.50000000000003, 105.94999999999999, 118.16000000000005, 128.0, 161.12000000000006, 159.01999999999998, 160.39999999999995, 131.27000000000012, 110.0, 133.25000000000009, 144.07999999999998, 107.03000000000002, 186.14, 161.0, 133.07, 91.00999999999999, 167.03, 151.48999999999987, 104.68999999999993, 65.08999999999997, 163.01, 169.25, 166.13, 187.01, 137.03, 150.02, 122.03, 135.43999999999997, 197.0, 146.12000000000003, 96.29000000000015, 151.36999999999995, 198.02, 59.05999999999998, 143.06, 129.28999999999988, 98.0, 164.36, 171.29, 117.02, 169.1, 57.08, 157.04000000000002, 161.39, 182.0, 85.13000000000001, 145.55, 164.0, 183.16999999999996, 154.01, 104.0, 186.14, 183.17000000000002, 120.16999999999999, 153.35, 154.46, 145.22000000000003, 179.0, 139.19000000000005, 117.3200000000001, 172.10000000000005, 56.42000000000004, 187.01, 145.1599999999999, 74.26999999999997, 156.01999999999998, 147.37999999999994, 130.01, 156.17000000000002, 194.0, 176.24, 195.05, 181.1899999999999, 136.37000000000012, 107.74999999999999, 193.07, 97.49, 112.07, 130.31000000000006, 81.53000000000016], "policy_predator_policy_reward": [56.0, 52.0, 75.0, 11.0, 23.0, 55.0, 3.0, 0.0, 97.0, 81.0, 60.0, 61.0, 32.0, 23.0, 40.0, 33.0, 40.0, 37.0, 30.0, 13.0, 6.0, 13.0, 144.0, 175.0, 50.0, 10.0, 24.0, 5.0, 181.0, 22.0, 64.0, 59.0, 56.0, 91.0, 13.0, 12.0, 70.0, 66.0, 16.0, 22.0, 76.0, 76.0, 12.0, 19.0, 50.0, 28.0, 28.0, 23.0, 27.0, 105.0, 17.0, 13.0, 23.0, 76.0, 54.0, 45.0, 6.0, 45.0, 35.0, 200.0, 11.0, 17.0, 97.0, 100.0, 14.0, 6.0, 26.0, 19.0, 88.0, 110.0, 88.0, 84.0, 24.0, 35.0, 24.0, 196.0, 45.0, 87.0, 75.0, 188.0, 25.0, 23.0, 152.0, 50.0, 29.0, 26.0, 31.0, 54.0, 94.0, 98.0, 67.0, 71.0, 18.0, 200.0, 113.0, 110.0, 64.0, 36.0, 94.0, 5.0, 86.0, 100.0, 30.0, 79.0, 81.0, 82.0, 11.0, 19.0, 40.0, 3.0, 26.0, 21.0, 89.0, 72.0, 62.0, 97.0, 135.0, 12.0, 13.0, 72.0, 23.0, 10.0, 14.0, 62.0, 41.0, 62.0, 18.0, 15.0, 43.0, 47.0, 36.0, 35.0, 47.0, 35.0, 69.0, 72.0, 13.0, 10.0, 53.0, 49.0, 15.0, 11.0, 89.0, 102.0, 90.0, 6.0, 69.0, 59.0, 22.0, 9.0, 6.0, 65.0, 77.0, 73.0, 37.0, 32.0, 54.0, 52.0, 41.0, 40.0, 70.0, 4.0, 28.0, 26.0, 10.0, 3.0, 18.0, 23.0, 23.0, 23.0, 1.0, 69.0, 20.0, 23.0, 18.0, 138.0, 35.0, 19.0, 66.0, 33.0, 53.0, 56.0, 42.0, 27.0, 39.0, 41.0, 7.0, 49.0, 3.0, 15.0, 1.0, 1.0, 5.0, 11.0, 9.0, 10.0, 59.0, 57.0, 30.0, 31.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7067021420693118, "mean_inference_ms": 1.9033913683560097, "mean_action_processing_ms": 0.29301666694435907, "mean_env_wait_ms": 0.241175643450785, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004918336868286133, "StateBufferConnector_ms": 0.003688812255859375, "ViewRequirementAgentConnector_ms": 0.11649441719055176}, "num_episodes": 18, "episode_return_max": 578.15, "episode_return_min": -262.93, "episode_return_mean": 351.93329999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.46738692712313, "num_env_steps_trained_throughput_per_sec": 323.46738692712313, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 12508.26, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12508.207, "sample_time_ms": 1560.924, "learn_time_ms": 10925.667, "learn_throughput": 366.11, "synch_weights_time_ms": 17.892}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "0e60f_00000", "date": "2024-08-15_01-13-37", "timestamp": 1723664617, "time_this_iter_s": 12.409980297088623, "time_total_s": 1034.474576473236, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2ff6310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1034.474576473236, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 57.92777777777777, "ram_util_percent": 82.82222222222222}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.591627735530258, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.085812566362361, "policy_loss": -0.0047321126881306845, "vf_loss": 2.089581235502132, "vf_explained_var": 0.23459599109553786, "kl": 0.009022034311246464, "entropy": 0.9337367418897216, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9205703864652643, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.322006574888078, "policy_loss": -0.0017844716449164682, "vf_loss": 3.3237552462431488, "vf_explained_var": 0.08616423013979796, "kl": 0.007639020468876042, "entropy": 0.7880700656345913, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 554.16, "episode_reward_min": -262.93, "episode_reward_mean": 357.4176999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -255.94000000000003, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 131.92385, "predator_policy": 46.785}, "custom_metrics": {}, "hist_stats": {"episode_reward": [336.61000000000007, 447.36999999999995, 360.3999999999999, 370.09, 392.32, 397.20999999999987, -262.93, 308.78000000000003, 441.17999999999995, 332.88, 393.2199999999999, 462.4599999999999, 441.26, 385.6500000000001, 153.05, 470.26000000000005, 444.15, 343.65999999999997, 321.08, 261.1400000000002, 346.6399999999997, 487.0899999999999, 342.3399999999997, 150.0, 334.43, 392.39, 293.16999999999996, 527.05, 390.11, 262.54999999999893, 346.4799999999999, 405.23, 374.2199999999998, 358.25999999999897, 303.03999999999996, 462.42999999999995, 229.60999999999981, 235.45, 322.1599999999999, 423.1399999999999, 324.66999999999973, 333.2499999999998, 322.1099999999999, 429.14, 365.08, 341.51999999999987, 271.7799999999997, 358.26, 544.14, 383.04999999999995, 385.46999999999986, 374.11999999999995, 318.65999999999974, 407.0799999999999, 341.34999999999974, 368.36, 369.30999999999995, 300.18, 372.43, 280.13000000000005, 350.54999999999995, 383.17999999999984, 360.14, 346.34000000000003, 463.81, 378.22, 355.50999999999976, 337.5199999999996, 401.1699999999999, 310.28999999999974, 333.3899999999999, 368.16999999999996, 373.29, 333.55999999999983, 319.82000000000005, 325.5599999999997, 272.8399999999994, 341.03999999999996, 381.41999999999985, 379.21000000000004, 372.18, 256.00000000000006, 395.11, 304.2099999999999, 554.16, 288.1600000000002, 376.25, 491.06, 350.5799999999999, 343.5700000000001, 476.12, 466.67999999999995, 364.01, 358.46000000000004, 357.25, 440.0, 404.46, 364.46000000000004, 304.2899999999999, 384.01], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [178.22, 107.38999999999997, 174.23000000000002, 141.14000000000004, 164.36, 166.04000000000002, 92.09, 179.0, 169.30999999999997, 124.01, 193.07, 153.14, -255.94000000000003, -241.99, 112.46000000000006, 168.32, 189.11, 55.06999999999999, 175.25, 137.63, 163.07, 185.15000000000003, 154.45999999999998, 110.0, 109.03999999999999, 160.22, 165.35, 161.3, -239.95, 173.0, 158.12, 180.14, 143.0, 38.150000000000006, 128.32999999999998, 167.32999999999998, -55.0, 174.07999999999998, 108.56000000000009, 97.5800000000001, 137.0, 124.64000000000019, 180.07999999999993, 115.01, 62.20999999999999, 142.12999999999994, -241.0, 173.0, 158.42000000000002, -46.99000000000001, 163.10000000000002, 129.29000000000008, 58.129999999999995, 136.04, 188.0, 153.05, 101.0, 180.11, 95.60000000000024, 3.949999999999985, 194.06, 122.42000000000009, 185.03, 177.2, 176.0, 151.21999999999983, 25.010000000000137, 172.25000000000006, 64.00999999999999, 80.03, 137.21000000000004, 178.2199999999999, 125.4800000000001, 19.130000000000006, 96.50000000000003, 105.94999999999999, 118.16000000000005, 128.0, 161.12000000000006, 159.01999999999998, 160.39999999999995, 131.27000000000012, 110.0, 133.25000000000009, 144.07999999999998, 107.03000000000002, 186.14, 161.0, 133.07, 91.00999999999999, 167.03, 151.48999999999987, 104.68999999999993, 65.08999999999997, 163.01, 169.25, 166.13, 187.01, 137.03, 150.02, 122.03, 135.43999999999997, 197.0, 146.12000000000003, 96.29000000000015, 151.36999999999995, 198.02, 59.05999999999998, 143.06, 129.28999999999988, 98.0, 164.36, 171.29, 117.02, 169.1, 57.08, 157.04000000000002, 161.39, 182.0, 85.13000000000001, 145.55, 164.0, 183.16999999999996, 154.01, 104.0, 186.14, 183.17000000000002, 120.16999999999999, 153.35, 154.46, 145.22000000000003, 179.0, 139.19000000000005, 117.3200000000001, 172.10000000000005, 56.42000000000004, 187.01, 145.1599999999999, 74.26999999999997, 156.01999999999998, 147.37999999999994, 130.01, 156.17000000000002, 194.0, 176.24, 195.05, 181.1899999999999, 136.37000000000012, 107.74999999999999, 193.07, 97.49, 112.07, 130.31000000000006, 81.53000000000016, 71.03, 130.01, 179.21, 107.2100000000001, 173.12, 167.09, 142.16000000000003, 198.01999999999998, 114.76999999999998, 90.22999999999996, 165.11, 200.0, 149.21000000000004, -49.0, 192.08, 126.08000000000001, 190.1, 80.05999999999997, 137.0, 154.25, 155.03, 116.03, 101.11999999999998, 154.46, 176.0, 143.57000000000002, 167.12, 185.0, 200.0, 120.68000000000004, 167.0, 160.01, 183.01999999999998, 156.44, 160.19, 128.06, 155.0, 200.0, 161.24, 178.22, 159.41, 162.05, 124.03999999999999, 127.25000000000003, 179.0, 178.01], "policy_predator_policy_reward": [28.0, 23.0, 27.0, 105.0, 17.0, 13.0, 23.0, 76.0, 54.0, 45.0, 6.0, 45.0, 35.0, 200.0, 11.0, 17.0, 97.0, 100.0, 14.0, 6.0, 26.0, 19.0, 88.0, 110.0, 88.0, 84.0, 24.0, 35.0, 24.0, 196.0, 45.0, 87.0, 75.0, 188.0, 25.0, 23.0, 152.0, 50.0, 29.0, 26.0, 31.0, 54.0, 94.0, 98.0, 67.0, 71.0, 18.0, 200.0, 113.0, 110.0, 64.0, 36.0, 94.0, 5.0, 86.0, 100.0, 30.0, 79.0, 81.0, 82.0, 11.0, 19.0, 40.0, 3.0, 26.0, 21.0, 89.0, 72.0, 62.0, 97.0, 135.0, 12.0, 13.0, 72.0, 23.0, 10.0, 14.0, 62.0, 41.0, 62.0, 18.0, 15.0, 43.0, 47.0, 36.0, 35.0, 47.0, 35.0, 69.0, 72.0, 13.0, 10.0, 53.0, 49.0, 15.0, 11.0, 89.0, 102.0, 90.0, 6.0, 69.0, 59.0, 22.0, 9.0, 6.0, 65.0, 77.0, 73.0, 37.0, 32.0, 54.0, 52.0, 41.0, 40.0, 70.0, 4.0, 28.0, 26.0, 10.0, 3.0, 18.0, 23.0, 23.0, 23.0, 1.0, 69.0, 20.0, 23.0, 18.0, 138.0, 35.0, 19.0, 66.0, 33.0, 53.0, 56.0, 42.0, 27.0, 39.0, 41.0, 7.0, 49.0, 3.0, 15.0, 1.0, 1.0, 5.0, 11.0, 9.0, 10.0, 59.0, 57.0, 30.0, 31.0, 75.0, 65.0, 51.0, 44.0, 17.0, 22.0, 16.0, 16.0, 42.0, 9.0, 12.0, 18.0, 84.0, 120.0, 159.0, 77.0, 11.0, 7.0, 20.0, 65.0, 197.0, 23.0, 38.0, 57.0, 13.0, 11.0, 10.0, 114.0, 50.0, 96.0, 18.0, 19.0, 14.0, 5.0, 33.0, 36.0, 42.0, 43.0, 33.0, 32.0, 2.0, 41.0, 20.0, 33.0, 21.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7061467611833216, "mean_inference_ms": 1.9062177513126506, "mean_action_processing_ms": 0.29273016553141984, "mean_env_wait_ms": 0.24104623204696174, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00510561466217041, "StateBufferConnector_ms": 0.003797173500061035, "ViewRequirementAgentConnector_ms": 0.12819206714630127}, "num_episodes": 23, "episode_return_max": 554.16, "episode_return_min": -262.93, "episode_return_mean": 357.4176999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.01441692922407, "num_env_steps_trained_throughput_per_sec": 329.01441692922407, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 12423.216, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12423.162, "sample_time_ms": 1552.929, "learn_time_ms": 10848.33, "learn_throughput": 368.72, "synch_weights_time_ms": 17.852}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "0e60f_00000", "date": "2024-08-15_01-13-49", "timestamp": 1723664629, "time_this_iter_s": 12.192500829696655, "time_total_s": 1046.6670773029327, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2ff65e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1046.6670773029327, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 58.6764705882353, "ram_util_percent": 82.70588235294117}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.773183157456615, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5712992227266707, "policy_loss": -0.007373958065977724, "vf_loss": 2.5777592016906334, "vf_explained_var": 0.18567057996199876, "kl": 0.008558886144471346, "entropy": 0.8810269345051397, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.512774491940856, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.531343906014054, "policy_loss": -0.0040665144135278684, "vf_loss": 3.5353635234176797, "vf_explained_var": 0.21542690847285842, "kl": 0.01000613981833765, "entropy": 0.7185354891908232, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 554.16, "episode_reward_min": 150.0, "episode_reward_mean": 363.8807, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -241.0, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 138.67535, "predator_policy": 43.265}, "custom_metrics": {}, "hist_stats": {"episode_reward": [321.08, 261.1400000000002, 346.6399999999997, 487.0899999999999, 342.3399999999997, 150.0, 334.43, 392.39, 293.16999999999996, 527.05, 390.11, 262.54999999999893, 346.4799999999999, 405.23, 374.2199999999998, 358.25999999999897, 303.03999999999996, 462.42999999999995, 229.60999999999981, 235.45, 322.1599999999999, 423.1399999999999, 324.66999999999973, 333.2499999999998, 322.1099999999999, 429.14, 365.08, 341.51999999999987, 271.7799999999997, 358.26, 544.14, 383.04999999999995, 385.46999999999986, 374.11999999999995, 318.65999999999974, 407.0799999999999, 341.34999999999974, 368.36, 369.30999999999995, 300.18, 372.43, 280.13000000000005, 350.54999999999995, 383.17999999999984, 360.14, 346.34000000000003, 463.81, 378.22, 355.50999999999976, 337.5199999999996, 401.1699999999999, 310.28999999999974, 333.3899999999999, 368.16999999999996, 373.29, 333.55999999999983, 319.82000000000005, 325.5599999999997, 272.8399999999994, 341.03999999999996, 381.41999999999985, 379.21000000000004, 372.18, 256.00000000000006, 395.11, 304.2099999999999, 554.16, 288.1600000000002, 376.25, 491.06, 350.5799999999999, 343.5700000000001, 476.12, 466.67999999999995, 364.01, 358.46000000000004, 357.25, 440.0, 404.46, 364.46000000000004, 304.2899999999999, 384.01, 353.44999999999993, 355.46000000000004, 425.35999999999996, 395.42999999999995, 386.0, 336.3499999999998, 395.14, 353.10999999999996, 466.23, 402.21000000000004, 410.16999999999996, 372.24, 422.32, 360.33, 336.7999999999997, 347.0999999999999, 366.16999999999996, 380.04999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-55.0, 174.07999999999998, 108.56000000000009, 97.5800000000001, 137.0, 124.64000000000019, 180.07999999999993, 115.01, 62.20999999999999, 142.12999999999994, -241.0, 173.0, 158.42000000000002, -46.99000000000001, 163.10000000000002, 129.29000000000008, 58.129999999999995, 136.04, 188.0, 153.05, 101.0, 180.11, 95.60000000000024, 3.949999999999985, 194.06, 122.42000000000009, 185.03, 177.2, 176.0, 151.21999999999983, 25.010000000000137, 172.25000000000006, 64.00999999999999, 80.03, 137.21000000000004, 178.2199999999999, 125.4800000000001, 19.130000000000006, 96.50000000000003, 105.94999999999999, 118.16000000000005, 128.0, 161.12000000000006, 159.01999999999998, 160.39999999999995, 131.27000000000012, 110.0, 133.25000000000009, 144.07999999999998, 107.03000000000002, 186.14, 161.0, 133.07, 91.00999999999999, 167.03, 151.48999999999987, 104.68999999999993, 65.08999999999997, 163.01, 169.25, 166.13, 187.01, 137.03, 150.02, 122.03, 135.43999999999997, 197.0, 146.12000000000003, 96.29000000000015, 151.36999999999995, 198.02, 59.05999999999998, 143.06, 129.28999999999988, 98.0, 164.36, 171.29, 117.02, 169.1, 57.08, 157.04000000000002, 161.39, 182.0, 85.13000000000001, 145.55, 164.0, 183.16999999999996, 154.01, 104.0, 186.14, 183.17000000000002, 120.16999999999999, 153.35, 154.46, 145.22000000000003, 179.0, 139.19000000000005, 117.3200000000001, 172.10000000000005, 56.42000000000004, 187.01, 145.1599999999999, 74.26999999999997, 156.01999999999998, 147.37999999999994, 130.01, 156.17000000000002, 194.0, 176.24, 195.05, 181.1899999999999, 136.37000000000012, 107.74999999999999, 193.07, 97.49, 112.07, 130.31000000000006, 81.53000000000016, 71.03, 130.01, 179.21, 107.2100000000001, 173.12, 167.09, 142.16000000000003, 198.01999999999998, 114.76999999999998, 90.22999999999996, 165.11, 200.0, 149.21000000000004, -49.0, 192.08, 126.08000000000001, 190.1, 80.05999999999997, 137.0, 154.25, 155.03, 116.03, 101.11999999999998, 154.46, 176.0, 143.57000000000002, 167.12, 185.0, 200.0, 120.68000000000004, 167.0, 160.01, 183.01999999999998, 156.44, 160.19, 128.06, 155.0, 200.0, 161.24, 178.22, 159.41, 162.05, 124.03999999999999, 127.25000000000003, 179.0, 178.01, 161.26999999999995, 182.18, 154.46, 164.0, 171.29000000000002, 151.07, 149.0, 148.43, 191.0, 152.0, 79.34000000000012, 157.01, 187.12999999999997, 193.01, 151.07, 157.04, 158.20999999999998, 147.01999999999998, 130.15999999999997, 189.05, 135.17, 128.0, 155.20999999999998, 197.03000000000003, 172.27999999999997, 82.03999999999999, 164.0, 167.33, 137.45, 135.3500000000001, 148.09999999999997, 119.0, 183.17000000000002, 98.0, 144.05, 149.0], "policy_predator_policy_reward": [152.0, 50.0, 29.0, 26.0, 31.0, 54.0, 94.0, 98.0, 67.0, 71.0, 18.0, 200.0, 113.0, 110.0, 64.0, 36.0, 94.0, 5.0, 86.0, 100.0, 30.0, 79.0, 81.0, 82.0, 11.0, 19.0, 40.0, 3.0, 26.0, 21.0, 89.0, 72.0, 62.0, 97.0, 135.0, 12.0, 13.0, 72.0, 23.0, 10.0, 14.0, 62.0, 41.0, 62.0, 18.0, 15.0, 43.0, 47.0, 36.0, 35.0, 47.0, 35.0, 69.0, 72.0, 13.0, 10.0, 53.0, 49.0, 15.0, 11.0, 89.0, 102.0, 90.0, 6.0, 69.0, 59.0, 22.0, 9.0, 6.0, 65.0, 77.0, 73.0, 37.0, 32.0, 54.0, 52.0, 41.0, 40.0, 70.0, 4.0, 28.0, 26.0, 10.0, 3.0, 18.0, 23.0, 23.0, 23.0, 1.0, 69.0, 20.0, 23.0, 18.0, 138.0, 35.0, 19.0, 66.0, 33.0, 53.0, 56.0, 42.0, 27.0, 39.0, 41.0, 7.0, 49.0, 3.0, 15.0, 1.0, 1.0, 5.0, 11.0, 9.0, 10.0, 59.0, 57.0, 30.0, 31.0, 75.0, 65.0, 51.0, 44.0, 17.0, 22.0, 16.0, 16.0, 42.0, 9.0, 12.0, 18.0, 84.0, 120.0, 159.0, 77.0, 11.0, 7.0, 20.0, 65.0, 197.0, 23.0, 38.0, 57.0, 13.0, 11.0, 10.0, 114.0, 50.0, 96.0, 18.0, 19.0, 14.0, 5.0, 33.0, 36.0, 42.0, 43.0, 33.0, 32.0, 2.0, 41.0, 20.0, 33.0, 21.0, 6.0, 6.0, 4.0, 21.0, 16.0, 48.0, 55.0, 72.0, 26.0, 21.0, 22.0, 20.0, 80.0, 5.0, 10.0, 24.0, 21.0, 142.0, 19.0, 61.0, 22.0, 79.0, 68.0, 10.0, 10.0, 140.0, 28.0, 27.0, 2.0, 21.0, 43.0, 38.0, 42.0, 33.0, 52.0, 50.0, 37.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7061717634895959, "mean_inference_ms": 1.9092220465452454, "mean_action_processing_ms": 0.2925356364595188, "mean_env_wait_ms": 0.24109536200588177, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00502622127532959, "StateBufferConnector_ms": 0.0034455060958862305, "ViewRequirementAgentConnector_ms": 0.12625420093536377}, "num_episodes": 18, "episode_return_max": 554.16, "episode_return_min": 150.0, "episode_return_mean": 363.8807, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 307.7962707357799, "num_env_steps_trained_throughput_per_sec": 307.7962707357799, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 12489.072, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12489.019, "sample_time_ms": 1583.87, "learn_time_ms": 10883.713, "learn_throughput": 367.522, "synch_weights_time_ms": 17.14}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "0e60f_00000", "date": "2024-08-15_01-14-02", "timestamp": 1723664642, "time_this_iter_s": 13.044339895248413, "time_total_s": 1059.7114171981812, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a303b670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1059.7114171981812, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 58.84736842105263, "ram_util_percent": 82.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.673831385815585, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0980127460742124, "policy_loss": -0.0036933924220551653, "vf_loss": 2.1011008154778255, "vf_explained_var": 0.1937160543033055, "kl": 0.005668471622402006, "entropy": 0.8821755410186828, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.869158970268946, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7244332295246223, "policy_loss": -0.003888494703578689, "vf_loss": 2.7282789797379228, "vf_explained_var": 0.13890928925660553, "kl": 0.009118517220131782, "entropy": 0.7312979350329707, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 554.16, "episode_reward_min": 246.45999999999998, "episode_reward_mean": 369.7686, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -106.54000000000002, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 147.61430000000001, "predator_policy": 37.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [324.66999999999973, 333.2499999999998, 322.1099999999999, 429.14, 365.08, 341.51999999999987, 271.7799999999997, 358.26, 544.14, 383.04999999999995, 385.46999999999986, 374.11999999999995, 318.65999999999974, 407.0799999999999, 341.34999999999974, 368.36, 369.30999999999995, 300.18, 372.43, 280.13000000000005, 350.54999999999995, 383.17999999999984, 360.14, 346.34000000000003, 463.81, 378.22, 355.50999999999976, 337.5199999999996, 401.1699999999999, 310.28999999999974, 333.3899999999999, 368.16999999999996, 373.29, 333.55999999999983, 319.82000000000005, 325.5599999999997, 272.8399999999994, 341.03999999999996, 381.41999999999985, 379.21000000000004, 372.18, 256.00000000000006, 395.11, 304.2099999999999, 554.16, 288.1600000000002, 376.25, 491.06, 350.5799999999999, 343.5700000000001, 476.12, 466.67999999999995, 364.01, 358.46000000000004, 357.25, 440.0, 404.46, 364.46000000000004, 304.2899999999999, 384.01, 353.44999999999993, 355.46000000000004, 425.35999999999996, 395.42999999999995, 386.0, 336.3499999999998, 395.14, 353.10999999999996, 466.23, 402.21000000000004, 410.16999999999996, 372.24, 422.32, 360.33, 336.7999999999997, 347.0999999999999, 366.16999999999996, 380.04999999999995, 340.06, 364.2699999999999, 491.27, 246.45999999999998, 413.03, 375.22999999999996, 398.0, 360.30999999999995, 343.53, 343.1799999999999, 336.45000000000005, 391.2099999999998, 402.15, 345.26, 353.4699999999999, 343.46, 401.02, 386.2, 376.11, 379.04999999999995, 438.3, 328.78], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [160.39999999999995, 131.27000000000012, 110.0, 133.25000000000009, 144.07999999999998, 107.03000000000002, 186.14, 161.0, 133.07, 91.00999999999999, 167.03, 151.48999999999987, 104.68999999999993, 65.08999999999997, 163.01, 169.25, 166.13, 187.01, 137.03, 150.02, 122.03, 135.43999999999997, 197.0, 146.12000000000003, 96.29000000000015, 151.36999999999995, 198.02, 59.05999999999998, 143.06, 129.28999999999988, 98.0, 164.36, 171.29, 117.02, 169.1, 57.08, 157.04000000000002, 161.39, 182.0, 85.13000000000001, 145.55, 164.0, 183.16999999999996, 154.01, 104.0, 186.14, 183.17000000000002, 120.16999999999999, 153.35, 154.46, 145.22000000000003, 179.0, 139.19000000000005, 117.3200000000001, 172.10000000000005, 56.42000000000004, 187.01, 145.1599999999999, 74.26999999999997, 156.01999999999998, 147.37999999999994, 130.01, 156.17000000000002, 194.0, 176.24, 195.05, 181.1899999999999, 136.37000000000012, 107.74999999999999, 193.07, 97.49, 112.07, 130.31000000000006, 81.53000000000016, 71.03, 130.01, 179.21, 107.2100000000001, 173.12, 167.09, 142.16000000000003, 198.01999999999998, 114.76999999999998, 90.22999999999996, 165.11, 200.0, 149.21000000000004, -49.0, 192.08, 126.08000000000001, 190.1, 80.05999999999997, 137.0, 154.25, 155.03, 116.03, 101.11999999999998, 154.46, 176.0, 143.57000000000002, 167.12, 185.0, 200.0, 120.68000000000004, 167.0, 160.01, 183.01999999999998, 156.44, 160.19, 128.06, 155.0, 200.0, 161.24, 178.22, 159.41, 162.05, 124.03999999999999, 127.25000000000003, 179.0, 178.01, 161.26999999999995, 182.18, 154.46, 164.0, 171.29000000000002, 151.07, 149.0, 148.43, 191.0, 152.0, 79.34000000000012, 157.01, 187.12999999999997, 193.01, 151.07, 157.04, 158.20999999999998, 147.01999999999998, 130.15999999999997, 189.05, 135.17, 128.0, 155.20999999999998, 197.03000000000003, 172.27999999999997, 82.03999999999999, 164.0, 167.33, 137.45, 135.3500000000001, 148.09999999999997, 119.0, 183.17000000000002, 98.0, 144.05, 149.0, 148.04, 144.01999999999998, 126.22999999999999, 196.04000000000002, 146.0, 173.26999999999998, -106.54000000000002, 173.0, 176.03, 146.0, 140.0, 141.23, 188.0, 179.0, 148.22000000000006, 191.09, 153.14000000000001, 158.39, 155.05999999999997, 143.11999999999995, 146.45, 161.0, 155.06, 179.15000000000006, 191.09, 161.06, 156.26, 137.0, 92.36000000000004, 189.10999999999999, 144.44, 156.01999999999998, 200.0, 147.01999999999998, 195.01999999999998, 182.18, 180.11, 140.0, 132.05, 191.0, 64.25000000000003, 186.04999999999998, 139.34000000000006, 156.44], "policy_predator_policy_reward": [18.0, 15.0, 43.0, 47.0, 36.0, 35.0, 47.0, 35.0, 69.0, 72.0, 13.0, 10.0, 53.0, 49.0, 15.0, 11.0, 89.0, 102.0, 90.0, 6.0, 69.0, 59.0, 22.0, 9.0, 6.0, 65.0, 77.0, 73.0, 37.0, 32.0, 54.0, 52.0, 41.0, 40.0, 70.0, 4.0, 28.0, 26.0, 10.0, 3.0, 18.0, 23.0, 23.0, 23.0, 1.0, 69.0, 20.0, 23.0, 18.0, 138.0, 35.0, 19.0, 66.0, 33.0, 53.0, 56.0, 42.0, 27.0, 39.0, 41.0, 7.0, 49.0, 3.0, 15.0, 1.0, 1.0, 5.0, 11.0, 9.0, 10.0, 59.0, 57.0, 30.0, 31.0, 75.0, 65.0, 51.0, 44.0, 17.0, 22.0, 16.0, 16.0, 42.0, 9.0, 12.0, 18.0, 84.0, 120.0, 159.0, 77.0, 11.0, 7.0, 20.0, 65.0, 197.0, 23.0, 38.0, 57.0, 13.0, 11.0, 10.0, 114.0, 50.0, 96.0, 18.0, 19.0, 14.0, 5.0, 33.0, 36.0, 42.0, 43.0, 33.0, 32.0, 2.0, 41.0, 20.0, 33.0, 21.0, 6.0, 6.0, 4.0, 21.0, 16.0, 48.0, 55.0, 72.0, 26.0, 21.0, 22.0, 20.0, 80.0, 5.0, 10.0, 24.0, 21.0, 142.0, 19.0, 61.0, 22.0, 79.0, 68.0, 10.0, 10.0, 140.0, 28.0, 27.0, 2.0, 21.0, 43.0, 38.0, 42.0, 33.0, 52.0, 50.0, 37.0, 28.0, 20.0, 26.0, 16.0, 45.0, 127.0, 133.0, 47.0, 25.0, 66.0, 34.0, 60.0, 18.0, 13.0, 9.0, 12.0, 13.0, 19.0, 25.0, 20.0, 7.0, 22.0, 3.0, 54.0, 28.0, 22.0, 29.0, 23.0, 64.0, 8.0, 21.0, 22.0, 28.0, 26.0, 7.0, 2.0, 17.0, 39.0, 27.0, 29.0, 160.0, 28.0, 16.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7058840364587877, "mean_inference_ms": 1.9130737817981185, "mean_action_processing_ms": 0.29173505447375264, "mean_env_wait_ms": 0.24111001311233488, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005017280578613281, "StateBufferConnector_ms": 0.003429412841796875, "ViewRequirementAgentConnector_ms": 0.11543726921081543}, "num_episodes": 22, "episode_return_max": 554.16, "episode_return_min": 246.45999999999998, "episode_return_mean": 369.7686, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 327.8379256757591, "num_env_steps_trained_throughput_per_sec": 327.8379256757591, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 12408.289, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12408.236, "sample_time_ms": 1572.608, "learn_time_ms": 10815.385, "learn_throughput": 369.844, "synch_weights_time_ms": 16.541}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "0e60f_00000", "date": "2024-08-15_01-14-14", "timestamp": 1723664654, "time_this_iter_s": 12.262266874313354, "time_total_s": 1071.9736840724945, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2ff6310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1071.9736840724945, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 59.21764705882352, "ram_util_percent": 82.81764705882354}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.395632466610777, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6258126957706673, "policy_loss": -0.0040420895301929065, "vf_loss": 1.6291219317408465, "vf_explained_var": 0.10940843839494009, "kl": 0.00686276432699161, "entropy": 0.8837427388738703, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.422041430044427, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.674542670779758, "policy_loss": -0.005659825308987546, "vf_loss": 3.680165053801562, "vf_explained_var": 0.21009981613310558, "kl": 0.007986178358294219, "entropy": 0.7440269736701218, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 554.16, "episode_reward_min": 246.45999999999998, "episode_reward_mean": 372.4573999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -106.54000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 150.3887, "predator_policy": 35.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [372.43, 280.13000000000005, 350.54999999999995, 383.17999999999984, 360.14, 346.34000000000003, 463.81, 378.22, 355.50999999999976, 337.5199999999996, 401.1699999999999, 310.28999999999974, 333.3899999999999, 368.16999999999996, 373.29, 333.55999999999983, 319.82000000000005, 325.5599999999997, 272.8399999999994, 341.03999999999996, 381.41999999999985, 379.21000000000004, 372.18, 256.00000000000006, 395.11, 304.2099999999999, 554.16, 288.1600000000002, 376.25, 491.06, 350.5799999999999, 343.5700000000001, 476.12, 466.67999999999995, 364.01, 358.46000000000004, 357.25, 440.0, 404.46, 364.46000000000004, 304.2899999999999, 384.01, 353.44999999999993, 355.46000000000004, 425.35999999999996, 395.42999999999995, 386.0, 336.3499999999998, 395.14, 353.10999999999996, 466.23, 402.21000000000004, 410.16999999999996, 372.24, 422.32, 360.33, 336.7999999999997, 347.0999999999999, 366.16999999999996, 380.04999999999995, 340.06, 364.2699999999999, 491.27, 246.45999999999998, 413.03, 375.22999999999996, 398.0, 360.30999999999995, 343.53, 343.1799999999999, 336.45000000000005, 391.2099999999998, 402.15, 345.26, 353.4699999999999, 343.46, 401.02, 386.2, 376.11, 379.04999999999995, 438.3, 328.78, 381.07, 408.0, 378.15999999999997, 387.65, 330.01, 352.35, 384.33, 380.43999999999994, 405.03999999999996, 312.4, 347.52, 345.08, 398.18, 354.06, 421.04, 401.02, 445.02, 375.04], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [157.04000000000002, 161.39, 182.0, 85.13000000000001, 145.55, 164.0, 183.16999999999996, 154.01, 104.0, 186.14, 183.17000000000002, 120.16999999999999, 153.35, 154.46, 145.22000000000003, 179.0, 139.19000000000005, 117.3200000000001, 172.10000000000005, 56.42000000000004, 187.01, 145.1599999999999, 74.26999999999997, 156.01999999999998, 147.37999999999994, 130.01, 156.17000000000002, 194.0, 176.24, 195.05, 181.1899999999999, 136.37000000000012, 107.74999999999999, 193.07, 97.49, 112.07, 130.31000000000006, 81.53000000000016, 71.03, 130.01, 179.21, 107.2100000000001, 173.12, 167.09, 142.16000000000003, 198.01999999999998, 114.76999999999998, 90.22999999999996, 165.11, 200.0, 149.21000000000004, -49.0, 192.08, 126.08000000000001, 190.1, 80.05999999999997, 137.0, 154.25, 155.03, 116.03, 101.11999999999998, 154.46, 176.0, 143.57000000000002, 167.12, 185.0, 200.0, 120.68000000000004, 167.0, 160.01, 183.01999999999998, 156.44, 160.19, 128.06, 155.0, 200.0, 161.24, 178.22, 159.41, 162.05, 124.03999999999999, 127.25000000000003, 179.0, 178.01, 161.26999999999995, 182.18, 154.46, 164.0, 171.29000000000002, 151.07, 149.0, 148.43, 191.0, 152.0, 79.34000000000012, 157.01, 187.12999999999997, 193.01, 151.07, 157.04, 158.20999999999998, 147.01999999999998, 130.15999999999997, 189.05, 135.17, 128.0, 155.20999999999998, 197.03000000000003, 172.27999999999997, 82.03999999999999, 164.0, 167.33, 137.45, 135.3500000000001, 148.09999999999997, 119.0, 183.17000000000002, 98.0, 144.05, 149.0, 148.04, 144.01999999999998, 126.22999999999999, 196.04000000000002, 146.0, 173.26999999999998, -106.54000000000002, 173.0, 176.03, 146.0, 140.0, 141.23, 188.0, 179.0, 148.22000000000006, 191.09, 153.14000000000001, 158.39, 155.05999999999997, 143.11999999999995, 146.45, 161.0, 155.06, 179.15000000000006, 191.09, 161.06, 156.26, 137.0, 92.36000000000004, 189.10999999999999, 144.44, 156.01999999999998, 200.0, 147.01999999999998, 195.01999999999998, 182.18, 180.11, 140.0, 132.05, 191.0, 64.25000000000003, 186.04999999999998, 139.34000000000006, 156.44, 157.04, 155.03, 191.0, 80.0, 159.05, 189.11, 152.45, 180.2, -13.989999999999995, 158.0, 190.1, 130.25000000000003, 169.13, 180.20000000000002, 156.41000000000003, 161.03000000000003, 193.04000000000002, 191.0, 151.33999999999997, 119.06000000000002, 128.06000000000003, 154.46, 74.0, 165.07999999999998, 185.15, 176.03, 87.05, 160.01, 176.03, 178.01, 155.0, 159.01999999999998, 154.01, 175.01, 154.01, 197.03000000000003], "policy_predator_policy_reward": [28.0, 26.0, 10.0, 3.0, 18.0, 23.0, 23.0, 23.0, 1.0, 69.0, 20.0, 23.0, 18.0, 138.0, 35.0, 19.0, 66.0, 33.0, 53.0, 56.0, 42.0, 27.0, 39.0, 41.0, 7.0, 49.0, 3.0, 15.0, 1.0, 1.0, 5.0, 11.0, 9.0, 10.0, 59.0, 57.0, 30.0, 31.0, 75.0, 65.0, 51.0, 44.0, 17.0, 22.0, 16.0, 16.0, 42.0, 9.0, 12.0, 18.0, 84.0, 120.0, 159.0, 77.0, 11.0, 7.0, 20.0, 65.0, 197.0, 23.0, 38.0, 57.0, 13.0, 11.0, 10.0, 114.0, 50.0, 96.0, 18.0, 19.0, 14.0, 5.0, 33.0, 36.0, 42.0, 43.0, 33.0, 32.0, 2.0, 41.0, 20.0, 33.0, 21.0, 6.0, 6.0, 4.0, 21.0, 16.0, 48.0, 55.0, 72.0, 26.0, 21.0, 22.0, 20.0, 80.0, 5.0, 10.0, 24.0, 21.0, 142.0, 19.0, 61.0, 22.0, 79.0, 68.0, 10.0, 10.0, 140.0, 28.0, 27.0, 2.0, 21.0, 43.0, 38.0, 42.0, 33.0, 52.0, 50.0, 37.0, 28.0, 20.0, 26.0, 16.0, 45.0, 127.0, 133.0, 47.0, 25.0, 66.0, 34.0, 60.0, 18.0, 13.0, 9.0, 12.0, 13.0, 19.0, 25.0, 20.0, 7.0, 22.0, 3.0, 54.0, 28.0, 22.0, 29.0, 23.0, 64.0, 8.0, 21.0, 22.0, 28.0, 26.0, 7.0, 2.0, 17.0, 39.0, 27.0, 29.0, 160.0, 28.0, 16.0, 17.0, 43.0, 26.0, 67.0, 70.0, 17.0, 13.0, 0.0, 55.0, 39.0, 147.0, 17.0, 15.0, 18.0, 17.0, 32.0, 31.0, 11.0, 10.0, 35.0, 7.0, 31.0, 34.0, 56.0, 50.0, 15.0, 22.0, 55.0, 52.0, 22.0, 45.0, 41.0, 46.0, 102.0, 14.0, 23.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7055875568030805, "mean_inference_ms": 1.9144740605674744, "mean_action_processing_ms": 0.291890895380425, "mean_env_wait_ms": 0.24105290534387208, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004243016242980957, "StateBufferConnector_ms": 0.003396749496459961, "ViewRequirementAgentConnector_ms": 0.11669039726257324}, "num_episodes": 18, "episode_return_max": 554.16, "episode_return_min": 246.45999999999998, "episode_return_mean": 372.4573999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 322.44950377395793, "num_env_steps_trained_throughput_per_sec": 322.44950377395793, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 12408.546, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12408.494, "sample_time_ms": 1568.745, "learn_time_ms": 10819.305, "learn_throughput": 369.71, "synch_weights_time_ms": 16.792}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "0e60f_00000", "date": "2024-08-15_01-14-27", "timestamp": 1723664667, "time_this_iter_s": 12.442777872085571, "time_total_s": 1084.41646194458, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a318c3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1084.41646194458, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 58.30555555555556, "ram_util_percent": 83.04444444444442}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3266439117451823, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0008477749647917, "policy_loss": -0.0026042734388577403, "vf_loss": 2.0027018178707707, "vf_explained_var": 0.07056927614741855, "kl": 0.007025475549192941, "entropy": 0.8802463112369416, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.055072360442429, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6877745362185927, "policy_loss": -0.0027587972172393054, "vf_loss": 3.6904726274429804, "vf_explained_var": 0.07246518317984525, "kl": 0.01295032124202847, "entropy": 0.8279791205333024, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 554.16, "episode_reward_min": 246.45999999999998, "episode_reward_mean": 379.7795999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -106.99000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 151.3298, "predator_policy": 38.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [256.00000000000006, 395.11, 304.2099999999999, 554.16, 288.1600000000002, 376.25, 491.06, 350.5799999999999, 343.5700000000001, 476.12, 466.67999999999995, 364.01, 358.46000000000004, 357.25, 440.0, 404.46, 364.46000000000004, 304.2899999999999, 384.01, 353.44999999999993, 355.46000000000004, 425.35999999999996, 395.42999999999995, 386.0, 336.3499999999998, 395.14, 353.10999999999996, 466.23, 402.21000000000004, 410.16999999999996, 372.24, 422.32, 360.33, 336.7999999999997, 347.0999999999999, 366.16999999999996, 380.04999999999995, 340.06, 364.2699999999999, 491.27, 246.45999999999998, 413.03, 375.22999999999996, 398.0, 360.30999999999995, 343.53, 343.1799999999999, 336.45000000000005, 391.2099999999998, 402.15, 345.26, 353.4699999999999, 343.46, 401.02, 386.2, 376.11, 379.04999999999995, 438.3, 328.78, 381.07, 408.0, 378.15999999999997, 387.65, 330.01, 352.35, 384.33, 380.43999999999994, 405.03999999999996, 312.4, 347.52, 345.08, 398.18, 354.06, 421.04, 401.02, 445.02, 375.04, 368.21, 302.21, 326.19000000000005, 500.0999999999999, 400.14, 345.32999999999976, 343.09999999999997, 338.04999999999995, 461.17999999999995, 384.10999999999996, 354.29, 419.0, 333.09, 409.06, 521.0, 407.0, 401.01, 347.41999999999996, 398.21, 364.1699999999999, 382.02, 393.03, 374.07], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [114.76999999999998, 90.22999999999996, 165.11, 200.0, 149.21000000000004, -49.0, 192.08, 126.08000000000001, 190.1, 80.05999999999997, 137.0, 154.25, 155.03, 116.03, 101.11999999999998, 154.46, 176.0, 143.57000000000002, 167.12, 185.0, 200.0, 120.68000000000004, 167.0, 160.01, 183.01999999999998, 156.44, 160.19, 128.06, 155.0, 200.0, 161.24, 178.22, 159.41, 162.05, 124.03999999999999, 127.25000000000003, 179.0, 178.01, 161.26999999999995, 182.18, 154.46, 164.0, 171.29000000000002, 151.07, 149.0, 148.43, 191.0, 152.0, 79.34000000000012, 157.01, 187.12999999999997, 193.01, 151.07, 157.04, 158.20999999999998, 147.01999999999998, 130.15999999999997, 189.05, 135.17, 128.0, 155.20999999999998, 197.03000000000003, 172.27999999999997, 82.03999999999999, 164.0, 167.33, 137.45, 135.3500000000001, 148.09999999999997, 119.0, 183.17000000000002, 98.0, 144.05, 149.0, 148.04, 144.01999999999998, 126.22999999999999, 196.04000000000002, 146.0, 173.26999999999998, -106.54000000000002, 173.0, 176.03, 146.0, 140.0, 141.23, 188.0, 179.0, 148.22000000000006, 191.09, 153.14000000000001, 158.39, 155.05999999999997, 143.11999999999995, 146.45, 161.0, 155.06, 179.15000000000006, 191.09, 161.06, 156.26, 137.0, 92.36000000000004, 189.10999999999999, 144.44, 156.01999999999998, 200.0, 147.01999999999998, 195.01999999999998, 182.18, 180.11, 140.0, 132.05, 191.0, 64.25000000000003, 186.04999999999998, 139.34000000000006, 156.44, 157.04, 155.03, 191.0, 80.0, 159.05, 189.11, 152.45, 180.2, -13.989999999999995, 158.0, 190.1, 130.25000000000003, 169.13, 180.20000000000002, 156.41000000000003, 161.03000000000003, 193.04000000000002, 191.0, 151.33999999999997, 119.06000000000002, 128.06000000000003, 154.46, 74.0, 165.07999999999998, 185.15, 176.03, 87.05, 160.01, 176.03, 178.01, 155.0, 159.01999999999998, 154.01, 175.01, 154.01, 197.03000000000003, 179.21, 104.0, 180.2, -106.99000000000001, 149.0, 142.19000000000003, 128.0, 121.10000000000004, 127.00999999999999, 187.13, 145.07000000000002, 129.2600000000001, 129.01999999999998, 144.08, 152.0, 132.05, 181.16, 195.02, 148.06999999999994, 163.04000000000002, 128.24000000000004, 195.05, 179.0, 200.0, 152.0, 131.09000000000003, 164.0, 179.06, 173.0, 161.0, 149.0, 200.0, 131.0, 151.01, 158.42000000000002, 116.0, 185.03, 182.18, 147.14000000000004, 155.03000000000003, 189.01999999999998, 89.0, 194.02999999999997, 164.0, 157.07, 140.0], "policy_predator_policy_reward": [42.0, 9.0, 12.0, 18.0, 84.0, 120.0, 159.0, 77.0, 11.0, 7.0, 20.0, 65.0, 197.0, 23.0, 38.0, 57.0, 13.0, 11.0, 10.0, 114.0, 50.0, 96.0, 18.0, 19.0, 14.0, 5.0, 33.0, 36.0, 42.0, 43.0, 33.0, 32.0, 2.0, 41.0, 20.0, 33.0, 21.0, 6.0, 6.0, 4.0, 21.0, 16.0, 48.0, 55.0, 72.0, 26.0, 21.0, 22.0, 20.0, 80.0, 5.0, 10.0, 24.0, 21.0, 142.0, 19.0, 61.0, 22.0, 79.0, 68.0, 10.0, 10.0, 140.0, 28.0, 27.0, 2.0, 21.0, 43.0, 38.0, 42.0, 33.0, 52.0, 50.0, 37.0, 28.0, 20.0, 26.0, 16.0, 45.0, 127.0, 133.0, 47.0, 25.0, 66.0, 34.0, 60.0, 18.0, 13.0, 9.0, 12.0, 13.0, 19.0, 25.0, 20.0, 7.0, 22.0, 3.0, 54.0, 28.0, 22.0, 29.0, 23.0, 64.0, 8.0, 21.0, 22.0, 28.0, 26.0, 7.0, 2.0, 17.0, 39.0, 27.0, 29.0, 160.0, 28.0, 16.0, 17.0, 43.0, 26.0, 67.0, 70.0, 17.0, 13.0, 0.0, 55.0, 39.0, 147.0, 17.0, 15.0, 18.0, 17.0, 32.0, 31.0, 11.0, 10.0, 35.0, 7.0, 31.0, 34.0, 56.0, 50.0, 15.0, 22.0, 55.0, 52.0, 22.0, 45.0, 41.0, 46.0, 102.0, 14.0, 23.0, 1.0, 45.0, 40.0, 193.0, 36.0, 21.0, 14.0, 123.0, 128.0, 43.0, 43.0, 37.0, 34.0, 50.0, 20.0, 47.0, 7.0, 27.0, 58.0, 38.0, 35.0, 20.0, 11.0, 23.0, 17.0, 24.0, 26.0, 31.0, 35.0, 101.0, 86.0, 33.0, 25.0, 54.0, 65.0, 16.0, 57.0, 15.0, 16.0, 23.0, 39.0, 68.0, 36.0, 8.0, 27.0, 49.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7055029768935447, "mean_inference_ms": 1.9171817364094323, "mean_action_processing_ms": 0.2917342720230226, "mean_env_wait_ms": 0.24128033952771477, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005365967750549316, "StateBufferConnector_ms": 0.003383636474609375, "ViewRequirementAgentConnector_ms": 0.12624144554138184}, "num_episodes": 23, "episode_return_max": 554.16, "episode_return_min": 246.45999999999998, "episode_return_mean": 379.7795999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 325.23176075129913, "num_env_steps_trained_throughput_per_sec": 325.23176075129913, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 12396.079, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12396.025, "sample_time_ms": 1567.565, "learn_time_ms": 10807.886, "learn_throughput": 370.1, "synch_weights_time_ms": 16.915}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "0e60f_00000", "date": "2024-08-15_01-14-39", "timestamp": 1723664679, "time_this_iter_s": 12.34317684173584, "time_total_s": 1096.759638786316, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a318c5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1096.759638786316, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 58.56470588235294, "ram_util_percent": 83.07058823529412}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4042522540168156, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1848585052465004, "policy_loss": -0.0007318338921303471, "vf_loss": 2.1851087425120923, "vf_explained_var": 0.10038164964428654, "kl": 0.004509836496637617, "entropy": 0.8602389970153728, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.496888682261977, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.679270464402658, "policy_loss": -0.004893856285701668, "vf_loss": 5.6841137778822075, "vf_explained_var": 0.13582425212103222, "kl": 0.010785077743022366, "entropy": 0.6567744870665212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 561.23, "episode_reward_min": 246.45999999999998, "episode_reward_mean": 384.8577, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -106.99000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 193.0}, "policy_reward_mean": {"prey_policy": 152.77384999999998, "predator_policy": 39.655}, "custom_metrics": {}, "hist_stats": {"episode_reward": [384.01, 353.44999999999993, 355.46000000000004, 425.35999999999996, 395.42999999999995, 386.0, 336.3499999999998, 395.14, 353.10999999999996, 466.23, 402.21000000000004, 410.16999999999996, 372.24, 422.32, 360.33, 336.7999999999997, 347.0999999999999, 366.16999999999996, 380.04999999999995, 340.06, 364.2699999999999, 491.27, 246.45999999999998, 413.03, 375.22999999999996, 398.0, 360.30999999999995, 343.53, 343.1799999999999, 336.45000000000005, 391.2099999999998, 402.15, 345.26, 353.4699999999999, 343.46, 401.02, 386.2, 376.11, 379.04999999999995, 438.3, 328.78, 381.07, 408.0, 378.15999999999997, 387.65, 330.01, 352.35, 384.33, 380.43999999999994, 405.03999999999996, 312.4, 347.52, 345.08, 398.18, 354.06, 421.04, 401.02, 445.02, 375.04, 368.21, 302.21, 326.19000000000005, 500.0999999999999, 400.14, 345.32999999999976, 343.09999999999997, 338.04999999999995, 461.17999999999995, 384.10999999999996, 354.29, 419.0, 333.09, 409.06, 521.0, 407.0, 401.01, 347.41999999999996, 398.21, 364.1699999999999, 382.02, 393.03, 374.07, 378.08, 397.06, 352.13999999999993, 421.01, 387.01, 514.01, 383.18, 396.25, 428.02, 292.12, 355.44, 473.37, 419.01, 462.56, 501.02, 343.46999999999997, 337.66, 561.23], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [179.0, 178.01, 161.26999999999995, 182.18, 154.46, 164.0, 171.29000000000002, 151.07, 149.0, 148.43, 191.0, 152.0, 79.34000000000012, 157.01, 187.12999999999997, 193.01, 151.07, 157.04, 158.20999999999998, 147.01999999999998, 130.15999999999997, 189.05, 135.17, 128.0, 155.20999999999998, 197.03000000000003, 172.27999999999997, 82.03999999999999, 164.0, 167.33, 137.45, 135.3500000000001, 148.09999999999997, 119.0, 183.17000000000002, 98.0, 144.05, 149.0, 148.04, 144.01999999999998, 126.22999999999999, 196.04000000000002, 146.0, 173.26999999999998, -106.54000000000002, 173.0, 176.03, 146.0, 140.0, 141.23, 188.0, 179.0, 148.22000000000006, 191.09, 153.14000000000001, 158.39, 155.05999999999997, 143.11999999999995, 146.45, 161.0, 155.06, 179.15000000000006, 191.09, 161.06, 156.26, 137.0, 92.36000000000004, 189.10999999999999, 144.44, 156.01999999999998, 200.0, 147.01999999999998, 195.01999999999998, 182.18, 180.11, 140.0, 132.05, 191.0, 64.25000000000003, 186.04999999999998, 139.34000000000006, 156.44, 157.04, 155.03, 191.0, 80.0, 159.05, 189.11, 152.45, 180.2, -13.989999999999995, 158.0, 190.1, 130.25000000000003, 169.13, 180.20000000000002, 156.41000000000003, 161.03000000000003, 193.04000000000002, 191.0, 151.33999999999997, 119.06000000000002, 128.06000000000003, 154.46, 74.0, 165.07999999999998, 185.15, 176.03, 87.05, 160.01, 176.03, 178.01, 155.0, 159.01999999999998, 154.01, 175.01, 154.01, 197.03000000000003, 179.21, 104.0, 180.2, -106.99000000000001, 149.0, 142.19000000000003, 128.0, 121.10000000000004, 127.00999999999999, 187.13, 145.07000000000002, 129.2600000000001, 129.01999999999998, 144.08, 152.0, 132.05, 181.16, 195.02, 148.06999999999994, 163.04000000000002, 128.24000000000004, 195.05, 179.0, 200.0, 152.0, 131.09000000000003, 164.0, 179.06, 173.0, 161.0, 149.0, 200.0, 131.0, 151.01, 158.42000000000002, 116.0, 185.03, 182.18, 147.14000000000004, 155.03000000000003, 189.01999999999998, 89.0, 194.02999999999997, 164.0, 157.07, 140.0, 174.05, 134.03000000000003, 188.0, 173.06, 144.11, 173.03, 166.01, 194.0, 176.0, 160.01, 196.01, 182.0, 194.06, 140.12, 176.0, 175.25, 198.01999999999998, 161.0, 145.1, -44.980000000000004, 139.39999999999998, 175.04, 158.09, 172.28, 200.0, 46.00999999999999, 125.33000000000006, 177.23000000000002, 160.01, 199.01, 45.20000000000001, 137.27000000000004, 150.47, 181.19, 150.23000000000002, 158.0], "policy_predator_policy_reward": [21.0, 6.0, 6.0, 4.0, 21.0, 16.0, 48.0, 55.0, 72.0, 26.0, 21.0, 22.0, 20.0, 80.0, 5.0, 10.0, 24.0, 21.0, 142.0, 19.0, 61.0, 22.0, 79.0, 68.0, 10.0, 10.0, 140.0, 28.0, 27.0, 2.0, 21.0, 43.0, 38.0, 42.0, 33.0, 52.0, 50.0, 37.0, 28.0, 20.0, 26.0, 16.0, 45.0, 127.0, 133.0, 47.0, 25.0, 66.0, 34.0, 60.0, 18.0, 13.0, 9.0, 12.0, 13.0, 19.0, 25.0, 20.0, 7.0, 22.0, 3.0, 54.0, 28.0, 22.0, 29.0, 23.0, 64.0, 8.0, 21.0, 22.0, 28.0, 26.0, 7.0, 2.0, 17.0, 39.0, 27.0, 29.0, 160.0, 28.0, 16.0, 17.0, 43.0, 26.0, 67.0, 70.0, 17.0, 13.0, 0.0, 55.0, 39.0, 147.0, 17.0, 15.0, 18.0, 17.0, 32.0, 31.0, 11.0, 10.0, 35.0, 7.0, 31.0, 34.0, 56.0, 50.0, 15.0, 22.0, 55.0, 52.0, 22.0, 45.0, 41.0, 46.0, 102.0, 14.0, 23.0, 1.0, 45.0, 40.0, 193.0, 36.0, 21.0, 14.0, 123.0, 128.0, 43.0, 43.0, 37.0, 34.0, 50.0, 20.0, 47.0, 7.0, 27.0, 58.0, 38.0, 35.0, 20.0, 11.0, 23.0, 17.0, 24.0, 26.0, 31.0, 35.0, 101.0, 86.0, 33.0, 25.0, 54.0, 65.0, 16.0, 57.0, 15.0, 16.0, 23.0, 39.0, 68.0, 36.0, 8.0, 27.0, 49.0, 28.0, 26.0, 44.0, 15.0, 21.0, 23.0, 12.0, 31.0, 30.0, 22.0, 29.0, 63.0, 73.0, 14.0, 35.0, 44.0, 1.0, 32.0, 37.0, 166.0, 26.0, 32.0, 9.0, 63.0, 80.0, 80.0, 93.0, 108.0, 52.0, 61.0, 81.0, 153.0, 8.0, 3.0, 3.0, 93.0, 160.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7050948633111731, "mean_inference_ms": 1.9196076905668462, "mean_action_processing_ms": 0.29119172768750173, "mean_env_wait_ms": 0.24099339485119295, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005791068077087402, "StateBufferConnector_ms": 0.0033212900161743164, "ViewRequirementAgentConnector_ms": 0.1209864616394043}, "num_episodes": 18, "episode_return_max": 561.23, "episode_return_min": 246.45999999999998, "episode_return_mean": 384.8577, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 323.61622090908077, "num_env_steps_trained_throughput_per_sec": 323.61622090908077, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 12395.234, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12395.181, "sample_time_ms": 1600.831, "learn_time_ms": 10773.42, "learn_throughput": 371.284, "synch_weights_time_ms": 17.339}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "0e60f_00000", "date": "2024-08-15_01-14-52", "timestamp": 1723664692, "time_this_iter_s": 12.407537937164307, "time_total_s": 1109.1671767234802, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a309f550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1109.1671767234802, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 57.53333333333333, "ram_util_percent": 83.43888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.5490047115812855, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.756041959038487, "policy_loss": -0.0029856717979003275, "vf_loss": 2.7583985095301635, "vf_explained_var": 0.12977001808938526, "kl": 0.011783007902553525, "entropy": 0.8264610370315572, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.126098321228431, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.415558700208311, "policy_loss": -0.002129915730027413, "vf_loss": 6.417645159978715, "vf_explained_var": 0.09655256722339246, "kl": 0.009271255832127893, "entropy": 0.5799958760618533, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 667.02, "episode_reward_min": 244.22, "episode_reward_mean": 393.7632, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -131.92000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 150.6416, "predator_policy": 46.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [380.04999999999995, 340.06, 364.2699999999999, 491.27, 246.45999999999998, 413.03, 375.22999999999996, 398.0, 360.30999999999995, 343.53, 343.1799999999999, 336.45000000000005, 391.2099999999998, 402.15, 345.26, 353.4699999999999, 343.46, 401.02, 386.2, 376.11, 379.04999999999995, 438.3, 328.78, 381.07, 408.0, 378.15999999999997, 387.65, 330.01, 352.35, 384.33, 380.43999999999994, 405.03999999999996, 312.4, 347.52, 345.08, 398.18, 354.06, 421.04, 401.02, 445.02, 375.04, 368.21, 302.21, 326.19000000000005, 500.0999999999999, 400.14, 345.32999999999976, 343.09999999999997, 338.04999999999995, 461.17999999999995, 384.10999999999996, 354.29, 419.0, 333.09, 409.06, 521.0, 407.0, 401.01, 347.41999999999996, 398.21, 364.1699999999999, 382.02, 393.03, 374.07, 378.08, 397.06, 352.13999999999993, 421.01, 387.01, 514.01, 383.18, 396.25, 428.02, 292.12, 355.44, 473.37, 419.01, 462.56, 501.02, 343.46999999999997, 337.66, 561.23, 385.27000000000004, 341.43999999999994, 468.07, 391.1799999999999, 429.03, 472.03999999999996, 244.22, 490.2299999999999, 495.06, 282.07, 496.2199999999999, 667.02, 363.02, 527.0, 487.0, 439.0799999999999, 366.45, 414.03], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [144.05, 149.0, 148.04, 144.01999999999998, 126.22999999999999, 196.04000000000002, 146.0, 173.26999999999998, -106.54000000000002, 173.0, 176.03, 146.0, 140.0, 141.23, 188.0, 179.0, 148.22000000000006, 191.09, 153.14000000000001, 158.39, 155.05999999999997, 143.11999999999995, 146.45, 161.0, 155.06, 179.15000000000006, 191.09, 161.06, 156.26, 137.0, 92.36000000000004, 189.10999999999999, 144.44, 156.01999999999998, 200.0, 147.01999999999998, 195.01999999999998, 182.18, 180.11, 140.0, 132.05, 191.0, 64.25000000000003, 186.04999999999998, 139.34000000000006, 156.44, 157.04, 155.03, 191.0, 80.0, 159.05, 189.11, 152.45, 180.2, -13.989999999999995, 158.0, 190.1, 130.25000000000003, 169.13, 180.20000000000002, 156.41000000000003, 161.03000000000003, 193.04000000000002, 191.0, 151.33999999999997, 119.06000000000002, 128.06000000000003, 154.46, 74.0, 165.07999999999998, 185.15, 176.03, 87.05, 160.01, 176.03, 178.01, 155.0, 159.01999999999998, 154.01, 175.01, 154.01, 197.03000000000003, 179.21, 104.0, 180.2, -106.99000000000001, 149.0, 142.19000000000003, 128.0, 121.10000000000004, 127.00999999999999, 187.13, 145.07000000000002, 129.2600000000001, 129.01999999999998, 144.08, 152.0, 132.05, 181.16, 195.02, 148.06999999999994, 163.04000000000002, 128.24000000000004, 195.05, 179.0, 200.0, 152.0, 131.09000000000003, 164.0, 179.06, 173.0, 161.0, 149.0, 200.0, 131.0, 151.01, 158.42000000000002, 116.0, 185.03, 182.18, 147.14000000000004, 155.03000000000003, 189.01999999999998, 89.0, 194.02999999999997, 164.0, 157.07, 140.0, 174.05, 134.03000000000003, 188.0, 173.06, 144.11, 173.03, 166.01, 194.0, 176.0, 160.01, 196.01, 182.0, 194.06, 140.12, 176.0, 175.25, 198.01999999999998, 161.0, 145.1, -44.980000000000004, 139.39999999999998, 175.04, 158.09, 172.28, 200.0, 46.00999999999999, 125.33000000000006, 177.23000000000002, 160.01, 199.01, 45.20000000000001, 137.27000000000004, 150.47, 181.19, 150.23000000000002, 158.0, 162.14, 154.13, 184.15999999999997, 136.28000000000003, 193.07, 164.0, 100.13, 147.05, 122.03, 110.0, 196.04, 188.0, 171.14, -131.92000000000002, 177.2299999999999, 116.0, 161.06, 167.0, 19.069999999999986, 26.0, 194.0, 157.2199999999999, 189.02, 155.0, 173.0, 72.02, 164.0, 152.0, 176.0, 149.0, 131.0, 192.08000000000004, 175.25, 144.20000000000005, 179.0, 161.03], "policy_predator_policy_reward": [50.0, 37.0, 28.0, 20.0, 26.0, 16.0, 45.0, 127.0, 133.0, 47.0, 25.0, 66.0, 34.0, 60.0, 18.0, 13.0, 9.0, 12.0, 13.0, 19.0, 25.0, 20.0, 7.0, 22.0, 3.0, 54.0, 28.0, 22.0, 29.0, 23.0, 64.0, 8.0, 21.0, 22.0, 28.0, 26.0, 7.0, 2.0, 17.0, 39.0, 27.0, 29.0, 160.0, 28.0, 16.0, 17.0, 43.0, 26.0, 67.0, 70.0, 17.0, 13.0, 0.0, 55.0, 39.0, 147.0, 17.0, 15.0, 18.0, 17.0, 32.0, 31.0, 11.0, 10.0, 35.0, 7.0, 31.0, 34.0, 56.0, 50.0, 15.0, 22.0, 55.0, 52.0, 22.0, 45.0, 41.0, 46.0, 102.0, 14.0, 23.0, 1.0, 45.0, 40.0, 193.0, 36.0, 21.0, 14.0, 123.0, 128.0, 43.0, 43.0, 37.0, 34.0, 50.0, 20.0, 47.0, 7.0, 27.0, 58.0, 38.0, 35.0, 20.0, 11.0, 23.0, 17.0, 24.0, 26.0, 31.0, 35.0, 101.0, 86.0, 33.0, 25.0, 54.0, 65.0, 16.0, 57.0, 15.0, 16.0, 23.0, 39.0, 68.0, 36.0, 8.0, 27.0, 49.0, 28.0, 26.0, 44.0, 15.0, 21.0, 23.0, 12.0, 31.0, 30.0, 22.0, 29.0, 63.0, 73.0, 14.0, 35.0, 44.0, 1.0, 32.0, 37.0, 166.0, 26.0, 32.0, 9.0, 63.0, 80.0, 80.0, 93.0, 108.0, 52.0, 61.0, 81.0, 153.0, 8.0, 3.0, 3.0, 93.0, 160.0, 27.0, 42.0, 14.0, 7.0, 68.0, 43.0, 77.0, 67.0, 179.0, 18.0, 24.0, 64.0, 8.0, 197.0, 71.0, 126.0, 20.0, 147.0, 53.0, 184.0, 92.0, 53.0, 147.0, 176.0, 57.0, 61.0, 112.0, 99.0, 74.0, 88.0, 59.0, 57.0, 11.0, 36.0, 39.0, 35.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7048340987922534, "mean_inference_ms": 1.9214244610501754, "mean_action_processing_ms": 0.29096488959987044, "mean_env_wait_ms": 0.24089495676884773, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006252288818359375, "StateBufferConnector_ms": 0.003344893455505371, "ViewRequirementAgentConnector_ms": 0.12657439708709717}, "num_episodes": 18, "episode_return_max": 667.02, "episode_return_min": 244.22, "episode_return_mean": 393.7632, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.5899708071838, "num_env_steps_trained_throughput_per_sec": 316.5899708071838, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 12404.868, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12404.814, "sample_time_ms": 1632.097, "learn_time_ms": 10751.637, "learn_throughput": 372.036, "synch_weights_time_ms": 17.536}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "0e60f_00000", "date": "2024-08-15_01-15-04", "timestamp": 1723664704, "time_this_iter_s": 12.675997972488403, "time_total_s": 1121.8431746959686, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a309f700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1121.8431746959686, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 59.45000000000001, "ram_util_percent": 83.41666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.609369120742909, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5525689634696516, "policy_loss": -0.0006169188093817817, "vf_loss": 3.5526746621207583, "vf_explained_var": 0.1970358034921071, "kl": 0.009574557396578426, "entropy": 0.8137399137650848, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.545075032193825, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.897384313553099, "policy_loss": -0.0036517080678432077, "vf_loss": 5.901003462927682, "vf_explained_var": 0.08767088509741283, "kl": 0.006946564572382839, "entropy": 0.6726024079259741, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 667.02, "episode_reward_min": 244.22, "episode_reward_mean": 400.25079999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -131.92000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 148.7954, "predator_policy": 51.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [328.78, 381.07, 408.0, 378.15999999999997, 387.65, 330.01, 352.35, 384.33, 380.43999999999994, 405.03999999999996, 312.4, 347.52, 345.08, 398.18, 354.06, 421.04, 401.02, 445.02, 375.04, 368.21, 302.21, 326.19000000000005, 500.0999999999999, 400.14, 345.32999999999976, 343.09999999999997, 338.04999999999995, 461.17999999999995, 384.10999999999996, 354.29, 419.0, 333.09, 409.06, 521.0, 407.0, 401.01, 347.41999999999996, 398.21, 364.1699999999999, 382.02, 393.03, 374.07, 378.08, 397.06, 352.13999999999993, 421.01, 387.01, 514.01, 383.18, 396.25, 428.02, 292.12, 355.44, 473.37, 419.01, 462.56, 501.02, 343.46999999999997, 337.66, 561.23, 385.27000000000004, 341.43999999999994, 468.07, 391.1799999999999, 429.03, 472.03999999999996, 244.22, 490.2299999999999, 495.06, 282.07, 496.2199999999999, 667.02, 363.02, 527.0, 487.0, 439.0799999999999, 366.45, 414.03, 320.3399999999999, 321.1, 450.64999999999964, 395.03, 376.05, 412.05, 410.09999999999997, 402.49000000000007, 323.6999999999999, 501.02, 444.13999999999993, 405.1, 470.03, 421.30999999999995, 420.0, 348.5299999999998, 437.2099999999999, 424.5199999999998, 446.12999999999994, 353.4500000000001, 355.50999999999965, 418.3700000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [139.34000000000006, 156.44, 157.04, 155.03, 191.0, 80.0, 159.05, 189.11, 152.45, 180.2, -13.989999999999995, 158.0, 190.1, 130.25000000000003, 169.13, 180.20000000000002, 156.41000000000003, 161.03000000000003, 193.04000000000002, 191.0, 151.33999999999997, 119.06000000000002, 128.06000000000003, 154.46, 74.0, 165.07999999999998, 185.15, 176.03, 87.05, 160.01, 176.03, 178.01, 155.0, 159.01999999999998, 154.01, 175.01, 154.01, 197.03000000000003, 179.21, 104.0, 180.2, -106.99000000000001, 149.0, 142.19000000000003, 128.0, 121.10000000000004, 127.00999999999999, 187.13, 145.07000000000002, 129.2600000000001, 129.01999999999998, 144.08, 152.0, 132.05, 181.16, 195.02, 148.06999999999994, 163.04000000000002, 128.24000000000004, 195.05, 179.0, 200.0, 152.0, 131.09000000000003, 164.0, 179.06, 173.0, 161.0, 149.0, 200.0, 131.0, 151.01, 158.42000000000002, 116.0, 185.03, 182.18, 147.14000000000004, 155.03000000000003, 189.01999999999998, 89.0, 194.02999999999997, 164.0, 157.07, 140.0, 174.05, 134.03000000000003, 188.0, 173.06, 144.11, 173.03, 166.01, 194.0, 176.0, 160.01, 196.01, 182.0, 194.06, 140.12, 176.0, 175.25, 198.01999999999998, 161.0, 145.1, -44.980000000000004, 139.39999999999998, 175.04, 158.09, 172.28, 200.0, 46.00999999999999, 125.33000000000006, 177.23000000000002, 160.01, 199.01, 45.20000000000001, 137.27000000000004, 150.47, 181.19, 150.23000000000002, 158.0, 162.14, 154.13, 184.15999999999997, 136.28000000000003, 193.07, 164.0, 100.13, 147.05, 122.03, 110.0, 196.04, 188.0, 171.14, -131.92000000000002, 177.2299999999999, 116.0, 161.06, 167.0, 19.069999999999986, 26.0, 194.0, 157.2199999999999, 189.02, 155.0, 173.0, 72.02, 164.0, 152.0, 176.0, 149.0, 131.0, 192.08000000000004, 175.25, 144.20000000000005, 179.0, 161.03, 131.24000000000004, 148.10000000000005, 192.07999999999998, 6.019999999999996, 160.3399999999997, 166.31, 170.03, 101.0, 200.0, 48.050000000000026, 152.0, 183.05, 123.05, 174.05, 116.36000000000004, 187.13, 146.0, 67.69999999999999, 156.01999999999998, 179.0, 109.04, 169.10000000000002, 150.08, 129.02, 72.02, 199.01, 154.1599999999999, 143.15000000000003, 200.0, 116.0, 124.19000000000001, 166.34000000000003, 184.15999999999997, 174.05, 120.50000000000014, 180.01999999999998, 153.08, 192.04999999999998, 151.19000000000003, 162.25999999999996, 39.02, 115.48999999999995, 180.05, 138.32], "policy_predator_policy_reward": [16.0, 17.0, 43.0, 26.0, 67.0, 70.0, 17.0, 13.0, 0.0, 55.0, 39.0, 147.0, 17.0, 15.0, 18.0, 17.0, 32.0, 31.0, 11.0, 10.0, 35.0, 7.0, 31.0, 34.0, 56.0, 50.0, 15.0, 22.0, 55.0, 52.0, 22.0, 45.0, 41.0, 46.0, 102.0, 14.0, 23.0, 1.0, 45.0, 40.0, 193.0, 36.0, 21.0, 14.0, 123.0, 128.0, 43.0, 43.0, 37.0, 34.0, 50.0, 20.0, 47.0, 7.0, 27.0, 58.0, 38.0, 35.0, 20.0, 11.0, 23.0, 17.0, 24.0, 26.0, 31.0, 35.0, 101.0, 86.0, 33.0, 25.0, 54.0, 65.0, 16.0, 57.0, 15.0, 16.0, 23.0, 39.0, 68.0, 36.0, 8.0, 27.0, 49.0, 28.0, 26.0, 44.0, 15.0, 21.0, 23.0, 12.0, 31.0, 30.0, 22.0, 29.0, 63.0, 73.0, 14.0, 35.0, 44.0, 1.0, 32.0, 37.0, 166.0, 26.0, 32.0, 9.0, 63.0, 80.0, 80.0, 93.0, 108.0, 52.0, 61.0, 81.0, 153.0, 8.0, 3.0, 3.0, 93.0, 160.0, 27.0, 42.0, 14.0, 7.0, 68.0, 43.0, 77.0, 67.0, 179.0, 18.0, 24.0, 64.0, 8.0, 197.0, 71.0, 126.0, 20.0, 147.0, 53.0, 184.0, 92.0, 53.0, 147.0, 176.0, 57.0, 61.0, 112.0, 99.0, 74.0, 88.0, 59.0, 57.0, 11.0, 36.0, 39.0, 35.0, 24.0, 17.0, 101.0, 22.0, 103.0, 21.0, 79.0, 45.0, 64.0, 64.0, 34.0, 43.0, 53.0, 60.0, 94.0, 5.0, 60.0, 50.0, 34.0, 132.0, 62.0, 104.0, 63.0, 63.0, 101.0, 98.0, 73.0, 51.0, 49.0, 55.0, 25.0, 33.0, 57.0, 22.0, 93.0, 31.0, 47.0, 54.0, 27.0, 13.0, 140.0, 61.0, 70.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7050694844819096, "mean_inference_ms": 1.9245739390800736, "mean_action_processing_ms": 0.29089106555544475, "mean_env_wait_ms": 0.24098075153246362, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01570725440979004, "StateBufferConnector_ms": 0.003682374954223633, "ViewRequirementAgentConnector_ms": 0.1448972225189209}, "num_episodes": 22, "episode_return_max": 667.02, "episode_return_min": 244.22, "episode_return_mean": 400.25079999999997, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.721080628114, "num_env_steps_trained_throughput_per_sec": 324.721080628114, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 12396.921, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12396.868, "sample_time_ms": 1662.608, "learn_time_ms": 10713.619, "learn_throughput": 373.357, "synch_weights_time_ms": 17.439}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "0e60f_00000", "date": "2024-08-15_01-15-17", "timestamp": 1723664717, "time_this_iter_s": 12.35343599319458, "time_total_s": 1134.1966106891632, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2ff6550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1134.1966106891632, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 59.04117647058824, "ram_util_percent": 83.67647058823529}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.520597891832786, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.742313487189157, "policy_loss": -0.004009209988668325, "vf_loss": 2.7459192783744246, "vf_explained_var": 0.17611069802253965, "kl": 0.007555433198082201, "entropy": 0.8200438736607789, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.666301278273265, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.715756609074022, "policy_loss": -0.0011884963993603985, "vf_loss": 6.716911677204112, "vf_explained_var": 0.020361811900265002, "kl": 0.007129026094608172, "entropy": 0.6083340343659517, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 667.02, "episode_reward_min": 244.22, "episode_reward_mean": 419.08229999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -131.92000000000002, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 149.21615, "predator_policy": 60.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [375.04, 368.21, 302.21, 326.19000000000005, 500.0999999999999, 400.14, 345.32999999999976, 343.09999999999997, 338.04999999999995, 461.17999999999995, 384.10999999999996, 354.29, 419.0, 333.09, 409.06, 521.0, 407.0, 401.01, 347.41999999999996, 398.21, 364.1699999999999, 382.02, 393.03, 374.07, 378.08, 397.06, 352.13999999999993, 421.01, 387.01, 514.01, 383.18, 396.25, 428.02, 292.12, 355.44, 473.37, 419.01, 462.56, 501.02, 343.46999999999997, 337.66, 561.23, 385.27000000000004, 341.43999999999994, 468.07, 391.1799999999999, 429.03, 472.03999999999996, 244.22, 490.2299999999999, 495.06, 282.07, 496.2199999999999, 667.02, 363.02, 527.0, 487.0, 439.0799999999999, 366.45, 414.03, 320.3399999999999, 321.1, 450.64999999999964, 395.03, 376.05, 412.05, 410.09999999999997, 402.49000000000007, 323.6999999999999, 501.02, 444.13999999999993, 405.1, 470.03, 421.30999999999995, 420.0, 348.5299999999998, 437.2099999999999, 424.5199999999998, 446.12999999999994, 353.4500000000001, 355.50999999999965, 418.3700000000001, 438.3699999999999, 608.09, 397.4699999999999, 566.0, 404.16, 452.1, 485.26, 633.01, 378.3499999999998, 390.86999999999983, 522.26, 483.43999999999994, 470.24, 554.0799999999999, 391.31999999999977, 494.13, 388.0899999999999, 586.06], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [154.01, 197.03000000000003, 179.21, 104.0, 180.2, -106.99000000000001, 149.0, 142.19000000000003, 128.0, 121.10000000000004, 127.00999999999999, 187.13, 145.07000000000002, 129.2600000000001, 129.01999999999998, 144.08, 152.0, 132.05, 181.16, 195.02, 148.06999999999994, 163.04000000000002, 128.24000000000004, 195.05, 179.0, 200.0, 152.0, 131.09000000000003, 164.0, 179.06, 173.0, 161.0, 149.0, 200.0, 131.0, 151.01, 158.42000000000002, 116.0, 185.03, 182.18, 147.14000000000004, 155.03000000000003, 189.01999999999998, 89.0, 194.02999999999997, 164.0, 157.07, 140.0, 174.05, 134.03000000000003, 188.0, 173.06, 144.11, 173.03, 166.01, 194.0, 176.0, 160.01, 196.01, 182.0, 194.06, 140.12, 176.0, 175.25, 198.01999999999998, 161.0, 145.1, -44.980000000000004, 139.39999999999998, 175.04, 158.09, 172.28, 200.0, 46.00999999999999, 125.33000000000006, 177.23000000000002, 160.01, 199.01, 45.20000000000001, 137.27000000000004, 150.47, 181.19, 150.23000000000002, 158.0, 162.14, 154.13, 184.15999999999997, 136.28000000000003, 193.07, 164.0, 100.13, 147.05, 122.03, 110.0, 196.04, 188.0, 171.14, -131.92000000000002, 177.2299999999999, 116.0, 161.06, 167.0, 19.069999999999986, 26.0, 194.0, 157.2199999999999, 189.02, 155.0, 173.0, 72.02, 164.0, 152.0, 176.0, 149.0, 131.0, 192.08000000000004, 175.25, 144.20000000000005, 179.0, 161.03, 131.24000000000004, 148.10000000000005, 192.07999999999998, 6.019999999999996, 160.3399999999997, 166.31, 170.03, 101.0, 200.0, 48.050000000000026, 152.0, 183.05, 123.05, 174.05, 116.36000000000004, 187.13, 146.0, 67.69999999999999, 156.01999999999998, 179.0, 109.04, 169.10000000000002, 150.08, 129.02, 72.02, 199.01, 154.1599999999999, 143.15000000000003, 200.0, 116.0, 124.19000000000001, 166.34000000000003, 184.15999999999997, 174.05, 120.50000000000014, 180.01999999999998, 153.08, 192.04999999999998, 151.19000000000003, 162.25999999999996, 39.02, 115.48999999999995, 180.05, 138.32, 151.25000000000006, 158.12, 164.0, 185.09, 173.15, 153.32000000000005, 137.0, 134.0, 183.05, 177.11, 130.1, 140.0, 186.14, 170.12, 157.01, 122.0, 138.23000000000008, 161.11999999999995, 148.51999999999998, 147.34999999999994, 198.01999999999998, 143.24, 155.39, 153.05, 157.01, 165.23, 162.07999999999998, 188.0, 136.31000000000012, 136.01, 170.12, 106.00999999999999, 155.0, 143.08999999999997, 110.06, 161.0], "policy_predator_policy_reward": [23.0, 1.0, 45.0, 40.0, 193.0, 36.0, 21.0, 14.0, 123.0, 128.0, 43.0, 43.0, 37.0, 34.0, 50.0, 20.0, 47.0, 7.0, 27.0, 58.0, 38.0, 35.0, 20.0, 11.0, 23.0, 17.0, 24.0, 26.0, 31.0, 35.0, 101.0, 86.0, 33.0, 25.0, 54.0, 65.0, 16.0, 57.0, 15.0, 16.0, 23.0, 39.0, 68.0, 36.0, 8.0, 27.0, 49.0, 28.0, 26.0, 44.0, 15.0, 21.0, 23.0, 12.0, 31.0, 30.0, 22.0, 29.0, 63.0, 73.0, 14.0, 35.0, 44.0, 1.0, 32.0, 37.0, 166.0, 26.0, 32.0, 9.0, 63.0, 80.0, 80.0, 93.0, 108.0, 52.0, 61.0, 81.0, 153.0, 8.0, 3.0, 3.0, 93.0, 160.0, 27.0, 42.0, 14.0, 7.0, 68.0, 43.0, 77.0, 67.0, 179.0, 18.0, 24.0, 64.0, 8.0, 197.0, 71.0, 126.0, 20.0, 147.0, 53.0, 184.0, 92.0, 53.0, 147.0, 176.0, 57.0, 61.0, 112.0, 99.0, 74.0, 88.0, 59.0, 57.0, 11.0, 36.0, 39.0, 35.0, 24.0, 17.0, 101.0, 22.0, 103.0, 21.0, 79.0, 45.0, 64.0, 64.0, 34.0, 43.0, 53.0, 60.0, 94.0, 5.0, 60.0, 50.0, 34.0, 132.0, 62.0, 104.0, 63.0, 63.0, 101.0, 98.0, 73.0, 51.0, 49.0, 55.0, 25.0, 33.0, 57.0, 22.0, 93.0, 31.0, 47.0, 54.0, 27.0, 13.0, 140.0, 61.0, 70.0, 30.0, 42.0, 87.0, 138.0, 121.0, 33.0, 38.0, 145.0, 150.0, 12.0, 32.0, 21.0, 161.0, 61.0, 68.0, 176.0, 178.0, 34.0, 45.0, 43.0, 52.0, 28.0, 153.0, 78.0, 97.0, 47.0, 101.0, 10.0, 194.0, 39.0, 80.0, 91.0, 127.0, 36.0, 54.0, 171.0, 144.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7053124646842537, "mean_inference_ms": 1.9272424014897893, "mean_action_processing_ms": 0.2908473006501443, "mean_env_wait_ms": 0.24110570726491865, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015902400016784668, "StateBufferConnector_ms": 0.0046384334564208984, "ViewRequirementAgentConnector_ms": 0.14065492153167725}, "num_episodes": 18, "episode_return_max": 667.02, "episode_return_min": 244.22, "episode_return_mean": 419.08229999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.43892140701075, "num_env_steps_trained_throughput_per_sec": 316.43892140701075, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 12437.827, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12437.773, "sample_time_ms": 1660.134, "learn_time_ms": 10757.543, "learn_throughput": 371.832, "synch_weights_time_ms": 16.855}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "0e60f_00000", "date": "2024-08-15_01-15-30", "timestamp": 1723664730, "time_this_iter_s": 12.683073997497559, "time_total_s": 1146.8796846866608, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2ff6670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1146.8796846866608, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 57.705555555555556, "ram_util_percent": 83.1611111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7063625242344287, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2281324213459377, "policy_loss": -0.004594289277133251, "vf_loss": 2.23230277880159, "vf_explained_var": 0.3035225147608096, "kl": 0.007939757610534755, "entropy": 0.8307245659134376, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.01017959672938, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.380844726259746, "policy_loss": -0.0036643546615436513, "vf_loss": 6.384471297137952, "vf_explained_var": -0.013499110117160453, "kl": 0.008058500270033991, "entropy": 0.6435353509963505, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 667.02, "episode_reward_min": 244.22, "episode_reward_mean": 424.2824999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -131.92000000000002, "predator_policy": 1.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 147.99124999999998, "predator_policy": 64.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [374.07, 378.08, 397.06, 352.13999999999993, 421.01, 387.01, 514.01, 383.18, 396.25, 428.02, 292.12, 355.44, 473.37, 419.01, 462.56, 501.02, 343.46999999999997, 337.66, 561.23, 385.27000000000004, 341.43999999999994, 468.07, 391.1799999999999, 429.03, 472.03999999999996, 244.22, 490.2299999999999, 495.06, 282.07, 496.2199999999999, 667.02, 363.02, 527.0, 487.0, 439.0799999999999, 366.45, 414.03, 320.3399999999999, 321.1, 450.64999999999964, 395.03, 376.05, 412.05, 410.09999999999997, 402.49000000000007, 323.6999999999999, 501.02, 444.13999999999993, 405.1, 470.03, 421.30999999999995, 420.0, 348.5299999999998, 437.2099999999999, 424.5199999999998, 446.12999999999994, 353.4500000000001, 355.50999999999965, 418.3700000000001, 438.3699999999999, 608.09, 397.4699999999999, 566.0, 404.16, 452.1, 485.26, 633.01, 378.3499999999998, 390.86999999999983, 522.26, 483.43999999999994, 470.24, 554.0799999999999, 391.31999999999977, 494.13, 388.0899999999999, 586.06, 346.46000000000004, 461.02, 339.14, 344.45, 371.0, 443.03, 353.74000000000007, 367.53999999999996, 462.03999999999996, 397.40000000000003, 434.02, 383.11999999999995, 511.4899999999999, 327.01, 412.33000000000004, 398.27, 355.07, 353.12, 445.14, 489.23, 478.15999999999997, 525.0, 395.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [157.07, 140.0, 174.05, 134.03000000000003, 188.0, 173.06, 144.11, 173.03, 166.01, 194.0, 176.0, 160.01, 196.01, 182.0, 194.06, 140.12, 176.0, 175.25, 198.01999999999998, 161.0, 145.1, -44.980000000000004, 139.39999999999998, 175.04, 158.09, 172.28, 200.0, 46.00999999999999, 125.33000000000006, 177.23000000000002, 160.01, 199.01, 45.20000000000001, 137.27000000000004, 150.47, 181.19, 150.23000000000002, 158.0, 162.14, 154.13, 184.15999999999997, 136.28000000000003, 193.07, 164.0, 100.13, 147.05, 122.03, 110.0, 196.04, 188.0, 171.14, -131.92000000000002, 177.2299999999999, 116.0, 161.06, 167.0, 19.069999999999986, 26.0, 194.0, 157.2199999999999, 189.02, 155.0, 173.0, 72.02, 164.0, 152.0, 176.0, 149.0, 131.0, 192.08000000000004, 175.25, 144.20000000000005, 179.0, 161.03, 131.24000000000004, 148.10000000000005, 192.07999999999998, 6.019999999999996, 160.3399999999997, 166.31, 170.03, 101.0, 200.0, 48.050000000000026, 152.0, 183.05, 123.05, 174.05, 116.36000000000004, 187.13, 146.0, 67.69999999999999, 156.01999999999998, 179.0, 109.04, 169.10000000000002, 150.08, 129.02, 72.02, 199.01, 154.1599999999999, 143.15000000000003, 200.0, 116.0, 124.19000000000001, 166.34000000000003, 184.15999999999997, 174.05, 120.50000000000014, 180.01999999999998, 153.08, 192.04999999999998, 151.19000000000003, 162.25999999999996, 39.02, 115.48999999999995, 180.05, 138.32, 151.25000000000006, 158.12, 164.0, 185.09, 173.15, 153.32000000000005, 137.0, 134.0, 183.05, 177.11, 130.1, 140.0, 186.14, 170.12, 157.01, 122.0, 138.23000000000008, 161.11999999999995, 148.51999999999998, 147.34999999999994, 198.01999999999998, 143.24, 155.39, 153.05, 157.01, 165.23, 162.07999999999998, 188.0, 136.31000000000012, 136.01, 170.12, 106.00999999999999, 155.0, 143.08999999999997, 110.06, 161.0, 112.34000000000003, 188.12, 167.0, 111.02, 125.03000000000002, 150.11, 188.12, 116.32999999999993, 101.0, 101.0, 194.0, 155.03, 128.27000000000004, 108.47000000000003, 121.34000000000003, 153.20000000000005, 175.04000000000002, 161.0, 133.34, 152.06, 170.0, 144.02, 89.0, 119.12, 161.38999999999987, 157.1, -1.990000000000009, 173.0, 172.28, 189.05, 138.02, 175.25, 169.01, 146.06, 156.05, 145.07, 139.10000000000002, 178.04, 177.23, 134.0, 113.0, 184.16000000000003, 185.0, 146.0, 172.04, 136.16000000000003], "policy_predator_policy_reward": [49.0, 28.0, 26.0, 44.0, 15.0, 21.0, 23.0, 12.0, 31.0, 30.0, 22.0, 29.0, 63.0, 73.0, 14.0, 35.0, 44.0, 1.0, 32.0, 37.0, 166.0, 26.0, 32.0, 9.0, 63.0, 80.0, 80.0, 93.0, 108.0, 52.0, 61.0, 81.0, 153.0, 8.0, 3.0, 3.0, 93.0, 160.0, 27.0, 42.0, 14.0, 7.0, 68.0, 43.0, 77.0, 67.0, 179.0, 18.0, 24.0, 64.0, 8.0, 197.0, 71.0, 126.0, 20.0, 147.0, 53.0, 184.0, 92.0, 53.0, 147.0, 176.0, 57.0, 61.0, 112.0, 99.0, 74.0, 88.0, 59.0, 57.0, 11.0, 36.0, 39.0, 35.0, 24.0, 17.0, 101.0, 22.0, 103.0, 21.0, 79.0, 45.0, 64.0, 64.0, 34.0, 43.0, 53.0, 60.0, 94.0, 5.0, 60.0, 50.0, 34.0, 132.0, 62.0, 104.0, 63.0, 63.0, 101.0, 98.0, 73.0, 51.0, 49.0, 55.0, 25.0, 33.0, 57.0, 22.0, 93.0, 31.0, 47.0, 54.0, 27.0, 13.0, 140.0, 61.0, 70.0, 30.0, 42.0, 87.0, 138.0, 121.0, 33.0, 38.0, 145.0, 150.0, 12.0, 32.0, 21.0, 161.0, 61.0, 68.0, 176.0, 178.0, 34.0, 45.0, 43.0, 52.0, 28.0, 153.0, 78.0, 97.0, 47.0, 101.0, 10.0, 194.0, 39.0, 80.0, 91.0, 127.0, 36.0, 54.0, 171.0, 144.0, 13.0, 33.0, 151.0, 32.0, 16.0, 48.0, 19.0, 21.0, 99.0, 70.0, 26.0, 68.0, 69.0, 48.0, 64.0, 29.0, 58.0, 68.0, 53.0, 59.0, 18.0, 102.0, 75.0, 100.0, 96.0, 97.0, 69.0, 87.0, 17.0, 34.0, 42.0, 43.0, 28.0, 12.0, 28.0, 24.0, 78.0, 50.0, 13.0, 165.0, 86.0, 95.0, 61.0, 133.0, 40.0, 47.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7061069943896139, "mean_inference_ms": 1.9319905013629852, "mean_action_processing_ms": 0.29101018714149485, "mean_env_wait_ms": 0.24143912292920056, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014735579490661621, "StateBufferConnector_ms": 0.004589676856994629, "ViewRequirementAgentConnector_ms": 0.13877320289611816}, "num_episodes": 23, "episode_return_max": 667.02, "episode_return_min": 244.22, "episode_return_mean": 424.2824999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 314.30781101338226, "num_env_steps_trained_throughput_per_sec": 314.30781101338226, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 12473.864, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12473.811, "sample_time_ms": 1712.766, "learn_time_ms": 10741.168, "learn_throughput": 372.399, "synch_weights_time_ms": 17.038}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "0e60f_00000", "date": "2024-08-15_01-15-42", "timestamp": 1723664742, "time_this_iter_s": 12.773498058319092, "time_total_s": 1159.6531827449799, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a30a58b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1159.6531827449799, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 59.12777777777777, "ram_util_percent": 82.48333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.997960900408881, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2872307999424204, "policy_loss": -0.009343708509569445, "vf_loss": 3.2961647611446483, "vf_explained_var": 0.2966093390076249, "kl": 0.007674132290566247, "entropy": 0.8568773471804523, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.443065169753221, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.8514569396064395, "policy_loss": -0.006784361415350484, "vf_loss": 6.858184828581633, "vf_explained_var": 0.11321526399995915, "kl": 0.012049679425750916, "entropy": 0.6073096618450508, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 667.02, "episode_reward_min": 244.22, "episode_reward_mean": 424.62899999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -131.92000000000002, "predator_policy": 2.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 147.9545, "predator_policy": 64.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [561.23, 385.27000000000004, 341.43999999999994, 468.07, 391.1799999999999, 429.03, 472.03999999999996, 244.22, 490.2299999999999, 495.06, 282.07, 496.2199999999999, 667.02, 363.02, 527.0, 487.0, 439.0799999999999, 366.45, 414.03, 320.3399999999999, 321.1, 450.64999999999964, 395.03, 376.05, 412.05, 410.09999999999997, 402.49000000000007, 323.6999999999999, 501.02, 444.13999999999993, 405.1, 470.03, 421.30999999999995, 420.0, 348.5299999999998, 437.2099999999999, 424.5199999999998, 446.12999999999994, 353.4500000000001, 355.50999999999965, 418.3700000000001, 438.3699999999999, 608.09, 397.4699999999999, 566.0, 404.16, 452.1, 485.26, 633.01, 378.3499999999998, 390.86999999999983, 522.26, 483.43999999999994, 470.24, 554.0799999999999, 391.31999999999977, 494.13, 388.0899999999999, 586.06, 346.46000000000004, 461.02, 339.14, 344.45, 371.0, 443.03, 353.74000000000007, 367.53999999999996, 462.03999999999996, 397.40000000000003, 434.02, 383.11999999999995, 511.4899999999999, 327.01, 412.33000000000004, 398.27, 355.07, 353.12, 445.14, 489.23, 478.15999999999997, 525.0, 395.2, 390.59, 470.4699999999998, 369.5499999999997, 314.6399999999999, 456.61, 394.36999999999995, 430.12, 439.37, 372.28999999999996, 345.67999999999995, 364.33000000000004, 433.08, 377.3599999999999, 407.87000000000006, 426.5800000000001, 392.38999999999965, 502.11999999999995, 362.71], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [150.23000000000002, 158.0, 162.14, 154.13, 184.15999999999997, 136.28000000000003, 193.07, 164.0, 100.13, 147.05, 122.03, 110.0, 196.04, 188.0, 171.14, -131.92000000000002, 177.2299999999999, 116.0, 161.06, 167.0, 19.069999999999986, 26.0, 194.0, 157.2199999999999, 189.02, 155.0, 173.0, 72.02, 164.0, 152.0, 176.0, 149.0, 131.0, 192.08000000000004, 175.25, 144.20000000000005, 179.0, 161.03, 131.24000000000004, 148.10000000000005, 192.07999999999998, 6.019999999999996, 160.3399999999997, 166.31, 170.03, 101.0, 200.0, 48.050000000000026, 152.0, 183.05, 123.05, 174.05, 116.36000000000004, 187.13, 146.0, 67.69999999999999, 156.01999999999998, 179.0, 109.04, 169.10000000000002, 150.08, 129.02, 72.02, 199.01, 154.1599999999999, 143.15000000000003, 200.0, 116.0, 124.19000000000001, 166.34000000000003, 184.15999999999997, 174.05, 120.50000000000014, 180.01999999999998, 153.08, 192.04999999999998, 151.19000000000003, 162.25999999999996, 39.02, 115.48999999999995, 180.05, 138.32, 151.25000000000006, 158.12, 164.0, 185.09, 173.15, 153.32000000000005, 137.0, 134.0, 183.05, 177.11, 130.1, 140.0, 186.14, 170.12, 157.01, 122.0, 138.23000000000008, 161.11999999999995, 148.51999999999998, 147.34999999999994, 198.01999999999998, 143.24, 155.39, 153.05, 157.01, 165.23, 162.07999999999998, 188.0, 136.31000000000012, 136.01, 170.12, 106.00999999999999, 155.0, 143.08999999999997, 110.06, 161.0, 112.34000000000003, 188.12, 167.0, 111.02, 125.03000000000002, 150.11, 188.12, 116.32999999999993, 101.0, 101.0, 194.0, 155.03, 128.27000000000004, 108.47000000000003, 121.34000000000003, 153.20000000000005, 175.04000000000002, 161.0, 133.34, 152.06, 170.0, 144.02, 89.0, 119.12, 161.38999999999987, 157.1, -1.990000000000009, 173.0, 172.28, 189.05, 138.02, 175.25, 169.01, 146.06, 156.05, 145.07, 139.10000000000002, 178.04, 177.23, 134.0, 113.0, 184.16000000000003, 185.0, 146.0, 172.04, 136.16000000000003, 175.12999999999997, 154.45999999999998, 156.11, 161.3599999999998, 147.52999999999994, 153.01999999999998, 131.33000000000004, 130.3100000000001, 137.51, 190.1, 158.12, 160.25, 192.07999999999998, 148.04000000000002, 177.04999999999998, 168.32, 162.29000000000002, 170.0, 158.18000000000004, 126.49999999999999, 199.01, 156.32, 36.079999999999984, 167.0, 151.13, 174.23000000000005, 148.22000000000003, 126.65000000000002, 184.16, 155.42, 141.26000000000005, 187.1299999999999, 130.04, 189.07999999999998, 86.6300000000001, 171.07999999999993], "policy_predator_policy_reward": [93.0, 160.0, 27.0, 42.0, 14.0, 7.0, 68.0, 43.0, 77.0, 67.0, 179.0, 18.0, 24.0, 64.0, 8.0, 197.0, 71.0, 126.0, 20.0, 147.0, 53.0, 184.0, 92.0, 53.0, 147.0, 176.0, 57.0, 61.0, 112.0, 99.0, 74.0, 88.0, 59.0, 57.0, 11.0, 36.0, 39.0, 35.0, 24.0, 17.0, 101.0, 22.0, 103.0, 21.0, 79.0, 45.0, 64.0, 64.0, 34.0, 43.0, 53.0, 60.0, 94.0, 5.0, 60.0, 50.0, 34.0, 132.0, 62.0, 104.0, 63.0, 63.0, 101.0, 98.0, 73.0, 51.0, 49.0, 55.0, 25.0, 33.0, 57.0, 22.0, 93.0, 31.0, 47.0, 54.0, 27.0, 13.0, 140.0, 61.0, 70.0, 30.0, 42.0, 87.0, 138.0, 121.0, 33.0, 38.0, 145.0, 150.0, 12.0, 32.0, 21.0, 161.0, 61.0, 68.0, 176.0, 178.0, 34.0, 45.0, 43.0, 52.0, 28.0, 153.0, 78.0, 97.0, 47.0, 101.0, 10.0, 194.0, 39.0, 80.0, 91.0, 127.0, 36.0, 54.0, 171.0, 144.0, 13.0, 33.0, 151.0, 32.0, 16.0, 48.0, 19.0, 21.0, 99.0, 70.0, 26.0, 68.0, 69.0, 48.0, 64.0, 29.0, 58.0, 68.0, 53.0, 59.0, 18.0, 102.0, 75.0, 100.0, 96.0, 97.0, 69.0, 87.0, 17.0, 34.0, 42.0, 43.0, 28.0, 12.0, 28.0, 24.0, 78.0, 50.0, 13.0, 165.0, 86.0, 95.0, 61.0, 133.0, 40.0, 47.0, 41.0, 20.0, 89.0, 64.0, 40.0, 29.0, 15.0, 38.0, 41.0, 88.0, 39.0, 37.0, 52.0, 38.0, 36.0, 58.0, 34.0, 6.0, 47.0, 14.0, 7.0, 2.0, 67.0, 163.0, 23.0, 29.0, 45.0, 88.0, 44.0, 43.0, 38.0, 26.0, 81.0, 102.0, 39.0, 66.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7072864088406766, "mean_inference_ms": 1.9370547481208582, "mean_action_processing_ms": 0.29139406088045533, "mean_env_wait_ms": 0.24180531679385658, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01507270336151123, "StateBufferConnector_ms": 0.0047751665115356445, "ViewRequirementAgentConnector_ms": 0.12543010711669922}, "num_episodes": 18, "episode_return_max": 667.02, "episode_return_min": 244.22, "episode_return_mean": 424.62899999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.1730665023048, "num_env_steps_trained_throughput_per_sec": 316.1730665023048, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 12523.242, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12523.189, "sample_time_ms": 1795.211, "learn_time_ms": 10707.721, "learn_throughput": 373.562, "synch_weights_time_ms": 17.736}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "0e60f_00000", "date": "2024-08-15_01-15-55", "timestamp": 1723664755, "time_this_iter_s": 12.684391975402832, "time_total_s": 1172.3375747203827, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a3058940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1172.3375747203827, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 57.10555555555556, "ram_util_percent": 82.59444444444443}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.858995547843358, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9170840189570473, "policy_loss": -0.007529563843839304, "vf_loss": 1.9240686629815076, "vf_explained_var": 0.17999245795623336, "kl": 0.01020573299988677, "entropy": 0.8796180017095394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.345634461206103, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.809144423247645, "policy_loss": -0.0032851768169729484, "vf_loss": 7.812397071545717, "vf_explained_var": 0.10817882399710398, "kl": 0.006940510374840793, "entropy": 0.38733997939440307, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 633.01, "episode_reward_min": 314.6399999999999, "episode_reward_mean": 435.6930999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -7.929999999999964, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": 150.78155, "predator_policy": 67.065}, "custom_metrics": {}, "hist_stats": {"episode_reward": [395.03, 376.05, 412.05, 410.09999999999997, 402.49000000000007, 323.6999999999999, 501.02, 444.13999999999993, 405.1, 470.03, 421.30999999999995, 420.0, 348.5299999999998, 437.2099999999999, 424.5199999999998, 446.12999999999994, 353.4500000000001, 355.50999999999965, 418.3700000000001, 438.3699999999999, 608.09, 397.4699999999999, 566.0, 404.16, 452.1, 485.26, 633.01, 378.3499999999998, 390.86999999999983, 522.26, 483.43999999999994, 470.24, 554.0799999999999, 391.31999999999977, 494.13, 388.0899999999999, 586.06, 346.46000000000004, 461.02, 339.14, 344.45, 371.0, 443.03, 353.74000000000007, 367.53999999999996, 462.03999999999996, 397.40000000000003, 434.02, 383.11999999999995, 511.4899999999999, 327.01, 412.33000000000004, 398.27, 355.07, 353.12, 445.14, 489.23, 478.15999999999997, 525.0, 395.2, 390.59, 470.4699999999998, 369.5499999999997, 314.6399999999999, 456.61, 394.36999999999995, 430.12, 439.37, 372.28999999999996, 345.67999999999995, 364.33000000000004, 433.08, 377.3599999999999, 407.87000000000006, 426.5800000000001, 392.38999999999965, 502.11999999999995, 362.71, 600.28, 501.12999999999994, 561.01, 450.09, 464.1099999999999, 441.23, 385.31999999999994, 551.0, 555.2, 483.9, 375.36, 496.03, 476.25, 612.03, 397.32, 508.27, 380.0999999999999, 493.17999999999995, 412.25, 390.45, 547.3199999999999, 436.3299999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.03, 101.0, 200.0, 48.050000000000026, 152.0, 183.05, 123.05, 174.05, 116.36000000000004, 187.13, 146.0, 67.69999999999999, 156.01999999999998, 179.0, 109.04, 169.10000000000002, 150.08, 129.02, 72.02, 199.01, 154.1599999999999, 143.15000000000003, 200.0, 116.0, 124.19000000000001, 166.34000000000003, 184.15999999999997, 174.05, 120.50000000000014, 180.01999999999998, 153.08, 192.04999999999998, 151.19000000000003, 162.25999999999996, 39.02, 115.48999999999995, 180.05, 138.32, 151.25000000000006, 158.12, 164.0, 185.09, 173.15, 153.32000000000005, 137.0, 134.0, 183.05, 177.11, 130.1, 140.0, 186.14, 170.12, 157.01, 122.0, 138.23000000000008, 161.11999999999995, 148.51999999999998, 147.34999999999994, 198.01999999999998, 143.24, 155.39, 153.05, 157.01, 165.23, 162.07999999999998, 188.0, 136.31000000000012, 136.01, 170.12, 106.00999999999999, 155.0, 143.08999999999997, 110.06, 161.0, 112.34000000000003, 188.12, 167.0, 111.02, 125.03000000000002, 150.11, 188.12, 116.32999999999993, 101.0, 101.0, 194.0, 155.03, 128.27000000000004, 108.47000000000003, 121.34000000000003, 153.20000000000005, 175.04000000000002, 161.0, 133.34, 152.06, 170.0, 144.02, 89.0, 119.12, 161.38999999999987, 157.1, -1.990000000000009, 173.0, 172.28, 189.05, 138.02, 175.25, 169.01, 146.06, 156.05, 145.07, 139.10000000000002, 178.04, 177.23, 134.0, 113.0, 184.16000000000003, 185.0, 146.0, 172.04, 136.16000000000003, 175.12999999999997, 154.45999999999998, 156.11, 161.3599999999998, 147.52999999999994, 153.01999999999998, 131.33000000000004, 130.3100000000001, 137.51, 190.1, 158.12, 160.25, 192.07999999999998, 148.04000000000002, 177.04999999999998, 168.32, 162.29000000000002, 170.0, 158.18000000000004, 126.49999999999999, 199.01, 156.32, 36.079999999999984, 167.0, 151.13, 174.23000000000005, 148.22000000000003, 126.65000000000002, 184.16, 155.42, 141.26000000000005, 187.1299999999999, 130.04, 189.07999999999998, 86.6300000000001, 171.07999999999993, 198.01999999999998, 162.25999999999993, 188.03, 145.1, 158.0, 193.01, 158.06, 128.03000000000003, 192.08000000000004, 164.02999999999997, 167.15, 192.07999999999998, 154.25, 142.07, 191.0, 158.0, 142.01, 181.19, 157.43, 147.47000000000003, 160.25, 189.11, 168.02, 154.01, 173.11999999999998, 100.13000000000002, 138.02, 196.01, 174.08, 140.24000000000004, 160.07, 147.20000000000002, 141.05, 150.05, 170.0, 89.18, 179.09, 145.16000000000003, 66.11, 166.34, 158.12, 159.20000000000002, -7.929999999999964, 168.26], "policy_predator_policy_reward": [79.0, 45.0, 64.0, 64.0, 34.0, 43.0, 53.0, 60.0, 94.0, 5.0, 60.0, 50.0, 34.0, 132.0, 62.0, 104.0, 63.0, 63.0, 101.0, 98.0, 73.0, 51.0, 49.0, 55.0, 25.0, 33.0, 57.0, 22.0, 93.0, 31.0, 47.0, 54.0, 27.0, 13.0, 140.0, 61.0, 70.0, 30.0, 42.0, 87.0, 138.0, 121.0, 33.0, 38.0, 145.0, 150.0, 12.0, 32.0, 21.0, 161.0, 61.0, 68.0, 176.0, 178.0, 34.0, 45.0, 43.0, 52.0, 28.0, 153.0, 78.0, 97.0, 47.0, 101.0, 10.0, 194.0, 39.0, 80.0, 91.0, 127.0, 36.0, 54.0, 171.0, 144.0, 13.0, 33.0, 151.0, 32.0, 16.0, 48.0, 19.0, 21.0, 99.0, 70.0, 26.0, 68.0, 69.0, 48.0, 64.0, 29.0, 58.0, 68.0, 53.0, 59.0, 18.0, 102.0, 75.0, 100.0, 96.0, 97.0, 69.0, 87.0, 17.0, 34.0, 42.0, 43.0, 28.0, 12.0, 28.0, 24.0, 78.0, 50.0, 13.0, 165.0, 86.0, 95.0, 61.0, 133.0, 40.0, 47.0, 41.0, 20.0, 89.0, 64.0, 40.0, 29.0, 15.0, 38.0, 41.0, 88.0, 39.0, 37.0, 52.0, 38.0, 36.0, 58.0, 34.0, 6.0, 47.0, 14.0, 7.0, 2.0, 67.0, 163.0, 23.0, 29.0, 45.0, 88.0, 44.0, 43.0, 38.0, 26.0, 81.0, 102.0, 39.0, 66.0, 103.0, 137.0, 64.0, 104.0, 104.0, 106.0, 42.0, 122.0, 83.0, 25.0, 17.0, 65.0, 42.0, 47.0, 128.0, 74.0, 119.0, 113.0, 102.0, 77.0, 15.0, 11.0, 87.0, 87.0, 98.0, 105.0, 156.0, 122.0, 29.0, 54.0, 117.0, 84.0, 38.0, 51.0, 119.0, 115.0, 28.0, 60.0, 0.0, 158.0, 122.0, 108.0, 139.0, 137.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7094459386943066, "mean_inference_ms": 1.94507480214759, "mean_action_processing_ms": 0.2916329163112336, "mean_env_wait_ms": 0.24245666934960539, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014391899108886719, "StateBufferConnector_ms": 0.004757285118103027, "ViewRequirementAgentConnector_ms": 0.1253107786178589}, "num_episodes": 22, "episode_return_max": 633.01, "episode_return_min": 314.6399999999999, "episode_return_mean": 435.6930999999999, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.82853473282154, "num_env_steps_trained_throughput_per_sec": 294.82853473282154, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 12580.401, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12580.349, "sample_time_ms": 1847.006, "learn_time_ms": 10713.106, "learn_throughput": 373.374, "synch_weights_time_ms": 17.66}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "0e60f_00000", "date": "2024-08-15_01-16-09", "timestamp": 1723664769, "time_this_iter_s": 13.606687068939209, "time_total_s": 1185.944261789322, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a303b790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1185.944261789322, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 63.300000000000004, "ram_util_percent": 83.09473684210528}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.8738009170249654, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2122138521027943, "policy_loss": -0.005808125603106366, "vf_loss": 2.2176437278273244, "vf_explained_var": 0.16884606240918396, "kl": 0.00708405671552942, "entropy": 0.8860781607804475, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.420661033650554, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.305494820630109, "policy_loss": -0.001410171839226254, "vf_loss": 7.306884240599536, "vf_explained_var": 0.07778473698272907, "kl": 0.004428078612719945, "entropy": 0.3089478547610934, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 663.12, "episode_reward_min": 314.6399999999999, "episode_reward_mean": 447.0365999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -22.869999999999962, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": 152.43829999999997, "predator_policy": 71.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [418.3700000000001, 438.3699999999999, 608.09, 397.4699999999999, 566.0, 404.16, 452.1, 485.26, 633.01, 378.3499999999998, 390.86999999999983, 522.26, 483.43999999999994, 470.24, 554.0799999999999, 391.31999999999977, 494.13, 388.0899999999999, 586.06, 346.46000000000004, 461.02, 339.14, 344.45, 371.0, 443.03, 353.74000000000007, 367.53999999999996, 462.03999999999996, 397.40000000000003, 434.02, 383.11999999999995, 511.4899999999999, 327.01, 412.33000000000004, 398.27, 355.07, 353.12, 445.14, 489.23, 478.15999999999997, 525.0, 395.2, 390.59, 470.4699999999998, 369.5499999999997, 314.6399999999999, 456.61, 394.36999999999995, 430.12, 439.37, 372.28999999999996, 345.67999999999995, 364.33000000000004, 433.08, 377.3599999999999, 407.87000000000006, 426.5800000000001, 392.38999999999965, 502.11999999999995, 362.71, 600.28, 501.12999999999994, 561.01, 450.09, 464.1099999999999, 441.23, 385.31999999999994, 551.0, 555.2, 483.9, 375.36, 496.03, 476.25, 612.03, 397.32, 508.27, 380.0999999999999, 493.17999999999995, 412.25, 390.45, 547.3199999999999, 436.3299999999999, 453.05999999999995, 364.02, 383.3, 381.1999999999998, 501.11, 466.15999999999997, 496.01, 528.14, 638.1700000000001, 348.21, 562.3399999999999, 459.15, 663.12, 439.16999999999996, 476.27, 352.40000000000003, 421.6299999999999, 547.26], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [180.05, 138.32, 151.25000000000006, 158.12, 164.0, 185.09, 173.15, 153.32000000000005, 137.0, 134.0, 183.05, 177.11, 130.1, 140.0, 186.14, 170.12, 157.01, 122.0, 138.23000000000008, 161.11999999999995, 148.51999999999998, 147.34999999999994, 198.01999999999998, 143.24, 155.39, 153.05, 157.01, 165.23, 162.07999999999998, 188.0, 136.31000000000012, 136.01, 170.12, 106.00999999999999, 155.0, 143.08999999999997, 110.06, 161.0, 112.34000000000003, 188.12, 167.0, 111.02, 125.03000000000002, 150.11, 188.12, 116.32999999999993, 101.0, 101.0, 194.0, 155.03, 128.27000000000004, 108.47000000000003, 121.34000000000003, 153.20000000000005, 175.04000000000002, 161.0, 133.34, 152.06, 170.0, 144.02, 89.0, 119.12, 161.38999999999987, 157.1, -1.990000000000009, 173.0, 172.28, 189.05, 138.02, 175.25, 169.01, 146.06, 156.05, 145.07, 139.10000000000002, 178.04, 177.23, 134.0, 113.0, 184.16000000000003, 185.0, 146.0, 172.04, 136.16000000000003, 175.12999999999997, 154.45999999999998, 156.11, 161.3599999999998, 147.52999999999994, 153.01999999999998, 131.33000000000004, 130.3100000000001, 137.51, 190.1, 158.12, 160.25, 192.07999999999998, 148.04000000000002, 177.04999999999998, 168.32, 162.29000000000002, 170.0, 158.18000000000004, 126.49999999999999, 199.01, 156.32, 36.079999999999984, 167.0, 151.13, 174.23000000000005, 148.22000000000003, 126.65000000000002, 184.16, 155.42, 141.26000000000005, 187.1299999999999, 130.04, 189.07999999999998, 86.6300000000001, 171.07999999999993, 198.01999999999998, 162.25999999999993, 188.03, 145.1, 158.0, 193.01, 158.06, 128.03000000000003, 192.08000000000004, 164.02999999999997, 167.15, 192.07999999999998, 154.25, 142.07, 191.0, 158.0, 142.01, 181.19, 157.43, 147.47000000000003, 160.25, 189.11, 168.02, 154.01, 173.11999999999998, 100.13000000000002, 138.02, 196.01, 174.08, 140.24000000000004, 160.07, 147.20000000000002, 141.05, 150.05, 170.0, 89.18, 179.09, 145.16000000000003, 66.11, 166.34, 158.12, 159.20000000000002, -7.929999999999964, 168.26, 148.03999999999996, 99.01999999999998, 124.00999999999999, 70.00999999999999, 199.01, 171.29, 169.04000000000002, 160.15999999999997, 198.02, 167.09, 170.0, 184.16, 166.01, 200.0, 175.13, 139.01, 183.11, 167.06, 192.07999999999998, -22.869999999999962, 193.07, 128.27000000000004, 75.02, 148.13, 152.0, 188.12, 163.07, 124.09999999999998, 170.26999999999998, 161.0, 189.10999999999999, 132.29000000000002, 144.55999999999986, 178.07, 165.05, 167.21], "policy_predator_policy_reward": [70.0, 30.0, 42.0, 87.0, 138.0, 121.0, 33.0, 38.0, 145.0, 150.0, 12.0, 32.0, 21.0, 161.0, 61.0, 68.0, 176.0, 178.0, 34.0, 45.0, 43.0, 52.0, 28.0, 153.0, 78.0, 97.0, 47.0, 101.0, 10.0, 194.0, 39.0, 80.0, 91.0, 127.0, 36.0, 54.0, 171.0, 144.0, 13.0, 33.0, 151.0, 32.0, 16.0, 48.0, 19.0, 21.0, 99.0, 70.0, 26.0, 68.0, 69.0, 48.0, 64.0, 29.0, 58.0, 68.0, 53.0, 59.0, 18.0, 102.0, 75.0, 100.0, 96.0, 97.0, 69.0, 87.0, 17.0, 34.0, 42.0, 43.0, 28.0, 12.0, 28.0, 24.0, 78.0, 50.0, 13.0, 165.0, 86.0, 95.0, 61.0, 133.0, 40.0, 47.0, 41.0, 20.0, 89.0, 64.0, 40.0, 29.0, 15.0, 38.0, 41.0, 88.0, 39.0, 37.0, 52.0, 38.0, 36.0, 58.0, 34.0, 6.0, 47.0, 14.0, 7.0, 2.0, 67.0, 163.0, 23.0, 29.0, 45.0, 88.0, 44.0, 43.0, 38.0, 26.0, 81.0, 102.0, 39.0, 66.0, 103.0, 137.0, 64.0, 104.0, 104.0, 106.0, 42.0, 122.0, 83.0, 25.0, 17.0, 65.0, 42.0, 47.0, 128.0, 74.0, 119.0, 113.0, 102.0, 77.0, 15.0, 11.0, 87.0, 87.0, 98.0, 105.0, 156.0, 122.0, 29.0, 54.0, 117.0, 84.0, 38.0, 51.0, 119.0, 115.0, 28.0, 60.0, 0.0, 158.0, 122.0, 108.0, 139.0, 137.0, 102.0, 104.0, 84.0, 86.0, 9.0, 4.0, 28.0, 24.0, 68.0, 68.0, 39.0, 73.0, 26.0, 104.0, 103.0, 111.0, 145.0, 143.0, 70.0, 109.0, 115.0, 126.0, 130.0, 106.0, 155.0, 168.0, 83.0, 69.0, 36.0, 109.0, 17.0, 14.0, 35.0, 64.0, 88.0, 127.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7115643891723953, "mean_inference_ms": 1.9517189548900413, "mean_action_processing_ms": 0.292745441215595, "mean_env_wait_ms": 0.24299622185049352, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005070328712463379, "StateBufferConnector_ms": 0.004354357719421387, "ViewRequirementAgentConnector_ms": 0.11175405979156494}, "num_episodes": 18, "episode_return_max": 663.12, "episode_return_min": 314.6399999999999, "episode_return_mean": 447.0365999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 310.20785174648177, "num_env_steps_trained_throughput_per_sec": 310.20785174648177, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 12649.745, "restore_workers_time_ms": 0.015, "training_step_time_ms": 12649.691, "sample_time_ms": 1915.905, "learn_time_ms": 10712.963, "learn_throughput": 373.379, "synch_weights_time_ms": 17.637}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "0e60f_00000", "date": "2024-08-15_01-16-22", "timestamp": 1723664782, "time_this_iter_s": 12.940798997879028, "time_total_s": 1198.885060787201, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a2ff60d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1198.885060787201, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 58.27894736842105, "ram_util_percent": 83.52105263157894}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.651218984082893, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.061685889202451, "policy_loss": -0.0046484037400987095, "vf_loss": 2.06589804383182, "vf_explained_var": 0.3793579677109996, "kl": 0.008170468816531025, "entropy": 0.7913953882991952, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.879286008537131, "cur_kl_coeff": 0.0023437499999999995, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.113567506699335, "policy_loss": -0.007733718200621229, "vf_loss": 8.121250878944599, "vf_explained_var": 0.1597073761243669, "kl": 0.021487315249619637, "entropy": 0.41766463809858556, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 663.12, "episode_reward_min": 314.6399999999999, "episode_reward_mean": 454.8228, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -22.869999999999962, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 168.0}, "policy_reward_mean": {"prey_policy": 153.5564, "predator_policy": 73.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [371.0, 443.03, 353.74000000000007, 367.53999999999996, 462.03999999999996, 397.40000000000003, 434.02, 383.11999999999995, 511.4899999999999, 327.01, 412.33000000000004, 398.27, 355.07, 353.12, 445.14, 489.23, 478.15999999999997, 525.0, 395.2, 390.59, 470.4699999999998, 369.5499999999997, 314.6399999999999, 456.61, 394.36999999999995, 430.12, 439.37, 372.28999999999996, 345.67999999999995, 364.33000000000004, 433.08, 377.3599999999999, 407.87000000000006, 426.5800000000001, 392.38999999999965, 502.11999999999995, 362.71, 600.28, 501.12999999999994, 561.01, 450.09, 464.1099999999999, 441.23, 385.31999999999994, 551.0, 555.2, 483.9, 375.36, 496.03, 476.25, 612.03, 397.32, 508.27, 380.0999999999999, 493.17999999999995, 412.25, 390.45, 547.3199999999999, 436.3299999999999, 453.05999999999995, 364.02, 383.3, 381.1999999999998, 501.11, 466.15999999999997, 496.01, 528.14, 638.1700000000001, 348.21, 562.3399999999999, 459.15, 663.12, 439.16999999999996, 476.27, 352.40000000000003, 421.6299999999999, 547.26, 560.3299999999999, 579.01, 487.01, 529.17, 487.16999999999996, 413.08, 384.15000000000003, 346.59, 521.7, 481.0, 414.5099999999998, 530.1800000000001, 537.04, 359.22, 581.23, 367.00999999999976, 572.3, 486.53, 630.1, 400.51, 563.11, 511.34000000000003, 589.0699999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [101.0, 101.0, 194.0, 155.03, 128.27000000000004, 108.47000000000003, 121.34000000000003, 153.20000000000005, 175.04000000000002, 161.0, 133.34, 152.06, 170.0, 144.02, 89.0, 119.12, 161.38999999999987, 157.1, -1.990000000000009, 173.0, 172.28, 189.05, 138.02, 175.25, 169.01, 146.06, 156.05, 145.07, 139.10000000000002, 178.04, 177.23, 134.0, 113.0, 184.16000000000003, 185.0, 146.0, 172.04, 136.16000000000003, 175.12999999999997, 154.45999999999998, 156.11, 161.3599999999998, 147.52999999999994, 153.01999999999998, 131.33000000000004, 130.3100000000001, 137.51, 190.1, 158.12, 160.25, 192.07999999999998, 148.04000000000002, 177.04999999999998, 168.32, 162.29000000000002, 170.0, 158.18000000000004, 126.49999999999999, 199.01, 156.32, 36.079999999999984, 167.0, 151.13, 174.23000000000005, 148.22000000000003, 126.65000000000002, 184.16, 155.42, 141.26000000000005, 187.1299999999999, 130.04, 189.07999999999998, 86.6300000000001, 171.07999999999993, 198.01999999999998, 162.25999999999993, 188.03, 145.1, 158.0, 193.01, 158.06, 128.03000000000003, 192.08000000000004, 164.02999999999997, 167.15, 192.07999999999998, 154.25, 142.07, 191.0, 158.0, 142.01, 181.19, 157.43, 147.47000000000003, 160.25, 189.11, 168.02, 154.01, 173.11999999999998, 100.13000000000002, 138.02, 196.01, 174.08, 140.24000000000004, 160.07, 147.20000000000002, 141.05, 150.05, 170.0, 89.18, 179.09, 145.16000000000003, 66.11, 166.34, 158.12, 159.20000000000002, -7.929999999999964, 168.26, 148.03999999999996, 99.01999999999998, 124.00999999999999, 70.00999999999999, 199.01, 171.29, 169.04000000000002, 160.15999999999997, 198.02, 167.09, 170.0, 184.16, 166.01, 200.0, 175.13, 139.01, 183.11, 167.06, 192.07999999999998, -22.869999999999962, 193.07, 128.27000000000004, 75.02, 148.13, 152.0, 188.12, 163.07, 124.09999999999998, 170.26999999999998, 161.0, 189.10999999999999, 132.29000000000002, 144.55999999999986, 178.07, 165.05, 167.21, 158.0, 167.33, 199.01, 158.0, 158.0, 154.01, 157.03999999999996, 172.13, 199.01, 172.15999999999997, 151.07, 151.01, 143.15, 140.0, 130.34000000000006, 175.25, 155.36, 151.34, 173.0, 164.0, 138.04999999999998, 124.46000000000006, 185.03, 185.15, 200.0, 109.03999999999999, 113.20999999999995, 163.01, 157.04000000000002, 154.19000000000003, 144.56, 122.45000000000017, 170.3, 176.0, 147.53, 131.0, 167.0, 190.1, 154.16000000000003, 132.35000000000005, 155.0, 165.11, 182.18, 157.16000000000003, 167.03, 136.04000000000002], "policy_predator_policy_reward": [99.0, 70.0, 26.0, 68.0, 69.0, 48.0, 64.0, 29.0, 58.0, 68.0, 53.0, 59.0, 18.0, 102.0, 75.0, 100.0, 96.0, 97.0, 69.0, 87.0, 17.0, 34.0, 42.0, 43.0, 28.0, 12.0, 28.0, 24.0, 78.0, 50.0, 13.0, 165.0, 86.0, 95.0, 61.0, 133.0, 40.0, 47.0, 41.0, 20.0, 89.0, 64.0, 40.0, 29.0, 15.0, 38.0, 41.0, 88.0, 39.0, 37.0, 52.0, 38.0, 36.0, 58.0, 34.0, 6.0, 47.0, 14.0, 7.0, 2.0, 67.0, 163.0, 23.0, 29.0, 45.0, 88.0, 44.0, 43.0, 38.0, 26.0, 81.0, 102.0, 39.0, 66.0, 103.0, 137.0, 64.0, 104.0, 104.0, 106.0, 42.0, 122.0, 83.0, 25.0, 17.0, 65.0, 42.0, 47.0, 128.0, 74.0, 119.0, 113.0, 102.0, 77.0, 15.0, 11.0, 87.0, 87.0, 98.0, 105.0, 156.0, 122.0, 29.0, 54.0, 117.0, 84.0, 38.0, 51.0, 119.0, 115.0, 28.0, 60.0, 0.0, 158.0, 122.0, 108.0, 139.0, 137.0, 102.0, 104.0, 84.0, 86.0, 9.0, 4.0, 28.0, 24.0, 68.0, 68.0, 39.0, 73.0, 26.0, 104.0, 103.0, 111.0, 145.0, 143.0, 70.0, 109.0, 115.0, 126.0, 130.0, 106.0, 155.0, 168.0, 83.0, 69.0, 36.0, 109.0, 17.0, 14.0, 35.0, 64.0, 88.0, 127.0, 117.0, 118.0, 104.0, 118.0, 111.0, 64.0, 97.0, 103.0, 63.0, 53.0, 57.0, 54.0, 54.0, 47.0, 13.0, 28.0, 109.0, 106.0, 44.0, 100.0, 94.0, 58.0, 78.0, 82.0, 130.0, 98.0, 33.0, 50.0, 134.0, 136.0, 42.0, 58.0, 111.0, 115.0, 98.0, 110.0, 139.0, 134.0, 37.0, 77.0, 124.0, 119.0, 78.0, 94.0, 149.0, 137.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7153218711779296, "mean_inference_ms": 1.9619078577958027, "mean_action_processing_ms": 0.294075041632083, "mean_env_wait_ms": 0.24418949792738878, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004806637763977051, "StateBufferConnector_ms": 0.003394484519958496, "ViewRequirementAgentConnector_ms": 0.1407604217529297}, "num_episodes": 23, "episode_return_max": 663.12, "episode_return_min": 314.6399999999999, "episode_return_mean": 454.8228, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.9359816616056, "num_env_steps_trained_throughput_per_sec": 320.9359816616056, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 12655.595, "restore_workers_time_ms": 0.014, "training_step_time_ms": 12655.541, "sample_time_ms": 2002.336, "learn_time_ms": 10633.132, "learn_throughput": 376.183, "synch_weights_time_ms": 17.035}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "0e60f_00000", "date": "2024-08-15_01-16-34", "timestamp": 1723664794, "time_this_iter_s": 12.48265290260315, "time_total_s": 1211.367713689804, "pid": 85867, "hostname": "Joys-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "prey_view_size": 10, "predator_view_size": 15}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3a3119dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 1, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 1, (15, 15), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1211.367713689804, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 57.72352941176471, "ram_util_percent": 83.12941176470588}}
