{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2826435157566001, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.233036319540922, "policy_loss": -0.0006788521362025114, "vf_loss": 4.233399640820013, "vf_explained_var": 0.0009252788528563485, "kl": 0.0015776417159070162, "entropy": 1.6078632733809255, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1646802026679908, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.85058100816434, "policy_loss": 0.00031007077968704005, "vf_loss": 7.850183716274443, "vf_explained_var": 0.007821435966188945, "kl": 0.0004360498417822152, "entropy": 1.6090029637649577, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 210.7999999999993, "episode_reward_min": -80.30000000000005, "episode_reward_mean": 36.566666666666485, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -281.1999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 138.7999999999996, "predator_policy": 114.0}, "policy_reward_mean": {"prey_policy": -12.13333333333343, "predator_policy": 30.416666666666668}, "custom_metrics": {}, "hist_stats": {"episode_reward": [210.7999999999993, 24.10000000000007, 45.10000000000019, 162.3999999999989, 16.900000000000198, -52.89999999999979, -42.99999999999974, -31.49999999999971, 69.29999999999994, -80.30000000000005, 110.99999999999918, 49.90000000000046, 139.89999999999918, -46.79999999999978, -66.70000000000044, 78.49999999999942, 144.6999999999996, -73.20000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [87.49999999999977, 113.29999999999964, 47.00000000000024, -61.90000000000068, 75.80000000000015, -99.7000000000003, 23.60000000000008, 138.7999999999996, 72.20000000000005, -154.30000000000004, -106.00000000000057, -55.899999999999956, -26.799999999999986, -152.20000000000044, 20.000000000000014, -116.5000000000005, 38.29999999999998, 20.000000000000014, -190.00000000000003, -7.300000000000042, 85.99999999999969, 20.000000000000014, 20.000000000000014, 29.90000000000018, 22.700000000000053, 117.19999999999973, -192.40000000000023, 17.60000000000022, -57.70000000000008, -106.00000000000031, 68.59999999999988, -0.10000000000002768, 105.8, 26.900000000000126, 20.000000000000014, -281.1999999999998], "policy_predator_policy_reward": [6.0, 4.0, 18.0, 21.0, 25.0, 44.0, 0.0, 0.0, 19.0, 80.0, 60.0, 49.0, 109.0, 27.0, 0.0, 65.0, 11.0, 0.0, 20.0, 97.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 114.0, 14.0, 37.0, 60.0, 5.0, 5.0, 0.0, 12.0, 83.0, 105.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8266303435204997, "mean_inference_ms": 2.0853151777781105, "mean_action_processing_ms": 0.33441759633800916, "mean_env_wait_ms": 0.2723730242518034, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03543496131896973, "StateBufferConnector_ms": 0.00452929072909885, "ViewRequirementAgentConnector_ms": 0.1789742045932346}, "num_episodes": 18, "episode_return_max": 210.7999999999993, "episode_return_min": -80.30000000000005, "episode_return_mean": 36.566666666666485, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 266.633351567957, "num_env_steps_trained_throughput_per_sec": 266.633351567957, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 15001.883, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15001.835, "sample_time_ms": 1662.147, "learn_time_ms": 13320.766, "learn_throughput": 300.283, "synch_weights_time_ms": 17.201}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "3a355_00000", "date": "2024-08-13_01-09-59", "timestamp": 1723525799, "time_this_iter_s": 15.126776695251465, "time_total_s": 15.126776695251465, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3cee790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15.126776695251465, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 73.10454545454546, "ram_util_percent": 83.67272727272727}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27400515999191655, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.189259871351656, "policy_loss": -0.00464940918929796, "vf_loss": 4.1927079528727855, "vf_explained_var": -0.0008922407551417276, "kl": 0.012013296841661717, "entropy": 1.5892715580879695, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8860287573208254, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.786008852499503, "policy_loss": -0.0015880179883439153, "vf_loss": 7.786498665935778, "vf_explained_var": 0.021199106413220602, "kl": 0.010982094750608993, "entropy": 1.5991664448112406, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 210.7999999999993, "episode_reward_min": -215.300000000001, "episode_reward_mean": 38.56666666666652, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -281.1999999999998, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 148.1, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": -9.008333333333404, "predator_policy": 28.291666666666668}, "custom_metrics": {}, "hist_stats": {"episode_reward": [210.7999999999993, 24.10000000000007, 45.10000000000019, 162.3999999999989, 16.900000000000198, -52.89999999999979, -42.99999999999974, -31.49999999999971, 69.29999999999994, -80.30000000000005, 110.99999999999918, 49.90000000000046, 139.89999999999918, -46.79999999999978, -66.70000000000044, 78.49999999999942, 144.6999999999996, -73.20000000000002, 94.8999999999995, -17.89999999999963, -82.29999999999993, 33.90000000000013, 39.40000000000012, -47.09999999999981, 53.899999999998954, -71.59999999999988, 180.6999999999993, 49.90000000000043, 68.30000000000024, 86.40000000000003, 16.60000000000025, -215.300000000001, 126.19999999999959, 129.39999999999975, 86.39999999999984, 198.40000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [87.49999999999977, 113.29999999999964, 47.00000000000024, -61.90000000000068, 75.80000000000015, -99.7000000000003, 23.60000000000008, 138.7999999999996, 72.20000000000005, -154.30000000000004, -106.00000000000057, -55.899999999999956, -26.799999999999986, -152.20000000000044, 20.000000000000014, -116.5000000000005, 38.29999999999998, 20.000000000000014, -190.00000000000003, -7.300000000000042, 85.99999999999969, 20.000000000000014, 20.000000000000014, 29.90000000000018, 22.700000000000053, 117.19999999999973, -192.40000000000023, 17.60000000000022, -57.70000000000008, -106.00000000000031, 68.59999999999988, -0.10000000000002768, 105.8, 26.900000000000126, 20.000000000000014, -281.1999999999998, 36.20000000000002, 58.7000000000002, -10.599999999999891, -49.29999999999997, 20.000000000000014, -214.3000000000002, 20.000000000000014, -57.10000000000002, -28.000000000000043, -16.59999999999995, 20.000000000000014, -147.1000000000003, 11.299999999999542, -9.400000000000036, -75.70000000000003, -70.89999999999998, 24.500000000000096, 144.2, 20.000000000000014, 29.900000000000183, -3.1000000000000476, 10.400000000000057, 46.40000000000014, 38.00000000000011, 26.300000000000068, -51.70000000000004, -194.20000000000056, -201.1000000000003, 20.000000000000014, 96.19999999999999, 148.1, -78.70000000000087, 62.00000000000011, -34.60000000000017, 83.90000000000012, 114.49999999999999], "policy_predator_policy_reward": [6.0, 4.0, 18.0, 21.0, 25.0, 44.0, 0.0, 0.0, 19.0, 80.0, 60.0, 49.0, 109.0, 27.0, 0.0, 65.0, 11.0, 0.0, 20.0, 97.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 114.0, 14.0, 37.0, 60.0, 5.0, 5.0, 0.0, 12.0, 83.0, 105.0, 0.0, 0.0, 0.0, 42.0, 0.0, 112.0, 1.0, 70.0, 56.0, 28.0, 80.0, 0.0, 15.0, 37.0, 31.0, 44.0, 12.0, 0.0, 0.0, 0.0, 31.0, 30.0, 0.0, 2.0, 4.0, 38.0, 164.0, 16.0, 0.0, 10.0, 54.0, 6.0, 59.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9820889153574888, "mean_inference_ms": 2.5665153937546115, "mean_action_processing_ms": 0.3855134193145316, "mean_env_wait_ms": 0.34609231376777533, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02143912845187717, "StateBufferConnector_ms": 0.0062968995836046, "ViewRequirementAgentConnector_ms": 0.21986597114139134}, "num_episodes": 18, "episode_return_max": 210.7999999999993, "episode_return_min": -215.300000000001, "episode_return_mean": 38.56666666666652, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 336.508342369052, "num_env_steps_trained_throughput_per_sec": 336.508342369052, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 13444.45, "restore_workers_time_ms": 0.09, "training_step_time_ms": 13444.187, "sample_time_ms": 2372.748, "learn_time_ms": 11054.449, "learn_throughput": 361.845, "synch_weights_time_ms": 14.555}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "3a355_00000", "date": "2024-08-13_01-10-16", "timestamp": 1723525816, "time_this_iter_s": 11.940614938735962, "time_total_s": 27.067391633987427, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d21f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 27.067391633987427, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 68.74166666666667, "ram_util_percent": 83.8375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2349177600254142, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.481571875173579, "policy_loss": -0.0031879361234753143, "vf_loss": 4.484039895875114, "vf_explained_var": 0.0003854508437807598, "kl": 0.007199284942247596, "entropy": 1.572976912644805, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8226338387639434, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.627519341120644, "policy_loss": -0.0020522303173377636, "vf_loss": 6.628809943274846, "vf_explained_var": 0.006393936702183314, "kl": 0.007616143510680142, "entropy": 1.6029368399942994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 210.7999999999993, "episode_reward_min": -282.49999999999767, "episode_reward_mean": 30.99814814814804, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -322.3000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 148.1, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": -17.213888888888956, "predator_policy": 32.71296296296296}, "custom_metrics": {}, "hist_stats": {"episode_reward": [210.7999999999993, 24.10000000000007, 45.10000000000019, 162.3999999999989, 16.900000000000198, -52.89999999999979, -42.99999999999974, -31.49999999999971, 69.29999999999994, -80.30000000000005, 110.99999999999918, 49.90000000000046, 139.89999999999918, -46.79999999999978, -66.70000000000044, 78.49999999999942, 144.6999999999996, -73.20000000000002, 94.8999999999995, -17.89999999999963, -82.29999999999993, 33.90000000000013, 39.40000000000012, -47.09999999999981, 53.899999999998954, -71.59999999999988, 180.6999999999993, 49.90000000000043, 68.30000000000024, 86.40000000000003, 16.60000000000025, -215.300000000001, 126.19999999999959, 129.39999999999975, 86.39999999999984, 198.40000000000003, -282.49999999999767, 24.600000000000136, -59.39999999999973, 119.20000000000006, -72.49999999999986, -28.399999999999963, 26.09999999999996, 89.69999999999952, 18.400000000000006, 58.00000000000027, -90.30000000000007, 33.5000000000001, 71.09999999999965, 92.19999999999892, 99.39999999999941, 140.39999999999958, -45.39999999999996, 91.39999999999891], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [87.49999999999977, 113.29999999999964, 47.00000000000024, -61.90000000000068, 75.80000000000015, -99.7000000000003, 23.60000000000008, 138.7999999999996, 72.20000000000005, -154.30000000000004, -106.00000000000057, -55.899999999999956, -26.799999999999986, -152.20000000000044, 20.000000000000014, -116.5000000000005, 38.29999999999998, 20.000000000000014, -190.00000000000003, -7.300000000000042, 85.99999999999969, 20.000000000000014, 20.000000000000014, 29.90000000000018, 22.700000000000053, 117.19999999999973, -192.40000000000023, 17.60000000000022, -57.70000000000008, -106.00000000000031, 68.59999999999988, -0.10000000000002768, 105.8, 26.900000000000126, 20.000000000000014, -281.1999999999998, 36.20000000000002, 58.7000000000002, -10.599999999999891, -49.29999999999997, 20.000000000000014, -214.3000000000002, 20.000000000000014, -57.10000000000002, -28.000000000000043, -16.59999999999995, 20.000000000000014, -147.1000000000003, 11.299999999999542, -9.400000000000036, -75.70000000000003, -70.89999999999998, 24.500000000000096, 144.2, 20.000000000000014, 29.900000000000183, -3.1000000000000476, 10.400000000000057, 46.40000000000014, 38.00000000000011, 26.300000000000068, -51.70000000000004, -194.20000000000056, -201.1000000000003, 20.000000000000014, 96.19999999999999, 148.1, -78.70000000000087, 62.00000000000011, -34.60000000000017, 83.90000000000012, 114.49999999999999, -284.4999999999993, -229.00000000000043, 82.09999999999994, -134.5000000000004, -192.10000000000056, 31.699999999999996, 20.90000000000003, 98.30000000000015, -150.10000000000042, -30.39999999999992, 20.000000000000014, -264.40000000000015, 16.399999999999977, -37.29999999999997, 20.300000000000033, 10.400000000000048, 20.000000000000014, -64.60000000000042, 20.000000000000014, 37.999999999999986, -322.3000000000002, 20.000000000000014, 27.200000000000017, -57.699999999999925, -108.40000000000003, 60.499999999999744, 67.69999999999987, 24.50000000000009, 20.000000000000014, 79.39999999999972, 15.80000000000011, 74.6, 24.800000000000022, -215.2, 20.000000000000014, 67.40000000000002], "policy_predator_policy_reward": [6.0, 4.0, 18.0, 21.0, 25.0, 44.0, 0.0, 0.0, 19.0, 80.0, 60.0, 49.0, 109.0, 27.0, 0.0, 65.0, 11.0, 0.0, 20.0, 97.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 114.0, 14.0, 37.0, 60.0, 5.0, 5.0, 0.0, 12.0, 83.0, 105.0, 0.0, 0.0, 0.0, 42.0, 0.0, 112.0, 1.0, 70.0, 56.0, 28.0, 80.0, 0.0, 15.0, 37.0, 31.0, 44.0, 12.0, 0.0, 0.0, 0.0, 31.0, 30.0, 0.0, 2.0, 4.0, 38.0, 164.0, 16.0, 0.0, 10.0, 54.0, 6.0, 59.0, 0.0, 0.0, 0.0, 102.0, 129.0, 77.0, 0.0, 101.0, 0.0, 0.0, 0.0, 108.0, 0.0, 111.0, 105.0, 3.0, 44.0, 20.0, 39.0, 30.0, 33.0, 0.0, 0.0, 153.0, 59.0, 0.0, 64.0, 21.0, 98.0, 0.0, 0.0, 0.0, 0.0, 16.0, 34.0, 145.0, 0.0, 0.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9785749398329803, "mean_inference_ms": 2.566986157853878, "mean_action_processing_ms": 0.38298724347404384, "mean_env_wait_ms": 0.3476309266041755, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016359267411408602, "StateBufferConnector_ms": 0.005262207101892542, "ViewRequirementAgentConnector_ms": 0.1802910257268835}, "num_episodes": 18, "episode_return_max": 210.7999999999993, "episode_return_min": -282.49999999999767, "episode_return_mean": 30.99814814814804, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 388.57957176613525, "num_env_steps_trained_throughput_per_sec": 388.57957176613525, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 12394.269, "restore_workers_time_ms": 0.064, "training_step_time_ms": 12394.081, "sample_time_ms": 2022.919, "learn_time_ms": 10353.947, "learn_throughput": 386.326, "synch_weights_time_ms": 13.808}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "3a355_00000", "date": "2024-08-13_01-10-26", "timestamp": 1723525826, "time_this_iter_s": 10.341462135314941, "time_total_s": 37.40885376930237, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d35dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 37.40885376930237, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 53.535714285714285, "ram_util_percent": 83.51428571428572}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.33419010914152575, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9372400792187485, "policy_loss": -0.005511477137743323, "vf_loss": 2.941569444805226, "vf_explained_var": 0.0019571003144380275, "kl": 0.011821059991507857, "entropy": 1.5523474143295692, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5360166621586633, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.51408419798291, "policy_loss": -0.0008816339254192023, "vf_loss": 5.514242780271661, "vf_explained_var": 0.010236043557918892, "kl": 0.0072305464035989, "entropy": 1.601029314313616, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 247.89999999999944, "episode_reward_min": -282.49999999999767, "episode_reward_mean": 26.82777777777763, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -336.09999999999957, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": -20.120833333333387, "predator_policy": 33.53472222222222}, "custom_metrics": {}, "hist_stats": {"episode_reward": [210.7999999999993, 24.10000000000007, 45.10000000000019, 162.3999999999989, 16.900000000000198, -52.89999999999979, -42.99999999999974, -31.49999999999971, 69.29999999999994, -80.30000000000005, 110.99999999999918, 49.90000000000046, 139.89999999999918, -46.79999999999978, -66.70000000000044, 78.49999999999942, 144.6999999999996, -73.20000000000002, 94.8999999999995, -17.89999999999963, -82.29999999999993, 33.90000000000013, 39.40000000000012, -47.09999999999981, 53.899999999998954, -71.59999999999988, 180.6999999999993, 49.90000000000043, 68.30000000000024, 86.40000000000003, 16.60000000000025, -215.300000000001, 126.19999999999959, 129.39999999999975, 86.39999999999984, 198.40000000000003, -282.49999999999767, 24.600000000000136, -59.39999999999973, 119.20000000000006, -72.49999999999986, -28.399999999999963, 26.09999999999996, 89.69999999999952, 18.400000000000006, 58.00000000000027, -90.30000000000007, 33.5000000000001, 71.09999999999965, 92.19999999999892, 99.39999999999941, 140.39999999999958, -45.39999999999996, 91.39999999999891, -47.70000000000133, 22.2000000000003, -109.60000000000039, -26.200000000000202, -14.199999999999699, -112.10000000000068, -59.40000000000052, 102.79999999999939, -96.1999999999999, 137.69999999999936, -131.90000000000057, 133.89999999999924, 40.9000000000003, 34.100000000000236, 247.89999999999944, 50.00000000000041, -27.299999999999777, 112.79999999999973], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [87.49999999999977, 113.29999999999964, 47.00000000000024, -61.90000000000068, 75.80000000000015, -99.7000000000003, 23.60000000000008, 138.7999999999996, 72.20000000000005, -154.30000000000004, -106.00000000000057, -55.899999999999956, -26.799999999999986, -152.20000000000044, 20.000000000000014, -116.5000000000005, 38.29999999999998, 20.000000000000014, -190.00000000000003, -7.300000000000042, 85.99999999999969, 20.000000000000014, 20.000000000000014, 29.90000000000018, 22.700000000000053, 117.19999999999973, -192.40000000000023, 17.60000000000022, -57.70000000000008, -106.00000000000031, 68.59999999999988, -0.10000000000002768, 105.8, 26.900000000000126, 20.000000000000014, -281.1999999999998, 36.20000000000002, 58.7000000000002, -10.599999999999891, -49.29999999999997, 20.000000000000014, -214.3000000000002, 20.000000000000014, -57.10000000000002, -28.000000000000043, -16.59999999999995, 20.000000000000014, -147.1000000000003, 11.299999999999542, -9.400000000000036, -75.70000000000003, -70.89999999999998, 24.500000000000096, 144.2, 20.000000000000014, 29.900000000000183, -3.1000000000000476, 10.400000000000057, 46.40000000000014, 38.00000000000011, 26.300000000000068, -51.70000000000004, -194.20000000000056, -201.1000000000003, 20.000000000000014, 96.19999999999999, 148.1, -78.70000000000087, 62.00000000000011, -34.60000000000017, 83.90000000000012, 114.49999999999999, -284.4999999999993, -229.00000000000043, 82.09999999999994, -134.5000000000004, -192.10000000000056, 31.699999999999996, 20.90000000000003, 98.30000000000015, -150.10000000000042, -30.39999999999992, 20.000000000000014, -264.40000000000015, 16.399999999999977, -37.29999999999997, 20.300000000000033, 10.400000000000048, 20.000000000000014, -64.60000000000042, 20.000000000000014, 37.999999999999986, -322.3000000000002, 20.000000000000014, 27.200000000000017, -57.699999999999925, -108.40000000000003, 60.499999999999744, 67.69999999999987, 24.50000000000009, 20.000000000000014, 79.39999999999972, 15.80000000000011, 74.6, 24.800000000000022, -215.2, 20.000000000000014, 67.40000000000002, -54.40000000000012, -49.29999999999976, 65.90000000000008, -105.70000000000029, -79.30000000000024, -175.30000000000015, -125.19999999999999, -0.9999999999999992, -105.10000000000021, 17.899999999999988, 20.000000000000014, -336.09999999999957, -150.10000000000056, -46.30000000000018, 27.20000000000009, 74.5999999999998, -116.19999999999995, -151.00000000000009, 114.7999999999999, 11.899999999999967, -334.89999999999964, 20.000000000000014, 92.89999999999972, 20.000000000000014, 20.900000000000013, 20.000000000000014, -10.899999999999878, 20.000000000000014, 195.49999999999997, 52.40000000000003, 26.000000000000114, 20.000000000000014, 20.000000000000014, -109.30000000000041, -17.79999999999974, 89.59999999999994], "policy_predator_policy_reward": [6.0, 4.0, 18.0, 21.0, 25.0, 44.0, 0.0, 0.0, 19.0, 80.0, 60.0, 49.0, 109.0, 27.0, 0.0, 65.0, 11.0, 0.0, 20.0, 97.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 114.0, 14.0, 37.0, 60.0, 5.0, 5.0, 0.0, 12.0, 83.0, 105.0, 0.0, 0.0, 0.0, 42.0, 0.0, 112.0, 1.0, 70.0, 56.0, 28.0, 80.0, 0.0, 15.0, 37.0, 31.0, 44.0, 12.0, 0.0, 0.0, 0.0, 31.0, 30.0, 0.0, 2.0, 4.0, 38.0, 164.0, 16.0, 0.0, 10.0, 54.0, 6.0, 59.0, 0.0, 0.0, 0.0, 102.0, 129.0, 77.0, 0.0, 101.0, 0.0, 0.0, 0.0, 108.0, 0.0, 111.0, 105.0, 3.0, 44.0, 20.0, 39.0, 30.0, 33.0, 0.0, 0.0, 153.0, 59.0, 0.0, 64.0, 21.0, 98.0, 0.0, 0.0, 0.0, 0.0, 16.0, 34.0, 145.0, 0.0, 0.0, 4.0, 56.0, 0.0, 0.0, 62.0, 52.0, 93.0, 0.0, 100.0, 72.0, 1.0, 47.0, 157.0, 81.0, 56.0, 1.0, 0.0, 64.0, 107.0, 6.0, 5.0, 14.0, 169.0, 10.0, 11.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 4.0, 0.0, 62.0, 20.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.956208517941351, "mean_inference_ms": 2.512409736094076, "mean_action_processing_ms": 0.3749811997712562, "mean_env_wait_ms": 0.3412017047962367, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022198259830474854, "StateBufferConnector_ms": 0.004744695292578803, "ViewRequirementAgentConnector_ms": 0.17244633701112536}, "num_episodes": 18, "episode_return_max": 247.89999999999944, "episode_return_min": -282.49999999999767, "episode_return_mean": 26.82777777777763, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 395.6046360672845, "num_env_steps_trained_throughput_per_sec": 395.6046360672845, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 11823.48, "restore_workers_time_ms": 0.052, "training_step_time_ms": 11823.328, "sample_time_ms": 1845.096, "learn_time_ms": 9960.06, "learn_throughput": 401.604, "synch_weights_time_ms": 15.399}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "3a355_00000", "date": "2024-08-13_01-10-37", "timestamp": 1723525837, "time_this_iter_s": 10.149940013885498, "time_total_s": 47.558793783187866, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d35e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 47.558793783187866, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 49.96000000000001, "ram_util_percent": 83.38666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28077726742380826, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0449441419076666, "policy_loss": -0.002947110458272238, "vf_loss": 3.0472462258010946, "vf_explained_var": 0.007022627920070023, "kl": 0.006450266951063956, "entropy": 1.5211613658874754, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4399068346651143, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.104138292963543, "policy_loss": -0.0037339373922872323, "vf_loss": 5.106203361793801, "vf_explained_var": 0.006078483440257885, "kl": 0.016688583919863675, "entropy": 1.567767147160081, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 260.19999999999993, "episode_reward_min": -282.49999999999767, "episode_reward_mean": 34.68282828282812, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -336.09999999999957, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": -13.451515151515217, "predator_policy": 30.792929292929294}, "custom_metrics": {}, "hist_stats": {"episode_reward": [210.7999999999993, 24.10000000000007, 45.10000000000019, 162.3999999999989, 16.900000000000198, -52.89999999999979, -42.99999999999974, -31.49999999999971, 69.29999999999994, -80.30000000000005, 110.99999999999918, 49.90000000000046, 139.89999999999918, -46.79999999999978, -66.70000000000044, 78.49999999999942, 144.6999999999996, -73.20000000000002, 94.8999999999995, -17.89999999999963, -82.29999999999993, 33.90000000000013, 39.40000000000012, -47.09999999999981, 53.899999999998954, -71.59999999999988, 180.6999999999993, 49.90000000000043, 68.30000000000024, 86.40000000000003, 16.60000000000025, -215.300000000001, 126.19999999999959, 129.39999999999975, 86.39999999999984, 198.40000000000003, -282.49999999999767, 24.600000000000136, -59.39999999999973, 119.20000000000006, -72.49999999999986, -28.399999999999963, 26.09999999999996, 89.69999999999952, 18.400000000000006, 58.00000000000027, -90.30000000000007, 33.5000000000001, 71.09999999999965, 92.19999999999892, 99.39999999999941, 140.39999999999958, -45.39999999999996, 91.39999999999891, -47.70000000000133, 22.2000000000003, -109.60000000000039, -26.200000000000202, -14.199999999999699, -112.10000000000068, -59.40000000000052, 102.79999999999939, -96.1999999999999, 137.69999999999936, -131.90000000000057, 133.89999999999924, 40.9000000000003, 34.100000000000236, 247.89999999999944, 50.00000000000041, -27.299999999999777, 112.79999999999973, 90.30000000000013, -8.899999999999928, 80.49999999999918, 260.19999999999993, 40.0000000000003, 40.0000000000003, -102.70000000000078, 9.20000000000027, 190.29999999999893, 94.49999999999973, -15.29999999999957, -37.99999999999987, 23.699999999999598, 31.80000000000002, 86.59999999999991, 10.79999999999999, 99.19999999999891, 67.59999999999954, 141.69999999999922, 100.1999999999995, 45.80000000000019, 75.59999999999974, 73.99999999999972, -60.600000000001, 70.7, 58.00000000000051, 36.80000000000041], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [87.49999999999977, 113.29999999999964, 47.00000000000024, -61.90000000000068, 75.80000000000015, -99.7000000000003, 23.60000000000008, 138.7999999999996, 72.20000000000005, -154.30000000000004, -106.00000000000057, -55.899999999999956, -26.799999999999986, -152.20000000000044, 20.000000000000014, -116.5000000000005, 38.29999999999998, 20.000000000000014, -190.00000000000003, -7.300000000000042, 85.99999999999969, 20.000000000000014, 20.000000000000014, 29.90000000000018, 22.700000000000053, 117.19999999999973, -192.40000000000023, 17.60000000000022, -57.70000000000008, -106.00000000000031, 68.59999999999988, -0.10000000000002768, 105.8, 26.900000000000126, 20.000000000000014, -281.1999999999998, 36.20000000000002, 58.7000000000002, -10.599999999999891, -49.29999999999997, 20.000000000000014, -214.3000000000002, 20.000000000000014, -57.10000000000002, -28.000000000000043, -16.59999999999995, 20.000000000000014, -147.1000000000003, 11.299999999999542, -9.400000000000036, -75.70000000000003, -70.89999999999998, 24.500000000000096, 144.2, 20.000000000000014, 29.900000000000183, -3.1000000000000476, 10.400000000000057, 46.40000000000014, 38.00000000000011, 26.300000000000068, -51.70000000000004, -194.20000000000056, -201.1000000000003, 20.000000000000014, 96.19999999999999, 148.1, -78.70000000000087, 62.00000000000011, -34.60000000000017, 83.90000000000012, 114.49999999999999, -284.4999999999993, -229.00000000000043, 82.09999999999994, -134.5000000000004, -192.10000000000056, 31.699999999999996, 20.90000000000003, 98.30000000000015, -150.10000000000042, -30.39999999999992, 20.000000000000014, -264.40000000000015, 16.399999999999977, -37.29999999999997, 20.300000000000033, 10.400000000000048, 20.000000000000014, -64.60000000000042, 20.000000000000014, 37.999999999999986, -322.3000000000002, 20.000000000000014, 27.200000000000017, -57.699999999999925, -108.40000000000003, 60.499999999999744, 67.69999999999987, 24.50000000000009, 20.000000000000014, 79.39999999999972, 15.80000000000011, 74.6, 24.800000000000022, -215.2, 20.000000000000014, 67.40000000000002, -54.40000000000012, -49.29999999999976, 65.90000000000008, -105.70000000000029, -79.30000000000024, -175.30000000000015, -125.19999999999999, -0.9999999999999992, -105.10000000000021, 17.899999999999988, 20.000000000000014, -336.09999999999957, -150.10000000000056, -46.30000000000018, 27.20000000000009, 74.5999999999998, -116.19999999999995, -151.00000000000009, 114.7999999999999, 11.899999999999967, -334.89999999999964, 20.000000000000014, 92.89999999999972, 20.000000000000014, 20.900000000000013, 20.000000000000014, -10.899999999999878, 20.000000000000014, 195.49999999999997, 52.40000000000003, 26.000000000000114, 20.000000000000014, 20.000000000000014, -109.30000000000041, -17.79999999999974, 89.59999999999994, 65.30000000000014, 20.000000000000014, -89.80000000000044, 20.90000000000003, 20.000000000000014, 60.500000000000156, 151.39999999999998, 102.79999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -148.90000000000012, -59.800000000000196, 31.700000000000156, -86.5000000000006, 78.50000000000017, 111.79999999999984, 20.000000000000014, 72.49999999999986, 4.700000000000115, -85.00000000000085, -21.4, -118.60000000000008, 33.49999999999986, -140.80000000000038, -57.69999999999998, -23.499999999999968, -87.4000000000002, 88.99999999999994, -74.50000000000051, -6.6999999999999975, 78.19999999999973, 20.000000000000014, 132.79999999999973, -152.20000000000047, 68.29999999999998, 55.400000000000176, 71.5999999999998, -9.399999999999897, -95.5, 44.30000000000017, 86.59999999999928, -76.0000000000006, 35.00000000000017, 20.000000000000014, -46.899999999999814, -78.70000000000059, 45.800000000000225, 20.900000000000027, 20.000000000000014, 38.000000000000256, 20.000000000000014, -26.199999999999847], "policy_predator_policy_reward": [6.0, 4.0, 18.0, 21.0, 25.0, 44.0, 0.0, 0.0, 19.0, 80.0, 60.0, 49.0, 109.0, 27.0, 0.0, 65.0, 11.0, 0.0, 20.0, 97.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 114.0, 14.0, 37.0, 60.0, 5.0, 5.0, 0.0, 12.0, 83.0, 105.0, 0.0, 0.0, 0.0, 42.0, 0.0, 112.0, 1.0, 70.0, 56.0, 28.0, 80.0, 0.0, 15.0, 37.0, 31.0, 44.0, 12.0, 0.0, 0.0, 0.0, 31.0, 30.0, 0.0, 2.0, 4.0, 38.0, 164.0, 16.0, 0.0, 10.0, 54.0, 6.0, 59.0, 0.0, 0.0, 0.0, 102.0, 129.0, 77.0, 0.0, 101.0, 0.0, 0.0, 0.0, 108.0, 0.0, 111.0, 105.0, 3.0, 44.0, 20.0, 39.0, 30.0, 33.0, 0.0, 0.0, 153.0, 59.0, 0.0, 64.0, 21.0, 98.0, 0.0, 0.0, 0.0, 0.0, 16.0, 34.0, 145.0, 0.0, 0.0, 4.0, 56.0, 0.0, 0.0, 62.0, 52.0, 93.0, 0.0, 100.0, 72.0, 1.0, 47.0, 157.0, 81.0, 56.0, 1.0, 0.0, 64.0, 107.0, 6.0, 5.0, 14.0, 169.0, 10.0, 11.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 4.0, 0.0, 62.0, 20.0, 21.0, 0.0, 5.0, 60.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 106.0, 64.0, 0.0, 0.0, 0.0, 0.0, 2.0, 53.0, 12.0, 31.0, 71.0, 39.0, 92.0, 83.0, 30.0, 43.0, 42.0, 79.0, 13.0, 0.0, 1.0, 82.0, 5.0, 11.0, 7.0, 0.0, 38.0, 42.0, 55.0, 58.0, 7.0, 0.0, 19.0, 65.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 43.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9243150048650346, "mean_inference_ms": 2.427515483687557, "mean_action_processing_ms": 0.36311131560253496, "mean_env_wait_ms": 0.3298491574573811, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02127657032976247, "StateBufferConnector_ms": 0.004398100303881096, "ViewRequirementAgentConnector_ms": 0.15348930551548196}, "num_episodes": 27, "episode_return_max": 260.19999999999993, "episode_return_min": -282.49999999999767, "episode_return_mean": 34.68282828282812, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 376.3136180687785, "num_env_steps_trained_throughput_per_sec": 376.3136180687785, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 11584.672, "restore_workers_time_ms": 0.044, "training_step_time_ms": 11584.542, "sample_time_ms": 1734.019, "learn_time_ms": 9832.035, "learn_throughput": 406.833, "synch_weights_time_ms": 15.032}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "3a355_00000", "date": "2024-08-13_01-10-47", "timestamp": 1723525847, "time_this_iter_s": 10.677022933959961, "time_total_s": 58.23581671714783, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d45dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 58.23581671714783, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 52.37333333333334, "ram_util_percent": 83.35999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3135817657387446, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.993338991220666, "policy_loss": -0.007608761010622537, "vf_loss": 3.9999059018634613, "vf_explained_var": 0.0015026427135265694, "kl": 0.010418400668725092, "entropy": 1.4824081013442347, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.29102144626871, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.674440716814112, "policy_loss": -0.0071855572322087865, "vf_loss": 4.678838749915834, "vf_explained_var": 0.004730792083437481, "kl": 0.027875146931500176, "entropy": 1.574873029239594, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 260.19999999999993, "episode_reward_min": -282.49999999999767, "episode_reward_mean": 26.091999999999874, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -336.09999999999957, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": -18.874000000000052, "predator_policy": 31.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-73.20000000000002, 94.8999999999995, -17.89999999999963, -82.29999999999993, 33.90000000000013, 39.40000000000012, -47.09999999999981, 53.899999999998954, -71.59999999999988, 180.6999999999993, 49.90000000000043, 68.30000000000024, 86.40000000000003, 16.60000000000025, -215.300000000001, 126.19999999999959, 129.39999999999975, 86.39999999999984, 198.40000000000003, -282.49999999999767, 24.600000000000136, -59.39999999999973, 119.20000000000006, -72.49999999999986, -28.399999999999963, 26.09999999999996, 89.69999999999952, 18.400000000000006, 58.00000000000027, -90.30000000000007, 33.5000000000001, 71.09999999999965, 92.19999999999892, 99.39999999999941, 140.39999999999958, -45.39999999999996, 91.39999999999891, -47.70000000000133, 22.2000000000003, -109.60000000000039, -26.200000000000202, -14.199999999999699, -112.10000000000068, -59.40000000000052, 102.79999999999939, -96.1999999999999, 137.69999999999936, -131.90000000000057, 133.89999999999924, 40.9000000000003, 34.100000000000236, 247.89999999999944, 50.00000000000041, -27.299999999999777, 112.79999999999973, 90.30000000000013, -8.899999999999928, 80.49999999999918, 260.19999999999993, 40.0000000000003, 40.0000000000003, -102.70000000000078, 9.20000000000027, 190.29999999999893, 94.49999999999973, -15.29999999999957, -37.99999999999987, 23.699999999999598, 31.80000000000002, 86.59999999999991, 10.79999999999999, 99.19999999999891, 67.59999999999954, 141.69999999999922, 100.1999999999995, 45.80000000000019, 75.59999999999974, 73.99999999999972, -60.600000000001, 70.7, 58.00000000000051, 36.80000000000041, -6.399999999999922, 54.09999999999921, 21.100000000000005, 26.4000000000001, 45.30000000000035, 26.000000000000234, -125.40000000000029, -90.9000000000003, 59.69999999999955, 25.70000000000005, -20.299999999999635, 40.0000000000003, -15.299999999999912, -154.0999999999999, -58.79999999999986, 65.70000000000023, 11.399999999999984, 2.7999999999999505], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -281.1999999999998, 36.20000000000002, 58.7000000000002, -10.599999999999891, -49.29999999999997, 20.000000000000014, -214.3000000000002, 20.000000000000014, -57.10000000000002, -28.000000000000043, -16.59999999999995, 20.000000000000014, -147.1000000000003, 11.299999999999542, -9.400000000000036, -75.70000000000003, -70.89999999999998, 24.500000000000096, 144.2, 20.000000000000014, 29.900000000000183, -3.1000000000000476, 10.400000000000057, 46.40000000000014, 38.00000000000011, 26.300000000000068, -51.70000000000004, -194.20000000000056, -201.1000000000003, 20.000000000000014, 96.19999999999999, 148.1, -78.70000000000087, 62.00000000000011, -34.60000000000017, 83.90000000000012, 114.49999999999999, -284.4999999999993, -229.00000000000043, 82.09999999999994, -134.5000000000004, -192.10000000000056, 31.699999999999996, 20.90000000000003, 98.30000000000015, -150.10000000000042, -30.39999999999992, 20.000000000000014, -264.40000000000015, 16.399999999999977, -37.29999999999997, 20.300000000000033, 10.400000000000048, 20.000000000000014, -64.60000000000042, 20.000000000000014, 37.999999999999986, -322.3000000000002, 20.000000000000014, 27.200000000000017, -57.699999999999925, -108.40000000000003, 60.499999999999744, 67.69999999999987, 24.50000000000009, 20.000000000000014, 79.39999999999972, 15.80000000000011, 74.6, 24.800000000000022, -215.2, 20.000000000000014, 67.40000000000002, -54.40000000000012, -49.29999999999976, 65.90000000000008, -105.70000000000029, -79.30000000000024, -175.30000000000015, -125.19999999999999, -0.9999999999999992, -105.10000000000021, 17.899999999999988, 20.000000000000014, -336.09999999999957, -150.10000000000056, -46.30000000000018, 27.20000000000009, 74.5999999999998, -116.19999999999995, -151.00000000000009, 114.7999999999999, 11.899999999999967, -334.89999999999964, 20.000000000000014, 92.89999999999972, 20.000000000000014, 20.900000000000013, 20.000000000000014, -10.899999999999878, 20.000000000000014, 195.49999999999997, 52.40000000000003, 26.000000000000114, 20.000000000000014, 20.000000000000014, -109.30000000000041, -17.79999999999974, 89.59999999999994, 65.30000000000014, 20.000000000000014, -89.80000000000044, 20.90000000000003, 20.000000000000014, 60.500000000000156, 151.39999999999998, 102.79999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -148.90000000000012, -59.800000000000196, 31.700000000000156, -86.5000000000006, 78.50000000000017, 111.79999999999984, 20.000000000000014, 72.49999999999986, 4.700000000000115, -85.00000000000085, -21.4, -118.60000000000008, 33.49999999999986, -140.80000000000038, -57.69999999999998, -23.499999999999968, -87.4000000000002, 88.99999999999994, -74.50000000000051, -6.6999999999999975, 78.19999999999973, 20.000000000000014, 132.79999999999973, -152.20000000000047, 68.29999999999998, 55.400000000000176, 71.5999999999998, -9.399999999999897, -95.5, 44.30000000000017, 86.59999999999928, -76.0000000000006, 35.00000000000017, 20.000000000000014, -46.899999999999814, -78.70000000000059, 45.800000000000225, 20.900000000000027, 20.000000000000014, 38.000000000000256, 20.000000000000014, -26.199999999999847, -22.59999999999981, -98.80000000000018, 60.50000000000016, -30.400000000000027, 7.699999999999971, -13.599999999999783, 20.000000000000014, -22.599999999999802, 20.30000000000002, 20.000000000000014, 35.300000000000054, -70.30000000000044, -89.20000000000023, -110.20000000000016, -229.90000000000043, 20.000000000000014, 80.89999999999955, -89.20000000000014, 20.000000000000014, -7.300000000000042, -112.30000000000067, 29.000000000000163, 20.000000000000014, 20.000000000000014, 20.000000000000014, -154.30000000000024, -60.399999999999935, -309.70000000000005, -204.70000000000027, -12.100000000000009, 46.10000000000023, -27.399999999999828, 20.000000000000014, -34.59999999999978, -36.699999999999854, 9.499999999999982], "policy_predator_policy_reward": [83.0, 105.0, 0.0, 0.0, 0.0, 42.0, 0.0, 112.0, 1.0, 70.0, 56.0, 28.0, 80.0, 0.0, 15.0, 37.0, 31.0, 44.0, 12.0, 0.0, 0.0, 0.0, 31.0, 30.0, 0.0, 2.0, 4.0, 38.0, 164.0, 16.0, 0.0, 10.0, 54.0, 6.0, 59.0, 0.0, 0.0, 0.0, 102.0, 129.0, 77.0, 0.0, 101.0, 0.0, 0.0, 0.0, 108.0, 0.0, 111.0, 105.0, 3.0, 44.0, 20.0, 39.0, 30.0, 33.0, 0.0, 0.0, 153.0, 59.0, 0.0, 64.0, 21.0, 98.0, 0.0, 0.0, 0.0, 0.0, 16.0, 34.0, 145.0, 0.0, 0.0, 4.0, 56.0, 0.0, 0.0, 62.0, 52.0, 93.0, 0.0, 100.0, 72.0, 1.0, 47.0, 157.0, 81.0, 56.0, 1.0, 0.0, 64.0, 107.0, 6.0, 5.0, 14.0, 169.0, 10.0, 11.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 4.0, 0.0, 62.0, 20.0, 21.0, 0.0, 5.0, 60.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 106.0, 64.0, 0.0, 0.0, 0.0, 0.0, 2.0, 53.0, 12.0, 31.0, 71.0, 39.0, 92.0, 83.0, 30.0, 43.0, 42.0, 79.0, 13.0, 0.0, 1.0, 82.0, 5.0, 11.0, 7.0, 0.0, 38.0, 42.0, 55.0, 58.0, 7.0, 0.0, 19.0, 65.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 43.0, 40.0, 75.0, 12.0, 12.0, 11.0, 16.0, 25.0, 4.0, 5.0, 0.0, 29.0, 32.0, 74.0, 0.0, 119.0, 0.0, 16.0, 52.0, 0.0, 13.0, 0.0, 63.0, 0.0, 0.0, 83.0, 36.0, 128.0, 88.0, 85.0, 73.0, 32.0, 15.0, 0.0, 26.0, 30.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9240748942084198, "mean_inference_ms": 2.4379923149382154, "mean_action_processing_ms": 0.3622452070858529, "mean_env_wait_ms": 0.3322839881715381, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015447020530700684, "StateBufferConnector_ms": 0.004114747047424316, "ViewRequirementAgentConnector_ms": 0.14190351963043213}, "num_episodes": 18, "episode_return_max": 260.19999999999993, "episode_return_min": -282.49999999999767, "episode_return_mean": 26.091999999999874, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 124.56520420768224, "num_env_steps_trained_throughput_per_sec": 124.56520420768224, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 15005.844, "restore_workers_time_ms": 0.039, "training_step_time_ms": 15005.728, "sample_time_ms": 1718.084, "learn_time_ms": 13269.545, "learn_throughput": 301.442, "synch_weights_time_ms": 14.78}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "3a355_00000", "date": "2024-08-13_01-11-19", "timestamp": 1723525879, "time_this_iter_s": 32.15887713432312, "time_total_s": 90.39469385147095, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3de35e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 90.39469385147095, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 76.7625, "ram_util_percent": 83.67083333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2516146839492851, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7889162806922165, "policy_loss": -0.0008375371975094947, "vf_loss": 1.789502353516836, "vf_explained_var": 0.004949085989957133, "kl": 0.0025146790131102712, "entropy": 1.4998588353237778, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2448892693276759, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.191392233068981, "policy_loss": -0.0033455943916653277, "vf_loss": 3.193615762014238, "vf_explained_var": 0.0006847587212052926, "kl": 0.007480484345530667, "entropy": 1.5890934646444976, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 260.19999999999993, "episode_reward_min": -282.49999999999767, "episode_reward_mean": 24.54799999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -336.09999999999957, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": -18.13600000000007, "predator_policy": 30.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [198.40000000000003, -282.49999999999767, 24.600000000000136, -59.39999999999973, 119.20000000000006, -72.49999999999986, -28.399999999999963, 26.09999999999996, 89.69999999999952, 18.400000000000006, 58.00000000000027, -90.30000000000007, 33.5000000000001, 71.09999999999965, 92.19999999999892, 99.39999999999941, 140.39999999999958, -45.39999999999996, 91.39999999999891, -47.70000000000133, 22.2000000000003, -109.60000000000039, -26.200000000000202, -14.199999999999699, -112.10000000000068, -59.40000000000052, 102.79999999999939, -96.1999999999999, 137.69999999999936, -131.90000000000057, 133.89999999999924, 40.9000000000003, 34.100000000000236, 247.89999999999944, 50.00000000000041, -27.299999999999777, 112.79999999999973, 90.30000000000013, -8.899999999999928, 80.49999999999918, 260.19999999999993, 40.0000000000003, 40.0000000000003, -102.70000000000078, 9.20000000000027, 190.29999999999893, 94.49999999999973, -15.29999999999957, -37.99999999999987, 23.699999999999598, 31.80000000000002, 86.59999999999991, 10.79999999999999, 99.19999999999891, 67.59999999999954, 141.69999999999922, 100.1999999999995, 45.80000000000019, 75.59999999999974, 73.99999999999972, -60.600000000001, 70.7, 58.00000000000051, 36.80000000000041, -6.399999999999922, 54.09999999999921, 21.100000000000005, 26.4000000000001, 45.30000000000035, 26.000000000000234, -125.40000000000029, -90.9000000000003, 59.69999999999955, 25.70000000000005, -20.299999999999635, 40.0000000000003, -15.299999999999912, -154.0999999999999, -58.79999999999986, 65.70000000000023, 11.399999999999984, 2.7999999999999505, 130.8999999999987, 59.80000000000005, -42.59999999999962, 41.90000000000033, -17.199999999999534, 38.900000000000276, 18.30000000000007, 61.400000000000446, -50.700000000000145, 118.29999999999912, 63.80000000000042, -210.9000000000013, 20.19999999999998, 17.39999999999994, -74.79999999999984, -28.199999999999726, 75.99999999999963, 81.69999999999875], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [83.90000000000012, 114.49999999999999, -284.4999999999993, -229.00000000000043, 82.09999999999994, -134.5000000000004, -192.10000000000056, 31.699999999999996, 20.90000000000003, 98.30000000000015, -150.10000000000042, -30.39999999999992, 20.000000000000014, -264.40000000000015, 16.399999999999977, -37.29999999999997, 20.300000000000033, 10.400000000000048, 20.000000000000014, -64.60000000000042, 20.000000000000014, 37.999999999999986, -322.3000000000002, 20.000000000000014, 27.200000000000017, -57.699999999999925, -108.40000000000003, 60.499999999999744, 67.69999999999987, 24.50000000000009, 20.000000000000014, 79.39999999999972, 15.80000000000011, 74.6, 24.800000000000022, -215.2, 20.000000000000014, 67.40000000000002, -54.40000000000012, -49.29999999999976, 65.90000000000008, -105.70000000000029, -79.30000000000024, -175.30000000000015, -125.19999999999999, -0.9999999999999992, -105.10000000000021, 17.899999999999988, 20.000000000000014, -336.09999999999957, -150.10000000000056, -46.30000000000018, 27.20000000000009, 74.5999999999998, -116.19999999999995, -151.00000000000009, 114.7999999999999, 11.899999999999967, -334.89999999999964, 20.000000000000014, 92.89999999999972, 20.000000000000014, 20.900000000000013, 20.000000000000014, -10.899999999999878, 20.000000000000014, 195.49999999999997, 52.40000000000003, 26.000000000000114, 20.000000000000014, 20.000000000000014, -109.30000000000041, -17.79999999999974, 89.59999999999994, 65.30000000000014, 20.000000000000014, -89.80000000000044, 20.90000000000003, 20.000000000000014, 60.500000000000156, 151.39999999999998, 102.79999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -148.90000000000012, -59.800000000000196, 31.700000000000156, -86.5000000000006, 78.50000000000017, 111.79999999999984, 20.000000000000014, 72.49999999999986, 4.700000000000115, -85.00000000000085, -21.4, -118.60000000000008, 33.49999999999986, -140.80000000000038, -57.69999999999998, -23.499999999999968, -87.4000000000002, 88.99999999999994, -74.50000000000051, -6.6999999999999975, 78.19999999999973, 20.000000000000014, 132.79999999999973, -152.20000000000047, 68.29999999999998, 55.400000000000176, 71.5999999999998, -9.399999999999897, -95.5, 44.30000000000017, 86.59999999999928, -76.0000000000006, 35.00000000000017, 20.000000000000014, -46.899999999999814, -78.70000000000059, 45.800000000000225, 20.900000000000027, 20.000000000000014, 38.000000000000256, 20.000000000000014, -26.199999999999847, -22.59999999999981, -98.80000000000018, 60.50000000000016, -30.400000000000027, 7.699999999999971, -13.599999999999783, 20.000000000000014, -22.599999999999802, 20.30000000000002, 20.000000000000014, 35.300000000000054, -70.30000000000044, -89.20000000000023, -110.20000000000016, -229.90000000000043, 20.000000000000014, 80.89999999999955, -89.20000000000014, 20.000000000000014, -7.300000000000042, -112.30000000000067, 29.000000000000163, 20.000000000000014, 20.000000000000014, 20.000000000000014, -154.30000000000024, -60.399999999999935, -309.70000000000005, -204.70000000000027, -12.100000000000009, 46.10000000000023, -27.399999999999828, 20.000000000000014, -34.59999999999978, -36.699999999999854, 9.499999999999982, 20.000000000000014, 110.89999999999944, -42.099999999999824, 65.8999999999999, -129.10000000000073, 15.499999999999963, -7.299999999999891, 36.200000000000244, -72.40000000000086, 3.199999999999974, 17.899999999999988, 20.000000000000014, -64.00000000000028, 17.300000000000033, 31.400000000000198, 20.000000000000014, 13.699999999999992, -198.40000000000052, 98.29999999999964, 20.000000000000014, -32.49999999999985, 71.29999999999968, -198.40000000000055, -116.50000000000077, 15.799999999999963, -25.599999999999767, 42.50000000000025, -66.1000000000009, 51.500000000000234, -259.3000000000003, 34.400000000000155, -157.60000000000048, 20.000000000000014, 56.00000000000023, 58.399999999999885, 5.299999999999969], "policy_predator_policy_reward": [0.0, 0.0, 102.0, 129.0, 77.0, 0.0, 101.0, 0.0, 0.0, 0.0, 108.0, 0.0, 111.0, 105.0, 3.0, 44.0, 20.0, 39.0, 30.0, 33.0, 0.0, 0.0, 153.0, 59.0, 0.0, 64.0, 21.0, 98.0, 0.0, 0.0, 0.0, 0.0, 16.0, 34.0, 145.0, 0.0, 0.0, 4.0, 56.0, 0.0, 0.0, 62.0, 52.0, 93.0, 0.0, 100.0, 72.0, 1.0, 47.0, 157.0, 81.0, 56.0, 1.0, 0.0, 64.0, 107.0, 6.0, 5.0, 14.0, 169.0, 10.0, 11.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 4.0, 0.0, 62.0, 20.0, 21.0, 0.0, 5.0, 60.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 106.0, 64.0, 0.0, 0.0, 0.0, 0.0, 2.0, 53.0, 12.0, 31.0, 71.0, 39.0, 92.0, 83.0, 30.0, 43.0, 42.0, 79.0, 13.0, 0.0, 1.0, 82.0, 5.0, 11.0, 7.0, 0.0, 38.0, 42.0, 55.0, 58.0, 7.0, 0.0, 19.0, 65.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 43.0, 40.0, 75.0, 12.0, 12.0, 11.0, 16.0, 25.0, 4.0, 5.0, 0.0, 29.0, 32.0, 74.0, 0.0, 119.0, 0.0, 16.0, 52.0, 0.0, 13.0, 0.0, 63.0, 0.0, 0.0, 83.0, 36.0, 128.0, 88.0, 85.0, 73.0, 32.0, 15.0, 0.0, 26.0, 30.0, 0.0, 0.0, 0.0, 21.0, 15.0, 71.0, 0.0, 0.0, 13.0, 44.0, 8.0, 0.0, 1.0, 40.0, 25.0, 0.0, 10.0, 104.0, 30.0, 0.0, 0.0, 25.0, 0.0, 0.0, 104.0, 26.0, 4.0, 0.0, 41.0, 88.0, 45.0, 47.0, 48.0, 0.0, 0.0, 0.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8731539184349864, "mean_inference_ms": 2.2901798350136717, "mean_action_processing_ms": 0.34245369760600114, "mean_env_wait_ms": 0.310663850701179, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015552282333374023, "StateBufferConnector_ms": 0.0034401416778564453, "ViewRequirementAgentConnector_ms": 0.13425087928771973}, "num_episodes": 18, "episode_return_max": 260.19999999999993, "episode_return_min": -282.49999999999767, "episode_return_mean": 24.54799999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 378.84951722768733, "num_env_steps_trained_throughput_per_sec": 378.84951722768733, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 14370.48, "restore_workers_time_ms": 0.035, "training_step_time_ms": 14370.373, "sample_time_ms": 1717.482, "learn_time_ms": 12634.367, "learn_throughput": 316.597, "synch_weights_time_ms": 14.871}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "3a355_00000", "date": "2024-08-13_01-11-30", "timestamp": 1723525890, "time_this_iter_s": 10.614092826843262, "time_total_s": 101.00878667831421, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dc7dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 101.00878667831421, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 52.800000000000004, "ram_util_percent": 82.67333333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.25259441757407136, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6330006167371438, "policy_loss": -0.001964928057271416, "vf_loss": 1.6347090885437354, "vf_explained_var": 0.0007786296662830171, "kl": 0.005129185380749359, "entropy": 1.5079249031960018, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3116981845053415, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3809503565389645, "policy_loss": -0.0013632631491100977, "vf_loss": 3.3813483108288396, "vf_explained_var": 0.01080540800220752, "kl": 0.006435420380600431, "entropy": 1.6032867105549606, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 260.19999999999993, "episode_reward_min": -210.9000000000013, "episode_reward_mean": 32.65399999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -336.09999999999957, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 195.49999999999997, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": -8.578000000000062, "predator_policy": 24.905}, "custom_metrics": {}, "hist_stats": {"episode_reward": [91.39999999999891, -47.70000000000133, 22.2000000000003, -109.60000000000039, -26.200000000000202, -14.199999999999699, -112.10000000000068, -59.40000000000052, 102.79999999999939, -96.1999999999999, 137.69999999999936, -131.90000000000057, 133.89999999999924, 40.9000000000003, 34.100000000000236, 247.89999999999944, 50.00000000000041, -27.299999999999777, 112.79999999999973, 90.30000000000013, -8.899999999999928, 80.49999999999918, 260.19999999999993, 40.0000000000003, 40.0000000000003, -102.70000000000078, 9.20000000000027, 190.29999999999893, 94.49999999999973, -15.29999999999957, -37.99999999999987, 23.699999999999598, 31.80000000000002, 86.59999999999991, 10.79999999999999, 99.19999999999891, 67.59999999999954, 141.69999999999922, 100.1999999999995, 45.80000000000019, 75.59999999999974, 73.99999999999972, -60.600000000001, 70.7, 58.00000000000051, 36.80000000000041, -6.399999999999922, 54.09999999999921, 21.100000000000005, 26.4000000000001, 45.30000000000035, 26.000000000000234, -125.40000000000029, -90.9000000000003, 59.69999999999955, 25.70000000000005, -20.299999999999635, 40.0000000000003, -15.299999999999912, -154.0999999999999, -58.79999999999986, 65.70000000000023, 11.399999999999984, 2.7999999999999505, 130.8999999999987, 59.80000000000005, -42.59999999999962, 41.90000000000033, -17.199999999999534, 38.900000000000276, 18.30000000000007, 61.400000000000446, -50.700000000000145, 118.29999999999912, 63.80000000000042, -210.9000000000013, 20.19999999999998, 17.39999999999994, -74.79999999999984, -28.199999999999726, 75.99999999999963, 81.69999999999875, 24.20000000000005, 85.49999999999899, 61.60000000000029, 148.1999999999996, -36.099999999999575, 87.2999999999988, 189.199999999999, 70.59999999999997, -5.8999999999999595, 23.500000000000043, 122.49999999999922, 147.99999999999935, 54.4000000000005, -3.5999999999997594, -9.49999999999998, 106.59999999999974, 76.8999999999995, 59.70000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 67.40000000000002, -54.40000000000012, -49.29999999999976, 65.90000000000008, -105.70000000000029, -79.30000000000024, -175.30000000000015, -125.19999999999999, -0.9999999999999992, -105.10000000000021, 17.899999999999988, 20.000000000000014, -336.09999999999957, -150.10000000000056, -46.30000000000018, 27.20000000000009, 74.5999999999998, -116.19999999999995, -151.00000000000009, 114.7999999999999, 11.899999999999967, -334.89999999999964, 20.000000000000014, 92.89999999999972, 20.000000000000014, 20.900000000000013, 20.000000000000014, -10.899999999999878, 20.000000000000014, 195.49999999999997, 52.40000000000003, 26.000000000000114, 20.000000000000014, 20.000000000000014, -109.30000000000041, -17.79999999999974, 89.59999999999994, 65.30000000000014, 20.000000000000014, -89.80000000000044, 20.90000000000003, 20.000000000000014, 60.500000000000156, 151.39999999999998, 102.79999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -148.90000000000012, -59.800000000000196, 31.700000000000156, -86.5000000000006, 78.50000000000017, 111.79999999999984, 20.000000000000014, 72.49999999999986, 4.700000000000115, -85.00000000000085, -21.4, -118.60000000000008, 33.49999999999986, -140.80000000000038, -57.69999999999998, -23.499999999999968, -87.4000000000002, 88.99999999999994, -74.50000000000051, -6.6999999999999975, 78.19999999999973, 20.000000000000014, 132.79999999999973, -152.20000000000047, 68.29999999999998, 55.400000000000176, 71.5999999999998, -9.399999999999897, -95.5, 44.30000000000017, 86.59999999999928, -76.0000000000006, 35.00000000000017, 20.000000000000014, -46.899999999999814, -78.70000000000059, 45.800000000000225, 20.900000000000027, 20.000000000000014, 38.000000000000256, 20.000000000000014, -26.199999999999847, -22.59999999999981, -98.80000000000018, 60.50000000000016, -30.400000000000027, 7.699999999999971, -13.599999999999783, 20.000000000000014, -22.599999999999802, 20.30000000000002, 20.000000000000014, 35.300000000000054, -70.30000000000044, -89.20000000000023, -110.20000000000016, -229.90000000000043, 20.000000000000014, 80.89999999999955, -89.20000000000014, 20.000000000000014, -7.300000000000042, -112.30000000000067, 29.000000000000163, 20.000000000000014, 20.000000000000014, 20.000000000000014, -154.30000000000024, -60.399999999999935, -309.70000000000005, -204.70000000000027, -12.100000000000009, 46.10000000000023, -27.399999999999828, 20.000000000000014, -34.59999999999978, -36.699999999999854, 9.499999999999982, 20.000000000000014, 110.89999999999944, -42.099999999999824, 65.8999999999999, -129.10000000000073, 15.499999999999963, -7.299999999999891, 36.200000000000244, -72.40000000000086, 3.199999999999974, 17.899999999999988, 20.000000000000014, -64.00000000000028, 17.300000000000033, 31.400000000000198, 20.000000000000014, 13.699999999999992, -198.40000000000052, 98.29999999999964, 20.000000000000014, -32.49999999999985, 71.29999999999968, -198.40000000000055, -116.50000000000077, 15.799999999999963, -25.599999999999767, 42.50000000000025, -66.1000000000009, 51.500000000000234, -259.3000000000003, 34.400000000000155, -157.60000000000048, 20.000000000000014, 56.00000000000023, 58.399999999999885, 5.299999999999969, 20.000000000000014, -11.799999999999828, -34.89999999999976, 79.3999999999995, 32.60000000000015, 20.000000000000014, 29.000000000000135, 93.2, -113.50000000000043, 13.399999999999945, 20.000000000000014, 65.30000000000011, 57.20000000000001, 100.99999999999937, 9.499999999999986, 52.1000000000002, 20.000000000000014, -97.90000000000049, 20.000000000000014, -11.499999999999837, 7.399999999999965, 109.09999999999971, 127.99999999999991, 20.000000000000014, 20.000000000000014, 34.40000000000025, 5.299999999999974, -40.89999999999978, -72.40000000000018, 17.899999999999988, 20.000000000000014, 68.60000000000008, 20.000000000000014, 56.90000000000005, 35.30000000000025, 19.4], "policy_predator_policy_reward": [0.0, 4.0, 56.0, 0.0, 0.0, 62.0, 52.0, 93.0, 0.0, 100.0, 72.0, 1.0, 47.0, 157.0, 81.0, 56.0, 1.0, 0.0, 64.0, 107.0, 6.0, 5.0, 14.0, 169.0, 10.0, 11.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 4.0, 0.0, 62.0, 20.0, 21.0, 0.0, 5.0, 60.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 106.0, 64.0, 0.0, 0.0, 0.0, 0.0, 2.0, 53.0, 12.0, 31.0, 71.0, 39.0, 92.0, 83.0, 30.0, 43.0, 42.0, 79.0, 13.0, 0.0, 1.0, 82.0, 5.0, 11.0, 7.0, 0.0, 38.0, 42.0, 55.0, 58.0, 7.0, 0.0, 19.0, 65.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 43.0, 40.0, 75.0, 12.0, 12.0, 11.0, 16.0, 25.0, 4.0, 5.0, 0.0, 29.0, 32.0, 74.0, 0.0, 119.0, 0.0, 16.0, 52.0, 0.0, 13.0, 0.0, 63.0, 0.0, 0.0, 83.0, 36.0, 128.0, 88.0, 85.0, 73.0, 32.0, 15.0, 0.0, 26.0, 30.0, 0.0, 0.0, 0.0, 21.0, 15.0, 71.0, 0.0, 0.0, 13.0, 44.0, 8.0, 0.0, 1.0, 40.0, 25.0, 0.0, 10.0, 104.0, 30.0, 0.0, 0.0, 25.0, 0.0, 0.0, 104.0, 26.0, 4.0, 0.0, 41.0, 88.0, 45.0, 47.0, 48.0, 0.0, 0.0, 0.0, 18.0, 0.0, 16.0, 16.0, 25.0, 9.0, 0.0, 0.0, 26.0, 31.0, 33.0, 2.0, 0.0, 13.0, 18.0, 0.0, 9.0, 0.0, 72.0, 0.0, 15.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 45.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8501416526630641, "mean_inference_ms": 2.215308493043423, "mean_action_processing_ms": 0.33406191869417223, "mean_env_wait_ms": 0.29834610467720873, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015230655670166016, "StateBufferConnector_ms": 0.003634214401245117, "ViewRequirementAgentConnector_ms": 0.1322535276412964}, "num_episodes": 18, "episode_return_max": 260.19999999999993, "episode_return_min": -210.9000000000013, "episode_return_mean": 32.65399999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 342.17695491027706, "num_env_steps_trained_throughput_per_sec": 342.17695491027706, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 14035.403, "restore_workers_time_ms": 0.032, "training_step_time_ms": 14035.304, "sample_time_ms": 1729.691, "learn_time_ms": 12286.655, "learn_throughput": 325.556, "synch_weights_time_ms": 15.271}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "3a355_00000", "date": "2024-08-13_01-11-42", "timestamp": 1723525902, "time_this_iter_s": 11.735312223434448, "time_total_s": 112.74409890174866, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3de34c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 112.74409890174866, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 55.36875, "ram_util_percent": 82.1875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.22164501956609822, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0757435102311392, "policy_loss": -0.001130093987439833, "vf_loss": 3.076693025467888, "vf_explained_var": 0.00048599328313555037, "kl": 0.0036115503947585386, "entropy": 1.5231690290743711, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.39073596334962, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.817341051656733, "policy_loss": -0.007745618202659504, "vf_loss": 4.822595263032055, "vf_explained_var": 0.011105025413805845, "kl": 0.01660936454388883, "entropy": 1.5775172729340812, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 260.19999999999993, "episode_reward_min": -210.9000000000013, "episode_reward_mean": 37.148999999999866, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -336.99999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 151.39999999999998, "predator_policy": 163.0}, "policy_reward_mean": {"prey_policy": -5.735500000000072, "predator_policy": 24.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [260.19999999999993, 40.0000000000003, 40.0000000000003, -102.70000000000078, 9.20000000000027, 190.29999999999893, 94.49999999999973, -15.29999999999957, -37.99999999999987, 23.699999999999598, 31.80000000000002, 86.59999999999991, 10.79999999999999, 99.19999999999891, 67.59999999999954, 141.69999999999922, 100.1999999999995, 45.80000000000019, 75.59999999999974, 73.99999999999972, -60.600000000001, 70.7, 58.00000000000051, 36.80000000000041, -6.399999999999922, 54.09999999999921, 21.100000000000005, 26.4000000000001, 45.30000000000035, 26.000000000000234, -125.40000000000029, -90.9000000000003, 59.69999999999955, 25.70000000000005, -20.299999999999635, 40.0000000000003, -15.299999999999912, -154.0999999999999, -58.79999999999986, 65.70000000000023, 11.399999999999984, 2.7999999999999505, 130.8999999999987, 59.80000000000005, -42.59999999999962, 41.90000000000033, -17.199999999999534, 38.900000000000276, 18.30000000000007, 61.400000000000446, -50.700000000000145, 118.29999999999912, 63.80000000000042, -210.9000000000013, 20.19999999999998, 17.39999999999994, -74.79999999999984, -28.199999999999726, 75.99999999999963, 81.69999999999875, 24.20000000000005, 85.49999999999899, 61.60000000000029, 148.1999999999996, -36.099999999999575, 87.2999999999988, 189.199999999999, 70.59999999999997, -5.8999999999999595, 23.500000000000043, 122.49999999999922, 147.99999999999935, 54.4000000000005, -3.5999999999997594, -9.49999999999998, 106.59999999999974, 76.8999999999995, 59.70000000000045, 179.79999999999953, 36.8000000000003, -18.59999999999986, 40.0000000000003, 125.09999999999982, 170.99999999999972, -20.29999999999974, 24.600000000000072, -124.00000000000077, 54.40000000000052, 6.000000000000018, 129.09999999999914, 0.6000000000000757, 164.19999999999865, 51.50000000000046, 32.000000000000185, 12.799999999999883, 120.09999999999957, 79.19999999999924, 52.200000000000266, -48.899999999999764, -107.10000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [151.39999999999998, 102.79999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -148.90000000000012, -59.800000000000196, 31.700000000000156, -86.5000000000006, 78.50000000000017, 111.79999999999984, 20.000000000000014, 72.49999999999986, 4.700000000000115, -85.00000000000085, -21.4, -118.60000000000008, 33.49999999999986, -140.80000000000038, -57.69999999999998, -23.499999999999968, -87.4000000000002, 88.99999999999994, -74.50000000000051, -6.6999999999999975, 78.19999999999973, 20.000000000000014, 132.79999999999973, -152.20000000000047, 68.29999999999998, 55.400000000000176, 71.5999999999998, -9.399999999999897, -95.5, 44.30000000000017, 86.59999999999928, -76.0000000000006, 35.00000000000017, 20.000000000000014, -46.899999999999814, -78.70000000000059, 45.800000000000225, 20.900000000000027, 20.000000000000014, 38.000000000000256, 20.000000000000014, -26.199999999999847, -22.59999999999981, -98.80000000000018, 60.50000000000016, -30.400000000000027, 7.699999999999971, -13.599999999999783, 20.000000000000014, -22.599999999999802, 20.30000000000002, 20.000000000000014, 35.300000000000054, -70.30000000000044, -89.20000000000023, -110.20000000000016, -229.90000000000043, 20.000000000000014, 80.89999999999955, -89.20000000000014, 20.000000000000014, -7.300000000000042, -112.30000000000067, 29.000000000000163, 20.000000000000014, 20.000000000000014, 20.000000000000014, -154.30000000000024, -60.399999999999935, -309.70000000000005, -204.70000000000027, -12.100000000000009, 46.10000000000023, -27.399999999999828, 20.000000000000014, -34.59999999999978, -36.699999999999854, 9.499999999999982, 20.000000000000014, 110.89999999999944, -42.099999999999824, 65.8999999999999, -129.10000000000073, 15.499999999999963, -7.299999999999891, 36.200000000000244, -72.40000000000086, 3.199999999999974, 17.899999999999988, 20.000000000000014, -64.00000000000028, 17.300000000000033, 31.400000000000198, 20.000000000000014, 13.699999999999992, -198.40000000000052, 98.29999999999964, 20.000000000000014, -32.49999999999985, 71.29999999999968, -198.40000000000055, -116.50000000000077, 15.799999999999963, -25.599999999999767, 42.50000000000025, -66.1000000000009, 51.500000000000234, -259.3000000000003, 34.400000000000155, -157.60000000000048, 20.000000000000014, 56.00000000000023, 58.399999999999885, 5.299999999999969, 20.000000000000014, -11.799999999999828, -34.89999999999976, 79.3999999999995, 32.60000000000015, 20.000000000000014, 29.000000000000135, 93.2, -113.50000000000043, 13.399999999999945, 20.000000000000014, 65.30000000000011, 57.20000000000001, 100.99999999999937, 9.499999999999986, 52.1000000000002, 20.000000000000014, -97.90000000000049, 20.000000000000014, -11.499999999999837, 7.399999999999965, 109.09999999999971, 127.99999999999991, 20.000000000000014, 20.000000000000014, 34.40000000000025, 5.299999999999974, -40.89999999999978, -72.40000000000018, 17.899999999999988, 20.000000000000014, 68.60000000000008, 20.000000000000014, 56.90000000000005, 35.30000000000025, 19.4, 104.6, 63.200000000000216, -48.99999999999986, 12.799999999999962, -103.90000000000049, 26.300000000000118, 20.000000000000014, 20.000000000000014, 47.0, 13.099999999999966, 78.5, 81.49999999999991, -102.70000000000039, 7.3999999999999915, 20.000000000000014, -9.399999999999912, 20.000000000000014, -336.99999999999966, 23.600000000000065, 30.800000000000196, -47.19999999999976, -8.799999999999942, 36.2, 92.89999999999955, 23.300000000000182, -75.70000000000084, 46.10000000000024, 118.09999999999948, 20.000000000000014, 12.499999999999988, 56.00000000000023, -64.00000000000088, -91.00000000000013, 21.800000000000047, -19.30000000000002, -64.59999999999992, 13.699999999999964, 45.500000000000135, 6.8000000000000345, 25.400000000000098, -109.00000000000036, -16.899999999999842, -208.0000000000001, -66.1000000000009], "policy_predator_policy_reward": [0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 106.0, 64.0, 0.0, 0.0, 0.0, 0.0, 2.0, 53.0, 12.0, 31.0, 71.0, 39.0, 92.0, 83.0, 30.0, 43.0, 42.0, 79.0, 13.0, 0.0, 1.0, 82.0, 5.0, 11.0, 7.0, 0.0, 38.0, 42.0, 55.0, 58.0, 7.0, 0.0, 19.0, 65.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 43.0, 40.0, 75.0, 12.0, 12.0, 11.0, 16.0, 25.0, 4.0, 5.0, 0.0, 29.0, 32.0, 74.0, 0.0, 119.0, 0.0, 16.0, 52.0, 0.0, 13.0, 0.0, 63.0, 0.0, 0.0, 83.0, 36.0, 128.0, 88.0, 85.0, 73.0, 32.0, 15.0, 0.0, 26.0, 30.0, 0.0, 0.0, 0.0, 21.0, 15.0, 71.0, 0.0, 0.0, 13.0, 44.0, 8.0, 0.0, 1.0, 40.0, 25.0, 0.0, 10.0, 104.0, 30.0, 0.0, 0.0, 25.0, 0.0, 0.0, 104.0, 26.0, 4.0, 0.0, 41.0, 88.0, 45.0, 47.0, 48.0, 0.0, 0.0, 0.0, 18.0, 0.0, 16.0, 16.0, 25.0, 9.0, 0.0, 0.0, 26.0, 31.0, 33.0, 2.0, 0.0, 13.0, 18.0, 0.0, 9.0, 0.0, 72.0, 0.0, 15.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 45.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 5.0, 34.0, 39.0, 59.0, 0.0, 0.0, 0.0, 32.0, 33.0, 11.0, 0.0, 48.0, 27.0, 0.0, 14.0, 163.0, 30.0, 0.0, 0.0, 30.0, 32.0, 0.0, 0.0, 7.0, 46.0, 0.0, 0.0, 0.0, 19.0, 0.0, 40.0, 77.0, 5.0, 94.0, 110.0, 20.0, 0.0, 20.0, 0.0, 0.0, 77.0, 63.0, 104.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.846740451469767, "mean_inference_ms": 2.1908717829969397, "mean_action_processing_ms": 0.3320665160205775, "mean_env_wait_ms": 0.2918921185810138, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008888959884643555, "StateBufferConnector_ms": 0.003949761390686035, "ViewRequirementAgentConnector_ms": 0.13214445114135742}, "num_episodes": 22, "episode_return_max": 260.19999999999993, "episode_return_min": -210.9000000000013, "episode_return_mean": 37.148999999999866, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 301.0377477491541, "num_env_steps_trained_throughput_per_sec": 301.0377477491541, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 13952.289, "restore_workers_time_ms": 0.03, "training_step_time_ms": 13952.196, "sample_time_ms": 1760.701, "learn_time_ms": 12172.596, "learn_throughput": 328.607, "synch_weights_time_ms": 15.166}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "3a355_00000", "date": "2024-08-13_01-11-55", "timestamp": 1723525915, "time_this_iter_s": 13.316898822784424, "time_total_s": 126.06099772453308, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dc7b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 126.06099772453308, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 58.22631578947368, "ram_util_percent": 81.57368421052632}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27399080689779665, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.28985055107919, "policy_loss": -0.0051270975822474436, "vf_loss": 1.2946033937748147, "vf_explained_var": 0.003749222824813197, "kl": 0.014970207874998961, "entropy": 1.478463614617706, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3868785408202302, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.209203262303872, "policy_loss": -0.00222991681583817, "vf_loss": 3.210151927370243, "vf_explained_var": 0.06480138434304131, "kl": 0.008541579229539643, "entropy": 1.5769928840102343, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 314.2000000000005, "episode_reward_min": -210.9000000000013, "episode_reward_mean": 39.782999999999916, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -336.99999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 163.9999999999998, "predator_policy": 163.0}, "policy_reward_mean": {"prey_policy": -1.5235000000000445, "predator_policy": 21.415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.80000000000041, -6.399999999999922, 54.09999999999921, 21.100000000000005, 26.4000000000001, 45.30000000000035, 26.000000000000234, -125.40000000000029, -90.9000000000003, 59.69999999999955, 25.70000000000005, -20.299999999999635, 40.0000000000003, -15.299999999999912, -154.0999999999999, -58.79999999999986, 65.70000000000023, 11.399999999999984, 2.7999999999999505, 130.8999999999987, 59.80000000000005, -42.59999999999962, 41.90000000000033, -17.199999999999534, 38.900000000000276, 18.30000000000007, 61.400000000000446, -50.700000000000145, 118.29999999999912, 63.80000000000042, -210.9000000000013, 20.19999999999998, 17.39999999999994, -74.79999999999984, -28.199999999999726, 75.99999999999963, 81.69999999999875, 24.20000000000005, 85.49999999999899, 61.60000000000029, 148.1999999999996, -36.099999999999575, 87.2999999999988, 189.199999999999, 70.59999999999997, -5.8999999999999595, 23.500000000000043, 122.49999999999922, 147.99999999999935, 54.4000000000005, -3.5999999999997594, -9.49999999999998, 106.59999999999974, 76.8999999999995, 59.70000000000045, 179.79999999999953, 36.8000000000003, -18.59999999999986, 40.0000000000003, 125.09999999999982, 170.99999999999972, -20.29999999999974, 24.600000000000072, -124.00000000000077, 54.40000000000052, 6.000000000000018, 129.09999999999914, 0.6000000000000757, 164.19999999999865, 51.50000000000046, 32.000000000000185, 12.799999999999883, 120.09999999999957, 79.19999999999924, 52.200000000000266, -48.899999999999764, -107.10000000000036, 79.59999999999937, 81.8999999999991, 59.80000000000048, 40.0000000000003, 66.00000000000026, 197.79999999999902, 76.89999999999957, 41.50000000000033, -26.499999999999766, 75.9999999999995, 132.49999999999957, 314.2000000000005, -18.59999999999958, 49.6000000000004, 41.60000000000018, 53.500000000000405, 131.19999999999885, -49.39999999999987, 44.80000000000013, 57.60000000000016, 40.0000000000003, 34.90000000000022, 41.800000000000324], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -26.199999999999847, -22.59999999999981, -98.80000000000018, 60.50000000000016, -30.400000000000027, 7.699999999999971, -13.599999999999783, 20.000000000000014, -22.599999999999802, 20.30000000000002, 20.000000000000014, 35.300000000000054, -70.30000000000044, -89.20000000000023, -110.20000000000016, -229.90000000000043, 20.000000000000014, 80.89999999999955, -89.20000000000014, 20.000000000000014, -7.300000000000042, -112.30000000000067, 29.000000000000163, 20.000000000000014, 20.000000000000014, 20.000000000000014, -154.30000000000024, -60.399999999999935, -309.70000000000005, -204.70000000000027, -12.100000000000009, 46.10000000000023, -27.399999999999828, 20.000000000000014, -34.59999999999978, -36.699999999999854, 9.499999999999982, 20.000000000000014, 110.89999999999944, -42.099999999999824, 65.8999999999999, -129.10000000000073, 15.499999999999963, -7.299999999999891, 36.200000000000244, -72.40000000000086, 3.199999999999974, 17.899999999999988, 20.000000000000014, -64.00000000000028, 17.300000000000033, 31.400000000000198, 20.000000000000014, 13.699999999999992, -198.40000000000052, 98.29999999999964, 20.000000000000014, -32.49999999999985, 71.29999999999968, -198.40000000000055, -116.50000000000077, 15.799999999999963, -25.599999999999767, 42.50000000000025, -66.1000000000009, 51.500000000000234, -259.3000000000003, 34.400000000000155, -157.60000000000048, 20.000000000000014, 56.00000000000023, 58.399999999999885, 5.299999999999969, 20.000000000000014, -11.799999999999828, -34.89999999999976, 79.3999999999995, 32.60000000000015, 20.000000000000014, 29.000000000000135, 93.2, -113.50000000000043, 13.399999999999945, 20.000000000000014, 65.30000000000011, 57.20000000000001, 100.99999999999937, 9.499999999999986, 52.1000000000002, 20.000000000000014, -97.90000000000049, 20.000000000000014, -11.499999999999837, 7.399999999999965, 109.09999999999971, 127.99999999999991, 20.000000000000014, 20.000000000000014, 34.40000000000025, 5.299999999999974, -40.89999999999978, -72.40000000000018, 17.899999999999988, 20.000000000000014, 68.60000000000008, 20.000000000000014, 56.90000000000005, 35.30000000000025, 19.4, 104.6, 63.200000000000216, -48.99999999999986, 12.799999999999962, -103.90000000000049, 26.300000000000118, 20.000000000000014, 20.000000000000014, 47.0, 13.099999999999966, 78.5, 81.49999999999991, -102.70000000000039, 7.3999999999999915, 20.000000000000014, -9.399999999999912, 20.000000000000014, -336.99999999999966, 23.600000000000065, 30.800000000000196, -47.19999999999976, -8.799999999999942, 36.2, 92.89999999999955, 23.300000000000182, -75.70000000000084, 46.10000000000024, 118.09999999999948, 20.000000000000014, 12.499999999999988, 56.00000000000023, -64.00000000000088, -91.00000000000013, 21.800000000000047, -19.30000000000002, -64.59999999999992, 13.699999999999964, 45.500000000000135, 6.8000000000000345, 25.400000000000098, -109.00000000000036, -16.899999999999842, -208.0000000000001, -66.1000000000009, 20.000000000000014, 59.60000000000022, -21.999999999999808, 83.89999999999952, 39.80000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, -17.79999999999979, 60.80000000000019, 94.69999999999956, 100.09999999999943, 56.900000000000226, 20.000000000000014, 20.000000000000014, 6.499999999999975, -92.80000000000042, -15.699999999999747, 22.700000000000053, 53.30000000000017, 20.600000000000044, 47.90000000000008, 163.9999999999998, 144.1999999999998, -11.499999999999833, -66.1000000000002, -40.89999999999976, 57.5000000000002, 2.599999999999989, 20.000000000000014, 20.000000000000014, 33.5000000000002, 65.90000000000008, 44.30000000000014, 20.000000000000014, -207.40000000000003, 0.4999999999999635, 5.300000000000028, 3.1999999999999615, 16.399999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, -6.100000000000023, 21.80000000000004, 20.000000000000014], "policy_predator_policy_reward": [0.0, 43.0, 40.0, 75.0, 12.0, 12.0, 11.0, 16.0, 25.0, 4.0, 5.0, 0.0, 29.0, 32.0, 74.0, 0.0, 119.0, 0.0, 16.0, 52.0, 0.0, 13.0, 0.0, 63.0, 0.0, 0.0, 83.0, 36.0, 128.0, 88.0, 85.0, 73.0, 32.0, 15.0, 0.0, 26.0, 30.0, 0.0, 0.0, 0.0, 21.0, 15.0, 71.0, 0.0, 0.0, 13.0, 44.0, 8.0, 0.0, 1.0, 40.0, 25.0, 0.0, 10.0, 104.0, 30.0, 0.0, 0.0, 25.0, 0.0, 0.0, 104.0, 26.0, 4.0, 0.0, 41.0, 88.0, 45.0, 47.0, 48.0, 0.0, 0.0, 0.0, 18.0, 0.0, 16.0, 16.0, 25.0, 9.0, 0.0, 0.0, 26.0, 31.0, 33.0, 2.0, 0.0, 13.0, 18.0, 0.0, 9.0, 0.0, 72.0, 0.0, 15.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 45.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 5.0, 34.0, 39.0, 59.0, 0.0, 0.0, 0.0, 32.0, 33.0, 11.0, 0.0, 48.0, 27.0, 0.0, 14.0, 163.0, 30.0, 0.0, 0.0, 30.0, 32.0, 0.0, 0.0, 7.0, 46.0, 0.0, 0.0, 0.0, 19.0, 0.0, 40.0, 77.0, 5.0, 94.0, 110.0, 20.0, 0.0, 20.0, 0.0, 0.0, 77.0, 63.0, 104.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 3.0, 0.0, 0.0, 15.0, 0.0, 4.0, 78.0, 0.0, 0.0, 34.0, 30.0, 0.0, 6.0, 18.0, 41.0, 4.0, 29.0, 0.0, 19.0, 0.0, 0.0, 15.0, 6.0, 108.0, 30.0, 39.0, 0.0, 10.0, 28.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8684496118773629, "mean_inference_ms": 2.235645412756823, "mean_action_processing_ms": 0.337943393711975, "mean_env_wait_ms": 0.29246404577889346, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005840659141540527, "StateBufferConnector_ms": 0.006654977798461914, "ViewRequirementAgentConnector_ms": 0.17036938667297363}, "num_episodes": 23, "episode_return_max": 314.2000000000005, "episode_return_min": -210.9000000000013, "episode_return_mean": 39.782999999999916, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 25.086897722229182, "num_env_steps_trained_throughput_per_sec": 25.086897722229182, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 28501.639, "restore_workers_time_ms": 0.029, "training_step_time_ms": 28501.551, "sample_time_ms": 1887.813, "learn_time_ms": 26592.94, "learn_throughput": 150.416, "synch_weights_time_ms": 16.998}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "3a355_00000", "date": "2024-08-13_01-14-35", "timestamp": 1723526075, "time_this_iter_s": 159.64819812774658, "time_total_s": 285.70919585227966, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df8940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 285.70919585227966, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 80.72647058823527, "ram_util_percent": 83.80588235294118}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.30506040660674294, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.22430883008967, "policy_loss": -0.001317429249963314, "vf_loss": 2.2255164281401054, "vf_explained_var": 0.007476597330557606, "kl": 0.004393411808908279, "entropy": 1.4395081873293276, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2936507766957952, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.658968277456899, "policy_loss": -0.0014128907726555274, "vf_loss": 3.659440271059672, "vf_explained_var": 0.007442938051526508, "kl": 0.0062726346633508985, "entropy": 1.5653662239432966, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 314.2000000000005, "episode_reward_min": -210.9000000000013, "episode_reward_mean": 49.074999999999875, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -336.99999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 163.9999999999998, "predator_policy": 163.0}, "policy_reward_mean": {"prey_policy": 5.742499999999955, "predator_policy": 18.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.7999999999999505, 130.8999999999987, 59.80000000000005, -42.59999999999962, 41.90000000000033, -17.199999999999534, 38.900000000000276, 18.30000000000007, 61.400000000000446, -50.700000000000145, 118.29999999999912, 63.80000000000042, -210.9000000000013, 20.19999999999998, 17.39999999999994, -74.79999999999984, -28.199999999999726, 75.99999999999963, 81.69999999999875, 24.20000000000005, 85.49999999999899, 61.60000000000029, 148.1999999999996, -36.099999999999575, 87.2999999999988, 189.199999999999, 70.59999999999997, -5.8999999999999595, 23.500000000000043, 122.49999999999922, 147.99999999999935, 54.4000000000005, -3.5999999999997594, -9.49999999999998, 106.59999999999974, 76.8999999999995, 59.70000000000045, 179.79999999999953, 36.8000000000003, -18.59999999999986, 40.0000000000003, 125.09999999999982, 170.99999999999972, -20.29999999999974, 24.600000000000072, -124.00000000000077, 54.40000000000052, 6.000000000000018, 129.09999999999914, 0.6000000000000757, 164.19999999999865, 51.50000000000046, 32.000000000000185, 12.799999999999883, 120.09999999999957, 79.19999999999924, 52.200000000000266, -48.899999999999764, -107.10000000000036, 79.59999999999937, 81.8999999999991, 59.80000000000048, 40.0000000000003, 66.00000000000026, 197.79999999999902, 76.89999999999957, 41.50000000000033, -26.499999999999766, 75.9999999999995, 132.49999999999957, 314.2000000000005, -18.59999999999958, 49.6000000000004, 41.60000000000018, 53.500000000000405, 131.19999999999885, -49.39999999999987, 44.80000000000013, 57.60000000000016, 40.0000000000003, 34.90000000000022, 41.800000000000324, 90.8999999999993, 113.69999999999911, 40.20000000000036, 40.0000000000003, 143.49999999999878, -7.300000000000038, 44.100000000000115, 14.899999999999958, 42.50000000000026, 17.19999999999999, 75.99999999999964, 26.80000000000011, 25.20000000000019, 40.0000000000003, 94.29999999999832, 44.50000000000029, 20.19999999999994, 3.5000000000000853], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-36.699999999999854, 9.499999999999982, 20.000000000000014, 110.89999999999944, -42.099999999999824, 65.8999999999999, -129.10000000000073, 15.499999999999963, -7.299999999999891, 36.200000000000244, -72.40000000000086, 3.199999999999974, 17.899999999999988, 20.000000000000014, -64.00000000000028, 17.300000000000033, 31.400000000000198, 20.000000000000014, 13.699999999999992, -198.40000000000052, 98.29999999999964, 20.000000000000014, -32.49999999999985, 71.29999999999968, -198.40000000000055, -116.50000000000077, 15.799999999999963, -25.599999999999767, 42.50000000000025, -66.1000000000009, 51.500000000000234, -259.3000000000003, 34.400000000000155, -157.60000000000048, 20.000000000000014, 56.00000000000023, 58.399999999999885, 5.299999999999969, 20.000000000000014, -11.799999999999828, -34.89999999999976, 79.3999999999995, 32.60000000000015, 20.000000000000014, 29.000000000000135, 93.2, -113.50000000000043, 13.399999999999945, 20.000000000000014, 65.30000000000011, 57.20000000000001, 100.99999999999937, 9.499999999999986, 52.1000000000002, 20.000000000000014, -97.90000000000049, 20.000000000000014, -11.499999999999837, 7.399999999999965, 109.09999999999971, 127.99999999999991, 20.000000000000014, 20.000000000000014, 34.40000000000025, 5.299999999999974, -40.89999999999978, -72.40000000000018, 17.899999999999988, 20.000000000000014, 68.60000000000008, 20.000000000000014, 56.90000000000005, 35.30000000000025, 19.4, 104.6, 63.200000000000216, -48.99999999999986, 12.799999999999962, -103.90000000000049, 26.300000000000118, 20.000000000000014, 20.000000000000014, 47.0, 13.099999999999966, 78.5, 81.49999999999991, -102.70000000000039, 7.3999999999999915, 20.000000000000014, -9.399999999999912, 20.000000000000014, -336.99999999999966, 23.600000000000065, 30.800000000000196, -47.19999999999976, -8.799999999999942, 36.2, 92.89999999999955, 23.300000000000182, -75.70000000000084, 46.10000000000024, 118.09999999999948, 20.000000000000014, 12.499999999999988, 56.00000000000023, -64.00000000000088, -91.00000000000013, 21.800000000000047, -19.30000000000002, -64.59999999999992, 13.699999999999964, 45.500000000000135, 6.8000000000000345, 25.400000000000098, -109.00000000000036, -16.899999999999842, -208.0000000000001, -66.1000000000009, 20.000000000000014, 59.60000000000022, -21.999999999999808, 83.89999999999952, 39.80000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, -17.79999999999979, 60.80000000000019, 94.69999999999956, 100.09999999999943, 56.900000000000226, 20.000000000000014, 20.000000000000014, 6.499999999999975, -92.80000000000042, -15.699999999999747, 22.700000000000053, 53.30000000000017, 20.600000000000044, 47.90000000000008, 163.9999999999998, 144.1999999999998, -11.499999999999833, -66.1000000000002, -40.89999999999976, 57.5000000000002, 2.599999999999989, 20.000000000000014, 20.000000000000014, 33.5000000000002, 65.90000000000008, 44.30000000000014, 20.000000000000014, -207.40000000000003, 0.4999999999999635, 5.300000000000028, 3.1999999999999615, 16.399999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, -6.100000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 50.9000000000001, -66.1000000000009, 138.7999999999996, -16.899999999999935, 4.0999999999999694, 20.000000000000014, 20.000000000000014, 83.89999999999999, 59.600000000000165, -70.30000000000032, 20.000000000000014, 20.000000000000014, -82.90000000000026, 14.599999999999968, -48.69999999999981, 18.20000000000001, 5.299999999999965, 37.10000000000008, -106.90000000000035, 43.400000000000226, 32.60000000000023, -50.19999999999985, -12.999999999999993, -23.799999999999784, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.300000000000246, 56.00000000000023, 20.000000000000014, 24.500000000000096, 40.70000000000025, -65.50000000000063, 83.89999999999937, -177.40000000000018], "policy_predator_policy_reward": [30.0, 0.0, 0.0, 0.0, 21.0, 15.0, 71.0, 0.0, 0.0, 13.0, 44.0, 8.0, 0.0, 1.0, 40.0, 25.0, 0.0, 10.0, 104.0, 30.0, 0.0, 0.0, 25.0, 0.0, 0.0, 104.0, 26.0, 4.0, 0.0, 41.0, 88.0, 45.0, 47.0, 48.0, 0.0, 0.0, 0.0, 18.0, 0.0, 16.0, 16.0, 25.0, 9.0, 0.0, 0.0, 26.0, 31.0, 33.0, 2.0, 0.0, 13.0, 18.0, 0.0, 9.0, 0.0, 72.0, 0.0, 15.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 45.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 5.0, 34.0, 39.0, 59.0, 0.0, 0.0, 0.0, 32.0, 33.0, 11.0, 0.0, 48.0, 27.0, 0.0, 14.0, 163.0, 30.0, 0.0, 0.0, 30.0, 32.0, 0.0, 0.0, 7.0, 46.0, 0.0, 0.0, 0.0, 19.0, 0.0, 40.0, 77.0, 5.0, 94.0, 110.0, 20.0, 0.0, 20.0, 0.0, 0.0, 77.0, 63.0, 104.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 3.0, 0.0, 0.0, 15.0, 0.0, 4.0, 78.0, 0.0, 0.0, 34.0, 30.0, 0.0, 6.0, 18.0, 41.0, 4.0, 29.0, 0.0, 19.0, 0.0, 0.0, 15.0, 6.0, 108.0, 30.0, 39.0, 0.0, 10.0, 28.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 41.0, 16.0, 37.0, 0.0, 0.0, 0.0, 0.0, 43.0, 0.0, 60.0, 47.0, 30.0, 19.0, 0.0, 19.0, 30.0, 57.0, 0.0, 0.0, 44.0, 46.0, 0.0, 29.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 0.0, 0.0, 97.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9249034734585706, "mean_inference_ms": 2.4149145477419522, "mean_action_processing_ms": 0.35979719698975626, "mean_env_wait_ms": 0.31286393149767244, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008038759231567383, "StateBufferConnector_ms": 0.011006355285644531, "ViewRequirementAgentConnector_ms": 0.2370373010635376}, "num_episodes": 18, "episode_return_max": 314.2000000000005, "episode_return_min": -210.9000000000013, "episode_return_mean": 49.074999999999875, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.80258031500665, "num_env_steps_trained_throughput_per_sec": 210.80258031500665, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 28898.962, "restore_workers_time_ms": 0.029, "training_step_time_ms": 28898.873, "sample_time_ms": 2502.389, "learn_time_ms": 26373.739, "learn_throughput": 151.666, "synch_weights_time_ms": 18.306}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "3a355_00000", "date": "2024-08-13_01-14-54", "timestamp": 1723526094, "time_this_iter_s": 19.088205099105835, "time_total_s": 304.7974009513855, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3de34c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 304.7974009513855, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 74.27777777777777, "ram_util_percent": 83.55185185185184}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3739272844815065, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.182617697766218, "policy_loss": -0.0008260346554889881, "vf_loss": 3.1833493018907215, "vf_explained_var": 0.005493425502978935, "kl": 0.007553968156832989, "entropy": 1.406766575543338, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3717148473338476, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.970113624088348, "policy_loss": -0.001306141899755747, "vf_loss": 4.970784478338938, "vf_explained_var": 0.003162124201103493, "kl": 0.0042352254804485946, "entropy": 1.5686775287623127, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 314.2000000000005, "episode_reward_min": -173.70000000000084, "episode_reward_mean": 53.045999999999886, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -336.99999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 163.9999999999998, "predator_policy": 163.0}, "policy_reward_mean": {"prey_policy": 6.667999999999963, "predator_policy": 19.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [81.69999999999875, 24.20000000000005, 85.49999999999899, 61.60000000000029, 148.1999999999996, -36.099999999999575, 87.2999999999988, 189.199999999999, 70.59999999999997, -5.8999999999999595, 23.500000000000043, 122.49999999999922, 147.99999999999935, 54.4000000000005, -3.5999999999997594, -9.49999999999998, 106.59999999999974, 76.8999999999995, 59.70000000000045, 179.79999999999953, 36.8000000000003, -18.59999999999986, 40.0000000000003, 125.09999999999982, 170.99999999999972, -20.29999999999974, 24.600000000000072, -124.00000000000077, 54.40000000000052, 6.000000000000018, 129.09999999999914, 0.6000000000000757, 164.19999999999865, 51.50000000000046, 32.000000000000185, 12.799999999999883, 120.09999999999957, 79.19999999999924, 52.200000000000266, -48.899999999999764, -107.10000000000036, 79.59999999999937, 81.8999999999991, 59.80000000000048, 40.0000000000003, 66.00000000000026, 197.79999999999902, 76.89999999999957, 41.50000000000033, -26.499999999999766, 75.9999999999995, 132.49999999999957, 314.2000000000005, -18.59999999999958, 49.6000000000004, 41.60000000000018, 53.500000000000405, 131.19999999999885, -49.39999999999987, 44.80000000000013, 57.60000000000016, 40.0000000000003, 34.90000000000022, 41.800000000000324, 90.8999999999993, 113.69999999999911, 40.20000000000036, 40.0000000000003, 143.49999999999878, -7.300000000000038, 44.100000000000115, 14.899999999999958, 42.50000000000026, 17.19999999999999, 75.99999999999964, 26.80000000000011, 25.20000000000019, 40.0000000000003, 94.29999999999832, 44.50000000000029, 20.19999999999994, 3.5000000000000853, 84.20000000000017, -15.299999999999894, 127.29999999999941, 71.49999999999953, 74.39999999999971, 163.2999999999989, -173.70000000000084, 35.80000000000024, 50.100000000000335, 62.80000000000034, 23.500000000000043, -27.099999999999575, 94.00000000000026, 21.800000000000125, 1.9999999999999607, -73.90000000000015, 20.400000000000283, 81.29999999999978], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [58.399999999999885, 5.299999999999969, 20.000000000000014, -11.799999999999828, -34.89999999999976, 79.3999999999995, 32.60000000000015, 20.000000000000014, 29.000000000000135, 93.2, -113.50000000000043, 13.399999999999945, 20.000000000000014, 65.30000000000011, 57.20000000000001, 100.99999999999937, 9.499999999999986, 52.1000000000002, 20.000000000000014, -97.90000000000049, 20.000000000000014, -11.499999999999837, 7.399999999999965, 109.09999999999971, 127.99999999999991, 20.000000000000014, 20.000000000000014, 34.40000000000025, 5.299999999999974, -40.89999999999978, -72.40000000000018, 17.899999999999988, 20.000000000000014, 68.60000000000008, 20.000000000000014, 56.90000000000005, 35.30000000000025, 19.4, 104.6, 63.200000000000216, -48.99999999999986, 12.799999999999962, -103.90000000000049, 26.300000000000118, 20.000000000000014, 20.000000000000014, 47.0, 13.099999999999966, 78.5, 81.49999999999991, -102.70000000000039, 7.3999999999999915, 20.000000000000014, -9.399999999999912, 20.000000000000014, -336.99999999999966, 23.600000000000065, 30.800000000000196, -47.19999999999976, -8.799999999999942, 36.2, 92.89999999999955, 23.300000000000182, -75.70000000000084, 46.10000000000024, 118.09999999999948, 20.000000000000014, 12.499999999999988, 56.00000000000023, -64.00000000000088, -91.00000000000013, 21.800000000000047, -19.30000000000002, -64.59999999999992, 13.699999999999964, 45.500000000000135, 6.8000000000000345, 25.400000000000098, -109.00000000000036, -16.899999999999842, -208.0000000000001, -66.1000000000009, 20.000000000000014, 59.60000000000022, -21.999999999999808, 83.89999999999952, 39.80000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, -17.79999999999979, 60.80000000000019, 94.69999999999956, 100.09999999999943, 56.900000000000226, 20.000000000000014, 20.000000000000014, 6.499999999999975, -92.80000000000042, -15.699999999999747, 22.700000000000053, 53.30000000000017, 20.600000000000044, 47.90000000000008, 163.9999999999998, 144.1999999999998, -11.499999999999833, -66.1000000000002, -40.89999999999976, 57.5000000000002, 2.599999999999989, 20.000000000000014, 20.000000000000014, 33.5000000000002, 65.90000000000008, 44.30000000000014, 20.000000000000014, -207.40000000000003, 0.4999999999999635, 5.300000000000028, 3.1999999999999615, 16.399999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, -6.100000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 50.9000000000001, -66.1000000000009, 138.7999999999996, -16.899999999999935, 4.0999999999999694, 20.000000000000014, 20.000000000000014, 83.89999999999999, 59.600000000000165, -70.30000000000032, 20.000000000000014, 20.000000000000014, -82.90000000000026, 14.599999999999968, -48.69999999999981, 18.20000000000001, 5.299999999999965, 37.10000000000008, -106.90000000000035, 43.400000000000226, 32.60000000000023, -50.19999999999985, -12.999999999999993, -23.799999999999784, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.300000000000246, 56.00000000000023, 20.000000000000014, 24.500000000000096, 40.70000000000025, -65.50000000000063, 83.89999999999937, -177.40000000000018, 23.60000000000005, -9.399999999999942, -267.6999999999991, 115.39999999999947, 97.09999999999968, -32.799999999999905, -87.10000000000039, 104.59999999999945, 46.400000000000205, 20.000000000000014, 139.69999999999965, 23.60000000000008, -135.40000000000032, -175.30000000000055, 20.000000000000014, 3.799999999999985, -32.499999999999766, 38.60000000000017, 3.8000000000001535, 20.000000000000014, -11.499999999999925, 20.000000000000014, -102.70000000000076, 11.599999999999978, 20.000000000000014, 74.00000000000018, 7.399999999999965, -76.60000000000014, -21.999999999999876, -12.999999999999813, -119.80000000000013, -78.10000000000082, -31.59999999999995, -64.00000000000087, 33.50000000000006, 6.799999999999994], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 16.0, 16.0, 25.0, 9.0, 0.0, 0.0, 26.0, 31.0, 33.0, 2.0, 0.0, 13.0, 18.0, 0.0, 9.0, 0.0, 72.0, 0.0, 15.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 45.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 5.0, 34.0, 39.0, 59.0, 0.0, 0.0, 0.0, 32.0, 33.0, 11.0, 0.0, 48.0, 27.0, 0.0, 14.0, 163.0, 30.0, 0.0, 0.0, 30.0, 32.0, 0.0, 0.0, 7.0, 46.0, 0.0, 0.0, 0.0, 19.0, 0.0, 40.0, 77.0, 5.0, 94.0, 110.0, 20.0, 0.0, 20.0, 0.0, 0.0, 77.0, 63.0, 104.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 3.0, 0.0, 0.0, 15.0, 0.0, 4.0, 78.0, 0.0, 0.0, 34.0, 30.0, 0.0, 6.0, 18.0, 41.0, 4.0, 29.0, 0.0, 19.0, 0.0, 0.0, 15.0, 6.0, 108.0, 30.0, 39.0, 0.0, 10.0, 28.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 41.0, 16.0, 37.0, 0.0, 0.0, 0.0, 0.0, 43.0, 0.0, 60.0, 47.0, 30.0, 19.0, 0.0, 19.0, 30.0, 57.0, 0.0, 0.0, 44.0, 46.0, 0.0, 29.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 0.0, 0.0, 97.0, 39.0, 31.0, 0.0, 137.0, 25.0, 38.0, 52.0, 2.0, 5.0, 3.0, 0.0, 0.0, 137.0, 0.0, 0.0, 12.0, 19.0, 25.0, 29.0, 10.0, 15.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 91.0, 1.0, 36.0, 76.0, 48.0, 82.0, 34.0, 0.0, 41.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.976948405632221, "mean_inference_ms": 2.5887663022193528, "mean_action_processing_ms": 0.38041878959446407, "mean_env_wait_ms": 0.3332351379476938, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00786900520324707, "StateBufferConnector_ms": 0.010958075523376465, "ViewRequirementAgentConnector_ms": 0.23602187633514404}, "num_episodes": 18, "episode_return_max": 314.2000000000005, "episode_return_min": -173.70000000000084, "episode_return_mean": 53.045999999999886, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 217.0843311370061, "num_env_steps_trained_throughput_per_sec": 217.0843311370061, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 29552.863, "restore_workers_time_ms": 0.014, "training_step_time_ms": 29552.816, "sample_time_ms": 2407.89, "learn_time_ms": 27120.668, "learn_throughput": 147.489, "synch_weights_time_ms": 19.11}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "3a355_00000", "date": "2024-08-13_01-15-13", "timestamp": 1723526113, "time_this_iter_s": 18.58422088623047, "time_total_s": 323.38162183761597, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d6d670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 323.38162183761597, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 73.16666666666667, "ram_util_percent": 83.56666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31021764643450894, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8535820053998755, "policy_loss": -0.0026256218458964396, "vf_loss": 2.856105714247971, "vf_explained_var": 0.0016867792480206364, "kl": 0.00815287059768446, "entropy": 1.3493453753057612, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1845768507826264, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.406518773300938, "policy_loss": -0.0023519851681258943, "vf_loss": 4.407942453515592, "vf_explained_var": 0.004244318840995668, "kl": 0.012377358706737536, "entropy": 1.527398717592633, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 314.2000000000005, "episode_reward_min": -173.70000000000084, "episode_reward_mean": 43.49799999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -336.99999999999966, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 163.9999999999998, "predator_policy": 163.0}, "policy_reward_mean": {"prey_policy": -1.6510000000000344, "predator_policy": 23.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [59.70000000000045, 179.79999999999953, 36.8000000000003, -18.59999999999986, 40.0000000000003, 125.09999999999982, 170.99999999999972, -20.29999999999974, 24.600000000000072, -124.00000000000077, 54.40000000000052, 6.000000000000018, 129.09999999999914, 0.6000000000000757, 164.19999999999865, 51.50000000000046, 32.000000000000185, 12.799999999999883, 120.09999999999957, 79.19999999999924, 52.200000000000266, -48.899999999999764, -107.10000000000036, 79.59999999999937, 81.8999999999991, 59.80000000000048, 40.0000000000003, 66.00000000000026, 197.79999999999902, 76.89999999999957, 41.50000000000033, -26.499999999999766, 75.9999999999995, 132.49999999999957, 314.2000000000005, -18.59999999999958, 49.6000000000004, 41.60000000000018, 53.500000000000405, 131.19999999999885, -49.39999999999987, 44.80000000000013, 57.60000000000016, 40.0000000000003, 34.90000000000022, 41.800000000000324, 90.8999999999993, 113.69999999999911, 40.20000000000036, 40.0000000000003, 143.49999999999878, -7.300000000000038, 44.100000000000115, 14.899999999999958, 42.50000000000026, 17.19999999999999, 75.99999999999964, 26.80000000000011, 25.20000000000019, 40.0000000000003, 94.29999999999832, 44.50000000000029, 20.19999999999994, 3.5000000000000853, 84.20000000000017, -15.299999999999894, 127.29999999999941, 71.49999999999953, 74.39999999999971, 163.2999999999989, -173.70000000000084, 35.80000000000024, 50.100000000000335, 62.80000000000034, 23.500000000000043, -27.099999999999575, 94.00000000000026, 21.800000000000125, 1.9999999999999607, -73.90000000000015, 20.400000000000283, 81.29999999999978, -46.2999999999998, 82.59999999999916, 58.59999999999981, -8.699999999999921, 13.400000000000215, 105.69999999999871, -23.500000000000057, 40.0000000000003, -56.29999999999972, 56.59999999999966, -50.79999999999975, -46.89999999999978, -39.29999999999978, 142.89999999999955, 40.0000000000003, -17.999999999999773, 112.49999999999994, -92.20000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [35.30000000000025, 19.4, 104.6, 63.200000000000216, -48.99999999999986, 12.799999999999962, -103.90000000000049, 26.300000000000118, 20.000000000000014, 20.000000000000014, 47.0, 13.099999999999966, 78.5, 81.49999999999991, -102.70000000000039, 7.3999999999999915, 20.000000000000014, -9.399999999999912, 20.000000000000014, -336.99999999999966, 23.600000000000065, 30.800000000000196, -47.19999999999976, -8.799999999999942, 36.2, 92.89999999999955, 23.300000000000182, -75.70000000000084, 46.10000000000024, 118.09999999999948, 20.000000000000014, 12.499999999999988, 56.00000000000023, -64.00000000000088, -91.00000000000013, 21.800000000000047, -19.30000000000002, -64.59999999999992, 13.699999999999964, 45.500000000000135, 6.8000000000000345, 25.400000000000098, -109.00000000000036, -16.899999999999842, -208.0000000000001, -66.1000000000009, 20.000000000000014, 59.60000000000022, -21.999999999999808, 83.89999999999952, 39.80000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, -17.79999999999979, 60.80000000000019, 94.69999999999956, 100.09999999999943, 56.900000000000226, 20.000000000000014, 20.000000000000014, 6.499999999999975, -92.80000000000042, -15.699999999999747, 22.700000000000053, 53.30000000000017, 20.600000000000044, 47.90000000000008, 163.9999999999998, 144.1999999999998, -11.499999999999833, -66.1000000000002, -40.89999999999976, 57.5000000000002, 2.599999999999989, 20.000000000000014, 20.000000000000014, 33.5000000000002, 65.90000000000008, 44.30000000000014, 20.000000000000014, -207.40000000000003, 0.4999999999999635, 5.300000000000028, 3.1999999999999615, 16.399999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, -6.100000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 50.9000000000001, -66.1000000000009, 138.7999999999996, -16.899999999999935, 4.0999999999999694, 20.000000000000014, 20.000000000000014, 83.89999999999999, 59.600000000000165, -70.30000000000032, 20.000000000000014, 20.000000000000014, -82.90000000000026, 14.599999999999968, -48.69999999999981, 18.20000000000001, 5.299999999999965, 37.10000000000008, -106.90000000000035, 43.400000000000226, 32.60000000000023, -50.19999999999985, -12.999999999999993, -23.799999999999784, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.300000000000246, 56.00000000000023, 20.000000000000014, 24.500000000000096, 40.70000000000025, -65.50000000000063, 83.89999999999937, -177.40000000000018, 23.60000000000005, -9.399999999999942, -267.6999999999991, 115.39999999999947, 97.09999999999968, -32.799999999999905, -87.10000000000039, 104.59999999999945, 46.400000000000205, 20.000000000000014, 139.69999999999965, 23.60000000000008, -135.40000000000032, -175.30000000000055, 20.000000000000014, 3.799999999999985, -32.499999999999766, 38.60000000000017, 3.8000000000001535, 20.000000000000014, -11.499999999999925, 20.000000000000014, -102.70000000000076, 11.599999999999978, 20.000000000000014, 74.00000000000018, 7.399999999999965, -76.60000000000014, -21.999999999999876, -12.999999999999813, -119.80000000000013, -78.10000000000082, -31.59999999999995, -64.00000000000087, 33.50000000000006, 6.799999999999994, -71.8000000000004, -95.50000000000003, 22.700000000000053, 56.90000000000021, 20.000000000000014, -90.39999999999999, 17.899999999999988, -106.60000000000005, -30.399999999999807, -35.20000000000004, 60.50000000000017, 45.20000000000016, 20.000000000000014, -113.50000000000011, 20.000000000000014, 20.000000000000014, -160.5999999999999, -12.699999999999857, 20.000000000000014, -15.400000000000007, -138.70000000000041, -3.100000000000047, 20.000000000000014, -145.90000000000035, -145.90000000000038, 23.600000000000076, 155.89999999999995, -42.99999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, -94.0, 28.1, 82.40000000000003, 20.000000000000014, -233.20000000000002], "policy_predator_policy_reward": [0.0, 5.0, 7.0, 5.0, 34.0, 39.0, 59.0, 0.0, 0.0, 0.0, 32.0, 33.0, 11.0, 0.0, 48.0, 27.0, 0.0, 14.0, 163.0, 30.0, 0.0, 0.0, 30.0, 32.0, 0.0, 0.0, 7.0, 46.0, 0.0, 0.0, 0.0, 19.0, 0.0, 40.0, 77.0, 5.0, 94.0, 110.0, 20.0, 0.0, 20.0, 0.0, 0.0, 77.0, 63.0, 104.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 3.0, 0.0, 0.0, 15.0, 0.0, 4.0, 78.0, 0.0, 0.0, 34.0, 30.0, 0.0, 6.0, 18.0, 41.0, 4.0, 29.0, 0.0, 19.0, 0.0, 0.0, 15.0, 6.0, 108.0, 30.0, 39.0, 0.0, 10.0, 28.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 41.0, 16.0, 37.0, 0.0, 0.0, 0.0, 0.0, 43.0, 0.0, 60.0, 47.0, 30.0, 19.0, 0.0, 19.0, 30.0, 57.0, 0.0, 0.0, 44.0, 46.0, 0.0, 29.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 0.0, 0.0, 97.0, 39.0, 31.0, 0.0, 137.0, 25.0, 38.0, 52.0, 2.0, 5.0, 3.0, 0.0, 0.0, 137.0, 0.0, 0.0, 12.0, 19.0, 25.0, 29.0, 10.0, 15.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 91.0, 1.0, 36.0, 76.0, 48.0, 82.0, 34.0, 0.0, 41.0, 0.0, 121.0, 3.0, 0.0, 84.0, 45.0, 80.0, 0.0, 79.0, 0.0, 0.0, 0.0, 50.0, 20.0, 0.0, 0.0, 95.0, 22.0, 52.0, 0.0, 49.0, 42.0, 79.0, 0.0, 0.0, 83.0, 30.0, 0.0, 0.0, 0.0, 56.0, 0.0, 2.0, 0.0, 0.0, 121.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.031879124562378, "mean_inference_ms": 2.771045757673329, "mean_action_processing_ms": 0.40127474604962077, "mean_env_wait_ms": 0.35518438814679887, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007922053337097168, "StateBufferConnector_ms": 0.011378288269042969, "ViewRequirementAgentConnector_ms": 0.24689722061157227}, "num_episodes": 18, "episode_return_max": 314.2000000000005, "episode_return_min": -173.70000000000084, "episode_return_mean": 43.49799999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 280.3906118336183, "num_env_steps_trained_throughput_per_sec": 280.3906118336183, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 29950.055, "restore_workers_time_ms": 0.014, "training_step_time_ms": 29950.005, "sample_time_ms": 2590.734, "learn_time_ms": 27333.488, "learn_throughput": 146.341, "synch_weights_time_ms": 20.99}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "3a355_00000", "date": "2024-08-13_01-15-27", "timestamp": 1723526127, "time_this_iter_s": 14.323575973510742, "time_total_s": 337.7051978111267, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d35040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 337.7051978111267, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 62.5047619047619, "ram_util_percent": 83.55714285714284}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.39675379312306486, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.802282629000447, "policy_loss": -0.0016044129647078023, "vf_loss": 2.8037903815980942, "vf_explained_var": 0.004719180120992913, "kl": 0.007732913113134313, "entropy": 1.310153372830184, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.209522365427837, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.830540524588691, "policy_loss": -0.0009494209059676717, "vf_loss": 4.831001472977734, "vf_explained_var": 0.003923331145887022, "kl": 0.006512766168180858, "entropy": 1.5426755955610325, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 314.2000000000005, "episode_reward_min": -176.79999999999976, "episode_reward_mean": 31.921999999999933, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -307.59999999999985, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 163.9999999999998, "predator_policy": 154.0}, "policy_reward_mean": {"prey_policy": -8.464000000000038, "predator_policy": 24.425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [66.00000000000026, 197.79999999999902, 76.89999999999957, 41.50000000000033, -26.499999999999766, 75.9999999999995, 132.49999999999957, 314.2000000000005, -18.59999999999958, 49.6000000000004, 41.60000000000018, 53.500000000000405, 131.19999999999885, -49.39999999999987, 44.80000000000013, 57.60000000000016, 40.0000000000003, 34.90000000000022, 41.800000000000324, 90.8999999999993, 113.69999999999911, 40.20000000000036, 40.0000000000003, 143.49999999999878, -7.300000000000038, 44.100000000000115, 14.899999999999958, 42.50000000000026, 17.19999999999999, 75.99999999999964, 26.80000000000011, 25.20000000000019, 40.0000000000003, 94.29999999999832, 44.50000000000029, 20.19999999999994, 3.5000000000000853, 84.20000000000017, -15.299999999999894, 127.29999999999941, 71.49999999999953, 74.39999999999971, 163.2999999999989, -173.70000000000084, 35.80000000000024, 50.100000000000335, 62.80000000000034, 23.500000000000043, -27.099999999999575, 94.00000000000026, 21.800000000000125, 1.9999999999999607, -73.90000000000015, 20.400000000000283, 81.29999999999978, -46.2999999999998, 82.59999999999916, 58.59999999999981, -8.699999999999921, 13.400000000000215, 105.69999999999871, -23.500000000000057, 40.0000000000003, -56.29999999999972, 56.59999999999966, -50.79999999999975, -46.89999999999978, -39.29999999999978, 142.89999999999955, 40.0000000000003, -17.999999999999773, 112.49999999999994, -92.20000000000007, 40.0000000000003, -76.10000000000007, -18.39999999999989, 51.70000000000049, 21.900000000000137, 40.600000000000364, -81.69999999999968, -79.0, 86.79999999999885, 80.69999999999997, 23.40000000000006, -164.20000000000064, 56.20000000000048, 114.09999999999897, -2.8999999999998156, -102.80000000000058, 105.39999999999884, 59.30000000000027, -24.399999999999658, 30.100000000000158, -32.79999999999981, 169.59999999999934, 61.80000000000046, -21.999999999999673, -100.00000000000111, 63.40000000000026, -176.79999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-17.79999999999979, 60.80000000000019, 94.69999999999956, 100.09999999999943, 56.900000000000226, 20.000000000000014, 20.000000000000014, 6.499999999999975, -92.80000000000042, -15.699999999999747, 22.700000000000053, 53.30000000000017, 20.600000000000044, 47.90000000000008, 163.9999999999998, 144.1999999999998, -11.499999999999833, -66.1000000000002, -40.89999999999976, 57.5000000000002, 2.599999999999989, 20.000000000000014, 20.000000000000014, 33.5000000000002, 65.90000000000008, 44.30000000000014, 20.000000000000014, -207.40000000000003, 0.4999999999999635, 5.300000000000028, 3.1999999999999615, 16.399999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, -6.100000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 50.9000000000001, -66.1000000000009, 138.7999999999996, -16.899999999999935, 4.0999999999999694, 20.000000000000014, 20.000000000000014, 83.89999999999999, 59.600000000000165, -70.30000000000032, 20.000000000000014, 20.000000000000014, -82.90000000000026, 14.599999999999968, -48.69999999999981, 18.20000000000001, 5.299999999999965, 37.10000000000008, -106.90000000000035, 43.400000000000226, 32.60000000000023, -50.19999999999985, -12.999999999999993, -23.799999999999784, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.300000000000246, 56.00000000000023, 20.000000000000014, 24.500000000000096, 40.70000000000025, -65.50000000000063, 83.89999999999937, -177.40000000000018, 23.60000000000005, -9.399999999999942, -267.6999999999991, 115.39999999999947, 97.09999999999968, -32.799999999999905, -87.10000000000039, 104.59999999999945, 46.400000000000205, 20.000000000000014, 139.69999999999965, 23.60000000000008, -135.40000000000032, -175.30000000000055, 20.000000000000014, 3.799999999999985, -32.499999999999766, 38.60000000000017, 3.8000000000001535, 20.000000000000014, -11.499999999999925, 20.000000000000014, -102.70000000000076, 11.599999999999978, 20.000000000000014, 74.00000000000018, 7.399999999999965, -76.60000000000014, -21.999999999999876, -12.999999999999813, -119.80000000000013, -78.10000000000082, -31.59999999999995, -64.00000000000087, 33.50000000000006, 6.799999999999994, -71.8000000000004, -95.50000000000003, 22.700000000000053, 56.90000000000021, 20.000000000000014, -90.39999999999999, 17.899999999999988, -106.60000000000005, -30.399999999999807, -35.20000000000004, 60.50000000000017, 45.20000000000016, 20.000000000000014, -113.50000000000011, 20.000000000000014, 20.000000000000014, -160.5999999999999, -12.699999999999857, 20.000000000000014, -15.400000000000007, -138.70000000000041, -3.100000000000047, 20.000000000000014, -145.90000000000035, -145.90000000000038, 23.600000000000076, 155.89999999999995, -42.99999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, -94.0, 28.1, 82.40000000000003, 20.000000000000014, -233.20000000000002, 20.000000000000014, 20.000000000000014, -19.900000000000027, -131.2000000000001, -19.900000000000027, -53.49999999999977, 31.700000000000212, 20.000000000000014, 17.899999999999988, -54.99999999999989, -17.199999999999793, 24.800000000000168, -12.099999999999948, -178.6000000000004, -3.4000000000000314, -193.6, 50.60000000000019, 27.20000000000013, 62.60000000000009, -52.90000000000017, 20.000000000000014, -25.599999999999866, -215.20000000000016, -103.00000000000063, 33.500000000000234, 22.700000000000053, 103.39999999999955, -10.299999999999851, 29.90000000000018, -80.8000000000008, 48.80000000000019, -307.59999999999985, 20.000000000000014, 70.39999999999968, 65.00000000000014, -66.70000000000019, -114.4000000000006, 20.000000000000014, -7.8999999999998884, 20.000000000000014, -64.30000000000021, -44.499999999999886, 20.000000000000014, 149.5999999999999, 38.00000000000021, 15.799999999999962, 20.000000000000014, -109.0000000000006, -139.60000000000065, -69.39999999999998, 43.40000000000006, 20.000000000000014, -76.00000000000006, -215.80000000000044], "policy_predator_policy_reward": [0.0, 23.0, 0.0, 3.0, 0.0, 0.0, 15.0, 0.0, 4.0, 78.0, 0.0, 0.0, 34.0, 30.0, 0.0, 6.0, 18.0, 41.0, 4.0, 29.0, 0.0, 19.0, 0.0, 0.0, 15.0, 6.0, 108.0, 30.0, 39.0, 0.0, 10.0, 28.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 41.0, 16.0, 37.0, 0.0, 0.0, 0.0, 0.0, 43.0, 0.0, 60.0, 47.0, 30.0, 19.0, 0.0, 19.0, 30.0, 57.0, 0.0, 0.0, 44.0, 46.0, 0.0, 29.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 0.0, 0.0, 97.0, 39.0, 31.0, 0.0, 137.0, 25.0, 38.0, 52.0, 2.0, 5.0, 3.0, 0.0, 0.0, 137.0, 0.0, 0.0, 12.0, 19.0, 25.0, 29.0, 10.0, 15.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 91.0, 1.0, 36.0, 76.0, 48.0, 82.0, 34.0, 0.0, 41.0, 0.0, 121.0, 3.0, 0.0, 84.0, 45.0, 80.0, 0.0, 79.0, 0.0, 0.0, 0.0, 50.0, 20.0, 0.0, 0.0, 95.0, 22.0, 52.0, 0.0, 49.0, 42.0, 79.0, 0.0, 0.0, 83.0, 30.0, 0.0, 0.0, 0.0, 56.0, 0.0, 2.0, 0.0, 0.0, 121.0, 0.0, 0.0, 75.0, 0.0, 3.0, 52.0, 0.0, 0.0, 4.0, 55.0, 0.0, 33.0, 0.0, 109.0, 90.0, 28.0, 0.0, 9.0, 71.0, 0.0, 0.0, 29.0, 0.0, 154.0, 0.0, 0.0, 4.0, 17.0, 0.0, 48.0, 138.0, 18.0, 2.0, 13.0, 61.0, 0.0, 11.0, 59.0, 13.0, 5.0, 0.0, 76.0, 0.0, 0.0, 8.0, 0.0, 0.0, 67.0, 109.0, 0.0, 0.0, 0.0, 115.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.105893352944181, "mean_inference_ms": 3.0366901793923393, "mean_action_processing_ms": 0.42932471105909725, "mean_env_wait_ms": 0.3855152743945744, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007958769798278809, "StateBufferConnector_ms": 0.013157248497009277, "ViewRequirementAgentConnector_ms": 0.2809203863143921}, "num_episodes": 27, "episode_return_max": 314.2000000000005, "episode_return_min": -176.79999999999976, "episode_return_mean": 31.921999999999933, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 262.3761331842077, "num_env_steps_trained_throughput_per_sec": 262.3761331842077, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 30463.473, "restore_workers_time_ms": 0.014, "training_step_time_ms": 30463.423, "sample_time_ms": 2723.863, "learn_time_ms": 27714.145, "learn_throughput": 144.331, "synch_weights_time_ms": 20.545}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "3a355_00000", "date": "2024-08-13_01-15-43", "timestamp": 1723526143, "time_this_iter_s": 15.29142713546753, "time_total_s": 352.99662494659424, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d6dee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 352.99662494659424, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 69.51904761904764, "ram_util_percent": 83.47142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3369825022502078, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.356206626740713, "policy_loss": -0.003165416283749793, "vf_loss": 2.359152938133825, "vf_explained_var": 0.00822517127587051, "kl": 0.017528985629458406, "entropy": 1.1629291608220056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.209736869701002, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.163676748893879, "policy_loss": -0.00046170396710593233, "vf_loss": 3.1636634778724146, "vf_explained_var": -0.00015159785432159584, "kl": 0.006333020343212571, "entropy": 1.537495960508074, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 169.59999999999934, "episode_reward_min": -176.79999999999976, "episode_reward_mean": 25.54299999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -307.59999999999985, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 155.89999999999995, "predator_policy": 154.0}, "policy_reward_mean": {"prey_policy": -12.548500000000038, "predator_policy": 25.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [41.800000000000324, 90.8999999999993, 113.69999999999911, 40.20000000000036, 40.0000000000003, 143.49999999999878, -7.300000000000038, 44.100000000000115, 14.899999999999958, 42.50000000000026, 17.19999999999999, 75.99999999999964, 26.80000000000011, 25.20000000000019, 40.0000000000003, 94.29999999999832, 44.50000000000029, 20.19999999999994, 3.5000000000000853, 84.20000000000017, -15.299999999999894, 127.29999999999941, 71.49999999999953, 74.39999999999971, 163.2999999999989, -173.70000000000084, 35.80000000000024, 50.100000000000335, 62.80000000000034, 23.500000000000043, -27.099999999999575, 94.00000000000026, 21.800000000000125, 1.9999999999999607, -73.90000000000015, 20.400000000000283, 81.29999999999978, -46.2999999999998, 82.59999999999916, 58.59999999999981, -8.699999999999921, 13.400000000000215, 105.69999999999871, -23.500000000000057, 40.0000000000003, -56.29999999999972, 56.59999999999966, -50.79999999999975, -46.89999999999978, -39.29999999999978, 142.89999999999955, 40.0000000000003, -17.999999999999773, 112.49999999999994, -92.20000000000007, 40.0000000000003, -76.10000000000007, -18.39999999999989, 51.70000000000049, 21.900000000000137, 40.600000000000364, -81.69999999999968, -79.0, 86.79999999999885, 80.69999999999997, 23.40000000000006, -164.20000000000064, 56.20000000000048, 114.09999999999897, -2.8999999999998156, -102.80000000000058, 105.39999999999884, 59.30000000000027, -24.399999999999658, 30.100000000000158, -32.79999999999981, 169.59999999999934, 61.80000000000046, -21.999999999999673, -100.00000000000111, 63.40000000000026, -176.79999999999976, -11.699999999999605, 33.500000000000206, 23.300000000000146, -27.999999999999652, 21.500000000000025, 55.00000000000032, 57.000000000000384, 56.20000000000049, 101.5999999999988, 83.19999999999911, 106.49999999999824, -17.599999999999753, 90.19999999999877, 13.600000000000046, 52.60000000000049, -12.699999999999708, -5.499999999999886, 7.000000000000071], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [21.80000000000004, 20.000000000000014, 20.000000000000014, 50.9000000000001, -66.1000000000009, 138.7999999999996, -16.899999999999935, 4.0999999999999694, 20.000000000000014, 20.000000000000014, 83.89999999999999, 59.600000000000165, -70.30000000000032, 20.000000000000014, 20.000000000000014, -82.90000000000026, 14.599999999999968, -48.69999999999981, 18.20000000000001, 5.299999999999965, 37.10000000000008, -106.90000000000035, 43.400000000000226, 32.60000000000023, -50.19999999999985, -12.999999999999993, -23.799999999999784, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.300000000000246, 56.00000000000023, 20.000000000000014, 24.500000000000096, 40.70000000000025, -65.50000000000063, 83.89999999999937, -177.40000000000018, 23.60000000000005, -9.399999999999942, -267.6999999999991, 115.39999999999947, 97.09999999999968, -32.799999999999905, -87.10000000000039, 104.59999999999945, 46.400000000000205, 20.000000000000014, 139.69999999999965, 23.60000000000008, -135.40000000000032, -175.30000000000055, 20.000000000000014, 3.799999999999985, -32.499999999999766, 38.60000000000017, 3.8000000000001535, 20.000000000000014, -11.499999999999925, 20.000000000000014, -102.70000000000076, 11.599999999999978, 20.000000000000014, 74.00000000000018, 7.399999999999965, -76.60000000000014, -21.999999999999876, -12.999999999999813, -119.80000000000013, -78.10000000000082, -31.59999999999995, -64.00000000000087, 33.50000000000006, 6.799999999999994, -71.8000000000004, -95.50000000000003, 22.700000000000053, 56.90000000000021, 20.000000000000014, -90.39999999999999, 17.899999999999988, -106.60000000000005, -30.399999999999807, -35.20000000000004, 60.50000000000017, 45.20000000000016, 20.000000000000014, -113.50000000000011, 20.000000000000014, 20.000000000000014, -160.5999999999999, -12.699999999999857, 20.000000000000014, -15.400000000000007, -138.70000000000041, -3.100000000000047, 20.000000000000014, -145.90000000000035, -145.90000000000038, 23.600000000000076, 155.89999999999995, -42.99999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, -94.0, 28.1, 82.40000000000003, 20.000000000000014, -233.20000000000002, 20.000000000000014, 20.000000000000014, -19.900000000000027, -131.2000000000001, -19.900000000000027, -53.49999999999977, 31.700000000000212, 20.000000000000014, 17.899999999999988, -54.99999999999989, -17.199999999999793, 24.800000000000168, -12.099999999999948, -178.6000000000004, -3.4000000000000314, -193.6, 50.60000000000019, 27.20000000000013, 62.60000000000009, -52.90000000000017, 20.000000000000014, -25.599999999999866, -215.20000000000016, -103.00000000000063, 33.500000000000234, 22.700000000000053, 103.39999999999955, -10.299999999999851, 29.90000000000018, -80.8000000000008, 48.80000000000019, -307.59999999999985, 20.000000000000014, 70.39999999999968, 65.00000000000014, -66.70000000000019, -114.4000000000006, 20.000000000000014, -7.8999999999998884, 20.000000000000014, -64.30000000000021, -44.499999999999886, 20.000000000000014, 149.5999999999999, 38.00000000000021, 15.799999999999962, 20.000000000000014, -109.0000000000006, -139.60000000000065, -69.39999999999998, 43.40000000000006, 20.000000000000014, -76.00000000000006, -215.80000000000044, 20.000000000000014, -78.70000000000087, 3.4999999999999654, 20.000000000000014, -78.70000000000059, -9.999999999999853, -28.29999999999979, -78.70000000000051, -50.799999999999926, 14.299999999999963, -24.999999999999844, 20.000000000000014, -25.29999999999984, 29.300000000000203, 36.200000000000244, 20.000000000000014, 26.900000000000112, 49.70000000000024, 63.200000000000216, 20.000000000000014, 65.90000000000008, 35.600000000000236, -99.70000000000003, 19.099999999999998, 87.49999999999937, -34.29999999999981, -24.099999999999945, 13.699999999999958, 20.90000000000003, 31.700000000000212, -19.899999999999824, -38.799999999999805, -27.399999999999984, -57.09999999999987, 20.000000000000014, -55.00000000000023], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 20.0, 0.0, 41.0, 16.0, 37.0, 0.0, 0.0, 0.0, 0.0, 43.0, 0.0, 60.0, 47.0, 30.0, 19.0, 0.0, 19.0, 30.0, 57.0, 0.0, 0.0, 44.0, 46.0, 0.0, 29.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 45.0, 0.0, 0.0, 97.0, 39.0, 31.0, 0.0, 137.0, 25.0, 38.0, 52.0, 2.0, 5.0, 3.0, 0.0, 0.0, 137.0, 0.0, 0.0, 12.0, 19.0, 25.0, 29.0, 10.0, 15.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 91.0, 1.0, 36.0, 76.0, 48.0, 82.0, 34.0, 0.0, 41.0, 0.0, 121.0, 3.0, 0.0, 84.0, 45.0, 80.0, 0.0, 79.0, 0.0, 0.0, 0.0, 50.0, 20.0, 0.0, 0.0, 95.0, 22.0, 52.0, 0.0, 49.0, 42.0, 79.0, 0.0, 0.0, 83.0, 30.0, 0.0, 0.0, 0.0, 56.0, 0.0, 2.0, 0.0, 0.0, 121.0, 0.0, 0.0, 75.0, 0.0, 3.0, 52.0, 0.0, 0.0, 4.0, 55.0, 0.0, 33.0, 0.0, 109.0, 90.0, 28.0, 0.0, 9.0, 71.0, 0.0, 0.0, 29.0, 0.0, 154.0, 0.0, 0.0, 4.0, 17.0, 0.0, 48.0, 138.0, 18.0, 2.0, 13.0, 61.0, 0.0, 11.0, 59.0, 13.0, 5.0, 0.0, 76.0, 0.0, 0.0, 8.0, 0.0, 0.0, 67.0, 109.0, 0.0, 0.0, 0.0, 115.0, 0.0, 47.0, 0.0, 10.0, 0.0, 61.0, 51.0, 32.0, 47.0, 12.0, 46.0, 22.0, 38.0, 25.0, 28.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 5.0, 0.0, 6.0, 57.0, 31.0, 6.0, 0.0, 24.0, 0.0, 0.0, 12.0, 34.0, 66.0, 13.0, 33.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1393397903859848, "mean_inference_ms": 3.174491930657098, "mean_action_processing_ms": 0.4444208354737302, "mean_env_wait_ms": 0.40199260833997824, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007205843925476074, "StateBufferConnector_ms": 0.011843085289001465, "ViewRequirementAgentConnector_ms": 0.2504146099090576}, "num_episodes": 18, "episode_return_max": 169.59999999999934, "episode_return_min": -176.79999999999976, "episode_return_mean": 25.54299999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 311.44990156976934, "num_env_steps_trained_throughput_per_sec": 311.44990156976934, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 30684.845, "restore_workers_time_ms": 0.014, "training_step_time_ms": 30684.795, "sample_time_ms": 2759.105, "learn_time_ms": 27900.195, "learn_throughput": 143.368, "synch_weights_time_ms": 21.035}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "3a355_00000", "date": "2024-08-13_01-15-56", "timestamp": 1723526156, "time_this_iter_s": 12.902947187423706, "time_total_s": 365.89957213401794, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df80d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 365.89957213401794, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 55.652631578947364, "ram_util_percent": 83.14736842105263}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.41180228928409557, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6015624334572482, "policy_loss": -0.0029562013058691584, "vf_loss": 2.6043734945317425, "vf_explained_var": 0.006215933391026088, "kl": 0.011610912417865478, "entropy": 1.23908617010823, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1950176266293047, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8338147790343675, "policy_loss": -0.002572098984407685, "vf_loss": 3.8355370710766503, "vf_explained_var": -0.0016953450031381436, "kl": 0.011330763573530833, "entropy": 1.511577701694751, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 169.59999999999934, "episode_reward_min": -326.1999999999971, "episode_reward_mean": 9.824999999999939, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -307.59999999999985, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 155.89999999999995, "predator_policy": 154.0}, "policy_reward_mean": {"prey_policy": -23.732500000000055, "predator_policy": 28.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.5000000000000853, 84.20000000000017, -15.299999999999894, 127.29999999999941, 71.49999999999953, 74.39999999999971, 163.2999999999989, -173.70000000000084, 35.80000000000024, 50.100000000000335, 62.80000000000034, 23.500000000000043, -27.099999999999575, 94.00000000000026, 21.800000000000125, 1.9999999999999607, -73.90000000000015, 20.400000000000283, 81.29999999999978, -46.2999999999998, 82.59999999999916, 58.59999999999981, -8.699999999999921, 13.400000000000215, 105.69999999999871, -23.500000000000057, 40.0000000000003, -56.29999999999972, 56.59999999999966, -50.79999999999975, -46.89999999999978, -39.29999999999978, 142.89999999999955, 40.0000000000003, -17.999999999999773, 112.49999999999994, -92.20000000000007, 40.0000000000003, -76.10000000000007, -18.39999999999989, 51.70000000000049, 21.900000000000137, 40.600000000000364, -81.69999999999968, -79.0, 86.79999999999885, 80.69999999999997, 23.40000000000006, -164.20000000000064, 56.20000000000048, 114.09999999999897, -2.8999999999998156, -102.80000000000058, 105.39999999999884, 59.30000000000027, -24.399999999999658, 30.100000000000158, -32.79999999999981, 169.59999999999934, 61.80000000000046, -21.999999999999673, -100.00000000000111, 63.40000000000026, -176.79999999999976, -11.699999999999605, 33.500000000000206, 23.300000000000146, -27.999999999999652, 21.500000000000025, 55.00000000000032, 57.000000000000384, 56.20000000000049, 101.5999999999988, 83.19999999999911, 106.49999999999824, -17.599999999999753, 90.19999999999877, 13.600000000000046, 52.60000000000049, -12.699999999999708, -5.499999999999886, 7.000000000000071, 40.0000000000003, 37.80000000000027, -158.900000000001, -136.80000000000078, 107.19999999999851, 41.800000000000324, -58.90000000000024, -136.6000000000009, 47.40000000000035, -326.1999999999971, -139.00000000000102, 31.100000000000378, -5.399999999999921, 40.0000000000003, -80.30000000000072, 49.900000000000446, -18.69999999999969, 2.300000000000193], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [83.89999999999937, -177.40000000000018, 23.60000000000005, -9.399999999999942, -267.6999999999991, 115.39999999999947, 97.09999999999968, -32.799999999999905, -87.10000000000039, 104.59999999999945, 46.400000000000205, 20.000000000000014, 139.69999999999965, 23.60000000000008, -135.40000000000032, -175.30000000000055, 20.000000000000014, 3.799999999999985, -32.499999999999766, 38.60000000000017, 3.8000000000001535, 20.000000000000014, -11.499999999999925, 20.000000000000014, -102.70000000000076, 11.599999999999978, 20.000000000000014, 74.00000000000018, 7.399999999999965, -76.60000000000014, -21.999999999999876, -12.999999999999813, -119.80000000000013, -78.10000000000082, -31.59999999999995, -64.00000000000087, 33.50000000000006, 6.799999999999994, -71.8000000000004, -95.50000000000003, 22.700000000000053, 56.90000000000021, 20.000000000000014, -90.39999999999999, 17.899999999999988, -106.60000000000005, -30.399999999999807, -35.20000000000004, 60.50000000000017, 45.20000000000016, 20.000000000000014, -113.50000000000011, 20.000000000000014, 20.000000000000014, -160.5999999999999, -12.699999999999857, 20.000000000000014, -15.400000000000007, -138.70000000000041, -3.100000000000047, 20.000000000000014, -145.90000000000035, -145.90000000000038, 23.600000000000076, 155.89999999999995, -42.99999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, -94.0, 28.1, 82.40000000000003, 20.000000000000014, -233.20000000000002, 20.000000000000014, 20.000000000000014, -19.900000000000027, -131.2000000000001, -19.900000000000027, -53.49999999999977, 31.700000000000212, 20.000000000000014, 17.899999999999988, -54.99999999999989, -17.199999999999793, 24.800000000000168, -12.099999999999948, -178.6000000000004, -3.4000000000000314, -193.6, 50.60000000000019, 27.20000000000013, 62.60000000000009, -52.90000000000017, 20.000000000000014, -25.599999999999866, -215.20000000000016, -103.00000000000063, 33.500000000000234, 22.700000000000053, 103.39999999999955, -10.299999999999851, 29.90000000000018, -80.8000000000008, 48.80000000000019, -307.59999999999985, 20.000000000000014, 70.39999999999968, 65.00000000000014, -66.70000000000019, -114.4000000000006, 20.000000000000014, -7.8999999999998884, 20.000000000000014, -64.30000000000021, -44.499999999999886, 20.000000000000014, 149.5999999999999, 38.00000000000021, 15.799999999999962, 20.000000000000014, -109.0000000000006, -139.60000000000065, -69.39999999999998, 43.40000000000006, 20.000000000000014, -76.00000000000006, -215.80000000000044, 20.000000000000014, -78.70000000000087, 3.4999999999999654, 20.000000000000014, -78.70000000000059, -9.999999999999853, -28.29999999999979, -78.70000000000051, -50.799999999999926, 14.299999999999963, -24.999999999999844, 20.000000000000014, -25.29999999999984, 29.300000000000203, 36.200000000000244, 20.000000000000014, 26.900000000000112, 49.70000000000024, 63.200000000000216, 20.000000000000014, 65.90000000000008, 35.600000000000236, -99.70000000000003, 19.099999999999998, 87.49999999999937, -34.29999999999981, -24.099999999999945, 13.699999999999958, 20.90000000000003, 31.700000000000212, -19.899999999999824, -38.799999999999805, -27.399999999999984, -57.09999999999987, 20.000000000000014, -55.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, -169.00000000000045, -82.90000000000049, -128.50000000000043, -133.30000000000072, 49.100000000000215, 34.100000000000115, 21.80000000000004, 20.000000000000014, -187.90000000000057, 20.000000000000014, -203.20000000000041, -90.39999999999985, 20.000000000000014, 1.3999999999999797, -248.80000000000032, -240.40000000000043, -21.09999999999978, -292.899999999999, -28.899999999999828, 20.000000000000014, -121.00000000000033, 11.599999999999957, 20.000000000000014, 20.000000000000014, -211.3000000000005, 20.000000000000014, 20.000000000000014, 29.900000000000187, 20.000000000000014, -93.70000000000059, 11.599999999999978, -76.30000000000013], "policy_predator_policy_reward": [0.0, 97.0, 39.0, 31.0, 0.0, 137.0, 25.0, 38.0, 52.0, 2.0, 5.0, 3.0, 0.0, 0.0, 137.0, 0.0, 0.0, 12.0, 19.0, 25.0, 29.0, 10.0, 15.0, 0.0, 64.0, 0.0, 0.0, 0.0, 0.0, 91.0, 1.0, 36.0, 76.0, 48.0, 82.0, 34.0, 0.0, 41.0, 0.0, 121.0, 3.0, 0.0, 84.0, 45.0, 80.0, 0.0, 79.0, 0.0, 0.0, 0.0, 50.0, 20.0, 0.0, 0.0, 95.0, 22.0, 52.0, 0.0, 49.0, 42.0, 79.0, 0.0, 0.0, 83.0, 30.0, 0.0, 0.0, 0.0, 56.0, 0.0, 2.0, 0.0, 0.0, 121.0, 0.0, 0.0, 75.0, 0.0, 3.0, 52.0, 0.0, 0.0, 4.0, 55.0, 0.0, 33.0, 0.0, 109.0, 90.0, 28.0, 0.0, 9.0, 71.0, 0.0, 0.0, 29.0, 0.0, 154.0, 0.0, 0.0, 4.0, 17.0, 0.0, 48.0, 138.0, 18.0, 2.0, 13.0, 61.0, 0.0, 11.0, 59.0, 13.0, 5.0, 0.0, 76.0, 0.0, 0.0, 8.0, 0.0, 0.0, 67.0, 109.0, 0.0, 0.0, 0.0, 115.0, 0.0, 47.0, 0.0, 10.0, 0.0, 61.0, 51.0, 32.0, 47.0, 12.0, 46.0, 22.0, 38.0, 25.0, 28.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 5.0, 0.0, 6.0, 57.0, 31.0, 6.0, 0.0, 24.0, 0.0, 0.0, 12.0, 34.0, 66.0, 13.0, 33.0, 9.0, 0.0, 0.0, 0.0, 2.0, 93.0, 0.0, 125.0, 0.0, 24.0, 0.0, 0.0, 0.0, 64.0, 45.0, 133.0, 24.0, 19.0, 7.0, 71.0, 92.0, 26.0, 149.0, 8.0, 32.0, 36.0, 68.0, 0.0, 0.0, 111.0, 0.0, 0.0, 0.0, 55.0, 0.0, 3.0, 64.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1343002977843075, "mean_inference_ms": 3.175671593992017, "mean_action_processing_ms": 0.4429870553668714, "mean_env_wait_ms": 0.4005993885955448, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005126595497131348, "StateBufferConnector_ms": 0.007605910301208496, "ViewRequirementAgentConnector_ms": 0.18725907802581787}, "num_episodes": 18, "episode_return_max": 169.59999999999934, "episode_return_min": -326.1999999999971, "episode_return_mean": 9.824999999999939, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 263.4963331730576, "num_env_steps_trained_throughput_per_sec": 263.4963331730576, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 28991.738, "restore_workers_time_ms": 0.014, "training_step_time_ms": 28991.674, "sample_time_ms": 2789.804, "learn_time_ms": 26175.627, "learn_throughput": 152.814, "synch_weights_time_ms": 21.543}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "3a355_00000", "date": "2024-08-13_01-16-11", "timestamp": 1723526171, "time_this_iter_s": 15.25975513458252, "time_total_s": 381.15932726860046, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d35040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 381.15932726860046, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 67.00952380952381, "ram_util_percent": 83.47619047619048}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4276366625651323, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.031667360363814, "policy_loss": -0.002165475674219942, "vf_loss": 3.033720627411333, "vf_explained_var": 0.006142733746735507, "kl": 0.008976379925730417, "entropy": 1.2829498913553026, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.158006724494475, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.3021295628219685, "policy_loss": -0.00021546314366989667, "vf_loss": 4.3020600963521884, "vf_explained_var": -0.0034233095153929694, "kl": 0.0037990269220289454, "entropy": 1.483601649854549, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 169.59999999999934, "episode_reward_min": -468.7000000000001, "episode_reward_mean": 5.184999999999896, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -438.80000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 155.89999999999995, "predator_policy": 320.0}, "policy_reward_mean": {"prey_policy": -25.837500000000027, "predator_policy": 28.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [81.29999999999978, -46.2999999999998, 82.59999999999916, 58.59999999999981, -8.699999999999921, 13.400000000000215, 105.69999999999871, -23.500000000000057, 40.0000000000003, -56.29999999999972, 56.59999999999966, -50.79999999999975, -46.89999999999978, -39.29999999999978, 142.89999999999955, 40.0000000000003, -17.999999999999773, 112.49999999999994, -92.20000000000007, 40.0000000000003, -76.10000000000007, -18.39999999999989, 51.70000000000049, 21.900000000000137, 40.600000000000364, -81.69999999999968, -79.0, 86.79999999999885, 80.69999999999997, 23.40000000000006, -164.20000000000064, 56.20000000000048, 114.09999999999897, -2.8999999999998156, -102.80000000000058, 105.39999999999884, 59.30000000000027, -24.399999999999658, 30.100000000000158, -32.79999999999981, 169.59999999999934, 61.80000000000046, -21.999999999999673, -100.00000000000111, 63.40000000000026, -176.79999999999976, -11.699999999999605, 33.500000000000206, 23.300000000000146, -27.999999999999652, 21.500000000000025, 55.00000000000032, 57.000000000000384, 56.20000000000049, 101.5999999999988, 83.19999999999911, 106.49999999999824, -17.599999999999753, 90.19999999999877, 13.600000000000046, 52.60000000000049, -12.699999999999708, -5.499999999999886, 7.000000000000071, 40.0000000000003, 37.80000000000027, -158.900000000001, -136.80000000000078, 107.19999999999851, 41.800000000000324, -58.90000000000024, -136.6000000000009, 47.40000000000035, -326.1999999999971, -139.00000000000102, 31.100000000000378, -5.399999999999921, 40.0000000000003, -80.30000000000072, 49.900000000000446, -18.69999999999969, 2.300000000000193, -93.5000000000005, 40.0000000000003, 40.0000000000003, 87.79999999999875, 73.99999999999977, 89.49999999999868, 123.39999999999924, 111.99999999999824, 120.99999999999838, -66.00000000000045, 57.2000000000005, -468.7000000000001, 48.20000000000038, 21.300000000000296, 2.9000000000000736, -55.499999999999886, 40.0000000000003, -92.99999999999989], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [33.50000000000006, 6.799999999999994, -71.8000000000004, -95.50000000000003, 22.700000000000053, 56.90000000000021, 20.000000000000014, -90.39999999999999, 17.899999999999988, -106.60000000000005, -30.399999999999807, -35.20000000000004, 60.50000000000017, 45.20000000000016, 20.000000000000014, -113.50000000000011, 20.000000000000014, 20.000000000000014, -160.5999999999999, -12.699999999999857, 20.000000000000014, -15.400000000000007, -138.70000000000041, -3.100000000000047, 20.000000000000014, -145.90000000000035, -145.90000000000038, 23.600000000000076, 155.89999999999995, -42.99999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, -94.0, 28.1, 82.40000000000003, 20.000000000000014, -233.20000000000002, 20.000000000000014, 20.000000000000014, -19.900000000000027, -131.2000000000001, -19.900000000000027, -53.49999999999977, 31.700000000000212, 20.000000000000014, 17.899999999999988, -54.99999999999989, -17.199999999999793, 24.800000000000168, -12.099999999999948, -178.6000000000004, -3.4000000000000314, -193.6, 50.60000000000019, 27.20000000000013, 62.60000000000009, -52.90000000000017, 20.000000000000014, -25.599999999999866, -215.20000000000016, -103.00000000000063, 33.500000000000234, 22.700000000000053, 103.39999999999955, -10.299999999999851, 29.90000000000018, -80.8000000000008, 48.80000000000019, -307.59999999999985, 20.000000000000014, 70.39999999999968, 65.00000000000014, -66.70000000000019, -114.4000000000006, 20.000000000000014, -7.8999999999998884, 20.000000000000014, -64.30000000000021, -44.499999999999886, 20.000000000000014, 149.5999999999999, 38.00000000000021, 15.799999999999962, 20.000000000000014, -109.0000000000006, -139.60000000000065, -69.39999999999998, 43.40000000000006, 20.000000000000014, -76.00000000000006, -215.80000000000044, 20.000000000000014, -78.70000000000087, 3.4999999999999654, 20.000000000000014, -78.70000000000059, -9.999999999999853, -28.29999999999979, -78.70000000000051, -50.799999999999926, 14.299999999999963, -24.999999999999844, 20.000000000000014, -25.29999999999984, 29.300000000000203, 36.200000000000244, 20.000000000000014, 26.900000000000112, 49.70000000000024, 63.200000000000216, 20.000000000000014, 65.90000000000008, 35.600000000000236, -99.70000000000003, 19.099999999999998, 87.49999999999937, -34.29999999999981, -24.099999999999945, 13.699999999999958, 20.90000000000003, 31.700000000000212, -19.899999999999824, -38.799999999999805, -27.399999999999984, -57.09999999999987, 20.000000000000014, -55.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, -169.00000000000045, -82.90000000000049, -128.50000000000043, -133.30000000000072, 49.100000000000215, 34.100000000000115, 21.80000000000004, 20.000000000000014, -187.90000000000057, 20.000000000000014, -203.20000000000041, -90.39999999999985, 20.000000000000014, 1.3999999999999797, -248.80000000000032, -240.40000000000043, -21.09999999999978, -292.899999999999, -28.899999999999828, 20.000000000000014, -121.00000000000033, 11.599999999999957, 20.000000000000014, 20.000000000000014, -211.3000000000005, 20.000000000000014, 20.000000000000014, 29.900000000000187, 20.000000000000014, -93.70000000000059, 11.599999999999978, -76.30000000000013, -72.40000000000026, -111.10000000000028, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 63.800000000000196, 20.000000000000014, 53.00000000000023, 20.000000000000014, 41.60000000000025, 47.90000000000024, 64.99999999999997, 43.400000000000134, 56.900000000000226, 55.10000000000023, 56.0000000000002, 65.00000000000014, -155.20000000000056, -17.79999999999996, 11.599999999999966, 41.60000000000025, -438.80000000000007, -418.90000000000003, 42.5000000000002, -7.299999999999891, 20.000000000000014, -60.69999999999992, -126.40000000000029, 26.300000000000114, -116.20000000000002, -76.29999999999993, 20.000000000000014, 20.000000000000014, -181.6000000000006, -51.400000000000105], "policy_predator_policy_reward": [0.0, 41.0, 0.0, 121.0, 3.0, 0.0, 84.0, 45.0, 80.0, 0.0, 79.0, 0.0, 0.0, 0.0, 50.0, 20.0, 0.0, 0.0, 95.0, 22.0, 52.0, 0.0, 49.0, 42.0, 79.0, 0.0, 0.0, 83.0, 30.0, 0.0, 0.0, 0.0, 56.0, 0.0, 2.0, 0.0, 0.0, 121.0, 0.0, 0.0, 75.0, 0.0, 3.0, 52.0, 0.0, 0.0, 4.0, 55.0, 0.0, 33.0, 0.0, 109.0, 90.0, 28.0, 0.0, 9.0, 71.0, 0.0, 0.0, 29.0, 0.0, 154.0, 0.0, 0.0, 4.0, 17.0, 0.0, 48.0, 138.0, 18.0, 2.0, 13.0, 61.0, 0.0, 11.0, 59.0, 13.0, 5.0, 0.0, 76.0, 0.0, 0.0, 8.0, 0.0, 0.0, 67.0, 109.0, 0.0, 0.0, 0.0, 115.0, 0.0, 47.0, 0.0, 10.0, 0.0, 61.0, 51.0, 32.0, 47.0, 12.0, 46.0, 22.0, 38.0, 25.0, 28.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 5.0, 0.0, 6.0, 57.0, 31.0, 6.0, 0.0, 24.0, 0.0, 0.0, 12.0, 34.0, 66.0, 13.0, 33.0, 9.0, 0.0, 0.0, 0.0, 2.0, 93.0, 0.0, 125.0, 0.0, 24.0, 0.0, 0.0, 0.0, 64.0, 45.0, 133.0, 24.0, 19.0, 7.0, 71.0, 92.0, 26.0, 149.0, 8.0, 32.0, 36.0, 68.0, 0.0, 0.0, 111.0, 0.0, 0.0, 0.0, 55.0, 0.0, 3.0, 64.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 107.0, 0.0, 0.0, 4.0, 320.0, 69.0, 13.0, 0.0, 59.0, 3.0, 65.0, 38.0, 84.0, 53.0, 0.0, 0.0, 9.0, 131.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1275476722734203, "mean_inference_ms": 3.1677343207855246, "mean_action_processing_ms": 0.43944641073284324, "mean_env_wait_ms": 0.3968015272338573, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005056023597717285, "StateBufferConnector_ms": 0.008246183395385742, "ViewRequirementAgentConnector_ms": 0.19129443168640137}, "num_episodes": 18, "episode_return_max": 169.59999999999934, "episode_return_min": -468.7000000000001, "episode_return_mean": 5.184999999999896, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 300.8251238047905, "num_env_steps_trained_throughput_per_sec": 300.8251238047905, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 29265.586, "restore_workers_time_ms": 0.014, "training_step_time_ms": 29265.52, "sample_time_ms": 2798.77, "learn_time_ms": 26440.439, "learn_throughput": 151.283, "synch_weights_time_ms": 21.757}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "3a355_00000", "date": "2024-08-13_01-16-24", "timestamp": 1723526184, "time_this_iter_s": 13.339210987091064, "time_total_s": 394.4985382556915, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df81f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 394.4985382556915, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 61.04210526315789, "ram_util_percent": 83.1842105263158}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5884615867462738, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.000134706371045, "policy_loss": -0.004644457981601437, "vf_loss": 5.004574024866498, "vf_explained_var": 0.009710246955276166, "kl": 0.016409571001790847, "entropy": 1.1656648736782176, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1257188315192859, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.864368862071365, "policy_loss": -0.002080094071583103, "vf_loss": 6.865924065453665, "vf_explained_var": 0.016639285680478212, "kl": 0.013997384450100868, "entropy": 1.4694735986845835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 170.89999999999955, "episode_reward_min": -468.7000000000001, "episode_reward_mean": 4.549999999999883, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -438.80000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 149.5999999999999, "predator_policy": 320.0}, "policy_reward_mean": {"prey_policy": -28.560000000000038, "predator_policy": 30.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [51.70000000000049, 21.900000000000137, 40.600000000000364, -81.69999999999968, -79.0, 86.79999999999885, 80.69999999999997, 23.40000000000006, -164.20000000000064, 56.20000000000048, 114.09999999999897, -2.8999999999998156, -102.80000000000058, 105.39999999999884, 59.30000000000027, -24.399999999999658, 30.100000000000158, -32.79999999999981, 169.59999999999934, 61.80000000000046, -21.999999999999673, -100.00000000000111, 63.40000000000026, -176.79999999999976, -11.699999999999605, 33.500000000000206, 23.300000000000146, -27.999999999999652, 21.500000000000025, 55.00000000000032, 57.000000000000384, 56.20000000000049, 101.5999999999988, 83.19999999999911, 106.49999999999824, -17.599999999999753, 90.19999999999877, 13.600000000000046, 52.60000000000049, -12.699999999999708, -5.499999999999886, 7.000000000000071, 40.0000000000003, 37.80000000000027, -158.900000000001, -136.80000000000078, 107.19999999999851, 41.800000000000324, -58.90000000000024, -136.6000000000009, 47.40000000000035, -326.1999999999971, -139.00000000000102, 31.100000000000378, -5.399999999999921, 40.0000000000003, -80.30000000000072, 49.900000000000446, -18.69999999999969, 2.300000000000193, -93.5000000000005, 40.0000000000003, 40.0000000000003, 87.79999999999875, 73.99999999999977, 89.49999999999868, 123.39999999999924, 111.99999999999824, 120.99999999999838, -66.00000000000045, 57.2000000000005, -468.7000000000001, 48.20000000000038, 21.300000000000296, 2.9000000000000736, -55.499999999999886, 40.0000000000003, -92.99999999999989, 58.600000000000456, -69.6, 170.89999999999955, 65.69999999999892, 23.500000000000277, -52.299999999999976, -34.39999999999983, 59.000000000000355, -99.70000000000059, -51.199999999999754, 118.69999999999965, 4.000000000000245, 111.49999999999852, -39.90000000000001, -164.10000000000113, 21.90000000000024, 55.60000000000031, -41.499999999999936, 56.59999999999957, 59.700000000000486, 7.5000000000001865, -26.899999999999856], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [31.700000000000212, 20.000000000000014, 17.899999999999988, -54.99999999999989, -17.199999999999793, 24.800000000000168, -12.099999999999948, -178.6000000000004, -3.4000000000000314, -193.6, 50.60000000000019, 27.20000000000013, 62.60000000000009, -52.90000000000017, 20.000000000000014, -25.599999999999866, -215.20000000000016, -103.00000000000063, 33.500000000000234, 22.700000000000053, 103.39999999999955, -10.299999999999851, 29.90000000000018, -80.8000000000008, 48.80000000000019, -307.59999999999985, 20.000000000000014, 70.39999999999968, 65.00000000000014, -66.70000000000019, -114.4000000000006, 20.000000000000014, -7.8999999999998884, 20.000000000000014, -64.30000000000021, -44.499999999999886, 20.000000000000014, 149.5999999999999, 38.00000000000021, 15.799999999999962, 20.000000000000014, -109.0000000000006, -139.60000000000065, -69.39999999999998, 43.40000000000006, 20.000000000000014, -76.00000000000006, -215.80000000000044, 20.000000000000014, -78.70000000000087, 3.4999999999999654, 20.000000000000014, -78.70000000000059, -9.999999999999853, -28.29999999999979, -78.70000000000051, -50.799999999999926, 14.299999999999963, -24.999999999999844, 20.000000000000014, -25.29999999999984, 29.300000000000203, 36.200000000000244, 20.000000000000014, 26.900000000000112, 49.70000000000024, 63.200000000000216, 20.000000000000014, 65.90000000000008, 35.600000000000236, -99.70000000000003, 19.099999999999998, 87.49999999999937, -34.29999999999981, -24.099999999999945, 13.699999999999958, 20.90000000000003, 31.700000000000212, -19.899999999999824, -38.799999999999805, -27.399999999999984, -57.09999999999987, 20.000000000000014, -55.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, -169.00000000000045, -82.90000000000049, -128.50000000000043, -133.30000000000072, 49.100000000000215, 34.100000000000115, 21.80000000000004, 20.000000000000014, -187.90000000000057, 20.000000000000014, -203.20000000000041, -90.39999999999985, 20.000000000000014, 1.3999999999999797, -248.80000000000032, -240.40000000000043, -21.09999999999978, -292.899999999999, -28.899999999999828, 20.000000000000014, -121.00000000000033, 11.599999999999957, 20.000000000000014, 20.000000000000014, -211.3000000000005, 20.000000000000014, 20.000000000000014, 29.900000000000187, 20.000000000000014, -93.70000000000059, 11.599999999999978, -76.30000000000013, -72.40000000000026, -111.10000000000028, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 63.800000000000196, 20.000000000000014, 53.00000000000023, 20.000000000000014, 41.60000000000025, 47.90000000000024, 64.99999999999997, 43.400000000000134, 56.900000000000226, 55.10000000000023, 56.0000000000002, 65.00000000000014, -155.20000000000056, -17.79999999999996, 11.599999999999966, 41.60000000000025, -438.80000000000007, -418.90000000000003, 42.5000000000002, -7.299999999999891, 20.000000000000014, -60.69999999999992, -126.40000000000029, 26.300000000000114, -116.20000000000002, -76.29999999999993, 20.000000000000014, 20.000000000000014, -181.6000000000006, -51.400000000000105, 23.600000000000083, 20.000000000000014, -79.30000000000013, -106.30000000000003, 64.09999999999982, 60.800000000000075, 5.299999999999981, 22.399999999999537, 20.000000000000014, -11.50000000000005, -239.50000000000009, 48.2000000000001, -90.39999999999998, -64.00000000000077, 46.40000000000017, -9.39999999999988, -79.60000000000039, -192.10000000000005, -45.09999999999984, -138.10000000000025, -15.400000000000048, 73.09999999999992, -71.80000000000008, 30.800000000000196, 29.000000000000185, 66.5, 1.0999999999999688, -135.9999999999999, -164.80000000000055, -112.30000000000047, 20.900000000000027, -30.999999999999993, 24.500000000000092, 19.1000000000002, 9.499999999999964, -127.00000000000007, -52.900000000000006, 9.500000000000213, 34.70000000000023, 20.000000000000014, 20.000000000000014, -170.49999999999994, 47.900000000000205, -311.8000000000002], "policy_predator_policy_reward": [0.0, 0.0, 4.0, 55.0, 0.0, 33.0, 0.0, 109.0, 90.0, 28.0, 0.0, 9.0, 71.0, 0.0, 0.0, 29.0, 0.0, 154.0, 0.0, 0.0, 4.0, 17.0, 0.0, 48.0, 138.0, 18.0, 2.0, 13.0, 61.0, 0.0, 11.0, 59.0, 13.0, 5.0, 0.0, 76.0, 0.0, 0.0, 8.0, 0.0, 0.0, 67.0, 109.0, 0.0, 0.0, 0.0, 115.0, 0.0, 47.0, 0.0, 10.0, 0.0, 61.0, 51.0, 32.0, 47.0, 12.0, 46.0, 22.0, 38.0, 25.0, 28.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 5.0, 0.0, 6.0, 57.0, 31.0, 6.0, 0.0, 24.0, 0.0, 0.0, 12.0, 34.0, 66.0, 13.0, 33.0, 9.0, 0.0, 0.0, 0.0, 2.0, 93.0, 0.0, 125.0, 0.0, 24.0, 0.0, 0.0, 0.0, 64.0, 45.0, 133.0, 24.0, 19.0, 7.0, 71.0, 92.0, 26.0, 149.0, 8.0, 32.0, 36.0, 68.0, 0.0, 0.0, 111.0, 0.0, 0.0, 0.0, 55.0, 0.0, 3.0, 64.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 107.0, 0.0, 0.0, 4.0, 320.0, 69.0, 13.0, 0.0, 59.0, 3.0, 65.0, 38.0, 84.0, 53.0, 0.0, 0.0, 9.0, 131.0, 15.0, 0.0, 52.0, 64.0, 45.0, 1.0, 9.0, 29.0, 15.0, 0.0, 139.0, 0.0, 115.0, 5.0, 22.0, 0.0, 71.0, 101.0, 98.0, 34.0, 0.0, 61.0, 40.0, 5.0, 16.0, 0.0, 5.0, 90.0, 0.0, 113.0, 0.0, 32.0, 8.0, 4.0, 70.0, 6.0, 66.0, 34.0, 5.0, 0.0, 100.0, 58.0, 94.0, 143.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1117956275891643, "mean_inference_ms": 3.140791106816365, "mean_action_processing_ms": 0.4324770291302166, "mean_env_wait_ms": 0.3895953760918037, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004973053932189941, "StateBufferConnector_ms": 0.007986783981323242, "ViewRequirementAgentConnector_ms": 0.1830892562866211}, "num_episodes": 22, "episode_return_max": 170.89999999999955, "episode_return_min": -468.7000000000001, "episode_return_mean": 4.549999999999883, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 275.6517180700034, "num_env_steps_trained_throughput_per_sec": 275.6517180700034, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 29547.707, "restore_workers_time_ms": 0.015, "training_step_time_ms": 29547.639, "sample_time_ms": 2825.389, "learn_time_ms": 26695.986, "learn_throughput": 149.835, "synch_weights_time_ms": 21.485}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "3a355_00000", "date": "2024-08-13_01-16-39", "timestamp": 1723526199, "time_this_iter_s": 14.57634687423706, "time_total_s": 409.0748851299286, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df6280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 409.0748851299286, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 65.98095238095239, "ram_util_percent": 82.97142857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4559534656682185, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.408314167759406, "policy_loss": -0.0016612932837454888, "vf_loss": 4.409915165169529, "vf_explained_var": 0.006991788508400085, "kl": 0.0048228789281808265, "entropy": 1.1351682203787345, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3353951091804201, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.962344750147017, "policy_loss": -0.003962330468905666, "vf_loss": 5.965802648332384, "vf_explained_var": 0.015053704207536404, "kl": 0.013451642471450798, "entropy": 1.471705302738008, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 170.89999999999955, "episode_reward_min": -468.7000000000001, "episode_reward_mean": -0.4030000000001445, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -438.80000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 140.6, "predator_policy": 320.0}, "policy_reward_mean": {"prey_policy": -34.541500000000035, "predator_policy": 34.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-176.79999999999976, -11.699999999999605, 33.500000000000206, 23.300000000000146, -27.999999999999652, 21.500000000000025, 55.00000000000032, 57.000000000000384, 56.20000000000049, 101.5999999999988, 83.19999999999911, 106.49999999999824, -17.599999999999753, 90.19999999999877, 13.600000000000046, 52.60000000000049, -12.699999999999708, -5.499999999999886, 7.000000000000071, 40.0000000000003, 37.80000000000027, -158.900000000001, -136.80000000000078, 107.19999999999851, 41.800000000000324, -58.90000000000024, -136.6000000000009, 47.40000000000035, -326.1999999999971, -139.00000000000102, 31.100000000000378, -5.399999999999921, 40.0000000000003, -80.30000000000072, 49.900000000000446, -18.69999999999969, 2.300000000000193, -93.5000000000005, 40.0000000000003, 40.0000000000003, 87.79999999999875, 73.99999999999977, 89.49999999999868, 123.39999999999924, 111.99999999999824, 120.99999999999838, -66.00000000000045, 57.2000000000005, -468.7000000000001, 48.20000000000038, 21.300000000000296, 2.9000000000000736, -55.499999999999886, 40.0000000000003, -92.99999999999989, 58.600000000000456, -69.6, 170.89999999999955, 65.69999999999892, 23.500000000000277, -52.299999999999976, -34.39999999999983, 59.000000000000355, -99.70000000000059, -51.199999999999754, 118.69999999999965, 4.000000000000245, 111.49999999999852, -39.90000000000001, -164.10000000000113, 21.90000000000024, 55.60000000000031, -41.499999999999936, 56.59999999999957, 59.700000000000486, 7.5000000000001865, -26.899999999999856, 62.79999999999897, -57.09999999999972, 9.700000000000054, -104.0, 124.89999999999836, -71.29999999999994, -33.199999999999925, 136.29999999999959, -206.1999999999998, 126.19999999999908, -58.599999999999774, 73.5, -94.80000000000007, 73.49999999999984, -0.4999999999998941, 40.0000000000003, 117.69999999999914, 37.70000000000011, 12.300000000000216, -299.60000000000025, 146.199999999999, -45.09999999999999, -130.5000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-76.00000000000006, -215.80000000000044, 20.000000000000014, -78.70000000000087, 3.4999999999999654, 20.000000000000014, -78.70000000000059, -9.999999999999853, -28.29999999999979, -78.70000000000051, -50.799999999999926, 14.299999999999963, -24.999999999999844, 20.000000000000014, -25.29999999999984, 29.300000000000203, 36.200000000000244, 20.000000000000014, 26.900000000000112, 49.70000000000024, 63.200000000000216, 20.000000000000014, 65.90000000000008, 35.600000000000236, -99.70000000000003, 19.099999999999998, 87.49999999999937, -34.29999999999981, -24.099999999999945, 13.699999999999958, 20.90000000000003, 31.700000000000212, -19.899999999999824, -38.799999999999805, -27.399999999999984, -57.09999999999987, 20.000000000000014, -55.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, -169.00000000000045, -82.90000000000049, -128.50000000000043, -133.30000000000072, 49.100000000000215, 34.100000000000115, 21.80000000000004, 20.000000000000014, -187.90000000000057, 20.000000000000014, -203.20000000000041, -90.39999999999985, 20.000000000000014, 1.3999999999999797, -248.80000000000032, -240.40000000000043, -21.09999999999978, -292.899999999999, -28.899999999999828, 20.000000000000014, -121.00000000000033, 11.599999999999957, 20.000000000000014, 20.000000000000014, -211.3000000000005, 20.000000000000014, 20.000000000000014, 29.900000000000187, 20.000000000000014, -93.70000000000059, 11.599999999999978, -76.30000000000013, -72.40000000000026, -111.10000000000028, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 63.800000000000196, 20.000000000000014, 53.00000000000023, 20.000000000000014, 41.60000000000025, 47.90000000000024, 64.99999999999997, 43.400000000000134, 56.900000000000226, 55.10000000000023, 56.0000000000002, 65.00000000000014, -155.20000000000056, -17.79999999999996, 11.599999999999966, 41.60000000000025, -438.80000000000007, -418.90000000000003, 42.5000000000002, -7.299999999999891, 20.000000000000014, -60.69999999999992, -126.40000000000029, 26.300000000000114, -116.20000000000002, -76.29999999999993, 20.000000000000014, 20.000000000000014, -181.6000000000006, -51.400000000000105, 23.600000000000083, 20.000000000000014, -79.30000000000013, -106.30000000000003, 64.09999999999982, 60.800000000000075, 5.299999999999981, 22.399999999999537, 20.000000000000014, -11.50000000000005, -239.50000000000009, 48.2000000000001, -90.39999999999998, -64.00000000000077, 46.40000000000017, -9.39999999999988, -79.60000000000039, -192.10000000000005, -45.09999999999984, -138.10000000000025, -15.400000000000048, 73.09999999999992, -71.80000000000008, 30.800000000000196, 29.000000000000185, 66.5, 1.0999999999999688, -135.9999999999999, -164.80000000000055, -112.30000000000047, 20.900000000000027, -30.999999999999993, 24.500000000000092, 19.1000000000002, 9.499999999999964, -127.00000000000007, -52.900000000000006, 9.500000000000213, 34.70000000000023, 20.000000000000014, 20.000000000000014, -170.49999999999994, 47.900000000000205, -311.8000000000002, 62.00000000000014, -47.20000000000002, -360.10000000000014, 20.000000000000014, 20.000000000000014, -49.299999999999905, 9.799999999999955, -251.79999999999995, 40.70000000000022, 81.19999999999925, -179.50000000000017, -14.800000000000015, -19.899999999999913, -82.30000000000003, 73.09999999999985, 0.20000000000000065, -203.19999999999996, -127.0, 22.700000000000063, 102.49999999999966, -34.29999999999985, -130.30000000000067, -166.10000000000002, 140.6, -288.7000000000003, 38.90000000000024, 62.60000000000021, -24.099999999999895, 2.899999999999995, -51.39999999999992, 20.000000000000014, 20.000000000000014, 76.69999999999965, 20.000000000000014, -180.50000000000003, 81.19999999999982, -99.10000000000001, 4.400000000000171, -187.90000000000003, -246.7000000000001, 91.99999999999953, 54.199999999999996, 20.000000000000014, -171.10000000000008, -173.2000000000002, -49.299999999999976], "policy_predator_policy_reward": [115.0, 0.0, 47.0, 0.0, 10.0, 0.0, 61.0, 51.0, 32.0, 47.0, 12.0, 46.0, 22.0, 38.0, 25.0, 28.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 5.0, 0.0, 6.0, 57.0, 31.0, 6.0, 0.0, 24.0, 0.0, 0.0, 12.0, 34.0, 66.0, 13.0, 33.0, 9.0, 0.0, 0.0, 0.0, 2.0, 93.0, 0.0, 125.0, 0.0, 24.0, 0.0, 0.0, 0.0, 64.0, 45.0, 133.0, 24.0, 19.0, 7.0, 71.0, 92.0, 26.0, 149.0, 8.0, 32.0, 36.0, 68.0, 0.0, 0.0, 111.0, 0.0, 0.0, 0.0, 55.0, 0.0, 3.0, 64.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 107.0, 0.0, 0.0, 4.0, 320.0, 69.0, 13.0, 0.0, 59.0, 3.0, 65.0, 38.0, 84.0, 53.0, 0.0, 0.0, 9.0, 131.0, 15.0, 0.0, 52.0, 64.0, 45.0, 1.0, 9.0, 29.0, 15.0, 0.0, 139.0, 0.0, 115.0, 5.0, 22.0, 0.0, 71.0, 101.0, 98.0, 34.0, 0.0, 61.0, 40.0, 5.0, 16.0, 0.0, 5.0, 90.0, 0.0, 113.0, 0.0, 32.0, 8.0, 4.0, 70.0, 6.0, 66.0, 34.0, 5.0, 0.0, 100.0, 58.0, 94.0, 143.0, 32.0, 16.0, 110.0, 173.0, 6.0, 33.0, 20.0, 118.0, 0.0, 3.0, 0.0, 123.0, 0.0, 69.0, 52.0, 11.0, 0.0, 124.0, 1.0, 0.0, 0.0, 106.0, 99.0, 0.0, 112.0, 43.0, 33.0, 2.0, 0.0, 48.0, 0.0, 0.0, 21.0, 0.0, 137.0, 0.0, 82.0, 25.0, 135.0, 0.0, 0.0, 0.0, 16.0, 90.0, 92.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0898754228805532, "mean_inference_ms": 3.0985354761315667, "mean_action_processing_ms": 0.4251752900517028, "mean_env_wait_ms": 0.38243529052538316, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009498238563537598, "StateBufferConnector_ms": 0.006244182586669922, "ViewRequirementAgentConnector_ms": 0.1532365083694458}, "num_episodes": 23, "episode_return_max": 170.89999999999955, "episode_return_min": -468.7000000000001, "episode_return_mean": -0.4030000000001445, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.8612396602652, "num_env_steps_trained_throughput_per_sec": 329.8612396602652, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 29431.602, "restore_workers_time_ms": 0.016, "training_step_time_ms": 29431.524, "sample_time_ms": 2795.357, "learn_time_ms": 26609.768, "learn_throughput": 150.321, "synch_weights_time_ms": 21.519}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "3a355_00000", "date": "2024-08-13_01-16-51", "timestamp": 1723526211, "time_this_iter_s": 12.165662288665771, "time_total_s": 421.24054741859436, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3ddfa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 421.24054741859436, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 55.18888888888888, "ram_util_percent": 83.36666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37346338337809637, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3092431588147684, "policy_loss": -0.0009354702087375459, "vf_loss": 2.310152605475572, "vf_explained_var": 0.0010838917008152715, "kl": 0.004162926293689794, "entropy": 1.1466771402686993, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.105553712400179, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1444192312381887, "policy_loss": -0.006527395954690676, "vf_loss": 3.1502008311962957, "vf_explained_var": 0.002535362313033412, "kl": 0.019887800808801984, "entropy": 1.396214663414728, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 170.89999999999955, "episode_reward_min": -468.7000000000001, "episode_reward_mean": -1.431000000000124, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -438.80000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 140.6, "predator_policy": 320.0}, "policy_reward_mean": {"prey_policy": -34.68550000000004, "predator_policy": 33.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.000000000000071, 40.0000000000003, 37.80000000000027, -158.900000000001, -136.80000000000078, 107.19999999999851, 41.800000000000324, -58.90000000000024, -136.6000000000009, 47.40000000000035, -326.1999999999971, -139.00000000000102, 31.100000000000378, -5.399999999999921, 40.0000000000003, -80.30000000000072, 49.900000000000446, -18.69999999999969, 2.300000000000193, -93.5000000000005, 40.0000000000003, 40.0000000000003, 87.79999999999875, 73.99999999999977, 89.49999999999868, 123.39999999999924, 111.99999999999824, 120.99999999999838, -66.00000000000045, 57.2000000000005, -468.7000000000001, 48.20000000000038, 21.300000000000296, 2.9000000000000736, -55.499999999999886, 40.0000000000003, -92.99999999999989, 58.600000000000456, -69.6, 170.89999999999955, 65.69999999999892, 23.500000000000277, -52.299999999999976, -34.39999999999983, 59.000000000000355, -99.70000000000059, -51.199999999999754, 118.69999999999965, 4.000000000000245, 111.49999999999852, -39.90000000000001, -164.10000000000113, 21.90000000000024, 55.60000000000031, -41.499999999999936, 56.59999999999957, 59.700000000000486, 7.5000000000001865, -26.899999999999856, 62.79999999999897, -57.09999999999972, 9.700000000000054, -104.0, 124.89999999999836, -71.29999999999994, -33.199999999999925, 136.29999999999959, -206.1999999999998, 126.19999999999908, -58.599999999999774, 73.5, -94.80000000000007, 73.49999999999984, -0.4999999999998941, 40.0000000000003, 117.69999999999914, 37.70000000000011, 12.300000000000216, -299.60000000000025, 146.199999999999, -45.09999999999999, -130.5000000000004, -105.40000000000077, 37.40000000000026, 66.10000000000035, -49.70000000000008, 57.19999999999954, 40.0000000000003, 40.0000000000003, -0.29999999999987104, -9.199999999999886, 45.900000000000404, 49.00000000000045, -24.399999999999686, 104.79999999999873, 52.200000000000415, -42.49999999999957, 50.90000000000043, -52.69999999999981, 79.79999999999927], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -55.00000000000023, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999962, -169.00000000000045, -82.90000000000049, -128.50000000000043, -133.30000000000072, 49.100000000000215, 34.100000000000115, 21.80000000000004, 20.000000000000014, -187.90000000000057, 20.000000000000014, -203.20000000000041, -90.39999999999985, 20.000000000000014, 1.3999999999999797, -248.80000000000032, -240.40000000000043, -21.09999999999978, -292.899999999999, -28.899999999999828, 20.000000000000014, -121.00000000000033, 11.599999999999957, 20.000000000000014, 20.000000000000014, -211.3000000000005, 20.000000000000014, 20.000000000000014, 29.900000000000187, 20.000000000000014, -93.70000000000059, 11.599999999999978, -76.30000000000013, -72.40000000000026, -111.10000000000028, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 63.800000000000196, 20.000000000000014, 53.00000000000023, 20.000000000000014, 41.60000000000025, 47.90000000000024, 64.99999999999997, 43.400000000000134, 56.900000000000226, 55.10000000000023, 56.0000000000002, 65.00000000000014, -155.20000000000056, -17.79999999999996, 11.599999999999966, 41.60000000000025, -438.80000000000007, -418.90000000000003, 42.5000000000002, -7.299999999999891, 20.000000000000014, -60.69999999999992, -126.40000000000029, 26.300000000000114, -116.20000000000002, -76.29999999999993, 20.000000000000014, 20.000000000000014, -181.6000000000006, -51.400000000000105, 23.600000000000083, 20.000000000000014, -79.30000000000013, -106.30000000000003, 64.09999999999982, 60.800000000000075, 5.299999999999981, 22.399999999999537, 20.000000000000014, -11.50000000000005, -239.50000000000009, 48.2000000000001, -90.39999999999998, -64.00000000000077, 46.40000000000017, -9.39999999999988, -79.60000000000039, -192.10000000000005, -45.09999999999984, -138.10000000000025, -15.400000000000048, 73.09999999999992, -71.80000000000008, 30.800000000000196, 29.000000000000185, 66.5, 1.0999999999999688, -135.9999999999999, -164.80000000000055, -112.30000000000047, 20.900000000000027, -30.999999999999993, 24.500000000000092, 19.1000000000002, 9.499999999999964, -127.00000000000007, -52.900000000000006, 9.500000000000213, 34.70000000000023, 20.000000000000014, 20.000000000000014, -170.49999999999994, 47.900000000000205, -311.8000000000002, 62.00000000000014, -47.20000000000002, -360.10000000000014, 20.000000000000014, 20.000000000000014, -49.299999999999905, 9.799999999999955, -251.79999999999995, 40.70000000000022, 81.19999999999925, -179.50000000000017, -14.800000000000015, -19.899999999999913, -82.30000000000003, 73.09999999999985, 0.20000000000000065, -203.19999999999996, -127.0, 22.700000000000063, 102.49999999999966, -34.29999999999985, -130.30000000000067, -166.10000000000002, 140.6, -288.7000000000003, 38.90000000000024, 62.60000000000021, -24.099999999999895, 2.899999999999995, -51.39999999999992, 20.000000000000014, 20.000000000000014, 76.69999999999965, 20.000000000000014, -180.50000000000003, 81.19999999999982, -99.10000000000001, 4.400000000000171, -187.90000000000003, -246.7000000000001, 91.99999999999953, 54.199999999999996, 20.000000000000014, -171.10000000000008, -173.2000000000002, -49.299999999999976, -46.299999999999876, -183.10000000000028, 13.399999999999965, 20.000000000000014, 25.400000000000112, 40.70000000000025, -174.70000000000047, 20.000000000000014, 50.90000000000009, -15.700000000000028, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -36.699999999999804, 7.39999999999998, -43.900000000000006, -46.29999999999998, 14.899999999999965, 20.000000000000014, 29.000000000000163, 20.000000000000014, -88.00000000000054, -30.39999999999978, 20.000000000000014, 84.79999999999939, 24.50000000000009, 7.6999999999999815, -68.20000000000013, -49.29999999999986, -0.1000000000000259, 20.000000000000014, 54.80000000000018, -242.49999999999991, 4.099999999999966, 67.69999999999992], "policy_predator_policy_reward": [33.0, 9.0, 0.0, 0.0, 0.0, 2.0, 93.0, 0.0, 125.0, 0.0, 24.0, 0.0, 0.0, 0.0, 64.0, 45.0, 133.0, 24.0, 19.0, 7.0, 71.0, 92.0, 26.0, 149.0, 8.0, 32.0, 36.0, 68.0, 0.0, 0.0, 111.0, 0.0, 0.0, 0.0, 55.0, 0.0, 3.0, 64.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 107.0, 0.0, 0.0, 4.0, 320.0, 69.0, 13.0, 0.0, 59.0, 3.0, 65.0, 38.0, 84.0, 53.0, 0.0, 0.0, 9.0, 131.0, 15.0, 0.0, 52.0, 64.0, 45.0, 1.0, 9.0, 29.0, 15.0, 0.0, 139.0, 0.0, 115.0, 5.0, 22.0, 0.0, 71.0, 101.0, 98.0, 34.0, 0.0, 61.0, 40.0, 5.0, 16.0, 0.0, 5.0, 90.0, 0.0, 113.0, 0.0, 32.0, 8.0, 4.0, 70.0, 6.0, 66.0, 34.0, 5.0, 0.0, 100.0, 58.0, 94.0, 143.0, 32.0, 16.0, 110.0, 173.0, 6.0, 33.0, 20.0, 118.0, 0.0, 3.0, 0.0, 123.0, 0.0, 69.0, 52.0, 11.0, 0.0, 124.0, 1.0, 0.0, 0.0, 106.0, 99.0, 0.0, 112.0, 43.0, 33.0, 2.0, 0.0, 48.0, 0.0, 0.0, 21.0, 0.0, 137.0, 0.0, 82.0, 25.0, 135.0, 0.0, 0.0, 0.0, 16.0, 90.0, 92.0, 0.0, 36.0, 88.0, 0.0, 4.0, 0.0, 0.0, 100.0, 5.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 42.0, 39.0, 11.0, 0.0, 0.0, 0.0, 43.0, 51.0, 0.0, 0.0, 0.0, 20.0, 31.0, 44.0, 0.0, 31.0, 28.0, 107.0, 0.0, 8.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0751106363486014, "mean_inference_ms": 3.0677936259299696, "mean_action_processing_ms": 0.41950297569293954, "mean_env_wait_ms": 0.3770045189215901, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009517908096313477, "StateBufferConnector_ms": 0.0062781572341918945, "ViewRequirementAgentConnector_ms": 0.16180932521820068}, "num_episodes": 18, "episode_return_max": 170.89999999999955, "episode_return_min": -468.7000000000001, "episode_return_mean": -1.431000000000124, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 339.63612699632347, "num_env_steps_trained_throughput_per_sec": 339.63612699632347, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 14664.755, "restore_workers_time_ms": 0.016, "training_step_time_ms": 14664.677, "sample_time_ms": 2649.832, "learn_time_ms": 11990.832, "learn_throughput": 333.588, "synch_weights_time_ms": 19.45}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "3a355_00000", "date": "2024-08-13_01-17-03", "timestamp": 1723526223, "time_this_iter_s": 11.825137853622437, "time_total_s": 433.0656852722168, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3cba940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 433.0656852722168, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 54.28125, "ram_util_percent": 83.01875000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.35527623510037465, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5081776036471917, "policy_loss": -0.004600539704952291, "vf_loss": 1.5127256724569533, "vf_explained_var": -0.0002599276562847158, "kl": 0.01679140311864819, "entropy": 1.0014469735521487, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0482662339729292, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.118911003278046, "policy_loss": -0.005946939494017334, "vf_loss": 2.1241321990098903, "vf_explained_var": 0.016729048730204345, "kl": 0.019353100344163352, "entropy": 1.3056218407772207, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 170.89999999999955, "episode_reward_min": -468.7000000000001, "episode_reward_mean": 11.321999999999832, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -438.80000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 140.6, "predator_policy": 320.0}, "policy_reward_mean": {"prey_policy": -25.324000000000026, "predator_policy": 30.985}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.300000000000193, -93.5000000000005, 40.0000000000003, 40.0000000000003, 87.79999999999875, 73.99999999999977, 89.49999999999868, 123.39999999999924, 111.99999999999824, 120.99999999999838, -66.00000000000045, 57.2000000000005, -468.7000000000001, 48.20000000000038, 21.300000000000296, 2.9000000000000736, -55.499999999999886, 40.0000000000003, -92.99999999999989, 58.600000000000456, -69.6, 170.89999999999955, 65.69999999999892, 23.500000000000277, -52.299999999999976, -34.39999999999983, 59.000000000000355, -99.70000000000059, -51.199999999999754, 118.69999999999965, 4.000000000000245, 111.49999999999852, -39.90000000000001, -164.10000000000113, 21.90000000000024, 55.60000000000031, -41.499999999999936, 56.59999999999957, 59.700000000000486, 7.5000000000001865, -26.899999999999856, 62.79999999999897, -57.09999999999972, 9.700000000000054, -104.0, 124.89999999999836, -71.29999999999994, -33.199999999999925, 136.29999999999959, -206.1999999999998, 126.19999999999908, -58.599999999999774, 73.5, -94.80000000000007, 73.49999999999984, -0.4999999999998941, 40.0000000000003, 117.69999999999914, 37.70000000000011, 12.300000000000216, -299.60000000000025, 146.199999999999, -45.09999999999999, -130.5000000000004, -105.40000000000077, 37.40000000000026, 66.10000000000035, -49.70000000000008, 57.19999999999954, 40.0000000000003, 40.0000000000003, -0.29999999999987104, -9.199999999999886, 45.900000000000404, 49.00000000000045, -24.399999999999686, 104.79999999999873, 52.200000000000415, -42.49999999999957, 50.90000000000043, -52.69999999999981, 79.79999999999927, -105.80000000000086, 16.100000000000076, 63.80000000000041, -33.299999999999535, 100.29999999999862, -0.6999999999998212, 106.59999999999894, 5.900000000000054, -50.19999999999977, 40.0000000000003, -5.099999999999735, 90.89999999999884, 64.3000000000004, 76.8999999999996, 101.19999999999878, -50.700000000000124, 137.9999999999986, 58.500000000000504], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999978, -76.30000000000013, -72.40000000000026, -111.10000000000028, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 63.800000000000196, 20.000000000000014, 53.00000000000023, 20.000000000000014, 41.60000000000025, 47.90000000000024, 64.99999999999997, 43.400000000000134, 56.900000000000226, 55.10000000000023, 56.0000000000002, 65.00000000000014, -155.20000000000056, -17.79999999999996, 11.599999999999966, 41.60000000000025, -438.80000000000007, -418.90000000000003, 42.5000000000002, -7.299999999999891, 20.000000000000014, -60.69999999999992, -126.40000000000029, 26.300000000000114, -116.20000000000002, -76.29999999999993, 20.000000000000014, 20.000000000000014, -181.6000000000006, -51.400000000000105, 23.600000000000083, 20.000000000000014, -79.30000000000013, -106.30000000000003, 64.09999999999982, 60.800000000000075, 5.299999999999981, 22.399999999999537, 20.000000000000014, -11.50000000000005, -239.50000000000009, 48.2000000000001, -90.39999999999998, -64.00000000000077, 46.40000000000017, -9.39999999999988, -79.60000000000039, -192.10000000000005, -45.09999999999984, -138.10000000000025, -15.400000000000048, 73.09999999999992, -71.80000000000008, 30.800000000000196, 29.000000000000185, 66.5, 1.0999999999999688, -135.9999999999999, -164.80000000000055, -112.30000000000047, 20.900000000000027, -30.999999999999993, 24.500000000000092, 19.1000000000002, 9.499999999999964, -127.00000000000007, -52.900000000000006, 9.500000000000213, 34.70000000000023, 20.000000000000014, 20.000000000000014, -170.49999999999994, 47.900000000000205, -311.8000000000002, 62.00000000000014, -47.20000000000002, -360.10000000000014, 20.000000000000014, 20.000000000000014, -49.299999999999905, 9.799999999999955, -251.79999999999995, 40.70000000000022, 81.19999999999925, -179.50000000000017, -14.800000000000015, -19.899999999999913, -82.30000000000003, 73.09999999999985, 0.20000000000000065, -203.19999999999996, -127.0, 22.700000000000063, 102.49999999999966, -34.29999999999985, -130.30000000000067, -166.10000000000002, 140.6, -288.7000000000003, 38.90000000000024, 62.60000000000021, -24.099999999999895, 2.899999999999995, -51.39999999999992, 20.000000000000014, 20.000000000000014, 76.69999999999965, 20.000000000000014, -180.50000000000003, 81.19999999999982, -99.10000000000001, 4.400000000000171, -187.90000000000003, -246.7000000000001, 91.99999999999953, 54.199999999999996, 20.000000000000014, -171.10000000000008, -173.2000000000002, -49.299999999999976, -46.299999999999876, -183.10000000000028, 13.399999999999965, 20.000000000000014, 25.400000000000112, 40.70000000000025, -174.70000000000047, 20.000000000000014, 50.90000000000009, -15.700000000000028, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -36.699999999999804, 7.39999999999998, -43.900000000000006, -46.29999999999998, 14.899999999999965, 20.000000000000014, 29.000000000000163, 20.000000000000014, -88.00000000000054, -30.39999999999978, 20.000000000000014, 84.79999999999939, 24.50000000000009, 7.6999999999999815, -68.20000000000013, -49.29999999999986, -0.1000000000000259, 20.000000000000014, 54.80000000000018, -242.49999999999991, 4.099999999999966, 67.69999999999992, -231.40000000000035, -18.39999999999975, -104.50000000000048, 32.60000000000023, 20.000000000000014, 27.80000000000016, -19.89999999999978, -51.39999999999999, 20.000000000000014, 80.29999999999932, -20.799999999999798, -37.89999999999976, 20.000000000000014, 86.59999999999951, -7.299999999999912, -17.79999999999979, 11.599999999999964, -143.80000000000044, 20.000000000000014, 20.000000000000014, -66.10000000000086, 20.000000000000014, 71.29999999999963, 17.599999999999984, 20.000000000000014, 44.300000000000196, 32.60000000000022, 44.300000000000246, 47.90000000000015, 53.30000000000023, -3.099999999999958, -160.60000000000056, 95.59999999999941, 28.40000000000017, 36.50000000000025, 20.000000000000014], "policy_predator_policy_reward": [3.0, 64.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 107.0, 0.0, 0.0, 4.0, 320.0, 69.0, 13.0, 0.0, 59.0, 3.0, 65.0, 38.0, 84.0, 53.0, 0.0, 0.0, 9.0, 131.0, 15.0, 0.0, 52.0, 64.0, 45.0, 1.0, 9.0, 29.0, 15.0, 0.0, 139.0, 0.0, 115.0, 5.0, 22.0, 0.0, 71.0, 101.0, 98.0, 34.0, 0.0, 61.0, 40.0, 5.0, 16.0, 0.0, 5.0, 90.0, 0.0, 113.0, 0.0, 32.0, 8.0, 4.0, 70.0, 6.0, 66.0, 34.0, 5.0, 0.0, 100.0, 58.0, 94.0, 143.0, 32.0, 16.0, 110.0, 173.0, 6.0, 33.0, 20.0, 118.0, 0.0, 3.0, 0.0, 123.0, 0.0, 69.0, 52.0, 11.0, 0.0, 124.0, 1.0, 0.0, 0.0, 106.0, 99.0, 0.0, 112.0, 43.0, 33.0, 2.0, 0.0, 48.0, 0.0, 0.0, 21.0, 0.0, 137.0, 0.0, 82.0, 25.0, 135.0, 0.0, 0.0, 0.0, 16.0, 90.0, 92.0, 0.0, 36.0, 88.0, 0.0, 4.0, 0.0, 0.0, 100.0, 5.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 42.0, 39.0, 11.0, 0.0, 0.0, 0.0, 43.0, 51.0, 0.0, 0.0, 0.0, 20.0, 31.0, 44.0, 0.0, 31.0, 28.0, 107.0, 0.0, 8.0, 124.0, 20.0, 45.0, 43.0, 16.0, 0.0, 38.0, 0.0, 0.0, 0.0, 36.0, 22.0, 0.0, 0.0, 31.0, 0.0, 0.0, 82.0, 0.0, 0.0, 0.0, 41.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 58.0, 14.0, 0.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0600390833905495, "mean_inference_ms": 3.035871465474654, "mean_action_processing_ms": 0.41376246082137186, "mean_env_wait_ms": 0.3714956780087768, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009440422058105469, "StateBufferConnector_ms": 0.006255507469177246, "ViewRequirementAgentConnector_ms": 0.15494167804718018}, "num_episodes": 18, "episode_return_max": 170.89999999999955, "episode_return_min": -468.7000000000001, "episode_return_mean": 11.321999999999832, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 326.7874808406579, "num_env_steps_trained_throughput_per_sec": 326.7874808406579, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 13991.282, "restore_workers_time_ms": 0.016, "training_step_time_ms": 13991.205, "sample_time_ms": 2024.913, "learn_time_ms": 11944.074, "learn_throughput": 334.894, "synch_weights_time_ms": 18.343}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "3a355_00000", "date": "2024-08-13_01-17-15", "timestamp": 1723526235, "time_this_iter_s": 12.28739881515503, "time_total_s": 445.3530840873718, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3ceeca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 445.3530840873718, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 61.18888888888888, "ram_util_percent": 83.50555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.36749035659290497, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0258507698301285, "policy_loss": -0.0026468817331882382, "vf_loss": 1.0284768370251176, "vf_explained_var": 0.0027481541116401633, "kl": 0.006660888061472522, "entropy": 1.026268503274867, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9657468402748386, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6203798755136116, "policy_loss": -0.004205696202972263, "vf_loss": 1.62383973790855, "vf_explained_var": 0.0006609791485720841, "kl": 0.019888809866431396, "entropy": 1.2862776899463917, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 170.89999999999955, "episode_reward_min": -299.60000000000025, "episode_reward_mean": 15.355999999999874, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -360.10000000000014, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 140.6, "predator_policy": 173.0}, "policy_reward_mean": {"prey_policy": -20.53700000000003, "predator_policy": 28.215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-92.99999999999989, 58.600000000000456, -69.6, 170.89999999999955, 65.69999999999892, 23.500000000000277, -52.299999999999976, -34.39999999999983, 59.000000000000355, -99.70000000000059, -51.199999999999754, 118.69999999999965, 4.000000000000245, 111.49999999999852, -39.90000000000001, -164.10000000000113, 21.90000000000024, 55.60000000000031, -41.499999999999936, 56.59999999999957, 59.700000000000486, 7.5000000000001865, -26.899999999999856, 62.79999999999897, -57.09999999999972, 9.700000000000054, -104.0, 124.89999999999836, -71.29999999999994, -33.199999999999925, 136.29999999999959, -206.1999999999998, 126.19999999999908, -58.599999999999774, 73.5, -94.80000000000007, 73.49999999999984, -0.4999999999998941, 40.0000000000003, 117.69999999999914, 37.70000000000011, 12.300000000000216, -299.60000000000025, 146.199999999999, -45.09999999999999, -130.5000000000004, -105.40000000000077, 37.40000000000026, 66.10000000000035, -49.70000000000008, 57.19999999999954, 40.0000000000003, 40.0000000000003, -0.29999999999987104, -9.199999999999886, 45.900000000000404, 49.00000000000045, -24.399999999999686, 104.79999999999873, 52.200000000000415, -42.49999999999957, 50.90000000000043, -52.69999999999981, 79.79999999999927, -105.80000000000086, 16.100000000000076, 63.80000000000041, -33.299999999999535, 100.29999999999862, -0.6999999999998212, 106.59999999999894, 5.900000000000054, -50.19999999999977, 40.0000000000003, -5.099999999999735, 90.89999999999884, 64.3000000000004, 76.8999999999996, 101.19999999999878, -50.700000000000124, 137.9999999999986, 58.500000000000504, 110.89999999999833, 4.800000000000157, 25.300000000000075, 66.10000000000035, -1.799999999999765, -219.50000000000023, -2.099999999999815, 45.8000000000004, 26.800000000000107, 60.00000000000048, 59.40000000000043, 31.100000000000158, 73.69999999999975, 91.29999999999849, 44.30000000000038, 40.0000000000003, 87.0999999999988, 36.100000000000335], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-181.6000000000006, -51.400000000000105, 23.600000000000083, 20.000000000000014, -79.30000000000013, -106.30000000000003, 64.09999999999982, 60.800000000000075, 5.299999999999981, 22.399999999999537, 20.000000000000014, -11.50000000000005, -239.50000000000009, 48.2000000000001, -90.39999999999998, -64.00000000000077, 46.40000000000017, -9.39999999999988, -79.60000000000039, -192.10000000000005, -45.09999999999984, -138.10000000000025, -15.400000000000048, 73.09999999999992, -71.80000000000008, 30.800000000000196, 29.000000000000185, 66.5, 1.0999999999999688, -135.9999999999999, -164.80000000000055, -112.30000000000047, 20.900000000000027, -30.999999999999993, 24.500000000000092, 19.1000000000002, 9.499999999999964, -127.00000000000007, -52.900000000000006, 9.500000000000213, 34.70000000000023, 20.000000000000014, 20.000000000000014, -170.49999999999994, 47.900000000000205, -311.8000000000002, 62.00000000000014, -47.20000000000002, -360.10000000000014, 20.000000000000014, 20.000000000000014, -49.299999999999905, 9.799999999999955, -251.79999999999995, 40.70000000000022, 81.19999999999925, -179.50000000000017, -14.800000000000015, -19.899999999999913, -82.30000000000003, 73.09999999999985, 0.20000000000000065, -203.19999999999996, -127.0, 22.700000000000063, 102.49999999999966, -34.29999999999985, -130.30000000000067, -166.10000000000002, 140.6, -288.7000000000003, 38.90000000000024, 62.60000000000021, -24.099999999999895, 2.899999999999995, -51.39999999999992, 20.000000000000014, 20.000000000000014, 76.69999999999965, 20.000000000000014, -180.50000000000003, 81.19999999999982, -99.10000000000001, 4.400000000000171, -187.90000000000003, -246.7000000000001, 91.99999999999953, 54.199999999999996, 20.000000000000014, -171.10000000000008, -173.2000000000002, -49.299999999999976, -46.299999999999876, -183.10000000000028, 13.399999999999965, 20.000000000000014, 25.400000000000112, 40.70000000000025, -174.70000000000047, 20.000000000000014, 50.90000000000009, -15.700000000000028, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -36.699999999999804, 7.39999999999998, -43.900000000000006, -46.29999999999998, 14.899999999999965, 20.000000000000014, 29.000000000000163, 20.000000000000014, -88.00000000000054, -30.39999999999978, 20.000000000000014, 84.79999999999939, 24.50000000000009, 7.6999999999999815, -68.20000000000013, -49.29999999999986, -0.1000000000000259, 20.000000000000014, 54.80000000000018, -242.49999999999991, 4.099999999999966, 67.69999999999992, -231.40000000000035, -18.39999999999975, -104.50000000000048, 32.60000000000023, 20.000000000000014, 27.80000000000016, -19.89999999999978, -51.39999999999999, 20.000000000000014, 80.29999999999932, -20.799999999999798, -37.89999999999976, 20.000000000000014, 86.59999999999951, -7.299999999999912, -17.79999999999979, 11.599999999999964, -143.80000000000044, 20.000000000000014, 20.000000000000014, -66.10000000000086, 20.000000000000014, 71.29999999999963, 17.599999999999984, 20.000000000000014, 44.300000000000196, 32.60000000000022, 44.300000000000246, 47.90000000000015, 53.30000000000023, -3.099999999999958, -160.60000000000056, 95.59999999999941, 28.40000000000017, 36.50000000000025, 20.000000000000014, 68.59999999999987, 32.30000000000022, -47.19999999999976, 20.000000000000014, -1.6000000000000352, -15.099999999999831, 46.10000000000024, 20.000000000000014, -59.80000000000061, 20.000000000000014, -156.40000000000018, -147.1000000000002, 15.799999999999963, -61.90000000000067, 38.000000000000256, -8.199999999999905, 20.000000000000014, -14.199999999999823, 32.00000000000022, 20.000000000000014, 46.70000000000024, -19.299999999999805, -9.399999999999855, 9.49999999999998, 58.10000000000019, 11.599999999999964, 29.90000000000019, 52.40000000000022, -66.10000000000082, 61.40000000000016, 20.000000000000014, 20.000000000000014, 46.10000000000023, 38.000000000000206, 5.299999999999965, 15.79999999999996], "policy_predator_policy_reward": [9.0, 131.0, 15.0, 0.0, 52.0, 64.0, 45.0, 1.0, 9.0, 29.0, 15.0, 0.0, 139.0, 0.0, 115.0, 5.0, 22.0, 0.0, 71.0, 101.0, 98.0, 34.0, 0.0, 61.0, 40.0, 5.0, 16.0, 0.0, 5.0, 90.0, 0.0, 113.0, 0.0, 32.0, 8.0, 4.0, 70.0, 6.0, 66.0, 34.0, 5.0, 0.0, 100.0, 58.0, 94.0, 143.0, 32.0, 16.0, 110.0, 173.0, 6.0, 33.0, 20.0, 118.0, 0.0, 3.0, 0.0, 123.0, 0.0, 69.0, 52.0, 11.0, 0.0, 124.0, 1.0, 0.0, 0.0, 106.0, 99.0, 0.0, 112.0, 43.0, 33.0, 2.0, 0.0, 48.0, 0.0, 0.0, 21.0, 0.0, 137.0, 0.0, 82.0, 25.0, 135.0, 0.0, 0.0, 0.0, 16.0, 90.0, 92.0, 0.0, 36.0, 88.0, 0.0, 4.0, 0.0, 0.0, 100.0, 5.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 42.0, 39.0, 11.0, 0.0, 0.0, 0.0, 43.0, 51.0, 0.0, 0.0, 0.0, 20.0, 31.0, 44.0, 0.0, 31.0, 28.0, 107.0, 0.0, 8.0, 124.0, 20.0, 45.0, 43.0, 16.0, 0.0, 38.0, 0.0, 0.0, 0.0, 36.0, 22.0, 0.0, 0.0, 31.0, 0.0, 0.0, 82.0, 0.0, 0.0, 0.0, 41.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 58.0, 14.0, 0.0, 2.0, 0.0, 10.0, 0.0, 32.0, 0.0, 25.0, 17.0, 0.0, 0.0, 0.0, 38.0, 84.0, 0.0, 39.0, 5.0, 0.0, 16.0, 0.0, 21.0, 8.0, 0.0, 9.0, 23.0, 31.0, 0.0, 0.0, 4.0, 9.0, 0.0, 29.0, 20.0, 0.0, 0.0, 3.0, 0.0, 15.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0502283855949723, "mean_inference_ms": 3.0114297546696793, "mean_action_processing_ms": 0.4092914041177783, "mean_env_wait_ms": 0.3670973956950958, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0102616548538208, "StateBufferConnector_ms": 0.005596160888671875, "ViewRequirementAgentConnector_ms": 0.175376296043396}, "num_episodes": 18, "episode_return_max": 170.89999999999955, "episode_return_min": -299.60000000000025, "episode_return_mean": 15.355999999999874, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 189.95748673255693, "num_env_steps_trained_throughput_per_sec": 189.95748673255693, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 14254.414, "restore_workers_time_ms": 0.016, "training_step_time_ms": 14254.337, "sample_time_ms": 2046.728, "learn_time_ms": 12184.597, "learn_throughput": 328.283, "synch_weights_time_ms": 19.597}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "3a355_00000", "date": "2024-08-13_01-17-37", "timestamp": 1723526257, "time_this_iter_s": 21.177242040634155, "time_total_s": 466.530326128006, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d6d8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 466.530326128006, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 85.93333333333334, "ram_util_percent": 83.72666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3253039344494778, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5273863130460972, "policy_loss": -0.003260263317836222, "vf_loss": 1.5306247816199348, "vf_explained_var": 0.0011876340896364243, "kl": 0.0069751902495276685, "entropy": 0.8670141545553056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8818267934300281, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.081584773492561, "policy_loss": -0.003185180928829131, "vf_loss": 2.0840097913666376, "vf_explained_var": -0.005781056294365535, "kl": 0.020271082189489708, "entropy": 1.2821938762589107, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 146.199999999999, "episode_reward_min": -299.60000000000025, "episode_reward_mean": 18.45599999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -288.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 140.6, "predator_policy": 137.0}, "policy_reward_mean": {"prey_policy": -11.527000000000019, "predator_policy": 20.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [124.89999999999836, -71.29999999999994, -33.199999999999925, 136.29999999999959, -206.1999999999998, 126.19999999999908, -58.599999999999774, 73.5, -94.80000000000007, 73.49999999999984, -0.4999999999998941, 40.0000000000003, 117.69999999999914, 37.70000000000011, 12.300000000000216, -299.60000000000025, 146.199999999999, -45.09999999999999, -130.5000000000004, -105.40000000000077, 37.40000000000026, 66.10000000000035, -49.70000000000008, 57.19999999999954, 40.0000000000003, 40.0000000000003, -0.29999999999987104, -9.199999999999886, 45.900000000000404, 49.00000000000045, -24.399999999999686, 104.79999999999873, 52.200000000000415, -42.49999999999957, 50.90000000000043, -52.69999999999981, 79.79999999999927, -105.80000000000086, 16.100000000000076, 63.80000000000041, -33.299999999999535, 100.29999999999862, -0.6999999999998212, 106.59999999999894, 5.900000000000054, -50.19999999999977, 40.0000000000003, -5.099999999999735, 90.89999999999884, 64.3000000000004, 76.8999999999996, 101.19999999999878, -50.700000000000124, 137.9999999999986, 58.500000000000504, 110.89999999999833, 4.800000000000157, 25.300000000000075, 66.10000000000035, -1.799999999999765, -219.50000000000023, -2.099999999999815, 45.8000000000004, 26.800000000000107, 60.00000000000048, 59.40000000000043, 31.100000000000158, 73.69999999999975, 91.29999999999849, 44.30000000000038, 40.0000000000003, 87.0999999999988, 36.100000000000335, 82.29999999999917, 51.90000000000042, 20.400000000000016, 75.99999999999963, -14.599999999999566, 40.0000000000003, 44.10000000000038, 32.90000000000022, 44.80000000000038, 15.799999999999976, 40.0000000000003, 40.0000000000003, 10.099999999999968, -198.10000000000076, -18.900000000000055, -19.399999999999658, 67.00000000000028, 57.600000000000264, 63.400000000000496, -90.00000000000097, 40.0000000000003, 9.100000000000056, -8.399999999999851, -15.199999999999564, 19.29999999999997, -33.699999999999555, 5.600000000000183], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [40.70000000000022, 81.19999999999925, -179.50000000000017, -14.800000000000015, -19.899999999999913, -82.30000000000003, 73.09999999999985, 0.20000000000000065, -203.19999999999996, -127.0, 22.700000000000063, 102.49999999999966, -34.29999999999985, -130.30000000000067, -166.10000000000002, 140.6, -288.7000000000003, 38.90000000000024, 62.60000000000021, -24.099999999999895, 2.899999999999995, -51.39999999999992, 20.000000000000014, 20.000000000000014, 76.69999999999965, 20.000000000000014, -180.50000000000003, 81.19999999999982, -99.10000000000001, 4.400000000000171, -187.90000000000003, -246.7000000000001, 91.99999999999953, 54.199999999999996, 20.000000000000014, -171.10000000000008, -173.2000000000002, -49.299999999999976, -46.299999999999876, -183.10000000000028, 13.399999999999965, 20.000000000000014, 25.400000000000112, 40.70000000000025, -174.70000000000047, 20.000000000000014, 50.90000000000009, -15.700000000000028, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -36.699999999999804, 7.39999999999998, -43.900000000000006, -46.29999999999998, 14.899999999999965, 20.000000000000014, 29.000000000000163, 20.000000000000014, -88.00000000000054, -30.39999999999978, 20.000000000000014, 84.79999999999939, 24.50000000000009, 7.6999999999999815, -68.20000000000013, -49.29999999999986, -0.1000000000000259, 20.000000000000014, 54.80000000000018, -242.49999999999991, 4.099999999999966, 67.69999999999992, -231.40000000000035, -18.39999999999975, -104.50000000000048, 32.60000000000023, 20.000000000000014, 27.80000000000016, -19.89999999999978, -51.39999999999999, 20.000000000000014, 80.29999999999932, -20.799999999999798, -37.89999999999976, 20.000000000000014, 86.59999999999951, -7.299999999999912, -17.79999999999979, 11.599999999999964, -143.80000000000044, 20.000000000000014, 20.000000000000014, -66.10000000000086, 20.000000000000014, 71.29999999999963, 17.599999999999984, 20.000000000000014, 44.300000000000196, 32.60000000000022, 44.300000000000246, 47.90000000000015, 53.30000000000023, -3.099999999999958, -160.60000000000056, 95.59999999999941, 28.40000000000017, 36.50000000000025, 20.000000000000014, 68.59999999999987, 32.30000000000022, -47.19999999999976, 20.000000000000014, -1.6000000000000352, -15.099999999999831, 46.10000000000024, 20.000000000000014, -59.80000000000061, 20.000000000000014, -156.40000000000018, -147.1000000000002, 15.799999999999963, -61.90000000000067, 38.000000000000256, -8.199999999999905, 20.000000000000014, -14.199999999999823, 32.00000000000022, 20.000000000000014, 46.70000000000024, -19.299999999999805, -9.399999999999855, 9.49999999999998, 58.10000000000019, 11.599999999999964, 29.90000000000019, 52.40000000000022, -66.10000000000082, 61.40000000000016, 20.000000000000014, 20.000000000000014, 46.10000000000023, 38.000000000000206, 5.299999999999965, 15.79999999999996, 62.30000000000021, 20.000000000000014, 36.20000000000026, -10.299999999999894, 20.000000000000014, -34.599999999999795, 49.70000000000024, 26.300000000000125, -16.599999999999767, -24.999999999999773, 20.000000000000014, 20.000000000000014, 43.70000000000024, -34.59999999999975, -20.799999999999798, 22.700000000000053, 6.7999999999999705, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -57.70000000000035, 30.800000000000196, -133.30000000000038, -185.80000000000038, -82.90000000000057, -1.0000000000000107, 20.000000000000014, -93.40000000000063, 33.50000000000024, 33.500000000000234, 56.00000000000012, -27.399999999999793, 43.40000000000024, 20.000000000000014, -178.7000000000004, -49.299999999999905, 20.000000000000014, 20.000000000000014, -13.599999999999783, -31.299999999999784, -72.40000000000057, 20.000000000000014, 20.000000000000014, -110.20000000000078, -27.69999999999977, 20.000000000000014, -120.70000000000076, 20.000000000000014, 3.1999999999999615, -13.599999999999783], "policy_predator_policy_reward": [0.0, 3.0, 0.0, 123.0, 0.0, 69.0, 52.0, 11.0, 0.0, 124.0, 1.0, 0.0, 0.0, 106.0, 99.0, 0.0, 112.0, 43.0, 33.0, 2.0, 0.0, 48.0, 0.0, 0.0, 21.0, 0.0, 137.0, 0.0, 82.0, 25.0, 135.0, 0.0, 0.0, 0.0, 16.0, 90.0, 92.0, 0.0, 36.0, 88.0, 0.0, 4.0, 0.0, 0.0, 100.0, 5.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 42.0, 39.0, 11.0, 0.0, 0.0, 0.0, 43.0, 51.0, 0.0, 0.0, 0.0, 20.0, 31.0, 44.0, 0.0, 31.0, 28.0, 107.0, 0.0, 8.0, 124.0, 20.0, 45.0, 43.0, 16.0, 0.0, 38.0, 0.0, 0.0, 0.0, 36.0, 22.0, 0.0, 0.0, 31.0, 0.0, 0.0, 82.0, 0.0, 0.0, 0.0, 41.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 58.0, 14.0, 0.0, 2.0, 0.0, 10.0, 0.0, 32.0, 0.0, 25.0, 17.0, 0.0, 0.0, 0.0, 38.0, 84.0, 0.0, 39.0, 5.0, 0.0, 16.0, 0.0, 21.0, 8.0, 0.0, 9.0, 23.0, 31.0, 0.0, 0.0, 4.0, 9.0, 0.0, 29.0, 20.0, 0.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 0.0, 26.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 26.0, 9.0, 31.0, 0.0, 8.0, 10.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 23.0, 98.0, 27.0, 38.0, 0.0, 54.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 105.0, 33.0, 0.0, 0.0, 20.0, 34.0, 0.0, 44.0, 43.0, 32.0, 27.0, 0.0, 67.0, 0.0, 0.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0468019812814051, "mean_inference_ms": 2.9987499086010767, "mean_action_processing_ms": 0.4068790294360907, "mean_env_wait_ms": 0.3638744737637169, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018870830535888672, "StateBufferConnector_ms": 0.00567936897277832, "ViewRequirementAgentConnector_ms": 0.19066011905670166}, "num_episodes": 27, "episode_return_max": 146.199999999999, "episode_return_min": -299.60000000000025, "episode_return_mean": 18.45599999999993, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 263.31324658573345, "num_env_steps_trained_throughput_per_sec": 263.31324658573345, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 14346.936, "restore_workers_time_ms": 0.016, "training_step_time_ms": 14346.86, "sample_time_ms": 2095.093, "learn_time_ms": 12228.306, "learn_throughput": 327.11, "synch_weights_time_ms": 19.868}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "3a355_00000", "date": "2024-08-13_01-17-52", "timestamp": 1723526272, "time_this_iter_s": 15.260867834091187, "time_total_s": 481.79119396209717, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3cba940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 481.79119396209717, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 72.35454545454544, "ram_util_percent": 83.43636363636364}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31198875620842925, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.546081348638686, "policy_loss": -0.0028882094343542736, "vf_loss": 2.548950850459003, "vf_explained_var": 0.00041149801047390733, "kl": 0.00598632412333056, "entropy": 0.8428152810328852, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9396331391597866, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2755252524027747, "policy_loss": -0.0014035719418504014, "vf_loss": 3.276237283938776, "vf_explained_var": 0.00040989896607777427, "kl": 0.012294032898353105, "entropy": 1.2054037518602199, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 137.9999999999986, "episode_reward_min": -511.0000000000001, "episode_reward_mean": 8.122000000000021, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -569.0999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 95.59999999999941, "predator_policy": 562.0}, "policy_reward_mean": {"prey_policy": -17.409000000000002, "predator_policy": 21.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-130.5000000000004, -105.40000000000077, 37.40000000000026, 66.10000000000035, -49.70000000000008, 57.19999999999954, 40.0000000000003, 40.0000000000003, -0.29999999999987104, -9.199999999999886, 45.900000000000404, 49.00000000000045, -24.399999999999686, 104.79999999999873, 52.200000000000415, -42.49999999999957, 50.90000000000043, -52.69999999999981, 79.79999999999927, -105.80000000000086, 16.100000000000076, 63.80000000000041, -33.299999999999535, 100.29999999999862, -0.6999999999998212, 106.59999999999894, 5.900000000000054, -50.19999999999977, 40.0000000000003, -5.099999999999735, 90.89999999999884, 64.3000000000004, 76.8999999999996, 101.19999999999878, -50.700000000000124, 137.9999999999986, 58.500000000000504, 110.89999999999833, 4.800000000000157, 25.300000000000075, 66.10000000000035, -1.799999999999765, -219.50000000000023, -2.099999999999815, 45.8000000000004, 26.800000000000107, 60.00000000000048, 59.40000000000043, 31.100000000000158, 73.69999999999975, 91.29999999999849, 44.30000000000038, 40.0000000000003, 87.0999999999988, 36.100000000000335, 82.29999999999917, 51.90000000000042, 20.400000000000016, 75.99999999999963, -14.599999999999566, 40.0000000000003, 44.10000000000038, 32.90000000000022, 44.80000000000038, 15.799999999999976, 40.0000000000003, 40.0000000000003, 10.099999999999968, -198.10000000000076, -18.900000000000055, -19.399999999999658, 67.00000000000028, 57.600000000000264, 63.400000000000496, -90.00000000000097, 40.0000000000003, 9.100000000000056, -8.399999999999851, -15.199999999999564, 19.29999999999997, -33.699999999999555, 5.600000000000183, -26.399999999999643, 48.50000000000045, -5.099999999999721, 40.0000000000003, 34.50000000000022, 67.80000000000013, 48.10000000000043, 4.200000000000053, 40.90000000000031, -15.299999999999635, -214.9000000000001, -269.0, -511.0000000000001, 35.400000000000226, 46.50000000000042, 55.00000000000044, 26.800000000000093, -360.3999999999987], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-173.2000000000002, -49.299999999999976, -46.299999999999876, -183.10000000000028, 13.399999999999965, 20.000000000000014, 25.400000000000112, 40.70000000000025, -174.70000000000047, 20.000000000000014, 50.90000000000009, -15.700000000000028, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -36.699999999999804, 7.39999999999998, -43.900000000000006, -46.29999999999998, 14.899999999999965, 20.000000000000014, 29.000000000000163, 20.000000000000014, -88.00000000000054, -30.39999999999978, 20.000000000000014, 84.79999999999939, 24.50000000000009, 7.6999999999999815, -68.20000000000013, -49.29999999999986, -0.1000000000000259, 20.000000000000014, 54.80000000000018, -242.49999999999991, 4.099999999999966, 67.69999999999992, -231.40000000000035, -18.39999999999975, -104.50000000000048, 32.60000000000023, 20.000000000000014, 27.80000000000016, -19.89999999999978, -51.39999999999999, 20.000000000000014, 80.29999999999932, -20.799999999999798, -37.89999999999976, 20.000000000000014, 86.59999999999951, -7.299999999999912, -17.79999999999979, 11.599999999999964, -143.80000000000044, 20.000000000000014, 20.000000000000014, -66.10000000000086, 20.000000000000014, 71.29999999999963, 17.599999999999984, 20.000000000000014, 44.300000000000196, 32.60000000000022, 44.300000000000246, 47.90000000000015, 53.30000000000023, -3.099999999999958, -160.60000000000056, 95.59999999999941, 28.40000000000017, 36.50000000000025, 20.000000000000014, 68.59999999999987, 32.30000000000022, -47.19999999999976, 20.000000000000014, -1.6000000000000352, -15.099999999999831, 46.10000000000024, 20.000000000000014, -59.80000000000061, 20.000000000000014, -156.40000000000018, -147.1000000000002, 15.799999999999963, -61.90000000000067, 38.000000000000256, -8.199999999999905, 20.000000000000014, -14.199999999999823, 32.00000000000022, 20.000000000000014, 46.70000000000024, -19.299999999999805, -9.399999999999855, 9.49999999999998, 58.10000000000019, 11.599999999999964, 29.90000000000019, 52.40000000000022, -66.10000000000082, 61.40000000000016, 20.000000000000014, 20.000000000000014, 46.10000000000023, 38.000000000000206, 5.299999999999965, 15.79999999999996, 62.30000000000021, 20.000000000000014, 36.20000000000026, -10.299999999999894, 20.000000000000014, -34.599999999999795, 49.70000000000024, 26.300000000000125, -16.599999999999767, -24.999999999999773, 20.000000000000014, 20.000000000000014, 43.70000000000024, -34.59999999999975, -20.799999999999798, 22.700000000000053, 6.7999999999999705, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -57.70000000000035, 30.800000000000196, -133.30000000000038, -185.80000000000038, -82.90000000000057, -1.0000000000000107, 20.000000000000014, -93.40000000000063, 33.50000000000024, 33.500000000000234, 56.00000000000012, -27.399999999999793, 43.40000000000024, 20.000000000000014, -178.7000000000004, -49.299999999999905, 20.000000000000014, 20.000000000000014, -13.599999999999783, -31.299999999999784, -72.40000000000057, 20.000000000000014, 20.000000000000014, -110.20000000000078, -27.69999999999977, 20.000000000000014, -120.70000000000076, 20.000000000000014, 3.1999999999999615, -13.599999999999783, -64.29999999999986, -24.09999999999976, 21.500000000000036, 20.000000000000014, -66.10000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999968, 20.000000000000014, 20.000000000000014, 33.80000000000019, 28.100000000000147, 20.000000000000014, 22.700000000000053, -53.500000000000036, 20.000000000000014, 20.90000000000003, -9.999999999999867, -70.30000000000067, -213.40000000000006, -263.5, -250.9, -177.10000000000002, -362.2000000000001, -353.79999999999995, 1.3999999999999602, 20.000000000000014, 33.20000000000024, 5.299999999999974, 49.40000000000022, -9.399999999999869, 15.199999999999964, -9.399999999999855, -353.2999999999994, -569.0999999999995], "policy_predator_policy_reward": [92.0, 0.0, 36.0, 88.0, 0.0, 4.0, 0.0, 0.0, 100.0, 5.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 42.0, 39.0, 11.0, 0.0, 0.0, 0.0, 43.0, 51.0, 0.0, 0.0, 0.0, 20.0, 31.0, 44.0, 0.0, 31.0, 28.0, 107.0, 0.0, 8.0, 124.0, 20.0, 45.0, 43.0, 16.0, 0.0, 38.0, 0.0, 0.0, 0.0, 36.0, 22.0, 0.0, 0.0, 31.0, 0.0, 0.0, 82.0, 0.0, 0.0, 0.0, 41.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 58.0, 14.0, 0.0, 2.0, 0.0, 10.0, 0.0, 32.0, 0.0, 25.0, 17.0, 0.0, 0.0, 0.0, 38.0, 84.0, 0.0, 39.0, 5.0, 0.0, 16.0, 0.0, 21.0, 8.0, 0.0, 9.0, 23.0, 31.0, 0.0, 0.0, 4.0, 9.0, 0.0, 29.0, 20.0, 0.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 0.0, 26.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 26.0, 9.0, 31.0, 0.0, 8.0, 10.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 23.0, 98.0, 27.0, 38.0, 0.0, 54.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 105.0, 33.0, 0.0, 0.0, 20.0, 34.0, 0.0, 44.0, 43.0, 32.0, 27.0, 0.0, 67.0, 0.0, 0.0, 16.0, 62.0, 0.0, 0.0, 7.0, 0.0, 41.0, 0.0, 0.0, 5.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 65.0, 135.0, 127.0, 143.0, 16.0, 46.0, 159.0, 0.0, 14.0, 1.0, 7.0, 15.0, 0.0, 7.0, 14.0, 562.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.051728540521656, "mean_inference_ms": 3.019605513209855, "mean_action_processing_ms": 0.4085720916323944, "mean_env_wait_ms": 0.36455307903310746, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015088558197021484, "StateBufferConnector_ms": 0.006234169006347656, "ViewRequirementAgentConnector_ms": 0.23183560371398926}, "num_episodes": 18, "episode_return_max": 137.9999999999986, "episode_return_min": -511.0000000000001, "episode_return_mean": 8.122000000000021, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 258.7975615188144, "num_env_steps_trained_throughput_per_sec": 258.7975615188144, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 14368.017, "restore_workers_time_ms": 0.017, "training_step_time_ms": 14367.938, "sample_time_ms": 2205.44, "learn_time_ms": 12138.479, "learn_throughput": 329.531, "synch_weights_time_ms": 20.071}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "3a355_00000", "date": "2024-08-13_01-18-08", "timestamp": 1723526288, "time_this_iter_s": 15.987982749938965, "time_total_s": 497.77917671203613, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df9280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 497.77917671203613, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 69.82727272727273, "ram_util_percent": 82.78181818181817}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3987273001383064, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7549480759908285, "policy_loss": -0.0018332312886342012, "vf_loss": 2.756769352804416, "vf_explained_var": 0.0016926320141585416, "kl": 0.003825509893105061, "entropy": 0.8789040667354745, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.059095858455335, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.641613130153172, "policy_loss": -0.004892915289444977, "vf_loss": 3.6455802623557036, "vf_explained_var": 0.0021665698321408065, "kl": 0.01645842337817009, "entropy": 1.2080267458365708, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 137.9999999999986, "episode_reward_min": -511.0000000000001, "episode_reward_mean": 1.6610000000000111, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -569.0999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 95.59999999999941, "predator_policy": 562.0}, "policy_reward_mean": {"prey_policy": -23.744499999999995, "predator_policy": 24.575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [79.79999999999927, -105.80000000000086, 16.100000000000076, 63.80000000000041, -33.299999999999535, 100.29999999999862, -0.6999999999998212, 106.59999999999894, 5.900000000000054, -50.19999999999977, 40.0000000000003, -5.099999999999735, 90.89999999999884, 64.3000000000004, 76.8999999999996, 101.19999999999878, -50.700000000000124, 137.9999999999986, 58.500000000000504, 110.89999999999833, 4.800000000000157, 25.300000000000075, 66.10000000000035, -1.799999999999765, -219.50000000000023, -2.099999999999815, 45.8000000000004, 26.800000000000107, 60.00000000000048, 59.40000000000043, 31.100000000000158, 73.69999999999975, 91.29999999999849, 44.30000000000038, 40.0000000000003, 87.0999999999988, 36.100000000000335, 82.29999999999917, 51.90000000000042, 20.400000000000016, 75.99999999999963, -14.599999999999566, 40.0000000000003, 44.10000000000038, 32.90000000000022, 44.80000000000038, 15.799999999999976, 40.0000000000003, 40.0000000000003, 10.099999999999968, -198.10000000000076, -18.900000000000055, -19.399999999999658, 67.00000000000028, 57.600000000000264, 63.400000000000496, -90.00000000000097, 40.0000000000003, 9.100000000000056, -8.399999999999851, -15.199999999999564, 19.29999999999997, -33.699999999999555, 5.600000000000183, -26.399999999999643, 48.50000000000045, -5.099999999999721, 40.0000000000003, 34.50000000000022, 67.80000000000013, 48.10000000000043, 4.200000000000053, 40.90000000000031, -15.299999999999635, -214.9000000000001, -269.0, -511.0000000000001, 35.400000000000226, 46.50000000000042, 55.00000000000044, 26.800000000000093, -360.3999999999987, -337.19999999999993, 76.1999999999996, 82.29999999999917, 40.0000000000003, 34.50000000000022, -91.80000000000001, 28.70000000000026, 39.9000000000003, -228.3000000000001, -134.39999999999986, -39.29999999999958, 40.0000000000003, 85.8999999999989, -64.59999999999994, -0.6999999999997644, -17.899999999999757, 74.19999999999968, -104.79999999999988], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [4.099999999999966, 67.69999999999992, -231.40000000000035, -18.39999999999975, -104.50000000000048, 32.60000000000023, 20.000000000000014, 27.80000000000016, -19.89999999999978, -51.39999999999999, 20.000000000000014, 80.29999999999932, -20.799999999999798, -37.89999999999976, 20.000000000000014, 86.59999999999951, -7.299999999999912, -17.79999999999979, 11.599999999999964, -143.80000000000044, 20.000000000000014, 20.000000000000014, -66.10000000000086, 20.000000000000014, 71.29999999999963, 17.599999999999984, 20.000000000000014, 44.300000000000196, 32.60000000000022, 44.300000000000246, 47.90000000000015, 53.30000000000023, -3.099999999999958, -160.60000000000056, 95.59999999999941, 28.40000000000017, 36.50000000000025, 20.000000000000014, 68.59999999999987, 32.30000000000022, -47.19999999999976, 20.000000000000014, -1.6000000000000352, -15.099999999999831, 46.10000000000024, 20.000000000000014, -59.80000000000061, 20.000000000000014, -156.40000000000018, -147.1000000000002, 15.799999999999963, -61.90000000000067, 38.000000000000256, -8.199999999999905, 20.000000000000014, -14.199999999999823, 32.00000000000022, 20.000000000000014, 46.70000000000024, -19.299999999999805, -9.399999999999855, 9.49999999999998, 58.10000000000019, 11.599999999999964, 29.90000000000019, 52.40000000000022, -66.10000000000082, 61.40000000000016, 20.000000000000014, 20.000000000000014, 46.10000000000023, 38.000000000000206, 5.299999999999965, 15.79999999999996, 62.30000000000021, 20.000000000000014, 36.20000000000026, -10.299999999999894, 20.000000000000014, -34.599999999999795, 49.70000000000024, 26.300000000000125, -16.599999999999767, -24.999999999999773, 20.000000000000014, 20.000000000000014, 43.70000000000024, -34.59999999999975, -20.799999999999798, 22.700000000000053, 6.7999999999999705, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -57.70000000000035, 30.800000000000196, -133.30000000000038, -185.80000000000038, -82.90000000000057, -1.0000000000000107, 20.000000000000014, -93.40000000000063, 33.50000000000024, 33.500000000000234, 56.00000000000012, -27.399999999999793, 43.40000000000024, 20.000000000000014, -178.7000000000004, -49.299999999999905, 20.000000000000014, 20.000000000000014, -13.599999999999783, -31.299999999999784, -72.40000000000057, 20.000000000000014, 20.000000000000014, -110.20000000000078, -27.69999999999977, 20.000000000000014, -120.70000000000076, 20.000000000000014, 3.1999999999999615, -13.599999999999783, -64.29999999999986, -24.09999999999976, 21.500000000000036, 20.000000000000014, -66.10000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999968, 20.000000000000014, 20.000000000000014, 33.80000000000019, 28.100000000000147, 20.000000000000014, 22.700000000000053, -53.500000000000036, 20.000000000000014, 20.90000000000003, -9.999999999999867, -70.30000000000067, -213.40000000000006, -263.5, -250.9, -177.10000000000002, -362.2000000000001, -353.79999999999995, 1.3999999999999602, 20.000000000000014, 33.20000000000024, 5.299999999999974, 49.40000000000022, -9.399999999999869, 15.199999999999964, -9.399999999999855, -353.2999999999994, -569.0999999999995, -372.7, -179.50000000000003, 29.90000000000018, 38.30000000000022, 20.000000000000014, 62.30000000000022, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 15.799999999999962, -223.60000000000016, 37.10000000000026, -75.40000000000063, 20.000000000000014, 14.899999999999967, -107.49999999999989, -395.8, -112.30000000000004, -103.10000000000004, -52.299999999999805, -63.99999999999977, 20.000000000000014, 20.000000000000014, 46.7000000000002, 21.200000000000205, 20.000000000000014, -407.5999999999999, -13.599999999999783, -24.09999999999976, -124.90000000000055, 38.000000000000256, 20.000000000000014, 54.20000000000019, -150.9999999999999, -101.79999999999984], "policy_predator_policy_reward": [0.0, 8.0, 124.0, 20.0, 45.0, 43.0, 16.0, 0.0, 38.0, 0.0, 0.0, 0.0, 36.0, 22.0, 0.0, 0.0, 31.0, 0.0, 0.0, 82.0, 0.0, 0.0, 0.0, 41.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 55.0, 58.0, 14.0, 0.0, 2.0, 0.0, 10.0, 0.0, 32.0, 0.0, 25.0, 17.0, 0.0, 0.0, 0.0, 38.0, 84.0, 0.0, 39.0, 5.0, 0.0, 16.0, 0.0, 21.0, 8.0, 0.0, 9.0, 23.0, 31.0, 0.0, 0.0, 4.0, 9.0, 0.0, 29.0, 20.0, 0.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 0.0, 26.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 26.0, 9.0, 31.0, 0.0, 8.0, 10.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 23.0, 98.0, 27.0, 38.0, 0.0, 54.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 105.0, 33.0, 0.0, 0.0, 20.0, 34.0, 0.0, 44.0, 43.0, 32.0, 27.0, 0.0, 67.0, 0.0, 0.0, 16.0, 62.0, 0.0, 0.0, 7.0, 0.0, 41.0, 0.0, 0.0, 5.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 65.0, 135.0, 127.0, 143.0, 16.0, 46.0, 159.0, 0.0, 14.0, 1.0, 7.0, 15.0, 0.0, 7.0, 14.0, 562.0, 0.0, 182.0, 33.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 116.0, 0.0, 43.0, 24.0, 0.0, 5.0, 77.0, 198.0, 81.0, 0.0, 15.0, 62.0, 0.0, 0.0, 9.0, 9.0, 323.0, 0.0, 21.0, 16.0, 16.0, 53.0, 0.0, 0.0, 90.0, 58.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0629748309207114, "mean_inference_ms": 3.0539975029919293, "mean_action_processing_ms": 0.4123308037405646, "mean_env_wait_ms": 0.3675865013642048, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015666604042053223, "StateBufferConnector_ms": 0.0063629150390625, "ViewRequirementAgentConnector_ms": 0.23946809768676758}, "num_episodes": 18, "episode_return_max": 137.9999999999986, "episode_return_min": -511.0000000000001, "episode_return_mean": 1.6610000000000111, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 211.76790869253853, "num_env_steps_trained_throughput_per_sec": 211.76790869253853, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 14972.562, "restore_workers_time_ms": 0.017, "training_step_time_ms": 14972.482, "sample_time_ms": 2387.168, "learn_time_ms": 12551.976, "learn_throughput": 318.675, "synch_weights_time_ms": 27.281}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "3a355_00000", "date": "2024-08-13_01-18-27", "timestamp": 1723526307, "time_this_iter_s": 19.12886095046997, "time_total_s": 516.9080376625061, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d6de50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 516.9080376625061, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 83.00714285714287, "ram_util_percent": 83.63214285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.32068825946164825, "cur_kl_coeff": 0.0015625, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.495743731468443, "policy_loss": -0.0028640671439774373, "vf_loss": 4.498596085694732, "vf_explained_var": 0.00032207136431699075, "kl": 0.007499225055024187, "entropy": 0.8780965473286059, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8822534776632748, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.590963682548079, "policy_loss": -0.0037323721634007242, "vf_loss": 4.593642879541589, "vf_explained_var": -0.00121046090252185, "kl": 0.01872311549624563, "entropy": 1.1695337606485559, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 110.89999999999833, "episode_reward_min": -511.0000000000001, "episode_reward_mean": -5.670999999999903, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -569.0999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 68.59999999999987, "predator_policy": 562.0}, "policy_reward_mean": {"prey_policy": -30.32549999999998, "predator_policy": 27.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [58.500000000000504, 110.89999999999833, 4.800000000000157, 25.300000000000075, 66.10000000000035, -1.799999999999765, -219.50000000000023, -2.099999999999815, 45.8000000000004, 26.800000000000107, 60.00000000000048, 59.40000000000043, 31.100000000000158, 73.69999999999975, 91.29999999999849, 44.30000000000038, 40.0000000000003, 87.0999999999988, 36.100000000000335, 82.29999999999917, 51.90000000000042, 20.400000000000016, 75.99999999999963, -14.599999999999566, 40.0000000000003, 44.10000000000038, 32.90000000000022, 44.80000000000038, 15.799999999999976, 40.0000000000003, 40.0000000000003, 10.099999999999968, -198.10000000000076, -18.900000000000055, -19.399999999999658, 67.00000000000028, 57.600000000000264, 63.400000000000496, -90.00000000000097, 40.0000000000003, 9.100000000000056, -8.399999999999851, -15.199999999999564, 19.29999999999997, -33.699999999999555, 5.600000000000183, -26.399999999999643, 48.50000000000045, -5.099999999999721, 40.0000000000003, 34.50000000000022, 67.80000000000013, 48.10000000000043, 4.200000000000053, 40.90000000000031, -15.299999999999635, -214.9000000000001, -269.0, -511.0000000000001, 35.400000000000226, 46.50000000000042, 55.00000000000044, 26.800000000000093, -360.3999999999987, -337.19999999999993, 76.1999999999996, 82.29999999999917, 40.0000000000003, 34.50000000000022, -91.80000000000001, 28.70000000000026, 39.9000000000003, -228.3000000000001, -134.39999999999986, -39.29999999999958, 40.0000000000003, 85.8999999999989, -64.59999999999994, -0.6999999999997644, -17.899999999999757, 74.19999999999968, -104.79999999999988, 66.10000000000034, 52.50000000000045, 2.500000000000372, 22.500000000000277, 53.50000000000048, -25.899999999999892, 34.20000000000021, 23.300000000000093, -50.79999999999992, -89.09999999999991, -25.799999999999955, -109.60000000000016, 0.7000000000001858, -81.29999999999987, 29.000000000000284, 40.90000000000031, 28.30000000000012, -66.20000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [36.50000000000025, 20.000000000000014, 68.59999999999987, 32.30000000000022, -47.19999999999976, 20.000000000000014, -1.6000000000000352, -15.099999999999831, 46.10000000000024, 20.000000000000014, -59.80000000000061, 20.000000000000014, -156.40000000000018, -147.1000000000002, 15.799999999999963, -61.90000000000067, 38.000000000000256, -8.199999999999905, 20.000000000000014, -14.199999999999823, 32.00000000000022, 20.000000000000014, 46.70000000000024, -19.299999999999805, -9.399999999999855, 9.49999999999998, 58.10000000000019, 11.599999999999964, 29.90000000000019, 52.40000000000022, -66.10000000000082, 61.40000000000016, 20.000000000000014, 20.000000000000014, 46.10000000000023, 38.000000000000206, 5.299999999999965, 15.79999999999996, 62.30000000000021, 20.000000000000014, 36.20000000000026, -10.299999999999894, 20.000000000000014, -34.599999999999795, 49.70000000000024, 26.300000000000125, -16.599999999999767, -24.999999999999773, 20.000000000000014, 20.000000000000014, 43.70000000000024, -34.59999999999975, -20.799999999999798, 22.700000000000053, 6.7999999999999705, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -57.70000000000035, 30.800000000000196, -133.30000000000038, -185.80000000000038, -82.90000000000057, -1.0000000000000107, 20.000000000000014, -93.40000000000063, 33.50000000000024, 33.500000000000234, 56.00000000000012, -27.399999999999793, 43.40000000000024, 20.000000000000014, -178.7000000000004, -49.299999999999905, 20.000000000000014, 20.000000000000014, -13.599999999999783, -31.299999999999784, -72.40000000000057, 20.000000000000014, 20.000000000000014, -110.20000000000078, -27.69999999999977, 20.000000000000014, -120.70000000000076, 20.000000000000014, 3.1999999999999615, -13.599999999999783, -64.29999999999986, -24.09999999999976, 21.500000000000036, 20.000000000000014, -66.10000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999968, 20.000000000000014, 20.000000000000014, 33.80000000000019, 28.100000000000147, 20.000000000000014, 22.700000000000053, -53.500000000000036, 20.000000000000014, 20.90000000000003, -9.999999999999867, -70.30000000000067, -213.40000000000006, -263.5, -250.9, -177.10000000000002, -362.2000000000001, -353.79999999999995, 1.3999999999999602, 20.000000000000014, 33.20000000000024, 5.299999999999974, 49.40000000000022, -9.399999999999869, 15.199999999999964, -9.399999999999855, -353.2999999999994, -569.0999999999995, -372.7, -179.50000000000003, 29.90000000000018, 38.30000000000022, 20.000000000000014, 62.30000000000022, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 15.799999999999962, -223.60000000000016, 37.10000000000026, -75.40000000000063, 20.000000000000014, 14.899999999999967, -107.49999999999989, -395.8, -112.30000000000004, -103.10000000000004, -52.299999999999805, -63.99999999999977, 20.000000000000014, 20.000000000000014, 46.7000000000002, 21.200000000000205, 20.000000000000014, -407.5999999999999, -13.599999999999783, -24.09999999999976, -124.90000000000055, 38.000000000000256, 20.000000000000014, 54.20000000000019, -150.9999999999999, -101.79999999999984, 46.100000000000236, 20.000000000000014, 8.600000000000087, 20.90000000000003, -83.49999999999986, 20.000000000000014, 17.900000000000013, -9.40000000000002, 33.500000000000234, 20.000000000000014, -57.699999999999996, -5.200000000000003, 20.000000000000014, 3.1999999999999793, 52.40000000000022, -150.10000000000068, -164.80000000000004, 20.000000000000014, -228.1000000000003, 20.000000000000014, -92.79999999999998, -18.99999999999976, 10.099999999999989, -282.7, -8.799999999999885, -35.49999999999978, -37.899999999999814, -201.40000000000038, -1.0, 20.000000000000014, 20.90000000000003, 20.000000000000014, -9.699999999999868, 20.000000000000014, -324.5, 5.299999999999965], "policy_predator_policy_reward": [2.0, 0.0, 10.0, 0.0, 32.0, 0.0, 25.0, 17.0, 0.0, 0.0, 0.0, 38.0, 84.0, 0.0, 39.0, 5.0, 0.0, 16.0, 0.0, 21.0, 8.0, 0.0, 9.0, 23.0, 31.0, 0.0, 0.0, 4.0, 9.0, 0.0, 29.0, 20.0, 0.0, 0.0, 3.0, 0.0, 15.0, 0.0, 0.0, 0.0, 26.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 26.0, 9.0, 31.0, 0.0, 8.0, 10.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 23.0, 98.0, 27.0, 38.0, 0.0, 54.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 105.0, 33.0, 0.0, 0.0, 20.0, 34.0, 0.0, 44.0, 43.0, 32.0, 27.0, 0.0, 67.0, 0.0, 0.0, 16.0, 62.0, 0.0, 0.0, 7.0, 0.0, 41.0, 0.0, 0.0, 5.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 65.0, 135.0, 127.0, 143.0, 16.0, 46.0, 159.0, 0.0, 14.0, 1.0, 7.0, 15.0, 0.0, 7.0, 14.0, 562.0, 0.0, 182.0, 33.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 116.0, 0.0, 43.0, 24.0, 0.0, 5.0, 77.0, 198.0, 81.0, 0.0, 15.0, 62.0, 0.0, 0.0, 9.0, 9.0, 323.0, 0.0, 21.0, 16.0, 16.0, 53.0, 0.0, 0.0, 90.0, 58.0, 0.0, 0.0, 3.0, 20.0, 66.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 37.0, 11.0, 0.0, 81.0, 40.0, 80.0, 14.0, 59.0, 60.0, 19.0, 67.0, 154.0, 9.0, 32.0, 13.0, 38.0, 120.0, 10.0, 0.0, 0.0, 0.0, 18.0, 0.0, 56.0, 197.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0855601964851989, "mean_inference_ms": 3.1114436625234623, "mean_action_processing_ms": 0.4195447940909602, "mean_env_wait_ms": 0.3732174542329807, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01755392551422119, "StateBufferConnector_ms": 0.007070422172546387, "ViewRequirementAgentConnector_ms": 0.2864784002304077}, "num_episodes": 18, "episode_return_max": 110.89999999999833, "episode_return_min": -511.0000000000001, "episode_return_mean": -5.670999999999903, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 107.91166467560835, "num_env_steps_trained_throughput_per_sec": 107.91166467560835, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 17161.235, "restore_workers_time_ms": 0.017, "training_step_time_ms": 17161.169, "sample_time_ms": 2621.081, "learn_time_ms": 14506.67, "learn_throughput": 275.735, "synch_weights_time_ms": 27.379}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "3a355_00000", "date": "2024-08-13_01-19-05", "timestamp": 1723526345, "time_this_iter_s": 37.22040796279907, "time_total_s": 554.1284456253052, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df8160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 554.1284456253052, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 93.07843137254902, "ram_util_percent": 84.07254901960783}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.41115697890165304, "cur_kl_coeff": 0.0015625, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.835182746756014, "policy_loss": -0.001990200801895409, "vf_loss": 5.83716651573383, "vf_explained_var": 0.005396222216742379, "kl": 0.00411207483819478, "entropy": 0.8859100097386294, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7973594227519931, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.74264658418282, "policy_loss": -0.0035459511290013633, "vf_loss": 6.745343777994631, "vf_explained_var": 0.0002866548835915863, "kl": 0.015089060466778359, "entropy": 1.1672526219534496, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 435.60000000000105, "episode_reward_min": -541.1999999999998, "episode_reward_mean": -35.87299999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -783.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.30000000000022, "predator_policy": 711.0}, "policy_reward_mean": {"prey_policy": -71.81649999999998, "predator_policy": 53.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [75.99999999999963, -14.599999999999566, 40.0000000000003, 44.10000000000038, 32.90000000000022, 44.80000000000038, 15.799999999999976, 40.0000000000003, 40.0000000000003, 10.099999999999968, -198.10000000000076, -18.900000000000055, -19.399999999999658, 67.00000000000028, 57.600000000000264, 63.400000000000496, -90.00000000000097, 40.0000000000003, 9.100000000000056, -8.399999999999851, -15.199999999999564, 19.29999999999997, -33.699999999999555, 5.600000000000183, -26.399999999999643, 48.50000000000045, -5.099999999999721, 40.0000000000003, 34.50000000000022, 67.80000000000013, 48.10000000000043, 4.200000000000053, 40.90000000000031, -15.299999999999635, -214.9000000000001, -269.0, -511.0000000000001, 35.400000000000226, 46.50000000000042, 55.00000000000044, 26.800000000000093, -360.3999999999987, -337.19999999999993, 76.1999999999996, 82.29999999999917, 40.0000000000003, 34.50000000000022, -91.80000000000001, 28.70000000000026, 39.9000000000003, -228.3000000000001, -134.39999999999986, -39.29999999999958, 40.0000000000003, 85.8999999999989, -64.59999999999994, -0.6999999999997644, -17.899999999999757, 74.19999999999968, -104.79999999999988, 66.10000000000034, 52.50000000000045, 2.500000000000372, 22.500000000000277, 53.50000000000048, -25.899999999999892, 34.20000000000021, 23.300000000000093, -50.79999999999992, -89.09999999999991, -25.799999999999955, -109.60000000000016, 0.7000000000001858, -81.29999999999987, 29.000000000000284, 40.90000000000031, 28.30000000000012, -66.20000000000036, -110.49999999999994, 14.700000000000264, -142.00000000000063, -12.49999999999969, -316.30000000000007, -80.19999999999979, 40.0000000000003, 40.0000000000003, 25.500000000000448, 10.300000000000066, -150.1000000000009, -120.10000000000036, 435.60000000000105, -85.39999999999962, -422.9, -64.40000000000006, 40.0000000000003, -317.7999999999998, -225.3, -40.49999999999975, -541.1999999999998, -204.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [49.70000000000024, 26.300000000000125, -16.599999999999767, -24.999999999999773, 20.000000000000014, 20.000000000000014, 43.70000000000024, -34.59999999999975, -20.799999999999798, 22.700000000000053, 6.7999999999999705, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -57.70000000000035, 30.800000000000196, -133.30000000000038, -185.80000000000038, -82.90000000000057, -1.0000000000000107, 20.000000000000014, -93.40000000000063, 33.50000000000024, 33.500000000000234, 56.00000000000012, -27.399999999999793, 43.40000000000024, 20.000000000000014, -178.7000000000004, -49.299999999999905, 20.000000000000014, 20.000000000000014, -13.599999999999783, -31.299999999999784, -72.40000000000057, 20.000000000000014, 20.000000000000014, -110.20000000000078, -27.69999999999977, 20.000000000000014, -120.70000000000076, 20.000000000000014, 3.1999999999999615, -13.599999999999783, -64.29999999999986, -24.09999999999976, 21.500000000000036, 20.000000000000014, -66.10000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999968, 20.000000000000014, 20.000000000000014, 33.80000000000019, 28.100000000000147, 20.000000000000014, 22.700000000000053, -53.500000000000036, 20.000000000000014, 20.90000000000003, -9.999999999999867, -70.30000000000067, -213.40000000000006, -263.5, -250.9, -177.10000000000002, -362.2000000000001, -353.79999999999995, 1.3999999999999602, 20.000000000000014, 33.20000000000024, 5.299999999999974, 49.40000000000022, -9.399999999999869, 15.199999999999964, -9.399999999999855, -353.2999999999994, -569.0999999999995, -372.7, -179.50000000000003, 29.90000000000018, 38.30000000000022, 20.000000000000014, 62.30000000000022, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 15.799999999999962, -223.60000000000016, 37.10000000000026, -75.40000000000063, 20.000000000000014, 14.899999999999967, -107.49999999999989, -395.8, -112.30000000000004, -103.10000000000004, -52.299999999999805, -63.99999999999977, 20.000000000000014, 20.000000000000014, 46.7000000000002, 21.200000000000205, 20.000000000000014, -407.5999999999999, -13.599999999999783, -24.09999999999976, -124.90000000000055, 38.000000000000256, 20.000000000000014, 54.20000000000019, -150.9999999999999, -101.79999999999984, 46.100000000000236, 20.000000000000014, 8.600000000000087, 20.90000000000003, -83.49999999999986, 20.000000000000014, 17.900000000000013, -9.40000000000002, 33.500000000000234, 20.000000000000014, -57.699999999999996, -5.200000000000003, 20.000000000000014, 3.1999999999999793, 52.40000000000022, -150.10000000000068, -164.80000000000004, 20.000000000000014, -228.1000000000003, 20.000000000000014, -92.79999999999998, -18.99999999999976, 10.099999999999989, -282.7, -8.799999999999885, -35.49999999999978, -37.899999999999814, -201.40000000000038, -1.0, 20.000000000000014, 20.90000000000003, 20.000000000000014, -9.699999999999868, 20.000000000000014, -324.5, 5.299999999999965, -597.3, -631.2, 20.000000000000014, -28.30000000000002, 20.000000000000014, -388.0, 31.400000000000233, -382.90000000000003, -190.00000000000003, -259.29999999999995, -215.20000000000036, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -28.30000000000003, -36.699999999999754, 20.000000000000014, -269.80000000000035, -133.30000000000055, 41.60000000000023, -455.69999999999993, -783.4, -21.999999999999744, -85.00000000000003, -51.39999999999981, -313.9, -424.0, -15.70000000000001, -117.69999999999985, 20.000000000000014, 20.000000000000014, -265.89999999999986, -277.9, -76.29999999999984, -361.0, 5.29999999999999, -158.7999999999999, -509.89999999999986, -542.3000000000003, -301.29999999999984, -393.40000000000003], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 26.0, 9.0, 31.0, 0.0, 8.0, 10.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 23.0, 98.0, 27.0, 38.0, 0.0, 54.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 105.0, 33.0, 0.0, 0.0, 20.0, 34.0, 0.0, 44.0, 43.0, 32.0, 27.0, 0.0, 67.0, 0.0, 0.0, 16.0, 62.0, 0.0, 0.0, 7.0, 0.0, 41.0, 0.0, 0.0, 5.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 65.0, 135.0, 127.0, 143.0, 16.0, 46.0, 159.0, 0.0, 14.0, 1.0, 7.0, 15.0, 0.0, 7.0, 14.0, 562.0, 0.0, 182.0, 33.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 116.0, 0.0, 43.0, 24.0, 0.0, 5.0, 77.0, 198.0, 81.0, 0.0, 15.0, 62.0, 0.0, 0.0, 9.0, 9.0, 323.0, 0.0, 21.0, 16.0, 16.0, 53.0, 0.0, 0.0, 90.0, 58.0, 0.0, 0.0, 3.0, 20.0, 66.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 37.0, 11.0, 0.0, 81.0, 40.0, 80.0, 14.0, 59.0, 60.0, 19.0, 67.0, 154.0, 9.0, 32.0, 13.0, 38.0, 120.0, 10.0, 0.0, 0.0, 0.0, 18.0, 0.0, 56.0, 197.0, 711.0, 407.0, 23.0, 0.0, 196.0, 30.0, 1.0, 338.0, 2.0, 131.0, 3.0, 112.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 27.0, 0.0, 114.0, 139.0, 19.0, 275.0, 606.0, 635.0, 51.0, 0.0, 210.0, 105.0, 3.0, 66.0, 0.0, 0.0, 155.0, 71.0, 187.0, 25.0, 110.0, 3.0, 496.0, 15.0, 337.0, 153.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.110037009836236, "mean_inference_ms": 3.174807061661607, "mean_action_processing_ms": 0.4277862258437549, "mean_env_wait_ms": 0.37888153992761614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020929336547851562, "StateBufferConnector_ms": 0.007265686988830566, "ViewRequirementAgentConnector_ms": 0.26656925678253174}, "num_episodes": 22, "episode_return_max": 435.60000000000105, "episode_return_min": -541.1999999999998, "episode_return_mean": -35.87299999999986, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 222.95362318694208, "num_env_steps_trained_throughput_per_sec": 222.95362318694208, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 17625.655, "restore_workers_time_ms": 0.018, "training_step_time_ms": 17625.589, "sample_time_ms": 2669.116, "learn_time_ms": 14922.827, "learn_throughput": 268.046, "synch_weights_time_ms": 27.435}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "3a355_00000", "date": "2024-08-13_01-19-23", "timestamp": 1723526363, "time_this_iter_s": 18.000189065933228, "time_total_s": 572.1286346912384, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df8550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 572.1286346912384, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 85.044, "ram_util_percent": 83.896}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.38505060616387893, "cur_kl_coeff": 0.00078125, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.913646778480086, "policy_loss": -0.001077446698028811, "vf_loss": 4.9147197332331745, "vf_explained_var": 0.0022637161628279107, "kl": 0.005751068500172684, "entropy": 0.9442790921087618, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8352136136796424, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.2430003784320975, "policy_loss": -0.0009012880704301611, "vf_loss": 5.243474954776663, "vf_explained_var": 0.0029443896321392563, "kl": 0.007585931748042106, "entropy": 1.2019581446571956, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 435.60000000000105, "episode_reward_min": -541.1999999999998, "episode_reward_mean": -59.626999999999896, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -804.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.30000000000022, "predator_policy": 711.0}, "policy_reward_mean": {"prey_policy": -104.80349999999999, "predator_policy": 74.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.600000000000183, -26.399999999999643, 48.50000000000045, -5.099999999999721, 40.0000000000003, 34.50000000000022, 67.80000000000013, 48.10000000000043, 4.200000000000053, 40.90000000000031, -15.299999999999635, -214.9000000000001, -269.0, -511.0000000000001, 35.400000000000226, 46.50000000000042, 55.00000000000044, 26.800000000000093, -360.3999999999987, -337.19999999999993, 76.1999999999996, 82.29999999999917, 40.0000000000003, 34.50000000000022, -91.80000000000001, 28.70000000000026, 39.9000000000003, -228.3000000000001, -134.39999999999986, -39.29999999999958, 40.0000000000003, 85.8999999999989, -64.59999999999994, -0.6999999999997644, -17.899999999999757, 74.19999999999968, -104.79999999999988, 66.10000000000034, 52.50000000000045, 2.500000000000372, 22.500000000000277, 53.50000000000048, -25.899999999999892, 34.20000000000021, 23.300000000000093, -50.79999999999992, -89.09999999999991, -25.799999999999955, -109.60000000000016, 0.7000000000001858, -81.29999999999987, 29.000000000000284, 40.90000000000031, 28.30000000000012, -66.20000000000036, -110.49999999999994, 14.700000000000264, -142.00000000000063, -12.49999999999969, -316.30000000000007, -80.19999999999979, 40.0000000000003, 40.0000000000003, 25.500000000000448, 10.300000000000066, -150.1000000000009, -120.10000000000036, 435.60000000000105, -85.39999999999962, -422.9, -64.40000000000006, 40.0000000000003, -317.7999999999998, -225.3, -40.49999999999975, -541.1999999999998, -204.7, 49.90000000000046, -4.39999999999978, -269.1999999999998, -80.10000000000099, -74.20000000000002, 37.80000000000027, -176.60000000000028, -77.00000000000085, -9.899999999999679, 64.30000000000048, 21.80000000000001, -4.099999999999767, -399.99999999999994, -365.8, -20.29999999999994, 81.0999999999992, 40.30000000000029, -227.0000000000002, -155.800000000001, -103.20000000000013, -109.60000000000056, -304.7999999999971, -86.80000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.1999999999999615, -13.599999999999783, -64.29999999999986, -24.09999999999976, 21.500000000000036, 20.000000000000014, -66.10000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999968, 20.000000000000014, 20.000000000000014, 33.80000000000019, 28.100000000000147, 20.000000000000014, 22.700000000000053, -53.500000000000036, 20.000000000000014, 20.90000000000003, -9.999999999999867, -70.30000000000067, -213.40000000000006, -263.5, -250.9, -177.10000000000002, -362.2000000000001, -353.79999999999995, 1.3999999999999602, 20.000000000000014, 33.20000000000024, 5.299999999999974, 49.40000000000022, -9.399999999999869, 15.199999999999964, -9.399999999999855, -353.2999999999994, -569.0999999999995, -372.7, -179.50000000000003, 29.90000000000018, 38.30000000000022, 20.000000000000014, 62.30000000000022, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 15.799999999999962, -223.60000000000016, 37.10000000000026, -75.40000000000063, 20.000000000000014, 14.899999999999967, -107.49999999999989, -395.8, -112.30000000000004, -103.10000000000004, -52.299999999999805, -63.99999999999977, 20.000000000000014, 20.000000000000014, 46.7000000000002, 21.200000000000205, 20.000000000000014, -407.5999999999999, -13.599999999999783, -24.09999999999976, -124.90000000000055, 38.000000000000256, 20.000000000000014, 54.20000000000019, -150.9999999999999, -101.79999999999984, 46.100000000000236, 20.000000000000014, 8.600000000000087, 20.90000000000003, -83.49999999999986, 20.000000000000014, 17.900000000000013, -9.40000000000002, 33.500000000000234, 20.000000000000014, -57.699999999999996, -5.200000000000003, 20.000000000000014, 3.1999999999999793, 52.40000000000022, -150.10000000000068, -164.80000000000004, 20.000000000000014, -228.1000000000003, 20.000000000000014, -92.79999999999998, -18.99999999999976, 10.099999999999989, -282.7, -8.799999999999885, -35.49999999999978, -37.899999999999814, -201.40000000000038, -1.0, 20.000000000000014, 20.90000000000003, 20.000000000000014, -9.699999999999868, 20.000000000000014, -324.5, 5.299999999999965, -597.3, -631.2, 20.000000000000014, -28.30000000000002, 20.000000000000014, -388.0, 31.400000000000233, -382.90000000000003, -190.00000000000003, -259.29999999999995, -215.20000000000036, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -28.30000000000003, -36.699999999999754, 20.000000000000014, -269.80000000000035, -133.30000000000055, 41.60000000000023, -455.69999999999993, -783.4, -21.999999999999744, -85.00000000000003, -51.39999999999981, -313.9, -424.0, -15.70000000000001, -117.69999999999985, 20.000000000000014, 20.000000000000014, -265.89999999999986, -277.9, -76.29999999999984, -361.0, 5.29999999999999, -158.7999999999999, -509.89999999999986, -542.3000000000003, -301.29999999999984, -393.40000000000003, 29.90000000000018, 20.000000000000014, -372.3, 47.900000000000205, -420.9, -175.3, 20.000000000000014, -210.1000000000004, -15.699999999999747, -170.49999999999997, 15.799999999999963, 20.000000000000014, -174.0999999999999, -239.5000000000003, -45.09999999999976, -488.9, 36.20000000000026, -210.10000000000002, 44.300000000000246, 20.000000000000014, 32.600000000000236, -38.799999999999756, -69.1, 20.000000000000014, -331.29999999999995, -804.7, -227.49999999999994, -599.3, -112.30000000000025, 20.000000000000014, 45.200000000000166, 29.90000000000019, -289.4999999999999, 57.80000000000019, -211.59999999999994, -132.39999999999998, -51.39999999999986, -219.4000000000004, 20.000000000000014, -408.20000000000016, -49.29999999999976, -196.30000000000018, -221.50000000000045, -232.30000000000027, -559.6, -442.20000000000005], "policy_predator_policy_reward": [0.0, 16.0, 62.0, 0.0, 0.0, 7.0, 0.0, 41.0, 0.0, 0.0, 5.0, 0.0, 2.0, 12.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 65.0, 135.0, 127.0, 143.0, 16.0, 46.0, 159.0, 0.0, 14.0, 1.0, 7.0, 15.0, 0.0, 7.0, 14.0, 562.0, 0.0, 182.0, 33.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 116.0, 0.0, 43.0, 24.0, 0.0, 5.0, 77.0, 198.0, 81.0, 0.0, 15.0, 62.0, 0.0, 0.0, 9.0, 9.0, 323.0, 0.0, 21.0, 16.0, 16.0, 53.0, 0.0, 0.0, 90.0, 58.0, 0.0, 0.0, 3.0, 20.0, 66.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 37.0, 11.0, 0.0, 81.0, 40.0, 80.0, 14.0, 59.0, 60.0, 19.0, 67.0, 154.0, 9.0, 32.0, 13.0, 38.0, 120.0, 10.0, 0.0, 0.0, 0.0, 18.0, 0.0, 56.0, 197.0, 711.0, 407.0, 23.0, 0.0, 196.0, 30.0, 1.0, 338.0, 2.0, 131.0, 3.0, 112.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 27.0, 0.0, 114.0, 139.0, 19.0, 275.0, 606.0, 635.0, 51.0, 0.0, 210.0, 105.0, 3.0, 66.0, 0.0, 0.0, 155.0, 71.0, 187.0, 25.0, 110.0, 3.0, 496.0, 15.0, 337.0, 153.0, 0.0, 0.0, 0.0, 320.0, 34.0, 293.0, 94.0, 16.0, 112.0, 0.0, 0.0, 2.0, 167.0, 70.0, 270.0, 187.0, 158.0, 6.0, 0.0, 0.0, 28.0, 0.0, 45.0, 0.0, 702.0, 34.0, 0.0, 461.0, 61.0, 11.0, 6.0, 0.0, 197.0, 75.0, 0.0, 117.0, 115.0, 0.0, 244.0, 41.0, 0.0, 136.0, 0.0, 149.0, 557.0, 358.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.12567658030778, "mean_inference_ms": 3.2259430352661, "mean_action_processing_ms": 0.4805662700313144, "mean_env_wait_ms": 0.38464280901353926, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01597142219543457, "StateBufferConnector_ms": 0.0067032575607299805, "ViewRequirementAgentConnector_ms": 0.2528665065765381}, "num_episodes": 23, "episode_return_max": 435.60000000000105, "episode_return_min": -541.1999999999998, "episode_return_mean": -59.626999999999896, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.1980858582396525, "num_env_steps_trained_throughput_per_sec": 4.1980858582396525, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 111456.068, "restore_workers_time_ms": 0.018, "training_step_time_ms": 111456.003, "sample_time_ms": 2951.005, "learn_time_ms": 108460.424, "learn_throughput": 36.88, "synch_weights_time_ms": 38.356}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "3a355_00000", "date": "2024-08-13_01-35-16", "timestamp": 1723527316, "time_this_iter_s": 953.578929901123, "time_total_s": 1525.7075645923615, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b50a65e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1525.7075645923615, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 85.709375, "ram_util_percent": 83.6875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.41161278757862946, "cur_kl_coeff": 0.00078125, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.906877782735875, "policy_loss": -0.0032378642766849783, "vf_loss": 3.910108729645058, "vf_explained_var": 0.0012380281138041664, "kl": 0.00886620985494533, "entropy": 0.9571896353411296, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0373744483840055, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6218989973976496, "policy_loss": -0.003362317747934155, "vf_loss": 3.624480198930811, "vf_explained_var": 0.0005983604640557022, "kl": 0.013886483363360532, "entropy": 1.2160696782132305, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 435.60000000000105, "episode_reward_min": -541.1999999999998, "episode_reward_mean": -49.45999999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -804.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.30000000000022, "predator_policy": 711.0}, "policy_reward_mean": {"prey_policy": -110.86499999999998, "predator_policy": 86.135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-360.3999999999987, -337.19999999999993, 76.1999999999996, 82.29999999999917, 40.0000000000003, 34.50000000000022, -91.80000000000001, 28.70000000000026, 39.9000000000003, -228.3000000000001, -134.39999999999986, -39.29999999999958, 40.0000000000003, 85.8999999999989, -64.59999999999994, -0.6999999999997644, -17.899999999999757, 74.19999999999968, -104.79999999999988, 66.10000000000034, 52.50000000000045, 2.500000000000372, 22.500000000000277, 53.50000000000048, -25.899999999999892, 34.20000000000021, 23.300000000000093, -50.79999999999992, -89.09999999999991, -25.799999999999955, -109.60000000000016, 0.7000000000001858, -81.29999999999987, 29.000000000000284, 40.90000000000031, 28.30000000000012, -66.20000000000036, -110.49999999999994, 14.700000000000264, -142.00000000000063, -12.49999999999969, -316.30000000000007, -80.19999999999979, 40.0000000000003, 40.0000000000003, 25.500000000000448, 10.300000000000066, -150.1000000000009, -120.10000000000036, 435.60000000000105, -85.39999999999962, -422.9, -64.40000000000006, 40.0000000000003, -317.7999999999998, -225.3, -40.49999999999975, -541.1999999999998, -204.7, 49.90000000000046, -4.39999999999978, -269.1999999999998, -80.10000000000099, -74.20000000000002, 37.80000000000027, -176.60000000000028, -77.00000000000085, -9.899999999999679, 64.30000000000048, 21.80000000000001, -4.099999999999767, -399.99999999999994, -365.8, -20.29999999999994, 81.0999999999992, 40.30000000000029, -227.0000000000002, -155.800000000001, -103.20000000000013, -109.60000000000056, -304.7999999999971, -86.80000000000004, -23.299999999999557, -152.49999999999991, 22.400000000000084, 23.500000000000277, 44.700000000000394, 57.700000000000415, 7.0, 56.09999999999998, 40.90000000000031, 37.50000000000026, -93.40000000000109, 103.09999999999997, 22.50000000000004, -110.20000000000039, 39.900000000000496, 40.0000000000003, 39.40000000000028, 273.0000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-353.2999999999994, -569.0999999999995, -372.7, -179.50000000000003, 29.90000000000018, 38.30000000000022, 20.000000000000014, 62.30000000000022, 20.000000000000014, 20.000000000000014, 9.499999999999964, 20.000000000000014, 15.799999999999962, -223.60000000000016, 37.10000000000026, -75.40000000000063, 20.000000000000014, 14.899999999999967, -107.49999999999989, -395.8, -112.30000000000004, -103.10000000000004, -52.299999999999805, -63.99999999999977, 20.000000000000014, 20.000000000000014, 46.7000000000002, 21.200000000000205, 20.000000000000014, -407.5999999999999, -13.599999999999783, -24.09999999999976, -124.90000000000055, 38.000000000000256, 20.000000000000014, 54.20000000000019, -150.9999999999999, -101.79999999999984, 46.100000000000236, 20.000000000000014, 8.600000000000087, 20.90000000000003, -83.49999999999986, 20.000000000000014, 17.900000000000013, -9.40000000000002, 33.500000000000234, 20.000000000000014, -57.699999999999996, -5.200000000000003, 20.000000000000014, 3.1999999999999793, 52.40000000000022, -150.10000000000068, -164.80000000000004, 20.000000000000014, -228.1000000000003, 20.000000000000014, -92.79999999999998, -18.99999999999976, 10.099999999999989, -282.7, -8.799999999999885, -35.49999999999978, -37.899999999999814, -201.40000000000038, -1.0, 20.000000000000014, 20.90000000000003, 20.000000000000014, -9.699999999999868, 20.000000000000014, -324.5, 5.299999999999965, -597.3, -631.2, 20.000000000000014, -28.30000000000002, 20.000000000000014, -388.0, 31.400000000000233, -382.90000000000003, -190.00000000000003, -259.29999999999995, -215.20000000000036, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -28.30000000000003, -36.699999999999754, 20.000000000000014, -269.80000000000035, -133.30000000000055, 41.60000000000023, -455.69999999999993, -783.4, -21.999999999999744, -85.00000000000003, -51.39999999999981, -313.9, -424.0, -15.70000000000001, -117.69999999999985, 20.000000000000014, 20.000000000000014, -265.89999999999986, -277.9, -76.29999999999984, -361.0, 5.29999999999999, -158.7999999999999, -509.89999999999986, -542.3000000000003, -301.29999999999984, -393.40000000000003, 29.90000000000018, 20.000000000000014, -372.3, 47.900000000000205, -420.9, -175.3, 20.000000000000014, -210.1000000000004, -15.699999999999747, -170.49999999999997, 15.799999999999963, 20.000000000000014, -174.0999999999999, -239.5000000000003, -45.09999999999976, -488.9, 36.20000000000026, -210.10000000000002, 44.300000000000246, 20.000000000000014, 32.600000000000236, -38.799999999999756, -69.1, 20.000000000000014, -331.29999999999995, -804.7, -227.49999999999994, -599.3, -112.30000000000025, 20.000000000000014, 45.200000000000166, 29.90000000000019, -289.4999999999999, 57.80000000000019, -211.59999999999994, -132.39999999999998, -51.39999999999986, -219.4000000000004, 20.000000000000014, -408.20000000000016, -49.29999999999976, -196.30000000000018, -221.50000000000045, -232.30000000000027, -559.6, -442.20000000000005, 20.000000000000014, -112.30000000000078, -548.7, -206.8, 26.300000000000114, -28.899999999999757, 20.000000000000014, -11.500000000000007, 29.90000000000018, -11.199999999999877, 44.3000000000002, 7.399999999999965, -42.99999999999981, 20.000000000000014, 20.000000000000014, -280.90000000000003, 20.90000000000003, 20.000000000000014, 9.499999999999968, 20.000000000000014, -82.90000000000079, -158.50000000000043, -288.9, 20.000000000000014, -9.399999999999926, 17.899999999999977, -245.50000000000037, -538.7, 20.000000000000014, 5.90000000000019, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999972, 17.899999999999984, -569.8999999999999], "policy_predator_policy_reward": [562.0, 0.0, 182.0, 33.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 116.0, 0.0, 43.0, 24.0, 0.0, 5.0, 77.0, 198.0, 81.0, 0.0, 15.0, 62.0, 0.0, 0.0, 9.0, 9.0, 323.0, 0.0, 21.0, 16.0, 16.0, 53.0, 0.0, 0.0, 90.0, 58.0, 0.0, 0.0, 3.0, 20.0, 66.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 37.0, 11.0, 0.0, 81.0, 40.0, 80.0, 14.0, 59.0, 60.0, 19.0, 67.0, 154.0, 9.0, 32.0, 13.0, 38.0, 120.0, 10.0, 0.0, 0.0, 0.0, 18.0, 0.0, 56.0, 197.0, 711.0, 407.0, 23.0, 0.0, 196.0, 30.0, 1.0, 338.0, 2.0, 131.0, 3.0, 112.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 27.0, 0.0, 114.0, 139.0, 19.0, 275.0, 606.0, 635.0, 51.0, 0.0, 210.0, 105.0, 3.0, 66.0, 0.0, 0.0, 155.0, 71.0, 187.0, 25.0, 110.0, 3.0, 496.0, 15.0, 337.0, 153.0, 0.0, 0.0, 0.0, 320.0, 34.0, 293.0, 94.0, 16.0, 112.0, 0.0, 0.0, 2.0, 167.0, 70.0, 270.0, 187.0, 158.0, 6.0, 0.0, 0.0, 28.0, 0.0, 45.0, 0.0, 702.0, 34.0, 0.0, 461.0, 61.0, 11.0, 6.0, 0.0, 197.0, 75.0, 0.0, 117.0, 115.0, 0.0, 244.0, 41.0, 0.0, 136.0, 0.0, 149.0, 557.0, 358.0, 61.0, 8.0, 350.0, 253.0, 25.0, 0.0, 0.0, 15.0, 23.0, 3.0, 6.0, 0.0, 30.0, 0.0, 145.0, 172.0, 0.0, 0.0, 8.0, 0.0, 33.0, 115.0, 199.0, 173.0, 14.0, 0.0, 427.0, 247.0, 14.0, 0.0, 0.0, 0.0, 0.0, 12.0, 401.0, 424.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.141761486748601, "mean_inference_ms": 3.264772825463132, "mean_action_processing_ms": 0.5199752945867617, "mean_env_wait_ms": 0.38879778582996855, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027100682258605957, "StateBufferConnector_ms": 0.006994843482971191, "ViewRequirementAgentConnector_ms": 0.23039734363555908}, "num_episodes": 18, "episode_return_max": 435.60000000000105, "episode_return_min": -541.1999999999998, "episode_return_mean": -49.45999999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 136.49655102299783, "num_env_steps_trained_throughput_per_sec": 136.49655102299783, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 113173.918, "restore_workers_time_ms": 0.02, "training_step_time_ms": 113173.853, "sample_time_ms": 3228.728, "learn_time_ms": 109898.5, "learn_throughput": 36.397, "synch_weights_time_ms": 39.67}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "3a355_00000", "date": "2024-08-13_01-35-46", "timestamp": 1723527346, "time_this_iter_s": 29.52088189125061, "time_total_s": 1555.228446483612, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3c8b790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1555.228446483612, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 96.72926829268293, "ram_util_percent": 83.71463414634147}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5437823036478625, "cur_kl_coeff": 0.00078125, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.39031626988971, "policy_loss": -0.0014288248856448465, "vf_loss": 5.391740177800416, "vf_explained_var": 0.0007735791029753508, "kl": 0.006293890989245808, "entropy": 0.9175133930942999, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0982019762316393, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.965266160107164, "policy_loss": -0.0035240821960436366, "vf_loss": 5.968021325964146, "vf_explained_var": 0.001801217169988723, "kl": 0.013669484751720473, "entropy": 1.2126703739796996, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 435.60000000000105, "episode_reward_min": -541.1999999999998, "episode_reward_mean": -47.70899999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -804.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 57.80000000000021, "predator_policy": 711.0}, "policy_reward_mean": {"prey_policy": -114.90950000000001, "predator_policy": 91.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-104.79999999999988, 66.10000000000034, 52.50000000000045, 2.500000000000372, 22.500000000000277, 53.50000000000048, -25.899999999999892, 34.20000000000021, 23.300000000000093, -50.79999999999992, -89.09999999999991, -25.799999999999955, -109.60000000000016, 0.7000000000001858, -81.29999999999987, 29.000000000000284, 40.90000000000031, 28.30000000000012, -66.20000000000036, -110.49999999999994, 14.700000000000264, -142.00000000000063, -12.49999999999969, -316.30000000000007, -80.19999999999979, 40.0000000000003, 40.0000000000003, 25.500000000000448, 10.300000000000066, -150.1000000000009, -120.10000000000036, 435.60000000000105, -85.39999999999962, -422.9, -64.40000000000006, 40.0000000000003, -317.7999999999998, -225.3, -40.49999999999975, -541.1999999999998, -204.7, 49.90000000000046, -4.39999999999978, -269.1999999999998, -80.10000000000099, -74.20000000000002, 37.80000000000027, -176.60000000000028, -77.00000000000085, -9.899999999999679, 64.30000000000048, 21.80000000000001, -4.099999999999767, -399.99999999999994, -365.8, -20.29999999999994, 81.0999999999992, 40.30000000000029, -227.0000000000002, -155.800000000001, -103.20000000000013, -109.60000000000056, -304.7999999999971, -86.80000000000004, -23.299999999999557, -152.49999999999991, 22.400000000000084, 23.500000000000277, 44.700000000000394, 57.700000000000415, 7.0, 56.09999999999998, 40.90000000000031, 37.50000000000026, -93.40000000000109, 103.09999999999997, 22.50000000000004, -110.20000000000039, 39.900000000000496, 40.0000000000003, 39.40000000000028, 273.0000000000001, 42.30000000000003, 2.5000000000003326, -104.90000000000032, 67.59999999999998, -278.1000000000006, -51.79999999999989, 48.300000000000345, 27.900000000000205, 38.90000000000028, -58.099999999999994, -12.799999999999825, 53.20000000000051, 40.0000000000003, -170.2999999999999, -93.10000000000016, -120.60000000000099, 7.60000000000022, -36.399999999999785], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-150.9999999999999, -101.79999999999984, 46.100000000000236, 20.000000000000014, 8.600000000000087, 20.90000000000003, -83.49999999999986, 20.000000000000014, 17.900000000000013, -9.40000000000002, 33.500000000000234, 20.000000000000014, -57.699999999999996, -5.200000000000003, 20.000000000000014, 3.1999999999999793, 52.40000000000022, -150.10000000000068, -164.80000000000004, 20.000000000000014, -228.1000000000003, 20.000000000000014, -92.79999999999998, -18.99999999999976, 10.099999999999989, -282.7, -8.799999999999885, -35.49999999999978, -37.899999999999814, -201.40000000000038, -1.0, 20.000000000000014, 20.90000000000003, 20.000000000000014, -9.699999999999868, 20.000000000000014, -324.5, 5.299999999999965, -597.3, -631.2, 20.000000000000014, -28.30000000000002, 20.000000000000014, -388.0, 31.400000000000233, -382.90000000000003, -190.00000000000003, -259.29999999999995, -215.20000000000036, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -28.30000000000003, -36.699999999999754, 20.000000000000014, -269.80000000000035, -133.30000000000055, 41.60000000000023, -455.69999999999993, -783.4, -21.999999999999744, -85.00000000000003, -51.39999999999981, -313.9, -424.0, -15.70000000000001, -117.69999999999985, 20.000000000000014, 20.000000000000014, -265.89999999999986, -277.9, -76.29999999999984, -361.0, 5.29999999999999, -158.7999999999999, -509.89999999999986, -542.3000000000003, -301.29999999999984, -393.40000000000003, 29.90000000000018, 20.000000000000014, -372.3, 47.900000000000205, -420.9, -175.3, 20.000000000000014, -210.1000000000004, -15.699999999999747, -170.49999999999997, 15.799999999999963, 20.000000000000014, -174.0999999999999, -239.5000000000003, -45.09999999999976, -488.9, 36.20000000000026, -210.10000000000002, 44.300000000000246, 20.000000000000014, 32.600000000000236, -38.799999999999756, -69.1, 20.000000000000014, -331.29999999999995, -804.7, -227.49999999999994, -599.3, -112.30000000000025, 20.000000000000014, 45.200000000000166, 29.90000000000019, -289.4999999999999, 57.80000000000019, -211.59999999999994, -132.39999999999998, -51.39999999999986, -219.4000000000004, 20.000000000000014, -408.20000000000016, -49.29999999999976, -196.30000000000018, -221.50000000000045, -232.30000000000027, -559.6, -442.20000000000005, 20.000000000000014, -112.30000000000078, -548.7, -206.8, 26.300000000000114, -28.899999999999757, 20.000000000000014, -11.500000000000007, 29.90000000000018, -11.199999999999877, 44.3000000000002, 7.399999999999965, -42.99999999999981, 20.000000000000014, 20.000000000000014, -280.90000000000003, 20.90000000000003, 20.000000000000014, 9.499999999999968, 20.000000000000014, -82.90000000000079, -158.50000000000043, -288.9, 20.000000000000014, -9.399999999999926, 17.899999999999977, -245.50000000000037, -538.7, 20.000000000000014, 5.90000000000019, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999972, 17.899999999999984, -569.8999999999999, 20.000000000000014, -449.7, 37.40000000000022, -228.90000000000003, 11.59999999999996, -299.49999999999994, -5.199999999999948, 57.80000000000021, -238.79999999999998, -265.29999999999995, 20.000000000000014, -749.8, -55.000000000000014, 53.300000000000175, 26.000000000000128, -36.09999999999981, 20.000000000000014, 17.899999999999984, -164.00000000000003, -3.100000000000049, -11.799999999999983, -64.0000000000008, 27.200000000000244, 20.000000000000014, 20.000000000000014, 20.000000000000014, -167.40000000000003, -175.9, -200.5, -13.599999999999786, -117.10000000000068, -242.5000000000003, 56.90000000000015, -112.29999999999984, -72.40000000000043, -174.99999999999991], "policy_predator_policy_reward": [90.0, 58.0, 0.0, 0.0, 3.0, 20.0, 66.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 37.0, 11.0, 0.0, 81.0, 40.0, 80.0, 14.0, 59.0, 60.0, 19.0, 67.0, 154.0, 9.0, 32.0, 13.0, 38.0, 120.0, 10.0, 0.0, 0.0, 0.0, 18.0, 0.0, 56.0, 197.0, 711.0, 407.0, 23.0, 0.0, 196.0, 30.0, 1.0, 338.0, 2.0, 131.0, 3.0, 112.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 27.0, 0.0, 114.0, 139.0, 19.0, 275.0, 606.0, 635.0, 51.0, 0.0, 210.0, 105.0, 3.0, 66.0, 0.0, 0.0, 155.0, 71.0, 187.0, 25.0, 110.0, 3.0, 496.0, 15.0, 337.0, 153.0, 0.0, 0.0, 0.0, 320.0, 34.0, 293.0, 94.0, 16.0, 112.0, 0.0, 0.0, 2.0, 167.0, 70.0, 270.0, 187.0, 158.0, 6.0, 0.0, 0.0, 28.0, 0.0, 45.0, 0.0, 702.0, 34.0, 0.0, 461.0, 61.0, 11.0, 6.0, 0.0, 197.0, 75.0, 0.0, 117.0, 115.0, 0.0, 244.0, 41.0, 0.0, 136.0, 0.0, 149.0, 557.0, 358.0, 61.0, 8.0, 350.0, 253.0, 25.0, 0.0, 0.0, 15.0, 23.0, 3.0, 6.0, 0.0, 30.0, 0.0, 145.0, 172.0, 0.0, 0.0, 8.0, 0.0, 33.0, 115.0, 199.0, 173.0, 14.0, 0.0, 427.0, 247.0, 14.0, 0.0, 0.0, 0.0, 0.0, 12.0, 401.0, 424.0, 103.0, 369.0, 194.0, 0.0, 132.0, 51.0, 12.0, 3.0, 202.0, 24.0, 0.0, 678.0, 36.0, 14.0, 0.0, 38.0, 0.0, 1.0, 104.0, 5.0, 7.0, 56.0, 0.0, 6.0, 0.0, 0.0, 22.0, 151.0, 121.0, 0.0, 120.0, 119.0, 14.0, 49.0, 104.0, 107.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1632193878760024, "mean_inference_ms": 3.3168832401741963, "mean_action_processing_ms": 0.5600167397469547, "mean_env_wait_ms": 0.39531431110258525, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.026691317558288574, "StateBufferConnector_ms": 0.006994009017944336, "ViewRequirementAgentConnector_ms": 0.22722244262695312}, "num_episodes": 18, "episode_return_max": 435.60000000000105, "episode_return_min": -541.1999999999998, "episode_return_mean": -47.70899999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 194.78237706231764, "num_env_steps_trained_throughput_per_sec": 194.78237706231764, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 114049.762, "restore_workers_time_ms": 0.023, "training_step_time_ms": 114049.69, "sample_time_ms": 3619.621, "learn_time_ms": 110380.211, "learn_throughput": 36.238, "synch_weights_time_ms": 42.69}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "3a355_00000", "date": "2024-08-13_01-36-07", "timestamp": 1723527367, "time_this_iter_s": 20.605491876602173, "time_total_s": 1575.8339383602142, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3ddfee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1575.8339383602142, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 89.46206896551723, "ram_util_percent": 83.74137931034483}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4941915212011842, "cur_kl_coeff": 0.00078125, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.006089789400656, "policy_loss": -0.0008366274986189431, "vf_loss": 5.00692404376136, "vf_explained_var": 0.006865753540917049, "kl": 0.003037760459172918, "entropy": 0.8961357040695412, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1337118346855124, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.985905068261283, "policy_loss": -0.004448468330508423, "vf_loss": 4.989453046914762, "vf_explained_var": 0.005440364281336467, "kl": 0.016008706886842233, "entropy": 1.188152846079024, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 435.60000000000105, "episode_reward_min": -541.1999999999998, "episode_reward_mean": -52.94499999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -804.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 90.19999999999979, "predator_policy": 711.0}, "policy_reward_mean": {"prey_policy": -125.6575, "predator_policy": 99.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-66.20000000000036, -110.49999999999994, 14.700000000000264, -142.00000000000063, -12.49999999999969, -316.30000000000007, -80.19999999999979, 40.0000000000003, 40.0000000000003, 25.500000000000448, 10.300000000000066, -150.1000000000009, -120.10000000000036, 435.60000000000105, -85.39999999999962, -422.9, -64.40000000000006, 40.0000000000003, -317.7999999999998, -225.3, -40.49999999999975, -541.1999999999998, -204.7, 49.90000000000046, -4.39999999999978, -269.1999999999998, -80.10000000000099, -74.20000000000002, 37.80000000000027, -176.60000000000028, -77.00000000000085, -9.899999999999679, 64.30000000000048, 21.80000000000001, -4.099999999999767, -399.99999999999994, -365.8, -20.29999999999994, 81.0999999999992, 40.30000000000029, -227.0000000000002, -155.800000000001, -103.20000000000013, -109.60000000000056, -304.7999999999971, -86.80000000000004, -23.299999999999557, -152.49999999999991, 22.400000000000084, 23.500000000000277, 44.700000000000394, 57.700000000000415, 7.0, 56.09999999999998, 40.90000000000031, 37.50000000000026, -93.40000000000109, 103.09999999999997, 22.50000000000004, -110.20000000000039, 39.900000000000496, 40.0000000000003, 39.40000000000028, 273.0000000000001, 42.30000000000003, 2.5000000000003326, -104.90000000000032, 67.59999999999998, -278.1000000000006, -51.79999999999989, 48.300000000000345, 27.900000000000205, 38.90000000000028, -58.099999999999994, -12.799999999999825, 53.20000000000051, 40.0000000000003, -170.2999999999999, -93.10000000000016, -120.60000000000099, 7.60000000000022, -36.399999999999785, -179.0, -2.9999999999999294, -27.599999999999877, -52.69999999999984, -65.40000000000003, -100.80000000000021, -69.20000000000147, -76.30000000000041, -37.59999999999993, -27.199999999999832, -103.90000000000019, 39.90000000000031, -90.40000000000032, 1.3999999999993074, -26.299999999999912, 57.10000000000051, 83.1999999999991, 20.400000000000226], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-324.5, 5.299999999999965, -597.3, -631.2, 20.000000000000014, -28.30000000000002, 20.000000000000014, -388.0, 31.400000000000233, -382.90000000000003, -190.00000000000003, -259.29999999999995, -215.20000000000036, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.800000000000196, -28.30000000000003, -36.699999999999754, 20.000000000000014, -269.80000000000035, -133.30000000000055, 41.60000000000023, -455.69999999999993, -783.4, -21.999999999999744, -85.00000000000003, -51.39999999999981, -313.9, -424.0, -15.70000000000001, -117.69999999999985, 20.000000000000014, 20.000000000000014, -265.89999999999986, -277.9, -76.29999999999984, -361.0, 5.29999999999999, -158.7999999999999, -509.89999999999986, -542.3000000000003, -301.29999999999984, -393.40000000000003, 29.90000000000018, 20.000000000000014, -372.3, 47.900000000000205, -420.9, -175.3, 20.000000000000014, -210.1000000000004, -15.699999999999747, -170.49999999999997, 15.799999999999963, 20.000000000000014, -174.0999999999999, -239.5000000000003, -45.09999999999976, -488.9, 36.20000000000026, -210.10000000000002, 44.300000000000246, 20.000000000000014, 32.600000000000236, -38.799999999999756, -69.1, 20.000000000000014, -331.29999999999995, -804.7, -227.49999999999994, -599.3, -112.30000000000025, 20.000000000000014, 45.200000000000166, 29.90000000000019, -289.4999999999999, 57.80000000000019, -211.59999999999994, -132.39999999999998, -51.39999999999986, -219.4000000000004, 20.000000000000014, -408.20000000000016, -49.29999999999976, -196.30000000000018, -221.50000000000045, -232.30000000000027, -559.6, -442.20000000000005, 20.000000000000014, -112.30000000000078, -548.7, -206.8, 26.300000000000114, -28.899999999999757, 20.000000000000014, -11.500000000000007, 29.90000000000018, -11.199999999999877, 44.3000000000002, 7.399999999999965, -42.99999999999981, 20.000000000000014, 20.000000000000014, -280.90000000000003, 20.90000000000003, 20.000000000000014, 9.499999999999968, 20.000000000000014, -82.90000000000079, -158.50000000000043, -288.9, 20.000000000000014, -9.399999999999926, 17.899999999999977, -245.50000000000037, -538.7, 20.000000000000014, 5.90000000000019, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999972, 17.899999999999984, -569.8999999999999, 20.000000000000014, -449.7, 37.40000000000022, -228.90000000000003, 11.59999999999996, -299.49999999999994, -5.199999999999948, 57.80000000000021, -238.79999999999998, -265.29999999999995, 20.000000000000014, -749.8, -55.000000000000014, 53.300000000000175, 26.000000000000128, -36.09999999999981, 20.000000000000014, 17.899999999999984, -164.00000000000003, -3.100000000000049, -11.799999999999983, -64.0000000000008, 27.200000000000244, 20.000000000000014, 20.000000000000014, 20.000000000000014, -167.40000000000003, -175.9, -200.5, -13.599999999999786, -117.10000000000068, -242.5000000000003, 56.90000000000015, -112.29999999999984, -72.40000000000043, -174.99999999999991, -171.10000000000002, -124.90000000000003, -10.599999999999978, -42.39999999999982, -267.6, 20.000000000000014, -223.60000000000014, -51.09999999999987, -203.10000000000002, -82.30000000000007, 20.000000000000014, -248.7999999999999, -112.30000000000065, -19.8999999999998, 20.000000000000014, -322.3, -71.49999999999986, -66.10000000000068, -110.2000000000003, 20.000000000000014, -187.9, -61.000000000000284, 41.30000000000023, -42.39999999999979, 21.80000000000004, -408.2000000000001, -46.00000000000013, -16.599999999999824, 65.90000000000005, -739.2, 37.10000000000025, 20.000000000000014, 63.2000000000002, 20.000000000000014, -206.80000000000052, 90.19999999999979], "policy_predator_policy_reward": [56.0, 197.0, 711.0, 407.0, 23.0, 0.0, 196.0, 30.0, 1.0, 338.0, 2.0, 131.0, 3.0, 112.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 27.0, 0.0, 114.0, 139.0, 19.0, 275.0, 606.0, 635.0, 51.0, 0.0, 210.0, 105.0, 3.0, 66.0, 0.0, 0.0, 155.0, 71.0, 187.0, 25.0, 110.0, 3.0, 496.0, 15.0, 337.0, 153.0, 0.0, 0.0, 0.0, 320.0, 34.0, 293.0, 94.0, 16.0, 112.0, 0.0, 0.0, 2.0, 167.0, 70.0, 270.0, 187.0, 158.0, 6.0, 0.0, 0.0, 28.0, 0.0, 45.0, 0.0, 702.0, 34.0, 0.0, 461.0, 61.0, 11.0, 6.0, 0.0, 197.0, 75.0, 0.0, 117.0, 115.0, 0.0, 244.0, 41.0, 0.0, 136.0, 0.0, 149.0, 557.0, 358.0, 61.0, 8.0, 350.0, 253.0, 25.0, 0.0, 0.0, 15.0, 23.0, 3.0, 6.0, 0.0, 30.0, 0.0, 145.0, 172.0, 0.0, 0.0, 8.0, 0.0, 33.0, 115.0, 199.0, 173.0, 14.0, 0.0, 427.0, 247.0, 14.0, 0.0, 0.0, 0.0, 0.0, 12.0, 401.0, 424.0, 103.0, 369.0, 194.0, 0.0, 132.0, 51.0, 12.0, 3.0, 202.0, 24.0, 0.0, 678.0, 36.0, 14.0, 0.0, 38.0, 0.0, 1.0, 104.0, 5.0, 7.0, 56.0, 0.0, 6.0, 0.0, 0.0, 22.0, 151.0, 121.0, 0.0, 120.0, 119.0, 14.0, 49.0, 104.0, 107.0, 26.0, 91.0, 29.0, 21.0, 0.0, 220.0, 100.0, 122.0, 92.0, 128.0, 0.0, 128.0, 56.0, 7.0, 146.0, 80.0, 100.0, 0.0, 5.0, 58.0, 5.0, 140.0, 10.0, 31.0, 261.0, 35.0, 0.0, 64.0, 6.0, 641.0, 0.0, 0.0, 0.0, 0.0, 68.0, 69.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1778015678043652, "mean_inference_ms": 3.3600503566341193, "mean_action_processing_ms": 0.5975026480531881, "mean_env_wait_ms": 0.4011843619092595, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.024991989135742188, "StateBufferConnector_ms": 0.008049607276916504, "ViewRequirementAgentConnector_ms": 0.22683024406433105}, "num_episodes": 18, "episode_return_max": 435.60000000000105, "episode_return_min": -541.1999999999998, "episode_return_mean": -52.94499999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.69596785196592, "num_env_steps_trained_throughput_per_sec": 202.69596785196592, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 114799.124, "restore_workers_time_ms": 0.023, "training_step_time_ms": 114799.051, "sample_time_ms": 3793.836, "learn_time_ms": 110955.638, "learn_throughput": 36.05, "synch_weights_time_ms": 42.149}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "3a355_00000", "date": "2024-08-13_01-36-27", "timestamp": 1723527387, "time_this_iter_s": 19.847392082214355, "time_total_s": 1595.6813304424286, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3ddfdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1595.6813304424286, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 91.53928571428573, "ram_util_percent": 83.73928571428573}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37817535541912234, "cur_kl_coeff": 0.000390625, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.747857813923447, "policy_loss": -0.0013902234012093493, "vf_loss": 2.7492444566948704, "vf_explained_var": 0.004205527822807352, "kl": 0.00917087858664477, "entropy": 0.7590522310090444, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2894331987139094, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.356275425260029, "policy_loss": -0.0012896111826338466, "vf_loss": 5.357110384280089, "vf_explained_var": 0.04485824899698691, "kl": 0.008082736586414853, "entropy": 1.1794243243636278, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 273.0000000000001, "episode_reward_min": -399.99999999999994, "episode_reward_mean": -9.553000000000033, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -804.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 702.0}, "policy_reward_mean": {"prey_policy": -79.90650000000004, "predator_policy": 75.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-74.20000000000002, 37.80000000000027, -176.60000000000028, -77.00000000000085, -9.899999999999679, 64.30000000000048, 21.80000000000001, -4.099999999999767, -399.99999999999994, -365.8, -20.29999999999994, 81.0999999999992, 40.30000000000029, -227.0000000000002, -155.800000000001, -103.20000000000013, -109.60000000000056, -304.7999999999971, -86.80000000000004, -23.299999999999557, -152.49999999999991, 22.400000000000084, 23.500000000000277, 44.700000000000394, 57.700000000000415, 7.0, 56.09999999999998, 40.90000000000031, 37.50000000000026, -93.40000000000109, 103.09999999999997, 22.50000000000004, -110.20000000000039, 39.900000000000496, 40.0000000000003, 39.40000000000028, 273.0000000000001, 42.30000000000003, 2.5000000000003326, -104.90000000000032, 67.59999999999998, -278.1000000000006, -51.79999999999989, 48.300000000000345, 27.900000000000205, 38.90000000000028, -58.099999999999994, -12.799999999999825, 53.20000000000051, 40.0000000000003, -170.2999999999999, -93.10000000000016, -120.60000000000099, 7.60000000000022, -36.399999999999785, -179.0, -2.9999999999999294, -27.599999999999877, -52.69999999999984, -65.40000000000003, -100.80000000000021, -69.20000000000147, -76.30000000000041, -37.59999999999993, -27.199999999999832, -103.90000000000019, 39.90000000000031, -90.40000000000032, 1.3999999999993074, -26.299999999999912, 57.10000000000051, 83.1999999999991, 20.400000000000226, 49.000000000000284, 145.2999999999988, 61.40000000000024, 17.899999999999974, 239.3999999999993, 106.89999999999972, -163.90000000000015, 137.29999999999885, 150.49999999999923, -62.200000000001, 35.600000000000236, 194.19999999999945, 49.10000000000041, 255.9999999999999, 51.70000000000043, -80.60000000000002, -61.2000000000004, 82.49999999999994, 18.10000000000017, 14.500000000000156, 1.200000000000186, -39.89999999999964, 138.79999999999944, 119.19999999999976, 58.80000000000051, 151.8999999999998, 69.90000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.699999999999747, -170.49999999999997, 15.799999999999963, 20.000000000000014, -174.0999999999999, -239.5000000000003, -45.09999999999976, -488.9, 36.20000000000026, -210.10000000000002, 44.300000000000246, 20.000000000000014, 32.600000000000236, -38.799999999999756, -69.1, 20.000000000000014, -331.29999999999995, -804.7, -227.49999999999994, -599.3, -112.30000000000025, 20.000000000000014, 45.200000000000166, 29.90000000000019, -289.4999999999999, 57.80000000000019, -211.59999999999994, -132.39999999999998, -51.39999999999986, -219.4000000000004, 20.000000000000014, -408.20000000000016, -49.29999999999976, -196.30000000000018, -221.50000000000045, -232.30000000000027, -559.6, -442.20000000000005, 20.000000000000014, -112.30000000000078, -548.7, -206.8, 26.300000000000114, -28.899999999999757, 20.000000000000014, -11.500000000000007, 29.90000000000018, -11.199999999999877, 44.3000000000002, 7.399999999999965, -42.99999999999981, 20.000000000000014, 20.000000000000014, -280.90000000000003, 20.90000000000003, 20.000000000000014, 9.499999999999968, 20.000000000000014, -82.90000000000079, -158.50000000000043, -288.9, 20.000000000000014, -9.399999999999926, 17.899999999999977, -245.50000000000037, -538.7, 20.000000000000014, 5.90000000000019, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999972, 17.899999999999984, -569.8999999999999, 20.000000000000014, -449.7, 37.40000000000022, -228.90000000000003, 11.59999999999996, -299.49999999999994, -5.199999999999948, 57.80000000000021, -238.79999999999998, -265.29999999999995, 20.000000000000014, -749.8, -55.000000000000014, 53.300000000000175, 26.000000000000128, -36.09999999999981, 20.000000000000014, 17.899999999999984, -164.00000000000003, -3.100000000000049, -11.799999999999983, -64.0000000000008, 27.200000000000244, 20.000000000000014, 20.000000000000014, 20.000000000000014, -167.40000000000003, -175.9, -200.5, -13.599999999999786, -117.10000000000068, -242.5000000000003, 56.90000000000015, -112.29999999999984, -72.40000000000043, -174.99999999999991, -171.10000000000002, -124.90000000000003, -10.599999999999978, -42.39999999999982, -267.6, 20.000000000000014, -223.60000000000014, -51.09999999999987, -203.10000000000002, -82.30000000000007, 20.000000000000014, -248.7999999999999, -112.30000000000065, -19.8999999999998, 20.000000000000014, -322.3, -71.49999999999986, -66.10000000000068, -110.2000000000003, 20.000000000000014, -187.9, -61.000000000000284, 41.30000000000023, -42.39999999999979, 21.80000000000004, -408.2000000000001, -46.00000000000013, -16.599999999999824, 65.90000000000005, -739.2, 37.10000000000025, 20.000000000000014, 63.2000000000002, 20.000000000000014, -206.80000000000052, 90.19999999999979, 29.0, 20.000000000000014, 20.000000000000014, 125.29999999999953, 40.40000000000003, 20.000000000000014, 15.799999999999962, -16.899999999999743, 19.399999999999995, 197.0, 38.9, 20.000000000000014, -192.10000000000002, -185.80000000000007, 20.000000000000014, 113.29999999999953, 111.4999999999998, 20.000000000000014, -80.50000000000048, -36.69999999999984, 20.000000000000014, 11.599999999999968, -8.799999999999939, 173.00000000000006, 20.000000000000014, -28.899999999999842, 146.9, 109.10000000000008, 31.700000000000216, 20.000000000000014, -320.2, 77.5999999999995, -137.5000000000003, -15.699999999999775, 20.000000000000014, -288.50000000000006, 20.000000000000014, -34.899999999999785, -38.49999999999992, 20.000000000000014, -59.800000000000566, 20.000000000000014, -236.2000000000002, 5.299999999999981, 179.29999999999987, -221.50000000000043, -315.80000000000007, 172.99999999999983, 18.80000000000024, 29.000000000000163, -106.00000000000003, 155.9, -66.10000000000085, 91.99999999999932], "policy_predator_policy_reward": [112.0, 0.0, 0.0, 2.0, 167.0, 70.0, 270.0, 187.0, 158.0, 6.0, 0.0, 0.0, 28.0, 0.0, 45.0, 0.0, 702.0, 34.0, 0.0, 461.0, 61.0, 11.0, 6.0, 0.0, 197.0, 75.0, 0.0, 117.0, 115.0, 0.0, 244.0, 41.0, 0.0, 136.0, 0.0, 149.0, 557.0, 358.0, 61.0, 8.0, 350.0, 253.0, 25.0, 0.0, 0.0, 15.0, 23.0, 3.0, 6.0, 0.0, 30.0, 0.0, 145.0, 172.0, 0.0, 0.0, 8.0, 0.0, 33.0, 115.0, 199.0, 173.0, 14.0, 0.0, 427.0, 247.0, 14.0, 0.0, 0.0, 0.0, 0.0, 12.0, 401.0, 424.0, 103.0, 369.0, 194.0, 0.0, 132.0, 51.0, 12.0, 3.0, 202.0, 24.0, 0.0, 678.0, 36.0, 14.0, 0.0, 38.0, 0.0, 1.0, 104.0, 5.0, 7.0, 56.0, 0.0, 6.0, 0.0, 0.0, 22.0, 151.0, 121.0, 0.0, 120.0, 119.0, 14.0, 49.0, 104.0, 107.0, 26.0, 91.0, 29.0, 21.0, 0.0, 220.0, 100.0, 122.0, 92.0, 128.0, 0.0, 128.0, 56.0, 7.0, 146.0, 80.0, 100.0, 0.0, 5.0, 58.0, 5.0, 140.0, 10.0, 31.0, 261.0, 35.0, 0.0, 64.0, 6.0, 641.0, 0.0, 0.0, 0.0, 0.0, 68.0, 69.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 19.0, 23.0, 0.0, 0.0, 48.0, 117.0, 97.0, 4.0, 0.0, 19.0, 0.0, 0.0, 55.0, 0.0, 4.0, 0.0, 30.0, 43.0, 15.0, 0.0, 0.0, 0.0, 0.0, 162.0, 0.0, 0.0, 92.0, 198.0, 153.0, 33.0, 0.0, 0.0, 33.0, 0.0, 41.0, 116.0, 75.0, 100.0, 81.0, 45.0, 217.0, 9.0, 2.0, 51.0, 51.0, 0.0, 44.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1992794921442533, "mean_inference_ms": 3.4164778187128975, "mean_action_processing_ms": 0.6443612637469974, "mean_env_wait_ms": 0.4112269602780234, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.023853540420532227, "StateBufferConnector_ms": 0.010422945022583008, "ViewRequirementAgentConnector_ms": 0.24652552604675293}, "num_episodes": 27, "episode_return_max": 273.0000000000001, "episode_return_min": -399.99999999999994, "episode_return_mean": -9.553000000000033, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.75948553809465, "num_env_steps_trained_throughput_per_sec": 201.75948553809465, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 114675.949, "restore_workers_time_ms": 0.023, "training_step_time_ms": 114675.875, "sample_time_ms": 3797.783, "learn_time_ms": 110830.03, "learn_throughput": 36.091, "synch_weights_time_ms": 40.89}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "3a355_00000", "date": "2024-08-13_01-36-47", "timestamp": 1723527407, "time_this_iter_s": 19.885381937026978, "time_total_s": 1615.5667123794556, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d6d550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1615.5667123794556, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 90.69642857142857, "ram_util_percent": 83.68571428571427}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3992986169481088, "cur_kl_coeff": 0.000390625, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9013781973924586, "policy_loss": -0.0022846087005245624, "vf_loss": 2.903660703966857, "vf_explained_var": 0.002757333100788177, "kl": 0.005374953179197726, "entropy": 0.8722419138938662, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4302125927356502, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.3872611878410215, "policy_loss": -0.0046935227041738845, "vf_loss": 6.391399804120342, "vf_explained_var": 0.05787595188806927, "kl": 0.009865029351244595, "entropy": 1.1796946311123158, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 280.40000000000043, "episode_reward_min": -278.1000000000006, "episode_reward_mean": 28.1169999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -749.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 678.0}, "policy_reward_mean": {"prey_policy": -48.95150000000005, "predator_policy": 63.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-86.80000000000004, -23.299999999999557, -152.49999999999991, 22.400000000000084, 23.500000000000277, 44.700000000000394, 57.700000000000415, 7.0, 56.09999999999998, 40.90000000000031, 37.50000000000026, -93.40000000000109, 103.09999999999997, 22.50000000000004, -110.20000000000039, 39.900000000000496, 40.0000000000003, 39.40000000000028, 273.0000000000001, 42.30000000000003, 2.5000000000003326, -104.90000000000032, 67.59999999999998, -278.1000000000006, -51.79999999999989, 48.300000000000345, 27.900000000000205, 38.90000000000028, -58.099999999999994, -12.799999999999825, 53.20000000000051, 40.0000000000003, -170.2999999999999, -93.10000000000016, -120.60000000000099, 7.60000000000022, -36.399999999999785, -179.0, -2.9999999999999294, -27.599999999999877, -52.69999999999984, -65.40000000000003, -100.80000000000021, -69.20000000000147, -76.30000000000041, -37.59999999999993, -27.199999999999832, -103.90000000000019, 39.90000000000031, -90.40000000000032, 1.3999999999993074, -26.299999999999912, 57.10000000000051, 83.1999999999991, 20.400000000000226, 49.000000000000284, 145.2999999999988, 61.40000000000024, 17.899999999999974, 239.3999999999993, 106.89999999999972, -163.90000000000015, 137.29999999999885, 150.49999999999923, -62.200000000001, 35.600000000000236, 194.19999999999945, 49.10000000000041, 255.9999999999999, 51.70000000000043, -80.60000000000002, -61.2000000000004, 82.49999999999994, 18.10000000000017, 14.500000000000156, 1.200000000000186, -39.89999999999964, 138.79999999999944, 119.19999999999976, 58.80000000000051, 151.8999999999998, 69.90000000000022, 21.3, 57.69999999999925, 247.89999999999907, 57.80000000000015, 129.49999999999977, 43.99999999999994, 110.19999999999973, 67.9, 89.09999999999903, 168.19999999999925, 116.79999999999971, 92.59999999999914, 147.09999999999948, 154.99999999999966, -33.79999999999982, 222.6999999999994, 280.40000000000043, 9.600000000000101], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-559.6, -442.20000000000005, 20.000000000000014, -112.30000000000078, -548.7, -206.8, 26.300000000000114, -28.899999999999757, 20.000000000000014, -11.500000000000007, 29.90000000000018, -11.199999999999877, 44.3000000000002, 7.399999999999965, -42.99999999999981, 20.000000000000014, 20.000000000000014, -280.90000000000003, 20.90000000000003, 20.000000000000014, 9.499999999999968, 20.000000000000014, -82.90000000000079, -158.50000000000043, -288.9, 20.000000000000014, -9.399999999999926, 17.899999999999977, -245.50000000000037, -538.7, 20.000000000000014, 5.90000000000019, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999972, 17.899999999999984, -569.8999999999999, 20.000000000000014, -449.7, 37.40000000000022, -228.90000000000003, 11.59999999999996, -299.49999999999994, -5.199999999999948, 57.80000000000021, -238.79999999999998, -265.29999999999995, 20.000000000000014, -749.8, -55.000000000000014, 53.300000000000175, 26.000000000000128, -36.09999999999981, 20.000000000000014, 17.899999999999984, -164.00000000000003, -3.100000000000049, -11.799999999999983, -64.0000000000008, 27.200000000000244, 20.000000000000014, 20.000000000000014, 20.000000000000014, -167.40000000000003, -175.9, -200.5, -13.599999999999786, -117.10000000000068, -242.5000000000003, 56.90000000000015, -112.29999999999984, -72.40000000000043, -174.99999999999991, -171.10000000000002, -124.90000000000003, -10.599999999999978, -42.39999999999982, -267.6, 20.000000000000014, -223.60000000000014, -51.09999999999987, -203.10000000000002, -82.30000000000007, 20.000000000000014, -248.7999999999999, -112.30000000000065, -19.8999999999998, 20.000000000000014, -322.3, -71.49999999999986, -66.10000000000068, -110.2000000000003, 20.000000000000014, -187.9, -61.000000000000284, 41.30000000000023, -42.39999999999979, 21.80000000000004, -408.2000000000001, -46.00000000000013, -16.599999999999824, 65.90000000000005, -739.2, 37.10000000000025, 20.000000000000014, 63.2000000000002, 20.000000000000014, -206.80000000000052, 90.19999999999979, 29.0, 20.000000000000014, 20.000000000000014, 125.29999999999953, 40.40000000000003, 20.000000000000014, 15.799999999999962, -16.899999999999743, 19.399999999999995, 197.0, 38.9, 20.000000000000014, -192.10000000000002, -185.80000000000007, 20.000000000000014, 113.29999999999953, 111.4999999999998, 20.000000000000014, -80.50000000000048, -36.69999999999984, 20.000000000000014, 11.599999999999968, -8.799999999999939, 173.00000000000006, 20.000000000000014, -28.899999999999842, 146.9, 109.10000000000008, 31.700000000000216, 20.000000000000014, -320.2, 77.5999999999995, -137.5000000000003, -15.699999999999775, 20.000000000000014, -288.50000000000006, 20.000000000000014, -34.899999999999785, -38.49999999999992, 20.000000000000014, -59.800000000000566, 20.000000000000014, -236.2000000000002, 5.299999999999981, 179.29999999999987, -221.50000000000043, -315.80000000000007, 172.99999999999983, 18.80000000000024, 29.000000000000163, -106.00000000000003, 155.9, -66.10000000000085, 91.99999999999932, -15.699999999999765, 20.000000000000014, -87.10000000000014, 93.79999999999933, 47.90000000000023, 200.0, -139.30000000000035, 91.09999999999991, 181.1, -121.60000000000062, 56.000000000000014, -211.0, 90.19999999999996, 20.000000000000014, 47.90000000000011, 20.000000000000014, -78.70000000000003, 120.7999999999995, 123.19999999999999, 20.000000000000014, 66.80000000000001, 20.000000000000014, -11.499999999999819, 61.10000000000002, 82.99999999999994, 46.1000000000001, 72.49999999999967, -8.5, 20.000000000000014, -185.80000000000024, 188.3, 34.400000000000055, 66.49999999999989, 191.9, 101.89999999999985, -211.30000000000032], "policy_predator_policy_reward": [557.0, 358.0, 61.0, 8.0, 350.0, 253.0, 25.0, 0.0, 0.0, 15.0, 23.0, 3.0, 6.0, 0.0, 30.0, 0.0, 145.0, 172.0, 0.0, 0.0, 8.0, 0.0, 33.0, 115.0, 199.0, 173.0, 14.0, 0.0, 427.0, 247.0, 14.0, 0.0, 0.0, 0.0, 0.0, 12.0, 401.0, 424.0, 103.0, 369.0, 194.0, 0.0, 132.0, 51.0, 12.0, 3.0, 202.0, 24.0, 0.0, 678.0, 36.0, 14.0, 0.0, 38.0, 0.0, 1.0, 104.0, 5.0, 7.0, 56.0, 0.0, 6.0, 0.0, 0.0, 22.0, 151.0, 121.0, 0.0, 120.0, 119.0, 14.0, 49.0, 104.0, 107.0, 26.0, 91.0, 29.0, 21.0, 0.0, 220.0, 100.0, 122.0, 92.0, 128.0, 0.0, 128.0, 56.0, 7.0, 146.0, 80.0, 100.0, 0.0, 5.0, 58.0, 5.0, 140.0, 10.0, 31.0, 261.0, 35.0, 0.0, 64.0, 6.0, 641.0, 0.0, 0.0, 0.0, 0.0, 68.0, 69.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 19.0, 23.0, 0.0, 0.0, 48.0, 117.0, 97.0, 4.0, 0.0, 19.0, 0.0, 0.0, 55.0, 0.0, 4.0, 0.0, 30.0, 43.0, 15.0, 0.0, 0.0, 0.0, 0.0, 162.0, 0.0, 0.0, 92.0, 198.0, 153.0, 33.0, 0.0, 0.0, 33.0, 0.0, 41.0, 116.0, 75.0, 100.0, 81.0, 45.0, 217.0, 9.0, 2.0, 51.0, 51.0, 0.0, 44.0, 0.0, 17.0, 0.0, 51.0, 0.0, 0.0, 59.0, 47.0, 70.0, 0.0, 127.0, 72.0, 0.0, 0.0, 0.0, 0.0, 0.0, 47.0, 25.0, 0.0, 0.0, 30.0, 43.0, 0.0, 18.0, 0.0, 54.0, 37.0, 45.0, 87.0, 0.0, 0.0, 0.0, 22.0, 26.0, 93.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2170473101794328, "mean_inference_ms": 3.465609299057104, "mean_action_processing_ms": 0.6426970164581948, "mean_env_wait_ms": 0.4164212131280792, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02004539966583252, "StateBufferConnector_ms": 0.010462760925292969, "ViewRequirementAgentConnector_ms": 0.2426830530166626}, "num_episodes": 18, "episode_return_max": 280.40000000000043, "episode_return_min": -278.1000000000006, "episode_return_mean": 28.1169999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 194.70658147006532, "num_env_steps_trained_throughput_per_sec": 194.70658147006532, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 115211.219, "restore_workers_time_ms": 0.023, "training_step_time_ms": 115211.145, "sample_time_ms": 3704.95, "learn_time_ms": 111459.414, "learn_throughput": 35.888, "synch_weights_time_ms": 39.566}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "3a355_00000", "date": "2024-08-13_01-37-07", "timestamp": 1723527427, "time_this_iter_s": 20.60273504257202, "time_total_s": 1636.1694474220276, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df6820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1636.1694474220276, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 88.64482758620689, "ram_util_percent": 83.49655172413793}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31037628903157183, "cur_kl_coeff": 0.000390625, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1358048446594722, "policy_loss": -0.002094288942744098, "vf_loss": 1.1378943886391069, "vf_explained_var": -0.001006882909744505, "kl": 0.0121477649243421, "entropy": 0.7571939455453681, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4682990491390229, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.1722660203459405, "policy_loss": -0.003147290378720278, "vf_loss": 4.174415104099052, "vf_explained_var": 0.07435769615349946, "kl": 0.017745768920672467, "entropy": 1.168052414359239, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 306.1000000000014, "episode_reward_min": -278.1000000000006, "episode_reward_mean": 44.190999999999896, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -749.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 678.0}, "policy_reward_mean": {"prey_policy": -27.439500000000052, "predator_policy": 49.535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [273.0000000000001, 42.30000000000003, 2.5000000000003326, -104.90000000000032, 67.59999999999998, -278.1000000000006, -51.79999999999989, 48.300000000000345, 27.900000000000205, 38.90000000000028, -58.099999999999994, -12.799999999999825, 53.20000000000051, 40.0000000000003, -170.2999999999999, -93.10000000000016, -120.60000000000099, 7.60000000000022, -36.399999999999785, -179.0, -2.9999999999999294, -27.599999999999877, -52.69999999999984, -65.40000000000003, -100.80000000000021, -69.20000000000147, -76.30000000000041, -37.59999999999993, -27.199999999999832, -103.90000000000019, 39.90000000000031, -90.40000000000032, 1.3999999999993074, -26.299999999999912, 57.10000000000051, 83.1999999999991, 20.400000000000226, 49.000000000000284, 145.2999999999988, 61.40000000000024, 17.899999999999974, 239.3999999999993, 106.89999999999972, -163.90000000000015, 137.29999999999885, 150.49999999999923, -62.200000000001, 35.600000000000236, 194.19999999999945, 49.10000000000041, 255.9999999999999, 51.70000000000043, -80.60000000000002, -61.2000000000004, 82.49999999999994, 18.10000000000017, 14.500000000000156, 1.200000000000186, -39.89999999999964, 138.79999999999944, 119.19999999999976, 58.80000000000051, 151.8999999999998, 69.90000000000022, 21.3, 57.69999999999925, 247.89999999999907, 57.80000000000015, 129.49999999999977, 43.99999999999994, 110.19999999999973, 67.9, 89.09999999999903, 168.19999999999925, 116.79999999999971, 92.59999999999914, 147.09999999999948, 154.99999999999966, -33.79999999999982, 222.6999999999994, 280.40000000000043, 9.600000000000101, 21.299999999999994, 61.600000000000406, 119.79999999999974, 306.1000000000014, 38.4000000000003, 191.09999999999962, 150.69999999999982, 38.900000000000276, -37.299999999999855, 127.2999999999984, 40.0000000000003, 23.200000000000056, 21.400000000000006, 65.99999999999999, 119.1999999999999, 25.70000000000007, 276.70000000000067, 85.79999999999978], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999984, -569.8999999999999, 20.000000000000014, -449.7, 37.40000000000022, -228.90000000000003, 11.59999999999996, -299.49999999999994, -5.199999999999948, 57.80000000000021, -238.79999999999998, -265.29999999999995, 20.000000000000014, -749.8, -55.000000000000014, 53.300000000000175, 26.000000000000128, -36.09999999999981, 20.000000000000014, 17.899999999999984, -164.00000000000003, -3.100000000000049, -11.799999999999983, -64.0000000000008, 27.200000000000244, 20.000000000000014, 20.000000000000014, 20.000000000000014, -167.40000000000003, -175.9, -200.5, -13.599999999999786, -117.10000000000068, -242.5000000000003, 56.90000000000015, -112.29999999999984, -72.40000000000043, -174.99999999999991, -171.10000000000002, -124.90000000000003, -10.599999999999978, -42.39999999999982, -267.6, 20.000000000000014, -223.60000000000014, -51.09999999999987, -203.10000000000002, -82.30000000000007, 20.000000000000014, -248.7999999999999, -112.30000000000065, -19.8999999999998, 20.000000000000014, -322.3, -71.49999999999986, -66.10000000000068, -110.2000000000003, 20.000000000000014, -187.9, -61.000000000000284, 41.30000000000023, -42.39999999999979, 21.80000000000004, -408.2000000000001, -46.00000000000013, -16.599999999999824, 65.90000000000005, -739.2, 37.10000000000025, 20.000000000000014, 63.2000000000002, 20.000000000000014, -206.80000000000052, 90.19999999999979, 29.0, 20.000000000000014, 20.000000000000014, 125.29999999999953, 40.40000000000003, 20.000000000000014, 15.799999999999962, -16.899999999999743, 19.399999999999995, 197.0, 38.9, 20.000000000000014, -192.10000000000002, -185.80000000000007, 20.000000000000014, 113.29999999999953, 111.4999999999998, 20.000000000000014, -80.50000000000048, -36.69999999999984, 20.000000000000014, 11.599999999999968, -8.799999999999939, 173.00000000000006, 20.000000000000014, -28.899999999999842, 146.9, 109.10000000000008, 31.700000000000216, 20.000000000000014, -320.2, 77.5999999999995, -137.5000000000003, -15.699999999999775, 20.000000000000014, -288.50000000000006, 20.000000000000014, -34.899999999999785, -38.49999999999992, 20.000000000000014, -59.800000000000566, 20.000000000000014, -236.2000000000002, 5.299999999999981, 179.29999999999987, -221.50000000000043, -315.80000000000007, 172.99999999999983, 18.80000000000024, 29.000000000000163, -106.00000000000003, 155.9, -66.10000000000085, 91.99999999999932, -15.699999999999765, 20.000000000000014, -87.10000000000014, 93.79999999999933, 47.90000000000023, 200.0, -139.30000000000035, 91.09999999999991, 181.1, -121.60000000000062, 56.000000000000014, -211.0, 90.19999999999996, 20.000000000000014, 47.90000000000011, 20.000000000000014, -78.70000000000003, 120.7999999999995, 123.19999999999999, 20.000000000000014, 66.80000000000001, 20.000000000000014, -11.499999999999819, 61.10000000000002, 82.99999999999994, 46.1000000000001, 72.49999999999967, -8.5, 20.000000000000014, -185.80000000000024, 188.3, 34.400000000000055, 66.49999999999989, 191.9, 101.89999999999985, -211.30000000000032, 20.000000000000014, -15.699999999999747, 20.000000000000014, 2.5999999999999948, 93.79999999999998, 20.000000000000014, 162.19999999999993, 137.89999999999972, -57.700000000000195, 34.10000000000014, 67.09999999999998, 71.00000000000003, 82.6999999999999, 38.00000000000009, 20.000000000000014, 17.899999999999977, -133.30000000000027, 20.000000000000014, 83.8999999999995, 43.40000000000023, 20.000000000000014, 20.000000000000014, 26.300000000000114, -24.09999999999983, 20.000000000000014, -19.599999999999774, 20.000000000000014, 32.00000000000016, 99.19999999999999, 20.000000000000014, -7.299999999999891, 20.000000000000014, 137.8999999999996, 138.79999999999995, -248.8000000000004, 140.59999999999962], "policy_predator_policy_reward": [401.0, 424.0, 103.0, 369.0, 194.0, 0.0, 132.0, 51.0, 12.0, 3.0, 202.0, 24.0, 0.0, 678.0, 36.0, 14.0, 0.0, 38.0, 0.0, 1.0, 104.0, 5.0, 7.0, 56.0, 0.0, 6.0, 0.0, 0.0, 22.0, 151.0, 121.0, 0.0, 120.0, 119.0, 14.0, 49.0, 104.0, 107.0, 26.0, 91.0, 29.0, 21.0, 0.0, 220.0, 100.0, 122.0, 92.0, 128.0, 0.0, 128.0, 56.0, 7.0, 146.0, 80.0, 100.0, 0.0, 5.0, 58.0, 5.0, 140.0, 10.0, 31.0, 261.0, 35.0, 0.0, 64.0, 6.0, 641.0, 0.0, 0.0, 0.0, 0.0, 68.0, 69.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 19.0, 23.0, 0.0, 0.0, 48.0, 117.0, 97.0, 4.0, 0.0, 19.0, 0.0, 0.0, 55.0, 0.0, 4.0, 0.0, 30.0, 43.0, 15.0, 0.0, 0.0, 0.0, 0.0, 162.0, 0.0, 0.0, 92.0, 198.0, 153.0, 33.0, 0.0, 0.0, 33.0, 0.0, 41.0, 116.0, 75.0, 100.0, 81.0, 45.0, 217.0, 9.0, 2.0, 51.0, 51.0, 0.0, 44.0, 0.0, 17.0, 0.0, 51.0, 0.0, 0.0, 59.0, 47.0, 70.0, 0.0, 127.0, 72.0, 0.0, 0.0, 0.0, 0.0, 0.0, 47.0, 25.0, 0.0, 0.0, 30.0, 43.0, 0.0, 18.0, 0.0, 54.0, 37.0, 45.0, 87.0, 0.0, 0.0, 0.0, 22.0, 26.0, 93.0, 0.0, 17.0, 16.0, 23.0, 0.0, 6.0, 6.0, 0.0, 62.0, 0.0, 34.0, 19.0, 0.0, 30.0, 0.0, 1.0, 44.0, 32.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 77.0, 117.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2274834315505285, "mean_inference_ms": 3.493895699841072, "mean_action_processing_ms": 0.6412752433304868, "mean_env_wait_ms": 0.42053521040224723, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009449124336242676, "StateBufferConnector_ms": 0.00865018367767334, "ViewRequirementAgentConnector_ms": 0.22237920761108398}, "num_episodes": 18, "episode_return_max": 306.1000000000014, "episode_return_min": -278.1000000000006, "episode_return_mean": 44.190999999999896, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 213.36709518601094, "num_env_steps_trained_throughput_per_sec": 213.36709518601094, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 115540.314, "restore_workers_time_ms": 0.025, "training_step_time_ms": 115540.237, "sample_time_ms": 3602.015, "learn_time_ms": 111890.056, "learn_throughput": 35.749, "synch_weights_time_ms": 40.482}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "3a355_00000", "date": "2024-08-13_01-37-26", "timestamp": 1723527446, "time_this_iter_s": 18.83242392539978, "time_total_s": 1655.0018713474274, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5097dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1655.0018713474274, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 85.58846153846153, "ram_util_percent": 83.40384615384616}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4275652163676799, "cur_kl_coeff": 0.000390625, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8024307369870483, "policy_loss": -0.0013621473128084469, "vf_loss": 1.8037913513877404, "vf_explained_var": 0.0044250745937307046, "kl": 0.003932411639115796, "entropy": 0.6966455763294583, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4463996830677228, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.748306198851772, "policy_loss": -0.0036611617216347624, "vf_loss": 4.75133267104941, "vf_explained_var": 0.0503260386999322, "kl": 0.011282888881972465, "entropy": 1.1672451944578262, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 306.1000000000014, "episode_reward_min": -179.0, "episode_reward_mean": 64.83299999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -739.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 641.0}, "policy_reward_mean": {"prey_policy": -2.108500000000049, "predator_policy": 34.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-36.399999999999785, -179.0, -2.9999999999999294, -27.599999999999877, -52.69999999999984, -65.40000000000003, -100.80000000000021, -69.20000000000147, -76.30000000000041, -37.59999999999993, -27.199999999999832, -103.90000000000019, 39.90000000000031, -90.40000000000032, 1.3999999999993074, -26.299999999999912, 57.10000000000051, 83.1999999999991, 20.400000000000226, 49.000000000000284, 145.2999999999988, 61.40000000000024, 17.899999999999974, 239.3999999999993, 106.89999999999972, -163.90000000000015, 137.29999999999885, 150.49999999999923, -62.200000000001, 35.600000000000236, 194.19999999999945, 49.10000000000041, 255.9999999999999, 51.70000000000043, -80.60000000000002, -61.2000000000004, 82.49999999999994, 18.10000000000017, 14.500000000000156, 1.200000000000186, -39.89999999999964, 138.79999999999944, 119.19999999999976, 58.80000000000051, 151.8999999999998, 69.90000000000022, 21.3, 57.69999999999925, 247.89999999999907, 57.80000000000015, 129.49999999999977, 43.99999999999994, 110.19999999999973, 67.9, 89.09999999999903, 168.19999999999925, 116.79999999999971, 92.59999999999914, 147.09999999999948, 154.99999999999966, -33.79999999999982, 222.6999999999994, 280.40000000000043, 9.600000000000101, 21.299999999999994, 61.600000000000406, 119.79999999999974, 306.1000000000014, 38.4000000000003, 191.09999999999962, 150.69999999999982, 38.900000000000276, -37.299999999999855, 127.2999999999984, 40.0000000000003, 23.200000000000056, 21.400000000000006, 65.99999999999999, 119.1999999999999, 25.70000000000007, 276.70000000000067, 85.79999999999978, 102.6, 77.39999999999957, 71.50000000000003, 13.000000000000014, 235.2999999999991, 181.59999999999937, 108.89999999999989, 23.200000000000088, 219.09999999999926, 256.7999999999999, 94.89999999999978, 2.900000000000056, 98.49999999999972, 37.800000000000296, 49.90000000000046, 192.99999999999898, 3.700000000000117, 5.700000000000346], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-72.40000000000043, -174.99999999999991, -171.10000000000002, -124.90000000000003, -10.599999999999978, -42.39999999999982, -267.6, 20.000000000000014, -223.60000000000014, -51.09999999999987, -203.10000000000002, -82.30000000000007, 20.000000000000014, -248.7999999999999, -112.30000000000065, -19.8999999999998, 20.000000000000014, -322.3, -71.49999999999986, -66.10000000000068, -110.2000000000003, 20.000000000000014, -187.9, -61.000000000000284, 41.30000000000023, -42.39999999999979, 21.80000000000004, -408.2000000000001, -46.00000000000013, -16.599999999999824, 65.90000000000005, -739.2, 37.10000000000025, 20.000000000000014, 63.2000000000002, 20.000000000000014, -206.80000000000052, 90.19999999999979, 29.0, 20.000000000000014, 20.000000000000014, 125.29999999999953, 40.40000000000003, 20.000000000000014, 15.799999999999962, -16.899999999999743, 19.399999999999995, 197.0, 38.9, 20.000000000000014, -192.10000000000002, -185.80000000000007, 20.000000000000014, 113.29999999999953, 111.4999999999998, 20.000000000000014, -80.50000000000048, -36.69999999999984, 20.000000000000014, 11.599999999999968, -8.799999999999939, 173.00000000000006, 20.000000000000014, -28.899999999999842, 146.9, 109.10000000000008, 31.700000000000216, 20.000000000000014, -320.2, 77.5999999999995, -137.5000000000003, -15.699999999999775, 20.000000000000014, -288.50000000000006, 20.000000000000014, -34.899999999999785, -38.49999999999992, 20.000000000000014, -59.800000000000566, 20.000000000000014, -236.2000000000002, 5.299999999999981, 179.29999999999987, -221.50000000000043, -315.80000000000007, 172.99999999999983, 18.80000000000024, 29.000000000000163, -106.00000000000003, 155.9, -66.10000000000085, 91.99999999999932, -15.699999999999765, 20.000000000000014, -87.10000000000014, 93.79999999999933, 47.90000000000023, 200.0, -139.30000000000035, 91.09999999999991, 181.1, -121.60000000000062, 56.000000000000014, -211.0, 90.19999999999996, 20.000000000000014, 47.90000000000011, 20.000000000000014, -78.70000000000003, 120.7999999999995, 123.19999999999999, 20.000000000000014, 66.80000000000001, 20.000000000000014, -11.499999999999819, 61.10000000000002, 82.99999999999994, 46.1000000000001, 72.49999999999967, -8.5, 20.000000000000014, -185.80000000000024, 188.3, 34.400000000000055, 66.49999999999989, 191.9, 101.89999999999985, -211.30000000000032, 20.000000000000014, -15.699999999999747, 20.000000000000014, 2.5999999999999948, 93.79999999999998, 20.000000000000014, 162.19999999999993, 137.89999999999972, -57.700000000000195, 34.10000000000014, 67.09999999999998, 71.00000000000003, 82.6999999999999, 38.00000000000009, 20.000000000000014, 17.899999999999977, -133.30000000000027, 20.000000000000014, 83.8999999999995, 43.40000000000023, 20.000000000000014, 20.000000000000014, 26.300000000000114, -24.09999999999983, 20.000000000000014, -19.599999999999774, 20.000000000000014, 32.00000000000016, 99.19999999999999, 20.000000000000014, -7.299999999999891, 20.000000000000014, 137.8999999999996, 138.79999999999995, -248.8000000000004, 140.59999999999962, 80.60000000000008, 20.000000000000014, -13.599999999999847, 70.99999999999977, -55.59999999999987, 91.09999999999934, 20.000000000000014, -33.99999999999976, 157.69999999999987, 77.59999999999994, 158.6, 20.000000000000014, 111.19999999999999, -49.3, -217.30000000000047, 66.49999999999996, 199.1, 20.000000000000014, 162.7999999999999, 80.00000000000011, 32.60000000000023, 62.30000000000021, 20.000000000000014, -63.1000000000004, 20.000000000000014, 78.49999999999986, 15.799999999999946, 20.000000000000014, 20.000000000000014, 29.900000000000187, 133.40000000000006, 59.6000000000002, 20.000000000000014, -49.29999999999979, -80.50000000000054, 36.19999999999999], "policy_predator_policy_reward": [104.0, 107.0, 26.0, 91.0, 29.0, 21.0, 0.0, 220.0, 100.0, 122.0, 92.0, 128.0, 0.0, 128.0, 56.0, 7.0, 146.0, 80.0, 100.0, 0.0, 5.0, 58.0, 5.0, 140.0, 10.0, 31.0, 261.0, 35.0, 0.0, 64.0, 6.0, 641.0, 0.0, 0.0, 0.0, 0.0, 68.0, 69.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 19.0, 23.0, 0.0, 0.0, 48.0, 117.0, 97.0, 4.0, 0.0, 19.0, 0.0, 0.0, 55.0, 0.0, 4.0, 0.0, 30.0, 43.0, 15.0, 0.0, 0.0, 0.0, 0.0, 162.0, 0.0, 0.0, 92.0, 198.0, 153.0, 33.0, 0.0, 0.0, 33.0, 0.0, 41.0, 116.0, 75.0, 100.0, 81.0, 45.0, 217.0, 9.0, 2.0, 51.0, 51.0, 0.0, 44.0, 0.0, 17.0, 0.0, 51.0, 0.0, 0.0, 59.0, 47.0, 70.0, 0.0, 127.0, 72.0, 0.0, 0.0, 0.0, 0.0, 0.0, 47.0, 25.0, 0.0, 0.0, 30.0, 43.0, 0.0, 18.0, 0.0, 54.0, 37.0, 45.0, 87.0, 0.0, 0.0, 0.0, 22.0, 26.0, 93.0, 0.0, 17.0, 16.0, 23.0, 0.0, 6.0, 6.0, 0.0, 62.0, 0.0, 34.0, 19.0, 0.0, 30.0, 0.0, 1.0, 44.0, 32.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 77.0, 117.0, 0.0, 2.0, 1.0, 19.0, 0.0, 36.0, 0.0, 27.0, 0.0, 0.0, 0.0, 3.0, 0.0, 47.0, 91.0, 83.0, 0.0, 0.0, 13.0, 1.0, 0.0, 0.0, 3.0, 43.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 24.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2299505074837453, "mean_inference_ms": 3.5025283428206326, "mean_action_processing_ms": 0.637445279169078, "mean_env_wait_ms": 0.42122541272692055, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009656310081481934, "StateBufferConnector_ms": 0.008798599243164062, "ViewRequirementAgentConnector_ms": 0.2528371810913086}, "num_episodes": 18, "episode_return_max": 306.1000000000014, "episode_return_min": -179.0, "episode_return_mean": 64.83299999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 208.1220904358667, "num_env_steps_trained_throughput_per_sec": 208.1220904358667, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 115573.401, "restore_workers_time_ms": 0.025, "training_step_time_ms": 115573.325, "sample_time_ms": 3554.762, "learn_time_ms": 111979.039, "learn_throughput": 35.721, "synch_weights_time_ms": 33.423}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "3a355_00000", "date": "2024-08-13_01-37-46", "timestamp": 1723527466, "time_this_iter_s": 19.275797843933105, "time_total_s": 1674.2776691913605, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df6af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1674.2776691913605, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 84.76071428571429, "ram_util_percent": 83.60357142857141}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3610117080251849, "cur_kl_coeff": 0.0001953125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.311524848269407, "policy_loss": -0.001814456736649234, "vf_loss": 1.3133379742739693, "vf_explained_var": 0.0035938558755097567, "kl": 0.0068202883599779085, "entropy": 0.5989320630749697, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7694911077382072, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.880795109082782, "policy_loss": -0.00047576553003478143, "vf_loss": 3.8810912715064156, "vf_explained_var": 0.08414382158763825, "kl": 0.0031928181130686344, "entropy": 1.145206198301265, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 306.1000000000014, "episode_reward_min": -169.2000000000004, "episode_reward_mean": 84.35499999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 217.0}, "policy_reward_mean": {"prey_policy": 17.64249999999995, "predator_policy": 24.535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [17.899999999999974, 239.3999999999993, 106.89999999999972, -163.90000000000015, 137.29999999999885, 150.49999999999923, -62.200000000001, 35.600000000000236, 194.19999999999945, 49.10000000000041, 255.9999999999999, 51.70000000000043, -80.60000000000002, -61.2000000000004, 82.49999999999994, 18.10000000000017, 14.500000000000156, 1.200000000000186, -39.89999999999964, 138.79999999999944, 119.19999999999976, 58.80000000000051, 151.8999999999998, 69.90000000000022, 21.3, 57.69999999999925, 247.89999999999907, 57.80000000000015, 129.49999999999977, 43.99999999999994, 110.19999999999973, 67.9, 89.09999999999903, 168.19999999999925, 116.79999999999971, 92.59999999999914, 147.09999999999948, 154.99999999999966, -33.79999999999982, 222.6999999999994, 280.40000000000043, 9.600000000000101, 21.299999999999994, 61.600000000000406, 119.79999999999974, 306.1000000000014, 38.4000000000003, 191.09999999999962, 150.69999999999982, 38.900000000000276, -37.299999999999855, 127.2999999999984, 40.0000000000003, 23.200000000000056, 21.400000000000006, 65.99999999999999, 119.1999999999999, 25.70000000000007, 276.70000000000067, 85.79999999999978, 102.6, 77.39999999999957, 71.50000000000003, 13.000000000000014, 235.2999999999991, 181.59999999999937, 108.89999999999989, 23.200000000000088, 219.09999999999926, 256.7999999999999, 94.89999999999978, 2.900000000000056, 98.49999999999972, 37.800000000000296, 49.90000000000046, 192.99999999999898, 3.700000000000117, 5.700000000000346, 41.99999999999997, 139.5999999999994, 145.7999999999991, -64.70000000000007, 51.3000000000003, 117.30000000000003, 40.0000000000003, 59.8000000000005, 49.900000000000404, 40.0000000000003, 50.40000000000041, 197.69999999999968, 66.40000000000015, 132.19999999999933, 167.09999999999914, 40.0000000000003, -169.2000000000004, -5.199999999999763, 98.79999999999991, 201.09999999999914, 81.50000000000027, 32.30000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999962, -16.899999999999743, 19.399999999999995, 197.0, 38.9, 20.000000000000014, -192.10000000000002, -185.80000000000007, 20.000000000000014, 113.29999999999953, 111.4999999999998, 20.000000000000014, -80.50000000000048, -36.69999999999984, 20.000000000000014, 11.599999999999968, -8.799999999999939, 173.00000000000006, 20.000000000000014, -28.899999999999842, 146.9, 109.10000000000008, 31.700000000000216, 20.000000000000014, -320.2, 77.5999999999995, -137.5000000000003, -15.699999999999775, 20.000000000000014, -288.50000000000006, 20.000000000000014, -34.899999999999785, -38.49999999999992, 20.000000000000014, -59.800000000000566, 20.000000000000014, -236.2000000000002, 5.299999999999981, 179.29999999999987, -221.50000000000043, -315.80000000000007, 172.99999999999983, 18.80000000000024, 29.000000000000163, -106.00000000000003, 155.9, -66.10000000000085, 91.99999999999932, -15.699999999999765, 20.000000000000014, -87.10000000000014, 93.79999999999933, 47.90000000000023, 200.0, -139.30000000000035, 91.09999999999991, 181.1, -121.60000000000062, 56.000000000000014, -211.0, 90.19999999999996, 20.000000000000014, 47.90000000000011, 20.000000000000014, -78.70000000000003, 120.7999999999995, 123.19999999999999, 20.000000000000014, 66.80000000000001, 20.000000000000014, -11.499999999999819, 61.10000000000002, 82.99999999999994, 46.1000000000001, 72.49999999999967, -8.5, 20.000000000000014, -185.80000000000024, 188.3, 34.400000000000055, 66.49999999999989, 191.9, 101.89999999999985, -211.30000000000032, 20.000000000000014, -15.699999999999747, 20.000000000000014, 2.5999999999999948, 93.79999999999998, 20.000000000000014, 162.19999999999993, 137.89999999999972, -57.700000000000195, 34.10000000000014, 67.09999999999998, 71.00000000000003, 82.6999999999999, 38.00000000000009, 20.000000000000014, 17.899999999999977, -133.30000000000027, 20.000000000000014, 83.8999999999995, 43.40000000000023, 20.000000000000014, 20.000000000000014, 26.300000000000114, -24.09999999999983, 20.000000000000014, -19.599999999999774, 20.000000000000014, 32.00000000000016, 99.19999999999999, 20.000000000000014, -7.299999999999891, 20.000000000000014, 137.8999999999996, 138.79999999999995, -248.8000000000004, 140.59999999999962, 80.60000000000008, 20.000000000000014, -13.599999999999847, 70.99999999999977, -55.59999999999987, 91.09999999999934, 20.000000000000014, -33.99999999999976, 157.69999999999987, 77.59999999999994, 158.6, 20.000000000000014, 111.19999999999999, -49.3, -217.30000000000047, 66.49999999999996, 199.1, 20.000000000000014, 162.7999999999999, 80.00000000000011, 32.60000000000023, 62.30000000000021, 20.000000000000014, -63.1000000000004, 20.000000000000014, 78.49999999999986, 15.799999999999946, 20.000000000000014, 20.000000000000014, 29.900000000000187, 133.40000000000006, 59.6000000000002, 20.000000000000014, -49.29999999999979, -80.50000000000054, 36.19999999999999, 25.999999999999964, -139.0000000000005, 15.799999999999963, 99.79999999999984, 66.8, 53.00000000000006, 20.000000000000014, -183.70000000000016, 26.600000000000136, 13.699999999999962, -78.10000000000028, 88.39999999999999, 20.000000000000014, 20.000000000000014, 39.800000000000246, 20.000000000000014, 29.90000000000012, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999795, 49.40000000000005, 95.29999999999987, 57.800000000000146, -45.400000000000546, 65.60000000000005, 23.60000000000008, 126.49999999999986, 23.60000000000001, 20.000000000000014, 20.000000000000014, -145.9000000000003, -130.30000000000004, 20.000000000000014, -131.20000000000073, -120.70000000000056, 135.49999999999994, 181.09999999999988, 20.000000000000014, 20.000000000000014, 57.50000000000003, 5.299999999999965, 20.000000000000014], "policy_predator_policy_reward": [0.0, 19.0, 23.0, 0.0, 0.0, 48.0, 117.0, 97.0, 4.0, 0.0, 19.0, 0.0, 0.0, 55.0, 0.0, 4.0, 0.0, 30.0, 43.0, 15.0, 0.0, 0.0, 0.0, 0.0, 162.0, 0.0, 0.0, 92.0, 198.0, 153.0, 33.0, 0.0, 0.0, 33.0, 0.0, 41.0, 116.0, 75.0, 100.0, 81.0, 45.0, 217.0, 9.0, 2.0, 51.0, 51.0, 0.0, 44.0, 0.0, 17.0, 0.0, 51.0, 0.0, 0.0, 59.0, 47.0, 70.0, 0.0, 127.0, 72.0, 0.0, 0.0, 0.0, 0.0, 0.0, 47.0, 25.0, 0.0, 0.0, 30.0, 43.0, 0.0, 18.0, 0.0, 54.0, 37.0, 45.0, 87.0, 0.0, 0.0, 0.0, 22.0, 26.0, 93.0, 0.0, 17.0, 16.0, 23.0, 0.0, 6.0, 6.0, 0.0, 62.0, 0.0, 34.0, 19.0, 0.0, 30.0, 0.0, 1.0, 44.0, 32.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 77.0, 117.0, 0.0, 2.0, 1.0, 19.0, 0.0, 36.0, 0.0, 27.0, 0.0, 0.0, 0.0, 3.0, 0.0, 47.0, 91.0, 83.0, 0.0, 0.0, 13.0, 1.0, 0.0, 0.0, 3.0, 43.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 24.0, 26.0, 96.0, 59.0, 0.0, 24.0, 0.0, 26.0, 96.0, 3.0, 3.0, 8.0, 29.0, 78.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 24.0, 17.0, 36.0, 1.0, 53.0, 34.0, 9.0, 17.0, 0.0, 0.0, 0.0, 102.0, 5.0, 71.0, 35.0, 27.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2394921334854234, "mean_inference_ms": 3.518081976809259, "mean_action_processing_ms": 0.6360420899151586, "mean_env_wait_ms": 0.4237145085059138, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012631416320800781, "StateBufferConnector_ms": 0.007433056831359863, "ViewRequirementAgentConnector_ms": 0.2803746461868286}, "num_episodes": 22, "episode_return_max": 306.1000000000014, "episode_return_min": -169.2000000000004, "episode_return_mean": 84.35499999999989, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 173.75679041690975, "num_env_steps_trained_throughput_per_sec": 173.75679041690975, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 114168.734, "restore_workers_time_ms": 0.024, "training_step_time_ms": 114168.658, "sample_time_ms": 3638.231, "learn_time_ms": 110491.34, "learn_throughput": 36.202, "synch_weights_time_ms": 33.14}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "3a355_00000", "date": "2024-08-13_01-38-09", "timestamp": 1723527489, "time_this_iter_s": 23.065401792526245, "time_total_s": 1697.3430709838867, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dc7e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1697.3430709838867, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 86.84062499999999, "ram_util_percent": 83.34375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3490820677369518, "cur_kl_coeff": 0.0001953125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2820819456741293, "policy_loss": -0.002293748719489606, "vf_loss": 1.2843747339709095, "vf_explained_var": 0.0007962875580661511, "kl": 0.004931793668521233, "entropy": 0.7092405750953331, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.429596141926826, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.519473408202015, "policy_loss": -0.00021088349727775763, "vf_loss": 2.5193614673992943, "vf_explained_var": 0.05773215464183262, "kl": 0.011478120710402145, "entropy": 1.1160965093229183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 306.1000000000014, "episode_reward_min": -169.2000000000004, "episode_reward_mean": 83.65399999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -248.8000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 127.0}, "policy_reward_mean": {"prey_policy": 23.626999999999942, "predator_policy": 18.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [69.90000000000022, 21.3, 57.69999999999925, 247.89999999999907, 57.80000000000015, 129.49999999999977, 43.99999999999994, 110.19999999999973, 67.9, 89.09999999999903, 168.19999999999925, 116.79999999999971, 92.59999999999914, 147.09999999999948, 154.99999999999966, -33.79999999999982, 222.6999999999994, 280.40000000000043, 9.600000000000101, 21.299999999999994, 61.600000000000406, 119.79999999999974, 306.1000000000014, 38.4000000000003, 191.09999999999962, 150.69999999999982, 38.900000000000276, -37.299999999999855, 127.2999999999984, 40.0000000000003, 23.200000000000056, 21.400000000000006, 65.99999999999999, 119.1999999999999, 25.70000000000007, 276.70000000000067, 85.79999999999978, 102.6, 77.39999999999957, 71.50000000000003, 13.000000000000014, 235.2999999999991, 181.59999999999937, 108.89999999999989, 23.200000000000088, 219.09999999999926, 256.7999999999999, 94.89999999999978, 2.900000000000056, 98.49999999999972, 37.800000000000296, 49.90000000000046, 192.99999999999898, 3.700000000000117, 5.700000000000346, 41.99999999999997, 139.5999999999994, 145.7999999999991, -64.70000000000007, 51.3000000000003, 117.30000000000003, 40.0000000000003, 59.8000000000005, 49.900000000000404, 40.0000000000003, 50.40000000000041, 197.69999999999968, 66.40000000000015, 132.19999999999933, 167.09999999999914, 40.0000000000003, -169.2000000000004, -5.199999999999763, 98.79999999999991, 201.09999999999914, 81.50000000000027, 32.30000000000018, -48.8000000000001, 17.999999999999957, 52.400000000000446, 40.0000000000003, 149.59999999999934, 45.800000000000395, -20.49999999999971, 40.0000000000003, 40.0000000000003, 200.49999999999937, -34.0999999999996, 201.09999999999914, 80.59999999999971, 14.699999999999994, -79.90000000000083, 40.0000000000003, 80.99999999999909, 132.59999999999948, 153.6999999999989, 74.89999999999974, 40.0000000000003, 80.49999999999937, 43.60000000000035], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-66.10000000000085, 91.99999999999932, -15.699999999999765, 20.000000000000014, -87.10000000000014, 93.79999999999933, 47.90000000000023, 200.0, -139.30000000000035, 91.09999999999991, 181.1, -121.60000000000062, 56.000000000000014, -211.0, 90.19999999999996, 20.000000000000014, 47.90000000000011, 20.000000000000014, -78.70000000000003, 120.7999999999995, 123.19999999999999, 20.000000000000014, 66.80000000000001, 20.000000000000014, -11.499999999999819, 61.10000000000002, 82.99999999999994, 46.1000000000001, 72.49999999999967, -8.5, 20.000000000000014, -185.80000000000024, 188.3, 34.400000000000055, 66.49999999999989, 191.9, 101.89999999999985, -211.30000000000032, 20.000000000000014, -15.699999999999747, 20.000000000000014, 2.5999999999999948, 93.79999999999998, 20.000000000000014, 162.19999999999993, 137.89999999999972, -57.700000000000195, 34.10000000000014, 67.09999999999998, 71.00000000000003, 82.6999999999999, 38.00000000000009, 20.000000000000014, 17.899999999999977, -133.30000000000027, 20.000000000000014, 83.8999999999995, 43.40000000000023, 20.000000000000014, 20.000000000000014, 26.300000000000114, -24.09999999999983, 20.000000000000014, -19.599999999999774, 20.000000000000014, 32.00000000000016, 99.19999999999999, 20.000000000000014, -7.299999999999891, 20.000000000000014, 137.8999999999996, 138.79999999999995, -248.8000000000004, 140.59999999999962, 80.60000000000008, 20.000000000000014, -13.599999999999847, 70.99999999999977, -55.59999999999987, 91.09999999999934, 20.000000000000014, -33.99999999999976, 157.69999999999987, 77.59999999999994, 158.6, 20.000000000000014, 111.19999999999999, -49.3, -217.30000000000047, 66.49999999999996, 199.1, 20.000000000000014, 162.7999999999999, 80.00000000000011, 32.60000000000023, 62.30000000000021, 20.000000000000014, -63.1000000000004, 20.000000000000014, 78.49999999999986, 15.799999999999946, 20.000000000000014, 20.000000000000014, 29.900000000000187, 133.40000000000006, 59.6000000000002, 20.000000000000014, -49.29999999999979, -80.50000000000054, 36.19999999999999, 25.999999999999964, -139.0000000000005, 15.799999999999963, 99.79999999999984, 66.8, 53.00000000000006, 20.000000000000014, -183.70000000000016, 26.600000000000136, 13.699999999999962, -78.10000000000028, 88.39999999999999, 20.000000000000014, 20.000000000000014, 39.800000000000246, 20.000000000000014, 29.90000000000012, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999795, 49.40000000000005, 95.29999999999987, 57.800000000000146, -45.400000000000546, 65.60000000000005, 23.60000000000008, 126.49999999999986, 23.60000000000001, 20.000000000000014, 20.000000000000014, -145.9000000000003, -130.30000000000004, 20.000000000000014, -131.20000000000073, -120.70000000000056, 135.49999999999994, 181.09999999999988, 20.000000000000014, 20.000000000000014, 57.50000000000003, 5.299999999999965, 20.000000000000014, -150.1000000000006, 8.299999999999972, -136.00000000000068, 20.000000000000014, 5.299999999999965, 37.10000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 110.59999999999987, 20.000000000000014, 18.8, 20.000000000000014, -95.50000000000054, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 177.5, 20.000000000000014, -103.9000000000008, -14.199999999999877, 181.09999999999988, 20.000000000000014, -36.999999999999915, 68.59999999999988, 20.000000000000014, -28.29999999999975, -208.90000000000046, 20.000000000000014, 20.000000000000014, 20.000000000000014, 122.59999999999951, -97.60000000000059, 128.29999999999984, -15.699999999999761, 34.40000000000021, 116.29999999999961, 39.50000000000024, 34.40000000000026, 20.000000000000014, 20.000000000000014, 60.50000000000022, 20.000000000000014, 20.000000000000014, 23.600000000000065], "policy_predator_policy_reward": [0.0, 44.0, 0.0, 17.0, 0.0, 51.0, 0.0, 0.0, 59.0, 47.0, 70.0, 0.0, 127.0, 72.0, 0.0, 0.0, 0.0, 0.0, 0.0, 47.0, 25.0, 0.0, 0.0, 30.0, 43.0, 0.0, 18.0, 0.0, 54.0, 37.0, 45.0, 87.0, 0.0, 0.0, 0.0, 22.0, 26.0, 93.0, 0.0, 17.0, 16.0, 23.0, 0.0, 6.0, 6.0, 0.0, 62.0, 0.0, 34.0, 19.0, 0.0, 30.0, 0.0, 1.0, 44.0, 32.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 77.0, 117.0, 0.0, 2.0, 1.0, 19.0, 0.0, 36.0, 0.0, 27.0, 0.0, 0.0, 0.0, 3.0, 0.0, 47.0, 91.0, 83.0, 0.0, 0.0, 13.0, 1.0, 0.0, 0.0, 3.0, 43.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 24.0, 26.0, 96.0, 59.0, 0.0, 24.0, 0.0, 26.0, 96.0, 3.0, 3.0, 8.0, 29.0, 78.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 24.0, 17.0, 36.0, 1.0, 53.0, 34.0, 9.0, 17.0, 0.0, 0.0, 0.0, 102.0, 5.0, 71.0, 35.0, 27.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 7.0, 12.0, 81.0, 68.0, 66.0, 0.0, 10.0, 0.0, 0.0, 19.0, 0.0, 0.0, 7.0, 48.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 25.0, 59.0, 0.0, 0.0, 23.0, 26.0, 0.0, 23.0, 70.0, 39.0, 0.0, 0.0, 0.0, 56.0, 20.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2487874579309584, "mean_inference_ms": 3.5476689705218223, "mean_action_processing_ms": 0.6361381761491767, "mean_env_wait_ms": 0.4266899243032697, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010851740837097168, "StateBufferConnector_ms": 0.005192279815673828, "ViewRequirementAgentConnector_ms": 0.27531540393829346}, "num_episodes": 23, "episode_return_max": 306.1000000000014, "episode_return_min": -169.2000000000004, "episode_return_mean": 83.65399999999988, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 178.59527475369484, "num_env_steps_trained_throughput_per_sec": 178.59527475369484, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 114614.34, "restore_workers_time_ms": 0.024, "training_step_time_ms": 114614.263, "sample_time_ms": 3707.453, "learn_time_ms": 110867.462, "learn_throughput": 36.079, "synch_weights_time_ms": 33.643}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "3a355_00000", "date": "2024-08-13_01-38-31", "timestamp": 1723527511, "time_this_iter_s": 22.44962787628174, "time_total_s": 1719.7926988601685, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3ddf940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1719.7926988601685, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 85.540625, "ram_util_percent": 83.01249999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3029972821907707, "cur_kl_coeff": 9.765625e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.093737223507866, "policy_loss": -0.0020536963744138283, "vf_loss": 1.0957901764641362, "vf_explained_var": 0.002007486107488158, "kl": 0.0076198090978444434, "entropy": 0.6646532540598874, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3950412653820226, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.492891830048233, "policy_loss": -0.0016563044294281295, "vf_loss": 2.4941755103055763, "vf_explained_var": 0.036747294002109104, "kl": 0.013249032643682723, "entropy": 1.1506982665213328, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 306.1000000000014, "episode_reward_min": -169.2000000000004, "episode_reward_mean": 74.34699999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -248.8000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 117.0}, "policy_reward_mean": {"prey_policy": 21.423499999999947, "predator_policy": 15.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.600000000000101, 21.299999999999994, 61.600000000000406, 119.79999999999974, 306.1000000000014, 38.4000000000003, 191.09999999999962, 150.69999999999982, 38.900000000000276, -37.299999999999855, 127.2999999999984, 40.0000000000003, 23.200000000000056, 21.400000000000006, 65.99999999999999, 119.1999999999999, 25.70000000000007, 276.70000000000067, 85.79999999999978, 102.6, 77.39999999999957, 71.50000000000003, 13.000000000000014, 235.2999999999991, 181.59999999999937, 108.89999999999989, 23.200000000000088, 219.09999999999926, 256.7999999999999, 94.89999999999978, 2.900000000000056, 98.49999999999972, 37.800000000000296, 49.90000000000046, 192.99999999999898, 3.700000000000117, 5.700000000000346, 41.99999999999997, 139.5999999999994, 145.7999999999991, -64.70000000000007, 51.3000000000003, 117.30000000000003, 40.0000000000003, 59.8000000000005, 49.900000000000404, 40.0000000000003, 50.40000000000041, 197.69999999999968, 66.40000000000015, 132.19999999999933, 167.09999999999914, 40.0000000000003, -169.2000000000004, -5.199999999999763, 98.79999999999991, 201.09999999999914, 81.50000000000027, 32.30000000000018, -48.8000000000001, 17.999999999999957, 52.400000000000446, 40.0000000000003, 149.59999999999934, 45.800000000000395, -20.49999999999971, 40.0000000000003, 40.0000000000003, 200.49999999999937, -34.0999999999996, 201.09999999999914, 80.59999999999971, 14.699999999999994, -79.90000000000083, 40.0000000000003, 80.99999999999909, 132.59999999999948, 153.6999999999989, 74.89999999999974, 40.0000000000003, 80.49999999999937, 43.60000000000035, 94.3999999999998, 125.49999999999889, 169.1999999999991, -18.09999999999949, 40.0000000000003, 54.400000000000404, 40.0000000000003, 42.700000000000365, 83.19999999999911, 151.1999999999986, 60.40000000000042, -27.899999999999835, 152.59999999999886, 38.800000000000296, -13.799999999999569, 13.599999999999923, 52.00000000000045, 55.4000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [101.89999999999985, -211.30000000000032, 20.000000000000014, -15.699999999999747, 20.000000000000014, 2.5999999999999948, 93.79999999999998, 20.000000000000014, 162.19999999999993, 137.89999999999972, -57.700000000000195, 34.10000000000014, 67.09999999999998, 71.00000000000003, 82.6999999999999, 38.00000000000009, 20.000000000000014, 17.899999999999977, -133.30000000000027, 20.000000000000014, 83.8999999999995, 43.40000000000023, 20.000000000000014, 20.000000000000014, 26.300000000000114, -24.09999999999983, 20.000000000000014, -19.599999999999774, 20.000000000000014, 32.00000000000016, 99.19999999999999, 20.000000000000014, -7.299999999999891, 20.000000000000014, 137.8999999999996, 138.79999999999995, -248.8000000000004, 140.59999999999962, 80.60000000000008, 20.000000000000014, -13.599999999999847, 70.99999999999977, -55.59999999999987, 91.09999999999934, 20.000000000000014, -33.99999999999976, 157.69999999999987, 77.59999999999994, 158.6, 20.000000000000014, 111.19999999999999, -49.3, -217.30000000000047, 66.49999999999996, 199.1, 20.000000000000014, 162.7999999999999, 80.00000000000011, 32.60000000000023, 62.30000000000021, 20.000000000000014, -63.1000000000004, 20.000000000000014, 78.49999999999986, 15.799999999999946, 20.000000000000014, 20.000000000000014, 29.900000000000187, 133.40000000000006, 59.6000000000002, 20.000000000000014, -49.29999999999979, -80.50000000000054, 36.19999999999999, 25.999999999999964, -139.0000000000005, 15.799999999999963, 99.79999999999984, 66.8, 53.00000000000006, 20.000000000000014, -183.70000000000016, 26.600000000000136, 13.699999999999962, -78.10000000000028, 88.39999999999999, 20.000000000000014, 20.000000000000014, 39.800000000000246, 20.000000000000014, 29.90000000000012, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999795, 49.40000000000005, 95.29999999999987, 57.800000000000146, -45.400000000000546, 65.60000000000005, 23.60000000000008, 126.49999999999986, 23.60000000000001, 20.000000000000014, 20.000000000000014, -145.9000000000003, -130.30000000000004, 20.000000000000014, -131.20000000000073, -120.70000000000056, 135.49999999999994, 181.09999999999988, 20.000000000000014, 20.000000000000014, 57.50000000000003, 5.299999999999965, 20.000000000000014, -150.1000000000006, 8.299999999999972, -136.00000000000068, 20.000000000000014, 5.299999999999965, 37.10000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 110.59999999999987, 20.000000000000014, 18.8, 20.000000000000014, -95.50000000000054, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 177.5, 20.000000000000014, -103.9000000000008, -14.199999999999877, 181.09999999999988, 20.000000000000014, -36.999999999999915, 68.59999999999988, 20.000000000000014, -28.29999999999975, -208.90000000000046, 20.000000000000014, 20.000000000000014, 20.000000000000014, 122.59999999999951, -97.60000000000059, 128.29999999999984, -15.699999999999761, 34.40000000000021, 116.29999999999961, 39.50000000000024, 34.40000000000026, 20.000000000000014, 20.000000000000014, 60.50000000000022, 20.000000000000014, 20.000000000000014, 23.600000000000065, -164.8000000000001, 171.19999999999996, 31.700000000000212, 93.79999999999951, 97.69999999999976, 69.49999999999982, -7.299999999999891, -38.799999999999756, 20.000000000000014, 20.000000000000014, 27.20000000000008, 27.20000000000013, 20.000000000000014, 20.000000000000014, 56.00000000000021, -49.299999999999905, 20.000000000000014, 63.200000000000216, 75.79999999999941, 64.40000000000013, 20.000000000000014, 25.400000000000116, -103.90000000000032, 10.999999999999966, 40.400000000000105, 81.19999999999929, 28.100000000000147, -13.299999999999827, -78.70000000000087, 17.899999999999988, 20.000000000000014, -30.399999999999828, 20.000000000000014, 20.000000000000014, 13.399999999999968, 20.000000000000014], "policy_predator_policy_reward": [26.0, 93.0, 0.0, 17.0, 16.0, 23.0, 0.0, 6.0, 6.0, 0.0, 62.0, 0.0, 34.0, 19.0, 0.0, 30.0, 0.0, 1.0, 44.0, 32.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 77.0, 117.0, 0.0, 2.0, 1.0, 19.0, 0.0, 36.0, 0.0, 27.0, 0.0, 0.0, 0.0, 3.0, 0.0, 47.0, 91.0, 83.0, 0.0, 0.0, 13.0, 1.0, 0.0, 0.0, 3.0, 43.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 24.0, 26.0, 96.0, 59.0, 0.0, 24.0, 0.0, 26.0, 96.0, 3.0, 3.0, 8.0, 29.0, 78.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 24.0, 17.0, 36.0, 1.0, 53.0, 34.0, 9.0, 17.0, 0.0, 0.0, 0.0, 102.0, 5.0, 71.0, 35.0, 27.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 7.0, 12.0, 81.0, 68.0, 66.0, 0.0, 10.0, 0.0, 0.0, 19.0, 0.0, 0.0, 7.0, 48.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 25.0, 59.0, 0.0, 0.0, 23.0, 26.0, 0.0, 23.0, 70.0, 39.0, 0.0, 0.0, 0.0, 56.0, 20.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 88.0, 0.0, 0.0, 2.0, 0.0, 13.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 3.0, 0.0, 0.0, 0.0, 11.0, 15.0, 0.0, 65.0, 0.0, 0.0, 31.0, 24.0, 0.0, 29.0, 18.0, 0.0, 24.0, 0.0, 12.0, 0.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.257188017038889, "mean_inference_ms": 3.5693318338996263, "mean_action_processing_ms": 0.6366522956259333, "mean_env_wait_ms": 0.4290788984844921, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011127471923828125, "StateBufferConnector_ms": 0.005500674247741699, "ViewRequirementAgentConnector_ms": 0.29501092433929443}, "num_episodes": 18, "episode_return_max": 306.1000000000014, "episode_return_min": -169.2000000000004, "episode_return_mean": 74.34699999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.62933171071555, "num_env_steps_trained_throughput_per_sec": 154.62933171071555, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 21919.651, "restore_workers_time_ms": 0.024, "training_step_time_ms": 21919.572, "sample_time_ms": 3521.86, "learn_time_ms": 18368.488, "learn_throughput": 217.764, "synch_weights_time_ms": 23.499}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "3a355_00000", "date": "2024-08-13_01-38-57", "timestamp": 1723527537, "time_this_iter_s": 25.929343938827515, "time_total_s": 1745.722042798996, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b506b3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1745.722042798996, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 86.98055555555555, "ram_util_percent": 83.65833333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3441842218575181, "cur_kl_coeff": 9.765625e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6427003001882916, "policy_loss": -0.0013964881637582073, "vf_loss": 0.6440965523568805, "vf_explained_var": 0.005116079660950515, "kl": 0.002410689083297629, "entropy": 0.6790614016472347, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.38134264964906, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2489881167178432, "policy_loss": -0.0028885959997457804, "vf_loss": 1.2514395341040596, "vf_explained_var": 0.033343164599131024, "kl": 0.015544157471572603, "entropy": 1.1527389873903264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 256.7999999999999, "episode_reward_min": -169.2000000000004, "episode_reward_mean": 64.9239999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -248.8000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 199.1, "predator_policy": 117.0}, "policy_reward_mean": {"prey_policy": 17.611999999999963, "predator_policy": 14.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [85.79999999999978, 102.6, 77.39999999999957, 71.50000000000003, 13.000000000000014, 235.2999999999991, 181.59999999999937, 108.89999999999989, 23.200000000000088, 219.09999999999926, 256.7999999999999, 94.89999999999978, 2.900000000000056, 98.49999999999972, 37.800000000000296, 49.90000000000046, 192.99999999999898, 3.700000000000117, 5.700000000000346, 41.99999999999997, 139.5999999999994, 145.7999999999991, -64.70000000000007, 51.3000000000003, 117.30000000000003, 40.0000000000003, 59.8000000000005, 49.900000000000404, 40.0000000000003, 50.40000000000041, 197.69999999999968, 66.40000000000015, 132.19999999999933, 167.09999999999914, 40.0000000000003, -169.2000000000004, -5.199999999999763, 98.79999999999991, 201.09999999999914, 81.50000000000027, 32.30000000000018, -48.8000000000001, 17.999999999999957, 52.400000000000446, 40.0000000000003, 149.59999999999934, 45.800000000000395, -20.49999999999971, 40.0000000000003, 40.0000000000003, 200.49999999999937, -34.0999999999996, 201.09999999999914, 80.59999999999971, 14.699999999999994, -79.90000000000083, 40.0000000000003, 80.99999999999909, 132.59999999999948, 153.6999999999989, 74.89999999999974, 40.0000000000003, 80.49999999999937, 43.60000000000035, 94.3999999999998, 125.49999999999889, 169.1999999999991, -18.09999999999949, 40.0000000000003, 54.400000000000404, 40.0000000000003, 42.700000000000365, 83.19999999999911, 151.1999999999986, 60.40000000000042, -27.899999999999835, 152.59999999999886, 38.800000000000296, -13.799999999999569, 13.599999999999923, 52.00000000000045, 55.4000000000004, 51.20000000000049, 32.20000000000016, -9.1999999999996, 95.2999999999982, 52.10000000000048, 75.0999999999997, 55.4000000000005, 40.0000000000003, 36.400000000000276, 29.100000000000307, 31.100000000000165, 59.80000000000051, -128.00000000000148, 46.00000000000034, 76.8999999999996, 11.400000000000048, 19.099999999999973, 83.49999999999903], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-248.8000000000004, 140.59999999999962, 80.60000000000008, 20.000000000000014, -13.599999999999847, 70.99999999999977, -55.59999999999987, 91.09999999999934, 20.000000000000014, -33.99999999999976, 157.69999999999987, 77.59999999999994, 158.6, 20.000000000000014, 111.19999999999999, -49.3, -217.30000000000047, 66.49999999999996, 199.1, 20.000000000000014, 162.7999999999999, 80.00000000000011, 32.60000000000023, 62.30000000000021, 20.000000000000014, -63.1000000000004, 20.000000000000014, 78.49999999999986, 15.799999999999946, 20.000000000000014, 20.000000000000014, 29.900000000000187, 133.40000000000006, 59.6000000000002, 20.000000000000014, -49.29999999999979, -80.50000000000054, 36.19999999999999, 25.999999999999964, -139.0000000000005, 15.799999999999963, 99.79999999999984, 66.8, 53.00000000000006, 20.000000000000014, -183.70000000000016, 26.600000000000136, 13.699999999999962, -78.10000000000028, 88.39999999999999, 20.000000000000014, 20.000000000000014, 39.800000000000246, 20.000000000000014, 29.90000000000012, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999795, 49.40000000000005, 95.29999999999987, 57.800000000000146, -45.400000000000546, 65.60000000000005, 23.60000000000008, 126.49999999999986, 23.60000000000001, 20.000000000000014, 20.000000000000014, -145.9000000000003, -130.30000000000004, 20.000000000000014, -131.20000000000073, -120.70000000000056, 135.49999999999994, 181.09999999999988, 20.000000000000014, 20.000000000000014, 57.50000000000003, 5.299999999999965, 20.000000000000014, -150.1000000000006, 8.299999999999972, -136.00000000000068, 20.000000000000014, 5.299999999999965, 37.10000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 110.59999999999987, 20.000000000000014, 18.8, 20.000000000000014, -95.50000000000054, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 177.5, 20.000000000000014, -103.9000000000008, -14.199999999999877, 181.09999999999988, 20.000000000000014, -36.999999999999915, 68.59999999999988, 20.000000000000014, -28.29999999999975, -208.90000000000046, 20.000000000000014, 20.000000000000014, 20.000000000000014, 122.59999999999951, -97.60000000000059, 128.29999999999984, -15.699999999999761, 34.40000000000021, 116.29999999999961, 39.50000000000024, 34.40000000000026, 20.000000000000014, 20.000000000000014, 60.50000000000022, 20.000000000000014, 20.000000000000014, 23.600000000000065, -164.8000000000001, 171.19999999999996, 31.700000000000212, 93.79999999999951, 97.69999999999976, 69.49999999999982, -7.299999999999891, -38.799999999999756, 20.000000000000014, 20.000000000000014, 27.20000000000008, 27.20000000000013, 20.000000000000014, 20.000000000000014, 56.00000000000021, -49.299999999999905, 20.000000000000014, 63.200000000000216, 75.79999999999941, 64.40000000000013, 20.000000000000014, 25.400000000000116, -103.90000000000032, 10.999999999999966, 40.400000000000105, 81.19999999999929, 28.100000000000147, -13.299999999999827, -78.70000000000087, 17.899999999999988, 20.000000000000014, -30.399999999999828, 20.000000000000014, 20.000000000000014, 13.399999999999968, 20.000000000000014, 38.900000000000254, 5.299999999999965, -5.1999999999999265, 25.400000000000112, -17.79999999999974, -9.399999999999855, 46.10000000000024, 42.200000000000216, 16.099999999999962, 20.000000000000014, 55.10000000000023, 20.000000000000014, 11.599999999999964, 39.80000000000025, 20.000000000000014, 20.000000000000014, 0.499999999999967, 17.899999999999988, 5.900000000000066, -17.799999999999876, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 39.80000000000025, -120.70000000000076, -91.30000000000072, 23.600000000000055, 7.3999999999999755, 43.40000000000025, 33.50000000000024, 20.000000000000014, -34.59999999999975, 20.000000000000014, -19.899999999999785, 11.899999999999975, 50.60000000000023], "policy_predator_policy_reward": [77.0, 117.0, 0.0, 2.0, 1.0, 19.0, 0.0, 36.0, 0.0, 27.0, 0.0, 0.0, 0.0, 3.0, 0.0, 47.0, 91.0, 83.0, 0.0, 0.0, 13.0, 1.0, 0.0, 0.0, 3.0, 43.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 24.0, 26.0, 96.0, 59.0, 0.0, 24.0, 0.0, 26.0, 96.0, 3.0, 3.0, 8.0, 29.0, 78.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 24.0, 17.0, 36.0, 1.0, 53.0, 34.0, 9.0, 17.0, 0.0, 0.0, 0.0, 102.0, 5.0, 71.0, 35.0, 27.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 7.0, 12.0, 81.0, 68.0, 66.0, 0.0, 10.0, 0.0, 0.0, 19.0, 0.0, 0.0, 7.0, 48.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 25.0, 59.0, 0.0, 0.0, 23.0, 26.0, 0.0, 23.0, 70.0, 39.0, 0.0, 0.0, 0.0, 56.0, 20.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 88.0, 0.0, 0.0, 2.0, 0.0, 13.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 3.0, 0.0, 0.0, 0.0, 11.0, 15.0, 0.0, 65.0, 0.0, 0.0, 31.0, 24.0, 0.0, 29.0, 18.0, 0.0, 24.0, 0.0, 12.0, 0.0, 22.0, 0.0, 7.0, 0.0, 12.0, 18.0, 0.0, 0.0, 7.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 18.0, 0.0, 12.0, 29.0, 9.0, 1.0, 0.0, 0.0, 19.0, 65.0, 15.0, 0.0, 0.0, 0.0, 0.0, 26.0, 19.0, 0.0, 21.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2665120016351799, "mean_inference_ms": 3.5945099353466703, "mean_action_processing_ms": 0.6376545168850264, "mean_env_wait_ms": 0.4318266101891638, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010607123374938965, "StateBufferConnector_ms": 0.006273150444030762, "ViewRequirementAgentConnector_ms": 0.31416773796081543}, "num_episodes": 18, "episode_return_max": 256.7999999999999, "episode_return_min": -169.2000000000004, "episode_return_mean": 64.9239999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 175.75974989700163, "num_env_steps_trained_throughput_per_sec": 175.75974989700163, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 21265.004, "restore_workers_time_ms": 0.021, "training_step_time_ms": 21264.933, "sample_time_ms": 3401.185, "learn_time_ms": 17836.381, "learn_throughput": 224.261, "synch_weights_time_ms": 22.524}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "3a355_00000", "date": "2024-08-13_01-39-20", "timestamp": 1723527560, "time_this_iter_s": 22.829748153686523, "time_total_s": 1768.5517909526825, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b506bd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1768.5517909526825, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 84.70606060606062, "ram_util_percent": 83.51818181818183}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2398634524858266, "cur_kl_coeff": 4.8828125e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.837231789584513, "policy_loss": -0.005838240938699711, "vf_loss": 0.8430694548521566, "vf_explained_var": 0.0027440468154887043, "kl": 0.011797129080604858, "entropy": 0.6191190058276766, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.912979590124081, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.407695724361788, "policy_loss": -0.002308001762216605, "vf_loss": 1.4096708537094176, "vf_explained_var": -0.004309256020046416, "kl": 0.011835421379410427, "entropy": 1.074003109477815, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 201.09999999999914, "episode_reward_min": -169.2000000000004, "episode_reward_mean": 49.42299999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -208.90000000000046, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999988, "predator_policy": 124.0}, "policy_reward_mean": {"prey_policy": 11.091499999999966, "predator_policy": 13.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-64.70000000000007, 51.3000000000003, 117.30000000000003, 40.0000000000003, 59.8000000000005, 49.900000000000404, 40.0000000000003, 50.40000000000041, 197.69999999999968, 66.40000000000015, 132.19999999999933, 167.09999999999914, 40.0000000000003, -169.2000000000004, -5.199999999999763, 98.79999999999991, 201.09999999999914, 81.50000000000027, 32.30000000000018, -48.8000000000001, 17.999999999999957, 52.400000000000446, 40.0000000000003, 149.59999999999934, 45.800000000000395, -20.49999999999971, 40.0000000000003, 40.0000000000003, 200.49999999999937, -34.0999999999996, 201.09999999999914, 80.59999999999971, 14.699999999999994, -79.90000000000083, 40.0000000000003, 80.99999999999909, 132.59999999999948, 153.6999999999989, 74.89999999999974, 40.0000000000003, 80.49999999999937, 43.60000000000035, 94.3999999999998, 125.49999999999889, 169.1999999999991, -18.09999999999949, 40.0000000000003, 54.400000000000404, 40.0000000000003, 42.700000000000365, 83.19999999999911, 151.1999999999986, 60.40000000000042, -27.899999999999835, 152.59999999999886, 38.800000000000296, -13.799999999999569, 13.599999999999923, 52.00000000000045, 55.4000000000004, 51.20000000000049, 32.20000000000016, -9.1999999999996, 95.2999999999982, 52.10000000000048, 75.0999999999997, 55.4000000000005, 40.0000000000003, 36.400000000000276, 29.100000000000307, 31.100000000000165, 59.80000000000051, -128.00000000000148, 46.00000000000034, 76.8999999999996, 11.400000000000048, 19.099999999999973, 83.49999999999903, -3.9999999999997313, -10.599999999999623, -5.199999999999756, 62.30000000000037, 24.300000000000068, 23.500000000000032, 40.0000000000003, 38.900000000000276, 65.20000000000041, 60.70000000000047, 65.1000000000003, 43.60000000000035, 62.70000000000044, -30.39999999999987, 40.0000000000003, 67.90000000000019, 97.59999999999849, 40.0000000000003, 9.700000000000033, 55.90000000000045, 30.10000000000016, -138.40000000000109], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -183.70000000000016, 26.600000000000136, 13.699999999999962, -78.10000000000028, 88.39999999999999, 20.000000000000014, 20.000000000000014, 39.800000000000246, 20.000000000000014, 29.90000000000012, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999795, 49.40000000000005, 95.29999999999987, 57.800000000000146, -45.400000000000546, 65.60000000000005, 23.60000000000008, 126.49999999999986, 23.60000000000001, 20.000000000000014, 20.000000000000014, -145.9000000000003, -130.30000000000004, 20.000000000000014, -131.20000000000073, -120.70000000000056, 135.49999999999994, 181.09999999999988, 20.000000000000014, 20.000000000000014, 57.50000000000003, 5.299999999999965, 20.000000000000014, -150.1000000000006, 8.299999999999972, -136.00000000000068, 20.000000000000014, 5.299999999999965, 37.10000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 110.59999999999987, 20.000000000000014, 18.8, 20.000000000000014, -95.50000000000054, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 177.5, 20.000000000000014, -103.9000000000008, -14.199999999999877, 181.09999999999988, 20.000000000000014, -36.999999999999915, 68.59999999999988, 20.000000000000014, -28.29999999999975, -208.90000000000046, 20.000000000000014, 20.000000000000014, 20.000000000000014, 122.59999999999951, -97.60000000000059, 128.29999999999984, -15.699999999999761, 34.40000000000021, 116.29999999999961, 39.50000000000024, 34.40000000000026, 20.000000000000014, 20.000000000000014, 60.50000000000022, 20.000000000000014, 20.000000000000014, 23.600000000000065, -164.8000000000001, 171.19999999999996, 31.700000000000212, 93.79999999999951, 97.69999999999976, 69.49999999999982, -7.299999999999891, -38.799999999999756, 20.000000000000014, 20.000000000000014, 27.20000000000008, 27.20000000000013, 20.000000000000014, 20.000000000000014, 56.00000000000021, -49.299999999999905, 20.000000000000014, 63.200000000000216, 75.79999999999941, 64.40000000000013, 20.000000000000014, 25.400000000000116, -103.90000000000032, 10.999999999999966, 40.400000000000105, 81.19999999999929, 28.100000000000147, -13.299999999999827, -78.70000000000087, 17.899999999999988, 20.000000000000014, -30.399999999999828, 20.000000000000014, 20.000000000000014, 13.399999999999968, 20.000000000000014, 38.900000000000254, 5.299999999999965, -5.1999999999999265, 25.400000000000112, -17.79999999999974, -9.399999999999855, 46.10000000000024, 42.200000000000216, 16.099999999999962, 20.000000000000014, 55.10000000000023, 20.000000000000014, 11.599999999999964, 39.80000000000025, 20.000000000000014, 20.000000000000014, 0.499999999999967, 17.899999999999988, 5.900000000000066, -17.799999999999876, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 39.80000000000025, -120.70000000000076, -91.30000000000072, 23.600000000000055, 7.3999999999999755, 43.40000000000025, 33.50000000000024, 20.000000000000014, -34.59999999999975, 20.000000000000014, -19.899999999999785, 11.899999999999975, 50.60000000000023, 20.000000000000014, -64.00000000000091, 20.000000000000014, -76.60000000000088, -95.50000000000082, 35.30000000000026, -33.39999999999984, 58.70000000000022, -28.29999999999975, -33.39999999999979, -11.499999999999833, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999984, 45.200000000000244, 20.000000000000014, 20.000000000000014, 31.70000000000022, -33.69999999999978, 66.79999999999997, 23.600000000000065, 20.000000000000014, 5.299999999999965, 40.4000000000002, -7.3000000000000504, -96.1000000000003, 20.000000000000014, 20.000000000000014, 47.900000000000226, 20.000000000000014, 20.000000000000014, 77.59999999999923, 20.000000000000014, 20.000000000000014, 30.800000000000196, -60.10000000000063, -15.999999999999774, 47.900000000000226, 20.000000000000014, 1.0999999999999617, -135.40000000000072, -127.00000000000043], "policy_predator_policy_reward": [96.0, 3.0, 3.0, 8.0, 29.0, 78.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 24.0, 17.0, 36.0, 1.0, 53.0, 34.0, 9.0, 17.0, 0.0, 0.0, 0.0, 102.0, 5.0, 71.0, 35.0, 27.0, 57.0, 0.0, 0.0, 4.0, 0.0, 0.0, 7.0, 12.0, 81.0, 68.0, 66.0, 0.0, 10.0, 0.0, 0.0, 19.0, 0.0, 0.0, 7.0, 48.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 25.0, 59.0, 0.0, 0.0, 23.0, 26.0, 0.0, 23.0, 70.0, 39.0, 0.0, 0.0, 0.0, 56.0, 20.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 88.0, 0.0, 0.0, 2.0, 0.0, 13.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 3.0, 0.0, 0.0, 0.0, 11.0, 15.0, 0.0, 65.0, 0.0, 0.0, 31.0, 24.0, 0.0, 29.0, 18.0, 0.0, 24.0, 0.0, 12.0, 0.0, 22.0, 0.0, 7.0, 0.0, 12.0, 18.0, 0.0, 0.0, 7.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 18.0, 0.0, 12.0, 29.0, 9.0, 1.0, 0.0, 0.0, 19.0, 65.0, 15.0, 0.0, 0.0, 0.0, 0.0, 26.0, 19.0, 0.0, 21.0, 0.0, 40.0, 0.0, 0.0, 46.0, 0.0, 55.0, 0.0, 37.0, 40.0, 46.0, 15.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 32.0, 0.0, 0.0, 0.0, 0.0, 17.0, 19.0, 54.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 24.0, 9.0, 0.0, 0.0, 124.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2780637002884825, "mean_inference_ms": 3.617851685132206, "mean_action_processing_ms": 0.638413878935238, "mean_env_wait_ms": 0.43484398755945347, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011129498481750488, "StateBufferConnector_ms": 0.006401777267456055, "ViewRequirementAgentConnector_ms": 0.267173171043396}, "num_episodes": 22, "episode_return_max": 201.09999999999914, "episode_return_min": -169.2000000000004, "episode_return_mean": 49.42299999999997, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 175.2459731548812, "num_env_steps_trained_throughput_per_sec": 175.2459731548812, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 21493.934, "restore_workers_time_ms": 0.018, "training_step_time_ms": 21493.87, "sample_time_ms": 3162.55, "learn_time_ms": 18306.062, "learn_throughput": 218.507, "synch_weights_time_ms": 19.908}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "3a355_00000", "date": "2024-08-13_01-39-43", "timestamp": 1723527583, "time_this_iter_s": 22.870855808258057, "time_total_s": 1791.4226467609406, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b50a6310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1791.4226467609406, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 86.26875000000001, "ram_util_percent": 83.46562499999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2219375957370238, "cur_kl_coeff": 4.8828125e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6736428911250735, "policy_loss": -0.0020929565870020754, "vf_loss": 0.675735517181259, "vf_explained_var": 0.0016611560311897721, "kl": 0.0067742371681459995, "entropy": 0.6113896450353047, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8851019171928918, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1702140037344877, "policy_loss": -0.0006055723929964991, "vf_loss": 1.17058275988493, "vf_explained_var": 0.012774897031683139, "kl": 0.008420038785831212, "entropy": 1.0003764051293569, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 201.09999999999914, "episode_reward_min": -138.40000000000109, "episode_reward_mean": 45.275999999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -240.40000000000043, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999988, "predator_policy": 124.0}, "policy_reward_mean": {"prey_policy": 12.097999999999997, "predator_policy": 10.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [149.59999999999934, 45.800000000000395, -20.49999999999971, 40.0000000000003, 40.0000000000003, 200.49999999999937, -34.0999999999996, 201.09999999999914, 80.59999999999971, 14.699999999999994, -79.90000000000083, 40.0000000000003, 80.99999999999909, 132.59999999999948, 153.6999999999989, 74.89999999999974, 40.0000000000003, 80.49999999999937, 43.60000000000035, 94.3999999999998, 125.49999999999889, 169.1999999999991, -18.09999999999949, 40.0000000000003, 54.400000000000404, 40.0000000000003, 42.700000000000365, 83.19999999999911, 151.1999999999986, 60.40000000000042, -27.899999999999835, 152.59999999999886, 38.800000000000296, -13.799999999999569, 13.599999999999923, 52.00000000000045, 55.4000000000004, 51.20000000000049, 32.20000000000016, -9.1999999999996, 95.2999999999982, 52.10000000000048, 75.0999999999997, 55.4000000000005, 40.0000000000003, 36.400000000000276, 29.100000000000307, 31.100000000000165, 59.80000000000051, -128.00000000000148, 46.00000000000034, 76.8999999999996, 11.400000000000048, 19.099999999999973, 83.49999999999903, -3.9999999999997313, -10.599999999999623, -5.199999999999756, 62.30000000000037, 24.300000000000068, 23.500000000000032, 40.0000000000003, 38.900000000000276, 65.20000000000041, 60.70000000000047, 65.1000000000003, 43.60000000000035, 62.70000000000044, -30.39999999999987, 40.0000000000003, 67.90000000000019, 97.59999999999849, 40.0000000000003, 9.700000000000033, 55.90000000000045, 30.10000000000016, -138.40000000000109, 40.0000000000003, 36.70000000000025, 15.899999999999926, 36.70000000000025, 23.50000000000005, 18.69999999999996, 32.1000000000002, 10.299999999999953, 40.1000000000003, 76.79999999999957, 30.100000000000147, 52.200000000000514, 42.000000000000334, 49.00000000000045, 58.00000000000051, 67.90000000000023, 25.500000000000078, 34.60000000000022, 40.0000000000003, 66.8000000000003, 40.0000000000003, -96.40000000000109, 93.09999999999839], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 110.59999999999987, 20.000000000000014, 18.8, 20.000000000000014, -95.50000000000054, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 177.5, 20.000000000000014, -103.9000000000008, -14.199999999999877, 181.09999999999988, 20.000000000000014, -36.999999999999915, 68.59999999999988, 20.000000000000014, -28.29999999999975, -208.90000000000046, 20.000000000000014, 20.000000000000014, 20.000000000000014, 122.59999999999951, -97.60000000000059, 128.29999999999984, -15.699999999999761, 34.40000000000021, 116.29999999999961, 39.50000000000024, 34.40000000000026, 20.000000000000014, 20.000000000000014, 60.50000000000022, 20.000000000000014, 20.000000000000014, 23.600000000000065, -164.8000000000001, 171.19999999999996, 31.700000000000212, 93.79999999999951, 97.69999999999976, 69.49999999999982, -7.299999999999891, -38.799999999999756, 20.000000000000014, 20.000000000000014, 27.20000000000008, 27.20000000000013, 20.000000000000014, 20.000000000000014, 56.00000000000021, -49.299999999999905, 20.000000000000014, 63.200000000000216, 75.79999999999941, 64.40000000000013, 20.000000000000014, 25.400000000000116, -103.90000000000032, 10.999999999999966, 40.400000000000105, 81.19999999999929, 28.100000000000147, -13.299999999999827, -78.70000000000087, 17.899999999999988, 20.000000000000014, -30.399999999999828, 20.000000000000014, 20.000000000000014, 13.399999999999968, 20.000000000000014, 38.900000000000254, 5.299999999999965, -5.1999999999999265, 25.400000000000112, -17.79999999999974, -9.399999999999855, 46.10000000000024, 42.200000000000216, 16.099999999999962, 20.000000000000014, 55.10000000000023, 20.000000000000014, 11.599999999999964, 39.80000000000025, 20.000000000000014, 20.000000000000014, 0.499999999999967, 17.899999999999988, 5.900000000000066, -17.799999999999876, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 39.80000000000025, -120.70000000000076, -91.30000000000072, 23.600000000000055, 7.3999999999999755, 43.40000000000025, 33.50000000000024, 20.000000000000014, -34.59999999999975, 20.000000000000014, -19.899999999999785, 11.899999999999975, 50.60000000000023, 20.000000000000014, -64.00000000000091, 20.000000000000014, -76.60000000000088, -95.50000000000082, 35.30000000000026, -33.39999999999984, 58.70000000000022, -28.29999999999975, -33.39999999999979, -11.499999999999833, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999984, 45.200000000000244, 20.000000000000014, 20.000000000000014, 31.70000000000022, -33.69999999999978, 66.79999999999997, 23.600000000000065, 20.000000000000014, 5.299999999999965, 40.4000000000002, -7.3000000000000504, -96.1000000000003, 20.000000000000014, 20.000000000000014, 47.900000000000226, 20.000000000000014, 20.000000000000014, 77.59999999999923, 20.000000000000014, 20.000000000000014, 30.800000000000196, -60.10000000000063, -15.999999999999774, 47.900000000000226, 20.000000000000014, 1.0999999999999617, -135.40000000000072, -127.00000000000043, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -91.30000000000084, 54.20000000000023, 13.699999999999966, 20.000000000000014, -11.499999999999847, 20.000000000000014, 31.700000000000212, -42.99999999999976, 38.000000000000256, -31.89999999999978, 20.000000000000014, -36.699999999999804, 30.800000000000196, -3.6999999999999584, 22.100000000000044, 49.70000000000023, 20.000000000000014, 1.0999999999999865, 29.90000000000018, 11.299999999999972, -15.699999999999754, 40.70000000000025, 20.000000000000014, 29.000000000000163, 20.000000000000014, 38.000000000000256, 26.300000000000114, 41.60000000000025, 30.800000000000196, -28.299999999999777, 24.50000000000008, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 47.90000000000024, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -240.40000000000043, 41.60000000000023, 51.500000000000206], "policy_predator_policy_reward": [19.0, 0.0, 0.0, 7.0, 48.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 25.0, 59.0, 0.0, 0.0, 23.0, 26.0, 0.0, 23.0, 70.0, 39.0, 0.0, 0.0, 0.0, 56.0, 20.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 88.0, 0.0, 0.0, 2.0, 0.0, 13.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 3.0, 0.0, 0.0, 0.0, 11.0, 15.0, 0.0, 65.0, 0.0, 0.0, 31.0, 24.0, 0.0, 29.0, 18.0, 0.0, 24.0, 0.0, 12.0, 0.0, 22.0, 0.0, 7.0, 0.0, 12.0, 18.0, 0.0, 0.0, 7.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 18.0, 0.0, 12.0, 29.0, 9.0, 1.0, 0.0, 0.0, 19.0, 65.0, 15.0, 0.0, 0.0, 0.0, 0.0, 26.0, 19.0, 0.0, 21.0, 0.0, 40.0, 0.0, 0.0, 46.0, 0.0, 55.0, 0.0, 37.0, 40.0, 46.0, 15.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 32.0, 0.0, 0.0, 0.0, 0.0, 17.0, 19.0, 54.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 24.0, 9.0, 0.0, 0.0, 124.0, 0.0, 0.0, 0.0, 3.0, 53.0, 0.0, 3.0, 0.0, 0.0, 15.0, 20.0, 10.0, 0.0, 26.0, 27.0, 0.0, 0.0, 13.0, 5.0, 0.0, 0.0, 9.0, 0.0, 11.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 124.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2816154366893568, "mean_inference_ms": 3.63148385711186, "mean_action_processing_ms": 0.6376098134936494, "mean_env_wait_ms": 0.43618766964690125, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008034825325012207, "StateBufferConnector_ms": 0.007159113883972168, "ViewRequirementAgentConnector_ms": 0.23226499557495117}, "num_episodes": 23, "episode_return_max": 201.09999999999914, "episode_return_min": -138.40000000000109, "episode_return_mean": 45.275999999999975, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 176.8775416857951, "num_env_steps_trained_throughput_per_sec": 176.8775416857951, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 21781.987, "restore_workers_time_ms": 0.018, "training_step_time_ms": 21781.924, "sample_time_ms": 3142.996, "learn_time_ms": 18612.537, "learn_throughput": 214.909, "synch_weights_time_ms": 20.63}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "3a355_00000", "date": "2024-08-13_01-40-06", "timestamp": 1723527606, "time_this_iter_s": 22.67153310775757, "time_total_s": 1814.0941798686981, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df8820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1814.0941798686981, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 85.275, "ram_util_percent": 83.48750000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.287311738602344, "cur_kl_coeff": 4.8828125e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6216916457133949, "policy_loss": -0.0013406647995074905, "vf_loss": 0.6230320891197869, "vf_explained_var": 0.001835289234837527, "kl": 0.004525346714290149, "entropy": 0.6096472057715926, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8989707334568261, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0566547887577187, "policy_loss": -0.004051392426389078, "vf_loss": 1.060292360525598, "vf_explained_var": 0.0024757592135636265, "kl": 0.014713605573790008, "entropy": 0.9503364995358482, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 169.1999999999991, "episode_reward_min": -342.89999999999657, "episode_reward_mean": 36.27300000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -246.70000000000041, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 171.19999999999996, "predator_policy": 127.0}, "policy_reward_mean": {"prey_policy": 8.18150000000002, "predator_policy": 9.955}, "custom_metrics": {}, "hist_stats": {"episode_reward": [43.60000000000035, 94.3999999999998, 125.49999999999889, 169.1999999999991, -18.09999999999949, 40.0000000000003, 54.400000000000404, 40.0000000000003, 42.700000000000365, 83.19999999999911, 151.1999999999986, 60.40000000000042, -27.899999999999835, 152.59999999999886, 38.800000000000296, -13.799999999999569, 13.599999999999923, 52.00000000000045, 55.4000000000004, 51.20000000000049, 32.20000000000016, -9.1999999999996, 95.2999999999982, 52.10000000000048, 75.0999999999997, 55.4000000000005, 40.0000000000003, 36.400000000000276, 29.100000000000307, 31.100000000000165, 59.80000000000051, -128.00000000000148, 46.00000000000034, 76.8999999999996, 11.400000000000048, 19.099999999999973, 83.49999999999903, -3.9999999999997313, -10.599999999999623, -5.199999999999756, 62.30000000000037, 24.300000000000068, 23.500000000000032, 40.0000000000003, 38.900000000000276, 65.20000000000041, 60.70000000000047, 65.1000000000003, 43.60000000000035, 62.70000000000044, -30.39999999999987, 40.0000000000003, 67.90000000000019, 97.59999999999849, 40.0000000000003, 9.700000000000033, 55.90000000000045, 30.10000000000016, -138.40000000000109, 40.0000000000003, 36.70000000000025, 15.899999999999926, 36.70000000000025, 23.50000000000005, 18.69999999999996, 32.1000000000002, 10.299999999999953, 40.1000000000003, 76.79999999999957, 30.100000000000147, 52.200000000000514, 42.000000000000334, 49.00000000000045, 58.00000000000051, 67.90000000000023, 25.500000000000078, 34.60000000000022, 40.0000000000003, 66.8000000000003, 40.0000000000003, -96.40000000000109, 93.09999999999839, -342.89999999999657, 60.700000000000536, 40.0000000000003, 40.0000000000003, 65.70000000000032, 78.69999999999943, 67.00000000000023, 17.799999999999972, 26.8000000000001, 2.9000000000002157, 38.90000000000028, 23.500000000000036, 40.0000000000003, -6.200000000000088, 43.900000000000375, 41.30000000000032, 56.20000000000048, 45.90000000000046], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 23.600000000000065, -164.8000000000001, 171.19999999999996, 31.700000000000212, 93.79999999999951, 97.69999999999976, 69.49999999999982, -7.299999999999891, -38.799999999999756, 20.000000000000014, 20.000000000000014, 27.20000000000008, 27.20000000000013, 20.000000000000014, 20.000000000000014, 56.00000000000021, -49.299999999999905, 20.000000000000014, 63.200000000000216, 75.79999999999941, 64.40000000000013, 20.000000000000014, 25.400000000000116, -103.90000000000032, 10.999999999999966, 40.400000000000105, 81.19999999999929, 28.100000000000147, -13.299999999999827, -78.70000000000087, 17.899999999999988, 20.000000000000014, -30.399999999999828, 20.000000000000014, 20.000000000000014, 13.399999999999968, 20.000000000000014, 38.900000000000254, 5.299999999999965, -5.1999999999999265, 25.400000000000112, -17.79999999999974, -9.399999999999855, 46.10000000000024, 42.200000000000216, 16.099999999999962, 20.000000000000014, 55.10000000000023, 20.000000000000014, 11.599999999999964, 39.80000000000025, 20.000000000000014, 20.000000000000014, 0.499999999999967, 17.899999999999988, 5.900000000000066, -17.799999999999876, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 39.80000000000025, -120.70000000000076, -91.30000000000072, 23.600000000000055, 7.3999999999999755, 43.40000000000025, 33.50000000000024, 20.000000000000014, -34.59999999999975, 20.000000000000014, -19.899999999999785, 11.899999999999975, 50.60000000000023, 20.000000000000014, -64.00000000000091, 20.000000000000014, -76.60000000000088, -95.50000000000082, 35.30000000000026, -33.39999999999984, 58.70000000000022, -28.29999999999975, -33.39999999999979, -11.499999999999833, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999984, 45.200000000000244, 20.000000000000014, 20.000000000000014, 31.70000000000022, -33.69999999999978, 66.79999999999997, 23.600000000000065, 20.000000000000014, 5.299999999999965, 40.4000000000002, -7.3000000000000504, -96.1000000000003, 20.000000000000014, 20.000000000000014, 47.900000000000226, 20.000000000000014, 20.000000000000014, 77.59999999999923, 20.000000000000014, 20.000000000000014, 30.800000000000196, -60.10000000000063, -15.999999999999774, 47.900000000000226, 20.000000000000014, 1.0999999999999617, -135.40000000000072, -127.00000000000043, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -91.30000000000084, 54.20000000000023, 13.699999999999966, 20.000000000000014, -11.499999999999847, 20.000000000000014, 31.700000000000212, -42.99999999999976, 38.000000000000256, -31.89999999999978, 20.000000000000014, -36.699999999999804, 30.800000000000196, -3.6999999999999584, 22.100000000000044, 49.70000000000023, 20.000000000000014, 1.0999999999999865, 29.90000000000018, 11.299999999999972, -15.699999999999754, 40.70000000000025, 20.000000000000014, 29.000000000000163, 20.000000000000014, 38.000000000000256, 26.300000000000114, 41.60000000000025, 30.800000000000196, -28.299999999999777, 24.50000000000008, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 47.90000000000024, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -240.40000000000043, 41.60000000000023, 51.500000000000206, -246.70000000000041, -236.20000000000044, 32.60000000000023, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 8.599999999999978, 46.10000000000022, 35.30000000000025, 43.400000000000226, 47.000000000000206, 20.000000000000014, -23.199999999999747, 20.000000000000014, 20.000000000000014, -14.199999999999795, 1.0999999999999865, -20.199999999999747, 20.000000000000014, 17.899999999999988, 20.000000000000014, -11.499999999999826, 20.000000000000014, 20.000000000000014, -32.500000000000014, -15.699999999999747, 24.800000000000097, -1.9, 14.299999999999969, 20.000000000000014, 36.20000000000024, 20.000000000000014, 31.700000000000237, 3.1999999999999686], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 88.0, 0.0, 0.0, 2.0, 0.0, 13.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 3.0, 0.0, 0.0, 0.0, 11.0, 15.0, 0.0, 65.0, 0.0, 0.0, 31.0, 24.0, 0.0, 29.0, 18.0, 0.0, 24.0, 0.0, 12.0, 0.0, 22.0, 0.0, 7.0, 0.0, 12.0, 18.0, 0.0, 0.0, 7.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 18.0, 0.0, 12.0, 29.0, 9.0, 1.0, 0.0, 0.0, 19.0, 65.0, 15.0, 0.0, 0.0, 0.0, 0.0, 26.0, 19.0, 0.0, 21.0, 0.0, 40.0, 0.0, 0.0, 46.0, 0.0, 55.0, 0.0, 37.0, 40.0, 46.0, 15.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 32.0, 0.0, 0.0, 0.0, 0.0, 17.0, 19.0, 54.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 24.0, 9.0, 0.0, 0.0, 124.0, 0.0, 0.0, 0.0, 3.0, 53.0, 0.0, 3.0, 0.0, 0.0, 15.0, 20.0, 10.0, 0.0, 26.0, 27.0, 0.0, 0.0, 13.0, 5.0, 0.0, 0.0, 9.0, 0.0, 11.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 124.0, 0.0, 0.0, 0.0, 13.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 21.0, 22.0, 0.0, 1.0, 0.0, 15.0, 0.0, 0.0, 0.0, 25.0, 17.0, 0.0, 21.0, 0.0, 7.0, 0.0, 0.0, 8.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2880311553535142, "mean_inference_ms": 3.648978196737644, "mean_action_processing_ms": 0.6350690217482002, "mean_env_wait_ms": 0.4368335367711394, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007459878921508789, "StateBufferConnector_ms": 0.0072057247161865234, "ViewRequirementAgentConnector_ms": 0.24165797233581543}, "num_episodes": 18, "episode_return_max": 169.1999999999991, "episode_return_min": -342.89999999999657, "episode_return_mean": 36.27300000000009, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 168.02666663141326, "num_env_steps_trained_throughput_per_sec": 168.02666663141326, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 22180.003, "restore_workers_time_ms": 0.018, "training_step_time_ms": 22179.939, "sample_time_ms": 3249.518, "learn_time_ms": 18903.773, "learn_throughput": 211.598, "synch_weights_time_ms": 20.786}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "3a355_00000", "date": "2024-08-13_01-40-30", "timestamp": 1723527630, "time_this_iter_s": 23.866535902023315, "time_total_s": 1837.9607157707214, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df6c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1837.9607157707214, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 84.85000000000001, "ram_util_percent": 83.42647058823528}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2964490656223562, "cur_kl_coeff": 2.44140625e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1975202295672958, "policy_loss": -0.0008333621117922049, "vf_loss": 1.1983535227873339, "vf_explained_var": 0.0008293309855082679, "kl": 0.0025834756935107024, "entropy": 0.4936264993337096, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7062156068663749, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5883631749127907, "policy_loss": -0.0008418233131388665, "vf_loss": 1.58895620725773, "vf_explained_var": -0.003553485428845441, "kl": 0.008846088693070612, "entropy": 0.9295304671481803, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 97.59999999999849, "episode_reward_min": -342.89999999999657, "episode_reward_mean": 28.113000000000152, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -292.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 77.59999999999923, "predator_policy": 164.0}, "policy_reward_mean": {"prey_policy": 3.486500000000033, "predator_policy": 10.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [55.4000000000004, 51.20000000000049, 32.20000000000016, -9.1999999999996, 95.2999999999982, 52.10000000000048, 75.0999999999997, 55.4000000000005, 40.0000000000003, 36.400000000000276, 29.100000000000307, 31.100000000000165, 59.80000000000051, -128.00000000000148, 46.00000000000034, 76.8999999999996, 11.400000000000048, 19.099999999999973, 83.49999999999903, -3.9999999999997313, -10.599999999999623, -5.199999999999756, 62.30000000000037, 24.300000000000068, 23.500000000000032, 40.0000000000003, 38.900000000000276, 65.20000000000041, 60.70000000000047, 65.1000000000003, 43.60000000000035, 62.70000000000044, -30.39999999999987, 40.0000000000003, 67.90000000000019, 97.59999999999849, 40.0000000000003, 9.700000000000033, 55.90000000000045, 30.10000000000016, -138.40000000000109, 40.0000000000003, 36.70000000000025, 15.899999999999926, 36.70000000000025, 23.50000000000005, 18.69999999999996, 32.1000000000002, 10.299999999999953, 40.1000000000003, 76.79999999999957, 30.100000000000147, 52.200000000000514, 42.000000000000334, 49.00000000000045, 58.00000000000051, 67.90000000000023, 25.500000000000078, 34.60000000000022, 40.0000000000003, 66.8000000000003, 40.0000000000003, -96.40000000000109, 93.09999999999839, -342.89999999999657, 60.700000000000536, 40.0000000000003, 40.0000000000003, 65.70000000000032, 78.69999999999943, 67.00000000000023, 17.799999999999972, 26.8000000000001, 2.9000000000002157, 38.90000000000028, 23.500000000000036, 40.0000000000003, -6.200000000000088, 43.900000000000375, 41.30000000000032, 56.20000000000048, 45.90000000000046, 55.300000000000516, 40.80000000000031, -76.9, 40.0000000000003, 43.60000000000035, 51.50000000000049, 33.3000000000002, 40.0000000000003, -115.80000000000024, -200.90000000000066, 34.50000000000022, 51.70000000000049, 62.50000000000047, 49.30000000000046, 38.900000000000276, 40.0000000000003, 58.00000000000051, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.399999999999968, 20.000000000000014, 38.900000000000254, 5.299999999999965, -5.1999999999999265, 25.400000000000112, -17.79999999999974, -9.399999999999855, 46.10000000000024, 42.200000000000216, 16.099999999999962, 20.000000000000014, 55.10000000000023, 20.000000000000014, 11.599999999999964, 39.80000000000025, 20.000000000000014, 20.000000000000014, 0.499999999999967, 17.899999999999988, 5.900000000000066, -17.799999999999876, 20.000000000000014, 1.0999999999999865, 20.000000000000014, 39.80000000000025, -120.70000000000076, -91.30000000000072, 23.600000000000055, 7.3999999999999755, 43.40000000000025, 33.50000000000024, 20.000000000000014, -34.59999999999975, 20.000000000000014, -19.899999999999785, 11.899999999999975, 50.60000000000023, 20.000000000000014, -64.00000000000091, 20.000000000000014, -76.60000000000088, -95.50000000000082, 35.30000000000026, -33.39999999999984, 58.70000000000022, -28.29999999999975, -33.39999999999979, -11.499999999999833, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999984, 45.200000000000244, 20.000000000000014, 20.000000000000014, 31.70000000000022, -33.69999999999978, 66.79999999999997, 23.600000000000065, 20.000000000000014, 5.299999999999965, 40.4000000000002, -7.3000000000000504, -96.1000000000003, 20.000000000000014, 20.000000000000014, 47.900000000000226, 20.000000000000014, 20.000000000000014, 77.59999999999923, 20.000000000000014, 20.000000000000014, 30.800000000000196, -60.10000000000063, -15.999999999999774, 47.900000000000226, 20.000000000000014, 1.0999999999999617, -135.40000000000072, -127.00000000000043, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -91.30000000000084, 54.20000000000023, 13.699999999999966, 20.000000000000014, -11.499999999999847, 20.000000000000014, 31.700000000000212, -42.99999999999976, 38.000000000000256, -31.89999999999978, 20.000000000000014, -36.699999999999804, 30.800000000000196, -3.6999999999999584, 22.100000000000044, 49.70000000000023, 20.000000000000014, 1.0999999999999865, 29.90000000000018, 11.299999999999972, -15.699999999999754, 40.70000000000025, 20.000000000000014, 29.000000000000163, 20.000000000000014, 38.000000000000256, 26.300000000000114, 41.60000000000025, 30.800000000000196, -28.299999999999777, 24.50000000000008, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 47.90000000000024, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -240.40000000000043, 41.60000000000023, 51.500000000000206, -246.70000000000041, -236.20000000000044, 32.60000000000023, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 8.599999999999978, 46.10000000000022, 35.30000000000025, 43.400000000000226, 47.000000000000206, 20.000000000000014, -23.199999999999747, 20.000000000000014, 20.000000000000014, -14.199999999999795, 1.0999999999999865, -20.199999999999747, 20.000000000000014, 17.899999999999988, 20.000000000000014, -11.499999999999826, 20.000000000000014, 20.000000000000014, -32.500000000000014, -15.699999999999747, 24.800000000000097, -1.9, 14.299999999999969, 20.000000000000014, 36.20000000000024, 20.000000000000014, 31.700000000000237, 3.1999999999999686, 20.000000000000014, 35.30000000000026, 20.000000000000014, 15.799999999999962, -108.39999999999995, -53.499999999999766, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, 30.500000000000192, 20.000000000000014, -3.099999999999958, 25.400000000000098, 20.000000000000014, 20.000000000000014, 28.100000000000147, -292.9, -194.20000000000056, -252.7000000000001, 9.499999999999964, 20.000000000000014, 31.700000000000212, 20.000000000000014, 20.000000000000014, 42.50000000000023, 20.000000000000014, 26.300000000000118, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.000000000000256, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 22.0, 0.0, 7.0, 0.0, 12.0, 18.0, 0.0, 0.0, 7.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 18.0, 0.0, 12.0, 29.0, 9.0, 1.0, 0.0, 0.0, 19.0, 65.0, 15.0, 0.0, 0.0, 0.0, 0.0, 26.0, 19.0, 0.0, 21.0, 0.0, 40.0, 0.0, 0.0, 46.0, 0.0, 55.0, 0.0, 37.0, 40.0, 46.0, 15.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 32.0, 0.0, 0.0, 0.0, 0.0, 17.0, 19.0, 54.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 24.0, 9.0, 0.0, 0.0, 124.0, 0.0, 0.0, 0.0, 3.0, 53.0, 0.0, 3.0, 0.0, 0.0, 15.0, 20.0, 10.0, 0.0, 26.0, 27.0, 0.0, 0.0, 13.0, 5.0, 0.0, 0.0, 9.0, 0.0, 11.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 124.0, 0.0, 0.0, 0.0, 13.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 21.0, 22.0, 0.0, 1.0, 0.0, 15.0, 0.0, 0.0, 0.0, 25.0, 17.0, 0.0, 21.0, 0.0, 7.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 5.0, 0.0, 83.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 0.0, 0.0, 149.0, 0.0, 164.0, 82.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2947225231419355, "mean_inference_ms": 3.6652118028316414, "mean_action_processing_ms": 0.6344270718192611, "mean_env_wait_ms": 0.4381888881158869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007503032684326172, "StateBufferConnector_ms": 0.007326364517211914, "ViewRequirementAgentConnector_ms": 0.24537670612335205}, "num_episodes": 18, "episode_return_max": 97.59999999999849, "episode_return_min": -342.89999999999657, "episode_return_mean": 28.113000000000152, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 3.9897380625693017, "num_env_steps_trained_throughput_per_sec": 3.9897380625693017, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 120382.838, "restore_workers_time_ms": 0.018, "training_step_time_ms": 120382.774, "sample_time_ms": 3358.134, "learn_time_ms": 116998.027, "learn_throughput": 34.189, "synch_weights_time_ms": 20.734}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "3a355_00000", "date": "2024-08-13_01-57-12", "timestamp": 1723528632, "time_this_iter_s": 1002.6566979885101, "time_total_s": 2840.6174137592316, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b50974c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2840.6174137592316, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 92.12093023255814, "ram_util_percent": 83.5860465116279}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2090857093010551, "cur_kl_coeff": 1.220703125e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9153155155125119, "policy_loss": -0.001740831756599681, "vf_loss": 0.9170562955358672, "vf_explained_var": 0.0007185882992214626, "kl": 0.004475345564669914, "entropy": 0.5024459050130592, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8108621528717103, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0672921426786435, "policy_loss": -0.0036383952707712535, "vf_loss": 1.070285053141218, "vf_explained_var": -0.0019918328239804223, "kl": 0.022950508285002377, "entropy": 1.005496698207956, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 97.59999999999849, "episode_reward_min": -342.89999999999657, "episode_reward_mean": 21.683000000000167, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -378.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 77.59999999999923, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": -1.7484999999999655, "predator_policy": 12.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [83.49999999999903, -3.9999999999997313, -10.599999999999623, -5.199999999999756, 62.30000000000037, 24.300000000000068, 23.500000000000032, 40.0000000000003, 38.900000000000276, 65.20000000000041, 60.70000000000047, 65.1000000000003, 43.60000000000035, 62.70000000000044, -30.39999999999987, 40.0000000000003, 67.90000000000019, 97.59999999999849, 40.0000000000003, 9.700000000000033, 55.90000000000045, 30.10000000000016, -138.40000000000109, 40.0000000000003, 36.70000000000025, 15.899999999999926, 36.70000000000025, 23.50000000000005, 18.69999999999996, 32.1000000000002, 10.299999999999953, 40.1000000000003, 76.79999999999957, 30.100000000000147, 52.200000000000514, 42.000000000000334, 49.00000000000045, 58.00000000000051, 67.90000000000023, 25.500000000000078, 34.60000000000022, 40.0000000000003, 66.8000000000003, 40.0000000000003, -96.40000000000109, 93.09999999999839, -342.89999999999657, 60.700000000000536, 40.0000000000003, 40.0000000000003, 65.70000000000032, 78.69999999999943, 67.00000000000023, 17.799999999999972, 26.8000000000001, 2.9000000000002157, 38.90000000000028, 23.500000000000036, 40.0000000000003, -6.200000000000088, 43.900000000000375, 41.30000000000032, 56.20000000000048, 45.90000000000046, 55.300000000000516, 40.80000000000031, -76.9, 40.0000000000003, 43.60000000000035, 51.50000000000049, 33.3000000000002, 40.0000000000003, -115.80000000000024, -200.90000000000066, 34.50000000000022, 51.70000000000049, 62.50000000000047, 49.30000000000046, 38.900000000000276, 40.0000000000003, 58.00000000000051, 40.0000000000003, 53.50000000000052, 40.0000000000003, 26.30000000000009, 40.0000000000003, -3.3999999999997024, 48.10000000000043, -29.299999999999592, 40.90000000000031, 40.0000000000003, -101.40000000000076, -191.70000000000093, 65.20000000000041, -169.90000000000052, 11.39999999999992, 7.000000000000007, 40.0000000000003, 28.700000000000145, 40.90000000000031], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.899999999999975, 50.60000000000023, 20.000000000000014, -64.00000000000091, 20.000000000000014, -76.60000000000088, -95.50000000000082, 35.30000000000026, -33.39999999999984, 58.70000000000022, -28.29999999999975, -33.39999999999979, -11.499999999999833, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999984, 45.200000000000244, 20.000000000000014, 20.000000000000014, 31.70000000000022, -33.69999999999978, 66.79999999999997, 23.600000000000065, 20.000000000000014, 5.299999999999965, 40.4000000000002, -7.3000000000000504, -96.1000000000003, 20.000000000000014, 20.000000000000014, 47.900000000000226, 20.000000000000014, 20.000000000000014, 77.59999999999923, 20.000000000000014, 20.000000000000014, 30.800000000000196, -60.10000000000063, -15.999999999999774, 47.900000000000226, 20.000000000000014, 1.0999999999999617, -135.40000000000072, -127.00000000000043, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -91.30000000000084, 54.20000000000023, 13.699999999999966, 20.000000000000014, -11.499999999999847, 20.000000000000014, 31.700000000000212, -42.99999999999976, 38.000000000000256, -31.89999999999978, 20.000000000000014, -36.699999999999804, 30.800000000000196, -3.6999999999999584, 22.100000000000044, 49.70000000000023, 20.000000000000014, 1.0999999999999865, 29.90000000000018, 11.299999999999972, -15.699999999999754, 40.70000000000025, 20.000000000000014, 29.000000000000163, 20.000000000000014, 38.000000000000256, 26.300000000000114, 41.60000000000025, 30.800000000000196, -28.299999999999777, 24.50000000000008, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 47.90000000000024, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -240.40000000000043, 41.60000000000023, 51.500000000000206, -246.70000000000041, -236.20000000000044, 32.60000000000023, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 8.599999999999978, 46.10000000000022, 35.30000000000025, 43.400000000000226, 47.000000000000206, 20.000000000000014, -23.199999999999747, 20.000000000000014, 20.000000000000014, -14.199999999999795, 1.0999999999999865, -20.199999999999747, 20.000000000000014, 17.899999999999988, 20.000000000000014, -11.499999999999826, 20.000000000000014, 20.000000000000014, -32.500000000000014, -15.699999999999747, 24.800000000000097, -1.9, 14.299999999999969, 20.000000000000014, 36.20000000000024, 20.000000000000014, 31.700000000000237, 3.1999999999999686, 20.000000000000014, 35.30000000000026, 20.000000000000014, 15.799999999999962, -108.39999999999995, -53.499999999999766, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, 30.500000000000192, 20.000000000000014, -3.099999999999958, 25.400000000000098, 20.000000000000014, 20.000000000000014, 28.100000000000147, -292.9, -194.20000000000056, -252.7000000000001, 9.499999999999964, 20.000000000000014, 31.700000000000212, 20.000000000000014, 20.000000000000014, 42.50000000000023, 20.000000000000014, 26.300000000000118, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.000000000000256, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000024, 20.000000000000014, 20.000000000000014, -12.699999999999815, 20.000000000000014, 20.000000000000014, 20.000000000000014, 4.099999999999966, -32.49999999999975, 28.100000000000147, 20.000000000000014, 20.000000000000014, -112.3000000000007, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.000000000000014, -261.3999999999991, 20.000000000000014, -34.59999999999982, -318.10000000000025, 20.000000000000014, 45.200000000000244, -378.7, -5.200000000000051, -34.599999999999866, 20.000000000000014, -42.99999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -16.299999999999784, 20.90000000000003, 20.000000000000014], "policy_predator_policy_reward": [21.0, 0.0, 40.0, 0.0, 0.0, 46.0, 0.0, 55.0, 0.0, 37.0, 40.0, 46.0, 15.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 9.0, 32.0, 0.0, 0.0, 0.0, 0.0, 17.0, 19.0, 54.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 24.0, 9.0, 0.0, 0.0, 124.0, 0.0, 0.0, 0.0, 3.0, 53.0, 0.0, 3.0, 0.0, 0.0, 15.0, 20.0, 10.0, 0.0, 26.0, 27.0, 0.0, 0.0, 13.0, 5.0, 0.0, 0.0, 9.0, 0.0, 11.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 124.0, 0.0, 0.0, 0.0, 13.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 21.0, 22.0, 0.0, 1.0, 0.0, 15.0, 0.0, 0.0, 0.0, 25.0, 17.0, 0.0, 21.0, 0.0, 7.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 5.0, 0.0, 83.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 0.0, 0.0, 149.0, 0.0, 164.0, 82.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 140.0, 0.0, 161.0, 0.0, 0.0, 29.0, 185.0, 26.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.301135085943541, "mean_inference_ms": 3.6784294926772634, "mean_action_processing_ms": 0.6335009829277356, "mean_env_wait_ms": 0.43919825097459464, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0065566301345825195, "StateBufferConnector_ms": 0.009752869606018066, "ViewRequirementAgentConnector_ms": 0.2450122833251953}, "num_episodes": 18, "episode_return_max": 97.59999999999849, "episode_return_min": -342.89999999999657, "episode_return_mean": 21.683000000000167, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 211.40074571071935, "num_env_steps_trained_throughput_per_sec": 211.40074571071935, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 120400.275, "restore_workers_time_ms": 0.016, "training_step_time_ms": 120400.216, "sample_time_ms": 3408.86, "learn_time_ms": 116966.014, "learn_throughput": 34.198, "synch_weights_time_ms": 19.9}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "3a355_00000", "date": "2024-08-13_01-57-32", "timestamp": 1723528652, "time_this_iter_s": 19.001474142074585, "time_total_s": 2859.618887901306, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df6820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 2859.618887901306, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 86.75555555555556, "ram_util_percent": 83.52592592592592}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3581218430841411, "cur_kl_coeff": 6.103515625e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.39475174473707, "policy_loss": -0.002298512097655071, "vf_loss": 3.397050253676359, "vf_explained_var": 0.0011709617243872749, "kl": 0.0038811349050555024, "entropy": 0.4063353842528409, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7777672726877782, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5335098889138963, "policy_loss": -0.0010499814717424294, "vf_loss": 3.5343429975408727, "vf_explained_var": 0.0007564458582136366, "kl": 0.00514068754861772, "entropy": 1.0021666324327863, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 93.09999999999839, "episode_reward_min": -342.89999999999657, "episode_reward_mean": 9.567000000000169, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 54.20000000000023, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": -12.521499999999953, "predator_policy": 17.305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-138.40000000000109, 40.0000000000003, 36.70000000000025, 15.899999999999926, 36.70000000000025, 23.50000000000005, 18.69999999999996, 32.1000000000002, 10.299999999999953, 40.1000000000003, 76.79999999999957, 30.100000000000147, 52.200000000000514, 42.000000000000334, 49.00000000000045, 58.00000000000051, 67.90000000000023, 25.500000000000078, 34.60000000000022, 40.0000000000003, 66.8000000000003, 40.0000000000003, -96.40000000000109, 93.09999999999839, -342.89999999999657, 60.700000000000536, 40.0000000000003, 40.0000000000003, 65.70000000000032, 78.69999999999943, 67.00000000000023, 17.799999999999972, 26.8000000000001, 2.9000000000002157, 38.90000000000028, 23.500000000000036, 40.0000000000003, -6.200000000000088, 43.900000000000375, 41.30000000000032, 56.20000000000048, 45.90000000000046, 55.300000000000516, 40.80000000000031, -76.9, 40.0000000000003, 43.60000000000035, 51.50000000000049, 33.3000000000002, 40.0000000000003, -115.80000000000024, -200.90000000000066, 34.50000000000022, 51.70000000000049, 62.50000000000047, 49.30000000000046, 38.900000000000276, 40.0000000000003, 58.00000000000051, 40.0000000000003, 53.50000000000052, 40.0000000000003, 26.30000000000009, 40.0000000000003, -3.3999999999997024, 48.10000000000043, -29.299999999999592, 40.90000000000031, 40.0000000000003, -101.40000000000076, -191.70000000000093, 65.20000000000041, -169.90000000000052, 11.39999999999992, 7.000000000000007, 40.0000000000003, 28.700000000000145, 40.90000000000031, 24.60000000000005, 9.200000000000063, -227.60000000000002, 55.40000000000049, -13.899999999999826, 52.60000000000051, -24.799999999999635, 6.900000000000114, -134.80000000000038, 8.300000000000074, -173.60000000000034, -159.90000000000055, -0.39999999999998037, 42.40000000000046, 24.100000000000385, -42.299999999999834, 40.0000000000003, 40.0000000000003, 10.300000000000232, 40.0000000000003, 40.0000000000003, 32.700000000000195], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-135.40000000000072, -127.00000000000043, 20.000000000000014, 20.000000000000014, 13.699999999999964, 20.000000000000014, -91.30000000000084, 54.20000000000023, 13.699999999999966, 20.000000000000014, -11.499999999999847, 20.000000000000014, 31.700000000000212, -42.99999999999976, 38.000000000000256, -31.89999999999978, 20.000000000000014, -36.699999999999804, 30.800000000000196, -3.6999999999999584, 22.100000000000044, 49.70000000000023, 20.000000000000014, 1.0999999999999865, 29.90000000000018, 11.299999999999972, -15.699999999999754, 40.70000000000025, 20.000000000000014, 29.000000000000163, 20.000000000000014, 38.000000000000256, 26.300000000000114, 41.60000000000025, 30.800000000000196, -28.299999999999777, 24.50000000000008, 1.0999999999999865, 20.000000000000014, 20.000000000000014, 47.90000000000024, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -240.40000000000043, 41.60000000000023, 51.500000000000206, -246.70000000000041, -236.20000000000044, 32.60000000000023, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 8.599999999999978, 46.10000000000022, 35.30000000000025, 43.400000000000226, 47.000000000000206, 20.000000000000014, -23.199999999999747, 20.000000000000014, 20.000000000000014, -14.199999999999795, 1.0999999999999865, -20.199999999999747, 20.000000000000014, 17.899999999999988, 20.000000000000014, -11.499999999999826, 20.000000000000014, 20.000000000000014, -32.500000000000014, -15.699999999999747, 24.800000000000097, -1.9, 14.299999999999969, 20.000000000000014, 36.20000000000024, 20.000000000000014, 31.700000000000237, 3.1999999999999686, 20.000000000000014, 35.30000000000026, 20.000000000000014, 15.799999999999962, -108.39999999999995, -53.499999999999766, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, 30.500000000000192, 20.000000000000014, -3.099999999999958, 25.400000000000098, 20.000000000000014, 20.000000000000014, 28.100000000000147, -292.9, -194.20000000000056, -252.7000000000001, 9.499999999999964, 20.000000000000014, 31.700000000000212, 20.000000000000014, 20.000000000000014, 42.50000000000023, 20.000000000000014, 26.300000000000118, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.000000000000256, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000024, 20.000000000000014, 20.000000000000014, -12.699999999999815, 20.000000000000014, 20.000000000000014, 20.000000000000014, 4.099999999999966, -32.49999999999975, 28.100000000000147, 20.000000000000014, 20.000000000000014, -112.3000000000007, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.000000000000014, -261.3999999999991, 20.000000000000014, -34.59999999999982, -318.10000000000025, 20.000000000000014, 45.200000000000244, -378.7, -5.200000000000051, -34.599999999999866, 20.000000000000014, -42.99999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -16.299999999999784, 20.90000000000003, 20.000000000000014, 20.000000000000014, -9.399999999999855, -38.79999999999976, 20.000000000000014, -267.7, -208.90000000000003, 37.10000000000024, 5.299999999999972, 20.000000000000014, -82.90000000000003, 32.60000000000023, 20.000000000000014, -116.80000000000064, 20.000000000000014, -1.0000000000000098, -3.0999999999999828, -360.1, 44.300000000000246, -21.999999999999766, -6.699999999999921, -208.90000000000003, -159.70000000000064, -387.4, 33.50000000000024, -26.79999999999997, -13.599999999999786, 20.000000000000014, -1.5999999999998102, -20.499999999999964, 23.600000000000065, 14.299999999999969, -328.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.399999999999764, -10.299999999999777, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.90000000000018, -20.19999999999976], "policy_predator_policy_reward": [0.0, 124.0, 0.0, 0.0, 0.0, 3.0, 53.0, 0.0, 3.0, 0.0, 0.0, 15.0, 20.0, 10.0, 0.0, 26.0, 27.0, 0.0, 0.0, 13.0, 5.0, 0.0, 0.0, 9.0, 0.0, 11.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 9.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 124.0, 0.0, 0.0, 0.0, 13.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 21.0, 22.0, 0.0, 1.0, 0.0, 15.0, 0.0, 0.0, 0.0, 25.0, 17.0, 0.0, 21.0, 0.0, 7.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 5.0, 0.0, 83.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 0.0, 0.0, 149.0, 0.0, 164.0, 82.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 140.0, 0.0, 161.0, 0.0, 0.0, 29.0, 185.0, 26.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 14.0, 0.0, 28.0, 0.0, 137.0, 112.0, 0.0, 13.0, 0.0, 49.0, 0.0, 0.0, 0.0, 72.0, 0.0, 11.0, 179.0, 2.0, 17.0, 20.0, 61.0, 134.0, 0.0, 194.0, 0.0, 40.0, 0.0, 24.0, 0.0, 21.0, 172.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3092225610059431, "mean_inference_ms": 3.698578904711428, "mean_action_processing_ms": 0.6325995472661917, "mean_env_wait_ms": 0.44115939221241846, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005849957466125488, "StateBufferConnector_ms": 0.009344816207885742, "ViewRequirementAgentConnector_ms": 0.24580872058868408}, "num_episodes": 22, "episode_return_max": 93.09999999999839, "episode_return_min": -342.89999999999657, "episode_return_mean": 9.567000000000169, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.2308171674573885, "num_env_steps_trained_throughput_per_sec": 4.2308171674573885, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 213022.709, "restore_workers_time_ms": 0.016, "training_step_time_ms": 213022.65, "sample_time_ms": 3480.504, "learn_time_ms": 209512.277, "learn_throughput": 19.092, "synch_weights_time_ms": 24.64}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "3a355_00000", "date": "2024-08-13_02-13-17", "timestamp": 1723529597, "time_this_iter_s": 945.7597689628601, "time_total_s": 3805.3786568641663, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3ddff70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3805.3786568641663, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 89.2578947368421, "ram_util_percent": 83.51052631578948}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.41751331538947484, "cur_kl_coeff": 3.0517578125e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.090779778187867, "policy_loss": -0.002529252516401429, "vf_loss": 4.093309028691085, "vf_explained_var": 0.002220737145691322, "kl": 0.0035775201657291824, "entropy": 0.40840126006376176, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8042793739173147, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.543642354642273, "policy_loss": -0.0012809296259311614, "vf_loss": 4.5444221713555555, "vf_explained_var": 0.0025369051272276216, "kl": 0.01187851942992325, "entropy": 0.9461760164884032, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 93.09999999999839, "episode_reward_min": -446.69999999999993, "episode_reward_mean": -10.896999999999839, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 51.500000000000234, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -32.01849999999996, "predator_policy": 26.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [93.09999999999839, -342.89999999999657, 60.700000000000536, 40.0000000000003, 40.0000000000003, 65.70000000000032, 78.69999999999943, 67.00000000000023, 17.799999999999972, 26.8000000000001, 2.9000000000002157, 38.90000000000028, 23.500000000000036, 40.0000000000003, -6.200000000000088, 43.900000000000375, 41.30000000000032, 56.20000000000048, 45.90000000000046, 55.300000000000516, 40.80000000000031, -76.9, 40.0000000000003, 43.60000000000035, 51.50000000000049, 33.3000000000002, 40.0000000000003, -115.80000000000024, -200.90000000000066, 34.50000000000022, 51.70000000000049, 62.50000000000047, 49.30000000000046, 38.900000000000276, 40.0000000000003, 58.00000000000051, 40.0000000000003, 53.50000000000052, 40.0000000000003, 26.30000000000009, 40.0000000000003, -3.3999999999997024, 48.10000000000043, -29.299999999999592, 40.90000000000031, 40.0000000000003, -101.40000000000076, -191.70000000000093, 65.20000000000041, -169.90000000000052, 11.39999999999992, 7.000000000000007, 40.0000000000003, 28.700000000000145, 40.90000000000031, 24.60000000000005, 9.200000000000063, -227.60000000000002, 55.40000000000049, -13.899999999999826, 52.60000000000051, -24.799999999999635, 6.900000000000114, -134.80000000000038, 8.300000000000074, -173.60000000000034, -159.90000000000055, -0.39999999999998037, 42.40000000000046, 24.100000000000385, -42.299999999999834, 40.0000000000003, 40.0000000000003, 10.300000000000232, 40.0000000000003, 40.0000000000003, 32.700000000000195, 27.70000000000012, -90.09999999999998, -230.50000000000063, -172.10000000000062, 1.400000000000396, -102.99999999999997, -11.499999999999854, -306.5, -20.500000000000043, 40.0000000000003, -42.499999999999865, 56.3000000000005, 40.0000000000003, 74.69999999999966, 58.60000000000042, -19.399999999999835, 34.40000000000022, -108.500000000001, -37.69999999999978, 34.50000000000023, 40.0000000000003, -446.69999999999993, -262.89999999999986], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [41.60000000000023, 51.500000000000206, -246.70000000000041, -236.20000000000044, 32.60000000000023, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 8.599999999999978, 46.10000000000022, 35.30000000000025, 43.400000000000226, 47.000000000000206, 20.000000000000014, -23.199999999999747, 20.000000000000014, 20.000000000000014, -14.199999999999795, 1.0999999999999865, -20.199999999999747, 20.000000000000014, 17.899999999999988, 20.000000000000014, -11.499999999999826, 20.000000000000014, 20.000000000000014, -32.500000000000014, -15.699999999999747, 24.800000000000097, -1.9, 14.299999999999969, 20.000000000000014, 36.20000000000024, 20.000000000000014, 31.700000000000237, 3.1999999999999686, 20.000000000000014, 35.30000000000026, 20.000000000000014, 15.799999999999962, -108.39999999999995, -53.499999999999766, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, 30.500000000000192, 20.000000000000014, -3.099999999999958, 25.400000000000098, 20.000000000000014, 20.000000000000014, 28.100000000000147, -292.9, -194.20000000000056, -252.7000000000001, 9.499999999999964, 20.000000000000014, 31.700000000000212, 20.000000000000014, 20.000000000000014, 42.50000000000023, 20.000000000000014, 26.300000000000118, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.000000000000256, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000024, 20.000000000000014, 20.000000000000014, -12.699999999999815, 20.000000000000014, 20.000000000000014, 20.000000000000014, 4.099999999999966, -32.49999999999975, 28.100000000000147, 20.000000000000014, 20.000000000000014, -112.3000000000007, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.000000000000014, -261.3999999999991, 20.000000000000014, -34.59999999999982, -318.10000000000025, 20.000000000000014, 45.200000000000244, -378.7, -5.200000000000051, -34.599999999999866, 20.000000000000014, -42.99999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -16.299999999999784, 20.90000000000003, 20.000000000000014, 20.000000000000014, -9.399999999999855, -38.79999999999976, 20.000000000000014, -267.7, -208.90000000000003, 37.10000000000024, 5.299999999999972, 20.000000000000014, -82.90000000000003, 32.60000000000023, 20.000000000000014, -116.80000000000064, 20.000000000000014, -1.0000000000000098, -3.0999999999999828, -360.1, 44.300000000000246, -21.999999999999766, -6.699999999999921, -208.90000000000003, -159.70000000000064, -387.4, 33.50000000000024, -26.79999999999997, -13.599999999999786, 20.000000000000014, -1.5999999999998102, -20.499999999999964, 23.600000000000065, 14.299999999999969, -328.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.399999999999764, -10.299999999999777, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.90000000000018, -20.19999999999976, 30.800000000000196, -24.099999999999746, -278.2, 46.10000000000024, -106.30000000000064, -305.2, 17.899999999999988, -385.0, -76.59999999999984, 20.000000000000014, 20.000000000000014, -253.00000000000034, 20.000000000000014, -350.5, -303.40000000000026, -318.1, 26.300000000000114, -122.79999999999981, 20.000000000000014, 20.000000000000014, -70.30000000000004, -47.19999999999979, 20.000000000000014, 32.300000000000246, 20.000000000000014, 20.000000000000014, 50.0000000000002, 13.69999999999997, 23.600000000000083, 20.000000000000014, -93.40000000000003, 20.000000000000014, -4.599999999999971, 20.000000000000014, -5.200000000000051, -238.3000000000004, -203.1999999999999, 51.500000000000234, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, -400.0, -246.70000000000002, -313.9, -225.99999999999991], "policy_predator_policy_reward": [0.0, 0.0, 13.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 21.0, 22.0, 0.0, 1.0, 0.0, 15.0, 0.0, 0.0, 0.0, 25.0, 17.0, 0.0, 21.0, 0.0, 7.0, 0.0, 0.0, 8.0, 3.0, 0.0, 0.0, 5.0, 0.0, 83.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 0.0, 0.0, 149.0, 0.0, 164.0, 82.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 140.0, 0.0, 161.0, 0.0, 0.0, 29.0, 185.0, 26.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 14.0, 0.0, 28.0, 0.0, 137.0, 112.0, 0.0, 13.0, 0.0, 49.0, 0.0, 0.0, 0.0, 72.0, 0.0, 11.0, 179.0, 2.0, 17.0, 20.0, 61.0, 134.0, 0.0, 194.0, 0.0, 40.0, 0.0, 24.0, 0.0, 21.0, 172.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 21.0, 142.0, 0.0, 181.0, 0.0, 195.0, 0.0, 58.0, 0.0, 130.0, 0.0, 181.0, 138.0, 199.0, 116.0, 55.0, 21.0, 0.0, 0.0, 43.0, 32.0, 4.0, 0.0, 0.0, 0.0, 3.0, 8.0, 15.0, 0.0, 54.0, 0.0, 0.0, 19.0, 12.0, 123.0, 114.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 200.0, 118.0, 159.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.32600948956025, "mean_inference_ms": 3.7391531691385893, "mean_action_processing_ms": 0.6357559235836078, "mean_env_wait_ms": 0.44576570603944377, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00993037223815918, "StateBufferConnector_ms": 0.019057154655456543, "ViewRequirementAgentConnector_ms": 0.3331923484802246}, "num_episodes": 23, "episode_return_max": 93.09999999999839, "episode_return_min": -446.69999999999993, "episode_return_mean": -10.896999999999839, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 208.312219803526, "num_env_steps_trained_throughput_per_sec": 208.312219803526, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 212640.843, "restore_workers_time_ms": 0.028, "training_step_time_ms": 212640.764, "sample_time_ms": 3612.456, "learn_time_ms": 208998.596, "learn_throughput": 19.139, "synch_weights_time_ms": 24.364}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "3a355_00000", "date": "2024-08-13_02-13-37", "timestamp": 1723529617, "time_this_iter_s": 19.27966284751892, "time_total_s": 3824.658319711685, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b506b790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3824.658319711685, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 90.45714285714284, "ram_util_percent": 83.72857142857143}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4204354820211255, "cur_kl_coeff": 1.52587890625e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.783679544105732, "policy_loss": -0.0016545033094685071, "vf_loss": 3.7853340475647537, "vf_explained_var": 0.0033345318660534247, "kl": 0.0025527128961740013, "entropy": 0.4019118365787324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8724202668658956, "cur_kl_coeff": 0.0421875, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.493256341969525, "policy_loss": -0.0024080621793117155, "vf_loss": 4.495546695164272, "vf_explained_var": -0.0036713148551012474, "kl": 0.002789866448647762, "entropy": 0.9801171205031178, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 74.69999999999966, "episode_reward_min": -446.69999999999993, "episode_reward_mean": -30.867999999999885, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 51.500000000000234, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -50.40399999999999, "predator_policy": 34.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.90000000000046, 55.300000000000516, 40.80000000000031, -76.9, 40.0000000000003, 43.60000000000035, 51.50000000000049, 33.3000000000002, 40.0000000000003, -115.80000000000024, -200.90000000000066, 34.50000000000022, 51.70000000000049, 62.50000000000047, 49.30000000000046, 38.900000000000276, 40.0000000000003, 58.00000000000051, 40.0000000000003, 53.50000000000052, 40.0000000000003, 26.30000000000009, 40.0000000000003, -3.3999999999997024, 48.10000000000043, -29.299999999999592, 40.90000000000031, 40.0000000000003, -101.40000000000076, -191.70000000000093, 65.20000000000041, -169.90000000000052, 11.39999999999992, 7.000000000000007, 40.0000000000003, 28.700000000000145, 40.90000000000031, 24.60000000000005, 9.200000000000063, -227.60000000000002, 55.40000000000049, -13.899999999999826, 52.60000000000051, -24.799999999999635, 6.900000000000114, -134.80000000000038, 8.300000000000074, -173.60000000000034, -159.90000000000055, -0.39999999999998037, 42.40000000000046, 24.100000000000385, -42.299999999999834, 40.0000000000003, 40.0000000000003, 10.300000000000232, 40.0000000000003, 40.0000000000003, 32.700000000000195, 27.70000000000012, -90.09999999999998, -230.50000000000063, -172.10000000000062, 1.400000000000396, -102.99999999999997, -11.499999999999854, -306.5, -20.500000000000043, 40.0000000000003, -42.499999999999865, 56.3000000000005, 40.0000000000003, 74.69999999999966, 58.60000000000042, -19.399999999999835, 34.40000000000022, -108.500000000001, -37.69999999999978, 34.50000000000023, 40.0000000000003, -446.69999999999993, -262.89999999999986, -129.4000000000003, -33.99999999999978, -109.49999999999966, -72.2000000000007, -318.3999999999998, -145.90000000000035, 64.30000000000048, 40.0000000000003, 40.0000000000003, -122.80000000000032, -116.30000000000018, -296.5999999999998, 16.899999999999974, -343.4000000000001, -49.50000000000002, -57.50000000000015, 32.800000000000196, -8.199999999999747], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [31.700000000000237, 3.1999999999999686, 20.000000000000014, 35.30000000000026, 20.000000000000014, 15.799999999999962, -108.39999999999995, -53.499999999999766, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, 30.500000000000192, 20.000000000000014, -3.099999999999958, 25.400000000000098, 20.000000000000014, 20.000000000000014, 28.100000000000147, -292.9, -194.20000000000056, -252.7000000000001, 9.499999999999964, 20.000000000000014, 31.700000000000212, 20.000000000000014, 20.000000000000014, 42.50000000000023, 20.000000000000014, 26.300000000000118, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.000000000000256, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000024, 20.000000000000014, 20.000000000000014, -12.699999999999815, 20.000000000000014, 20.000000000000014, 20.000000000000014, 4.099999999999966, -32.49999999999975, 28.100000000000147, 20.000000000000014, 20.000000000000014, -112.3000000000007, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.000000000000014, -261.3999999999991, 20.000000000000014, -34.59999999999982, -318.10000000000025, 20.000000000000014, 45.200000000000244, -378.7, -5.200000000000051, -34.599999999999866, 20.000000000000014, -42.99999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -16.299999999999784, 20.90000000000003, 20.000000000000014, 20.000000000000014, -9.399999999999855, -38.79999999999976, 20.000000000000014, -267.7, -208.90000000000003, 37.10000000000024, 5.299999999999972, 20.000000000000014, -82.90000000000003, 32.60000000000023, 20.000000000000014, -116.80000000000064, 20.000000000000014, -1.0000000000000098, -3.0999999999999828, -360.1, 44.300000000000246, -21.999999999999766, -6.699999999999921, -208.90000000000003, -159.70000000000064, -387.4, 33.50000000000024, -26.79999999999997, -13.599999999999786, 20.000000000000014, -1.5999999999998102, -20.499999999999964, 23.600000000000065, 14.299999999999969, -328.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.399999999999764, -10.299999999999777, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.90000000000018, -20.19999999999976, 30.800000000000196, -24.099999999999746, -278.2, 46.10000000000024, -106.30000000000064, -305.2, 17.899999999999988, -385.0, -76.59999999999984, 20.000000000000014, 20.000000000000014, -253.00000000000034, 20.000000000000014, -350.5, -303.40000000000026, -318.1, 26.300000000000114, -122.79999999999981, 20.000000000000014, 20.000000000000014, -70.30000000000004, -47.19999999999979, 20.000000000000014, 32.300000000000246, 20.000000000000014, 20.000000000000014, 50.0000000000002, 13.69999999999997, 23.600000000000083, 20.000000000000014, -93.40000000000003, 20.000000000000014, -4.599999999999971, 20.000000000000014, -5.200000000000051, -238.3000000000004, -203.1999999999999, 51.500000000000234, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, -400.0, -246.70000000000002, -313.9, -225.99999999999991, -303.4000000000001, 20.000000000000014, 20.000000000000014, -358.0, -114.40000000000077, -108.09999999999987, 17.899999999999988, -192.10000000000034, -223.5999999999999, -218.8, -51.400000000000034, -263.49999999999994, 20.000000000000014, 44.300000000000246, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -290.8, 20.000000000000014, -155.50000000000048, -125.80000000000001, -206.80000000000052, -311.80000000000024, -24.099999999999746, 20.000000000000014, -376.00000000000006, -156.40000000000003, -161.50000000000054, 20.000000000000014, -182.50000000000043, 20.000000000000014, -36.699999999999754, 42.50000000000025, 11.599999999999946, -65.79999999999998], "policy_predator_policy_reward": [8.0, 3.0, 0.0, 0.0, 5.0, 0.0, 83.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 0.0, 0.0, 149.0, 0.0, 164.0, 82.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 140.0, 0.0, 161.0, 0.0, 0.0, 29.0, 185.0, 26.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 14.0, 0.0, 28.0, 0.0, 137.0, 112.0, 0.0, 13.0, 0.0, 49.0, 0.0, 0.0, 0.0, 72.0, 0.0, 11.0, 179.0, 2.0, 17.0, 20.0, 61.0, 134.0, 0.0, 194.0, 0.0, 40.0, 0.0, 24.0, 0.0, 21.0, 172.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 21.0, 142.0, 0.0, 181.0, 0.0, 195.0, 0.0, 58.0, 0.0, 130.0, 0.0, 181.0, 138.0, 199.0, 116.0, 55.0, 21.0, 0.0, 0.0, 43.0, 32.0, 4.0, 0.0, 0.0, 0.0, 3.0, 8.0, 15.0, 0.0, 54.0, 0.0, 0.0, 19.0, 12.0, 123.0, 114.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 200.0, 118.0, 159.0, 154.0, 0.0, 124.0, 180.0, 67.0, 46.0, 95.0, 7.0, 105.0, 19.0, 24.0, 145.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 148.0, 0.0, 165.0, 0.0, 158.0, 64.0, 21.0, 0.0, 189.0, 0.0, 92.0, 0.0, 105.0, 0.0, 27.0, 0.0, 0.0, 46.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3399040566603764, "mean_inference_ms": 3.7737787838008847, "mean_action_processing_ms": 0.6390897218835196, "mean_env_wait_ms": 0.4500056002169238, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017325401306152344, "StateBufferConnector_ms": 0.018694639205932617, "ViewRequirementAgentConnector_ms": 0.3448026180267334}, "num_episodes": 18, "episode_return_max": 74.69999999999966, "episode_return_min": -446.69999999999993, "episode_return_mean": -30.867999999999885, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 234.78875483681418, "num_env_steps_trained_throughput_per_sec": 234.78875483681418, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 212104.801, "restore_workers_time_ms": 0.029, "training_step_time_ms": 212104.723, "sample_time_ms": 3745.592, "learn_time_ms": 208326.459, "learn_throughput": 19.201, "synch_weights_time_ms": 27.546}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "3a355_00000", "date": "2024-08-13_02-13-54", "timestamp": 1723529634, "time_this_iter_s": 17.134922981262207, "time_total_s": 3841.7932426929474, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b50759d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3841.7932426929474, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 87.0, "ram_util_percent": 83.5125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.36595872092459886, "cur_kl_coeff": 7.62939453125e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.333776331830908, "policy_loss": -0.0014780079539392203, "vf_loss": 4.3352543325020525, "vf_explained_var": 0.0033465173194017358, "kl": 0.0023611175983138987, "entropy": 0.42699187976658026, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8167289645741226, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.763849889664423, "policy_loss": -0.0019435276219463616, "vf_loss": 4.765512586901427, "vf_explained_var": 0.0009214111106105583, "kl": 0.013313790438050529, "entropy": 0.9730576323138342, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 74.69999999999966, "episode_reward_min": -446.69999999999993, "episode_reward_mean": -41.56599999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 51.500000000000234, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -61.182999999999986, "predator_policy": 40.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 53.50000000000052, 40.0000000000003, 26.30000000000009, 40.0000000000003, -3.3999999999997024, 48.10000000000043, -29.299999999999592, 40.90000000000031, 40.0000000000003, -101.40000000000076, -191.70000000000093, 65.20000000000041, -169.90000000000052, 11.39999999999992, 7.000000000000007, 40.0000000000003, 28.700000000000145, 40.90000000000031, 24.60000000000005, 9.200000000000063, -227.60000000000002, 55.40000000000049, -13.899999999999826, 52.60000000000051, -24.799999999999635, 6.900000000000114, -134.80000000000038, 8.300000000000074, -173.60000000000034, -159.90000000000055, -0.39999999999998037, 42.40000000000046, 24.100000000000385, -42.299999999999834, 40.0000000000003, 40.0000000000003, 10.300000000000232, 40.0000000000003, 40.0000000000003, 32.700000000000195, 27.70000000000012, -90.09999999999998, -230.50000000000063, -172.10000000000062, 1.400000000000396, -102.99999999999997, -11.499999999999854, -306.5, -20.500000000000043, 40.0000000000003, -42.499999999999865, 56.3000000000005, 40.0000000000003, 74.69999999999966, 58.60000000000042, -19.399999999999835, 34.40000000000022, -108.500000000001, -37.69999999999978, 34.50000000000023, 40.0000000000003, -446.69999999999993, -262.89999999999986, -129.4000000000003, -33.99999999999978, -109.49999999999966, -72.2000000000007, -318.3999999999998, -145.90000000000035, 64.30000000000048, 40.0000000000003, 40.0000000000003, -122.80000000000032, -116.30000000000018, -296.5999999999998, 16.899999999999974, -343.4000000000001, -49.50000000000002, -57.50000000000015, 32.800000000000196, -8.199999999999747, -30.39999999999985, 73.59999999999978, -114.89999999999989, 24.099999999999973, -65.59999999999997, 8.100000000000243, -58.89999999999971, 58.100000000000435, 11.400000000000079, -420.9999999999977, 61.20000000000035, -68.9, 56.30000000000037, -23.299999999999798, 17.099999999999948, 55.30000000000052, -331.5999999999999, -28.699999999999676], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000024, 20.000000000000014, 20.000000000000014, -12.699999999999815, 20.000000000000014, 20.000000000000014, 20.000000000000014, 4.099999999999966, -32.49999999999975, 28.100000000000147, 20.000000000000014, 20.000000000000014, -112.3000000000007, 20.000000000000014, 20.900000000000027, 20.000000000000014, 20.000000000000014, -261.3999999999991, 20.000000000000014, -34.59999999999982, -318.10000000000025, 20.000000000000014, 45.200000000000244, -378.7, -5.200000000000051, -34.599999999999866, 20.000000000000014, -42.99999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -16.299999999999784, 20.90000000000003, 20.000000000000014, 20.000000000000014, -9.399999999999855, -38.79999999999976, 20.000000000000014, -267.7, -208.90000000000003, 37.10000000000024, 5.299999999999972, 20.000000000000014, -82.90000000000003, 32.60000000000023, 20.000000000000014, -116.80000000000064, 20.000000000000014, -1.0000000000000098, -3.0999999999999828, -360.1, 44.300000000000246, -21.999999999999766, -6.699999999999921, -208.90000000000003, -159.70000000000064, -387.4, 33.50000000000024, -26.79999999999997, -13.599999999999786, 20.000000000000014, -1.5999999999998102, -20.499999999999964, 23.600000000000065, 14.299999999999969, -328.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.399999999999764, -10.299999999999777, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.90000000000018, -20.19999999999976, 30.800000000000196, -24.099999999999746, -278.2, 46.10000000000024, -106.30000000000064, -305.2, 17.899999999999988, -385.0, -76.59999999999984, 20.000000000000014, 20.000000000000014, -253.00000000000034, 20.000000000000014, -350.5, -303.40000000000026, -318.1, 26.300000000000114, -122.79999999999981, 20.000000000000014, 20.000000000000014, -70.30000000000004, -47.19999999999979, 20.000000000000014, 32.300000000000246, 20.000000000000014, 20.000000000000014, 50.0000000000002, 13.69999999999997, 23.600000000000083, 20.000000000000014, -93.40000000000003, 20.000000000000014, -4.599999999999971, 20.000000000000014, -5.200000000000051, -238.3000000000004, -203.1999999999999, 51.500000000000234, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, -400.0, -246.70000000000002, -313.9, -225.99999999999991, -303.4000000000001, 20.000000000000014, 20.000000000000014, -358.0, -114.40000000000077, -108.09999999999987, 17.899999999999988, -192.10000000000034, -223.5999999999999, -218.8, -51.400000000000034, -263.49999999999994, 20.000000000000014, 44.300000000000246, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -290.8, 20.000000000000014, -155.50000000000048, -125.80000000000001, -206.80000000000052, -311.80000000000024, -24.099999999999746, 20.000000000000014, -376.00000000000006, -156.40000000000003, -161.50000000000054, 20.000000000000014, -182.50000000000043, 20.000000000000014, -36.699999999999754, 42.50000000000025, 11.599999999999946, -65.79999999999998, 20.000000000000014, -114.40000000000003, 20.000000000000014, 50.600000000000215, -124.90000000000003, -361.0, -52.899999999999885, 20.000000000000014, 20.000000000000014, -181.59999999999994, 20.000000000000014, -40.90000000000003, -122.20000000000044, -57.69999999999981, 20.000000000000014, 25.100000000000108, -26.19999999999996, 11.599999999999953, -334.8999999999993, -255.09999999999872, 30.200000000000177, 20.000000000000014, -175.3, 7.399999999999965, -138.6999999999999, 20.000000000000014, 20.000000000000014, -112.30000000000032, -40.89999999999976, 20.000000000000014, 35.30000000000026, 20.000000000000014, -343.3000000000002, -163.29999999999993, -131.50000000000048, 15.799999999999962], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 140.0, 0.0, 161.0, 0.0, 0.0, 29.0, 185.0, 26.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 14.0, 0.0, 28.0, 0.0, 137.0, 112.0, 0.0, 13.0, 0.0, 49.0, 0.0, 0.0, 0.0, 72.0, 0.0, 11.0, 179.0, 2.0, 17.0, 20.0, 61.0, 134.0, 0.0, 194.0, 0.0, 40.0, 0.0, 24.0, 0.0, 21.0, 172.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 21.0, 142.0, 0.0, 181.0, 0.0, 195.0, 0.0, 58.0, 0.0, 130.0, 0.0, 181.0, 138.0, 199.0, 116.0, 55.0, 21.0, 0.0, 0.0, 43.0, 32.0, 4.0, 0.0, 0.0, 0.0, 3.0, 8.0, 15.0, 0.0, 54.0, 0.0, 0.0, 19.0, 12.0, 123.0, 114.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 200.0, 118.0, 159.0, 154.0, 0.0, 124.0, 180.0, 67.0, 46.0, 95.0, 7.0, 105.0, 19.0, 24.0, 145.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 148.0, 0.0, 165.0, 0.0, 158.0, 64.0, 21.0, 0.0, 189.0, 0.0, 92.0, 0.0, 105.0, 0.0, 27.0, 0.0, 0.0, 46.0, 0.0, 64.0, 3.0, 0.0, 186.0, 185.0, 7.0, 50.0, 80.0, 16.0, 0.0, 29.0, 27.0, 94.0, 13.0, 0.0, 0.0, 26.0, 0.0, 169.0, 0.0, 11.0, 32.0, 67.0, 91.0, 84.0, 14.0, 55.0, 27.0, 11.0, 0.0, 0.0, 0.0, 175.0, 87.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3517348244883192, "mean_inference_ms": 3.8039266792674393, "mean_action_processing_ms": 0.6415647981072246, "mean_env_wait_ms": 0.4539259355884587, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017314910888671875, "StateBufferConnector_ms": 0.01814424991607666, "ViewRequirementAgentConnector_ms": 0.35533714294433594}, "num_episodes": 18, "episode_return_max": 74.69999999999966, "episode_return_min": -446.69999999999993, "episode_return_mean": -41.56599999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 219.96864231810216, "num_env_steps_trained_throughput_per_sec": 219.96864231810216, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 211336.416, "restore_workers_time_ms": 0.03, "training_step_time_ms": 211336.324, "sample_time_ms": 3744.007, "learn_time_ms": 207559.651, "learn_throughput": 19.272, "synch_weights_time_ms": 27.985}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "3a355_00000", "date": "2024-08-13_02-14-12", "timestamp": 1723529652, "time_this_iter_s": 18.246011972427368, "time_total_s": 3860.0392546653748, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52393a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3860.0392546653748, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 90.96923076923076, "ram_util_percent": 83.66153846153847}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4318114814343591, "cur_kl_coeff": 3.814697265625e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.350644005164899, "policy_loss": -0.0022878583978920702, "vf_loss": 4.352931850170963, "vf_explained_var": 0.004140366416759592, "kl": 0.002012441191679336, "entropy": 0.3581650747508599, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7523149843687418, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.947626352562476, "policy_loss": -0.0007953591679257375, "vf_loss": 4.948353562783943, "vf_explained_var": -0.0026869501386369977, "kl": 0.0032310442269970424, "entropy": 1.0251028389527053, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 77.7999999999995, "episode_reward_min": -446.69999999999993, "episode_reward_mean": -59.86999999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.1000000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -78.65499999999999, "predator_policy": 48.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [55.40000000000049, -13.899999999999826, 52.60000000000051, -24.799999999999635, 6.900000000000114, -134.80000000000038, 8.300000000000074, -173.60000000000034, -159.90000000000055, -0.39999999999998037, 42.40000000000046, 24.100000000000385, -42.299999999999834, 40.0000000000003, 40.0000000000003, 10.300000000000232, 40.0000000000003, 40.0000000000003, 32.700000000000195, 27.70000000000012, -90.09999999999998, -230.50000000000063, -172.10000000000062, 1.400000000000396, -102.99999999999997, -11.499999999999854, -306.5, -20.500000000000043, 40.0000000000003, -42.499999999999865, 56.3000000000005, 40.0000000000003, 74.69999999999966, 58.60000000000042, -19.399999999999835, 34.40000000000022, -108.500000000001, -37.69999999999978, 34.50000000000023, 40.0000000000003, -446.69999999999993, -262.89999999999986, -129.4000000000003, -33.99999999999978, -109.49999999999966, -72.2000000000007, -318.3999999999998, -145.90000000000035, 64.30000000000048, 40.0000000000003, 40.0000000000003, -122.80000000000032, -116.30000000000018, -296.5999999999998, 16.899999999999974, -343.4000000000001, -49.50000000000002, -57.50000000000015, 32.800000000000196, -8.199999999999747, -30.39999999999985, 73.59999999999978, -114.89999999999989, 24.099999999999973, -65.59999999999997, 8.100000000000243, -58.89999999999971, 58.100000000000435, 11.400000000000079, -420.9999999999977, 61.20000000000035, -68.9, 56.30000000000037, -23.299999999999798, 17.099999999999948, 55.30000000000052, -331.5999999999999, -28.699999999999676, -151.20000000000036, -138.70000000000113, -203.10000000000065, -245.9000000000002, -61.200000000000415, -30.799999999999628, 77.7999999999995, -286.59999999999945, -202.69999999999993, -103.69999999999978, -98.50000000000051, -226.50000000000023, -24.899999999999963, -33.89999999999976, -19.29999999999975, 50.20000000000046, -32.89999999999983, 19.099999999999973, -302.89999999999986, 34.50000000000022, -48.99999999999969, 32.30000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [37.10000000000024, 5.299999999999972, 20.000000000000014, -82.90000000000003, 32.60000000000023, 20.000000000000014, -116.80000000000064, 20.000000000000014, -1.0000000000000098, -3.0999999999999828, -360.1, 44.300000000000246, -21.999999999999766, -6.699999999999921, -208.90000000000003, -159.70000000000064, -387.4, 33.50000000000024, -26.79999999999997, -13.599999999999786, 20.000000000000014, -1.5999999999998102, -20.499999999999964, 23.600000000000065, 14.299999999999969, -328.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.399999999999764, -10.299999999999777, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.90000000000018, -20.19999999999976, 30.800000000000196, -24.099999999999746, -278.2, 46.10000000000024, -106.30000000000064, -305.2, 17.899999999999988, -385.0, -76.59999999999984, 20.000000000000014, 20.000000000000014, -253.00000000000034, 20.000000000000014, -350.5, -303.40000000000026, -318.1, 26.300000000000114, -122.79999999999981, 20.000000000000014, 20.000000000000014, -70.30000000000004, -47.19999999999979, 20.000000000000014, 32.300000000000246, 20.000000000000014, 20.000000000000014, 50.0000000000002, 13.69999999999997, 23.600000000000083, 20.000000000000014, -93.40000000000003, 20.000000000000014, -4.599999999999971, 20.000000000000014, -5.200000000000051, -238.3000000000004, -203.1999999999999, 51.500000000000234, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, -400.0, -246.70000000000002, -313.9, -225.99999999999991, -303.4000000000001, 20.000000000000014, 20.000000000000014, -358.0, -114.40000000000077, -108.09999999999987, 17.899999999999988, -192.10000000000034, -223.5999999999999, -218.8, -51.400000000000034, -263.49999999999994, 20.000000000000014, 44.300000000000246, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -290.8, 20.000000000000014, -155.50000000000048, -125.80000000000001, -206.80000000000052, -311.80000000000024, -24.099999999999746, 20.000000000000014, -376.00000000000006, -156.40000000000003, -161.50000000000054, 20.000000000000014, -182.50000000000043, 20.000000000000014, -36.699999999999754, 42.50000000000025, 11.599999999999946, -65.79999999999998, 20.000000000000014, -114.40000000000003, 20.000000000000014, 50.600000000000215, -124.90000000000003, -361.0, -52.899999999999885, 20.000000000000014, 20.000000000000014, -181.59999999999994, 20.000000000000014, -40.90000000000003, -122.20000000000044, -57.69999999999981, 20.000000000000014, 25.100000000000108, -26.19999999999996, 11.599999999999953, -334.8999999999993, -255.09999999999872, 30.200000000000177, 20.000000000000014, -175.3, 7.399999999999965, -138.6999999999999, 20.000000000000014, 20.000000000000014, -112.30000000000032, -40.89999999999976, 20.000000000000014, 35.30000000000026, 20.000000000000014, -343.3000000000002, -163.29999999999993, -131.50000000000048, 15.799999999999962, -81.40000000000002, -269.7999999999986, -246.7000000000003, -18.999999999999787, -366.4, -36.699999999999754, -297.1, -290.7999999999993, -169.0000000000003, 15.799999999999963, -143.80000000000064, 20.000000000000014, 57.800000000000225, 20.000000000000014, -199.90000000000046, -294.7, -131.20000000000005, -305.5, -144.10000000000002, -97.60000000000004, -248.50000000000009, 20.000000000000014, -101.80000000000004, -375.7, 3.1999999999999615, -87.10000000000004, -121.90000000000046, 20.000000000000014, -177.4000000000001, 64.1000000000002, 20.000000000000014, 9.199999999999983, 20.000000000000014, -151.9, 20.000000000000014, -19.89999999999977, -234.10000000000002, -290.79999999999995, 9.499999999999964, 20.000000000000014, -61.30000000000002, -36.70000000000003, 20.000000000000014, 5.299999999999965], "policy_predator_policy_reward": [0.0, 13.0, 0.0, 49.0, 0.0, 0.0, 0.0, 72.0, 0.0, 11.0, 179.0, 2.0, 17.0, 20.0, 61.0, 134.0, 0.0, 194.0, 0.0, 40.0, 0.0, 24.0, 0.0, 21.0, 172.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 21.0, 142.0, 0.0, 181.0, 0.0, 195.0, 0.0, 58.0, 0.0, 130.0, 0.0, 181.0, 138.0, 199.0, 116.0, 55.0, 21.0, 0.0, 0.0, 43.0, 32.0, 4.0, 0.0, 0.0, 0.0, 3.0, 8.0, 15.0, 0.0, 54.0, 0.0, 0.0, 19.0, 12.0, 123.0, 114.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 200.0, 118.0, 159.0, 154.0, 0.0, 124.0, 180.0, 67.0, 46.0, 95.0, 7.0, 105.0, 19.0, 24.0, 145.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 148.0, 0.0, 165.0, 0.0, 158.0, 64.0, 21.0, 0.0, 189.0, 0.0, 92.0, 0.0, 105.0, 0.0, 27.0, 0.0, 0.0, 46.0, 0.0, 64.0, 3.0, 0.0, 186.0, 185.0, 7.0, 50.0, 80.0, 16.0, 0.0, 29.0, 27.0, 94.0, 13.0, 0.0, 0.0, 26.0, 0.0, 169.0, 0.0, 11.0, 32.0, 67.0, 91.0, 84.0, 14.0, 55.0, 27.0, 11.0, 0.0, 0.0, 0.0, 175.0, 87.0, 0.0, 200.0, 0.0, 0.0, 127.0, 18.0, 182.0, 176.0, 166.0, 2.0, 90.0, 29.0, 64.0, 0.0, 0.0, 190.0, 18.0, 79.0, 155.0, 92.0, 46.0, 23.0, 107.0, 189.0, 62.0, 0.0, 59.0, 0.0, 68.0, 0.0, 94.0, 0.0, 21.0, 0.0, 99.0, 0.0, 19.0, 151.0, 71.0, 5.0, 0.0, 0.0, 49.0, 7.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.364702579823751, "mean_inference_ms": 3.833296717227709, "mean_action_processing_ms": 0.6447796265584127, "mean_env_wait_ms": 0.45830194589298484, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018349766731262207, "StateBufferConnector_ms": 0.01465749740600586, "ViewRequirementAgentConnector_ms": 0.33499133586883545}, "num_episodes": 22, "episode_return_max": 77.7999999999995, "episode_return_min": -446.69999999999993, "episode_return_mean": -59.86999999999992, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.45117182206883, "num_env_steps_trained_throughput_per_sec": 201.45117182206883, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 211046.175, "restore_workers_time_ms": 0.03, "training_step_time_ms": 211046.083, "sample_time_ms": 3683.685, "learn_time_ms": 207327.999, "learn_throughput": 19.293, "synch_weights_time_ms": 29.672}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "3a355_00000", "date": "2024-08-13_02-14-32", "timestamp": 1723529672, "time_this_iter_s": 19.93975329399109, "time_total_s": 3879.979007959366, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5075dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3879.979007959366, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 93.40357142857142, "ram_util_percent": 83.66785714285716}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45307525573741825, "cur_kl_coeff": 1.9073486328125e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.354286718494678, "policy_loss": -0.0016886313933701742, "vf_loss": 4.355975357439152, "vf_explained_var": 0.0006844340808807857, "kl": 0.0016820234724957356, "entropy": 0.41435081271267443, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8222840299642591, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.978782958959146, "policy_loss": -0.0032892948770452115, "vf_loss": 4.981826686859131, "vf_explained_var": -0.002988721769322794, "kl": 0.02328348428783067, "entropy": 1.011617238401736, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 77.7999999999995, "episode_reward_min": -446.69999999999993, "episode_reward_mean": -70.64299999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.1000000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -89.20150000000001, "predator_policy": 53.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.400000000000396, -102.99999999999997, -11.499999999999854, -306.5, -20.500000000000043, 40.0000000000003, -42.499999999999865, 56.3000000000005, 40.0000000000003, 74.69999999999966, 58.60000000000042, -19.399999999999835, 34.40000000000022, -108.500000000001, -37.69999999999978, 34.50000000000023, 40.0000000000003, -446.69999999999993, -262.89999999999986, -129.4000000000003, -33.99999999999978, -109.49999999999966, -72.2000000000007, -318.3999999999998, -145.90000000000035, 64.30000000000048, 40.0000000000003, 40.0000000000003, -122.80000000000032, -116.30000000000018, -296.5999999999998, 16.899999999999974, -343.4000000000001, -49.50000000000002, -57.50000000000015, 32.800000000000196, -8.199999999999747, -30.39999999999985, 73.59999999999978, -114.89999999999989, 24.099999999999973, -65.59999999999997, 8.100000000000243, -58.89999999999971, 58.100000000000435, 11.400000000000079, -420.9999999999977, 61.20000000000035, -68.9, 56.30000000000037, -23.299999999999798, 17.099999999999948, 55.30000000000052, -331.5999999999999, -28.699999999999676, -151.20000000000036, -138.70000000000113, -203.10000000000065, -245.9000000000002, -61.200000000000415, -30.799999999999628, 77.7999999999995, -286.59999999999945, -202.69999999999993, -103.69999999999978, -98.50000000000051, -226.50000000000023, -24.899999999999963, -33.89999999999976, -19.29999999999975, 50.20000000000046, -32.89999999999983, 19.099999999999973, -302.89999999999986, 34.50000000000022, -48.99999999999969, 32.30000000000018, -299.49999999999704, -52.699999999999854, -136.50000000000063, -90.79999999999998, 26.800000000000086, 59.90000000000008, 40.0000000000003, -99.90000000000018, -59.69999999999976, 40.0000000000003, -8.299999999999773, 22.400000000000034, 4.800000000000107, -148.30000000000027, -219.69999999999985, -223.00000000000034, -105.1000000000002, 49.90000000000046, -82.10000000000107, -196.50000000000023, -175.50000000000043, -22.89999999999963, -22.599999999999902], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-76.59999999999984, 20.000000000000014, 20.000000000000014, -253.00000000000034, 20.000000000000014, -350.5, -303.40000000000026, -318.1, 26.300000000000114, -122.79999999999981, 20.000000000000014, 20.000000000000014, -70.30000000000004, -47.19999999999979, 20.000000000000014, 32.300000000000246, 20.000000000000014, 20.000000000000014, 50.0000000000002, 13.69999999999997, 23.600000000000083, 20.000000000000014, -93.40000000000003, 20.000000000000014, -4.599999999999971, 20.000000000000014, -5.200000000000051, -238.3000000000004, -203.1999999999999, 51.500000000000234, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, -400.0, -246.70000000000002, -313.9, -225.99999999999991, -303.4000000000001, 20.000000000000014, 20.000000000000014, -358.0, -114.40000000000077, -108.09999999999987, 17.899999999999988, -192.10000000000034, -223.5999999999999, -218.8, -51.400000000000034, -263.49999999999994, 20.000000000000014, 44.300000000000246, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -290.8, 20.000000000000014, -155.50000000000048, -125.80000000000001, -206.80000000000052, -311.80000000000024, -24.099999999999746, 20.000000000000014, -376.00000000000006, -156.40000000000003, -161.50000000000054, 20.000000000000014, -182.50000000000043, 20.000000000000014, -36.699999999999754, 42.50000000000025, 11.599999999999946, -65.79999999999998, 20.000000000000014, -114.40000000000003, 20.000000000000014, 50.600000000000215, -124.90000000000003, -361.0, -52.899999999999885, 20.000000000000014, 20.000000000000014, -181.59999999999994, 20.000000000000014, -40.90000000000003, -122.20000000000044, -57.69999999999981, 20.000000000000014, 25.100000000000108, -26.19999999999996, 11.599999999999953, -334.8999999999993, -255.09999999999872, 30.200000000000177, 20.000000000000014, -175.3, 7.399999999999965, -138.6999999999999, 20.000000000000014, 20.000000000000014, -112.30000000000032, -40.89999999999976, 20.000000000000014, 35.30000000000026, 20.000000000000014, -343.3000000000002, -163.29999999999993, -131.50000000000048, 15.799999999999962, -81.40000000000002, -269.7999999999986, -246.7000000000003, -18.999999999999787, -366.4, -36.699999999999754, -297.1, -290.7999999999993, -169.0000000000003, 15.799999999999963, -143.80000000000064, 20.000000000000014, 57.800000000000225, 20.000000000000014, -199.90000000000046, -294.7, -131.20000000000005, -305.5, -144.10000000000002, -97.60000000000004, -248.50000000000009, 20.000000000000014, -101.80000000000004, -375.7, 3.1999999999999615, -87.10000000000004, -121.90000000000046, 20.000000000000014, -177.4000000000001, 64.1000000000002, 20.000000000000014, 9.199999999999983, 20.000000000000014, -151.9, 20.000000000000014, -19.89999999999977, -234.10000000000002, -290.79999999999995, 9.499999999999964, 20.000000000000014, -61.30000000000002, -36.70000000000003, 20.000000000000014, 5.299999999999965, -206.80000000000052, -246.70000000000041, -119.20000000000009, -32.49999999999975, 20.000000000000014, -386.5, -183.7000000000001, -108.10000000000004, -0.9999999999999846, 15.799999999999963, -184.89999999999998, 30.800000000000207, 20.000000000000014, 20.000000000000014, -17.79999999999974, -228.09999999999994, -242.50000000000014, 57.800000000000225, 20.000000000000014, 20.000000000000014, -75.10000000000085, 9.800000000000063, -72.40000000000089, 30.800000000000196, 15.79999999999996, -42.99999999999978, -229.30000000000027, -169.00000000000003, -233.5, -215.1999999999999, -105.9999999999998, -319.0, -74.50000000000088, -187.59999999999994, 29.90000000000018, 20.000000000000014, -45.09999999999976, -148.00000000000048, -145.90000000000012, -160.60000000000002, -194.20000000000002, -163.3000000000005, -115.00000000000065, 1.0999999999999688, -103.60000000000025, 20.000000000000014], "policy_predator_policy_reward": [58.0, 0.0, 130.0, 0.0, 181.0, 138.0, 199.0, 116.0, 55.0, 21.0, 0.0, 0.0, 43.0, 32.0, 4.0, 0.0, 0.0, 0.0, 3.0, 8.0, 15.0, 0.0, 54.0, 0.0, 0.0, 19.0, 12.0, 123.0, 114.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 200.0, 118.0, 159.0, 154.0, 0.0, 124.0, 180.0, 67.0, 46.0, 95.0, 7.0, 105.0, 19.0, 24.0, 145.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 148.0, 0.0, 165.0, 0.0, 158.0, 64.0, 21.0, 0.0, 189.0, 0.0, 92.0, 0.0, 105.0, 0.0, 27.0, 0.0, 0.0, 46.0, 0.0, 64.0, 3.0, 0.0, 186.0, 185.0, 7.0, 50.0, 80.0, 16.0, 0.0, 29.0, 27.0, 94.0, 13.0, 0.0, 0.0, 26.0, 0.0, 169.0, 0.0, 11.0, 32.0, 67.0, 91.0, 84.0, 14.0, 55.0, 27.0, 11.0, 0.0, 0.0, 0.0, 175.0, 87.0, 0.0, 200.0, 0.0, 0.0, 127.0, 18.0, 182.0, 176.0, 166.0, 2.0, 90.0, 29.0, 64.0, 0.0, 0.0, 190.0, 18.0, 79.0, 155.0, 92.0, 46.0, 23.0, 107.0, 189.0, 62.0, 0.0, 59.0, 0.0, 68.0, 0.0, 94.0, 0.0, 21.0, 0.0, 99.0, 0.0, 19.0, 151.0, 71.0, 5.0, 0.0, 0.0, 49.0, 7.0, 0.0, 20.0, 134.0, 99.0, 0.0, 120.0, 110.0, 134.0, 67.0, 2.0, 10.0, 98.0, 116.0, 0.0, 0.0, 146.0, 0.0, 0.0, 125.0, 0.0, 0.0, 57.0, 0.0, 44.0, 20.0, 0.0, 32.0, 86.0, 164.0, 98.0, 131.0, 29.0, 173.0, 3.0, 154.0, 0.0, 0.0, 0.0, 111.0, 110.0, 0.0, 0.0, 182.0, 66.0, 25.0, 7.0, 54.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3724286639735914, "mean_inference_ms": 3.856858982500953, "mean_action_processing_ms": 0.6479642334081771, "mean_env_wait_ms": 0.46130167198611816, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018730878829956055, "StateBufferConnector_ms": 0.006522178649902344, "ViewRequirementAgentConnector_ms": 0.30087995529174805}, "num_episodes": 23, "episode_return_max": 77.7999999999995, "episode_return_min": -446.69999999999993, "episode_return_mean": -70.64299999999989, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.4249449270563, "num_env_steps_trained_throughput_per_sec": 210.4249449270563, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 210664.585, "restore_workers_time_ms": 0.03, "training_step_time_ms": 210664.492, "sample_time_ms": 3634.133, "learn_time_ms": 206995.989, "learn_throughput": 19.324, "synch_weights_time_ms": 30.107}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "3a355_00000", "date": "2024-08-13_02-14-52", "timestamp": 1723529692, "time_this_iter_s": 19.089625120162964, "time_total_s": 3899.068633079529, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d6d550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3899.068633079529, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 90.27037037037037, "ram_util_percent": 83.4962962962963}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.36832938926126907, "cur_kl_coeff": 9.5367431640625e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.487780396017448, "policy_loss": -0.0015794718645453926, "vf_loss": 4.489359873312491, "vf_explained_var": 0.0023509107569538094, "kl": 0.0017099208607398862, "entropy": 0.34710481868534493, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6861605944496298, "cur_kl_coeff": 0.015820312499999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.045144997071968, "policy_loss": -0.0019750585772156243, "vf_loss": 4.046808000720998, "vf_explained_var": -0.0023614101939731175, "kl": 0.019724364023867135, "entropy": 1.0195478623506253, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 77.7999999999995, "episode_reward_min": -420.9999999999977, "episode_reward_mean": -79.60999999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.1000000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -95.74000000000002, "predator_policy": 55.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-262.89999999999986, -129.4000000000003, -33.99999999999978, -109.49999999999966, -72.2000000000007, -318.3999999999998, -145.90000000000035, 64.30000000000048, 40.0000000000003, 40.0000000000003, -122.80000000000032, -116.30000000000018, -296.5999999999998, 16.899999999999974, -343.4000000000001, -49.50000000000002, -57.50000000000015, 32.800000000000196, -8.199999999999747, -30.39999999999985, 73.59999999999978, -114.89999999999989, 24.099999999999973, -65.59999999999997, 8.100000000000243, -58.89999999999971, 58.100000000000435, 11.400000000000079, -420.9999999999977, 61.20000000000035, -68.9, 56.30000000000037, -23.299999999999798, 17.099999999999948, 55.30000000000052, -331.5999999999999, -28.699999999999676, -151.20000000000036, -138.70000000000113, -203.10000000000065, -245.9000000000002, -61.200000000000415, -30.799999999999628, 77.7999999999995, -286.59999999999945, -202.69999999999993, -103.69999999999978, -98.50000000000051, -226.50000000000023, -24.899999999999963, -33.89999999999976, -19.29999999999975, 50.20000000000046, -32.89999999999983, 19.099999999999973, -302.89999999999986, 34.50000000000022, -48.99999999999969, 32.30000000000018, -299.49999999999704, -52.699999999999854, -136.50000000000063, -90.79999999999998, 26.800000000000086, 59.90000000000008, 40.0000000000003, -99.90000000000018, -59.69999999999976, 40.0000000000003, -8.299999999999773, 22.400000000000034, 4.800000000000107, -148.30000000000027, -219.69999999999985, -223.00000000000034, -105.1000000000002, 49.90000000000046, -82.10000000000107, -196.50000000000023, -175.50000000000043, -22.89999999999963, -22.599999999999902, -0.09999999999999537, -72.10000000000068, 40.0000000000003, -371.99999999999886, -125.60000000000147, -120.6000000000003, 54.600000000000435, -280.59999999999945, -368.29999999999836, -114.00000000000091, -58.99999999999996, -24.299999999999734, -77.49999999999997, -242.0999999999999, 24.800000000000097, 7.700000000000154, 52.60000000000051, 63.4000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-313.9, -225.99999999999991, -303.4000000000001, 20.000000000000014, 20.000000000000014, -358.0, -114.40000000000077, -108.09999999999987, 17.899999999999988, -192.10000000000034, -223.5999999999999, -218.8, -51.400000000000034, -263.49999999999994, 20.000000000000014, 44.300000000000246, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -290.8, 20.000000000000014, -155.50000000000048, -125.80000000000001, -206.80000000000052, -311.80000000000024, -24.099999999999746, 20.000000000000014, -376.00000000000006, -156.40000000000003, -161.50000000000054, 20.000000000000014, -182.50000000000043, 20.000000000000014, -36.699999999999754, 42.50000000000025, 11.599999999999946, -65.79999999999998, 20.000000000000014, -114.40000000000003, 20.000000000000014, 50.600000000000215, -124.90000000000003, -361.0, -52.899999999999885, 20.000000000000014, 20.000000000000014, -181.59999999999994, 20.000000000000014, -40.90000000000003, -122.20000000000044, -57.69999999999981, 20.000000000000014, 25.100000000000108, -26.19999999999996, 11.599999999999953, -334.8999999999993, -255.09999999999872, 30.200000000000177, 20.000000000000014, -175.3, 7.399999999999965, -138.6999999999999, 20.000000000000014, 20.000000000000014, -112.30000000000032, -40.89999999999976, 20.000000000000014, 35.30000000000026, 20.000000000000014, -343.3000000000002, -163.29999999999993, -131.50000000000048, 15.799999999999962, -81.40000000000002, -269.7999999999986, -246.7000000000003, -18.999999999999787, -366.4, -36.699999999999754, -297.1, -290.7999999999993, -169.0000000000003, 15.799999999999963, -143.80000000000064, 20.000000000000014, 57.800000000000225, 20.000000000000014, -199.90000000000046, -294.7, -131.20000000000005, -305.5, -144.10000000000002, -97.60000000000004, -248.50000000000009, 20.000000000000014, -101.80000000000004, -375.7, 3.1999999999999615, -87.10000000000004, -121.90000000000046, 20.000000000000014, -177.4000000000001, 64.1000000000002, 20.000000000000014, 9.199999999999983, 20.000000000000014, -151.9, 20.000000000000014, -19.89999999999977, -234.10000000000002, -290.79999999999995, 9.499999999999964, 20.000000000000014, -61.30000000000002, -36.70000000000003, 20.000000000000014, 5.299999999999965, -206.80000000000052, -246.70000000000041, -119.20000000000009, -32.49999999999975, 20.000000000000014, -386.5, -183.7000000000001, -108.10000000000004, -0.9999999999999846, 15.799999999999963, -184.89999999999998, 30.800000000000207, 20.000000000000014, 20.000000000000014, -17.79999999999974, -228.09999999999994, -242.50000000000014, 57.800000000000225, 20.000000000000014, 20.000000000000014, -75.10000000000085, 9.800000000000063, -72.40000000000089, 30.800000000000196, 15.79999999999996, -42.99999999999978, -229.30000000000027, -169.00000000000003, -233.5, -215.1999999999999, -105.9999999999998, -319.0, -74.50000000000088, -187.59999999999994, 29.90000000000018, 20.000000000000014, -45.09999999999976, -148.00000000000048, -145.90000000000012, -160.60000000000002, -194.20000000000002, -163.3000000000005, -115.00000000000065, 1.0999999999999688, -103.60000000000025, 20.000000000000014, 20.000000000000014, -186.10000000000028, 20.000000000000014, -234.10000000000045, 20.000000000000014, 20.000000000000014, -274.9, -297.0999999999989, -112.30000000000078, -91.30000000000072, 20.000000000000014, -286.6, -34.59999999999977, 63.200000000000216, -214.30000000000018, -247.3, -221.50000000000037, -332.8, 20.000000000000014, -273.99999999999875, -169.0, 20.000000000000014, 20.000000000000014, -136.30000000000032, 20.000000000000014, -284.5, -230.20000000000002, -208.90000000000003, 20.000000000000014, -26.19999999999981, -91.30000000000004, 20.000000000000014, 32.60000000000023, 20.000000000000014, 20.000000000000014, 43.40000000000025], "policy_predator_policy_reward": [118.0, 159.0, 154.0, 0.0, 124.0, 180.0, 67.0, 46.0, 95.0, 7.0, 105.0, 19.0, 24.0, 145.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 148.0, 0.0, 165.0, 0.0, 158.0, 64.0, 21.0, 0.0, 189.0, 0.0, 92.0, 0.0, 105.0, 0.0, 27.0, 0.0, 0.0, 46.0, 0.0, 64.0, 3.0, 0.0, 186.0, 185.0, 7.0, 50.0, 80.0, 16.0, 0.0, 29.0, 27.0, 94.0, 13.0, 0.0, 0.0, 26.0, 0.0, 169.0, 0.0, 11.0, 32.0, 67.0, 91.0, 84.0, 14.0, 55.0, 27.0, 11.0, 0.0, 0.0, 0.0, 175.0, 87.0, 0.0, 200.0, 0.0, 0.0, 127.0, 18.0, 182.0, 176.0, 166.0, 2.0, 90.0, 29.0, 64.0, 0.0, 0.0, 190.0, 18.0, 79.0, 155.0, 92.0, 46.0, 23.0, 107.0, 189.0, 62.0, 0.0, 59.0, 0.0, 68.0, 0.0, 94.0, 0.0, 21.0, 0.0, 99.0, 0.0, 19.0, 151.0, 71.0, 5.0, 0.0, 0.0, 49.0, 7.0, 0.0, 20.0, 134.0, 99.0, 0.0, 120.0, 110.0, 134.0, 67.0, 2.0, 10.0, 98.0, 116.0, 0.0, 0.0, 146.0, 0.0, 0.0, 125.0, 0.0, 0.0, 57.0, 0.0, 44.0, 20.0, 0.0, 32.0, 86.0, 164.0, 98.0, 131.0, 29.0, 173.0, 3.0, 154.0, 0.0, 0.0, 0.0, 111.0, 110.0, 0.0, 0.0, 182.0, 66.0, 25.0, 7.0, 54.0, 84.0, 82.0, 110.0, 32.0, 0.0, 0.0, 200.0, 0.0, 75.0, 3.0, 36.0, 110.0, 26.0, 0.0, 58.0, 123.0, 175.0, 11.0, 115.0, 25.0, 86.0, 4.0, 0.0, 92.0, 114.0, 73.0, 77.0, 120.0, 31.0, 0.0, 26.0, 53.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.373637496340693, "mean_inference_ms": 3.864381741321701, "mean_action_processing_ms": 0.6458902464545969, "mean_env_wait_ms": 0.46139374822553114, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01517951488494873, "StateBufferConnector_ms": 0.00436246395111084, "ViewRequirementAgentConnector_ms": 0.22349131107330322}, "num_episodes": 18, "episode_return_max": 77.7999999999995, "episode_return_min": -420.9999999999977, "episode_return_mean": -79.60999999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.4503002682081, "num_env_steps_trained_throughput_per_sec": 210.4503002682081, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 210303.819, "restore_workers_time_ms": 0.03, "training_step_time_ms": 210303.727, "sample_time_ms": 3572.809, "learn_time_ms": 206697.699, "learn_throughput": 19.352, "synch_weights_time_ms": 29.619}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "3a355_00000", "date": "2024-08-13_02-15-11", "timestamp": 1723529711, "time_this_iter_s": 19.0507550239563, "time_total_s": 3918.119388103485, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df6c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3918.119388103485, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 88.54074074074073, "ram_util_percent": 83.54074074074073}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3770824187203611, "cur_kl_coeff": 4.76837158203125e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.402364097196589, "policy_loss": -0.0021291694768936073, "vf_loss": 3.404493271106135, "vf_explained_var": 0.0019311940859234522, "kl": 0.0026351683576779222, "entropy": 0.28584305737069043, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6792314066536843, "cur_kl_coeff": 0.015820312499999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8706810899512476, "policy_loss": -0.002080228507873558, "vf_loss": 3.872403016039934, "vf_explained_var": -0.005339782389383468, "kl": 0.022647559563124222, "entropy": 1.0331701784222214, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 77.7999999999995, "episode_reward_min": -420.9999999999977, "episode_reward_mean": -66.87199999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.1000000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -85.89100000000002, "predator_policy": 52.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-8.199999999999747, -30.39999999999985, 73.59999999999978, -114.89999999999989, 24.099999999999973, -65.59999999999997, 8.100000000000243, -58.89999999999971, 58.100000000000435, 11.400000000000079, -420.9999999999977, 61.20000000000035, -68.9, 56.30000000000037, -23.299999999999798, 17.099999999999948, 55.30000000000052, -331.5999999999999, -28.699999999999676, -151.20000000000036, -138.70000000000113, -203.10000000000065, -245.9000000000002, -61.200000000000415, -30.799999999999628, 77.7999999999995, -286.59999999999945, -202.69999999999993, -103.69999999999978, -98.50000000000051, -226.50000000000023, -24.899999999999963, -33.89999999999976, -19.29999999999975, 50.20000000000046, -32.89999999999983, 19.099999999999973, -302.89999999999986, 34.50000000000022, -48.99999999999969, 32.30000000000018, -299.49999999999704, -52.699999999999854, -136.50000000000063, -90.79999999999998, 26.800000000000086, 59.90000000000008, 40.0000000000003, -99.90000000000018, -59.69999999999976, 40.0000000000003, -8.299999999999773, 22.400000000000034, 4.800000000000107, -148.30000000000027, -219.69999999999985, -223.00000000000034, -105.1000000000002, 49.90000000000046, -82.10000000000107, -196.50000000000023, -175.50000000000043, -22.89999999999963, -22.599999999999902, -0.09999999999999537, -72.10000000000068, 40.0000000000003, -371.99999999999886, -125.60000000000147, -120.6000000000003, 54.600000000000435, -280.59999999999945, -368.29999999999836, -114.00000000000091, -58.99999999999996, -24.299999999999734, -77.49999999999997, -242.0999999999999, 24.800000000000097, 7.700000000000154, 52.60000000000051, 63.4000000000005, -63.40000000000016, -193.20000000000107, 23.700000000000045, -88.80000000000003, -14.999999999999686, -155.50000000000082, 49.00000000000045, -251.09999999999974, 50.70000000000048, 40.0000000000003, -0.2999999999999492, 35.30000000000023, 21.299999999999994, -40.499999999999844, 4.800000000000093, 28.00000000000025, 40.0000000000003, -75.60000000000102], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999946, -65.79999999999998, 20.000000000000014, -114.40000000000003, 20.000000000000014, 50.600000000000215, -124.90000000000003, -361.0, -52.899999999999885, 20.000000000000014, 20.000000000000014, -181.59999999999994, 20.000000000000014, -40.90000000000003, -122.20000000000044, -57.69999999999981, 20.000000000000014, 25.100000000000108, -26.19999999999996, 11.599999999999953, -334.8999999999993, -255.09999999999872, 30.200000000000177, 20.000000000000014, -175.3, 7.399999999999965, -138.6999999999999, 20.000000000000014, 20.000000000000014, -112.30000000000032, -40.89999999999976, 20.000000000000014, 35.30000000000026, 20.000000000000014, -343.3000000000002, -163.29999999999993, -131.50000000000048, 15.799999999999962, -81.40000000000002, -269.7999999999986, -246.7000000000003, -18.999999999999787, -366.4, -36.699999999999754, -297.1, -290.7999999999993, -169.0000000000003, 15.799999999999963, -143.80000000000064, 20.000000000000014, 57.800000000000225, 20.000000000000014, -199.90000000000046, -294.7, -131.20000000000005, -305.5, -144.10000000000002, -97.60000000000004, -248.50000000000009, 20.000000000000014, -101.80000000000004, -375.7, 3.1999999999999615, -87.10000000000004, -121.90000000000046, 20.000000000000014, -177.4000000000001, 64.1000000000002, 20.000000000000014, 9.199999999999983, 20.000000000000014, -151.9, 20.000000000000014, -19.89999999999977, -234.10000000000002, -290.79999999999995, 9.499999999999964, 20.000000000000014, -61.30000000000002, -36.70000000000003, 20.000000000000014, 5.299999999999965, -206.80000000000052, -246.70000000000041, -119.20000000000009, -32.49999999999975, 20.000000000000014, -386.5, -183.7000000000001, -108.10000000000004, -0.9999999999999846, 15.799999999999963, -184.89999999999998, 30.800000000000207, 20.000000000000014, 20.000000000000014, -17.79999999999974, -228.09999999999994, -242.50000000000014, 57.800000000000225, 20.000000000000014, 20.000000000000014, -75.10000000000085, 9.800000000000063, -72.40000000000089, 30.800000000000196, 15.79999999999996, -42.99999999999978, -229.30000000000027, -169.00000000000003, -233.5, -215.1999999999999, -105.9999999999998, -319.0, -74.50000000000088, -187.59999999999994, 29.90000000000018, 20.000000000000014, -45.09999999999976, -148.00000000000048, -145.90000000000012, -160.60000000000002, -194.20000000000002, -163.3000000000005, -115.00000000000065, 1.0999999999999688, -103.60000000000025, 20.000000000000014, 20.000000000000014, -186.10000000000028, 20.000000000000014, -234.10000000000045, 20.000000000000014, 20.000000000000014, -274.9, -297.0999999999989, -112.30000000000078, -91.30000000000072, 20.000000000000014, -286.6, -34.59999999999977, 63.200000000000216, -214.30000000000018, -247.3, -221.50000000000037, -332.8, 20.000000000000014, -273.99999999999875, -169.0, 20.000000000000014, 20.000000000000014, -136.30000000000032, 20.000000000000014, -284.5, -230.20000000000002, -208.90000000000003, 20.000000000000014, -26.19999999999981, -91.30000000000004, 20.000000000000014, 32.60000000000023, 20.000000000000014, 20.000000000000014, 43.40000000000025, 24.50000000000008, -271.8999999999994, -299.19999999999925, -48.99999999999979, -19.299999999999763, 20.000000000000014, -70.30000000000004, -74.5000000000001, -78.40000000000057, -13.59999999999979, -21.699999999999797, -374.8, 29.000000000000163, 20.000000000000014, -255.1000000000004, -127.00000000000003, 36.20000000000026, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -154.3000000000006, 25.400000000000098, -0.09999999999999937, 20.000000000000014, -15.699999999999747, -225.4, -108.10000000000056, -47.199999999999974, 20.000000000000014, 20.000000000000014, -42.99999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, -202.60000000000045], "policy_predator_policy_reward": [0.0, 46.0, 0.0, 64.0, 3.0, 0.0, 186.0, 185.0, 7.0, 50.0, 80.0, 16.0, 0.0, 29.0, 27.0, 94.0, 13.0, 0.0, 0.0, 26.0, 0.0, 169.0, 0.0, 11.0, 32.0, 67.0, 91.0, 84.0, 14.0, 55.0, 27.0, 11.0, 0.0, 0.0, 0.0, 175.0, 87.0, 0.0, 200.0, 0.0, 0.0, 127.0, 18.0, 182.0, 176.0, 166.0, 2.0, 90.0, 29.0, 64.0, 0.0, 0.0, 190.0, 18.0, 79.0, 155.0, 92.0, 46.0, 23.0, 107.0, 189.0, 62.0, 0.0, 59.0, 0.0, 68.0, 0.0, 94.0, 0.0, 21.0, 0.0, 99.0, 0.0, 19.0, 151.0, 71.0, 5.0, 0.0, 0.0, 49.0, 7.0, 0.0, 20.0, 134.0, 99.0, 0.0, 120.0, 110.0, 134.0, 67.0, 2.0, 10.0, 98.0, 116.0, 0.0, 0.0, 146.0, 0.0, 0.0, 125.0, 0.0, 0.0, 57.0, 0.0, 44.0, 20.0, 0.0, 32.0, 86.0, 164.0, 98.0, 131.0, 29.0, 173.0, 3.0, 154.0, 0.0, 0.0, 0.0, 111.0, 110.0, 0.0, 0.0, 182.0, 66.0, 25.0, 7.0, 54.0, 84.0, 82.0, 110.0, 32.0, 0.0, 0.0, 200.0, 0.0, 75.0, 3.0, 36.0, 110.0, 26.0, 0.0, 58.0, 123.0, 175.0, 11.0, 115.0, 25.0, 86.0, 4.0, 0.0, 92.0, 114.0, 73.0, 77.0, 120.0, 31.0, 0.0, 26.0, 53.0, 0.0, 0.0, 0.0, 0.0, 102.0, 82.0, 0.0, 155.0, 0.0, 23.0, 48.0, 8.0, 61.0, 16.0, 154.0, 87.0, 0.0, 0.0, 131.0, 0.0, 5.0, 0.0, 0.0, 0.0, 83.0, 51.0, 10.0, 0.0, 0.0, 17.0, 160.0, 133.0, 0.0, 32.0, 51.0, 0.0, 0.0, 0.0, 39.0, 68.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.371418434866631, "mean_inference_ms": 3.860478936572997, "mean_action_processing_ms": 0.6434685312326418, "mean_env_wait_ms": 0.4608096943122031, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007138490676879883, "StateBufferConnector_ms": 0.0048198699951171875, "ViewRequirementAgentConnector_ms": 0.20168185234069824}, "num_episodes": 18, "episode_return_max": 77.7999999999995, "episode_return_min": -420.9999999999977, "episode_return_mean": -66.87199999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.79320793601372, "num_env_steps_trained_throughput_per_sec": 198.79320793601372, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 209935.387, "restore_workers_time_ms": 0.03, "training_step_time_ms": 209935.293, "sample_time_ms": 3494.582, "learn_time_ms": 206404.582, "learn_throughput": 19.379, "synch_weights_time_ms": 32.724}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "3a355_00000", "date": "2024-08-13_02-15-31", "timestamp": 1723529731, "time_this_iter_s": 20.35439896583557, "time_total_s": 3938.4737870693207, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5239430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3938.4737870693207, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 86.9392857142857, "ram_util_percent": 83.60714285714288}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5934093883507466, "cur_kl_coeff": 2.384185791015625e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.578105682040018, "policy_loss": -0.004692008725993296, "vf_loss": 5.582797698116807, "vf_explained_var": 0.002256309260766973, "kl": 0.0038589740254376674, "entropy": 0.35611179538820154, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7486116792159105, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.86333103406997, "policy_loss": -0.00586512786553059, "vf_loss": 5.868532733311729, "vf_explained_var": -0.0007099690260710539, "kl": 0.027956367279024487, "entropy": 1.0296226356710707, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 77.7999999999995, "episode_reward_min": -374.49999999999994, "episode_reward_mean": -76.60099999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.1000000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -93.50050000000003, "predator_policy": 55.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.699999999999676, -151.20000000000036, -138.70000000000113, -203.10000000000065, -245.9000000000002, -61.200000000000415, -30.799999999999628, 77.7999999999995, -286.59999999999945, -202.69999999999993, -103.69999999999978, -98.50000000000051, -226.50000000000023, -24.899999999999963, -33.89999999999976, -19.29999999999975, 50.20000000000046, -32.89999999999983, 19.099999999999973, -302.89999999999986, 34.50000000000022, -48.99999999999969, 32.30000000000018, -299.49999999999704, -52.699999999999854, -136.50000000000063, -90.79999999999998, 26.800000000000086, 59.90000000000008, 40.0000000000003, -99.90000000000018, -59.69999999999976, 40.0000000000003, -8.299999999999773, 22.400000000000034, 4.800000000000107, -148.30000000000027, -219.69999999999985, -223.00000000000034, -105.1000000000002, 49.90000000000046, -82.10000000000107, -196.50000000000023, -175.50000000000043, -22.89999999999963, -22.599999999999902, -0.09999999999999537, -72.10000000000068, 40.0000000000003, -371.99999999999886, -125.60000000000147, -120.6000000000003, 54.600000000000435, -280.59999999999945, -368.29999999999836, -114.00000000000091, -58.99999999999996, -24.299999999999734, -77.49999999999997, -242.0999999999999, 24.800000000000097, 7.700000000000154, 52.60000000000051, 63.4000000000005, -63.40000000000016, -193.20000000000107, 23.700000000000045, -88.80000000000003, -14.999999999999686, -155.50000000000082, 49.00000000000045, -251.09999999999974, 50.70000000000048, 40.0000000000003, -0.2999999999999492, 35.30000000000023, 21.299999999999994, -40.499999999999844, 4.800000000000093, 28.00000000000025, 40.0000000000003, -75.60000000000102, 33.3000000000002, -107.1000000000002, -28.799999999999528, -214.50000000000034, -8.89999999999969, -374.49999999999994, -95.30000000000035, 41.50000000000031, -60.299999999999905, -26.399999999999665, -324.2999999999989, 43.900000000000404, -41.19999999999963, -52.29999999999992, -172.6000000000005, -5.899999999999746, 0.3999999999999866, -337.49999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-131.50000000000048, 15.799999999999962, -81.40000000000002, -269.7999999999986, -246.7000000000003, -18.999999999999787, -366.4, -36.699999999999754, -297.1, -290.7999999999993, -169.0000000000003, 15.799999999999963, -143.80000000000064, 20.000000000000014, 57.800000000000225, 20.000000000000014, -199.90000000000046, -294.7, -131.20000000000005, -305.5, -144.10000000000002, -97.60000000000004, -248.50000000000009, 20.000000000000014, -101.80000000000004, -375.7, 3.1999999999999615, -87.10000000000004, -121.90000000000046, 20.000000000000014, -177.4000000000001, 64.1000000000002, 20.000000000000014, 9.199999999999983, 20.000000000000014, -151.9, 20.000000000000014, -19.89999999999977, -234.10000000000002, -290.79999999999995, 9.499999999999964, 20.000000000000014, -61.30000000000002, -36.70000000000003, 20.000000000000014, 5.299999999999965, -206.80000000000052, -246.70000000000041, -119.20000000000009, -32.49999999999975, 20.000000000000014, -386.5, -183.7000000000001, -108.10000000000004, -0.9999999999999846, 15.799999999999963, -184.89999999999998, 30.800000000000207, 20.000000000000014, 20.000000000000014, -17.79999999999974, -228.09999999999994, -242.50000000000014, 57.800000000000225, 20.000000000000014, 20.000000000000014, -75.10000000000085, 9.800000000000063, -72.40000000000089, 30.800000000000196, 15.79999999999996, -42.99999999999978, -229.30000000000027, -169.00000000000003, -233.5, -215.1999999999999, -105.9999999999998, -319.0, -74.50000000000088, -187.59999999999994, 29.90000000000018, 20.000000000000014, -45.09999999999976, -148.00000000000048, -145.90000000000012, -160.60000000000002, -194.20000000000002, -163.3000000000005, -115.00000000000065, 1.0999999999999688, -103.60000000000025, 20.000000000000014, 20.000000000000014, -186.10000000000028, 20.000000000000014, -234.10000000000045, 20.000000000000014, 20.000000000000014, -274.9, -297.0999999999989, -112.30000000000078, -91.30000000000072, 20.000000000000014, -286.6, -34.59999999999977, 63.200000000000216, -214.30000000000018, -247.3, -221.50000000000037, -332.8, 20.000000000000014, -273.99999999999875, -169.0, 20.000000000000014, 20.000000000000014, -136.30000000000032, 20.000000000000014, -284.5, -230.20000000000002, -208.90000000000003, 20.000000000000014, -26.19999999999981, -91.30000000000004, 20.000000000000014, 32.60000000000023, 20.000000000000014, 20.000000000000014, 43.40000000000025, 24.50000000000008, -271.8999999999994, -299.19999999999925, -48.99999999999979, -19.299999999999763, 20.000000000000014, -70.30000000000004, -74.5000000000001, -78.40000000000057, -13.59999999999979, -21.699999999999797, -374.8, 29.000000000000163, 20.000000000000014, -255.1000000000004, -127.00000000000003, 36.20000000000026, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -154.3000000000006, 25.400000000000098, -0.09999999999999937, 20.000000000000014, -15.699999999999747, -225.4, -108.10000000000056, -47.199999999999974, 20.000000000000014, 20.000000000000014, -42.99999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, -202.60000000000045, 20.000000000000014, -15.699999999999747, -213.10000000000002, -48.999999999999815, -80.80000000000086, -21.999999999999744, -195.7, -185.80000000000038, -58.59999999999986, -28.299999999999777, -356.79999999999995, -204.70000000000002, -151.9000000000004, -261.4, 20.000000000000014, 15.499999999999963, 20.000000000000014, -196.3, 20.000000000000014, -117.40000000000013, -294.09999999999974, -194.20000000000022, -53.79999999999983, -7.299999999999891, -4.90000000000002, -91.30000000000061, -9.400000000000006, -187.90000000000003, -64.89999999999986, -267.7, -17.499999999999766, -30.399999999999793, -55.59999999999983, 20.000000000000014, -284.4999999999998, -255.99999999999957], "policy_predator_policy_reward": [87.0, 0.0, 200.0, 0.0, 0.0, 127.0, 18.0, 182.0, 176.0, 166.0, 2.0, 90.0, 29.0, 64.0, 0.0, 0.0, 190.0, 18.0, 79.0, 155.0, 92.0, 46.0, 23.0, 107.0, 189.0, 62.0, 0.0, 59.0, 0.0, 68.0, 0.0, 94.0, 0.0, 21.0, 0.0, 99.0, 0.0, 19.0, 151.0, 71.0, 5.0, 0.0, 0.0, 49.0, 7.0, 0.0, 20.0, 134.0, 99.0, 0.0, 120.0, 110.0, 134.0, 67.0, 2.0, 10.0, 98.0, 116.0, 0.0, 0.0, 146.0, 0.0, 0.0, 125.0, 0.0, 0.0, 57.0, 0.0, 44.0, 20.0, 0.0, 32.0, 86.0, 164.0, 98.0, 131.0, 29.0, 173.0, 3.0, 154.0, 0.0, 0.0, 0.0, 111.0, 110.0, 0.0, 0.0, 182.0, 66.0, 25.0, 7.0, 54.0, 84.0, 82.0, 110.0, 32.0, 0.0, 0.0, 200.0, 0.0, 75.0, 3.0, 36.0, 110.0, 26.0, 0.0, 58.0, 123.0, 175.0, 11.0, 115.0, 25.0, 86.0, 4.0, 0.0, 92.0, 114.0, 73.0, 77.0, 120.0, 31.0, 0.0, 26.0, 53.0, 0.0, 0.0, 0.0, 0.0, 102.0, 82.0, 0.0, 155.0, 0.0, 23.0, 48.0, 8.0, 61.0, 16.0, 154.0, 87.0, 0.0, 0.0, 131.0, 0.0, 5.0, 0.0, 0.0, 0.0, 83.0, 51.0, 10.0, 0.0, 0.0, 17.0, 160.0, 133.0, 0.0, 32.0, 51.0, 0.0, 0.0, 0.0, 39.0, 68.0, 12.0, 17.0, 3.0, 152.0, 43.0, 31.0, 0.0, 167.0, 55.0, 23.0, 24.0, 163.0, 161.0, 157.0, 6.0, 0.0, 103.0, 13.0, 0.0, 71.0, 148.0, 16.0, 51.0, 54.0, 0.0, 55.0, 46.0, 99.0, 155.0, 5.0, 42.0, 0.0, 36.0, 0.0, 118.0, 85.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3699024895087393, "mean_inference_ms": 3.857659946188129, "mean_action_processing_ms": 0.6414633732358886, "mean_env_wait_ms": 0.46032162261842857, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007078766822814941, "StateBufferConnector_ms": 0.0053005218505859375, "ViewRequirementAgentConnector_ms": 0.17518258094787598}, "num_episodes": 18, "episode_return_max": 77.7999999999995, "episode_return_min": -374.49999999999994, "episode_return_mean": -76.60099999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 197.94106425229106, "num_env_steps_trained_throughput_per_sec": 197.94106425229106, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 111698.986, "restore_workers_time_ms": 0.032, "training_step_time_ms": 111698.885, "sample_time_ms": 3461.065, "learn_time_ms": 108199.872, "learn_throughput": 36.969, "synch_weights_time_ms": 34.813}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "3a355_00000", "date": "2024-08-13_02-15-52", "timestamp": 1723529752, "time_this_iter_s": 20.29045581817627, "time_total_s": 3958.764242887497, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5239e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3958.764242887497, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 87.19655172413795, "ram_util_percent": 83.5103448275862}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5093125517090792, "cur_kl_coeff": 1.1920928955078126e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.484867628541573, "policy_loss": -0.002020069951851847, "vf_loss": 3.4868876994602265, "vf_explained_var": 0.0064195722499221725, "kl": 0.002969788757130975, "entropy": 0.3997559806341847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6660701804887996, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.686417694571157, "policy_loss": -0.003867053252487153, "vf_loss": 3.689652424893051, "vf_explained_var": -5.821377512008425e-05, "kl": 0.017764278844435284, "entropy": 0.9522385878537698, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 63.4000000000005, "episode_reward_min": -374.49999999999994, "episode_reward_mean": -68.68299999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -386.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 63.200000000000216, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -87.25150000000004, "predator_policy": 52.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.30000000000018, -299.49999999999704, -52.699999999999854, -136.50000000000063, -90.79999999999998, 26.800000000000086, 59.90000000000008, 40.0000000000003, -99.90000000000018, -59.69999999999976, 40.0000000000003, -8.299999999999773, 22.400000000000034, 4.800000000000107, -148.30000000000027, -219.69999999999985, -223.00000000000034, -105.1000000000002, 49.90000000000046, -82.10000000000107, -196.50000000000023, -175.50000000000043, -22.89999999999963, -22.599999999999902, -0.09999999999999537, -72.10000000000068, 40.0000000000003, -371.99999999999886, -125.60000000000147, -120.6000000000003, 54.600000000000435, -280.59999999999945, -368.29999999999836, -114.00000000000091, -58.99999999999996, -24.299999999999734, -77.49999999999997, -242.0999999999999, 24.800000000000097, 7.700000000000154, 52.60000000000051, 63.4000000000005, -63.40000000000016, -193.20000000000107, 23.700000000000045, -88.80000000000003, -14.999999999999686, -155.50000000000082, 49.00000000000045, -251.09999999999974, 50.70000000000048, 40.0000000000003, -0.2999999999999492, 35.30000000000023, 21.299999999999994, -40.499999999999844, 4.800000000000093, 28.00000000000025, 40.0000000000003, -75.60000000000102, 33.3000000000002, -107.1000000000002, -28.799999999999528, -214.50000000000034, -8.89999999999969, -374.49999999999994, -95.30000000000035, 41.50000000000031, -60.299999999999905, -26.399999999999665, -324.2999999999989, 43.900000000000404, -41.19999999999963, -52.29999999999992, -172.6000000000005, -5.899999999999746, 0.3999999999999866, -337.49999999999926, -352.99999999999875, 2.6000000000002297, 44.50000000000036, -25.70000000000004, -48.19999999999977, -55.99999999999971, -84.29999999999978, -58.1000000000006, 56.200000000000514, 18.100000000000236, -58.999999999999964, -78.99999999999986, 5.900000000000235, -2.89999999999983, -44.699999999999875, 40.0000000000003, -154.10000000000045, -42.49999999999966, -163.0000000000003, -68.90000000000083, -170.00000000000065, -24.99999999999975], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 5.299999999999965, -206.80000000000052, -246.70000000000041, -119.20000000000009, -32.49999999999975, 20.000000000000014, -386.5, -183.7000000000001, -108.10000000000004, -0.9999999999999846, 15.799999999999963, -184.89999999999998, 30.800000000000207, 20.000000000000014, 20.000000000000014, -17.79999999999974, -228.09999999999994, -242.50000000000014, 57.800000000000225, 20.000000000000014, 20.000000000000014, -75.10000000000085, 9.800000000000063, -72.40000000000089, 30.800000000000196, 15.79999999999996, -42.99999999999978, -229.30000000000027, -169.00000000000003, -233.5, -215.1999999999999, -105.9999999999998, -319.0, -74.50000000000088, -187.59999999999994, 29.90000000000018, 20.000000000000014, -45.09999999999976, -148.00000000000048, -145.90000000000012, -160.60000000000002, -194.20000000000002, -163.3000000000005, -115.00000000000065, 1.0999999999999688, -103.60000000000025, 20.000000000000014, 20.000000000000014, -186.10000000000028, 20.000000000000014, -234.10000000000045, 20.000000000000014, 20.000000000000014, -274.9, -297.0999999999989, -112.30000000000078, -91.30000000000072, 20.000000000000014, -286.6, -34.59999999999977, 63.200000000000216, -214.30000000000018, -247.3, -221.50000000000037, -332.8, 20.000000000000014, -273.99999999999875, -169.0, 20.000000000000014, 20.000000000000014, -136.30000000000032, 20.000000000000014, -284.5, -230.20000000000002, -208.90000000000003, 20.000000000000014, -26.19999999999981, -91.30000000000004, 20.000000000000014, 32.60000000000023, 20.000000000000014, 20.000000000000014, 43.40000000000025, 24.50000000000008, -271.8999999999994, -299.19999999999925, -48.99999999999979, -19.299999999999763, 20.000000000000014, -70.30000000000004, -74.5000000000001, -78.40000000000057, -13.59999999999979, -21.699999999999797, -374.8, 29.000000000000163, 20.000000000000014, -255.1000000000004, -127.00000000000003, 36.20000000000026, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -154.3000000000006, 25.400000000000098, -0.09999999999999937, 20.000000000000014, -15.699999999999747, -225.4, -108.10000000000056, -47.199999999999974, 20.000000000000014, 20.000000000000014, -42.99999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, -202.60000000000045, 20.000000000000014, -15.699999999999747, -213.10000000000002, -48.999999999999815, -80.80000000000086, -21.999999999999744, -195.7, -185.80000000000038, -58.59999999999986, -28.299999999999777, -356.79999999999995, -204.70000000000002, -151.9000000000004, -261.4, 20.000000000000014, 15.499999999999963, 20.000000000000014, -196.3, 20.000000000000014, -117.40000000000013, -294.09999999999974, -194.20000000000022, -53.79999999999983, -7.299999999999891, -4.90000000000002, -91.30000000000061, -9.400000000000006, -187.90000000000003, -64.89999999999986, -267.7, -17.499999999999766, -30.399999999999793, -55.59999999999983, 20.000000000000014, -284.4999999999998, -255.99999999999957, -358.2999999999997, -204.70000000000024, -3.099999999999958, -7.299999999999891, 20.000000000000014, 24.50000000000008, -225.40000000000003, -4.299999999999958, -149.20000000000036, 20.000000000000014, -9.999999999999881, -148.00000000000003, 20.000000000000014, -217.3000000000005, 20.000000000000014, -171.1000000000005, 20.000000000000014, 36.20000000000026, -34.899999999999785, 20.000000000000014, -158.50000000000006, 9.499999999999964, -271.9, -45.09999999999976, 20.000000000000014, -45.10000000000003, -70.90000000000074, 20.000000000000014, -13.599999999999786, -108.10000000000024, 20.000000000000014, 20.000000000000014, -202.60000000000002, -74.50000000000047, -160.9, 25.400000000000098, -5.200000000000003, -335.8, 20.000000000000014, -187.90000000000038, -233.50000000000043, -218.50000000000023, -227.80000000000047, 30.800000000000196], "policy_predator_policy_reward": [7.0, 0.0, 20.0, 134.0, 99.0, 0.0, 120.0, 110.0, 134.0, 67.0, 2.0, 10.0, 98.0, 116.0, 0.0, 0.0, 146.0, 0.0, 0.0, 125.0, 0.0, 0.0, 57.0, 0.0, 44.0, 20.0, 0.0, 32.0, 86.0, 164.0, 98.0, 131.0, 29.0, 173.0, 3.0, 154.0, 0.0, 0.0, 0.0, 111.0, 110.0, 0.0, 0.0, 182.0, 66.0, 25.0, 7.0, 54.0, 84.0, 82.0, 110.0, 32.0, 0.0, 0.0, 200.0, 0.0, 75.0, 3.0, 36.0, 110.0, 26.0, 0.0, 58.0, 123.0, 175.0, 11.0, 115.0, 25.0, 86.0, 4.0, 0.0, 92.0, 114.0, 73.0, 77.0, 120.0, 31.0, 0.0, 26.0, 53.0, 0.0, 0.0, 0.0, 0.0, 102.0, 82.0, 0.0, 155.0, 0.0, 23.0, 48.0, 8.0, 61.0, 16.0, 154.0, 87.0, 0.0, 0.0, 131.0, 0.0, 5.0, 0.0, 0.0, 0.0, 83.0, 51.0, 10.0, 0.0, 0.0, 17.0, 160.0, 133.0, 0.0, 32.0, 51.0, 0.0, 0.0, 0.0, 39.0, 68.0, 12.0, 17.0, 3.0, 152.0, 43.0, 31.0, 0.0, 167.0, 55.0, 23.0, 24.0, 163.0, 161.0, 157.0, 6.0, 0.0, 103.0, 13.0, 0.0, 71.0, 148.0, 16.0, 51.0, 54.0, 0.0, 55.0, 46.0, 99.0, 155.0, 5.0, 42.0, 0.0, 36.0, 0.0, 118.0, 85.0, 76.0, 134.0, 0.0, 13.0, 0.0, 0.0, 81.0, 123.0, 0.0, 81.0, 102.0, 0.0, 71.0, 42.0, 4.0, 89.0, 0.0, 0.0, 0.0, 33.0, 0.0, 90.0, 104.0, 134.0, 31.0, 0.0, 0.0, 48.0, 0.0, 77.0, 0.0, 0.0, 5.0, 118.0, 93.0, 0.0, 0.0, 178.0, 99.0, 0.0, 153.0, 129.0, 92.0, 80.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3684427831297683, "mean_inference_ms": 3.854793540338006, "mean_action_processing_ms": 0.639290458444791, "mean_env_wait_ms": 0.4597943178225218, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006216168403625488, "StateBufferConnector_ms": 0.005442142486572266, "ViewRequirementAgentConnector_ms": 0.18689608573913574}, "num_episodes": 22, "episode_return_max": 63.4000000000005, "episode_return_min": -374.49999999999994, "episode_return_mean": -68.68299999999991, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 191.98162016784153, "num_env_steps_trained_throughput_per_sec": 191.98162016784153, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 111890.379, "restore_workers_time_ms": 0.034, "training_step_time_ms": 111890.274, "sample_time_ms": 3416.412, "learn_time_ms": 108435.911, "learn_throughput": 36.888, "synch_weights_time_ms": 34.788}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "3a355_00000", "date": "2024-08-13_02-16-13", "timestamp": 1723529773, "time_this_iter_s": 20.91030788421631, "time_total_s": 3979.6745507717133, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5239550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3979.6745507717133, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 87.15172413793103, "ram_util_percent": 83.5551724137931}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4636257622371275, "cur_kl_coeff": 5.960464477539063e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1479822683586645, "policy_loss": -0.00215084114821539, "vf_loss": 3.150133117166146, "vf_explained_var": 0.004898971855325043, "kl": 0.002762825933922758, "entropy": 0.3499581614814738, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8072815962845371, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.892162957141008, "policy_loss": -0.0044526983176914866, "vf_loss": 2.896037102691711, "vf_explained_var": -0.0022650456933117416, "kl": 0.0162532190268556, "entropy": 1.053789163928814, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 63.4000000000005, "episode_reward_min": -374.49999999999994, "episode_reward_mean": -60.386999999999965, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -374.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 63.200000000000216, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -78.87850000000003, "predator_policy": 48.685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.599999999999902, -0.09999999999999537, -72.10000000000068, 40.0000000000003, -371.99999999999886, -125.60000000000147, -120.6000000000003, 54.600000000000435, -280.59999999999945, -368.29999999999836, -114.00000000000091, -58.99999999999996, -24.299999999999734, -77.49999999999997, -242.0999999999999, 24.800000000000097, 7.700000000000154, 52.60000000000051, 63.4000000000005, -63.40000000000016, -193.20000000000107, 23.700000000000045, -88.80000000000003, -14.999999999999686, -155.50000000000082, 49.00000000000045, -251.09999999999974, 50.70000000000048, 40.0000000000003, -0.2999999999999492, 35.30000000000023, 21.299999999999994, -40.499999999999844, 4.800000000000093, 28.00000000000025, 40.0000000000003, -75.60000000000102, 33.3000000000002, -107.1000000000002, -28.799999999999528, -214.50000000000034, -8.89999999999969, -374.49999999999994, -95.30000000000035, 41.50000000000031, -60.299999999999905, -26.399999999999665, -324.2999999999989, 43.900000000000404, -41.19999999999963, -52.29999999999992, -172.6000000000005, -5.899999999999746, 0.3999999999999866, -337.49999999999926, -352.99999999999875, 2.6000000000002297, 44.50000000000036, -25.70000000000004, -48.19999999999977, -55.99999999999971, -84.29999999999978, -58.1000000000006, 56.200000000000514, 18.100000000000236, -58.999999999999964, -78.99999999999986, 5.900000000000235, -2.89999999999983, -44.699999999999875, 40.0000000000003, -154.10000000000045, -42.49999999999966, -163.0000000000003, -68.90000000000083, -170.00000000000065, -24.99999999999975, 40.0000000000003, 57.40000000000049, 17.999999999999936, 2.4000000000002153, -50.799999999999926, 25.400000000000077, -93.40000000000023, -40.29999999999979, -137.00000000000074, -16.499999999999808, 27.900000000000116, 40.0000000000003, -63.4000000000007, -65.6000000000009, -121.40000000000055, -72.30000000000018, -50.89999999999993, -20.499999999999837, -110.40000000000066, 4.900000000000066, -115.40000000000103, -9.499999999999797, -63.399999999999835], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-103.60000000000025, 20.000000000000014, 20.000000000000014, -186.10000000000028, 20.000000000000014, -234.10000000000045, 20.000000000000014, 20.000000000000014, -274.9, -297.0999999999989, -112.30000000000078, -91.30000000000072, 20.000000000000014, -286.6, -34.59999999999977, 63.200000000000216, -214.30000000000018, -247.3, -221.50000000000037, -332.8, 20.000000000000014, -273.99999999999875, -169.0, 20.000000000000014, 20.000000000000014, -136.30000000000032, 20.000000000000014, -284.5, -230.20000000000002, -208.90000000000003, 20.000000000000014, -26.19999999999981, -91.30000000000004, 20.000000000000014, 32.60000000000023, 20.000000000000014, 20.000000000000014, 43.40000000000025, 24.50000000000008, -271.8999999999994, -299.19999999999925, -48.99999999999979, -19.299999999999763, 20.000000000000014, -70.30000000000004, -74.5000000000001, -78.40000000000057, -13.59999999999979, -21.699999999999797, -374.8, 29.000000000000163, 20.000000000000014, -255.1000000000004, -127.00000000000003, 36.20000000000026, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -154.3000000000006, 25.400000000000098, -0.09999999999999937, 20.000000000000014, -15.699999999999747, -225.4, -108.10000000000056, -47.199999999999974, 20.000000000000014, 20.000000000000014, -42.99999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, -202.60000000000045, 20.000000000000014, -15.699999999999747, -213.10000000000002, -48.999999999999815, -80.80000000000086, -21.999999999999744, -195.7, -185.80000000000038, -58.59999999999986, -28.299999999999777, -356.79999999999995, -204.70000000000002, -151.9000000000004, -261.4, 20.000000000000014, 15.499999999999963, 20.000000000000014, -196.3, 20.000000000000014, -117.40000000000013, -294.09999999999974, -194.20000000000022, -53.79999999999983, -7.299999999999891, -4.90000000000002, -91.30000000000061, -9.400000000000006, -187.90000000000003, -64.89999999999986, -267.7, -17.499999999999766, -30.399999999999793, -55.59999999999983, 20.000000000000014, -284.4999999999998, -255.99999999999957, -358.2999999999997, -204.70000000000024, -3.099999999999958, -7.299999999999891, 20.000000000000014, 24.50000000000008, -225.40000000000003, -4.299999999999958, -149.20000000000036, 20.000000000000014, -9.999999999999881, -148.00000000000003, 20.000000000000014, -217.3000000000005, 20.000000000000014, -171.1000000000005, 20.000000000000014, 36.20000000000026, -34.899999999999785, 20.000000000000014, -158.50000000000006, 9.499999999999964, -271.9, -45.09999999999976, 20.000000000000014, -45.10000000000003, -70.90000000000074, 20.000000000000014, -13.599999999999786, -108.10000000000024, 20.000000000000014, 20.000000000000014, -202.60000000000002, -74.50000000000047, -160.9, 25.400000000000098, -5.200000000000003, -335.8, 20.000000000000014, -187.90000000000038, -233.50000000000043, -218.50000000000023, -227.80000000000047, 30.800000000000196, 20.000000000000014, 20.000000000000014, 34.40000000000024, 20.000000000000014, -21.999999999999744, 20.000000000000014, -36.699999999999754, 1.0999999999999865, -38.19999999999982, -160.60000000000045, -34.59999999999975, 20.000000000000014, -49.29999999999976, -150.1, 20.000000000000014, -133.30000000000038, -89.50000000000037, -110.50000000000043, 20.000000000000014, -197.50000000000026, -3.0999999999999686, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -177.40000000000035, -154.00000000000043, -13.599999999999818, -153.10000000000028, -133.30000000000035, 20.000000000000014, -238.3000000000001, -169.90000000000046, 20.000000000000014, 20.000000000000014, -95.50000000000009, 13.699999999999973, -276.0999999999992, -99.1000000000004, 20.000000000000014, -140.5000000000003, -103.90000000000069, 20.000000000000014, -74.50000000000064, -72.40000000000052, -85.00000000000003], "policy_predator_policy_reward": [7.0, 54.0, 84.0, 82.0, 110.0, 32.0, 0.0, 0.0, 200.0, 0.0, 75.0, 3.0, 36.0, 110.0, 26.0, 0.0, 58.0, 123.0, 175.0, 11.0, 115.0, 25.0, 86.0, 4.0, 0.0, 92.0, 114.0, 73.0, 77.0, 120.0, 31.0, 0.0, 26.0, 53.0, 0.0, 0.0, 0.0, 0.0, 102.0, 82.0, 0.0, 155.0, 0.0, 23.0, 48.0, 8.0, 61.0, 16.0, 154.0, 87.0, 0.0, 0.0, 131.0, 0.0, 5.0, 0.0, 0.0, 0.0, 83.0, 51.0, 10.0, 0.0, 0.0, 17.0, 160.0, 133.0, 0.0, 32.0, 51.0, 0.0, 0.0, 0.0, 39.0, 68.0, 12.0, 17.0, 3.0, 152.0, 43.0, 31.0, 0.0, 167.0, 55.0, 23.0, 24.0, 163.0, 161.0, 157.0, 6.0, 0.0, 103.0, 13.0, 0.0, 71.0, 148.0, 16.0, 51.0, 54.0, 0.0, 55.0, 46.0, 99.0, 155.0, 5.0, 42.0, 0.0, 36.0, 0.0, 118.0, 85.0, 76.0, 134.0, 0.0, 13.0, 0.0, 0.0, 81.0, 123.0, 0.0, 81.0, 102.0, 0.0, 71.0, 42.0, 4.0, 89.0, 0.0, 0.0, 0.0, 33.0, 0.0, 90.0, 104.0, 134.0, 31.0, 0.0, 0.0, 48.0, 0.0, 77.0, 0.0, 0.0, 5.0, 118.0, 93.0, 0.0, 0.0, 178.0, 99.0, 0.0, 153.0, 129.0, 92.0, 80.0, 0.0, 0.0, 3.0, 0.0, 20.0, 0.0, 16.0, 22.0, 64.0, 84.0, 24.0, 16.0, 88.0, 18.0, 0.0, 73.0, 1.0, 62.0, 110.0, 51.0, 0.0, 11.0, 0.0, 0.0, 94.0, 0.0, 98.0, 4.0, 74.0, 91.0, 75.0, 71.0, 81.0, 18.0, 55.0, 0.0, 58.0, 94.0, 35.0, 49.0, 9.0, 120.0, 0.0, 45.0, 94.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.36817446318012, "mean_inference_ms": 3.853272754526139, "mean_action_processing_ms": 0.6372316107662181, "mean_env_wait_ms": 0.4593970373926151, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0069615840911865234, "StateBufferConnector_ms": 0.005198359489440918, "ViewRequirementAgentConnector_ms": 0.19301795959472656}, "num_episodes": 23, "episode_return_max": 63.4000000000005, "episode_return_min": -374.49999999999994, "episode_return_mean": -60.386999999999965, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.97634452263478, "num_env_steps_trained_throughput_per_sec": 199.97634452263478, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 19346.232, "restore_workers_time_ms": 0.034, "training_step_time_ms": 19346.128, "sample_time_ms": 3334.358, "learn_time_ms": 15978.558, "learn_throughput": 250.335, "synch_weights_time_ms": 29.783}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "3a355_00000", "date": "2024-08-13_02-16-33", "timestamp": 1723529793, "time_this_iter_s": 20.048969984054565, "time_total_s": 3999.723520755768, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5097e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 3999.723520755768, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 84.23103448275862, "ram_util_percent": 83.56206896551724}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5087638962698519, "cur_kl_coeff": 2.9802322387695314e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.17935363830082, "policy_loss": -0.002430388808654493, "vf_loss": 3.1817840216651794, "vf_explained_var": 0.005360312878139435, "kl": 0.0025859584828109, "entropy": 0.4633174827174535, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7986957822763731, "cur_kl_coeff": 0.03559570312499998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.046916441311912, "policy_loss": -0.004117685850345032, "vf_loss": 3.0502425399406876, "vf_explained_var": 0.0015675199725640513, "kl": 0.02223826970229667, "entropy": 1.1151199283423248, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 63.4000000000005, "episode_reward_min": -374.49999999999994, "episode_reward_mean": -46.14199999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -374.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 43.40000000000025, "predator_policy": 178.0}, "policy_reward_mean": {"prey_policy": -67.56100000000005, "predator_policy": 44.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [63.4000000000005, -63.40000000000016, -193.20000000000107, 23.700000000000045, -88.80000000000003, -14.999999999999686, -155.50000000000082, 49.00000000000045, -251.09999999999974, 50.70000000000048, 40.0000000000003, -0.2999999999999492, 35.30000000000023, 21.299999999999994, -40.499999999999844, 4.800000000000093, 28.00000000000025, 40.0000000000003, -75.60000000000102, 33.3000000000002, -107.1000000000002, -28.799999999999528, -214.50000000000034, -8.89999999999969, -374.49999999999994, -95.30000000000035, 41.50000000000031, -60.299999999999905, -26.399999999999665, -324.2999999999989, 43.900000000000404, -41.19999999999963, -52.29999999999992, -172.6000000000005, -5.899999999999746, 0.3999999999999866, -337.49999999999926, -352.99999999999875, 2.6000000000002297, 44.50000000000036, -25.70000000000004, -48.19999999999977, -55.99999999999971, -84.29999999999978, -58.1000000000006, 56.200000000000514, 18.100000000000236, -58.999999999999964, -78.99999999999986, 5.900000000000235, -2.89999999999983, -44.699999999999875, 40.0000000000003, -154.10000000000045, -42.49999999999966, -163.0000000000003, -68.90000000000083, -170.00000000000065, -24.99999999999975, 40.0000000000003, 57.40000000000049, 17.999999999999936, 2.4000000000002153, -50.799999999999926, 25.400000000000077, -93.40000000000023, -40.29999999999979, -137.00000000000074, -16.499999999999808, 27.900000000000116, 40.0000000000003, -63.4000000000007, -65.6000000000009, -121.40000000000055, -72.30000000000018, -50.89999999999993, -20.499999999999837, -110.40000000000066, 4.900000000000066, -115.40000000000103, -9.499999999999797, -63.399999999999835, 40.0000000000003, -10.4, 25.70000000000007, 8.100000000000046, 40.0000000000003, -66.00000000000003, -88.80000000000142, 17.3, -80.3000000000005, -60.09999999999983, -51.09999999999991, 29.50000000000018, 35.30000000000023, 51.70000000000049, -247.60000000000025, -5.599999999999804, 55.30000000000051, 32.40000000000019], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 43.40000000000025, 24.50000000000008, -271.8999999999994, -299.19999999999925, -48.99999999999979, -19.299999999999763, 20.000000000000014, -70.30000000000004, -74.5000000000001, -78.40000000000057, -13.59999999999979, -21.699999999999797, -374.8, 29.000000000000163, 20.000000000000014, -255.1000000000004, -127.00000000000003, 36.20000000000026, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -154.3000000000006, 25.400000000000098, -0.09999999999999937, 20.000000000000014, -15.699999999999747, -225.4, -108.10000000000056, -47.199999999999974, 20.000000000000014, 20.000000000000014, -42.99999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, -202.60000000000045, 20.000000000000014, -15.699999999999747, -213.10000000000002, -48.999999999999815, -80.80000000000086, -21.999999999999744, -195.7, -185.80000000000038, -58.59999999999986, -28.299999999999777, -356.79999999999995, -204.70000000000002, -151.9000000000004, -261.4, 20.000000000000014, 15.499999999999963, 20.000000000000014, -196.3, 20.000000000000014, -117.40000000000013, -294.09999999999974, -194.20000000000022, -53.79999999999983, -7.299999999999891, -4.90000000000002, -91.30000000000061, -9.400000000000006, -187.90000000000003, -64.89999999999986, -267.7, -17.499999999999766, -30.399999999999793, -55.59999999999983, 20.000000000000014, -284.4999999999998, -255.99999999999957, -358.2999999999997, -204.70000000000024, -3.099999999999958, -7.299999999999891, 20.000000000000014, 24.50000000000008, -225.40000000000003, -4.299999999999958, -149.20000000000036, 20.000000000000014, -9.999999999999881, -148.00000000000003, 20.000000000000014, -217.3000000000005, 20.000000000000014, -171.1000000000005, 20.000000000000014, 36.20000000000026, -34.899999999999785, 20.000000000000014, -158.50000000000006, 9.499999999999964, -271.9, -45.09999999999976, 20.000000000000014, -45.10000000000003, -70.90000000000074, 20.000000000000014, -13.599999999999786, -108.10000000000024, 20.000000000000014, 20.000000000000014, -202.60000000000002, -74.50000000000047, -160.9, 25.400000000000098, -5.200000000000003, -335.8, 20.000000000000014, -187.90000000000038, -233.50000000000043, -218.50000000000023, -227.80000000000047, 30.800000000000196, 20.000000000000014, 20.000000000000014, 34.40000000000024, 20.000000000000014, -21.999999999999744, 20.000000000000014, -36.699999999999754, 1.0999999999999865, -38.19999999999982, -160.60000000000045, -34.59999999999975, 20.000000000000014, -49.29999999999976, -150.1, 20.000000000000014, -133.30000000000038, -89.50000000000037, -110.50000000000043, 20.000000000000014, -197.50000000000026, -3.0999999999999686, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -177.40000000000035, -154.00000000000043, -13.599999999999818, -153.10000000000028, -133.30000000000035, 20.000000000000014, -238.3000000000001, -169.90000000000046, 20.000000000000014, 20.000000000000014, -95.50000000000009, 13.699999999999973, -276.0999999999992, -99.1000000000004, 20.000000000000014, -140.5000000000003, -103.90000000000069, 20.000000000000014, -74.50000000000064, -72.40000000000052, -85.00000000000003, 20.000000000000014, 20.000000000000014, -38.79999999999983, -34.599999999999774, -7.299999999999891, 20.000000000000014, -11.499999999999858, -9.399999999999855, 20.000000000000014, 20.000000000000014, -118.60000000000062, -135.40000000000012, -94.30000000000072, -137.5000000000007, -7.299999999999891, 11.599999999999964, -93.40000000000022, -40.89999999999994, -292.9, 3.7999999999999763, -137.50000000000017, -13.599999999999783, 20.000000000000014, -20.4999999999998, 20.000000000000014, 5.299999999999969, 31.700000000000212, 20.000000000000014, -208.90000000000012, -204.7000000000001, -65.80000000000072, 3.1999999999999615, 20.000000000000014, 35.30000000000025, -55.600000000000335, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 102.0, 82.0, 0.0, 155.0, 0.0, 23.0, 48.0, 8.0, 61.0, 16.0, 154.0, 87.0, 0.0, 0.0, 131.0, 0.0, 5.0, 0.0, 0.0, 0.0, 83.0, 51.0, 10.0, 0.0, 0.0, 17.0, 160.0, 133.0, 0.0, 32.0, 51.0, 0.0, 0.0, 0.0, 39.0, 68.0, 12.0, 17.0, 3.0, 152.0, 43.0, 31.0, 0.0, 167.0, 55.0, 23.0, 24.0, 163.0, 161.0, 157.0, 6.0, 0.0, 103.0, 13.0, 0.0, 71.0, 148.0, 16.0, 51.0, 54.0, 0.0, 55.0, 46.0, 99.0, 155.0, 5.0, 42.0, 0.0, 36.0, 0.0, 118.0, 85.0, 76.0, 134.0, 0.0, 13.0, 0.0, 0.0, 81.0, 123.0, 0.0, 81.0, 102.0, 0.0, 71.0, 42.0, 4.0, 89.0, 0.0, 0.0, 0.0, 33.0, 0.0, 90.0, 104.0, 134.0, 31.0, 0.0, 0.0, 48.0, 0.0, 77.0, 0.0, 0.0, 5.0, 118.0, 93.0, 0.0, 0.0, 178.0, 99.0, 0.0, 153.0, 129.0, 92.0, 80.0, 0.0, 0.0, 3.0, 0.0, 20.0, 0.0, 16.0, 22.0, 64.0, 84.0, 24.0, 16.0, 88.0, 18.0, 0.0, 73.0, 1.0, 62.0, 110.0, 51.0, 0.0, 11.0, 0.0, 0.0, 94.0, 0.0, 98.0, 4.0, 74.0, 91.0, 75.0, 71.0, 81.0, 18.0, 55.0, 0.0, 58.0, 94.0, 35.0, 49.0, 9.0, 120.0, 0.0, 45.0, 94.0, 0.0, 0.0, 0.0, 56.0, 7.0, 0.0, 13.0, 29.0, 0.0, 0.0, 0.0, 124.0, 64.0, 66.0, 77.0, 13.0, 0.0, 54.0, 0.0, 81.0, 148.0, 15.0, 85.0, 30.0, 0.0, 10.0, 0.0, 0.0, 0.0, 85.0, 81.0, 5.0, 52.0, 0.0, 0.0, 36.0, 32.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3686636355260573, "mean_inference_ms": 3.8538548163973303, "mean_action_processing_ms": 0.6360390510335696, "mean_env_wait_ms": 0.4591822041839103, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011667728424072266, "StateBufferConnector_ms": 0.005751132965087891, "ViewRequirementAgentConnector_ms": 0.2062091827392578}, "num_episodes": 18, "episode_return_max": 63.4000000000005, "episode_return_min": -374.49999999999994, "episode_return_mean": -46.14199999999995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 3.807584286936918, "num_env_steps_trained_throughput_per_sec": 3.807584286936918, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 122479.517, "restore_workers_time_ms": 0.023, "training_step_time_ms": 122479.43, "sample_time_ms": 2978.754, "learn_time_ms": 119463.438, "learn_throughput": 33.483, "synch_weights_time_ms": 33.253}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "3a355_00000", "date": "2024-08-13_02-34-03", "timestamp": 1723530843, "time_this_iter_s": 1050.6916768550873, "time_total_s": 5050.415197610855, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5075940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5050.415197610855, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 85.30588235294117, "ram_util_percent": 83.65588235294119}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5071198882544955, "cur_kl_coeff": 1.4901161193847657e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8524401077517756, "policy_loss": -0.002369859087325278, "vf_loss": 2.85480995815267, "vf_explained_var": 0.006290553612683816, "kl": 0.0023443393117772156, "entropy": 0.3845197229473679, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7223560247392882, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.752804865597417, "policy_loss": -0.006479599054350897, "vf_loss": 2.75755792780528, "vf_explained_var": 0.0013108616783505393, "kl": 0.032336133507116435, "entropy": 1.1371508663293546, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 57.40000000000049, "episode_reward_min": -374.49999999999994, "episode_reward_mean": -45.76599999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -358.2999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 37.10000000000025, "predator_policy": 178.0}, "policy_reward_mean": {"prey_policy": -67.67800000000007, "predator_policy": 44.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-75.60000000000102, 33.3000000000002, -107.1000000000002, -28.799999999999528, -214.50000000000034, -8.89999999999969, -374.49999999999994, -95.30000000000035, 41.50000000000031, -60.299999999999905, -26.399999999999665, -324.2999999999989, 43.900000000000404, -41.19999999999963, -52.29999999999992, -172.6000000000005, -5.899999999999746, 0.3999999999999866, -337.49999999999926, -352.99999999999875, 2.6000000000002297, 44.50000000000036, -25.70000000000004, -48.19999999999977, -55.99999999999971, -84.29999999999978, -58.1000000000006, 56.200000000000514, 18.100000000000236, -58.999999999999964, -78.99999999999986, 5.900000000000235, -2.89999999999983, -44.699999999999875, 40.0000000000003, -154.10000000000045, -42.49999999999966, -163.0000000000003, -68.90000000000083, -170.00000000000065, -24.99999999999975, 40.0000000000003, 57.40000000000049, 17.999999999999936, 2.4000000000002153, -50.799999999999926, 25.400000000000077, -93.40000000000023, -40.29999999999979, -137.00000000000074, -16.499999999999808, 27.900000000000116, 40.0000000000003, -63.4000000000007, -65.6000000000009, -121.40000000000055, -72.30000000000018, -50.89999999999993, -20.499999999999837, -110.40000000000066, 4.900000000000066, -115.40000000000103, -9.499999999999797, -63.399999999999835, 40.0000000000003, -10.4, 25.70000000000007, 8.100000000000046, 40.0000000000003, -66.00000000000003, -88.80000000000142, 17.3, -80.3000000000005, -60.09999999999983, -51.09999999999991, 29.50000000000018, 35.30000000000023, 51.70000000000049, -247.60000000000025, -5.599999999999804, 55.30000000000051, 32.40000000000019, -48.99999999999977, -20.499999999999638, -62.00000000000085, -237.50000000000074, 48.300000000000495, -33.29999999999967, -55.499999999999815, 48.500000000000355, 40.0000000000003, -91.30000000000035, 1.4999999999999265, -15.799999999999555, 52.60000000000051, -23.399999999999565, 11.599999999999971, -4.5999999999997225, 40.0000000000003, -63.60000000000176], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -202.60000000000045, 20.000000000000014, -15.699999999999747, -213.10000000000002, -48.999999999999815, -80.80000000000086, -21.999999999999744, -195.7, -185.80000000000038, -58.59999999999986, -28.299999999999777, -356.79999999999995, -204.70000000000002, -151.9000000000004, -261.4, 20.000000000000014, 15.499999999999963, 20.000000000000014, -196.3, 20.000000000000014, -117.40000000000013, -294.09999999999974, -194.20000000000022, -53.79999999999983, -7.299999999999891, -4.90000000000002, -91.30000000000061, -9.400000000000006, -187.90000000000003, -64.89999999999986, -267.7, -17.499999999999766, -30.399999999999793, -55.59999999999983, 20.000000000000014, -284.4999999999998, -255.99999999999957, -358.2999999999997, -204.70000000000024, -3.099999999999958, -7.299999999999891, 20.000000000000014, 24.50000000000008, -225.40000000000003, -4.299999999999958, -149.20000000000036, 20.000000000000014, -9.999999999999881, -148.00000000000003, 20.000000000000014, -217.3000000000005, 20.000000000000014, -171.1000000000005, 20.000000000000014, 36.20000000000026, -34.899999999999785, 20.000000000000014, -158.50000000000006, 9.499999999999964, -271.9, -45.09999999999976, 20.000000000000014, -45.10000000000003, -70.90000000000074, 20.000000000000014, -13.599999999999786, -108.10000000000024, 20.000000000000014, 20.000000000000014, -202.60000000000002, -74.50000000000047, -160.9, 25.400000000000098, -5.200000000000003, -335.8, 20.000000000000014, -187.90000000000038, -233.50000000000043, -218.50000000000023, -227.80000000000047, 30.800000000000196, 20.000000000000014, 20.000000000000014, 34.40000000000024, 20.000000000000014, -21.999999999999744, 20.000000000000014, -36.699999999999754, 1.0999999999999865, -38.19999999999982, -160.60000000000045, -34.59999999999975, 20.000000000000014, -49.29999999999976, -150.1, 20.000000000000014, -133.30000000000038, -89.50000000000037, -110.50000000000043, 20.000000000000014, -197.50000000000026, -3.0999999999999686, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -177.40000000000035, -154.00000000000043, -13.599999999999818, -153.10000000000028, -133.30000000000035, 20.000000000000014, -238.3000000000001, -169.90000000000046, 20.000000000000014, 20.000000000000014, -95.50000000000009, 13.699999999999973, -276.0999999999992, -99.1000000000004, 20.000000000000014, -140.5000000000003, -103.90000000000069, 20.000000000000014, -74.50000000000064, -72.40000000000052, -85.00000000000003, 20.000000000000014, 20.000000000000014, -38.79999999999983, -34.599999999999774, -7.299999999999891, 20.000000000000014, -11.499999999999858, -9.399999999999855, 20.000000000000014, 20.000000000000014, -118.60000000000062, -135.40000000000012, -94.30000000000072, -137.5000000000007, -7.299999999999891, 11.599999999999964, -93.40000000000022, -40.89999999999994, -292.9, 3.7999999999999763, -137.50000000000017, -13.599999999999783, 20.000000000000014, -20.4999999999998, 20.000000000000014, 5.299999999999969, 31.700000000000212, 20.000000000000014, -208.90000000000012, -204.7000000000001, -65.80000000000072, 3.1999999999999615, 20.000000000000014, 35.30000000000025, -55.600000000000335, 20.000000000000014, 1.7000000000000834, -120.70000000000064, 20.000000000000014, -95.50000000000064, -61.90000000000057, -81.10000000000045, -237.10000000000034, -198.40000000000038, 37.10000000000025, -38.799999999999756, -128.20000000000047, -24.099999999999746, -15.699999999999747, -227.80000000000027, -82.90000000000046, -1.6000000000000334, 20.000000000000014, 20.000000000000014, -232.3000000000002, 20.000000000000014, -53.49999999999986, 20.000000000000014, -89.80000000000081, 20.000000000000014, 32.60000000000023, 20.000000000000014, -34.59999999999975, -68.80000000000075, -117.10000000000058, -70.30000000000041, -7.299999999999919, -28.29999999999975, 20.000000000000014, 20.000000000000014, -97.60000000000082, -21.99999999999976], "policy_predator_policy_reward": [39.0, 68.0, 12.0, 17.0, 3.0, 152.0, 43.0, 31.0, 0.0, 167.0, 55.0, 23.0, 24.0, 163.0, 161.0, 157.0, 6.0, 0.0, 103.0, 13.0, 0.0, 71.0, 148.0, 16.0, 51.0, 54.0, 0.0, 55.0, 46.0, 99.0, 155.0, 5.0, 42.0, 0.0, 36.0, 0.0, 118.0, 85.0, 76.0, 134.0, 0.0, 13.0, 0.0, 0.0, 81.0, 123.0, 0.0, 81.0, 102.0, 0.0, 71.0, 42.0, 4.0, 89.0, 0.0, 0.0, 0.0, 33.0, 0.0, 90.0, 104.0, 134.0, 31.0, 0.0, 0.0, 48.0, 0.0, 77.0, 0.0, 0.0, 5.0, 118.0, 93.0, 0.0, 0.0, 178.0, 99.0, 0.0, 153.0, 129.0, 92.0, 80.0, 0.0, 0.0, 3.0, 0.0, 20.0, 0.0, 16.0, 22.0, 64.0, 84.0, 24.0, 16.0, 88.0, 18.0, 0.0, 73.0, 1.0, 62.0, 110.0, 51.0, 0.0, 11.0, 0.0, 0.0, 94.0, 0.0, 98.0, 4.0, 74.0, 91.0, 75.0, 71.0, 81.0, 18.0, 55.0, 0.0, 58.0, 94.0, 35.0, 49.0, 9.0, 120.0, 0.0, 45.0, 94.0, 0.0, 0.0, 0.0, 56.0, 7.0, 0.0, 13.0, 29.0, 0.0, 0.0, 0.0, 124.0, 64.0, 66.0, 77.0, 13.0, 0.0, 54.0, 0.0, 81.0, 148.0, 15.0, 85.0, 30.0, 0.0, 10.0, 0.0, 0.0, 0.0, 85.0, 81.0, 5.0, 52.0, 0.0, 0.0, 36.0, 32.0, 35.0, 35.0, 2.0, 53.0, 81.0, 0.0, 146.0, 52.0, 28.0, 22.0, 48.0, 71.0, 108.0, 80.0, 70.0, 63.0, 0.0, 0.0, 67.0, 54.0, 12.0, 23.0, 54.0, 0.0, 0.0, 0.0, 11.0, 69.0, 107.0, 92.0, 31.0, 0.0, 0.0, 0.0, 0.0, 56.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3737497105016745, "mean_inference_ms": 3.86551046738642, "mean_action_processing_ms": 0.63620760407764, "mean_env_wait_ms": 0.46036348517740533, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011841773986816406, "StateBufferConnector_ms": 0.005366802215576172, "ViewRequirementAgentConnector_ms": 0.22078442573547363}, "num_episodes": 18, "episode_return_max": 57.40000000000049, "episode_return_min": -374.49999999999994, "episode_return_mean": -45.76599999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 157.23640717570225, "num_env_steps_trained_throughput_per_sec": 157.23640717570225, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 123319.798, "restore_workers_time_ms": 0.022, "training_step_time_ms": 123319.526, "sample_time_ms": 3095.006, "learn_time_ms": 120189.358, "learn_throughput": 33.281, "synch_weights_time_ms": 30.859}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "3a355_00000", "date": "2024-08-13_02-34-29", "timestamp": 1723530869, "time_this_iter_s": 25.56462597846985, "time_total_s": 5075.979823589325, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5240700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5075.979823589325, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 93.91666666666667, "ram_util_percent": 83.42500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43024539614401797, "cur_kl_coeff": 7.450580596923829e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5569002914681005, "policy_loss": -0.0007503378333119804, "vf_loss": 2.55765062299355, "vf_explained_var": 0.006009680158877499, "kl": 0.0020479215295919136, "entropy": 0.3345694833331638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7886620007455349, "cur_kl_coeff": 0.08009033203125002, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2901900452280803, "policy_loss": -0.004206092404349456, "vf_loss": 2.2927646724004593, "vf_explained_var": 0.008552035736659216, "kl": 0.0203703040909524, "entropy": 1.1492325722855865, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 57.40000000000049, "episode_reward_min": -247.60000000000025, "episode_reward_mean": -24.742999999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -335.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 41.60000000000025, "predator_policy": 178.0}, "policy_reward_mean": {"prey_policy": -51.74650000000009, "predator_policy": 39.375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-25.70000000000004, -48.19999999999977, -55.99999999999971, -84.29999999999978, -58.1000000000006, 56.200000000000514, 18.100000000000236, -58.999999999999964, -78.99999999999986, 5.900000000000235, -2.89999999999983, -44.699999999999875, 40.0000000000003, -154.10000000000045, -42.49999999999966, -163.0000000000003, -68.90000000000083, -170.00000000000065, -24.99999999999975, 40.0000000000003, 57.40000000000049, 17.999999999999936, 2.4000000000002153, -50.799999999999926, 25.400000000000077, -93.40000000000023, -40.29999999999979, -137.00000000000074, -16.499999999999808, 27.900000000000116, 40.0000000000003, -63.4000000000007, -65.6000000000009, -121.40000000000055, -72.30000000000018, -50.89999999999993, -20.499999999999837, -110.40000000000066, 4.900000000000066, -115.40000000000103, -9.499999999999797, -63.399999999999835, 40.0000000000003, -10.4, 25.70000000000007, 8.100000000000046, 40.0000000000003, -66.00000000000003, -88.80000000000142, 17.3, -80.3000000000005, -60.09999999999983, -51.09999999999991, 29.50000000000018, 35.30000000000023, 51.70000000000049, -247.60000000000025, -5.599999999999804, 55.30000000000051, 32.40000000000019, -48.99999999999977, -20.499999999999638, -62.00000000000085, -237.50000000000074, 48.300000000000495, -33.29999999999967, -55.499999999999815, 48.500000000000355, 40.0000000000003, -91.30000000000035, 1.4999999999999265, -15.799999999999555, 52.60000000000051, -23.399999999999565, 11.599999999999971, -4.5999999999997225, 40.0000000000003, -63.60000000000176, -25.499999999999588, -55.40000000000056, -13.899999999999732, 9.700000000000033, 9.499999999999963, 32.100000000000264, -78.80000000000088, 7.9999999999999885, 15.999999999999982, 9.199999999999918, 43.10000000000043, 5.900000000000139, -96.20000000000036, 24.200000000000113, 40.0000000000003, 20.199999999999974, 40.0000000000003, -29.499999999999638, -9.19999999999994, 53.00000000000045, -52.09999999999968, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-225.40000000000003, -4.299999999999958, -149.20000000000036, 20.000000000000014, -9.999999999999881, -148.00000000000003, 20.000000000000014, -217.3000000000005, 20.000000000000014, -171.1000000000005, 20.000000000000014, 36.20000000000026, -34.899999999999785, 20.000000000000014, -158.50000000000006, 9.499999999999964, -271.9, -45.09999999999976, 20.000000000000014, -45.10000000000003, -70.90000000000074, 20.000000000000014, -13.599999999999786, -108.10000000000024, 20.000000000000014, 20.000000000000014, -202.60000000000002, -74.50000000000047, -160.9, 25.400000000000098, -5.200000000000003, -335.8, 20.000000000000014, -187.90000000000038, -233.50000000000043, -218.50000000000023, -227.80000000000047, 30.800000000000196, 20.000000000000014, 20.000000000000014, 34.40000000000024, 20.000000000000014, -21.999999999999744, 20.000000000000014, -36.699999999999754, 1.0999999999999865, -38.19999999999982, -160.60000000000045, -34.59999999999975, 20.000000000000014, -49.29999999999976, -150.1, 20.000000000000014, -133.30000000000038, -89.50000000000037, -110.50000000000043, 20.000000000000014, -197.50000000000026, -3.0999999999999686, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -177.40000000000035, -154.00000000000043, -13.599999999999818, -153.10000000000028, -133.30000000000035, 20.000000000000014, -238.3000000000001, -169.90000000000046, 20.000000000000014, 20.000000000000014, -95.50000000000009, 13.699999999999973, -276.0999999999992, -99.1000000000004, 20.000000000000014, -140.5000000000003, -103.90000000000069, 20.000000000000014, -74.50000000000064, -72.40000000000052, -85.00000000000003, 20.000000000000014, 20.000000000000014, -38.79999999999983, -34.599999999999774, -7.299999999999891, 20.000000000000014, -11.499999999999858, -9.399999999999855, 20.000000000000014, 20.000000000000014, -118.60000000000062, -135.40000000000012, -94.30000000000072, -137.5000000000007, -7.299999999999891, 11.599999999999964, -93.40000000000022, -40.89999999999994, -292.9, 3.7999999999999763, -137.50000000000017, -13.599999999999783, 20.000000000000014, -20.4999999999998, 20.000000000000014, 5.299999999999969, 31.700000000000212, 20.000000000000014, -208.90000000000012, -204.7000000000001, -65.80000000000072, 3.1999999999999615, 20.000000000000014, 35.30000000000025, -55.600000000000335, 20.000000000000014, 1.7000000000000834, -120.70000000000064, 20.000000000000014, -95.50000000000064, -61.90000000000057, -81.10000000000045, -237.10000000000034, -198.40000000000038, 37.10000000000025, -38.799999999999756, -128.20000000000047, -24.099999999999746, -15.699999999999747, -227.80000000000027, -82.90000000000046, -1.6000000000000334, 20.000000000000014, 20.000000000000014, -232.3000000000002, 20.000000000000014, -53.49999999999986, 20.000000000000014, -89.80000000000081, 20.000000000000014, 32.60000000000023, 20.000000000000014, -34.59999999999975, -68.80000000000075, -117.10000000000058, -70.30000000000041, -7.299999999999919, -28.29999999999975, 20.000000000000014, 20.000000000000014, -97.60000000000082, -21.99999999999976, -12.39999999999983, -108.10000000000073, -80.80000000000067, -118.60000000000049, 20.000000000000014, -82.9000000000006, -42.99999999999976, 22.700000000000053, -52.59999999999988, -103.90000000000039, -15.699999999999829, 30.800000000000196, -206.80000000000052, 20.000000000000014, -106.0000000000007, 20.000000000000014, 15.799999999999963, -17.79999999999974, 6.49999999999998, -43.29999999999976, 41.60000000000025, -74.5000000000008, -45.09999999999976, 20.000000000000014, 26.900000000000126, -255.1000000000004, -13.899999999999832, -25.89999999999982, 20.000000000000014, 20.000000000000014, -17.79999999999974, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.30000000000067, 24.80000000000011, 13.999999999999968, -89.20000000000026, 33.50000000000024, -5.499999999999989, -101.80000000000032, -49.299999999999805, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [81.0, 123.0, 0.0, 81.0, 102.0, 0.0, 71.0, 42.0, 4.0, 89.0, 0.0, 0.0, 0.0, 33.0, 0.0, 90.0, 104.0, 134.0, 31.0, 0.0, 0.0, 48.0, 0.0, 77.0, 0.0, 0.0, 5.0, 118.0, 93.0, 0.0, 0.0, 178.0, 99.0, 0.0, 153.0, 129.0, 92.0, 80.0, 0.0, 0.0, 3.0, 0.0, 20.0, 0.0, 16.0, 22.0, 64.0, 84.0, 24.0, 16.0, 88.0, 18.0, 0.0, 73.0, 1.0, 62.0, 110.0, 51.0, 0.0, 11.0, 0.0, 0.0, 94.0, 0.0, 98.0, 4.0, 74.0, 91.0, 75.0, 71.0, 81.0, 18.0, 55.0, 0.0, 58.0, 94.0, 35.0, 49.0, 9.0, 120.0, 0.0, 45.0, 94.0, 0.0, 0.0, 0.0, 56.0, 7.0, 0.0, 13.0, 29.0, 0.0, 0.0, 0.0, 124.0, 64.0, 66.0, 77.0, 13.0, 0.0, 54.0, 0.0, 81.0, 148.0, 15.0, 85.0, 30.0, 0.0, 10.0, 0.0, 0.0, 0.0, 85.0, 81.0, 5.0, 52.0, 0.0, 0.0, 36.0, 32.0, 35.0, 35.0, 2.0, 53.0, 81.0, 0.0, 146.0, 52.0, 28.0, 22.0, 48.0, 71.0, 108.0, 80.0, 70.0, 63.0, 0.0, 0.0, 67.0, 54.0, 12.0, 23.0, 54.0, 0.0, 0.0, 0.0, 11.0, 69.0, 107.0, 92.0, 31.0, 0.0, 0.0, 0.0, 0.0, 56.0, 37.0, 58.0, 76.0, 68.0, 49.0, 0.0, 15.0, 15.0, 80.0, 86.0, 17.0, 0.0, 74.0, 34.0, 60.0, 34.0, 0.0, 18.0, 3.0, 43.0, 31.0, 45.0, 31.0, 0.0, 86.0, 46.0, 44.0, 20.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 35.0, 44.0, 47.0, 19.0, 25.0, 0.0, 98.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3785944227018638, "mean_inference_ms": 3.8723766813213434, "mean_action_processing_ms": 0.63613453032913, "mean_env_wait_ms": 0.46133919961862274, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011319875717163086, "StateBufferConnector_ms": 0.0047969818115234375, "ViewRequirementAgentConnector_ms": 0.2002929449081421}, "num_episodes": 22, "episode_return_max": 57.40000000000049, "episode_return_min": -247.60000000000025, "episode_return_mean": -24.742999999999988, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 264.8798236750697, "num_env_steps_trained_throughput_per_sec": 264.8798236750697, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 123011.471, "restore_workers_time_ms": 0.024, "training_step_time_ms": 123011.212, "sample_time_ms": 3065.289, "learn_time_ms": 119911.613, "learn_throughput": 33.358, "synch_weights_time_ms": 29.834}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "3a355_00000", "date": "2024-08-13_02-34-44", "timestamp": 1723530884, "time_this_iter_s": 15.135698080062866, "time_total_s": 5091.115521669388, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b506b040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5091.115521669388, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 80.83333333333333, "ram_util_percent": 83.15238095238094}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3978785778085391, "cur_kl_coeff": 3.7252902984619143e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1047516258463026, "policy_loss": -0.0007464350329307967, "vf_loss": 1.1054980568469517, "vf_explained_var": 0.003482284936955366, "kl": 0.002552969239433254, "entropy": 0.3153645534994741, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8260011767150548, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.339791927372337, "policy_loss": -0.003631000965587282, "vf_loss": 1.3414883563758204, "vf_explained_var": -0.0013936941901212016, "kl": 0.016103239758100754, "entropy": 1.1571715777513212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 65.30000000000037, "episode_reward_min": -247.60000000000025, "episode_reward_mean": -13.37499999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -292.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 42.50000000000025, "predator_policy": 148.0}, "policy_reward_mean": {"prey_policy": -39.45250000000009, "predator_policy": 32.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-24.99999999999975, 40.0000000000003, 57.40000000000049, 17.999999999999936, 2.4000000000002153, -50.799999999999926, 25.400000000000077, -93.40000000000023, -40.29999999999979, -137.00000000000074, -16.499999999999808, 27.900000000000116, 40.0000000000003, -63.4000000000007, -65.6000000000009, -121.40000000000055, -72.30000000000018, -50.89999999999993, -20.499999999999837, -110.40000000000066, 4.900000000000066, -115.40000000000103, -9.499999999999797, -63.399999999999835, 40.0000000000003, -10.4, 25.70000000000007, 8.100000000000046, 40.0000000000003, -66.00000000000003, -88.80000000000142, 17.3, -80.3000000000005, -60.09999999999983, -51.09999999999991, 29.50000000000018, 35.30000000000023, 51.70000000000049, -247.60000000000025, -5.599999999999804, 55.30000000000051, 32.40000000000019, -48.99999999999977, -20.499999999999638, -62.00000000000085, -237.50000000000074, 48.300000000000495, -33.29999999999967, -55.499999999999815, 48.500000000000355, 40.0000000000003, -91.30000000000035, 1.4999999999999265, -15.799999999999555, 52.60000000000051, -23.399999999999565, 11.599999999999971, -4.5999999999997225, 40.0000000000003, -63.60000000000176, -25.499999999999588, -55.40000000000056, -13.899999999999732, 9.700000000000033, 9.499999999999963, 32.100000000000264, -78.80000000000088, 7.9999999999999885, 15.999999999999982, 9.199999999999918, 43.10000000000043, 5.900000000000139, -96.20000000000036, 24.200000000000113, 40.0000000000003, 20.199999999999974, 40.0000000000003, -29.499999999999638, -9.19999999999994, 53.00000000000045, -52.09999999999968, 40.0000000000003, 34.200000000000216, -23.79999999999952, 40.0000000000003, 34.50000000000022, 30.100000000000147, -33.09999999999954, 24.60000000000005, 40.0000000000003, -33.999999999999666, 10.799999999999994, -8.39999999999966, -5.599999999999826, -56.600000000000946, 37.80000000000026, 40.0000000000003, -16.19999999999964, 21.00000000000001, 65.30000000000037], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-227.80000000000047, 30.800000000000196, 20.000000000000014, 20.000000000000014, 34.40000000000024, 20.000000000000014, -21.999999999999744, 20.000000000000014, -36.699999999999754, 1.0999999999999865, -38.19999999999982, -160.60000000000045, -34.59999999999975, 20.000000000000014, -49.29999999999976, -150.1, 20.000000000000014, -133.30000000000038, -89.50000000000037, -110.50000000000043, 20.000000000000014, -197.50000000000026, -3.0999999999999686, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -177.40000000000035, -154.00000000000043, -13.599999999999818, -153.10000000000028, -133.30000000000035, 20.000000000000014, -238.3000000000001, -169.90000000000046, 20.000000000000014, 20.000000000000014, -95.50000000000009, 13.699999999999973, -276.0999999999992, -99.1000000000004, 20.000000000000014, -140.5000000000003, -103.90000000000069, 20.000000000000014, -74.50000000000064, -72.40000000000052, -85.00000000000003, 20.000000000000014, 20.000000000000014, -38.79999999999983, -34.599999999999774, -7.299999999999891, 20.000000000000014, -11.499999999999858, -9.399999999999855, 20.000000000000014, 20.000000000000014, -118.60000000000062, -135.40000000000012, -94.30000000000072, -137.5000000000007, -7.299999999999891, 11.599999999999964, -93.40000000000022, -40.89999999999994, -292.9, 3.7999999999999763, -137.50000000000017, -13.599999999999783, 20.000000000000014, -20.4999999999998, 20.000000000000014, 5.299999999999969, 31.700000000000212, 20.000000000000014, -208.90000000000012, -204.7000000000001, -65.80000000000072, 3.1999999999999615, 20.000000000000014, 35.30000000000025, -55.600000000000335, 20.000000000000014, 1.7000000000000834, -120.70000000000064, 20.000000000000014, -95.50000000000064, -61.90000000000057, -81.10000000000045, -237.10000000000034, -198.40000000000038, 37.10000000000025, -38.799999999999756, -128.20000000000047, -24.099999999999746, -15.699999999999747, -227.80000000000027, -82.90000000000046, -1.6000000000000334, 20.000000000000014, 20.000000000000014, -232.3000000000002, 20.000000000000014, -53.49999999999986, 20.000000000000014, -89.80000000000081, 20.000000000000014, 32.60000000000023, 20.000000000000014, -34.59999999999975, -68.80000000000075, -117.10000000000058, -70.30000000000041, -7.299999999999919, -28.29999999999975, 20.000000000000014, 20.000000000000014, -97.60000000000082, -21.99999999999976, -12.39999999999983, -108.10000000000073, -80.80000000000067, -118.60000000000049, 20.000000000000014, -82.9000000000006, -42.99999999999976, 22.700000000000053, -52.59999999999988, -103.90000000000039, -15.699999999999829, 30.800000000000196, -206.80000000000052, 20.000000000000014, -106.0000000000007, 20.000000000000014, 15.799999999999963, -17.79999999999974, 6.49999999999998, -43.29999999999976, 41.60000000000025, -74.5000000000008, -45.09999999999976, 20.000000000000014, 26.900000000000126, -255.1000000000004, -13.899999999999832, -25.89999999999982, 20.000000000000014, 20.000000000000014, -17.79999999999974, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.30000000000067, 24.80000000000011, 13.999999999999968, -89.20000000000026, 33.50000000000024, -5.499999999999989, -101.80000000000032, -49.299999999999805, 20.000000000000014, 20.000000000000014, 20.000000000000014, -17.79999999999974, -3.099999999999965, -78.70000000000087, 9.199999999999978, 21.80000000000004, 20.000000000000014, 9.499999999999973, 20.000000000000014, 1.0999999999999865, -2.4999999999999964, -76.60000000000088, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, -127.00000000000054, 20.000000000000014, -78.70000000000087, 42.50000000000025, 5.299999999999978, -57.69999999999997, -76.60000000000059, 20.000000000000032, -70.30000000000084, -55.300000000000075, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, -22.899999999999856, -49.29999999999983, 20.000000000000014, -42.99999999999981, 41.30000000000022, 20.000000000000014], "policy_predator_policy_reward": [92.0, 80.0, 0.0, 0.0, 3.0, 0.0, 20.0, 0.0, 16.0, 22.0, 64.0, 84.0, 24.0, 16.0, 88.0, 18.0, 0.0, 73.0, 1.0, 62.0, 110.0, 51.0, 0.0, 11.0, 0.0, 0.0, 94.0, 0.0, 98.0, 4.0, 74.0, 91.0, 75.0, 71.0, 81.0, 18.0, 55.0, 0.0, 58.0, 94.0, 35.0, 49.0, 9.0, 120.0, 0.0, 45.0, 94.0, 0.0, 0.0, 0.0, 56.0, 7.0, 0.0, 13.0, 29.0, 0.0, 0.0, 0.0, 124.0, 64.0, 66.0, 77.0, 13.0, 0.0, 54.0, 0.0, 81.0, 148.0, 15.0, 85.0, 30.0, 0.0, 10.0, 0.0, 0.0, 0.0, 85.0, 81.0, 5.0, 52.0, 0.0, 0.0, 36.0, 32.0, 35.0, 35.0, 2.0, 53.0, 81.0, 0.0, 146.0, 52.0, 28.0, 22.0, 48.0, 71.0, 108.0, 80.0, 70.0, 63.0, 0.0, 0.0, 67.0, 54.0, 12.0, 23.0, 54.0, 0.0, 0.0, 0.0, 11.0, 69.0, 107.0, 92.0, 31.0, 0.0, 0.0, 0.0, 0.0, 56.0, 37.0, 58.0, 76.0, 68.0, 49.0, 0.0, 15.0, 15.0, 80.0, 86.0, 17.0, 0.0, 74.0, 34.0, 60.0, 34.0, 0.0, 18.0, 3.0, 43.0, 31.0, 45.0, 31.0, 0.0, 86.0, 46.0, 44.0, 20.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 35.0, 44.0, 47.0, 19.0, 25.0, 0.0, 98.0, 1.0, 0.0, 0.0, 18.0, 14.0, 11.0, 47.0, 8.0, 1.0, 5.0, 0.0, 9.0, 0.0, 0.0, 46.0, 0.0, 14.0, 0.0, 0.0, 36.0, 37.0, 0.0, 47.0, 26.0, 18.0, 14.0, 37.0, 0.0, 69.0, 2.0, 0.0, 0.0, 0.0, 46.0, 10.0, 30.0, 14.0, 0.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.6126485407800035, "mean_inference_ms": 5.549845504225655, "mean_action_processing_ms": 0.6369652387350156, "mean_env_wait_ms": 0.7068596659746217, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011644601821899414, "StateBufferConnector_ms": 0.004978060722351074, "ViewRequirementAgentConnector_ms": 0.2964988946914673}, "num_episodes": 18, "episode_return_max": 65.30000000000037, "episode_return_min": -247.60000000000025, "episode_return_mean": -13.37499999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 12.095398336939107, "num_env_steps_trained_throughput_per_sec": 12.095398336939107, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 154096.306, "restore_workers_time_ms": 0.023, "training_step_time_ms": 154096.048, "sample_time_ms": 34319.535, "learn_time_ms": 119743.539, "learn_throughput": 33.405, "synch_weights_time_ms": 28.207}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "3a355_00000", "date": "2024-08-13_02-40-15", "timestamp": 1723531215, "time_this_iter_s": 330.7972311973572, "time_total_s": 5421.912752866745, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b50a6310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5421.912752866745, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 86.36904761904762, "ram_util_percent": 83.77142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4747047271865307, "cur_kl_coeff": 1.8626451492309571e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2018156056523954, "policy_loss": -0.00445245679729081, "vf_loss": 1.2062680656080524, "vf_explained_var": 0.003763311754458796, "kl": 0.004274810789797254, "entropy": 0.3149367789427439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9145449737865458, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9844178308254827, "policy_loss": -0.00219692187999725, "vf_loss": 1.9853966386229904, "vf_explained_var": 0.003124090098830127, "kl": 0.01013948943403678, "entropy": 1.1719746684271193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 67.90000000000025, "episode_reward_min": -247.60000000000025, "episode_reward_mean": -3.129999999999912, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -292.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 56.0000000000002, "predator_policy": 148.0}, "policy_reward_mean": {"prey_policy": -28.165000000000063, "predator_policy": 26.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.399999999999835, 40.0000000000003, -10.4, 25.70000000000007, 8.100000000000046, 40.0000000000003, -66.00000000000003, -88.80000000000142, 17.3, -80.3000000000005, -60.09999999999983, -51.09999999999991, 29.50000000000018, 35.30000000000023, 51.70000000000049, -247.60000000000025, -5.599999999999804, 55.30000000000051, 32.40000000000019, -48.99999999999977, -20.499999999999638, -62.00000000000085, -237.50000000000074, 48.300000000000495, -33.29999999999967, -55.499999999999815, 48.500000000000355, 40.0000000000003, -91.30000000000035, 1.4999999999999265, -15.799999999999555, 52.60000000000051, -23.399999999999565, 11.599999999999971, -4.5999999999997225, 40.0000000000003, -63.60000000000176, -25.499999999999588, -55.40000000000056, -13.899999999999732, 9.700000000000033, 9.499999999999963, 32.100000000000264, -78.80000000000088, 7.9999999999999885, 15.999999999999982, 9.199999999999918, 43.10000000000043, 5.900000000000139, -96.20000000000036, 24.200000000000113, 40.0000000000003, 20.199999999999974, 40.0000000000003, -29.499999999999638, -9.19999999999994, 53.00000000000045, -52.09999999999968, 40.0000000000003, 34.200000000000216, -23.79999999999952, 40.0000000000003, 34.50000000000022, 30.100000000000147, -33.09999999999954, 24.60000000000005, 40.0000000000003, -33.999999999999666, 10.799999999999994, -8.39999999999966, -5.599999999999826, -56.600000000000946, 37.80000000000026, 40.0000000000003, -16.19999999999964, 21.00000000000001, 65.30000000000037, -10.199999999999738, 20.90000000000004, 66.80000000000024, -5.099999999999827, -230.9000000000001, 30.10000000000013, 22.700000000000024, -21.099999999999618, 48.10000000000046, -47.700000000000564, 24.700000000000063, 67.90000000000025, 45.70000000000039, 62.40000000000042, 4.300000000000066, 22.00000000000001, 40.0000000000003, 22.70000000000002, -90.4000000000014, 67.00000000000028, 2.600000000000123, 60.20000000000043, 45.40000000000038], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-72.40000000000052, -85.00000000000003, 20.000000000000014, 20.000000000000014, -38.79999999999983, -34.599999999999774, -7.299999999999891, 20.000000000000014, -11.499999999999858, -9.399999999999855, 20.000000000000014, 20.000000000000014, -118.60000000000062, -135.40000000000012, -94.30000000000072, -137.5000000000007, -7.299999999999891, 11.599999999999964, -93.40000000000022, -40.89999999999994, -292.9, 3.7999999999999763, -137.50000000000017, -13.599999999999783, 20.000000000000014, -20.4999999999998, 20.000000000000014, 5.299999999999969, 31.700000000000212, 20.000000000000014, -208.90000000000012, -204.7000000000001, -65.80000000000072, 3.1999999999999615, 20.000000000000014, 35.30000000000025, -55.600000000000335, 20.000000000000014, 1.7000000000000834, -120.70000000000064, 20.000000000000014, -95.50000000000064, -61.90000000000057, -81.10000000000045, -237.10000000000034, -198.40000000000038, 37.10000000000025, -38.799999999999756, -128.20000000000047, -24.099999999999746, -15.699999999999747, -227.80000000000027, -82.90000000000046, -1.6000000000000334, 20.000000000000014, 20.000000000000014, -232.3000000000002, 20.000000000000014, -53.49999999999986, 20.000000000000014, -89.80000000000081, 20.000000000000014, 32.60000000000023, 20.000000000000014, -34.59999999999975, -68.80000000000075, -117.10000000000058, -70.30000000000041, -7.299999999999919, -28.29999999999975, 20.000000000000014, 20.000000000000014, -97.60000000000082, -21.99999999999976, -12.39999999999983, -108.10000000000073, -80.80000000000067, -118.60000000000049, 20.000000000000014, -82.9000000000006, -42.99999999999976, 22.700000000000053, -52.59999999999988, -103.90000000000039, -15.699999999999829, 30.800000000000196, -206.80000000000052, 20.000000000000014, -106.0000000000007, 20.000000000000014, 15.799999999999963, -17.79999999999974, 6.49999999999998, -43.29999999999976, 41.60000000000025, -74.5000000000008, -45.09999999999976, 20.000000000000014, 26.900000000000126, -255.1000000000004, -13.899999999999832, -25.89999999999982, 20.000000000000014, 20.000000000000014, -17.79999999999974, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.30000000000067, 24.80000000000011, 13.999999999999968, -89.20000000000026, 33.50000000000024, -5.499999999999989, -101.80000000000032, -49.299999999999805, 20.000000000000014, 20.000000000000014, 20.000000000000014, -17.79999999999974, -3.099999999999965, -78.70000000000087, 9.199999999999978, 21.80000000000004, 20.000000000000014, 9.499999999999973, 20.000000000000014, 1.0999999999999865, -2.4999999999999964, -76.60000000000088, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, -127.00000000000054, 20.000000000000014, -78.70000000000087, 42.50000000000025, 5.299999999999978, -57.69999999999997, -76.60000000000059, 20.000000000000032, -70.30000000000084, -55.300000000000075, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, -22.899999999999856, -49.29999999999983, 20.000000000000014, -42.99999999999981, 41.30000000000022, 20.000000000000014, 22.700000000000053, -94.90000000000066, 16.699999999999967, -29.799999999999812, 33.2000000000002, 23.600000000000065, -5.7999999999999385, -49.29999999999982, -200.50000000000003, -135.40000000000015, 20.000000000000014, 1.0999999999999759, 20.000000000000014, -22.29999999999975, -51.399999999999935, -12.699999999999878, 3.1999999999999615, 26.900000000000137, -91.30000000000084, -9.399999999999858, 3.4999999999999654, 3.1999999999999704, 38.000000000000256, 29.90000000000018, 13.699999999999964, 29.000000000000163, -34.59999999999977, 56.0000000000002, -42.6999999999998, -0.9999999999999846, 21.800000000000043, -17.79999999999974, 20.000000000000014, 20.000000000000014, -19.899999999999743, 23.600000000000065, -47.199999999999825, -110.2000000000007, 20.90000000000003, 46.10000000000024, 20.000000000000014, -51.399999999999935, 18.8, 25.400000000000098, 25.400000000000098, 20.000000000000014], "policy_predator_policy_reward": [94.0, 0.0, 0.0, 0.0, 56.0, 7.0, 0.0, 13.0, 29.0, 0.0, 0.0, 0.0, 124.0, 64.0, 66.0, 77.0, 13.0, 0.0, 54.0, 0.0, 81.0, 148.0, 15.0, 85.0, 30.0, 0.0, 10.0, 0.0, 0.0, 0.0, 85.0, 81.0, 5.0, 52.0, 0.0, 0.0, 36.0, 32.0, 35.0, 35.0, 2.0, 53.0, 81.0, 0.0, 146.0, 52.0, 28.0, 22.0, 48.0, 71.0, 108.0, 80.0, 70.0, 63.0, 0.0, 0.0, 67.0, 54.0, 12.0, 23.0, 54.0, 0.0, 0.0, 0.0, 11.0, 69.0, 107.0, 92.0, 31.0, 0.0, 0.0, 0.0, 0.0, 56.0, 37.0, 58.0, 76.0, 68.0, 49.0, 0.0, 15.0, 15.0, 80.0, 86.0, 17.0, 0.0, 74.0, 34.0, 60.0, 34.0, 0.0, 18.0, 3.0, 43.0, 31.0, 45.0, 31.0, 0.0, 86.0, 46.0, 44.0, 20.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 35.0, 44.0, 47.0, 19.0, 25.0, 0.0, 98.0, 1.0, 0.0, 0.0, 18.0, 14.0, 11.0, 47.0, 8.0, 1.0, 5.0, 0.0, 9.0, 0.0, 0.0, 46.0, 0.0, 14.0, 0.0, 0.0, 36.0, 37.0, 0.0, 47.0, 26.0, 18.0, 14.0, 37.0, 0.0, 69.0, 2.0, 0.0, 0.0, 0.0, 46.0, 10.0, 30.0, 14.0, 0.0, 4.0, 25.0, 37.0, 32.0, 2.0, 0.0, 10.0, 0.0, 50.0, 105.0, 0.0, 1.0, 8.0, 8.0, 17.0, 0.0, 43.0, 8.0, 10.0, 53.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 3.0, 15.0, 26.0, 10.0, 38.0, 0.0, 18.0, 0.0, 0.0, 19.0, 0.0, 37.0, 30.0, 0.0, 0.0, 0.0, 34.0, 15.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.845709268097118, "mean_inference_ms": 7.666168272363069, "mean_action_processing_ms": 0.6381506988471928, "mean_env_wait_ms": 1.0648241500526987, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011586308479309082, "StateBufferConnector_ms": 0.0054209232330322266, "ViewRequirementAgentConnector_ms": 0.30725622177124023}, "num_episodes": 23, "episode_return_max": 67.90000000000025, "episode_return_min": -247.60000000000025, "episode_return_mean": -3.129999999999912, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 252.66159836967373, "num_env_steps_trained_throughput_per_sec": 252.66159836967373, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 153778.536, "restore_workers_time_ms": 0.023, "training_step_time_ms": 153778.26, "sample_time_ms": 34380.32, "learn_time_ms": 119365.405, "learn_throughput": 33.511, "synch_weights_time_ms": 27.871}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "3a355_00000", "date": "2024-08-13_02-40-31", "timestamp": 1723531231, "time_this_iter_s": 15.880261898040771, "time_total_s": 5437.793014764786, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3ddf430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5437.793014764786, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 85.73636363636365, "ram_util_percent": 83.67272727272729}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3386174838024157, "cur_kl_coeff": 9.313225746154786e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0270153422519643, "policy_loss": -0.0011262165838310486, "vf_loss": 1.028141559479098, "vf_explained_var": 0.001355580898819777, "kl": 0.0021067666580028913, "entropy": 0.2441320111354192, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7440992618758212, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5225090393786709, "policy_loss": -0.0032196884349027953, "vf_loss": 1.524416497302434, "vf_explained_var": 0.0013876025638883075, "kl": 0.01092296069282716, "entropy": 1.1753259853711204, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 99.39999999999819, "episode_reward_min": -237.50000000000074, "episode_reward_mean": 6.7790000000000665, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -255.1000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.500000000000206, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -18.66550000000004, "predator_policy": 22.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.40000000000019, -48.99999999999977, -20.499999999999638, -62.00000000000085, -237.50000000000074, 48.300000000000495, -33.29999999999967, -55.499999999999815, 48.500000000000355, 40.0000000000003, -91.30000000000035, 1.4999999999999265, -15.799999999999555, 52.60000000000051, -23.399999999999565, 11.599999999999971, -4.5999999999997225, 40.0000000000003, -63.60000000000176, -25.499999999999588, -55.40000000000056, -13.899999999999732, 9.700000000000033, 9.499999999999963, 32.100000000000264, -78.80000000000088, 7.9999999999999885, 15.999999999999982, 9.199999999999918, 43.10000000000043, 5.900000000000139, -96.20000000000036, 24.200000000000113, 40.0000000000003, 20.199999999999974, 40.0000000000003, -29.499999999999638, -9.19999999999994, 53.00000000000045, -52.09999999999968, 40.0000000000003, 34.200000000000216, -23.79999999999952, 40.0000000000003, 34.50000000000022, 30.100000000000147, -33.09999999999954, 24.60000000000005, 40.0000000000003, -33.999999999999666, 10.799999999999994, -8.39999999999966, -5.599999999999826, -56.600000000000946, 37.80000000000026, 40.0000000000003, -16.19999999999964, 21.00000000000001, 65.30000000000037, -10.199999999999738, 20.90000000000004, 66.80000000000024, -5.099999999999827, -230.9000000000001, 30.10000000000013, 22.700000000000024, -21.099999999999618, 48.10000000000046, -47.700000000000564, 24.700000000000063, 67.90000000000025, 45.70000000000039, 62.40000000000042, 4.300000000000066, 22.00000000000001, 40.0000000000003, 22.70000000000002, -90.4000000000014, 67.00000000000028, 2.600000000000123, 60.20000000000043, 45.40000000000038, -83.6000000000013, 40.0000000000003, 50.20000000000047, 48.80000000000043, 80.49999999999928, -28.2999999999996, 99.39999999999819, 96.29999999999832, 37.80000000000027, 20.4, 22.90000000000005, 50.7000000000004, -43.49999999999999, 66.10000000000034, 41.800000000000324, 40.0000000000003, 37.4000000000003, 43.60000000000035], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-55.600000000000335, 20.000000000000014, 1.7000000000000834, -120.70000000000064, 20.000000000000014, -95.50000000000064, -61.90000000000057, -81.10000000000045, -237.10000000000034, -198.40000000000038, 37.10000000000025, -38.799999999999756, -128.20000000000047, -24.099999999999746, -15.699999999999747, -227.80000000000027, -82.90000000000046, -1.6000000000000334, 20.000000000000014, 20.000000000000014, -232.3000000000002, 20.000000000000014, -53.49999999999986, 20.000000000000014, -89.80000000000081, 20.000000000000014, 32.60000000000023, 20.000000000000014, -34.59999999999975, -68.80000000000075, -117.10000000000058, -70.30000000000041, -7.299999999999919, -28.29999999999975, 20.000000000000014, 20.000000000000014, -97.60000000000082, -21.99999999999976, -12.39999999999983, -108.10000000000073, -80.80000000000067, -118.60000000000049, 20.000000000000014, -82.9000000000006, -42.99999999999976, 22.700000000000053, -52.59999999999988, -103.90000000000039, -15.699999999999829, 30.800000000000196, -206.80000000000052, 20.000000000000014, -106.0000000000007, 20.000000000000014, 15.799999999999963, -17.79999999999974, 6.49999999999998, -43.29999999999976, 41.60000000000025, -74.5000000000008, -45.09999999999976, 20.000000000000014, 26.900000000000126, -255.1000000000004, -13.899999999999832, -25.89999999999982, 20.000000000000014, 20.000000000000014, -17.79999999999974, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.30000000000067, 24.80000000000011, 13.999999999999968, -89.20000000000026, 33.50000000000024, -5.499999999999989, -101.80000000000032, -49.299999999999805, 20.000000000000014, 20.000000000000014, 20.000000000000014, -17.79999999999974, -3.099999999999965, -78.70000000000087, 9.199999999999978, 21.80000000000004, 20.000000000000014, 9.499999999999973, 20.000000000000014, 1.0999999999999865, -2.4999999999999964, -76.60000000000088, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, -127.00000000000054, 20.000000000000014, -78.70000000000087, 42.50000000000025, 5.299999999999978, -57.69999999999997, -76.60000000000059, 20.000000000000032, -70.30000000000084, -55.300000000000075, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, -22.899999999999856, -49.29999999999983, 20.000000000000014, -42.99999999999981, 41.30000000000022, 20.000000000000014, 22.700000000000053, -94.90000000000066, 16.699999999999967, -29.799999999999812, 33.2000000000002, 23.600000000000065, -5.7999999999999385, -49.29999999999982, -200.50000000000003, -135.40000000000015, 20.000000000000014, 1.0999999999999759, 20.000000000000014, -22.29999999999975, -51.399999999999935, -12.699999999999878, 3.1999999999999615, 26.900000000000137, -91.30000000000084, -9.399999999999858, 3.4999999999999654, 3.1999999999999704, 38.000000000000256, 29.90000000000018, 13.699999999999964, 29.000000000000163, -34.59999999999977, 56.0000000000002, -42.6999999999998, -0.9999999999999846, 21.800000000000043, -17.79999999999974, 20.000000000000014, 20.000000000000014, -19.899999999999743, 23.600000000000065, -47.199999999999825, -110.2000000000007, 20.90000000000003, 46.10000000000024, 20.000000000000014, -51.399999999999935, 18.8, 25.400000000000098, 25.400000000000098, 20.000000000000014, -93.4000000000006, -68.20000000000068, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000134, 20.000000000000014, 9.799999999999983, 60.500000000000206, 20.000000000000014, -25.8999999999998, -30.399999999999785, 57.800000000000225, 41.60000000000024, 53.30000000000022, 41.000000000000206, 20.000000000000014, 15.799999999999963, -34.5999999999998, 20.000000000000014, -0.9999999999999846, -3.100000000000008, -28.29999999999975, 56.000000000000206, -47.19999999999982, -28.29999999999982, 25.400000000000098, 40.70000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.400000000000063, -15.999999999999782, 23.600000000000065, 20.000000000000014], "policy_predator_policy_reward": [36.0, 32.0, 35.0, 35.0, 2.0, 53.0, 81.0, 0.0, 146.0, 52.0, 28.0, 22.0, 48.0, 71.0, 108.0, 80.0, 70.0, 63.0, 0.0, 0.0, 67.0, 54.0, 12.0, 23.0, 54.0, 0.0, 0.0, 0.0, 11.0, 69.0, 107.0, 92.0, 31.0, 0.0, 0.0, 0.0, 0.0, 56.0, 37.0, 58.0, 76.0, 68.0, 49.0, 0.0, 15.0, 15.0, 80.0, 86.0, 17.0, 0.0, 74.0, 34.0, 60.0, 34.0, 0.0, 18.0, 3.0, 43.0, 31.0, 45.0, 31.0, 0.0, 86.0, 46.0, 44.0, 20.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 35.0, 44.0, 47.0, 19.0, 25.0, 0.0, 98.0, 1.0, 0.0, 0.0, 18.0, 14.0, 11.0, 47.0, 8.0, 1.0, 5.0, 0.0, 9.0, 0.0, 0.0, 46.0, 0.0, 14.0, 0.0, 0.0, 36.0, 37.0, 0.0, 47.0, 26.0, 18.0, 14.0, 37.0, 0.0, 69.0, 2.0, 0.0, 0.0, 0.0, 46.0, 10.0, 30.0, 14.0, 0.0, 4.0, 25.0, 37.0, 32.0, 2.0, 0.0, 10.0, 0.0, 50.0, 105.0, 0.0, 1.0, 8.0, 8.0, 17.0, 0.0, 43.0, 8.0, 10.0, 53.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 3.0, 15.0, 26.0, 10.0, 38.0, 0.0, 18.0, 0.0, 0.0, 19.0, 0.0, 37.0, 30.0, 0.0, 0.0, 0.0, 34.0, 15.0, 1.0, 0.0, 0.0, 36.0, 42.0, 0.0, 0.0, 3.0, 0.0, 0.0, 19.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 9.0, 26.0, 6.0, 21.0, 0.0, 23.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.0710902594012794, "mean_inference_ms": 9.28061953611327, "mean_action_processing_ms": 0.6384696747400824, "mean_env_wait_ms": 1.302277018246818, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006788134574890137, "StateBufferConnector_ms": 0.004779219627380371, "ViewRequirementAgentConnector_ms": 0.28818798065185547}, "num_episodes": 18, "episode_return_max": 99.39999999999819, "episode_return_min": -237.50000000000074, "episode_return_mean": 6.7790000000000665, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 265.3214188359778, "num_env_steps_trained_throughput_per_sec": 265.3214188359778, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 153385.455, "restore_workers_time_ms": 0.023, "training_step_time_ms": 153385.18, "sample_time_ms": 34312.794, "learn_time_ms": 119039.76, "learn_throughput": 33.602, "synch_weights_time_ms": 27.511}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "3a355_00000", "date": "2024-08-13_02-40-46", "timestamp": 1723531246, "time_this_iter_s": 15.133251905441284, "time_total_s": 5452.926266670227, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3bda430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5452.926266670227, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 84.14545454545454, "ram_util_percent": 83.5090909090909}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3811939612701141, "cur_kl_coeff": 4.656612873077393e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0896818085953042, "policy_loss": -0.0009041512308632412, "vf_loss": 1.0905859633570625, "vf_explained_var": 0.000661707082122722, "kl": 0.002117517988095067, "entropy": 0.26495350324129935, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7629091695818321, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7081836906059709, "policy_loss": -0.0009038356324983022, "vf_loss": 1.708447683551324, "vf_explained_var": -0.0037363965359945147, "kl": 0.005326006885697457, "entropy": 1.1523384845446027, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 99.39999999999819, "episode_reward_min": -458.69999999999976, "episode_reward_mean": 9.628000000000032, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -311.79999999999984, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.500000000000206, "predator_policy": 158.0}, "policy_reward_mean": {"prey_policy": -12.61600000000001, "predator_policy": 17.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.60000000000176, -25.499999999999588, -55.40000000000056, -13.899999999999732, 9.700000000000033, 9.499999999999963, 32.100000000000264, -78.80000000000088, 7.9999999999999885, 15.999999999999982, 9.199999999999918, 43.10000000000043, 5.900000000000139, -96.20000000000036, 24.200000000000113, 40.0000000000003, 20.199999999999974, 40.0000000000003, -29.499999999999638, -9.19999999999994, 53.00000000000045, -52.09999999999968, 40.0000000000003, 34.200000000000216, -23.79999999999952, 40.0000000000003, 34.50000000000022, 30.100000000000147, -33.09999999999954, 24.60000000000005, 40.0000000000003, -33.999999999999666, 10.799999999999994, -8.39999999999966, -5.599999999999826, -56.600000000000946, 37.80000000000026, 40.0000000000003, -16.19999999999964, 21.00000000000001, 65.30000000000037, -10.199999999999738, 20.90000000000004, 66.80000000000024, -5.099999999999827, -230.9000000000001, 30.10000000000013, 22.700000000000024, -21.099999999999618, 48.10000000000046, -47.700000000000564, 24.700000000000063, 67.90000000000025, 45.70000000000039, 62.40000000000042, 4.300000000000066, 22.00000000000001, 40.0000000000003, 22.70000000000002, -90.4000000000014, 67.00000000000028, 2.600000000000123, 60.20000000000043, 45.40000000000038, -83.6000000000013, 40.0000000000003, 50.20000000000047, 48.80000000000043, 80.49999999999928, -28.2999999999996, 99.39999999999819, 96.29999999999832, 37.80000000000027, 20.4, 22.90000000000005, 50.7000000000004, -43.49999999999999, 66.10000000000034, 41.800000000000324, 40.0000000000003, 37.4000000000003, 43.60000000000035, 39.40000000000032, 30.000000000000142, 15.49999999999992, -41.30000000000003, -458.69999999999976, 23.50000000000005, -62.40000000000137, 24.000000000000053, 70.6, 30.100000000000147, 24.100000000000055, 19.099999999999973, 49.90000000000046, 91.29999999999853, 22.300000000000068, 24.90000000000009, 40.0000000000003, 24.60000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-97.60000000000082, -21.99999999999976, -12.39999999999983, -108.10000000000073, -80.80000000000067, -118.60000000000049, 20.000000000000014, -82.9000000000006, -42.99999999999976, 22.700000000000053, -52.59999999999988, -103.90000000000039, -15.699999999999829, 30.800000000000196, -206.80000000000052, 20.000000000000014, -106.0000000000007, 20.000000000000014, 15.799999999999963, -17.79999999999974, 6.49999999999998, -43.29999999999976, 41.60000000000025, -74.5000000000008, -45.09999999999976, 20.000000000000014, 26.900000000000126, -255.1000000000004, -13.899999999999832, -25.89999999999982, 20.000000000000014, 20.000000000000014, -17.79999999999974, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.30000000000067, 24.80000000000011, 13.999999999999968, -89.20000000000026, 33.50000000000024, -5.499999999999989, -101.80000000000032, -49.299999999999805, 20.000000000000014, 20.000000000000014, 20.000000000000014, -17.79999999999974, -3.099999999999965, -78.70000000000087, 9.199999999999978, 21.80000000000004, 20.000000000000014, 9.499999999999973, 20.000000000000014, 1.0999999999999865, -2.4999999999999964, -76.60000000000088, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, -127.00000000000054, 20.000000000000014, -78.70000000000087, 42.50000000000025, 5.299999999999978, -57.69999999999997, -76.60000000000059, 20.000000000000032, -70.30000000000084, -55.300000000000075, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, -22.899999999999856, -49.29999999999983, 20.000000000000014, -42.99999999999981, 41.30000000000022, 20.000000000000014, 22.700000000000053, -94.90000000000066, 16.699999999999967, -29.799999999999812, 33.2000000000002, 23.600000000000065, -5.7999999999999385, -49.29999999999982, -200.50000000000003, -135.40000000000015, 20.000000000000014, 1.0999999999999759, 20.000000000000014, -22.29999999999975, -51.399999999999935, -12.699999999999878, 3.1999999999999615, 26.900000000000137, -91.30000000000084, -9.399999999999858, 3.4999999999999654, 3.1999999999999704, 38.000000000000256, 29.90000000000018, 13.699999999999964, 29.000000000000163, -34.59999999999977, 56.0000000000002, -42.6999999999998, -0.9999999999999846, 21.800000000000043, -17.79999999999974, 20.000000000000014, 20.000000000000014, -19.899999999999743, 23.600000000000065, -47.199999999999825, -110.2000000000007, 20.90000000000003, 46.10000000000024, 20.000000000000014, -51.399999999999935, 18.8, 25.400000000000098, 25.400000000000098, 20.000000000000014, -93.4000000000006, -68.20000000000068, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000134, 20.000000000000014, 9.799999999999983, 60.500000000000206, 20.000000000000014, -25.8999999999998, -30.399999999999785, 57.800000000000225, 41.60000000000024, 53.30000000000022, 41.000000000000206, 20.000000000000014, 15.799999999999963, -34.5999999999998, 20.000000000000014, -0.9999999999999846, -3.100000000000008, -28.29999999999975, 56.000000000000206, -47.19999999999982, -28.29999999999982, 25.400000000000098, 40.70000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.400000000000063, -15.999999999999782, 23.600000000000065, 20.000000000000014, 1.9999999999999607, 25.4000000000001, 20.000000000000014, -1.0000000000000382, -52.60000000000001, 25.100000000000094, -18.3999999999998, -61.90000000000067, -311.79999999999984, -304.89999999999986, -3.0999999999999934, 11.599999999999964, -110.20000000000064, -68.20000000000084, -34.599999999999774, 32.60000000000023, 50.600000000000215, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 13.999999999999968, -19.899999999999743, 20.000000000000014, -19.899999999999793, 20.000000000000014, 29.90000000000018, 48.80000000000023, 42.50000000000025, -27.699999999999804, 20.000000000000014, -41.79999999999979, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999855], "policy_predator_policy_reward": [0.0, 56.0, 37.0, 58.0, 76.0, 68.0, 49.0, 0.0, 15.0, 15.0, 80.0, 86.0, 17.0, 0.0, 74.0, 34.0, 60.0, 34.0, 0.0, 18.0, 3.0, 43.0, 31.0, 45.0, 31.0, 0.0, 86.0, 46.0, 44.0, 20.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 35.0, 44.0, 47.0, 19.0, 25.0, 0.0, 98.0, 1.0, 0.0, 0.0, 18.0, 14.0, 11.0, 47.0, 8.0, 1.0, 5.0, 0.0, 9.0, 0.0, 0.0, 46.0, 0.0, 14.0, 0.0, 0.0, 36.0, 37.0, 0.0, 47.0, 26.0, 18.0, 14.0, 37.0, 0.0, 69.0, 2.0, 0.0, 0.0, 0.0, 46.0, 10.0, 30.0, 14.0, 0.0, 4.0, 25.0, 37.0, 32.0, 2.0, 0.0, 10.0, 0.0, 50.0, 105.0, 0.0, 1.0, 8.0, 8.0, 17.0, 0.0, 43.0, 8.0, 10.0, 53.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 3.0, 15.0, 26.0, 10.0, 38.0, 0.0, 18.0, 0.0, 0.0, 19.0, 0.0, 37.0, 30.0, 0.0, 0.0, 0.0, 34.0, 15.0, 1.0, 0.0, 0.0, 36.0, 42.0, 0.0, 0.0, 3.0, 0.0, 0.0, 19.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 9.0, 26.0, 6.0, 21.0, 0.0, 23.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 12.0, 6.0, 5.0, 33.0, 10.0, 36.0, 3.0, 158.0, 0.0, 4.0, 11.0, 53.0, 63.0, 26.0, 0.0, 0.0, 0.0, 0.0, 9.0, 19.0, 11.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2876117434444376, "mean_inference_ms": 10.855376349481265, "mean_action_processing_ms": 0.6370432157093981, "mean_env_wait_ms": 1.5342605410663896, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006450653076171875, "StateBufferConnector_ms": 0.004587054252624512, "ViewRequirementAgentConnector_ms": 0.2754034996032715}, "num_episodes": 18, "episode_return_max": 99.39999999999819, "episode_return_min": -458.69999999999976, "episode_return_mean": 9.628000000000032, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 256.68029914183717, "num_env_steps_trained_throughput_per_sec": 256.68029914183717, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 152931.672, "restore_workers_time_ms": 0.022, "training_step_time_ms": 152931.399, "sample_time_ms": 34235.316, "learn_time_ms": 118667.016, "learn_throughput": 33.708, "synch_weights_time_ms": 24.031}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "3a355_00000", "date": "2024-08-13_02-41-02", "timestamp": 1723531262, "time_this_iter_s": 15.628237962722778, "time_total_s": 5468.55450463295, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52395e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5468.55450463295, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 86.20909090909092, "ram_util_percent": 83.60454545454546}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4002914432988123, "cur_kl_coeff": 2.3283064365386964e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0024657828467234, "policy_loss": -0.0004936334324714841, "vf_loss": 2.002959414165487, "vf_explained_var": -1.2183536297429807e-05, "kl": 0.0009871912392345407, "entropy": 0.2745200618470787, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7687735589723739, "cur_kl_coeff": 0.12013549804687497, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0481972566988103, "policy_loss": 0.00013579946188699632, "vf_loss": 3.0479896618575646, "vf_explained_var": -0.0006628998688289097, "kl": 0.000597595255573142, "entropy": 1.1568067691944264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 99.39999999999819, "episode_reward_min": -484.59999999999997, "episode_reward_mean": -0.6169999999999325, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.500000000000206, "predator_policy": 198.0}, "policy_reward_mean": {"prey_policy": -16.583499999999976, "predator_policy": 16.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 34.200000000000216, -23.79999999999952, 40.0000000000003, 34.50000000000022, 30.100000000000147, -33.09999999999954, 24.60000000000005, 40.0000000000003, -33.999999999999666, 10.799999999999994, -8.39999999999966, -5.599999999999826, -56.600000000000946, 37.80000000000026, 40.0000000000003, -16.19999999999964, 21.00000000000001, 65.30000000000037, -10.199999999999738, 20.90000000000004, 66.80000000000024, -5.099999999999827, -230.9000000000001, 30.10000000000013, 22.700000000000024, -21.099999999999618, 48.10000000000046, -47.700000000000564, 24.700000000000063, 67.90000000000025, 45.70000000000039, 62.40000000000042, 4.300000000000066, 22.00000000000001, 40.0000000000003, 22.70000000000002, -90.4000000000014, 67.00000000000028, 2.600000000000123, 60.20000000000043, 45.40000000000038, -83.6000000000013, 40.0000000000003, 50.20000000000047, 48.80000000000043, 80.49999999999928, -28.2999999999996, 99.39999999999819, 96.29999999999832, 37.80000000000027, 20.4, 22.90000000000005, 50.7000000000004, -43.49999999999999, 66.10000000000034, 41.800000000000324, 40.0000000000003, 37.4000000000003, 43.60000000000035, 39.40000000000032, 30.000000000000142, 15.49999999999992, -41.30000000000003, -458.69999999999976, 23.50000000000005, -62.40000000000137, 24.000000000000053, 70.6, 30.100000000000147, 24.100000000000055, 19.099999999999973, 49.90000000000046, 91.29999999999853, 22.300000000000068, 24.90000000000009, 40.0000000000003, 24.60000000000005, -484.59999999999997, 40.0000000000003, 84.09999999999907, 33.100000000000236, 34.40000000000022, -415.09999999999997, 24.100000000000055, -14.599999999999595, -434.9, 38.60000000000028, 21.80000000000001, 26.8000000000001, 62.20000000000048, 33.500000000000206, 23.100000000000026, 30.000000000000156, 40.0000000000003, -7.999999999999725, -398.99999999999994, 57.80000000000051, 54.40000000000052, 14.49999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, -17.79999999999974, -3.099999999999965, -78.70000000000087, 9.199999999999978, 21.80000000000004, 20.000000000000014, 9.499999999999973, 20.000000000000014, 1.0999999999999865, -2.4999999999999964, -76.60000000000088, 20.000000000000014, -9.399999999999855, 20.000000000000014, 20.000000000000014, -127.00000000000054, 20.000000000000014, -78.70000000000087, 42.50000000000025, 5.299999999999978, -57.69999999999997, -76.60000000000059, 20.000000000000032, -70.30000000000084, -55.300000000000075, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, -22.899999999999856, -49.29999999999983, 20.000000000000014, -42.99999999999981, 41.30000000000022, 20.000000000000014, 22.700000000000053, -94.90000000000066, 16.699999999999967, -29.799999999999812, 33.2000000000002, 23.600000000000065, -5.7999999999999385, -49.29999999999982, -200.50000000000003, -135.40000000000015, 20.000000000000014, 1.0999999999999759, 20.000000000000014, -22.29999999999975, -51.399999999999935, -12.699999999999878, 3.1999999999999615, 26.900000000000137, -91.30000000000084, -9.399999999999858, 3.4999999999999654, 3.1999999999999704, 38.000000000000256, 29.90000000000018, 13.699999999999964, 29.000000000000163, -34.59999999999977, 56.0000000000002, -42.6999999999998, -0.9999999999999846, 21.800000000000043, -17.79999999999974, 20.000000000000014, 20.000000000000014, -19.899999999999743, 23.600000000000065, -47.199999999999825, -110.2000000000007, 20.90000000000003, 46.10000000000024, 20.000000000000014, -51.399999999999935, 18.8, 25.400000000000098, 25.400000000000098, 20.000000000000014, -93.4000000000006, -68.20000000000068, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000134, 20.000000000000014, 9.799999999999983, 60.500000000000206, 20.000000000000014, -25.8999999999998, -30.399999999999785, 57.800000000000225, 41.60000000000024, 53.30000000000022, 41.000000000000206, 20.000000000000014, 15.799999999999963, -34.5999999999998, 20.000000000000014, -0.9999999999999846, -3.100000000000008, -28.29999999999975, 56.000000000000206, -47.19999999999982, -28.29999999999982, 25.400000000000098, 40.70000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.400000000000063, -15.999999999999782, 23.600000000000065, 20.000000000000014, 1.9999999999999607, 25.4000000000001, 20.000000000000014, -1.0000000000000382, -52.60000000000001, 25.100000000000094, -18.3999999999998, -61.90000000000067, -311.79999999999984, -304.89999999999986, -3.0999999999999934, 11.599999999999964, -110.20000000000064, -68.20000000000084, -34.599999999999774, 32.60000000000023, 50.600000000000215, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 13.999999999999968, -19.899999999999743, 20.000000000000014, -19.899999999999793, 20.000000000000014, 29.90000000000018, 48.80000000000023, 42.50000000000025, -27.699999999999804, 20.000000000000014, -41.79999999999979, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999855, -331.9, -327.7, 20.000000000000014, 20.000000000000014, 46.100000000000236, 38.000000000000256, -14.199999999999841, 17.29999999999998, -22.59999999999978, 20.000000000000014, -275.2, -304.9, -37.59999999999977, 31.700000000000212, 5.299999999999979, -64.90000000000084, -400.0, -361.9, 26.300000000000114, 5.299999999999965, -9.399999999999883, 3.1999999999999704, -5.199999999999962, 20.000000000000014, 10.099999999999977, 37.10000000000026, 20.000000000000014, -17.49999999999975, 20.000000000000014, -13.899999999999782, 20.000000000000014, -12.999999999999828, 20.000000000000014, 20.000000000000014, 1.9999999999999678, -42.9999999999998, -288.7, -277.3, 36.80000000000025, 20.000000000000014, 20.000000000000014, 34.40000000000026, -37.59999999999982, 13.099999999999971], "policy_predator_policy_reward": [0.0, 0.0, 18.0, 14.0, 11.0, 47.0, 8.0, 1.0, 5.0, 0.0, 9.0, 0.0, 0.0, 46.0, 0.0, 14.0, 0.0, 0.0, 36.0, 37.0, 0.0, 47.0, 26.0, 18.0, 14.0, 37.0, 0.0, 69.0, 2.0, 0.0, 0.0, 0.0, 46.0, 10.0, 30.0, 14.0, 0.0, 4.0, 25.0, 37.0, 32.0, 2.0, 0.0, 10.0, 0.0, 50.0, 105.0, 0.0, 1.0, 8.0, 8.0, 17.0, 0.0, 43.0, 8.0, 10.0, 53.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 3.0, 15.0, 26.0, 10.0, 38.0, 0.0, 18.0, 0.0, 0.0, 19.0, 0.0, 37.0, 30.0, 0.0, 0.0, 0.0, 34.0, 15.0, 1.0, 0.0, 0.0, 36.0, 42.0, 0.0, 0.0, 3.0, 0.0, 0.0, 19.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 9.0, 26.0, 6.0, 21.0, 0.0, 23.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 12.0, 6.0, 5.0, 33.0, 10.0, 36.0, 3.0, 158.0, 0.0, 4.0, 11.0, 53.0, 63.0, 26.0, 0.0, 0.0, 0.0, 0.0, 9.0, 19.0, 11.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 14.0, 174.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 15.0, 22.0, 165.0, 0.0, 30.0, 0.0, 24.0, 21.0, 129.0, 198.0, 7.0, 0.0, 14.0, 14.0, 0.0, 12.0, 15.0, 0.0, 14.0, 17.0, 0.0, 17.0, 12.0, 11.0, 0.0, 0.0, 33.0, 0.0, 162.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 39.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.6070909461607825, "mean_inference_ms": 12.734623123128467, "mean_action_processing_ms": 0.6352883211111038, "mean_env_wait_ms": 1.7663712384837464, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0067789554595947266, "StateBufferConnector_ms": 0.004862666130065918, "ViewRequirementAgentConnector_ms": 0.31083083152770996}, "num_episodes": 22, "episode_return_max": 99.39999999999819, "episode_return_min": -484.59999999999997, "episode_return_mean": -0.6169999999999325, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 233.66151232190327, "num_env_steps_trained_throughput_per_sec": 233.66151232190327, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 152622.742, "restore_workers_time_ms": 0.02, "training_step_time_ms": 152622.478, "sample_time_ms": 34161.35, "learn_time_ms": 118433.084, "learn_throughput": 33.774, "synch_weights_time_ms": 23.044}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "3a355_00000", "date": "2024-08-13_02-41-19", "timestamp": 1723531279, "time_this_iter_s": 17.18270492553711, "time_total_s": 5485.737209558487, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52393a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5485.737209558487, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 86.26666666666665, "ram_util_percent": 83.57083333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.41118788562478525, "cur_kl_coeff": 1.1641532182693482e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.622132617992068, "policy_loss": -0.0008722115177464075, "vf_loss": 1.6230048262568377, "vf_explained_var": 0.00023371201974374276, "kl": 0.002375180273909547, "entropy": 0.22639902595174374, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8322829654923192, "cur_kl_coeff": 0.060067749023437485, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.340071178365637, "policy_loss": -0.004386714937303353, "vf_loss": 2.3430308368470936, "vf_explained_var": 0.00023322029719277033, "kl": 0.023757536052616254, "entropy": 1.084038587789687, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 99.39999999999819, "episode_reward_min": -549.3, "episode_reward_mean": -18.115999999999936, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.500000000000206, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -27.597999999999956, "predator_policy": 18.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-230.9000000000001, 30.10000000000013, 22.700000000000024, -21.099999999999618, 48.10000000000046, -47.700000000000564, 24.700000000000063, 67.90000000000025, 45.70000000000039, 62.40000000000042, 4.300000000000066, 22.00000000000001, 40.0000000000003, 22.70000000000002, -90.4000000000014, 67.00000000000028, 2.600000000000123, 60.20000000000043, 45.40000000000038, -83.6000000000013, 40.0000000000003, 50.20000000000047, 48.80000000000043, 80.49999999999928, -28.2999999999996, 99.39999999999819, 96.29999999999832, 37.80000000000027, 20.4, 22.90000000000005, 50.7000000000004, -43.49999999999999, 66.10000000000034, 41.800000000000324, 40.0000000000003, 37.4000000000003, 43.60000000000035, 39.40000000000032, 30.000000000000142, 15.49999999999992, -41.30000000000003, -458.69999999999976, 23.50000000000005, -62.40000000000137, 24.000000000000053, 70.6, 30.100000000000147, 24.100000000000055, 19.099999999999973, 49.90000000000046, 91.29999999999853, 22.300000000000068, 24.90000000000009, 40.0000000000003, 24.60000000000005, -484.59999999999997, 40.0000000000003, 84.09999999999907, 33.100000000000236, 34.40000000000022, -415.09999999999997, 24.100000000000055, -14.599999999999595, -434.9, 38.60000000000028, 21.80000000000001, 26.8000000000001, 62.20000000000048, 33.500000000000206, 23.100000000000026, 30.000000000000156, 40.0000000000003, -7.999999999999725, -398.99999999999994, 57.80000000000051, 54.40000000000052, 14.49999999999995, 16.69999999999993, 32.800000000000196, 67.9000000000002, 36.90000000000025, 67.0000000000003, -112.30000000000057, 25.20000000000007, 20.499999999999982, -24.799999999999564, 64.50000000000041, 34.00000000000022, 51.70000000000049, 2.3000000000001157, 23.900000000000055, 40.0000000000003, 34.900000000000226, -503.2, -549.3, 50.80000000000048, 48.10000000000043, -420.99999999999994, -491.0, 47.50000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-200.50000000000003, -135.40000000000015, 20.000000000000014, 1.0999999999999759, 20.000000000000014, -22.29999999999975, -51.399999999999935, -12.699999999999878, 3.1999999999999615, 26.900000000000137, -91.30000000000084, -9.399999999999858, 3.4999999999999654, 3.1999999999999704, 38.000000000000256, 29.90000000000018, 13.699999999999964, 29.000000000000163, -34.59999999999977, 56.0000000000002, -42.6999999999998, -0.9999999999999846, 21.800000000000043, -17.79999999999974, 20.000000000000014, 20.000000000000014, -19.899999999999743, 23.600000000000065, -47.199999999999825, -110.2000000000007, 20.90000000000003, 46.10000000000024, 20.000000000000014, -51.399999999999935, 18.8, 25.400000000000098, 25.400000000000098, 20.000000000000014, -93.4000000000006, -68.20000000000068, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000134, 20.000000000000014, 9.799999999999983, 60.500000000000206, 20.000000000000014, -25.8999999999998, -30.399999999999785, 57.800000000000225, 41.60000000000024, 53.30000000000022, 41.000000000000206, 20.000000000000014, 15.799999999999963, -34.5999999999998, 20.000000000000014, -0.9999999999999846, -3.100000000000008, -28.29999999999975, 56.000000000000206, -47.19999999999982, -28.29999999999982, 25.400000000000098, 40.70000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.400000000000063, -15.999999999999782, 23.600000000000065, 20.000000000000014, 1.9999999999999607, 25.4000000000001, 20.000000000000014, -1.0000000000000382, -52.60000000000001, 25.100000000000094, -18.3999999999998, -61.90000000000067, -311.79999999999984, -304.89999999999986, -3.0999999999999934, 11.599999999999964, -110.20000000000064, -68.20000000000084, -34.599999999999774, 32.60000000000023, 50.600000000000215, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 13.999999999999968, -19.899999999999743, 20.000000000000014, -19.899999999999793, 20.000000000000014, 29.90000000000018, 48.80000000000023, 42.50000000000025, -27.699999999999804, 20.000000000000014, -41.79999999999979, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999855, -331.9, -327.7, 20.000000000000014, 20.000000000000014, 46.100000000000236, 38.000000000000256, -14.199999999999841, 17.29999999999998, -22.59999999999978, 20.000000000000014, -275.2, -304.9, -37.59999999999977, 31.700000000000212, 5.299999999999979, -64.90000000000084, -400.0, -361.9, 26.300000000000114, 5.299999999999965, -9.399999999999883, 3.1999999999999704, -5.199999999999962, 20.000000000000014, 10.099999999999977, 37.10000000000026, 20.000000000000014, -17.49999999999975, 20.000000000000014, -13.899999999999782, 20.000000000000014, -12.999999999999828, 20.000000000000014, 20.000000000000014, 1.9999999999999678, -42.9999999999998, -288.7, -277.3, 36.80000000000025, 20.000000000000014, 20.000000000000014, 34.40000000000026, -37.59999999999982, 13.099999999999971, 20.90000000000003, -26.19999999999979, 20.000000000000014, 3.7999999999999656, 23.600000000000065, 44.30000000000023, 21.80000000000004, -4.89999999999997, 37.10000000000026, 29.90000000000018, -194.20000000000027, -45.09999999999996, -14.799999999999779, 20.000000000000014, -19.899999999999743, 7.399999999999965, -40.89999999999979, -19.89999999999977, 20.000000000000014, 36.500000000000206, -6.999999999999934, 20.000000000000014, 31.700000000000212, 20.000000000000014, -61.300000000000615, 23.600000000000065, 1.0999999999999865, -8.199999999999916, 20.000000000000014, 20.000000000000014, 14.899999999999967, 7.999999999999968, -355.3, -367.9, -397.9, -360.4, 20.000000000000014, 30.800000000000196, 28.100000000000147, 20.000000000000014, -299.2, -302.79999999999995, -322.9, -339.1, 17.59999999999998, 17.899999999999988], "policy_predator_policy_reward": [105.0, 0.0, 1.0, 8.0, 8.0, 17.0, 0.0, 43.0, 8.0, 10.0, 53.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 3.0, 15.0, 26.0, 10.0, 38.0, 0.0, 18.0, 0.0, 0.0, 19.0, 0.0, 37.0, 30.0, 0.0, 0.0, 0.0, 34.0, 15.0, 1.0, 0.0, 0.0, 36.0, 42.0, 0.0, 0.0, 3.0, 0.0, 0.0, 19.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 9.0, 26.0, 6.0, 21.0, 0.0, 23.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 12.0, 6.0, 5.0, 33.0, 10.0, 36.0, 3.0, 158.0, 0.0, 4.0, 11.0, 53.0, 63.0, 26.0, 0.0, 0.0, 0.0, 0.0, 9.0, 19.0, 11.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 14.0, 174.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 15.0, 22.0, 165.0, 0.0, 30.0, 0.0, 24.0, 21.0, 129.0, 198.0, 7.0, 0.0, 14.0, 14.0, 0.0, 12.0, 15.0, 0.0, 14.0, 17.0, 0.0, 17.0, 12.0, 11.0, 0.0, 0.0, 33.0, 0.0, 162.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 39.0, 22.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 0.0, 79.0, 48.0, 20.0, 0.0, 14.0, 19.0, 32.0, 4.0, 0.0, 8.0, 0.0, 21.0, 0.0, 0.0, 10.0, 30.0, 0.0, 31.0, 0.0, 0.0, 12.0, 0.0, 189.0, 31.0, 10.0, 199.0, 0.0, 0.0, 0.0, 0.0, 29.0, 152.0, 0.0, 171.0, 2.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.58615070673679, "mean_inference_ms": 12.569529987015299, "mean_action_processing_ms": 0.6321139822752008, "mean_env_wait_ms": 1.8461673639353762, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0063446760177612305, "StateBufferConnector_ms": 0.005004286766052246, "ViewRequirementAgentConnector_ms": 0.22325289249420166}, "num_episodes": 23, "episode_return_max": 99.39999999999819, "episode_return_min": -549.3, "episode_return_mean": -18.115999999999936, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 232.44941529686722, "num_env_steps_trained_throughput_per_sec": 232.44941529686722, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 152260.013, "restore_workers_time_ms": 0.018, "training_step_time_ms": 152259.752, "sample_time_ms": 34220.082, "learn_time_ms": 118011.869, "learn_throughput": 33.895, "synch_weights_time_ms": 22.838}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "3a355_00000", "date": "2024-08-13_02-41-37", "timestamp": 1723531297, "time_this_iter_s": 17.254761934280396, "time_total_s": 5502.991971492767, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5240f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5502.991971492767, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 84.52083333333334, "ram_util_percent": 83.2625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.38650764399577703, "cur_kl_coeff": 5.820766091346741e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7114735761410975, "policy_loss": -0.00138593391939091, "vf_loss": 0.7128595099409933, "vf_explained_var": 0.002155706806788369, "kl": 0.0021007148512974215, "entropy": 0.2684767603953049, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0314016804572135, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0721092829194965, "policy_loss": -0.0022110621272413817, "vf_loss": 1.0735205209286756, "vf_explained_var": -0.003553671433181359, "kl": 0.00887691665149596, "entropy": 1.1294301261977544, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 99.39999999999819, "episode_reward_min": -549.3, "episode_reward_mean": -17.989999999999906, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 60.500000000000206, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -27.069999999999947, "predator_policy": 18.075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.40000000000038, -83.6000000000013, 40.0000000000003, 50.20000000000047, 48.80000000000043, 80.49999999999928, -28.2999999999996, 99.39999999999819, 96.29999999999832, 37.80000000000027, 20.4, 22.90000000000005, 50.7000000000004, -43.49999999999999, 66.10000000000034, 41.800000000000324, 40.0000000000003, 37.4000000000003, 43.60000000000035, 39.40000000000032, 30.000000000000142, 15.49999999999992, -41.30000000000003, -458.69999999999976, 23.50000000000005, -62.40000000000137, 24.000000000000053, 70.6, 30.100000000000147, 24.100000000000055, 19.099999999999973, 49.90000000000046, 91.29999999999853, 22.300000000000068, 24.90000000000009, 40.0000000000003, 24.60000000000005, -484.59999999999997, 40.0000000000003, 84.09999999999907, 33.100000000000236, 34.40000000000022, -415.09999999999997, 24.100000000000055, -14.599999999999595, -434.9, 38.60000000000028, 21.80000000000001, 26.8000000000001, 62.20000000000048, 33.500000000000206, 23.100000000000026, 30.000000000000156, 40.0000000000003, -7.999999999999725, -398.99999999999994, 57.80000000000051, 54.40000000000052, 14.49999999999995, 16.69999999999993, 32.800000000000196, 67.9000000000002, 36.90000000000025, 67.0000000000003, -112.30000000000057, 25.20000000000007, 20.499999999999982, -24.799999999999564, 64.50000000000041, 34.00000000000022, 51.70000000000049, 2.3000000000001157, 23.900000000000055, 40.0000000000003, 34.900000000000226, -503.2, -549.3, 50.80000000000048, 48.10000000000043, -420.99999999999994, -491.0, 47.50000000000045, -483.5, 43.50000000000036, 56.600000000000506, 29.400000000000144, 47.200000000000415, 40.0000000000003, 46.3000000000004, 17.99999999999995, 21.90000000000002, 43.00000000000034, 40.0000000000003, 32.100000000000186, 40.0000000000003, 56.20000000000052, 9.699999999999942, 40.0000000000003, 27.90000000000012, 34.60000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [25.400000000000098, 20.000000000000014, -93.4000000000006, -68.20000000000068, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.200000000000134, 20.000000000000014, 9.799999999999983, 60.500000000000206, 20.000000000000014, -25.8999999999998, -30.399999999999785, 57.800000000000225, 41.60000000000024, 53.30000000000022, 41.000000000000206, 20.000000000000014, 15.799999999999963, -34.5999999999998, 20.000000000000014, -0.9999999999999846, -3.100000000000008, -28.29999999999975, 56.000000000000206, -47.19999999999982, -28.29999999999982, 25.400000000000098, 40.70000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.400000000000063, -15.999999999999782, 23.600000000000065, 20.000000000000014, 1.9999999999999607, 25.4000000000001, 20.000000000000014, -1.0000000000000382, -52.60000000000001, 25.100000000000094, -18.3999999999998, -61.90000000000067, -311.79999999999984, -304.89999999999986, -3.0999999999999934, 11.599999999999964, -110.20000000000064, -68.20000000000084, -34.599999999999774, 32.60000000000023, 50.600000000000215, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 13.999999999999968, -19.899999999999743, 20.000000000000014, -19.899999999999793, 20.000000000000014, 29.90000000000018, 48.80000000000023, 42.50000000000025, -27.699999999999804, 20.000000000000014, -41.79999999999979, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999855, -331.9, -327.7, 20.000000000000014, 20.000000000000014, 46.100000000000236, 38.000000000000256, -14.199999999999841, 17.29999999999998, -22.59999999999978, 20.000000000000014, -275.2, -304.9, -37.59999999999977, 31.700000000000212, 5.299999999999979, -64.90000000000084, -400.0, -361.9, 26.300000000000114, 5.299999999999965, -9.399999999999883, 3.1999999999999704, -5.199999999999962, 20.000000000000014, 10.099999999999977, 37.10000000000026, 20.000000000000014, -17.49999999999975, 20.000000000000014, -13.899999999999782, 20.000000000000014, -12.999999999999828, 20.000000000000014, 20.000000000000014, 1.9999999999999678, -42.9999999999998, -288.7, -277.3, 36.80000000000025, 20.000000000000014, 20.000000000000014, 34.40000000000026, -37.59999999999982, 13.099999999999971, 20.90000000000003, -26.19999999999979, 20.000000000000014, 3.7999999999999656, 23.600000000000065, 44.30000000000023, 21.80000000000004, -4.89999999999997, 37.10000000000026, 29.90000000000018, -194.20000000000027, -45.09999999999996, -14.799999999999779, 20.000000000000014, -19.899999999999743, 7.399999999999965, -40.89999999999979, -19.89999999999977, 20.000000000000014, 36.500000000000206, -6.999999999999934, 20.000000000000014, 31.700000000000212, 20.000000000000014, -61.300000000000615, 23.600000000000065, 1.0999999999999865, -8.199999999999916, 20.000000000000014, 20.000000000000014, 14.899999999999967, 7.999999999999968, -355.3, -367.9, -397.9, -360.4, 20.000000000000014, 30.800000000000196, 28.100000000000147, 20.000000000000014, -299.2, -302.79999999999995, -322.9, -339.1, 17.59999999999998, 17.899999999999988, -328.59999999999997, -355.9, 26.90000000000013, 11.599999999999966, 18.8, 30.8000000000002, 15.799999999999963, -3.399999999999976, 24.50000000000008, 22.700000000000053, 20.000000000000014, 20.000000000000014, 2.899999999999965, 34.40000000000025, 20.000000000000014, -21.999999999999766, -16.599999999999753, -17.49999999999978, 20.000000000000014, 20.000000000000018, 20.000000000000014, 20.000000000000014, 25.400000000000098, -10.299999999999851, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, -45.09999999999981, -11.199999999999848, 20.000000000000014, 20.000000000000014, 29.90000000000018, -21.99999999999975, 13.699999999999964, 17.899999999999988], "policy_predator_policy_reward": [0.0, 0.0, 36.0, 42.0, 0.0, 0.0, 3.0, 0.0, 0.0, 19.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 9.0, 26.0, 6.0, 21.0, 0.0, 23.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 12.0, 6.0, 5.0, 33.0, 10.0, 36.0, 3.0, 158.0, 0.0, 4.0, 11.0, 53.0, 63.0, 26.0, 0.0, 0.0, 0.0, 0.0, 9.0, 19.0, 11.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 14.0, 174.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 15.0, 22.0, 165.0, 0.0, 30.0, 0.0, 24.0, 21.0, 129.0, 198.0, 7.0, 0.0, 14.0, 14.0, 0.0, 12.0, 15.0, 0.0, 14.0, 17.0, 0.0, 17.0, 12.0, 11.0, 0.0, 0.0, 33.0, 0.0, 162.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 39.0, 22.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 0.0, 79.0, 48.0, 20.0, 0.0, 14.0, 19.0, 32.0, 4.0, 0.0, 8.0, 0.0, 21.0, 0.0, 0.0, 10.0, 30.0, 0.0, 31.0, 0.0, 0.0, 12.0, 0.0, 189.0, 31.0, 10.0, 199.0, 0.0, 0.0, 0.0, 0.0, 29.0, 152.0, 0.0, 171.0, 2.0, 10.0, 22.0, 179.0, 1.0, 4.0, 0.0, 7.0, 15.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 20.0, 37.0, 19.0, 3.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 45.0, 21.0, 0.0, 0.0, 20.0, 0.0, 0.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5661798254221315, "mean_inference_ms": 12.550337024068273, "mean_action_processing_ms": 0.6295317823049916, "mean_env_wait_ms": 1.7197891561372614, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006639838218688965, "StateBufferConnector_ms": 0.0113295316696167, "ViewRequirementAgentConnector_ms": 0.22804391384124756}, "num_episodes": 18, "episode_return_max": 99.39999999999819, "episode_return_min": -549.3, "episode_return_mean": -17.989999999999906, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 219.41180867860942, "num_env_steps_trained_throughput_per_sec": 219.41180867860942, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 152082.832, "restore_workers_time_ms": 0.017, "training_step_time_ms": 152082.572, "sample_time_ms": 34301.741, "learn_time_ms": 117750.926, "learn_throughput": 33.97, "synch_weights_time_ms": 25.606}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "3a355_00000", "date": "2024-08-13_02-41-55", "timestamp": 1723531315, "time_this_iter_s": 18.361858129501343, "time_total_s": 5521.353829622269, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dcfd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5521.353829622269, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 85.67307692307692, "ram_util_percent": 83.22307692307692}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4428112312461491, "cur_kl_coeff": 2.9103830456733705e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8266239440630352, "policy_loss": -0.001240335409800527, "vf_loss": 1.8278642817464454, "vf_explained_var": 0.00042284071130096595, "kl": 0.0027136042236517847, "entropy": 0.24601110419426014, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8364537268877029, "cur_kl_coeff": 0.09010162353515624, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0583623951705046, "policy_loss": -0.00040635072167903656, "vf_loss": 3.0583595778576282, "vf_explained_var": 0.0020745493747569895, "kl": 0.004541180578800686, "entropy": 1.1260568763213183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 91.29999999999853, "episode_reward_min": -562.0, "episode_reward_mean": -35.15399999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 50.600000000000215, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -39.14199999999996, "predator_policy": 21.565}, "custom_metrics": {}, "hist_stats": {"episode_reward": [43.60000000000035, 39.40000000000032, 30.000000000000142, 15.49999999999992, -41.30000000000003, -458.69999999999976, 23.50000000000005, -62.40000000000137, 24.000000000000053, 70.6, 30.100000000000147, 24.100000000000055, 19.099999999999973, 49.90000000000046, 91.29999999999853, 22.300000000000068, 24.90000000000009, 40.0000000000003, 24.60000000000005, -484.59999999999997, 40.0000000000003, 84.09999999999907, 33.100000000000236, 34.40000000000022, -415.09999999999997, 24.100000000000055, -14.599999999999595, -434.9, 38.60000000000028, 21.80000000000001, 26.8000000000001, 62.20000000000048, 33.500000000000206, 23.100000000000026, 30.000000000000156, 40.0000000000003, -7.999999999999725, -398.99999999999994, 57.80000000000051, 54.40000000000052, 14.49999999999995, 16.69999999999993, 32.800000000000196, 67.9000000000002, 36.90000000000025, 67.0000000000003, -112.30000000000057, 25.20000000000007, 20.499999999999982, -24.799999999999564, 64.50000000000041, 34.00000000000022, 51.70000000000049, 2.3000000000001157, 23.900000000000055, 40.0000000000003, 34.900000000000226, -503.2, -549.3, 50.80000000000048, 48.10000000000043, -420.99999999999994, -491.0, 47.50000000000045, -483.5, 43.50000000000036, 56.600000000000506, 29.400000000000144, 47.200000000000415, 40.0000000000003, 46.3000000000004, 17.99999999999995, 21.90000000000002, 43.00000000000034, 40.0000000000003, 32.100000000000186, 40.0000000000003, 56.20000000000052, 9.699999999999942, 40.0000000000003, 27.90000000000012, 34.60000000000022, 55.600000000000534, 59.80000000000048, 40.0000000000003, -138.80000000000157, 26.80000000000009, 81.19999999999924, 27.300000000000104, -377.7, 40.0000000000003, 40.0000000000003, 47.300000000000416, -411.1, -562.0, 32.30000000000018, 23.100000000000026, 68.80000000000013, -207.39999999999998, 60.70000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [23.600000000000065, 20.000000000000014, 1.9999999999999607, 25.4000000000001, 20.000000000000014, -1.0000000000000382, -52.60000000000001, 25.100000000000094, -18.3999999999998, -61.90000000000067, -311.79999999999984, -304.89999999999986, -3.0999999999999934, 11.599999999999964, -110.20000000000064, -68.20000000000084, -34.599999999999774, 32.60000000000023, 50.600000000000215, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 13.999999999999968, -19.899999999999743, 20.000000000000014, -19.899999999999793, 20.000000000000014, 29.90000000000018, 48.80000000000023, 42.50000000000025, -27.699999999999804, 20.000000000000014, -41.79999999999979, 31.700000000000212, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999855, -331.9, -327.7, 20.000000000000014, 20.000000000000014, 46.100000000000236, 38.000000000000256, -14.199999999999841, 17.29999999999998, -22.59999999999978, 20.000000000000014, -275.2, -304.9, -37.59999999999977, 31.700000000000212, 5.299999999999979, -64.90000000000084, -400.0, -361.9, 26.300000000000114, 5.299999999999965, -9.399999999999883, 3.1999999999999704, -5.199999999999962, 20.000000000000014, 10.099999999999977, 37.10000000000026, 20.000000000000014, -17.49999999999975, 20.000000000000014, -13.899999999999782, 20.000000000000014, -12.999999999999828, 20.000000000000014, 20.000000000000014, 1.9999999999999678, -42.9999999999998, -288.7, -277.3, 36.80000000000025, 20.000000000000014, 20.000000000000014, 34.40000000000026, -37.59999999999982, 13.099999999999971, 20.90000000000003, -26.19999999999979, 20.000000000000014, 3.7999999999999656, 23.600000000000065, 44.30000000000023, 21.80000000000004, -4.89999999999997, 37.10000000000026, 29.90000000000018, -194.20000000000027, -45.09999999999996, -14.799999999999779, 20.000000000000014, -19.899999999999743, 7.399999999999965, -40.89999999999979, -19.89999999999977, 20.000000000000014, 36.500000000000206, -6.999999999999934, 20.000000000000014, 31.700000000000212, 20.000000000000014, -61.300000000000615, 23.600000000000065, 1.0999999999999865, -8.199999999999916, 20.000000000000014, 20.000000000000014, 14.899999999999967, 7.999999999999968, -355.3, -367.9, -397.9, -360.4, 20.000000000000014, 30.800000000000196, 28.100000000000147, 20.000000000000014, -299.2, -302.79999999999995, -322.9, -339.1, 17.59999999999998, 17.899999999999988, -328.59999999999997, -355.9, 26.90000000000013, 11.599999999999966, 18.8, 30.8000000000002, 15.799999999999963, -3.399999999999976, 24.50000000000008, 22.700000000000053, 20.000000000000014, 20.000000000000014, 2.899999999999965, 34.40000000000025, 20.000000000000014, -21.999999999999766, -16.599999999999753, -17.49999999999978, 20.000000000000014, 20.000000000000018, 20.000000000000014, 20.000000000000014, 25.400000000000098, -10.299999999999851, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, -45.09999999999981, -11.199999999999848, 20.000000000000014, 20.000000000000014, 29.90000000000018, -21.99999999999975, 13.699999999999964, 17.899999999999988, 24.500000000000085, 28.100000000000147, 20.000000000000014, 33.800000000000225, 20.000000000000014, 20.000000000000014, -97.60000000000079, -110.20000000000078, -5.1999999999999265, 20.000000000000014, 43.100000000000236, 37.10000000000023, 20.000000000000014, -6.699999999999907, -299.2, -386.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 18.8, 24.50000000000008, -400.0, -228.09999999999994, -391.6, -366.4, 20.000000000000014, -3.6999999999999726, -13.899999999999782, 20.000000000000014, 45.20000000000022, 23.600000000000065, -140.50000000000003, -181.89999999999992, 20.000000000000014, 40.70000000000023], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 12.0, 6.0, 5.0, 33.0, 10.0, 36.0, 3.0, 158.0, 0.0, 4.0, 11.0, 53.0, 63.0, 26.0, 0.0, 0.0, 0.0, 0.0, 9.0, 19.0, 11.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 35.0, 0.0, 0.0, 0.0, 0.0, 14.0, 174.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 15.0, 22.0, 165.0, 0.0, 30.0, 0.0, 24.0, 21.0, 129.0, 198.0, 7.0, 0.0, 14.0, 14.0, 0.0, 12.0, 15.0, 0.0, 14.0, 17.0, 0.0, 17.0, 12.0, 11.0, 0.0, 0.0, 33.0, 0.0, 162.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 39.0, 22.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 0.0, 79.0, 48.0, 20.0, 0.0, 14.0, 19.0, 32.0, 4.0, 0.0, 8.0, 0.0, 21.0, 0.0, 0.0, 10.0, 30.0, 0.0, 31.0, 0.0, 0.0, 12.0, 0.0, 189.0, 31.0, 10.0, 199.0, 0.0, 0.0, 0.0, 0.0, 29.0, 152.0, 0.0, 171.0, 2.0, 10.0, 22.0, 179.0, 1.0, 4.0, 0.0, 7.0, 15.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 20.0, 37.0, 19.0, 3.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 45.0, 21.0, 0.0, 0.0, 20.0, 0.0, 0.0, 3.0, 3.0, 0.0, 5.0, 1.0, 0.0, 0.0, 62.0, 7.0, 0.0, 12.0, 1.0, 0.0, 14.0, 0.0, 133.0, 175.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 186.0, 31.0, 196.0, 0.0, 16.0, 0.0, 0.0, 17.0, 0.0, 0.0, 9.0, 106.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5498315491220547, "mean_inference_ms": 12.427672180844176, "mean_action_processing_ms": 0.6282562880458373, "mean_env_wait_ms": 1.70219097610468, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007304668426513672, "StateBufferConnector_ms": 0.011508822441101074, "ViewRequirementAgentConnector_ms": 0.24889957904815674}, "num_episodes": 18, "episode_return_max": 91.29999999999853, "episode_return_min": -562.0, "episode_return_mean": -35.15399999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.13442151726488, "num_env_steps_trained_throughput_per_sec": 199.13442151726488, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 49038.039, "restore_workers_time_ms": 0.017, "training_step_time_ms": 49037.782, "sample_time_ms": 34378.772, "learn_time_ms": 14631.146, "learn_throughput": 273.389, "synch_weights_time_ms": 24.017}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "3a355_00000", "date": "2024-08-13_02-42-15", "timestamp": 1723531335, "time_this_iter_s": 20.18266201019287, "time_total_s": 5541.536491632462, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5239dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5541.536491632462, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 87.72758620689655, "ram_util_percent": 83.27931034482758}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.487652129370463, "cur_kl_coeff": 1.4551915228366853e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1159484201165104, "policy_loss": -0.0009159737176670836, "vf_loss": 1.116864392224443, "vf_explained_var": 0.0007957312165113984, "kl": 0.001807039207605162, "entropy": 0.20388612755865015, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8394944753714655, "cur_kl_coeff": 0.04505081176757812, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8727284309409913, "policy_loss": -5.6020199030480054e-05, "vf_loss": 1.8727510868556916, "vf_explained_var": -0.0017087531152856412, "kl": 0.0007406138161324782, "entropy": 1.1152808830220864, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 81.19999999999924, "episode_reward_min": -562.0, "episode_reward_mean": -32.535999999999845, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000022, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -37.482999999999954, "predator_policy": 21.215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.100000000000236, 34.40000000000022, -415.09999999999997, 24.100000000000055, -14.599999999999595, -434.9, 38.60000000000028, 21.80000000000001, 26.8000000000001, 62.20000000000048, 33.500000000000206, 23.100000000000026, 30.000000000000156, 40.0000000000003, -7.999999999999725, -398.99999999999994, 57.80000000000051, 54.40000000000052, 14.49999999999995, 16.69999999999993, 32.800000000000196, 67.9000000000002, 36.90000000000025, 67.0000000000003, -112.30000000000057, 25.20000000000007, 20.499999999999982, -24.799999999999564, 64.50000000000041, 34.00000000000022, 51.70000000000049, 2.3000000000001157, 23.900000000000055, 40.0000000000003, 34.900000000000226, -503.2, -549.3, 50.80000000000048, 48.10000000000043, -420.99999999999994, -491.0, 47.50000000000045, -483.5, 43.50000000000036, 56.600000000000506, 29.400000000000144, 47.200000000000415, 40.0000000000003, 46.3000000000004, 17.99999999999995, 21.90000000000002, 43.00000000000034, 40.0000000000003, 32.100000000000186, 40.0000000000003, 56.20000000000052, 9.699999999999942, 40.0000000000003, 27.90000000000012, 34.60000000000022, 55.600000000000534, 59.80000000000048, 40.0000000000003, -138.80000000000157, 26.80000000000009, 81.19999999999924, 27.300000000000104, -377.7, 40.0000000000003, 40.0000000000003, 47.300000000000416, -411.1, -562.0, 32.30000000000018, 23.100000000000026, 68.80000000000013, -207.39999999999998, 60.70000000000048, -302.50000000000006, 25.700000000000074, 49.00000000000045, 62.600000000000506, 15.79999999999994, 13.499999999999977, 23.800000000000047, 25.700000000000088, 25.20000000000007, -80.00000000000148, 15.999999999999925, 40.0000000000003, 0.7000000000001787, 3.7000000000001347, 40.0000000000003, -236.20000000000002, -21.199999999999584, 46.90000000000046, 38.900000000000276, 16.299999999999958, 67.90000000000018, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-14.199999999999841, 17.29999999999998, -22.59999999999978, 20.000000000000014, -275.2, -304.9, -37.59999999999977, 31.700000000000212, 5.299999999999979, -64.90000000000084, -400.0, -361.9, 26.300000000000114, 5.299999999999965, -9.399999999999883, 3.1999999999999704, -5.199999999999962, 20.000000000000014, 10.099999999999977, 37.10000000000026, 20.000000000000014, -17.49999999999975, 20.000000000000014, -13.899999999999782, 20.000000000000014, -12.999999999999828, 20.000000000000014, 20.000000000000014, 1.9999999999999678, -42.9999999999998, -288.7, -277.3, 36.80000000000025, 20.000000000000014, 20.000000000000014, 34.40000000000026, -37.59999999999982, 13.099999999999971, 20.90000000000003, -26.19999999999979, 20.000000000000014, 3.7999999999999656, 23.600000000000065, 44.30000000000023, 21.80000000000004, -4.89999999999997, 37.10000000000026, 29.90000000000018, -194.20000000000027, -45.09999999999996, -14.799999999999779, 20.000000000000014, -19.899999999999743, 7.399999999999965, -40.89999999999979, -19.89999999999977, 20.000000000000014, 36.500000000000206, -6.999999999999934, 20.000000000000014, 31.700000000000212, 20.000000000000014, -61.300000000000615, 23.600000000000065, 1.0999999999999865, -8.199999999999916, 20.000000000000014, 20.000000000000014, 14.899999999999967, 7.999999999999968, -355.3, -367.9, -397.9, -360.4, 20.000000000000014, 30.800000000000196, 28.100000000000147, 20.000000000000014, -299.2, -302.79999999999995, -322.9, -339.1, 17.59999999999998, 17.899999999999988, -328.59999999999997, -355.9, 26.90000000000013, 11.599999999999966, 18.8, 30.8000000000002, 15.799999999999963, -3.399999999999976, 24.50000000000008, 22.700000000000053, 20.000000000000014, 20.000000000000014, 2.899999999999965, 34.40000000000025, 20.000000000000014, -21.999999999999766, -16.599999999999753, -17.49999999999978, 20.000000000000014, 20.000000000000018, 20.000000000000014, 20.000000000000014, 25.400000000000098, -10.299999999999851, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, -45.09999999999981, -11.199999999999848, 20.000000000000014, 20.000000000000014, 29.90000000000018, -21.99999999999975, 13.699999999999964, 17.899999999999988, 24.500000000000085, 28.100000000000147, 20.000000000000014, 33.800000000000225, 20.000000000000014, 20.000000000000014, -97.60000000000079, -110.20000000000078, -5.1999999999999265, 20.000000000000014, 43.100000000000236, 37.10000000000023, 20.000000000000014, -6.699999999999907, -299.2, -386.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 18.8, 24.50000000000008, -400.0, -228.09999999999994, -391.6, -366.4, 20.000000000000014, -3.6999999999999726, -13.899999999999782, 20.000000000000014, 45.20000000000022, 23.600000000000065, -140.50000000000003, -181.89999999999992, 20.000000000000014, 40.70000000000023, -184.3, -257.20000000000005, 20.000000000000014, -7.299999999999898, 20.000000000000014, 29.000000000000163, 30.800000000000196, 24.800000000000093, 17.899999999999988, -24.09999999999976, 29.90000000000019, -51.40000000000005, -32.49999999999976, 29.30000000000017, -7.29999999999993, 20.000000000000014, 20.000000000000014, -14.799999999999779, -91.90000000000072, -48.09999999999981, 7.99999999999997, -21.999999999999794, 20.000000000000014, 20.000000000000014, 8.299999999999969, -55.60000000000028, -49.29999999999982, 20.000000000000014, 20.000000000000014, 20.000000000000014, -196.3, -151.90000000000003, -100.00000000000074, 15.799999999999962, 16.099999999999973, 15.799999999999963, 20.000000000000014, 17.899999999999988, -27.699999999999754, 20.000000000000014, 20.000000000000014, 47.90000000000022, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 30.0, 15.0, 22.0, 165.0, 0.0, 30.0, 0.0, 24.0, 21.0, 129.0, 198.0, 7.0, 0.0, 14.0, 14.0, 0.0, 12.0, 15.0, 0.0, 14.0, 17.0, 0.0, 17.0, 12.0, 11.0, 0.0, 0.0, 33.0, 0.0, 162.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 39.0, 22.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 0.0, 79.0, 48.0, 20.0, 0.0, 14.0, 19.0, 32.0, 4.0, 0.0, 8.0, 0.0, 21.0, 0.0, 0.0, 10.0, 30.0, 0.0, 31.0, 0.0, 0.0, 12.0, 0.0, 189.0, 31.0, 10.0, 199.0, 0.0, 0.0, 0.0, 0.0, 29.0, 152.0, 0.0, 171.0, 2.0, 10.0, 22.0, 179.0, 1.0, 4.0, 0.0, 7.0, 15.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 20.0, 37.0, 19.0, 3.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 45.0, 21.0, 0.0, 0.0, 20.0, 0.0, 0.0, 3.0, 3.0, 0.0, 5.0, 1.0, 0.0, 0.0, 62.0, 7.0, 0.0, 12.0, 1.0, 0.0, 14.0, 0.0, 133.0, 175.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 186.0, 31.0, 196.0, 0.0, 16.0, 0.0, 0.0, 17.0, 0.0, 0.0, 9.0, 106.0, 0.0, 0.0, 132.0, 7.0, 13.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 21.0, 35.0, 0.0, 2.0, 25.0, 13.0, 0.0, 20.0, 0.0, 2.0, 58.0, 0.0, 30.0, 0.0, 0.0, 26.0, 22.0, 0.0, 33.0, 0.0, 0.0, 3.0, 109.0, 14.0, 49.0, 11.0, 4.0, 0.0, 1.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.6382848703161117, "mean_inference_ms": 12.180255933427594, "mean_action_processing_ms": 0.6287128428536491, "mean_env_wait_ms": 1.6898860173596089, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008736729621887207, "StateBufferConnector_ms": 0.015068411827087402, "ViewRequirementAgentConnector_ms": 0.30937814712524414}, "num_episodes": 22, "episode_return_max": 81.19999999999924, "episode_return_min": -562.0, "episode_return_mean": -32.535999999999845, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 193.10312917537553, "num_env_steps_trained_throughput_per_sec": 193.10312917537553, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 48565.531, "restore_workers_time_ms": 0.017, "training_step_time_ms": 48565.458, "sample_time_ms": 34214.424, "learn_time_ms": 14322.889, "learn_throughput": 279.273, "synch_weights_time_ms": 23.894}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "3a355_00000", "date": "2024-08-13_02-42-36", "timestamp": 1723531356, "time_this_iter_s": 20.813140869140625, "time_total_s": 5562.349632501602, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5075790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5562.349632501602, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 87.17586206896551, "ram_util_percent": 83.40344827586208}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.509819582219004, "cur_kl_coeff": 7.275957614183426e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1252102989999075, "policy_loss": -0.0007992400770524034, "vf_loss": 2.126009541813028, "vf_explained_var": 0.0012948200185462912, "kl": 0.0009384719927357824, "entropy": 0.17391647261286539, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8052475885384612, "cur_kl_coeff": 0.02252540588378906, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5368908098765783, "policy_loss": -0.0023984420272181667, "vf_loss": 3.538887383193566, "vf_explained_var": -0.0018391602884524714, "kl": 0.017841077440460647, "entropy": 1.0636298044018013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 81.19999999999924, "episode_reward_min": -562.0, "episode_reward_mean": -40.563999999999865, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000022, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -41.94699999999996, "predator_policy": 21.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.49999999999995, 16.69999999999993, 32.800000000000196, 67.9000000000002, 36.90000000000025, 67.0000000000003, -112.30000000000057, 25.20000000000007, 20.499999999999982, -24.799999999999564, 64.50000000000041, 34.00000000000022, 51.70000000000049, 2.3000000000001157, 23.900000000000055, 40.0000000000003, 34.900000000000226, -503.2, -549.3, 50.80000000000048, 48.10000000000043, -420.99999999999994, -491.0, 47.50000000000045, -483.5, 43.50000000000036, 56.600000000000506, 29.400000000000144, 47.200000000000415, 40.0000000000003, 46.3000000000004, 17.99999999999995, 21.90000000000002, 43.00000000000034, 40.0000000000003, 32.100000000000186, 40.0000000000003, 56.20000000000052, 9.699999999999942, 40.0000000000003, 27.90000000000012, 34.60000000000022, 55.600000000000534, 59.80000000000048, 40.0000000000003, -138.80000000000157, 26.80000000000009, 81.19999999999924, 27.300000000000104, -377.7, 40.0000000000003, 40.0000000000003, 47.300000000000416, -411.1, -562.0, 32.30000000000018, 23.100000000000026, 68.80000000000013, -207.39999999999998, 60.70000000000048, -302.50000000000006, 25.700000000000074, 49.00000000000045, 62.600000000000506, 15.79999999999994, 13.499999999999977, 23.800000000000047, 25.700000000000088, 25.20000000000007, -80.00000000000148, 15.999999999999925, 40.0000000000003, 0.7000000000001787, 3.7000000000001347, 40.0000000000003, -236.20000000000002, -21.199999999999584, 46.90000000000046, 38.900000000000276, 16.299999999999958, 67.90000000000018, 40.0000000000003, -527.4, 30.300000000000153, 40.0000000000003, 40.0000000000003, 23.000000000000043, -366.1, 39.300000000000296, 40.90000000000031, -513.9, 45.80000000000043, 51.50000000000049, -101.29999999999973, 40.0000000000003, 40.0000000000003, 26.800000000000107, -426.49999999999994, -97.20000000000111, 20.199999999999978], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-37.59999999999982, 13.099999999999971, 20.90000000000003, -26.19999999999979, 20.000000000000014, 3.7999999999999656, 23.600000000000065, 44.30000000000023, 21.80000000000004, -4.89999999999997, 37.10000000000026, 29.90000000000018, -194.20000000000027, -45.09999999999996, -14.799999999999779, 20.000000000000014, -19.899999999999743, 7.399999999999965, -40.89999999999979, -19.89999999999977, 20.000000000000014, 36.500000000000206, -6.999999999999934, 20.000000000000014, 31.700000000000212, 20.000000000000014, -61.300000000000615, 23.600000000000065, 1.0999999999999865, -8.199999999999916, 20.000000000000014, 20.000000000000014, 14.899999999999967, 7.999999999999968, -355.3, -367.9, -397.9, -360.4, 20.000000000000014, 30.800000000000196, 28.100000000000147, 20.000000000000014, -299.2, -302.79999999999995, -322.9, -339.1, 17.59999999999998, 17.899999999999988, -328.59999999999997, -355.9, 26.90000000000013, 11.599999999999966, 18.8, 30.8000000000002, 15.799999999999963, -3.399999999999976, 24.50000000000008, 22.700000000000053, 20.000000000000014, 20.000000000000014, 2.899999999999965, 34.40000000000025, 20.000000000000014, -21.999999999999766, -16.599999999999753, -17.49999999999978, 20.000000000000014, 20.000000000000018, 20.000000000000014, 20.000000000000014, 25.400000000000098, -10.299999999999851, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, -45.09999999999981, -11.199999999999848, 20.000000000000014, 20.000000000000014, 29.90000000000018, -21.99999999999975, 13.699999999999964, 17.899999999999988, 24.500000000000085, 28.100000000000147, 20.000000000000014, 33.800000000000225, 20.000000000000014, 20.000000000000014, -97.60000000000079, -110.20000000000078, -5.1999999999999265, 20.000000000000014, 43.100000000000236, 37.10000000000023, 20.000000000000014, -6.699999999999907, -299.2, -386.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 18.8, 24.50000000000008, -400.0, -228.09999999999994, -391.6, -366.4, 20.000000000000014, -3.6999999999999726, -13.899999999999782, 20.000000000000014, 45.20000000000022, 23.600000000000065, -140.50000000000003, -181.89999999999992, 20.000000000000014, 40.70000000000023, -184.3, -257.20000000000005, 20.000000000000014, -7.299999999999898, 20.000000000000014, 29.000000000000163, 30.800000000000196, 24.800000000000093, 17.899999999999988, -24.09999999999976, 29.90000000000019, -51.40000000000005, -32.49999999999976, 29.30000000000017, -7.29999999999993, 20.000000000000014, 20.000000000000014, -14.799999999999779, -91.90000000000072, -48.09999999999981, 7.99999999999997, -21.999999999999794, 20.000000000000014, 20.000000000000014, 8.299999999999969, -55.60000000000028, -49.29999999999982, 20.000000000000014, 20.000000000000014, 20.000000000000014, -196.3, -151.90000000000003, -100.00000000000074, 15.799999999999962, 16.099999999999973, 15.799999999999963, 20.000000000000014, 17.899999999999988, -27.699999999999754, 20.000000000000014, 20.000000000000014, 47.90000000000022, 20.000000000000014, 20.000000000000014, -365.2, -383.2, 29.30000000000017, -42.99999999999978, 20.000000000000014, 20.000000000000014, 25.700000000000106, 5.299999999999965, 18.199999999999992, -26.199999999999775, -229.0, -297.0999999999999, 15.199999999999962, -1.9, 20.900000000000027, 20.000000000000014, -362.2, -351.69999999999993, 33.50000000000024, -3.6999999999999833, 23.30000000000006, 27.20000000000013, -93.39999999999999, -82.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999955, 20.000000000000014, -326.5, -265.0, -130.00000000000057, -47.199999999999875, 20.000000000000014, -17.79999999999974], "policy_predator_policy_reward": [0.0, 39.0, 22.0, 0.0, 9.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 0.0, 79.0, 48.0, 20.0, 0.0, 14.0, 19.0, 32.0, 4.0, 0.0, 8.0, 0.0, 21.0, 0.0, 0.0, 10.0, 30.0, 0.0, 31.0, 0.0, 0.0, 12.0, 0.0, 189.0, 31.0, 10.0, 199.0, 0.0, 0.0, 0.0, 0.0, 29.0, 152.0, 0.0, 171.0, 2.0, 10.0, 22.0, 179.0, 1.0, 4.0, 0.0, 7.0, 15.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 20.0, 37.0, 19.0, 3.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 45.0, 21.0, 0.0, 0.0, 20.0, 0.0, 0.0, 3.0, 3.0, 0.0, 5.0, 1.0, 0.0, 0.0, 62.0, 7.0, 0.0, 12.0, 1.0, 0.0, 14.0, 0.0, 133.0, 175.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 186.0, 31.0, 196.0, 0.0, 16.0, 0.0, 0.0, 17.0, 0.0, 0.0, 9.0, 106.0, 0.0, 0.0, 132.0, 7.0, 13.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 21.0, 35.0, 0.0, 2.0, 25.0, 13.0, 0.0, 20.0, 0.0, 2.0, 58.0, 0.0, 30.0, 0.0, 0.0, 26.0, 22.0, 0.0, 33.0, 0.0, 0.0, 3.0, 109.0, 14.0, 49.0, 11.0, 4.0, 0.0, 1.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 23.0, 198.0, 23.0, 21.0, 0.0, 0.0, 2.0, 7.0, 9.0, 22.0, 146.0, 14.0, 13.0, 13.0, 0.0, 0.0, 185.0, 15.0, 0.0, 16.0, 1.0, 0.0, 26.0, 49.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 165.0, 0.0, 0.0, 80.0, 0.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.51846695962036, "mean_inference_ms": 12.19116957671107, "mean_action_processing_ms": 0.6282282834253232, "mean_env_wait_ms": 1.6705500248560923, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008927583694458008, "StateBufferConnector_ms": 0.015133857727050781, "ViewRequirementAgentConnector_ms": 0.2996567487716675}, "num_episodes": 18, "episode_return_max": 81.19999999999924, "episode_return_min": -562.0, "episode_return_mean": -40.563999999999865, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.07757441889544, "num_env_steps_trained_throughput_per_sec": 199.07757441889544, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 49064.678, "restore_workers_time_ms": 0.016, "training_step_time_ms": 49064.608, "sample_time_ms": 34226.51, "learn_time_ms": 14809.989, "learn_throughput": 270.088, "synch_weights_time_ms": 23.921}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "3a355_00000", "date": "2024-08-13_02-42-56", "timestamp": 1723531376, "time_this_iter_s": 20.148871898651123, "time_total_s": 5582.498504400253, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dcfee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5582.498504400253, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 87.26206896551724, "ram_util_percent": 83.2655172413793}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37558848946182816, "cur_kl_coeff": 3.637978807091713e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7245504565970609, "policy_loss": -0.0007247753789963782, "vf_loss": 1.7252752329937364, "vf_explained_var": 0.0013981783831561053, "kl": 0.0012770171301122676, "entropy": 0.16616424456159903, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9060909318624351, "cur_kl_coeff": 0.02252540588378906, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2872964719615916, "policy_loss": -0.005855316958247275, "vf_loss": 3.292722417563988, "vf_explained_var": 0.003310636458573518, "kl": 0.019061464827287475, "entropy": 1.0419287069764718, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 81.19999999999924, "episode_reward_min": -562.0, "episode_reward_mean": -41.31299999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000022, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -42.65649999999998, "predator_policy": 22.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [47.50000000000045, -483.5, 43.50000000000036, 56.600000000000506, 29.400000000000144, 47.200000000000415, 40.0000000000003, 46.3000000000004, 17.99999999999995, 21.90000000000002, 43.00000000000034, 40.0000000000003, 32.100000000000186, 40.0000000000003, 56.20000000000052, 9.699999999999942, 40.0000000000003, 27.90000000000012, 34.60000000000022, 55.600000000000534, 59.80000000000048, 40.0000000000003, -138.80000000000157, 26.80000000000009, 81.19999999999924, 27.300000000000104, -377.7, 40.0000000000003, 40.0000000000003, 47.300000000000416, -411.1, -562.0, 32.30000000000018, 23.100000000000026, 68.80000000000013, -207.39999999999998, 60.70000000000048, -302.50000000000006, 25.700000000000074, 49.00000000000045, 62.600000000000506, 15.79999999999994, 13.499999999999977, 23.800000000000047, 25.700000000000088, 25.20000000000007, -80.00000000000148, 15.999999999999925, 40.0000000000003, 0.7000000000001787, 3.7000000000001347, 40.0000000000003, -236.20000000000002, -21.199999999999584, 46.90000000000046, 38.900000000000276, 16.299999999999958, 67.90000000000018, 40.0000000000003, -527.4, 30.300000000000153, 40.0000000000003, 40.0000000000003, 23.000000000000043, -366.1, 39.300000000000296, 40.90000000000031, -513.9, 45.80000000000043, 51.50000000000049, -101.29999999999973, 40.0000000000003, 40.0000000000003, 26.800000000000107, -426.49999999999994, -97.20000000000111, 20.199999999999978, -0.39999999999983193, -141.99999999999963, 53.300000000000466, 56.300000000000495, -19.099999999999554, -110.99999999999964, 58.90000000000049, 56.300000000000466, 40.0000000000003, 41.000000000000306, 67.90000000000025, -137.6000000000013, 15.599999999999921, -277.20000000000016, 33.400000000000205, 33.400000000000205, 40.0000000000003, 30.60000000000017, 45.40000000000038, -432.9, -377.5999999999999, -354.1, -264.9999999999977], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.59999999999998, 17.899999999999988, -328.59999999999997, -355.9, 26.90000000000013, 11.599999999999966, 18.8, 30.8000000000002, 15.799999999999963, -3.399999999999976, 24.50000000000008, 22.700000000000053, 20.000000000000014, 20.000000000000014, 2.899999999999965, 34.40000000000025, 20.000000000000014, -21.999999999999766, -16.599999999999753, -17.49999999999978, 20.000000000000014, 20.000000000000018, 20.000000000000014, 20.000000000000014, 25.400000000000098, -10.299999999999851, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, -45.09999999999981, -11.199999999999848, 20.000000000000014, 20.000000000000014, 29.90000000000018, -21.99999999999975, 13.699999999999964, 17.899999999999988, 24.500000000000085, 28.100000000000147, 20.000000000000014, 33.800000000000225, 20.000000000000014, 20.000000000000014, -97.60000000000079, -110.20000000000078, -5.1999999999999265, 20.000000000000014, 43.100000000000236, 37.10000000000023, 20.000000000000014, -6.699999999999907, -299.2, -386.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 18.8, 24.50000000000008, -400.0, -228.09999999999994, -391.6, -366.4, 20.000000000000014, -3.6999999999999726, -13.899999999999782, 20.000000000000014, 45.20000000000022, 23.600000000000065, -140.50000000000003, -181.89999999999992, 20.000000000000014, 40.70000000000023, -184.3, -257.20000000000005, 20.000000000000014, -7.299999999999898, 20.000000000000014, 29.000000000000163, 30.800000000000196, 24.800000000000093, 17.899999999999988, -24.09999999999976, 29.90000000000019, -51.40000000000005, -32.49999999999976, 29.30000000000017, -7.29999999999993, 20.000000000000014, 20.000000000000014, -14.799999999999779, -91.90000000000072, -48.09999999999981, 7.99999999999997, -21.999999999999794, 20.000000000000014, 20.000000000000014, 8.299999999999969, -55.60000000000028, -49.29999999999982, 20.000000000000014, 20.000000000000014, 20.000000000000014, -196.3, -151.90000000000003, -100.00000000000074, 15.799999999999962, 16.099999999999973, 15.799999999999963, 20.000000000000014, 17.899999999999988, -27.699999999999754, 20.000000000000014, 20.000000000000014, 47.90000000000022, 20.000000000000014, 20.000000000000014, -365.2, -383.2, 29.30000000000017, -42.99999999999978, 20.000000000000014, 20.000000000000014, 25.700000000000106, 5.299999999999965, 18.199999999999992, -26.199999999999775, -229.0, -297.0999999999999, 15.199999999999962, -1.9, 20.900000000000027, 20.000000000000014, -362.2, -351.69999999999993, 33.50000000000024, -3.6999999999999833, 23.30000000000006, 27.20000000000013, -93.39999999999999, -82.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999955, 20.000000000000014, -326.5, -265.0, -130.00000000000057, -47.199999999999875, 20.000000000000014, -17.79999999999974, -2.800000000000029, -31.59999999999979, -164.80000000000064, -68.20000000000002, 4.699999999999978, 29.600000000000204, 20.000000000000014, 32.300000000000225, -6.399999999999936, -48.69999999999979, -86.79999999999998, -83.19999999999993, 28.100000000000154, 30.800000000000203, 16.09999999999996, 27.20000000000013, 20.000000000000014, 20.000000000000014, 18.19999999999999, 15.799999999999963, 38.00000000000025, 29.90000000000018, -129.10000000000073, -107.50000000000057, 26.600000000000122, -42.99999999999976, -368.5, -93.69999999999993, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 21.20000000000003, 20.000000000000014, 20.000000000000014, -19.599999999999795, -2.8000000000000007, 25.400000000000098, 20.000000000000014, -232.89999999999992, -400.0, -256.3, -286.29999999999995, -244.60000000000002, -242.5, -174.4000000000003, -211.60000000000028], "policy_predator_policy_reward": [2.0, 10.0, 22.0, 179.0, 1.0, 4.0, 0.0, 7.0, 15.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 20.0, 37.0, 19.0, 3.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 45.0, 21.0, 0.0, 0.0, 20.0, 0.0, 0.0, 3.0, 3.0, 0.0, 5.0, 1.0, 0.0, 0.0, 62.0, 7.0, 0.0, 12.0, 1.0, 0.0, 14.0, 0.0, 133.0, 175.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 186.0, 31.0, 196.0, 0.0, 16.0, 0.0, 0.0, 17.0, 0.0, 0.0, 9.0, 106.0, 0.0, 0.0, 132.0, 7.0, 13.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 21.0, 35.0, 0.0, 2.0, 25.0, 13.0, 0.0, 20.0, 0.0, 2.0, 58.0, 0.0, 30.0, 0.0, 0.0, 26.0, 22.0, 0.0, 33.0, 0.0, 0.0, 3.0, 109.0, 14.0, 49.0, 11.0, 4.0, 0.0, 1.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 23.0, 198.0, 23.0, 21.0, 0.0, 0.0, 2.0, 7.0, 9.0, 22.0, 146.0, 14.0, 13.0, 13.0, 0.0, 0.0, 185.0, 15.0, 0.0, 16.0, 1.0, 0.0, 26.0, 49.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 165.0, 0.0, 0.0, 80.0, 0.0, 18.0, 34.0, 0.0, 88.0, 3.0, 0.0, 19.0, 0.0, 4.0, 0.0, 36.0, 53.0, 6.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 99.0, 0.0, 18.0, 14.0, 17.0, 168.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 37.0, 16.0, 0.0, 0.0, 0.0, 200.0, 10.0, 155.0, 133.0, 0.0, 6.0, 115.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.506566883810945, "mean_inference_ms": 12.056579851444669, "mean_action_processing_ms": 0.6280609559254517, "mean_env_wait_ms": 1.6477646768012, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014371395111083984, "StateBufferConnector_ms": 0.01503002643585205, "ViewRequirementAgentConnector_ms": 0.27973437309265137}, "num_episodes": 23, "episode_return_max": 81.19999999999924, "episode_return_min": -562.0, "episode_return_mean": -41.31299999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 193.63564742861587, "num_env_steps_trained_throughput_per_sec": 193.63564742861587, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 18059.986, "restore_workers_time_ms": 0.016, "training_step_time_ms": 18059.915, "sample_time_ms": 2986.208, "learn_time_ms": 15046.018, "learn_throughput": 265.851, "synch_weights_time_ms": 23.836}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "3a355_00000", "date": "2024-08-13_02-43-17", "timestamp": 1723531397, "time_this_iter_s": 20.707387924194336, "time_total_s": 5603.205892324448, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52ab550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5603.205892324448, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 88.11379310344829, "ram_util_percent": 83.38275862068966}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4534897947555812, "cur_kl_coeff": 1.8189894035458566e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.158910110734758, "policy_loss": -0.0012313830275729142, "vf_loss": 1.1601414955166913, "vf_explained_var": 0.002253385447951221, "kl": 0.0015999617838272306, "entropy": 0.1451050268476287, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0660703255898423, "cur_kl_coeff": 0.02252540588378906, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.207841337578637, "policy_loss": -0.0008508041540466289, "vf_loss": 2.208587513998072, "vf_explained_var": 0.0015786984925547606, "kl": 0.004644868194106001, "entropy": 1.0956178424850342, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 81.19999999999924, "episode_reward_min": -562.0, "episode_reward_mean": -48.64099999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000022, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -47.51049999999997, "predator_policy": 23.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.60000000000022, 55.600000000000534, 59.80000000000048, 40.0000000000003, -138.80000000000157, 26.80000000000009, 81.19999999999924, 27.300000000000104, -377.7, 40.0000000000003, 40.0000000000003, 47.300000000000416, -411.1, -562.0, 32.30000000000018, 23.100000000000026, 68.80000000000013, -207.39999999999998, 60.70000000000048, -302.50000000000006, 25.700000000000074, 49.00000000000045, 62.600000000000506, 15.79999999999994, 13.499999999999977, 23.800000000000047, 25.700000000000088, 25.20000000000007, -80.00000000000148, 15.999999999999925, 40.0000000000003, 0.7000000000001787, 3.7000000000001347, 40.0000000000003, -236.20000000000002, -21.199999999999584, 46.90000000000046, 38.900000000000276, 16.299999999999958, 67.90000000000018, 40.0000000000003, -527.4, 30.300000000000153, 40.0000000000003, 40.0000000000003, 23.000000000000043, -366.1, 39.300000000000296, 40.90000000000031, -513.9, 45.80000000000043, 51.50000000000049, -101.29999999999973, 40.0000000000003, 40.0000000000003, 26.800000000000107, -426.49999999999994, -97.20000000000111, 20.199999999999978, -0.39999999999983193, -141.99999999999963, 53.300000000000466, 56.300000000000495, -19.099999999999554, -110.99999999999964, 58.90000000000049, 56.300000000000466, 40.0000000000003, 41.000000000000306, 67.90000000000025, -137.6000000000013, 15.599999999999921, -277.20000000000016, 33.400000000000205, 33.400000000000205, 40.0000000000003, 30.60000000000017, 45.40000000000038, -432.9, -377.5999999999999, -354.1, -264.9999999999977, 40.0000000000003, 40.700000000000315, 76.39999999999962, 32.30000000000019, 48.10000000000043, 56.90000000000051, 24.700000000000063, 61.600000000000506, -266.7999999999999, 26.600000000000087, 40.0000000000003, 41.200000000000315, -222.7000000000007, -353.8999999999999, 43.300000000000345, 58.000000000000526, 48.10000000000043, -371.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999964, 17.899999999999988, 24.500000000000085, 28.100000000000147, 20.000000000000014, 33.800000000000225, 20.000000000000014, 20.000000000000014, -97.60000000000079, -110.20000000000078, -5.1999999999999265, 20.000000000000014, 43.100000000000236, 37.10000000000023, 20.000000000000014, -6.699999999999907, -299.2, -386.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 18.8, 24.50000000000008, -400.0, -228.09999999999994, -391.6, -366.4, 20.000000000000014, -3.6999999999999726, -13.899999999999782, 20.000000000000014, 45.20000000000022, 23.600000000000065, -140.50000000000003, -181.89999999999992, 20.000000000000014, 40.70000000000023, -184.3, -257.20000000000005, 20.000000000000014, -7.299999999999898, 20.000000000000014, 29.000000000000163, 30.800000000000196, 24.800000000000093, 17.899999999999988, -24.09999999999976, 29.90000000000019, -51.40000000000005, -32.49999999999976, 29.30000000000017, -7.29999999999993, 20.000000000000014, 20.000000000000014, -14.799999999999779, -91.90000000000072, -48.09999999999981, 7.99999999999997, -21.999999999999794, 20.000000000000014, 20.000000000000014, 8.299999999999969, -55.60000000000028, -49.29999999999982, 20.000000000000014, 20.000000000000014, 20.000000000000014, -196.3, -151.90000000000003, -100.00000000000074, 15.799999999999962, 16.099999999999973, 15.799999999999963, 20.000000000000014, 17.899999999999988, -27.699999999999754, 20.000000000000014, 20.000000000000014, 47.90000000000022, 20.000000000000014, 20.000000000000014, -365.2, -383.2, 29.30000000000017, -42.99999999999978, 20.000000000000014, 20.000000000000014, 25.700000000000106, 5.299999999999965, 18.199999999999992, -26.199999999999775, -229.0, -297.0999999999999, 15.199999999999962, -1.9, 20.900000000000027, 20.000000000000014, -362.2, -351.69999999999993, 33.50000000000024, -3.6999999999999833, 23.30000000000006, 27.20000000000013, -93.39999999999999, -82.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999955, 20.000000000000014, -326.5, -265.0, -130.00000000000057, -47.199999999999875, 20.000000000000014, -17.79999999999974, -2.800000000000029, -31.59999999999979, -164.80000000000064, -68.20000000000002, 4.699999999999978, 29.600000000000204, 20.000000000000014, 32.300000000000225, -6.399999999999936, -48.69999999999979, -86.79999999999998, -83.19999999999993, 28.100000000000154, 30.800000000000203, 16.09999999999996, 27.20000000000013, 20.000000000000014, 20.000000000000014, 18.19999999999999, 15.799999999999963, 38.00000000000025, 29.90000000000018, -129.10000000000073, -107.50000000000057, 26.600000000000122, -42.99999999999976, -368.5, -93.69999999999993, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 21.20000000000003, 20.000000000000014, 20.000000000000014, -19.599999999999795, -2.8000000000000007, 25.400000000000098, 20.000000000000014, -232.89999999999992, -400.0, -256.3, -286.29999999999995, -244.60000000000002, -242.5, -174.4000000000003, -211.60000000000028, 20.000000000000014, 20.000000000000014, 19.70000000000001, 20.000000000000014, 34.10000000000026, 41.300000000000246, 5.299999999999965, 20.000000000000014, 20.000000000000014, 28.100000000000147, 20.000000000000014, 35.900000000000254, 20.000000000000014, -28.299999999999763, 41.60000000000024, 20.000000000000014, -162.70000000000002, -225.10000000000002, -7.299999999999894, 20.90000000000003, 20.000000000000014, 20.000000000000014, 6.199999999999969, 20.000000000000014, -87.10000000000068, -301.59999999999974, -296.79999999999995, -219.0999999999999, 17.299999999999976, 20.000000000000014, 34.40000000000026, 23.600000000000065, 28.100000000000147, 20.000000000000014, -265.5999999999999, -250.90000000000003], "policy_predator_policy_reward": [0.0, 3.0, 3.0, 0.0, 5.0, 1.0, 0.0, 0.0, 62.0, 7.0, 0.0, 12.0, 1.0, 0.0, 14.0, 0.0, 133.0, 175.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 186.0, 31.0, 196.0, 0.0, 16.0, 0.0, 0.0, 17.0, 0.0, 0.0, 9.0, 106.0, 0.0, 0.0, 132.0, 7.0, 13.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 21.0, 35.0, 0.0, 2.0, 25.0, 13.0, 0.0, 20.0, 0.0, 2.0, 58.0, 0.0, 30.0, 0.0, 0.0, 26.0, 22.0, 0.0, 33.0, 0.0, 0.0, 3.0, 109.0, 14.0, 49.0, 11.0, 4.0, 0.0, 1.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 23.0, 198.0, 23.0, 21.0, 0.0, 0.0, 2.0, 7.0, 9.0, 22.0, 146.0, 14.0, 13.0, 13.0, 0.0, 0.0, 185.0, 15.0, 0.0, 16.0, 1.0, 0.0, 26.0, 49.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 165.0, 0.0, 0.0, 80.0, 0.0, 18.0, 34.0, 0.0, 88.0, 3.0, 0.0, 19.0, 0.0, 4.0, 0.0, 36.0, 53.0, 6.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 99.0, 0.0, 18.0, 14.0, 17.0, 168.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 37.0, 16.0, 0.0, 0.0, 0.0, 200.0, 10.0, 155.0, 133.0, 0.0, 6.0, 115.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 121.0, 0.0, 13.0, 0.0, 0.0, 6.0, 9.0, 0.0, 166.0, 0.0, 162.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 140.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4934116467053906, "mean_inference_ms": 11.952433905396704, "mean_action_processing_ms": 0.6277951345643263, "mean_env_wait_ms": 1.632616852132307, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013298273086547852, "StateBufferConnector_ms": 0.008270621299743652, "ViewRequirementAgentConnector_ms": 0.2618691921234131}, "num_episodes": 18, "episode_return_max": 81.19999999999924, "episode_return_min": -562.0, "episode_return_mean": -48.64099999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 185.77250926032534, "num_env_steps_trained_throughput_per_sec": 185.77250926032534, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 18630.011, "restore_workers_time_ms": 0.015, "training_step_time_ms": 18629.958, "sample_time_ms": 2961.247, "learn_time_ms": 15640.214, "learn_throughput": 255.751, "synch_weights_time_ms": 24.264}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "3a355_00000", "date": "2024-08-13_02-43-39", "timestamp": 1723531419, "time_this_iter_s": 21.59616994857788, "time_total_s": 5624.8020622730255, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52abf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5624.8020622730255, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 85.66000000000001, "ram_util_percent": 83.31333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4614212158752024, "cur_kl_coeff": 9.094947017729283e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4475613429748193, "policy_loss": -0.000711357149187101, "vf_loss": 1.4482727025236402, "vf_explained_var": 0.0007068301319445252, "kl": 0.0007759619982272149, "entropy": 0.17750205370011152, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.89987479872292, "cur_kl_coeff": 0.01126270294189453, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.284313958410233, "policy_loss": -0.001180223505401974, "vf_loss": 2.2853876289236483, "vf_explained_var": 0.003178197082388338, "kl": 0.009460782373935024, "entropy": 1.15529625415802, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 76.39999999999962, "episode_reward_min": -527.4, "episode_reward_mean": -46.34499999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 47.90000000000022, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -45.947499999999984, "predator_policy": 22.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.70000000000048, -302.50000000000006, 25.700000000000074, 49.00000000000045, 62.600000000000506, 15.79999999999994, 13.499999999999977, 23.800000000000047, 25.700000000000088, 25.20000000000007, -80.00000000000148, 15.999999999999925, 40.0000000000003, 0.7000000000001787, 3.7000000000001347, 40.0000000000003, -236.20000000000002, -21.199999999999584, 46.90000000000046, 38.900000000000276, 16.299999999999958, 67.90000000000018, 40.0000000000003, -527.4, 30.300000000000153, 40.0000000000003, 40.0000000000003, 23.000000000000043, -366.1, 39.300000000000296, 40.90000000000031, -513.9, 45.80000000000043, 51.50000000000049, -101.29999999999973, 40.0000000000003, 40.0000000000003, 26.800000000000107, -426.49999999999994, -97.20000000000111, 20.199999999999978, -0.39999999999983193, -141.99999999999963, 53.300000000000466, 56.300000000000495, -19.099999999999554, -110.99999999999964, 58.90000000000049, 56.300000000000466, 40.0000000000003, 41.000000000000306, 67.90000000000025, -137.6000000000013, 15.599999999999921, -277.20000000000016, 33.400000000000205, 33.400000000000205, 40.0000000000003, 30.60000000000017, 45.40000000000038, -432.9, -377.5999999999999, -354.1, -264.9999999999977, 40.0000000000003, 40.700000000000315, 76.39999999999962, 32.30000000000019, 48.10000000000043, 56.90000000000051, 24.700000000000063, 61.600000000000506, -266.7999999999999, 26.600000000000087, 40.0000000000003, 41.200000000000315, -222.7000000000007, -353.8999999999999, 43.300000000000345, 58.000000000000526, 48.10000000000043, -371.5, 47.20000000000042, 58.70000000000051, 61.70000000000051, -171.60000000000008, -303.6000000000007, 49.80000000000047, 44.40000000000037, -520.5, 22.40000000000002, 62.500000000000504, 40.0000000000003, -223.59999999999974, 51.8000000000005, 38.300000000000274, 25.700000000000074, 9.999999999999968, -223.79999999999998, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 40.70000000000023, -184.3, -257.20000000000005, 20.000000000000014, -7.299999999999898, 20.000000000000014, 29.000000000000163, 30.800000000000196, 24.800000000000093, 17.899999999999988, -24.09999999999976, 29.90000000000019, -51.40000000000005, -32.49999999999976, 29.30000000000017, -7.29999999999993, 20.000000000000014, 20.000000000000014, -14.799999999999779, -91.90000000000072, -48.09999999999981, 7.99999999999997, -21.999999999999794, 20.000000000000014, 20.000000000000014, 8.299999999999969, -55.60000000000028, -49.29999999999982, 20.000000000000014, 20.000000000000014, 20.000000000000014, -196.3, -151.90000000000003, -100.00000000000074, 15.799999999999962, 16.099999999999973, 15.799999999999963, 20.000000000000014, 17.899999999999988, -27.699999999999754, 20.000000000000014, 20.000000000000014, 47.90000000000022, 20.000000000000014, 20.000000000000014, -365.2, -383.2, 29.30000000000017, -42.99999999999978, 20.000000000000014, 20.000000000000014, 25.700000000000106, 5.299999999999965, 18.199999999999992, -26.199999999999775, -229.0, -297.0999999999999, 15.199999999999962, -1.9, 20.900000000000027, 20.000000000000014, -362.2, -351.69999999999993, 33.50000000000024, -3.6999999999999833, 23.30000000000006, 27.20000000000013, -93.39999999999999, -82.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999955, 20.000000000000014, -326.5, -265.0, -130.00000000000057, -47.199999999999875, 20.000000000000014, -17.79999999999974, -2.800000000000029, -31.59999999999979, -164.80000000000064, -68.20000000000002, 4.699999999999978, 29.600000000000204, 20.000000000000014, 32.300000000000225, -6.399999999999936, -48.69999999999979, -86.79999999999998, -83.19999999999993, 28.100000000000154, 30.800000000000203, 16.09999999999996, 27.20000000000013, 20.000000000000014, 20.000000000000014, 18.19999999999999, 15.799999999999963, 38.00000000000025, 29.90000000000018, -129.10000000000073, -107.50000000000057, 26.600000000000122, -42.99999999999976, -368.5, -93.69999999999993, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 21.20000000000003, 20.000000000000014, 20.000000000000014, -19.599999999999795, -2.8000000000000007, 25.400000000000098, 20.000000000000014, -232.89999999999992, -400.0, -256.3, -286.29999999999995, -244.60000000000002, -242.5, -174.4000000000003, -211.60000000000028, 20.000000000000014, 20.000000000000014, 19.70000000000001, 20.000000000000014, 34.10000000000026, 41.300000000000246, 5.299999999999965, 20.000000000000014, 20.000000000000014, 28.100000000000147, 20.000000000000014, 35.900000000000254, 20.000000000000014, -28.299999999999763, 41.60000000000024, 20.000000000000014, -162.70000000000002, -225.10000000000002, -7.299999999999894, 20.90000000000003, 20.000000000000014, 20.000000000000014, 6.199999999999969, 20.000000000000014, -87.10000000000068, -301.59999999999974, -296.79999999999995, -219.0999999999999, 17.299999999999976, 20.000000000000014, 34.40000000000026, 23.600000000000065, 28.100000000000147, 20.000000000000014, -265.5999999999999, -250.90000000000003, 9.199999999999969, 29.000000000000163, 20.000000000000014, 37.70000000000025, 28.100000000000147, 29.60000000000018, -40.90000000000003, -267.7, -233.2000000000003, -207.40000000000043, 24.800000000000093, 20.000000000000014, 15.799999999999963, 26.600000000000122, -330.7, -383.8, -5.199999999999944, 11.599999999999964, 20.000000000000014, 42.50000000000025, 20.000000000000014, 20.000000000000014, -246.70000000000041, -145.90000000000003, 11.599999999999964, 36.20000000000026, 20.000000000000014, -15.699999999999747, 20.000000000000014, -7.299999999999898, -76.30000000000078, 35.30000000000026, -233.50000000000003, -112.30000000000004, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 132.0, 7.0, 13.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 21.0, 35.0, 0.0, 2.0, 25.0, 13.0, 0.0, 20.0, 0.0, 2.0, 58.0, 0.0, 30.0, 0.0, 0.0, 26.0, 22.0, 0.0, 33.0, 0.0, 0.0, 3.0, 109.0, 14.0, 49.0, 11.0, 4.0, 0.0, 1.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 23.0, 198.0, 23.0, 21.0, 0.0, 0.0, 2.0, 7.0, 9.0, 22.0, 146.0, 14.0, 13.0, 13.0, 0.0, 0.0, 185.0, 15.0, 0.0, 16.0, 1.0, 0.0, 26.0, 49.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 165.0, 0.0, 0.0, 80.0, 0.0, 18.0, 34.0, 0.0, 88.0, 3.0, 0.0, 19.0, 0.0, 4.0, 0.0, 36.0, 53.0, 6.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 99.0, 0.0, 18.0, 14.0, 17.0, 168.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 37.0, 16.0, 0.0, 0.0, 0.0, 200.0, 10.0, 155.0, 133.0, 0.0, 6.0, 115.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 121.0, 0.0, 13.0, 0.0, 0.0, 6.0, 9.0, 0.0, 166.0, 0.0, 162.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 140.0, 9.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 137.0, 137.0, 0.0, 0.0, 5.0, 0.0, 2.0, 194.0, 0.0, 12.0, 4.0, 0.0, 0.0, 0.0, 0.0, 90.0, 79.0, 0.0, 4.0, 17.0, 17.0, 13.0, 0.0, 0.0, 51.0, 0.0, 122.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4799079872446987, "mean_inference_ms": 11.8494365550333, "mean_action_processing_ms": 0.6271175491190043, "mean_env_wait_ms": 1.6175034340638172, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013892769813537598, "StateBufferConnector_ms": 0.0084153413772583, "ViewRequirementAgentConnector_ms": 0.25994133949279785}, "num_episodes": 18, "episode_return_max": 76.39999999999962, "episode_return_min": -527.4, "episode_return_mean": -46.34499999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 192.11169995573255, "num_env_steps_trained_throughput_per_sec": 192.11169995573255, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 19204.528, "restore_workers_time_ms": 0.016, "training_step_time_ms": 19204.474, "sample_time_ms": 3093.253, "learn_time_ms": 16079.027, "learn_throughput": 248.771, "synch_weights_time_ms": 27.93}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "3a355_00000", "date": "2024-08-13_02-44-00", "timestamp": 1723531440, "time_this_iter_s": 20.878992080688477, "time_total_s": 5645.681054353714, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dcfee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5645.681054353714, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 85.45, "ram_util_percent": 83.33}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45562466629164877, "cur_kl_coeff": 4.5474735088646414e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2720643770442437, "policy_loss": -0.0001415149930854717, "vf_loss": 1.2722058920160173, "vf_explained_var": 0.001926930966200652, "kl": 0.000800730915150963, "entropy": 0.1663689325371432, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.069268463918614, "cur_kl_coeff": 0.01126270294189453, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1527720901385816, "policy_loss": -0.0016223016835591466, "vf_loss": 2.154180955823767, "vf_explained_var": 0.0007861791464386793, "kl": 0.01895052154993315, "entropy": 1.2077857648884809, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 76.39999999999962, "episode_reward_min": -527.4, "episode_reward_mean": -46.482999999999784, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 43.40000000000023, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -45.44649999999998, "predator_policy": 22.205}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, -527.4, 30.300000000000153, 40.0000000000003, 40.0000000000003, 23.000000000000043, -366.1, 39.300000000000296, 40.90000000000031, -513.9, 45.80000000000043, 51.50000000000049, -101.29999999999973, 40.0000000000003, 40.0000000000003, 26.800000000000107, -426.49999999999994, -97.20000000000111, 20.199999999999978, -0.39999999999983193, -141.99999999999963, 53.300000000000466, 56.300000000000495, -19.099999999999554, -110.99999999999964, 58.90000000000049, 56.300000000000466, 40.0000000000003, 41.000000000000306, 67.90000000000025, -137.6000000000013, 15.599999999999921, -277.20000000000016, 33.400000000000205, 33.400000000000205, 40.0000000000003, 30.60000000000017, 45.40000000000038, -432.9, -377.5999999999999, -354.1, -264.9999999999977, 40.0000000000003, 40.700000000000315, 76.39999999999962, 32.30000000000019, 48.10000000000043, 56.90000000000051, 24.700000000000063, 61.600000000000506, -266.7999999999999, 26.600000000000087, 40.0000000000003, 41.200000000000315, -222.7000000000007, -353.8999999999999, 43.300000000000345, 58.000000000000526, 48.10000000000043, -371.5, 47.20000000000042, 58.70000000000051, 61.70000000000051, -171.60000000000008, -303.6000000000007, 49.80000000000047, 44.40000000000037, -520.5, 22.40000000000002, 62.500000000000504, 40.0000000000003, -223.59999999999974, 51.8000000000005, 38.300000000000274, 25.700000000000074, 9.999999999999968, -223.79999999999998, 40.0000000000003, 63.400000000000475, 26.20000000000009, 40.0000000000003, 31.200000000000166, 13.09999999999995, 61.60000000000047, 24.70000000000006, 58.90000000000048, -520.8, 32.800000000000196, -17.799999999999528, 44.50000000000038, 38.50000000000028, 61.00000000000052, 37.90000000000027, 40.0000000000003, 37.80000000000027, 19.699999999999992, 30.100000000000144, -248.69999999999987, 38.9000000000003, 5.700000000000076], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -365.2, -383.2, 29.30000000000017, -42.99999999999978, 20.000000000000014, 20.000000000000014, 25.700000000000106, 5.299999999999965, 18.199999999999992, -26.199999999999775, -229.0, -297.0999999999999, 15.199999999999962, -1.9, 20.900000000000027, 20.000000000000014, -362.2, -351.69999999999993, 33.50000000000024, -3.6999999999999833, 23.30000000000006, 27.20000000000013, -93.39999999999999, -82.90000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.199999999999955, 20.000000000000014, -326.5, -265.0, -130.00000000000057, -47.199999999999875, 20.000000000000014, -17.79999999999974, -2.800000000000029, -31.59999999999979, -164.80000000000064, -68.20000000000002, 4.699999999999978, 29.600000000000204, 20.000000000000014, 32.300000000000225, -6.399999999999936, -48.69999999999979, -86.79999999999998, -83.19999999999993, 28.100000000000154, 30.800000000000203, 16.09999999999996, 27.20000000000013, 20.000000000000014, 20.000000000000014, 18.19999999999999, 15.799999999999963, 38.00000000000025, 29.90000000000018, -129.10000000000073, -107.50000000000057, 26.600000000000122, -42.99999999999976, -368.5, -93.69999999999993, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 21.20000000000003, 20.000000000000014, 20.000000000000014, -19.599999999999795, -2.8000000000000007, 25.400000000000098, 20.000000000000014, -232.89999999999992, -400.0, -256.3, -286.29999999999995, -244.60000000000002, -242.5, -174.4000000000003, -211.60000000000028, 20.000000000000014, 20.000000000000014, 19.70000000000001, 20.000000000000014, 34.10000000000026, 41.300000000000246, 5.299999999999965, 20.000000000000014, 20.000000000000014, 28.100000000000147, 20.000000000000014, 35.900000000000254, 20.000000000000014, -28.299999999999763, 41.60000000000024, 20.000000000000014, -162.70000000000002, -225.10000000000002, -7.299999999999894, 20.90000000000003, 20.000000000000014, 20.000000000000014, 6.199999999999969, 20.000000000000014, -87.10000000000068, -301.59999999999974, -296.79999999999995, -219.0999999999999, 17.299999999999976, 20.000000000000014, 34.40000000000026, 23.600000000000065, 28.100000000000147, 20.000000000000014, -265.5999999999999, -250.90000000000003, 9.199999999999969, 29.000000000000163, 20.000000000000014, 37.70000000000025, 28.100000000000147, 29.60000000000018, -40.90000000000003, -267.7, -233.2000000000003, -207.40000000000043, 24.800000000000093, 20.000000000000014, 15.799999999999963, 26.600000000000122, -330.7, -383.8, -5.199999999999944, 11.599999999999964, 20.000000000000014, 42.50000000000025, 20.000000000000014, 20.000000000000014, -246.70000000000041, -145.90000000000003, 11.599999999999964, 36.20000000000026, 20.000000000000014, -15.699999999999747, 20.000000000000014, -7.299999999999898, -76.30000000000078, 35.30000000000026, -233.50000000000003, -112.30000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 43.40000000000023, -38.79999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, -25.299999999999784, 41.60000000000023, 20.000000000000014, -20.19999999999976, 17.899999999999988, 20.000000000000014, 38.90000000000023, -343.3, -359.5, 1.0999999999999865, 22.700000000000053, -19.899999999999764, -19.899999999999764, 24.50000000000009, 20.000000000000014, 20.000000000000014, 15.499999999999964, 30.8000000000002, 27.20000000000013, -11.49999999999983, 34.40000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -23.19999999999976, 17.899999999999988, 13.699999999999964, 7.399999999999965, -242.5000000000002, -131.20000000000005, 20.000000000000014, 17.89999999999999, 28.100000000000154, -63.40000000000079], "policy_predator_policy_reward": [0.0, 0.0, 23.0, 198.0, 23.0, 21.0, 0.0, 0.0, 2.0, 7.0, 9.0, 22.0, 146.0, 14.0, 13.0, 13.0, 0.0, 0.0, 185.0, 15.0, 0.0, 16.0, 1.0, 0.0, 26.0, 49.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 165.0, 0.0, 0.0, 80.0, 0.0, 18.0, 34.0, 0.0, 88.0, 3.0, 0.0, 19.0, 0.0, 4.0, 0.0, 36.0, 53.0, 6.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 99.0, 0.0, 18.0, 14.0, 17.0, 168.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 37.0, 16.0, 0.0, 0.0, 0.0, 200.0, 10.0, 155.0, 133.0, 0.0, 6.0, 115.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 121.0, 0.0, 13.0, 0.0, 0.0, 6.0, 9.0, 0.0, 166.0, 0.0, 162.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 140.0, 9.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 137.0, 137.0, 0.0, 0.0, 5.0, 0.0, 2.0, 194.0, 0.0, 12.0, 4.0, 0.0, 0.0, 0.0, 0.0, 90.0, 79.0, 0.0, 4.0, 17.0, 17.0, 13.0, 0.0, 0.0, 51.0, 0.0, 122.0, 0.0, 0.0, 0.0, 0.0, 24.0, 21.0, 0.0, 0.0, 0.0, 8.0, 0.0, 31.0, 0.0, 0.0, 21.0, 6.0, 0.0, 0.0, 179.0, 3.0, 0.0, 9.0, 0.0, 22.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 15.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 24.0, 6.0, 3.0, 0.0, 125.0, 0.0, 1.0, 20.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4638824987200265, "mean_inference_ms": 11.736285315691962, "mean_action_processing_ms": 0.6275949867472073, "mean_env_wait_ms": 1.6034077580422967, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02037835121154785, "StateBufferConnector_ms": 0.007815837860107422, "ViewRequirementAgentConnector_ms": 0.28748786449432373}, "num_episodes": 22, "episode_return_max": 76.39999999999962, "episode_return_min": -527.4, "episode_return_mean": -46.482999999999784, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 173.0964278307533, "num_env_steps_trained_throughput_per_sec": 173.0964278307533, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 19957.02, "restore_workers_time_ms": 0.016, "training_step_time_ms": 19956.964, "sample_time_ms": 3503.72, "learn_time_ms": 16420.555, "learn_throughput": 243.597, "synch_weights_time_ms": 28.354}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "3a355_00000", "date": "2024-08-13_02-44-23", "timestamp": 1723531463, "time_this_iter_s": 23.19321918487549, "time_total_s": 5668.8742735385895, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dcf940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5668.8742735385895, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 86.66060606060606, "ram_util_percent": 83.41818181818182}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.63295707296994, "cur_kl_coeff": 2.2737367544323207e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.662170698529198, "policy_loss": -0.0015162467205078987, "vf_loss": 1.6636869388597983, "vf_explained_var": 0.001505814059070809, "kl": 0.002938196173549829, "entropy": 0.21661811223421149, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9502939266660226, "cur_kl_coeff": 0.01126270294189453, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5222377423729214, "policy_loss": -0.0018313914955046678, "vf_loss": 2.523898554005951, "vf_explained_var": 0.001731306755984271, "kl": 0.015145477136151062, "entropy": 1.1972899679153686, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 85.89999999999887, "episode_reward_min": -520.8, "episode_reward_mean": -39.5459999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 61.4000000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -41.51799999999997, "predator_policy": 21.745}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-19.099999999999554, -110.99999999999964, 58.90000000000049, 56.300000000000466, 40.0000000000003, 41.000000000000306, 67.90000000000025, -137.6000000000013, 15.599999999999921, -277.20000000000016, 33.400000000000205, 33.400000000000205, 40.0000000000003, 30.60000000000017, 45.40000000000038, -432.9, -377.5999999999999, -354.1, -264.9999999999977, 40.0000000000003, 40.700000000000315, 76.39999999999962, 32.30000000000019, 48.10000000000043, 56.90000000000051, 24.700000000000063, 61.600000000000506, -266.7999999999999, 26.600000000000087, 40.0000000000003, 41.200000000000315, -222.7000000000007, -353.8999999999999, 43.300000000000345, 58.000000000000526, 48.10000000000043, -371.5, 47.20000000000042, 58.70000000000051, 61.70000000000051, -171.60000000000008, -303.6000000000007, 49.80000000000047, 44.40000000000037, -520.5, 22.40000000000002, 62.500000000000504, 40.0000000000003, -223.59999999999974, 51.8000000000005, 38.300000000000274, 25.700000000000074, 9.999999999999968, -223.79999999999998, 40.0000000000003, 63.400000000000475, 26.20000000000009, 40.0000000000003, 31.200000000000166, 13.09999999999995, 61.60000000000047, 24.70000000000006, 58.90000000000048, -520.8, 32.800000000000196, -17.799999999999528, 44.50000000000038, 38.50000000000028, 61.00000000000052, 37.90000000000027, 40.0000000000003, 37.80000000000027, 19.699999999999992, 30.100000000000144, -248.69999999999987, 38.9000000000003, 5.700000000000076, 34.50000000000021, 43.70000000000037, 47.20000000000042, -219.99999999999977, 44.00000000000037, 50.20000000000048, 54.900000000000475, -444.4999999999999, 40.0000000000003, 56.200000000000514, 18.199999999999942, 6.900000000000107, 29.400000000000144, 27.90000000000011, 42.30000000000033, 43.00000000000035, 85.89999999999887, 8.10000000000001, -397.59999999999997, -218.3000000000005, -293.8000000000004, 8.100000000000103, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-6.399999999999936, -48.69999999999979, -86.79999999999998, -83.19999999999993, 28.100000000000154, 30.800000000000203, 16.09999999999996, 27.20000000000013, 20.000000000000014, 20.000000000000014, 18.19999999999999, 15.799999999999963, 38.00000000000025, 29.90000000000018, -129.10000000000073, -107.50000000000057, 26.600000000000122, -42.99999999999976, -368.5, -93.69999999999993, 20.000000000000014, 7.399999999999965, 3.1999999999999615, 21.20000000000003, 20.000000000000014, 20.000000000000014, -19.599999999999795, -2.8000000000000007, 25.400000000000098, 20.000000000000014, -232.89999999999992, -400.0, -256.3, -286.29999999999995, -244.60000000000002, -242.5, -174.4000000000003, -211.60000000000028, 20.000000000000014, 20.000000000000014, 19.70000000000001, 20.000000000000014, 34.10000000000026, 41.300000000000246, 5.299999999999965, 20.000000000000014, 20.000000000000014, 28.100000000000147, 20.000000000000014, 35.900000000000254, 20.000000000000014, -28.299999999999763, 41.60000000000024, 20.000000000000014, -162.70000000000002, -225.10000000000002, -7.299999999999894, 20.90000000000003, 20.000000000000014, 20.000000000000014, 6.199999999999969, 20.000000000000014, -87.10000000000068, -301.59999999999974, -296.79999999999995, -219.0999999999999, 17.299999999999976, 20.000000000000014, 34.40000000000026, 23.600000000000065, 28.100000000000147, 20.000000000000014, -265.5999999999999, -250.90000000000003, 9.199999999999969, 29.000000000000163, 20.000000000000014, 37.70000000000025, 28.100000000000147, 29.60000000000018, -40.90000000000003, -267.7, -233.2000000000003, -207.40000000000043, 24.800000000000093, 20.000000000000014, 15.799999999999963, 26.600000000000122, -330.7, -383.8, -5.199999999999944, 11.599999999999964, 20.000000000000014, 42.50000000000025, 20.000000000000014, 20.000000000000014, -246.70000000000041, -145.90000000000003, 11.599999999999964, 36.20000000000026, 20.000000000000014, -15.699999999999747, 20.000000000000014, -7.299999999999898, -76.30000000000078, 35.30000000000026, -233.50000000000003, -112.30000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 43.40000000000023, -38.79999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, -25.299999999999784, 41.60000000000023, 20.000000000000014, -20.19999999999976, 17.899999999999988, 20.000000000000014, 38.90000000000023, -343.3, -359.5, 1.0999999999999865, 22.700000000000053, -19.899999999999764, -19.899999999999764, 24.50000000000009, 20.000000000000014, 20.000000000000014, 15.499999999999964, 30.8000000000002, 27.20000000000013, -11.49999999999983, 34.40000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -23.19999999999976, 17.899999999999988, 13.699999999999964, 7.399999999999965, -242.5000000000002, -131.20000000000005, 20.000000000000014, 17.89999999999999, 28.100000000000154, -63.40000000000079, 0.49999999999997236, 20.000000000000014, -58.60000000000049, 29.300000000000175, 20.000000000000014, 27.200000000000134, -156.9999999999999, -210.9999999999999, 20.000000000000014, 16.99999999999997, 27.200000000000138, 20.000000000000014, -1.3000000000000385, 36.20000000000026, -303.4, -318.0999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, -38.799999999999756, 15.799999999999963, -40.899999999999764, 17.599999999999984, -5.199999999999962, -3.099999999999958, 20.000000000000014, 20.300000000000022, 20.000000000000014, 26.300000000000118, 13.699999999999964, 61.4000000000002, 24.50000000000008, -12.099999999999845, -44.7999999999998, -303.4, -278.19999999999993, -99.70000000000029, -244.60000000000028, -154.3, -305.5000000000002, -40.89999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 36.0, 53.0, 6.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 99.0, 0.0, 18.0, 14.0, 17.0, 168.0, 0.0, 6.0, 0.0, 9.0, 0.0, 0.0, 37.0, 16.0, 0.0, 0.0, 0.0, 200.0, 10.0, 155.0, 133.0, 0.0, 6.0, 115.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 121.0, 0.0, 13.0, 0.0, 0.0, 6.0, 9.0, 0.0, 166.0, 0.0, 162.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 140.0, 9.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 137.0, 137.0, 0.0, 0.0, 5.0, 0.0, 2.0, 194.0, 0.0, 12.0, 4.0, 0.0, 0.0, 0.0, 0.0, 90.0, 79.0, 0.0, 4.0, 17.0, 17.0, 13.0, 0.0, 0.0, 51.0, 0.0, 122.0, 0.0, 0.0, 0.0, 0.0, 24.0, 21.0, 0.0, 0.0, 0.0, 8.0, 0.0, 31.0, 0.0, 0.0, 21.0, 6.0, 0.0, 0.0, 179.0, 3.0, 0.0, 9.0, 0.0, 22.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 15.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 24.0, 6.0, 3.0, 0.0, 125.0, 0.0, 1.0, 20.0, 21.0, 0.0, 14.0, 34.0, 39.0, 0.0, 0.0, 115.0, 33.0, 0.0, 7.0, 0.0, 3.0, 0.0, 20.0, 154.0, 23.0, 0.0, 0.0, 0.0, 0.0, 19.0, 18.0, 18.0, 14.0, 12.0, 5.0, 0.0, 11.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 28.0, 37.0, 21.0, 163.0, 126.0, 0.0, 162.0, 4.0, 0.0, 29.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.460075813514454, "mean_inference_ms": 11.535507728512316, "mean_action_processing_ms": 0.6300786560205902, "mean_env_wait_ms": 1.678902699517785, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018111109733581543, "StateBufferConnector_ms": 0.007959723472595215, "ViewRequirementAgentConnector_ms": 0.35235798358917236}, "num_episodes": 23, "episode_return_max": 85.89999999999887, "episode_return_min": -520.8, "episode_return_mean": -39.5459999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 171.42691321906517, "num_env_steps_trained_throughput_per_sec": 171.42691321906517, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 20578.499, "restore_workers_time_ms": 0.018, "training_step_time_ms": 20578.438, "sample_time_ms": 3777.83, "learn_time_ms": 16764.489, "learn_throughput": 238.6, "synch_weights_time_ms": 31.041}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "3a355_00000", "date": "2024-08-13_02-44-47", "timestamp": 1723531487, "time_this_iter_s": 23.39603304862976, "time_total_s": 5692.270306587219, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52404c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5692.270306587219, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 86.50303030303031, "ram_util_percent": 83.10000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5540759611579161, "cur_kl_coeff": 1.1368683772161604e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7819171714404272, "policy_loss": -0.0006698999443047103, "vf_loss": 1.7825870748234804, "vf_explained_var": 0.0021684788206897715, "kl": 0.0010468479180470423, "entropy": 0.16337802192521475, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9113118944502382, "cur_kl_coeff": 0.01126270294189453, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2882327704202563, "policy_loss": -0.0005273543776224846, "vf_loss": 3.2886830428920724, "vf_explained_var": -6.810026194052721e-05, "kl": 0.0068437855856544275, "entropy": 1.2156414423670088, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 85.89999999999887, "episode_reward_min": -520.8, "episode_reward_mean": -36.90699999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 61.4000000000002, "predator_policy": 196.0}, "policy_reward_mean": {"prey_policy": -39.27849999999998, "predator_policy": 20.825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-264.9999999999977, 40.0000000000003, 40.700000000000315, 76.39999999999962, 32.30000000000019, 48.10000000000043, 56.90000000000051, 24.700000000000063, 61.600000000000506, -266.7999999999999, 26.600000000000087, 40.0000000000003, 41.200000000000315, -222.7000000000007, -353.8999999999999, 43.300000000000345, 58.000000000000526, 48.10000000000043, -371.5, 47.20000000000042, 58.70000000000051, 61.70000000000051, -171.60000000000008, -303.6000000000007, 49.80000000000047, 44.40000000000037, -520.5, 22.40000000000002, 62.500000000000504, 40.0000000000003, -223.59999999999974, 51.8000000000005, 38.300000000000274, 25.700000000000074, 9.999999999999968, -223.79999999999998, 40.0000000000003, 63.400000000000475, 26.20000000000009, 40.0000000000003, 31.200000000000166, 13.09999999999995, 61.60000000000047, 24.70000000000006, 58.90000000000048, -520.8, 32.800000000000196, -17.799999999999528, 44.50000000000038, 38.50000000000028, 61.00000000000052, 37.90000000000027, 40.0000000000003, 37.80000000000027, 19.699999999999992, 30.100000000000144, -248.69999999999987, 38.9000000000003, 5.700000000000076, 34.50000000000021, 43.70000000000037, 47.20000000000042, -219.99999999999977, 44.00000000000037, 50.20000000000048, 54.900000000000475, -444.4999999999999, 40.0000000000003, 56.200000000000514, 18.199999999999942, 6.900000000000107, 29.400000000000144, 27.90000000000011, 42.30000000000033, 43.00000000000035, 85.89999999999887, 8.10000000000001, -397.59999999999997, -218.3000000000005, -293.8000000000004, 8.100000000000103, 40.0000000000003, 22.10000000000002, -436.0000000000002, 26.20000000000008, 40.0000000000003, 40.0000000000003, 46.60000000000043, 44.90000000000038, 62.20000000000046, -310.20000000000005, 40.0000000000003, -180.79999999999973, 40.0000000000003, -451.2, 40.90000000000031, -136.79999999999987, 49.000000000000455, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-174.4000000000003, -211.60000000000028, 20.000000000000014, 20.000000000000014, 19.70000000000001, 20.000000000000014, 34.10000000000026, 41.300000000000246, 5.299999999999965, 20.000000000000014, 20.000000000000014, 28.100000000000147, 20.000000000000014, 35.900000000000254, 20.000000000000014, -28.299999999999763, 41.60000000000024, 20.000000000000014, -162.70000000000002, -225.10000000000002, -7.299999999999894, 20.90000000000003, 20.000000000000014, 20.000000000000014, 6.199999999999969, 20.000000000000014, -87.10000000000068, -301.59999999999974, -296.79999999999995, -219.0999999999999, 17.299999999999976, 20.000000000000014, 34.40000000000026, 23.600000000000065, 28.100000000000147, 20.000000000000014, -265.5999999999999, -250.90000000000003, 9.199999999999969, 29.000000000000163, 20.000000000000014, 37.70000000000025, 28.100000000000147, 29.60000000000018, -40.90000000000003, -267.7, -233.2000000000003, -207.40000000000043, 24.800000000000093, 20.000000000000014, 15.799999999999963, 26.600000000000122, -330.7, -383.8, -5.199999999999944, 11.599999999999964, 20.000000000000014, 42.50000000000025, 20.000000000000014, 20.000000000000014, -246.70000000000041, -145.90000000000003, 11.599999999999964, 36.20000000000026, 20.000000000000014, -15.699999999999747, 20.000000000000014, -7.299999999999898, -76.30000000000078, 35.30000000000026, -233.50000000000003, -112.30000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 43.40000000000023, -38.79999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, -25.299999999999784, 41.60000000000023, 20.000000000000014, -20.19999999999976, 17.899999999999988, 20.000000000000014, 38.90000000000023, -343.3, -359.5, 1.0999999999999865, 22.700000000000053, -19.899999999999764, -19.899999999999764, 24.50000000000009, 20.000000000000014, 20.000000000000014, 15.499999999999964, 30.8000000000002, 27.20000000000013, -11.49999999999983, 34.40000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -23.19999999999976, 17.899999999999988, 13.699999999999964, 7.399999999999965, -242.5000000000002, -131.20000000000005, 20.000000000000014, 17.89999999999999, 28.100000000000154, -63.40000000000079, 0.49999999999997236, 20.000000000000014, -58.60000000000049, 29.300000000000175, 20.000000000000014, 27.200000000000134, -156.9999999999999, -210.9999999999999, 20.000000000000014, 16.99999999999997, 27.200000000000138, 20.000000000000014, -1.3000000000000385, 36.20000000000026, -303.4, -318.0999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, -38.799999999999756, 15.799999999999963, -40.899999999999764, 17.599999999999984, -5.199999999999962, -3.099999999999958, 20.000000000000014, 20.300000000000022, 20.000000000000014, 26.300000000000118, 13.699999999999964, 61.4000000000002, 24.50000000000008, -12.099999999999845, -44.7999999999998, -303.4, -278.19999999999993, -99.70000000000029, -244.60000000000028, -154.3, -305.5000000000002, -40.89999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.899999999999764, -252.99999999999994, -379.0, 22.70000000000006, -11.499999999999819, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 14.599999999999966, 20.000000000000014, 17.899999999999984, 20.000000000000014, 7.399999999999981, 48.80000000000022, -255.0999999999999, -192.0999999999999, 20.000000000000014, 20.000000000000014, -119.19999999999985, -154.60000000000002, 20.000000000000014, 20.000000000000014, -361.0, -278.19999999999993, 20.000000000000014, 20.90000000000003, -140.4999999999999, -133.30000000000072, 20.000000000000014, 29.00000000000017, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [6.0, 115.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 7.0, 0.0, 0.0, 0.0, 1.0, 0.0, 17.0, 16.0, 0.0, 0.0, 0.0, 121.0, 0.0, 13.0, 0.0, 0.0, 6.0, 9.0, 0.0, 166.0, 0.0, 162.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 140.0, 9.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 137.0, 137.0, 0.0, 0.0, 5.0, 0.0, 2.0, 194.0, 0.0, 12.0, 4.0, 0.0, 0.0, 0.0, 0.0, 90.0, 79.0, 0.0, 4.0, 17.0, 17.0, 13.0, 0.0, 0.0, 51.0, 0.0, 122.0, 0.0, 0.0, 0.0, 0.0, 24.0, 21.0, 0.0, 0.0, 0.0, 8.0, 0.0, 31.0, 0.0, 0.0, 21.0, 6.0, 0.0, 0.0, 179.0, 3.0, 0.0, 9.0, 0.0, 22.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 15.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 24.0, 6.0, 3.0, 0.0, 125.0, 0.0, 1.0, 20.0, 21.0, 0.0, 14.0, 34.0, 39.0, 0.0, 0.0, 115.0, 33.0, 0.0, 7.0, 0.0, 3.0, 0.0, 20.0, 154.0, 23.0, 0.0, 0.0, 0.0, 0.0, 19.0, 18.0, 18.0, 14.0, 12.0, 5.0, 0.0, 11.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 28.0, 37.0, 21.0, 163.0, 126.0, 0.0, 162.0, 4.0, 0.0, 29.0, 0.0, 0.0, 22.0, 0.0, 196.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 7.0, 0.0, 6.0, 114.0, 23.0, 0.0, 0.0, 19.0, 74.0, 0.0, 0.0, 1.0, 187.0, 0.0, 0.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4561642358325027, "mean_inference_ms": 11.561476967715288, "mean_action_processing_ms": 0.6330106225529946, "mean_env_wait_ms": 1.5741748114619156, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015921831130981445, "StateBufferConnector_ms": 0.008758306503295898, "ViewRequirementAgentConnector_ms": 0.3918496370315552}, "num_episodes": 18, "episode_return_max": 85.89999999999887, "episode_return_min": -520.8, "episode_return_mean": -36.90699999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 162.14541886086565, "num_env_steps_trained_throughput_per_sec": 162.14541886086565, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 21324.616, "restore_workers_time_ms": 0.018, "training_step_time_ms": 21324.553, "sample_time_ms": 3940.706, "learn_time_ms": 17340.986, "learn_throughput": 230.667, "synch_weights_time_ms": 36.564}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "3a355_00000", "date": "2024-08-13_02-45-11", "timestamp": 1723531511, "time_this_iter_s": 24.76172375679016, "time_total_s": 5717.032030344009, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52a1430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5717.032030344009, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 87.79714285714286, "ram_util_percent": 83.33714285714285}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.562212870425727, "cur_kl_coeff": 5.684341886080802e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4706690365990633, "policy_loss": -0.000549852423537424, "vf_loss": 1.4712188920016012, "vf_explained_var": 0.007442461466663098, "kl": 0.0015026651328984089, "entropy": 0.15338860836136278, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0131521868642677, "cur_kl_coeff": 0.01126270294189453, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.518278712002689, "policy_loss": -0.004425530003817387, "vf_loss": 2.522425584881394, "vf_explained_var": 0.0038656622644454713, "kl": 0.024741333958742045, "entropy": 1.1245585970146945, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 85.89999999999887, "episode_reward_min": -520.8, "episode_reward_mean": -34.8589999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -383.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 61.4000000000002, "predator_policy": 196.0}, "policy_reward_mean": {"prey_policy": -38.12949999999997, "predator_policy": 20.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-371.5, 47.20000000000042, 58.70000000000051, 61.70000000000051, -171.60000000000008, -303.6000000000007, 49.80000000000047, 44.40000000000037, -520.5, 22.40000000000002, 62.500000000000504, 40.0000000000003, -223.59999999999974, 51.8000000000005, 38.300000000000274, 25.700000000000074, 9.999999999999968, -223.79999999999998, 40.0000000000003, 63.400000000000475, 26.20000000000009, 40.0000000000003, 31.200000000000166, 13.09999999999995, 61.60000000000047, 24.70000000000006, 58.90000000000048, -520.8, 32.800000000000196, -17.799999999999528, 44.50000000000038, 38.50000000000028, 61.00000000000052, 37.90000000000027, 40.0000000000003, 37.80000000000027, 19.699999999999992, 30.100000000000144, -248.69999999999987, 38.9000000000003, 5.700000000000076, 34.50000000000021, 43.70000000000037, 47.20000000000042, -219.99999999999977, 44.00000000000037, 50.20000000000048, 54.900000000000475, -444.4999999999999, 40.0000000000003, 56.200000000000514, 18.199999999999942, 6.900000000000107, 29.400000000000144, 27.90000000000011, 42.30000000000033, 43.00000000000035, 85.89999999999887, 8.10000000000001, -397.59999999999997, -218.3000000000005, -293.8000000000004, 8.100000000000103, 40.0000000000003, 22.10000000000002, -436.0000000000002, 26.20000000000008, 40.0000000000003, 40.0000000000003, 46.60000000000043, 44.90000000000038, 62.20000000000046, -310.20000000000005, 40.0000000000003, -180.79999999999973, 40.0000000000003, -451.2, 40.90000000000031, -136.79999999999987, 49.000000000000455, 40.0000000000003, 40.0000000000003, -41.20000000000017, 39.7000000000003, 63.2000000000005, -174.4999999999999, -319.2999999999999, 49.20000000000046, 60.700000000000514, 31.200000000000166, -157.39999999999992, -126.49999999999989, -6.399999999999572, 64.30000000000051, 40.0000000000003, 40.700000000000315, 54.400000000000524, 39.9000000000003, 5.100000000000085, 71.19999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-265.5999999999999, -250.90000000000003, 9.199999999999969, 29.000000000000163, 20.000000000000014, 37.70000000000025, 28.100000000000147, 29.60000000000018, -40.90000000000003, -267.7, -233.2000000000003, -207.40000000000043, 24.800000000000093, 20.000000000000014, 15.799999999999963, 26.600000000000122, -330.7, -383.8, -5.199999999999944, 11.599999999999964, 20.000000000000014, 42.50000000000025, 20.000000000000014, 20.000000000000014, -246.70000000000041, -145.90000000000003, 11.599999999999964, 36.20000000000026, 20.000000000000014, -15.699999999999747, 20.000000000000014, -7.299999999999898, -76.30000000000078, 35.30000000000026, -233.50000000000003, -112.30000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 43.40000000000023, -38.79999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 7.399999999999965, -25.299999999999784, 41.60000000000023, 20.000000000000014, -20.19999999999976, 17.899999999999988, 20.000000000000014, 38.90000000000023, -343.3, -359.5, 1.0999999999999865, 22.700000000000053, -19.899999999999764, -19.899999999999764, 24.50000000000009, 20.000000000000014, 20.000000000000014, 15.499999999999964, 30.8000000000002, 27.20000000000013, -11.49999999999983, 34.40000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -23.19999999999976, 17.899999999999988, 13.699999999999964, 7.399999999999965, -242.5000000000002, -131.20000000000005, 20.000000000000014, 17.89999999999999, 28.100000000000154, -63.40000000000079, 0.49999999999997236, 20.000000000000014, -58.60000000000049, 29.300000000000175, 20.000000000000014, 27.200000000000134, -156.9999999999999, -210.9999999999999, 20.000000000000014, 16.99999999999997, 27.200000000000138, 20.000000000000014, -1.3000000000000385, 36.20000000000026, -303.4, -318.0999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, -38.799999999999756, 15.799999999999963, -40.899999999999764, 17.599999999999984, -5.199999999999962, -3.099999999999958, 20.000000000000014, 20.300000000000022, 20.000000000000014, 26.300000000000118, 13.699999999999964, 61.4000000000002, 24.50000000000008, -12.099999999999845, -44.7999999999998, -303.4, -278.19999999999993, -99.70000000000029, -244.60000000000028, -154.3, -305.5000000000002, -40.89999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.899999999999764, -252.99999999999994, -379.0, 22.70000000000006, -11.499999999999819, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 14.599999999999966, 20.000000000000014, 17.899999999999984, 20.000000000000014, 7.399999999999981, 48.80000000000022, -255.0999999999999, -192.0999999999999, 20.000000000000014, 20.000000000000014, -119.19999999999985, -154.60000000000002, 20.000000000000014, 20.000000000000014, -361.0, -278.19999999999993, 20.000000000000014, 20.90000000000003, -140.4999999999999, -133.30000000000072, 20.000000000000014, 29.00000000000017, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -49.299999999999834, -61.900000000000766, 13.69999999999996, 20.000000000000014, 42.200000000000244, 20.000000000000014, -160.59999999999985, -103.90000000000002, -165.10000000000002, -323.2, 37.10000000000026, 4.099999999999966, 40.70000000000025, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -165.40000000000038, -85.00000000000003, -93.4, -87.10000000000004, -0.6999999999997968, -30.699999999999996, 34.40000000000026, 29.90000000000018, 20.000000000000014, 20.000000000000014, -11.499999999999822, 33.20000000000023, 34.40000000000026, 20.000000000000014, 14.899999999999967, 20.000000000000014, -26.19999999999979, -36.69999999999977, 32.60000000000023, 32.600000000000215], "policy_predator_policy_reward": [5.0, 140.0, 9.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 137.0, 137.0, 0.0, 0.0, 5.0, 0.0, 2.0, 194.0, 0.0, 12.0, 4.0, 0.0, 0.0, 0.0, 0.0, 90.0, 79.0, 0.0, 4.0, 17.0, 17.0, 13.0, 0.0, 0.0, 51.0, 0.0, 122.0, 0.0, 0.0, 0.0, 0.0, 24.0, 21.0, 0.0, 0.0, 0.0, 8.0, 0.0, 31.0, 0.0, 0.0, 21.0, 6.0, 0.0, 0.0, 179.0, 3.0, 0.0, 9.0, 0.0, 22.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 15.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 24.0, 6.0, 3.0, 0.0, 125.0, 0.0, 1.0, 20.0, 21.0, 0.0, 14.0, 34.0, 39.0, 0.0, 0.0, 115.0, 33.0, 0.0, 7.0, 0.0, 3.0, 0.0, 20.0, 154.0, 23.0, 0.0, 0.0, 0.0, 0.0, 19.0, 18.0, 18.0, 14.0, 12.0, 5.0, 0.0, 11.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 28.0, 37.0, 21.0, 163.0, 126.0, 0.0, 162.0, 4.0, 0.0, 29.0, 0.0, 0.0, 22.0, 0.0, 196.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 7.0, 0.0, 6.0, 114.0, 23.0, 0.0, 0.0, 19.0, 74.0, 0.0, 0.0, 1.0, 187.0, 0.0, 0.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 33.0, 6.0, 0.0, 0.0, 1.0, 29.0, 61.0, 0.0, 169.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 93.0, 0.0, 3.0, 51.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 13.0, 6.0, 0.0, 0.0, 5.0, 0.0, 35.0, 33.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4560135281411704, "mean_inference_ms": 11.496306238967495, "mean_action_processing_ms": 0.6369231218361003, "mean_env_wait_ms": 1.5639985392359075, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015400409698486328, "StateBufferConnector_ms": 0.008868932723999023, "ViewRequirementAgentConnector_ms": 0.4270763397216797}, "num_episodes": 18, "episode_return_max": 85.89999999999887, "episode_return_min": -520.8, "episode_return_mean": -34.8589999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 167.93626563942018, "num_env_steps_trained_throughput_per_sec": 167.93626563942018, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 21883.417, "restore_workers_time_ms": 0.02, "training_step_time_ms": 21882.86, "sample_time_ms": 4083.158, "learn_time_ms": 17755.45, "learn_throughput": 225.283, "synch_weights_time_ms": 37.866}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "3a355_00000", "date": "2024-08-13_02-45-35", "timestamp": 1723531535, "time_this_iter_s": 23.89825201034546, "time_total_s": 5740.930282354355, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52a1dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5740.930282354355, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 87.32121212121211, "ram_util_percent": 83.43939393939394}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5067273974221534, "cur_kl_coeff": 2.842170943040401e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3903241578233305, "policy_loss": -0.0004302722579311757, "vf_loss": 2.3907544244534122, "vf_explained_var": 0.002047846336213369, "kl": 0.0012717709923942984, "entropy": 0.191550909920975, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8991815322448337, "cur_kl_coeff": 0.0168940544128418, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.553721486323725, "policy_loss": -0.0005102028832499865, "vf_loss": 4.554120559414859, "vf_explained_var": 0.002547677200307291, "kl": 0.006577796038105545, "entropy": 1.0810058005903134, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 85.89999999999887, "episode_reward_min": -520.8, "episode_reward_mean": -41.47499999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 61.4000000000002, "predator_policy": 196.0}, "policy_reward_mean": {"prey_policy": -43.157499999999956, "predator_policy": 22.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [31.200000000000166, 13.09999999999995, 61.60000000000047, 24.70000000000006, 58.90000000000048, -520.8, 32.800000000000196, -17.799999999999528, 44.50000000000038, 38.50000000000028, 61.00000000000052, 37.90000000000027, 40.0000000000003, 37.80000000000027, 19.699999999999992, 30.100000000000144, -248.69999999999987, 38.9000000000003, 5.700000000000076, 34.50000000000021, 43.70000000000037, 47.20000000000042, -219.99999999999977, 44.00000000000037, 50.20000000000048, 54.900000000000475, -444.4999999999999, 40.0000000000003, 56.200000000000514, 18.199999999999942, 6.900000000000107, 29.400000000000144, 27.90000000000011, 42.30000000000033, 43.00000000000035, 85.89999999999887, 8.10000000000001, -397.59999999999997, -218.3000000000005, -293.8000000000004, 8.100000000000103, 40.0000000000003, 22.10000000000002, -436.0000000000002, 26.20000000000008, 40.0000000000003, 40.0000000000003, 46.60000000000043, 44.90000000000038, 62.20000000000046, -310.20000000000005, 40.0000000000003, -180.79999999999973, 40.0000000000003, -451.2, 40.90000000000031, -136.79999999999987, 49.000000000000455, 40.0000000000003, 40.0000000000003, -41.20000000000017, 39.7000000000003, 63.2000000000005, -174.4999999999999, -319.2999999999999, 49.20000000000046, 60.700000000000514, 31.200000000000166, -157.39999999999992, -126.49999999999989, -6.399999999999572, 64.30000000000051, 40.0000000000003, 40.700000000000315, 54.400000000000524, 39.9000000000003, 5.100000000000085, 71.19999999999995, 40.0000000000003, -298.89999999999986, -347.9, 23.00000000000006, -8.599999999999834, -328.4000000000001, 42.10000000000032, -11.99999999999958, 35.70000000000024, 41.100000000000314, 51.70000000000049, 49.000000000000455, 17.99999999999995, -341.3, -347.59999999999997, -102.70000000000093, 50.80000000000048, 40.0000000000003, 1.2000000000002002, -393.09999999999997, 37.000000000000256, -43.199999999999775], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [3.1999999999999615, 20.000000000000014, 7.399999999999965, -25.299999999999784, 41.60000000000023, 20.000000000000014, -20.19999999999976, 17.899999999999988, 20.000000000000014, 38.90000000000023, -343.3, -359.5, 1.0999999999999865, 22.700000000000053, -19.899999999999764, -19.899999999999764, 24.50000000000009, 20.000000000000014, 20.000000000000014, 15.499999999999964, 30.8000000000002, 27.20000000000013, -11.49999999999983, 34.40000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -23.19999999999976, 17.899999999999988, 13.699999999999964, 7.399999999999965, -242.5000000000002, -131.20000000000005, 20.000000000000014, 17.89999999999999, 28.100000000000154, -63.40000000000079, 0.49999999999997236, 20.000000000000014, -58.60000000000049, 29.300000000000175, 20.000000000000014, 27.200000000000134, -156.9999999999999, -210.9999999999999, 20.000000000000014, 16.99999999999997, 27.200000000000138, 20.000000000000014, -1.3000000000000385, 36.20000000000026, -303.4, -318.0999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, -38.799999999999756, 15.799999999999963, -40.899999999999764, 17.599999999999984, -5.199999999999962, -3.099999999999958, 20.000000000000014, 20.300000000000022, 20.000000000000014, 26.300000000000118, 13.699999999999964, 61.4000000000002, 24.50000000000008, -12.099999999999845, -44.7999999999998, -303.4, -278.19999999999993, -99.70000000000029, -244.60000000000028, -154.3, -305.5000000000002, -40.89999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.899999999999764, -252.99999999999994, -379.0, 22.70000000000006, -11.499999999999819, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 14.599999999999966, 20.000000000000014, 17.899999999999984, 20.000000000000014, 7.399999999999981, 48.80000000000022, -255.0999999999999, -192.0999999999999, 20.000000000000014, 20.000000000000014, -119.19999999999985, -154.60000000000002, 20.000000000000014, 20.000000000000014, -361.0, -278.19999999999993, 20.000000000000014, 20.90000000000003, -140.4999999999999, -133.30000000000072, 20.000000000000014, 29.00000000000017, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -49.299999999999834, -61.900000000000766, 13.69999999999996, 20.000000000000014, 42.200000000000244, 20.000000000000014, -160.59999999999985, -103.90000000000002, -165.10000000000002, -323.2, 37.10000000000026, 4.099999999999966, 40.70000000000025, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -165.40000000000038, -85.00000000000003, -93.4, -87.10000000000004, -0.6999999999997968, -30.699999999999996, 34.40000000000026, 29.90000000000018, 20.000000000000014, 20.000000000000014, -11.499999999999822, 33.20000000000023, 34.40000000000026, 20.000000000000014, 14.899999999999967, 20.000000000000014, -26.19999999999979, -36.69999999999977, 32.60000000000023, 32.600000000000215, 20.000000000000014, 20.000000000000014, -264.7000000000003, -173.20000000000002, -351.7, -173.20000000000002, -11.199999999999863, -2.7999999999999754, 4.400000000000194, -42.999999999999794, -370.6, -143.8, 19.1, 20.000000000000014, -2.7999999999999297, -47.200000000000045, 7.699999999999967, 20.000000000000014, 13.09999999999997, 20.000000000000014, 31.700000000000212, 20.000000000000014, 28.10000000000015, 20.90000000000003, -21.999999999999766, 20.000000000000014, -171.10000000000002, -362.2, -204.69999999999987, -322.9, -278.1999999999987, 33.50000000000024, 20.000000000000014, 30.800000000000196, -17.799999999999756, 39.80000000000025, 20.000000000000014, -59.80000000000062, -248.8, -313.3, -16.89999999999975, 35.900000000000254, -34.6, -34.6], "policy_predator_policy_reward": [0.0, 8.0, 0.0, 31.0, 0.0, 0.0, 21.0, 6.0, 0.0, 0.0, 179.0, 3.0, 0.0, 9.0, 0.0, 22.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 15.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 24.0, 6.0, 3.0, 0.0, 125.0, 0.0, 1.0, 20.0, 21.0, 0.0, 14.0, 34.0, 39.0, 0.0, 0.0, 115.0, 33.0, 0.0, 7.0, 0.0, 3.0, 0.0, 20.0, 154.0, 23.0, 0.0, 0.0, 0.0, 0.0, 19.0, 18.0, 18.0, 14.0, 12.0, 5.0, 0.0, 11.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 28.0, 37.0, 21.0, 163.0, 126.0, 0.0, 162.0, 4.0, 0.0, 29.0, 0.0, 0.0, 22.0, 0.0, 196.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 7.0, 0.0, 6.0, 114.0, 23.0, 0.0, 0.0, 19.0, 74.0, 0.0, 0.0, 1.0, 187.0, 0.0, 0.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 33.0, 6.0, 0.0, 0.0, 1.0, 29.0, 61.0, 0.0, 169.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 93.0, 0.0, 3.0, 51.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 13.0, 6.0, 0.0, 0.0, 5.0, 0.0, 35.0, 33.0, 6.0, 0.0, 0.0, 0.0, 0.0, 139.0, 177.0, 0.0, 20.0, 17.0, 13.0, 17.0, 186.0, 0.0, 3.0, 0.0, 6.0, 32.0, 8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 171.0, 21.0, 15.0, 165.0, 142.0, 0.0, 0.0, 0.0, 0.0, 18.0, 21.0, 20.0, 169.0, 0.0, 18.0, 0.0, 0.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5489704847099195, "mean_inference_ms": 11.325288186476445, "mean_action_processing_ms": 0.6430175093874891, "mean_env_wait_ms": 1.5587960521660411, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011990666389465332, "StateBufferConnector_ms": 0.009045958518981934, "ViewRequirementAgentConnector_ms": 0.4524925947189331}, "num_episodes": 22, "episode_return_max": 85.89999999999887, "episode_return_min": -520.8, "episode_return_mean": -41.47499999999981, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 164.36304204339163, "num_env_steps_trained_throughput_per_sec": 164.36304204339163, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 22308.361, "restore_workers_time_ms": 0.03, "training_step_time_ms": 22307.794, "sample_time_ms": 4166.699, "learn_time_ms": 18093.146, "learn_throughput": 221.078, "synch_weights_time_ms": 41.931}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "3a355_00000", "date": "2024-08-13_02-46-00", "timestamp": 1723531560, "time_this_iter_s": 24.400286197662354, "time_total_s": 5765.330568552017, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5240d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5765.330568552017, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 88.22, "ram_util_percent": 83.04571428571428}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4815140404053545, "cur_kl_coeff": 1.4210854715202005e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8284163068526635, "policy_loss": -0.00019253162992379023, "vf_loss": 1.8286088375502794, "vf_explained_var": 0.004444144390247486, "kl": 0.001393491960162852, "entropy": 0.17483491703631385, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8542903435372171, "cur_kl_coeff": 0.0168940544128418, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.65013817006318, "policy_loss": -0.0016838220568994682, "vf_loss": 2.651655248548619, "vf_explained_var": -0.00017907502789976735, "kl": 0.009869931796556897, "entropy": 0.9881870868029418, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 85.89999999999887, "episode_reward_min": -451.2, "episode_reward_mean": -39.79799999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 61.4000000000002, "predator_policy": 196.0}, "policy_reward_mean": {"prey_policy": -43.36899999999996, "predator_policy": 23.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.700000000000076, 34.50000000000021, 43.70000000000037, 47.20000000000042, -219.99999999999977, 44.00000000000037, 50.20000000000048, 54.900000000000475, -444.4999999999999, 40.0000000000003, 56.200000000000514, 18.199999999999942, 6.900000000000107, 29.400000000000144, 27.90000000000011, 42.30000000000033, 43.00000000000035, 85.89999999999887, 8.10000000000001, -397.59999999999997, -218.3000000000005, -293.8000000000004, 8.100000000000103, 40.0000000000003, 22.10000000000002, -436.0000000000002, 26.20000000000008, 40.0000000000003, 40.0000000000003, 46.60000000000043, 44.90000000000038, 62.20000000000046, -310.20000000000005, 40.0000000000003, -180.79999999999973, 40.0000000000003, -451.2, 40.90000000000031, -136.79999999999987, 49.000000000000455, 40.0000000000003, 40.0000000000003, -41.20000000000017, 39.7000000000003, 63.2000000000005, -174.4999999999999, -319.2999999999999, 49.20000000000046, 60.700000000000514, 31.200000000000166, -157.39999999999992, -126.49999999999989, -6.399999999999572, 64.30000000000051, 40.0000000000003, 40.700000000000315, 54.400000000000524, 39.9000000000003, 5.100000000000085, 71.19999999999995, 40.0000000000003, -298.89999999999986, -347.9, 23.00000000000006, -8.599999999999834, -328.4000000000001, 42.10000000000032, -11.99999999999958, 35.70000000000024, 41.100000000000314, 51.70000000000049, 49.000000000000455, 17.99999999999995, -341.3, -347.59999999999997, -102.70000000000093, 50.80000000000048, 40.0000000000003, 1.2000000000002002, -393.09999999999997, 37.000000000000256, -43.199999999999775, 40.0000000000003, 35.600000000000236, 40.0000000000003, 40.0000000000003, -131.39999999999998, -168.19999999999987, -123.40000000000005, 19.099999999999966, 37.80000000000027, 24.800000000000065, 64.30000000000047, 31.50000000000018, 42.80000000000034, 71.49999999999999, 45.30000000000039, -220.29999999999993, 52.60000000000051, 49.10000000000046], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [28.100000000000154, -63.40000000000079, 0.49999999999997236, 20.000000000000014, -58.60000000000049, 29.300000000000175, 20.000000000000014, 27.200000000000134, -156.9999999999999, -210.9999999999999, 20.000000000000014, 16.99999999999997, 27.200000000000138, 20.000000000000014, -1.3000000000000385, 36.20000000000026, -303.4, -318.0999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, -38.799999999999756, 15.799999999999963, -40.899999999999764, 17.599999999999984, -5.199999999999962, -3.099999999999958, 20.000000000000014, 20.300000000000022, 20.000000000000014, 26.300000000000118, 13.699999999999964, 61.4000000000002, 24.50000000000008, -12.099999999999845, -44.7999999999998, -303.4, -278.19999999999993, -99.70000000000029, -244.60000000000028, -154.3, -305.5000000000002, -40.89999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.899999999999764, -252.99999999999994, -379.0, 22.70000000000006, -11.499999999999819, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 14.599999999999966, 20.000000000000014, 17.899999999999984, 20.000000000000014, 7.399999999999981, 48.80000000000022, -255.0999999999999, -192.0999999999999, 20.000000000000014, 20.000000000000014, -119.19999999999985, -154.60000000000002, 20.000000000000014, 20.000000000000014, -361.0, -278.19999999999993, 20.000000000000014, 20.90000000000003, -140.4999999999999, -133.30000000000072, 20.000000000000014, 29.00000000000017, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -49.299999999999834, -61.900000000000766, 13.69999999999996, 20.000000000000014, 42.200000000000244, 20.000000000000014, -160.59999999999985, -103.90000000000002, -165.10000000000002, -323.2, 37.10000000000026, 4.099999999999966, 40.70000000000025, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -165.40000000000038, -85.00000000000003, -93.4, -87.10000000000004, -0.6999999999997968, -30.699999999999996, 34.40000000000026, 29.90000000000018, 20.000000000000014, 20.000000000000014, -11.499999999999822, 33.20000000000023, 34.40000000000026, 20.000000000000014, 14.899999999999967, 20.000000000000014, -26.19999999999979, -36.69999999999977, 32.60000000000023, 32.600000000000215, 20.000000000000014, 20.000000000000014, -264.7000000000003, -173.20000000000002, -351.7, -173.20000000000002, -11.199999999999863, -2.7999999999999754, 4.400000000000194, -42.999999999999794, -370.6, -143.8, 19.1, 20.000000000000014, -2.7999999999999297, -47.200000000000045, 7.699999999999967, 20.000000000000014, 13.09999999999997, 20.000000000000014, 31.700000000000212, 20.000000000000014, 28.10000000000015, 20.90000000000003, -21.999999999999766, 20.000000000000014, -171.10000000000002, -362.2, -204.69999999999987, -322.9, -278.1999999999987, 33.50000000000024, 20.000000000000014, 30.800000000000196, -17.799999999999756, 39.80000000000025, 20.000000000000014, -59.80000000000062, -248.8, -313.3, -16.89999999999975, 35.900000000000254, -34.6, -34.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -111.70000000000005, -312.7, -120.70000000000003, -116.50000000000003, -227.8, -13.600000000000009, -19.899999999999757, 20.000000000000014, 15.799999999999963, 20.000000000000014, 22.700000000000053, -19.89999999999978, 44.30000000000024, 20.000000000000014, 9.19999999999997, 2.2999999999999643, 11.599999999999964, 27.20000000000013, 38.900000000000254, 32.60000000000023, 20.30000000000002, 20.000000000000014, -152.20000000000002, -150.10000000000002, 32.60000000000023, 20.000000000000014, -26.49999999999975, 41.600000000000236], "policy_predator_policy_reward": [20.0, 21.0, 0.0, 14.0, 34.0, 39.0, 0.0, 0.0, 115.0, 33.0, 0.0, 7.0, 0.0, 3.0, 0.0, 20.0, 154.0, 23.0, 0.0, 0.0, 0.0, 0.0, 19.0, 18.0, 18.0, 14.0, 12.0, 5.0, 0.0, 11.0, 2.0, 0.0, 0.0, 3.0, 0.0, 0.0, 28.0, 37.0, 21.0, 163.0, 126.0, 0.0, 162.0, 4.0, 0.0, 29.0, 0.0, 0.0, 22.0, 0.0, 196.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 7.0, 0.0, 6.0, 114.0, 23.0, 0.0, 0.0, 19.0, 74.0, 0.0, 0.0, 1.0, 187.0, 0.0, 0.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 33.0, 6.0, 0.0, 0.0, 1.0, 29.0, 61.0, 0.0, 169.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 93.0, 0.0, 3.0, 51.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 13.0, 6.0, 0.0, 0.0, 5.0, 0.0, 35.0, 33.0, 6.0, 0.0, 0.0, 0.0, 0.0, 139.0, 177.0, 0.0, 20.0, 17.0, 13.0, 17.0, 186.0, 0.0, 3.0, 0.0, 6.0, 32.0, 8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 171.0, 21.0, 15.0, 165.0, 142.0, 0.0, 0.0, 0.0, 0.0, 18.0, 21.0, 20.0, 169.0, 0.0, 18.0, 0.0, 0.0, 26.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 126.0, 167.0, 69.0, 0.0, 0.0, 118.0, 19.0, 0.0, 2.0, 0.0, 4.0, 18.0, 0.0, 0.0, 11.0, 9.0, 0.0, 4.0, 0.0, 0.0, 5.0, 0.0, 82.0, 0.0, 0.0, 0.0, 17.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.453807494813507, "mean_inference_ms": 11.36719232654512, "mean_action_processing_ms": 0.6462420387033841, "mean_env_wait_ms": 1.5457732020169868, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007182955741882324, "StateBufferConnector_ms": 0.014470219612121582, "ViewRequirementAgentConnector_ms": 0.39378392696380615}, "num_episodes": 18, "episode_return_max": 85.89999999999887, "episode_return_min": -451.2, "episode_return_mean": -39.79799999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 165.46595019001512, "num_env_steps_trained_throughput_per_sec": 165.46595019001512, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 22654.346, "restore_workers_time_ms": 0.032, "training_step_time_ms": 22653.775, "sample_time_ms": 4197.815, "learn_time_ms": 18405.976, "learn_throughput": 217.321, "synch_weights_time_ms": 44.293}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "3a355_00000", "date": "2024-08-13_02-46-24", "timestamp": 1723531584, "time_this_iter_s": 24.245139837265015, "time_total_s": 5789.575708389282, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5240820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5789.575708389282, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 87.78529411764706, "ram_util_percent": 82.99117647058823}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47094639774273944, "cur_kl_coeff": 7.105427357601002e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.645587939181656, "policy_loss": -0.0008210428395412034, "vf_loss": 1.6464089843646559, "vf_explained_var": 0.0025396346730529947, "kl": 0.0013529827987835493, "entropy": 0.16626096739576607, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8513870578180388, "cur_kl_coeff": 0.0168940544128418, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.544384113884477, "policy_loss": -0.0017864840030029573, "vf_loss": 2.545895499905581, "vf_explained_var": -0.0010937337837521992, "kl": 0.01628419725774547, "entropy": 1.0756919381479737, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 71.49999999999999, "episode_reward_min": -451.2, "episode_reward_mean": -38.17399999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 48.80000000000022, "predator_policy": 196.0}, "policy_reward_mean": {"prey_policy": -42.66699999999996, "predator_policy": 23.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 22.10000000000002, -436.0000000000002, 26.20000000000008, 40.0000000000003, 40.0000000000003, 46.60000000000043, 44.90000000000038, 62.20000000000046, -310.20000000000005, 40.0000000000003, -180.79999999999973, 40.0000000000003, -451.2, 40.90000000000031, -136.79999999999987, 49.000000000000455, 40.0000000000003, 40.0000000000003, -41.20000000000017, 39.7000000000003, 63.2000000000005, -174.4999999999999, -319.2999999999999, 49.20000000000046, 60.700000000000514, 31.200000000000166, -157.39999999999992, -126.49999999999989, -6.399999999999572, 64.30000000000051, 40.0000000000003, 40.700000000000315, 54.400000000000524, 39.9000000000003, 5.100000000000085, 71.19999999999995, 40.0000000000003, -298.89999999999986, -347.9, 23.00000000000006, -8.599999999999834, -328.4000000000001, 42.10000000000032, -11.99999999999958, 35.70000000000024, 41.100000000000314, 51.70000000000049, 49.000000000000455, 17.99999999999995, -341.3, -347.59999999999997, -102.70000000000093, 50.80000000000048, 40.0000000000003, 1.2000000000002002, -393.09999999999997, 37.000000000000256, -43.199999999999775, 40.0000000000003, 35.600000000000236, 40.0000000000003, 40.0000000000003, -131.39999999999998, -168.19999999999987, -123.40000000000005, 19.099999999999966, 37.80000000000027, 24.800000000000065, 64.30000000000047, 31.50000000000018, 42.80000000000034, 71.49999999999999, 45.30000000000039, -220.29999999999993, 52.60000000000051, 49.10000000000046, -194.80000000000064, 25.70000000000007, 40.0000000000003, -327.3999999999999, -197.90000000000015, 37.80000000000027, -116.40000000000022, 33.400000000000205, -103.00000000000085, 49.00000000000045, 34.50000000000022, 40.0000000000003, 40.0000000000003, -248.8, 40.80000000000031, 47.00000000000041, 36.70000000000025, 40.0000000000003, 3.500000000000209, 38.30000000000027, 46.300000000000395, 13.399999999999984, -143.70000000000044], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, -19.899999999999764, -252.99999999999994, -379.0, 22.70000000000006, -11.499999999999819, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 14.599999999999966, 20.000000000000014, 17.899999999999984, 20.000000000000014, 7.399999999999981, 48.80000000000022, -255.0999999999999, -192.0999999999999, 20.000000000000014, 20.000000000000014, -119.19999999999985, -154.60000000000002, 20.000000000000014, 20.000000000000014, -361.0, -278.19999999999993, 20.000000000000014, 20.90000000000003, -140.4999999999999, -133.30000000000072, 20.000000000000014, 29.00000000000017, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -49.299999999999834, -61.900000000000766, 13.69999999999996, 20.000000000000014, 42.200000000000244, 20.000000000000014, -160.59999999999985, -103.90000000000002, -165.10000000000002, -323.2, 37.10000000000026, 4.099999999999966, 40.70000000000025, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -165.40000000000038, -85.00000000000003, -93.4, -87.10000000000004, -0.6999999999997968, -30.699999999999996, 34.40000000000026, 29.90000000000018, 20.000000000000014, 20.000000000000014, -11.499999999999822, 33.20000000000023, 34.40000000000026, 20.000000000000014, 14.899999999999967, 20.000000000000014, -26.19999999999979, -36.69999999999977, 32.60000000000023, 32.600000000000215, 20.000000000000014, 20.000000000000014, -264.7000000000003, -173.20000000000002, -351.7, -173.20000000000002, -11.199999999999863, -2.7999999999999754, 4.400000000000194, -42.999999999999794, -370.6, -143.8, 19.1, 20.000000000000014, -2.7999999999999297, -47.200000000000045, 7.699999999999967, 20.000000000000014, 13.09999999999997, 20.000000000000014, 31.700000000000212, 20.000000000000014, 28.10000000000015, 20.90000000000003, -21.999999999999766, 20.000000000000014, -171.10000000000002, -362.2, -204.69999999999987, -322.9, -278.1999999999987, 33.50000000000024, 20.000000000000014, 30.800000000000196, -17.799999999999756, 39.80000000000025, 20.000000000000014, -59.80000000000062, -248.8, -313.3, -16.89999999999975, 35.900000000000254, -34.6, -34.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -111.70000000000005, -312.7, -120.70000000000003, -116.50000000000003, -227.8, -13.600000000000009, -19.899999999999757, 20.000000000000014, 15.799999999999963, 20.000000000000014, 22.700000000000053, -19.89999999999978, 44.30000000000024, 20.000000000000014, 9.19999999999997, 2.2999999999999643, 11.599999999999964, 27.20000000000013, 38.900000000000254, 32.60000000000023, 20.30000000000002, 20.000000000000014, -152.20000000000002, -150.10000000000002, 32.60000000000023, 20.000000000000014, -26.49999999999975, 41.600000000000236, -179.4999999999999, -208.3000000000004, -7.299999999999891, 20.000000000000014, 20.000000000000014, 20.000000000000014, -218.5, -268.9, -56.199999999999946, -288.69999999999993, 15.799999999999963, 20.000000000000014, -288.4, 20.000000000000014, 20.000000000000014, 7.399999999999965, -253.00000000000028, 20.000000000000014, 20.000000000000014, 29.000000000000163, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -129.10000000000002, -246.70000000000002, 11.599999999999964, 15.199999999999964, 20.000000000000014, 26.00000000000011, 13.699999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, -9.399999999999858, 20.000000000000014, 5.299999999999965, 26.300000000000114, 20.000000000000014, -34.59999999999977, 20.000000000000014, -330.7, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 22.0, 0.0, 196.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 7.0, 0.0, 6.0, 114.0, 23.0, 0.0, 0.0, 19.0, 74.0, 0.0, 0.0, 1.0, 187.0, 0.0, 0.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 33.0, 6.0, 0.0, 0.0, 1.0, 29.0, 61.0, 0.0, 169.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 93.0, 0.0, 3.0, 51.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 13.0, 6.0, 0.0, 0.0, 5.0, 0.0, 35.0, 33.0, 6.0, 0.0, 0.0, 0.0, 0.0, 139.0, 177.0, 0.0, 20.0, 17.0, 13.0, 17.0, 186.0, 0.0, 3.0, 0.0, 6.0, 32.0, 8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 171.0, 21.0, 15.0, 165.0, 142.0, 0.0, 0.0, 0.0, 0.0, 18.0, 21.0, 20.0, 169.0, 0.0, 18.0, 0.0, 0.0, 26.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 126.0, 167.0, 69.0, 0.0, 0.0, 118.0, 19.0, 0.0, 2.0, 0.0, 4.0, 18.0, 0.0, 0.0, 11.0, 9.0, 0.0, 4.0, 0.0, 0.0, 5.0, 0.0, 82.0, 0.0, 0.0, 0.0, 17.0, 17.0, 22.0, 171.0, 13.0, 0.0, 0.0, 0.0, 160.0, 0.0, 135.0, 12.0, 0.0, 2.0, 152.0, 0.0, 0.0, 6.0, 130.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.0, 0.0, 10.0, 4.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 16.0, 7.0, 6.0, 0.0, 0.0, 16.0, 12.0, 166.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.45289455920528, "mean_inference_ms": 11.283132932255214, "mean_action_processing_ms": 0.6493815940623969, "mean_env_wait_ms": 1.5303483076850497, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009838342666625977, "StateBufferConnector_ms": 0.014477252960205078, "ViewRequirementAgentConnector_ms": 0.34835267066955566}, "num_episodes": 23, "episode_return_max": 71.49999999999999, "episode_return_min": -451.2, "episode_return_mean": -38.17399999999982, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 171.53409657133858, "num_env_steps_trained_throughput_per_sec": 171.53409657133858, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 22976.976, "restore_workers_time_ms": 0.032, "training_step_time_ms": 22976.404, "sample_time_ms": 4243.102, "learn_time_ms": 18682.815, "learn_throughput": 214.1, "synch_weights_time_ms": 44.587}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "3a355_00000", "date": "2024-08-13_02-46-48", "timestamp": 1723531608, "time_this_iter_s": 23.378602981567383, "time_total_s": 5812.95431137085, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52ab670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5812.95431137085, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 86.43030303030302, "ram_util_percent": 83.27575757575757}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5028882904648386, "cur_kl_coeff": 3.552713678800501e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.660458245605388, "policy_loss": -0.0001041870411465723, "vf_loss": 1.6605624342406238, "vf_explained_var": 0.005173597133979596, "kl": 0.0010598930976916635, "entropy": 0.15292613970303032, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0732117741353928, "cur_kl_coeff": 0.0168940544128418, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3840579059073534, "policy_loss": -0.003121106698862696, "vf_loss": 2.3867263737178983, "vf_explained_var": -0.0012612284491301845, "kl": 0.02679288552457881, "entropy": 1.1487462193246871, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 78.69999999999945, "episode_reward_min": -393.09999999999997, "episode_reward_mean": -27.749999999999826, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -370.6, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 44.30000000000024, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": -36.51999999999995, "predator_policy": 22.645}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, -41.20000000000017, 39.7000000000003, 63.2000000000005, -174.4999999999999, -319.2999999999999, 49.20000000000046, 60.700000000000514, 31.200000000000166, -157.39999999999992, -126.49999999999989, -6.399999999999572, 64.30000000000051, 40.0000000000003, 40.700000000000315, 54.400000000000524, 39.9000000000003, 5.100000000000085, 71.19999999999995, 40.0000000000003, -298.89999999999986, -347.9, 23.00000000000006, -8.599999999999834, -328.4000000000001, 42.10000000000032, -11.99999999999958, 35.70000000000024, 41.100000000000314, 51.70000000000049, 49.000000000000455, 17.99999999999995, -341.3, -347.59999999999997, -102.70000000000093, 50.80000000000048, 40.0000000000003, 1.2000000000002002, -393.09999999999997, 37.000000000000256, -43.199999999999775, 40.0000000000003, 35.600000000000236, 40.0000000000003, 40.0000000000003, -131.39999999999998, -168.19999999999987, -123.40000000000005, 19.099999999999966, 37.80000000000027, 24.800000000000065, 64.30000000000047, 31.50000000000018, 42.80000000000034, 71.49999999999999, 45.30000000000039, -220.29999999999993, 52.60000000000051, 49.10000000000046, -194.80000000000064, 25.70000000000007, 40.0000000000003, -327.3999999999999, -197.90000000000015, 37.80000000000027, -116.40000000000022, 33.400000000000205, -103.00000000000085, 49.00000000000045, 34.50000000000022, 40.0000000000003, 40.0000000000003, -248.8, 40.80000000000031, 47.00000000000041, 36.70000000000025, 40.0000000000003, 3.500000000000209, 38.30000000000027, 46.300000000000395, 13.399999999999984, -143.70000000000044, 40.0000000000003, 17.399999999999952, 40.0000000000003, 47.00000000000043, 37.80000000000027, 27.600000000000108, -279.8000000000003, 31.600000000000165, 54.50000000000049, 32.00000000000043, 37.20000000000026, 78.69999999999945, 40.4000000000003, 33.60000000000021, -43.599999999999866, 44.50000000000037, 40.0000000000003, -219.6000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -49.299999999999834, -61.900000000000766, 13.69999999999996, 20.000000000000014, 42.200000000000244, 20.000000000000014, -160.59999999999985, -103.90000000000002, -165.10000000000002, -323.2, 37.10000000000026, 4.099999999999966, 40.70000000000025, 20.000000000000014, 3.1999999999999615, 20.000000000000014, -165.40000000000038, -85.00000000000003, -93.4, -87.10000000000004, -0.6999999999997968, -30.699999999999996, 34.40000000000026, 29.90000000000018, 20.000000000000014, 20.000000000000014, -11.499999999999822, 33.20000000000023, 34.40000000000026, 20.000000000000014, 14.899999999999967, 20.000000000000014, -26.19999999999979, -36.69999999999977, 32.60000000000023, 32.600000000000215, 20.000000000000014, 20.000000000000014, -264.7000000000003, -173.20000000000002, -351.7, -173.20000000000002, -11.199999999999863, -2.7999999999999754, 4.400000000000194, -42.999999999999794, -370.6, -143.8, 19.1, 20.000000000000014, -2.7999999999999297, -47.200000000000045, 7.699999999999967, 20.000000000000014, 13.09999999999997, 20.000000000000014, 31.700000000000212, 20.000000000000014, 28.10000000000015, 20.90000000000003, -21.999999999999766, 20.000000000000014, -171.10000000000002, -362.2, -204.69999999999987, -322.9, -278.1999999999987, 33.50000000000024, 20.000000000000014, 30.800000000000196, -17.799999999999756, 39.80000000000025, 20.000000000000014, -59.80000000000062, -248.8, -313.3, -16.89999999999975, 35.900000000000254, -34.6, -34.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -111.70000000000005, -312.7, -120.70000000000003, -116.50000000000003, -227.8, -13.600000000000009, -19.899999999999757, 20.000000000000014, 15.799999999999963, 20.000000000000014, 22.700000000000053, -19.89999999999978, 44.30000000000024, 20.000000000000014, 9.19999999999997, 2.2999999999999643, 11.599999999999964, 27.20000000000013, 38.900000000000254, 32.60000000000023, 20.30000000000002, 20.000000000000014, -152.20000000000002, -150.10000000000002, 32.60000000000023, 20.000000000000014, -26.49999999999975, 41.600000000000236, -179.4999999999999, -208.3000000000004, -7.299999999999891, 20.000000000000014, 20.000000000000014, 20.000000000000014, -218.5, -268.9, -56.199999999999946, -288.69999999999993, 15.799999999999963, 20.000000000000014, -288.4, 20.000000000000014, 20.000000000000014, 7.399999999999965, -253.00000000000028, 20.000000000000014, 20.000000000000014, 29.000000000000163, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -129.10000000000002, -246.70000000000002, 11.599999999999964, 15.199999999999964, 20.000000000000014, 26.00000000000011, 13.699999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, -9.399999999999858, 20.000000000000014, 5.299999999999965, 26.300000000000114, 20.000000000000014, -34.59999999999977, 20.000000000000014, -330.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999753, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 28.100000000000158, 20.000000000000014, 15.799999999999963, 20.000000000000014, -18.399999999999757, -364.0, -113.79999999999998, 2.8999999999999826, 13.699999999999964, 20.000000000000014, 30.500000000000195, -18.999999999999815, 20.000000000000014, 5.299999999999965, 17.899999999999984, 35.30000000000026, 43.40000000000024, 20.000000000000014, -7.599999999999914, -9.399999999999897, 29.00000000000017, -135.40000000000003, 15.799999999999946, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, -360.09999999999997, -53.49999999999978], "policy_predator_policy_reward": [0.0, 0.0, 37.0, 33.0, 6.0, 0.0, 0.0, 1.0, 29.0, 61.0, 0.0, 169.0, 8.0, 0.0, 0.0, 0.0, 8.0, 0.0, 93.0, 0.0, 3.0, 51.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 13.0, 6.0, 0.0, 0.0, 5.0, 0.0, 35.0, 33.0, 6.0, 0.0, 0.0, 0.0, 0.0, 139.0, 177.0, 0.0, 20.0, 17.0, 13.0, 17.0, 186.0, 0.0, 3.0, 0.0, 6.0, 32.0, 8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 171.0, 21.0, 15.0, 165.0, 142.0, 0.0, 0.0, 0.0, 0.0, 18.0, 21.0, 20.0, 169.0, 0.0, 18.0, 0.0, 0.0, 26.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 126.0, 167.0, 69.0, 0.0, 0.0, 118.0, 19.0, 0.0, 2.0, 0.0, 4.0, 18.0, 0.0, 0.0, 11.0, 9.0, 0.0, 4.0, 0.0, 0.0, 5.0, 0.0, 82.0, 0.0, 0.0, 0.0, 17.0, 17.0, 22.0, 171.0, 13.0, 0.0, 0.0, 0.0, 160.0, 0.0, 135.0, 12.0, 0.0, 2.0, 152.0, 0.0, 0.0, 6.0, 130.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.0, 0.0, 10.0, 4.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 16.0, 7.0, 6.0, 0.0, 0.0, 16.0, 12.0, 166.0, 1.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 17.0, 9.0, 11.0, 187.0, 12.0, 3.0, 4.0, 0.0, 0.0, 31.0, 0.0, 14.0, 0.0, 0.0, 11.0, 17.0, 10.0, 4.0, 0.0, 76.0, 0.0, 0.0, 0.0, 0.0, 0.0, 194.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.447633865889513, "mean_inference_ms": 11.214624610432347, "mean_action_processing_ms": 0.6511871310841444, "mean_env_wait_ms": 1.5197805491087246, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010018587112426758, "StateBufferConnector_ms": 0.013775825500488281, "ViewRequirementAgentConnector_ms": 0.32703661918640137}, "num_episodes": 18, "episode_return_max": 78.69999999999945, "episode_return_min": -393.09999999999997, "episode_return_mean": -27.749999999999826, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 170.79653451095672, "num_env_steps_trained_throughput_per_sec": 170.79653451095672, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 23253.209, "restore_workers_time_ms": 0.032, "training_step_time_ms": 23252.635, "sample_time_ms": 4300.746, "learn_time_ms": 18900.352, "learn_throughput": 211.636, "synch_weights_time_ms": 45.439}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "3a355_00000", "date": "2024-08-13_02-47-11", "timestamp": 1723531631, "time_this_iter_s": 23.482887983322144, "time_total_s": 5836.437199354172, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dbe670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5836.437199354172, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 86.14545454545456, "ram_util_percent": 83.14545454545454}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.322470206910222, "cur_kl_coeff": 1.7763568394002506e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4896573762729686, "policy_loss": -0.0016324849382890437, "vf_loss": 1.4912898591113468, "vf_explained_var": 0.006712754031337758, "kl": 0.006596057146415144, "entropy": 0.1508085780752399, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7739823542141094, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8968950170057792, "policy_loss": -0.0015061562460792995, "vf_loss": 2.8980656659161603, "vf_explained_var": 0.0013180284273056756, "kl": 0.013239703708367889, "entropy": 1.1065970272614212, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 78.69999999999945, "episode_reward_min": -393.09999999999997, "episode_reward_mean": -25.996999999999858, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -370.6, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 44.30000000000024, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": -35.55849999999995, "predator_policy": 22.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [23.00000000000006, -8.599999999999834, -328.4000000000001, 42.10000000000032, -11.99999999999958, 35.70000000000024, 41.100000000000314, 51.70000000000049, 49.000000000000455, 17.99999999999995, -341.3, -347.59999999999997, -102.70000000000093, 50.80000000000048, 40.0000000000003, 1.2000000000002002, -393.09999999999997, 37.000000000000256, -43.199999999999775, 40.0000000000003, 35.600000000000236, 40.0000000000003, 40.0000000000003, -131.39999999999998, -168.19999999999987, -123.40000000000005, 19.099999999999966, 37.80000000000027, 24.800000000000065, 64.30000000000047, 31.50000000000018, 42.80000000000034, 71.49999999999999, 45.30000000000039, -220.29999999999993, 52.60000000000051, 49.10000000000046, -194.80000000000064, 25.70000000000007, 40.0000000000003, -327.3999999999999, -197.90000000000015, 37.80000000000027, -116.40000000000022, 33.400000000000205, -103.00000000000085, 49.00000000000045, 34.50000000000022, 40.0000000000003, 40.0000000000003, -248.8, 40.80000000000031, 47.00000000000041, 36.70000000000025, 40.0000000000003, 3.500000000000209, 38.30000000000027, 46.300000000000395, 13.399999999999984, -143.70000000000044, 40.0000000000003, 17.399999999999952, 40.0000000000003, 47.00000000000043, 37.80000000000027, 27.600000000000108, -279.8000000000003, 31.600000000000165, 54.50000000000049, 32.00000000000043, 37.20000000000026, 78.69999999999945, 40.4000000000003, 33.60000000000021, -43.599999999999866, 44.50000000000037, 40.0000000000003, -219.6000000000006, -117.99999999999986, 40.0000000000003, 60.90000000000043, 40.0000000000003, 40.4000000000003, 20.199999999999985, -121.70000000000084, 31.400000000000162, 11.299999999999928, -270.9000000000001, 31.400000000000176, 33.400000000000205, -294.69999999999993, 55.0000000000005, -142.19999999999996, 31.200000000000166, 40.0000000000003, 15.799999999999976, -3.2999999999997236, -20.899999999999714, 42.70000000000034, -179.19999999999968], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-11.199999999999863, -2.7999999999999754, 4.400000000000194, -42.999999999999794, -370.6, -143.8, 19.1, 20.000000000000014, -2.7999999999999297, -47.200000000000045, 7.699999999999967, 20.000000000000014, 13.09999999999997, 20.000000000000014, 31.700000000000212, 20.000000000000014, 28.10000000000015, 20.90000000000003, -21.999999999999766, 20.000000000000014, -171.10000000000002, -362.2, -204.69999999999987, -322.9, -278.1999999999987, 33.50000000000024, 20.000000000000014, 30.800000000000196, -17.799999999999756, 39.80000000000025, 20.000000000000014, -59.80000000000062, -248.8, -313.3, -16.89999999999975, 35.900000000000254, -34.6, -34.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -111.70000000000005, -312.7, -120.70000000000003, -116.50000000000003, -227.8, -13.600000000000009, -19.899999999999757, 20.000000000000014, 15.799999999999963, 20.000000000000014, 22.700000000000053, -19.89999999999978, 44.30000000000024, 20.000000000000014, 9.19999999999997, 2.2999999999999643, 11.599999999999964, 27.20000000000013, 38.900000000000254, 32.60000000000023, 20.30000000000002, 20.000000000000014, -152.20000000000002, -150.10000000000002, 32.60000000000023, 20.000000000000014, -26.49999999999975, 41.600000000000236, -179.4999999999999, -208.3000000000004, -7.299999999999891, 20.000000000000014, 20.000000000000014, 20.000000000000014, -218.5, -268.9, -56.199999999999946, -288.69999999999993, 15.799999999999963, 20.000000000000014, -288.4, 20.000000000000014, 20.000000000000014, 7.399999999999965, -253.00000000000028, 20.000000000000014, 20.000000000000014, 29.000000000000163, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -129.10000000000002, -246.70000000000002, 11.599999999999964, 15.199999999999964, 20.000000000000014, 26.00000000000011, 13.699999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, -9.399999999999858, 20.000000000000014, 5.299999999999965, 26.300000000000114, 20.000000000000014, -34.59999999999977, 20.000000000000014, -330.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999753, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 28.100000000000158, 20.000000000000014, 15.799999999999963, 20.000000000000014, -18.399999999999757, -364.0, -113.79999999999998, 2.8999999999999826, 13.699999999999964, 20.000000000000014, 30.500000000000195, -18.999999999999815, 20.000000000000014, 5.299999999999965, 17.899999999999984, 35.30000000000026, 43.40000000000024, 20.000000000000014, -7.599999999999914, -9.399999999999897, 29.00000000000017, -135.40000000000003, 15.799999999999946, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, -360.09999999999997, -53.49999999999978, -84.69999999999997, -91.29999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 32.90000000000021, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.399999999999968, -17.799999999999763, 20.000000000000014, -288.699999999999, 20.000000000000014, -13.599999999999783, 29.000000000000174, -19.89999999999982, -17.79999999999974, -183.70000000000007, -224.2000000000001, 8.299999999999978, 7.0999999999999694, 7.39999999999997, 20.000000000000014, -137.50000000000003, -332.2, 37.40000000000025, 11.599999999999964, -57.70000000000004, -179.50000000000003, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, -3.099999999999965, -26.19999999999976, -36.70000000000003, -11.199999999999832, 22.700000000000053, 20.000000000000014, -91.30000000000004, -187.90000000000057], "policy_predator_policy_reward": [20.0, 17.0, 13.0, 17.0, 186.0, 0.0, 3.0, 0.0, 6.0, 32.0, 8.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 171.0, 21.0, 15.0, 165.0, 142.0, 0.0, 0.0, 0.0, 0.0, 18.0, 21.0, 20.0, 169.0, 0.0, 18.0, 0.0, 0.0, 26.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 126.0, 167.0, 69.0, 0.0, 0.0, 118.0, 19.0, 0.0, 2.0, 0.0, 4.0, 18.0, 0.0, 0.0, 11.0, 9.0, 0.0, 4.0, 0.0, 0.0, 5.0, 0.0, 82.0, 0.0, 0.0, 0.0, 17.0, 17.0, 22.0, 171.0, 13.0, 0.0, 0.0, 0.0, 160.0, 0.0, 135.0, 12.0, 0.0, 2.0, 152.0, 0.0, 0.0, 6.0, 130.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.0, 0.0, 10.0, 4.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 16.0, 7.0, 6.0, 0.0, 0.0, 16.0, 12.0, 166.0, 1.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 17.0, 9.0, 11.0, 187.0, 12.0, 3.0, 4.0, 0.0, 0.0, 31.0, 0.0, 14.0, 0.0, 0.0, 11.0, 17.0, 10.0, 4.0, 0.0, 76.0, 0.0, 0.0, 0.0, 0.0, 0.0, 194.0, 19.0, 39.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 18.0, 4.0, 143.0, 0.0, 16.0, 0.0, 49.0, 0.0, 137.0, 0.0, 16.0, 0.0, 6.0, 22.0, 153.0, 2.0, 4.0, 95.0, 0.0, 8.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 26.0, 7.0, 20.0, 0.0, 0.0, 0.0, 100.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.5253993411293902, "mean_inference_ms": 11.033783786327485, "mean_action_processing_ms": 0.6529594111910656, "mean_env_wait_ms": 1.5124872516942371, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010292649269104004, "StateBufferConnector_ms": 0.015021324157714844, "ViewRequirementAgentConnector_ms": 0.2996150255203247}, "num_episodes": 22, "episode_return_max": 78.69999999999945, "episode_return_min": -393.09999999999997, "episode_return_mean": -25.996999999999858, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 141.2634600507035, "num_env_steps_trained_throughput_per_sec": 141.2634600507035, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 23931.627, "restore_workers_time_ms": 0.032, "training_step_time_ms": 23931.05, "sample_time_ms": 4381.663, "learn_time_ms": 19498.192, "learn_throughput": 205.147, "synch_weights_time_ms": 45.333}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "3a355_00000", "date": "2024-08-13_02-47-40", "timestamp": 1723531660, "time_this_iter_s": 28.387059926986694, "time_total_s": 5864.824259281158, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3ddf430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5864.824259281158, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 89.0725, "ram_util_percent": 83.5875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5299385583609658, "cur_kl_coeff": 1.7763568394002506e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0379674361811744, "policy_loss": -0.0004203758547427478, "vf_loss": 1.0383878127923087, "vf_explained_var": 0.004877661176459499, "kl": 0.0017487523601099914, "entropy": 0.2694281055261849, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3491189357149538, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8644957905723936, "policy_loss": -0.001963597201500778, "vf_loss": 1.8662126258567528, "vf_explained_var": -0.004495224530103976, "kl": 0.009737552753051163, "entropy": 1.0872115805035545, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 87.69999999999875, "episode_reward_min": -327.3999999999999, "episode_reward_mean": -15.268999999999869, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 67.69999999999992, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": -27.61449999999996, "predator_policy": 19.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-43.199999999999775, 40.0000000000003, 35.600000000000236, 40.0000000000003, 40.0000000000003, -131.39999999999998, -168.19999999999987, -123.40000000000005, 19.099999999999966, 37.80000000000027, 24.800000000000065, 64.30000000000047, 31.50000000000018, 42.80000000000034, 71.49999999999999, 45.30000000000039, -220.29999999999993, 52.60000000000051, 49.10000000000046, -194.80000000000064, 25.70000000000007, 40.0000000000003, -327.3999999999999, -197.90000000000015, 37.80000000000027, -116.40000000000022, 33.400000000000205, -103.00000000000085, 49.00000000000045, 34.50000000000022, 40.0000000000003, 40.0000000000003, -248.8, 40.80000000000031, 47.00000000000041, 36.70000000000025, 40.0000000000003, 3.500000000000209, 38.30000000000027, 46.300000000000395, 13.399999999999984, -143.70000000000044, 40.0000000000003, 17.399999999999952, 40.0000000000003, 47.00000000000043, 37.80000000000027, 27.600000000000108, -279.8000000000003, 31.600000000000165, 54.50000000000049, 32.00000000000043, 37.20000000000026, 78.69999999999945, 40.4000000000003, 33.60000000000021, -43.599999999999866, 44.50000000000037, 40.0000000000003, -219.6000000000006, -117.99999999999986, 40.0000000000003, 60.90000000000043, 40.0000000000003, 40.4000000000003, 20.199999999999985, -121.70000000000084, 31.400000000000162, 11.299999999999928, -270.9000000000001, 31.400000000000176, 33.400000000000205, -294.69999999999993, 55.0000000000005, -142.19999999999996, 31.200000000000166, 40.0000000000003, 15.799999999999976, -3.2999999999997236, -20.899999999999714, 42.70000000000034, -179.19999999999968, 40.90000000000031, 27.300000000000104, 2.600000000000187, 48.900000000000446, 13.699999999999928, 52.60000000000049, 47.900000000000475, 87.69999999999875, 60.700000000000465, 50.80000000000049, -277.9, 22.400000000000013, -233.10000000000045, 32.40000000000019, 55.300000000000516, -171.50000000000082, 40.0000000000003, 28.000000000000114], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-34.6, -34.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -111.70000000000005, -312.7, -120.70000000000003, -116.50000000000003, -227.8, -13.600000000000009, -19.899999999999757, 20.000000000000014, 15.799999999999963, 20.000000000000014, 22.700000000000053, -19.89999999999978, 44.30000000000024, 20.000000000000014, 9.19999999999997, 2.2999999999999643, 11.599999999999964, 27.20000000000013, 38.900000000000254, 32.60000000000023, 20.30000000000002, 20.000000000000014, -152.20000000000002, -150.10000000000002, 32.60000000000023, 20.000000000000014, -26.49999999999975, 41.600000000000236, -179.4999999999999, -208.3000000000004, -7.299999999999891, 20.000000000000014, 20.000000000000014, 20.000000000000014, -218.5, -268.9, -56.199999999999946, -288.69999999999993, 15.799999999999963, 20.000000000000014, -288.4, 20.000000000000014, 20.000000000000014, 7.399999999999965, -253.00000000000028, 20.000000000000014, 20.000000000000014, 29.000000000000163, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -129.10000000000002, -246.70000000000002, 11.599999999999964, 15.199999999999964, 20.000000000000014, 26.00000000000011, 13.699999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, -9.399999999999858, 20.000000000000014, 5.299999999999965, 26.300000000000114, 20.000000000000014, -34.59999999999977, 20.000000000000014, -330.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999753, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 28.100000000000158, 20.000000000000014, 15.799999999999963, 20.000000000000014, -18.399999999999757, -364.0, -113.79999999999998, 2.8999999999999826, 13.699999999999964, 20.000000000000014, 30.500000000000195, -18.999999999999815, 20.000000000000014, 5.299999999999965, 17.899999999999984, 35.30000000000026, 43.40000000000024, 20.000000000000014, -7.599999999999914, -9.399999999999897, 29.00000000000017, -135.40000000000003, 15.799999999999946, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, -360.09999999999997, -53.49999999999978, -84.69999999999997, -91.29999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 32.90000000000021, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.399999999999968, -17.799999999999763, 20.000000000000014, -288.699999999999, 20.000000000000014, -13.599999999999783, 29.000000000000174, -19.89999999999982, -17.79999999999974, -183.70000000000007, -224.2000000000001, 8.299999999999978, 7.0999999999999694, 7.39999999999997, 20.000000000000014, -137.50000000000003, -332.2, 37.40000000000025, 11.599999999999964, -57.70000000000004, -179.50000000000003, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, -3.099999999999965, -26.19999999999976, -36.70000000000003, -11.199999999999832, 22.700000000000053, 20.000000000000014, -91.30000000000004, -187.90000000000057, 20.000000000000014, 20.90000000000003, 20.000000000000014, -18.699999999999754, -24.39999999999975, -1.0000000000000133, 23.900000000000077, 20.000000000000014, -52.29999999999986, 20.000000000000014, 20.000000000000014, 23.6000000000001, 8.89999999999998, 20.000000000000014, 20.000000000000014, 67.69999999999992, 20.000000000000014, 40.70000000000022, 30.8000000000002, 20.000000000000014, -187.90000000000003, -190.00000000000003, 20.000000000000014, -13.599999999999783, -213.10000000000045, -196.00000000000003, -3.0999999999999686, 24.50000000000008, 20.000000000000014, 35.30000000000026, -78.70000000000053, -215.8000000000003, 20.000000000000014, 20.000000000000014, 24.500000000000092, -11.499999999999819], "policy_predator_policy_reward": [0.0, 26.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 126.0, 167.0, 69.0, 0.0, 0.0, 118.0, 19.0, 0.0, 2.0, 0.0, 4.0, 18.0, 0.0, 0.0, 11.0, 9.0, 0.0, 4.0, 0.0, 0.0, 5.0, 0.0, 82.0, 0.0, 0.0, 0.0, 17.0, 17.0, 22.0, 171.0, 13.0, 0.0, 0.0, 0.0, 160.0, 0.0, 135.0, 12.0, 0.0, 2.0, 152.0, 0.0, 0.0, 6.0, 130.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.0, 0.0, 10.0, 4.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 16.0, 7.0, 6.0, 0.0, 0.0, 16.0, 12.0, 166.0, 1.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 17.0, 9.0, 11.0, 187.0, 12.0, 3.0, 4.0, 0.0, 0.0, 31.0, 0.0, 14.0, 0.0, 0.0, 11.0, 17.0, 10.0, 4.0, 0.0, 76.0, 0.0, 0.0, 0.0, 0.0, 0.0, 194.0, 19.0, 39.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 18.0, 4.0, 143.0, 0.0, 16.0, 0.0, 49.0, 0.0, 137.0, 0.0, 16.0, 0.0, 6.0, 22.0, 153.0, 2.0, 4.0, 95.0, 0.0, 8.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 26.0, 7.0, 20.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 21.0, 5.0, 28.0, 0.0, 0.0, 5.0, 30.0, 16.0, 9.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 16.0, 176.0, 0.0, 0.0, 11.0, 0.0, 0.0, 14.0, 109.0, 0.0, 0.0, 0.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4284382492511893, "mean_inference_ms": 11.059481889327968, "mean_action_processing_ms": 0.6526105323634109, "mean_env_wait_ms": 1.4980746598521588, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010928034782409668, "StateBufferConnector_ms": 0.015047430992126465, "ViewRequirementAgentConnector_ms": 0.2722851037979126}, "num_episodes": 18, "episode_return_max": 87.69999999999875, "episode_return_min": -327.3999999999999, "episode_return_mean": -15.268999999999869, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 160.4807047370105, "num_env_steps_trained_throughput_per_sec": 160.4807047370105, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 24342.017, "restore_workers_time_ms": 0.032, "training_step_time_ms": 24341.44, "sample_time_ms": 4424.066, "learn_time_ms": 19869.04, "learn_throughput": 201.318, "synch_weights_time_ms": 42.767}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "3a355_00000", "date": "2024-08-13_02-48-05", "timestamp": 1723531685, "time_this_iter_s": 24.995800018310547, "time_total_s": 5889.820059299469, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5075d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5889.820059299469, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 86.88857142857144, "ram_util_percent": 83.51428571428572}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3914124484947592, "cur_kl_coeff": 8.881784197001253e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.956440960982489, "policy_loss": -0.000785289745822194, "vf_loss": 1.9572262516097416, "vf_explained_var": 0.0007032756767575703, "kl": 0.002735479316145258, "entropy": 0.2562127539247432, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.880256467188398, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.096782173176922, "policy_loss": -0.0022581330544891812, "vf_loss": 3.098682973056874, "vf_explained_var": 0.004154353923898525, "kl": 0.014100777195175355, "entropy": 1.1214839653363304, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 87.69999999999875, "episode_reward_min": -352.4999999999999, "episode_reward_mean": -13.002999999999862, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 67.69999999999992, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": -25.826499999999967, "predator_policy": 19.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-197.90000000000015, 37.80000000000027, -116.40000000000022, 33.400000000000205, -103.00000000000085, 49.00000000000045, 34.50000000000022, 40.0000000000003, 40.0000000000003, -248.8, 40.80000000000031, 47.00000000000041, 36.70000000000025, 40.0000000000003, 3.500000000000209, 38.30000000000027, 46.300000000000395, 13.399999999999984, -143.70000000000044, 40.0000000000003, 17.399999999999952, 40.0000000000003, 47.00000000000043, 37.80000000000027, 27.600000000000108, -279.8000000000003, 31.600000000000165, 54.50000000000049, 32.00000000000043, 37.20000000000026, 78.69999999999945, 40.4000000000003, 33.60000000000021, -43.599999999999866, 44.50000000000037, 40.0000000000003, -219.6000000000006, -117.99999999999986, 40.0000000000003, 60.90000000000043, 40.0000000000003, 40.4000000000003, 20.199999999999985, -121.70000000000084, 31.400000000000162, 11.299999999999928, -270.9000000000001, 31.400000000000176, 33.400000000000205, -294.69999999999993, 55.0000000000005, -142.19999999999996, 31.200000000000166, 40.0000000000003, 15.799999999999976, -3.2999999999997236, -20.899999999999714, 42.70000000000034, -179.19999999999968, 40.90000000000031, 27.300000000000104, 2.600000000000187, 48.900000000000446, 13.699999999999928, 52.60000000000049, 47.900000000000475, 87.69999999999875, 60.700000000000465, 50.80000000000049, -277.9, 22.400000000000013, -233.10000000000045, 32.40000000000019, 55.300000000000516, -171.50000000000082, 40.0000000000003, 28.000000000000114, 53.70000000000047, -67.79999999999997, -203.5000000000004, -25.599999999999568, 14.799999999999992, 57.100000000000385, 67.50000000000021, 48.10000000000043, 40.0000000000003, 34.70000000000029, 40.0000000000003, -13.19999999999965, 30.700000000000163, -24.599999999999547, 57.70000000000041, 30.100000000000154, 12.100000000000046, 61.40000000000044, -28.199999999999584, -352.4999999999999, 81.39999999999918, -275.89999999999986, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-56.199999999999946, -288.69999999999993, 15.799999999999963, 20.000000000000014, -288.4, 20.000000000000014, 20.000000000000014, 7.399999999999965, -253.00000000000028, 20.000000000000014, 20.000000000000014, 29.000000000000163, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -129.10000000000002, -246.70000000000002, 11.599999999999964, 15.199999999999964, 20.000000000000014, 26.00000000000011, 13.699999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, -9.399999999999858, 20.000000000000014, 5.299999999999965, 26.300000000000114, 20.000000000000014, -34.59999999999977, 20.000000000000014, -330.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999753, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 28.100000000000158, 20.000000000000014, 15.799999999999963, 20.000000000000014, -18.399999999999757, -364.0, -113.79999999999998, 2.8999999999999826, 13.699999999999964, 20.000000000000014, 30.500000000000195, -18.999999999999815, 20.000000000000014, 5.299999999999965, 17.899999999999984, 35.30000000000026, 43.40000000000024, 20.000000000000014, -7.599999999999914, -9.399999999999897, 29.00000000000017, -135.40000000000003, 15.799999999999946, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, -360.09999999999997, -53.49999999999978, -84.69999999999997, -91.29999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 32.90000000000021, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.399999999999968, -17.799999999999763, 20.000000000000014, -288.699999999999, 20.000000000000014, -13.599999999999783, 29.000000000000174, -19.89999999999982, -17.79999999999974, -183.70000000000007, -224.2000000000001, 8.299999999999978, 7.0999999999999694, 7.39999999999997, 20.000000000000014, -137.50000000000003, -332.2, 37.40000000000025, 11.599999999999964, -57.70000000000004, -179.50000000000003, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, -3.099999999999965, -26.19999999999976, -36.70000000000003, -11.199999999999832, 22.700000000000053, 20.000000000000014, -91.30000000000004, -187.90000000000057, 20.000000000000014, 20.90000000000003, 20.000000000000014, -18.699999999999754, -24.39999999999975, -1.0000000000000133, 23.900000000000077, 20.000000000000014, -52.29999999999986, 20.000000000000014, 20.000000000000014, 23.6000000000001, 8.89999999999998, 20.000000000000014, 20.000000000000014, 67.69999999999992, 20.000000000000014, 40.70000000000022, 30.8000000000002, 20.000000000000014, -187.90000000000003, -190.00000000000003, 20.000000000000014, -13.599999999999783, -213.10000000000045, -196.00000000000003, -3.0999999999999686, 24.50000000000008, 20.000000000000014, 35.30000000000026, -78.70000000000053, -215.8000000000003, 20.000000000000014, 20.000000000000014, 24.500000000000092, -11.499999999999819, 20.000000000000014, 25.700000000000113, -39.39999999999998, -72.39999999999984, -231.70000000000005, -101.80000000000047, -28.299999999999784, -28.29999999999979, -51.99999999999987, 30.800000000000203, 59.60000000000018, -53.50000000000008, 46.10000000000022, 10.399999999999972, 26.300000000000114, 21.80000000000004, 20.000000000000014, 20.000000000000014, -68.2000000000009, 44.90000000000014, 20.000000000000014, 20.000000000000014, -85.00000000000074, 21.80000000000004, 20.000000000000014, -28.29999999999975, -51.39999999999998, -35.19999999999976, 13.699999999999967, 20.000000000000014, 20.000000000000014, -7.89999999999991, -57.70000000000004, 15.799999999999963, 7.399999999999965, 47.00000000000021, 7.399999999999965, -97.60000000000073, -228.39999999999992, -255.10000000000002, 20.000000000000014, 61.40000000000019, -225.70000000000002, -167.19999999999993, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [135.0, 12.0, 0.0, 2.0, 152.0, 0.0, 0.0, 6.0, 130.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.0, 0.0, 10.0, 4.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 16.0, 7.0, 6.0, 0.0, 0.0, 16.0, 12.0, 166.0, 1.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 17.0, 9.0, 11.0, 187.0, 12.0, 3.0, 4.0, 0.0, 0.0, 31.0, 0.0, 14.0, 0.0, 0.0, 11.0, 17.0, 10.0, 4.0, 0.0, 76.0, 0.0, 0.0, 0.0, 0.0, 0.0, 194.0, 19.0, 39.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 18.0, 4.0, 143.0, 0.0, 16.0, 0.0, 49.0, 0.0, 137.0, 0.0, 16.0, 0.0, 6.0, 22.0, 153.0, 2.0, 4.0, 95.0, 0.0, 8.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 26.0, 7.0, 20.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 21.0, 5.0, 28.0, 0.0, 0.0, 5.0, 30.0, 16.0, 9.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 16.0, 176.0, 0.0, 0.0, 11.0, 0.0, 0.0, 14.0, 109.0, 0.0, 0.0, 0.0, 15.0, 0.0, 8.0, 44.0, 0.0, 0.0, 130.0, 0.0, 31.0, 0.0, 36.0, 35.0, 16.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 15.0, 43.0, 0.0, 0.0, 0.0, 50.0, 23.0, 16.0, 28.0, 34.0, 0.0, 24.0, 18.0, 0.0, 0.0, 54.0, 6.0, 1.0, 5.0, 57.0, 0.0, 131.0, 0.0, 0.0, 117.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4221128563292194, "mean_inference_ms": 10.883336989325985, "mean_action_processing_ms": 0.6528159830490387, "mean_env_wait_ms": 1.5656023535046426, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012255549430847168, "StateBufferConnector_ms": 0.007514238357543945, "ViewRequirementAgentConnector_ms": 0.30043089389801025}, "num_episodes": 23, "episode_return_max": 87.69999999999875, "episode_return_min": -352.4999999999999, "episode_return_mean": -13.002999999999862, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 140.98286167272815, "num_env_steps_trained_throughput_per_sec": 140.98286167272815, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 24868.39, "restore_workers_time_ms": 0.032, "training_step_time_ms": 24867.812, "sample_time_ms": 4225.249, "learn_time_ms": 20591.645, "learn_throughput": 194.254, "synch_weights_time_ms": 44.844}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "3a355_00000", "date": "2024-08-13_02-48-33", "timestamp": 1723531713, "time_this_iter_s": 28.53627896308899, "time_total_s": 5918.356338262558, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dbe1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5918.356338262558, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 88.4675, "ram_util_percent": 83.625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5116670939243502, "cur_kl_coeff": 4.4408920985006264e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.12296869997625, "policy_loss": -0.0003076792960720403, "vf_loss": 1.1232763778595698, "vf_explained_var": 0.0009498995447915697, "kl": 0.0012518627113574437, "entropy": 0.2849898630112567, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8851990887195502, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.874733269277704, "policy_loss": -0.0027742227615798433, "vf_loss": 1.8770852167770344, "vf_explained_var": -0.007232442797807158, "kl": 0.016663781440766304, "entropy": 1.1174804626318513, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 97.39999999999817, "episode_reward_min": -404.4, "episode_reward_mean": -12.132999999999875, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 67.69999999999992, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": -25.181499999999968, "predator_policy": 19.115}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-143.70000000000044, 40.0000000000003, 17.399999999999952, 40.0000000000003, 47.00000000000043, 37.80000000000027, 27.600000000000108, -279.8000000000003, 31.600000000000165, 54.50000000000049, 32.00000000000043, 37.20000000000026, 78.69999999999945, 40.4000000000003, 33.60000000000021, -43.599999999999866, 44.50000000000037, 40.0000000000003, -219.6000000000006, -117.99999999999986, 40.0000000000003, 60.90000000000043, 40.0000000000003, 40.4000000000003, 20.199999999999985, -121.70000000000084, 31.400000000000162, 11.299999999999928, -270.9000000000001, 31.400000000000176, 33.400000000000205, -294.69999999999993, 55.0000000000005, -142.19999999999996, 31.200000000000166, 40.0000000000003, 15.799999999999976, -3.2999999999997236, -20.899999999999714, 42.70000000000034, -179.19999999999968, 40.90000000000031, 27.300000000000104, 2.600000000000187, 48.900000000000446, 13.699999999999928, 52.60000000000049, 47.900000000000475, 87.69999999999875, 60.700000000000465, 50.80000000000049, -277.9, 22.400000000000013, -233.10000000000045, 32.40000000000019, 55.300000000000516, -171.50000000000082, 40.0000000000003, 28.000000000000114, 53.70000000000047, -67.79999999999997, -203.5000000000004, -25.599999999999568, 14.799999999999992, 57.100000000000385, 67.50000000000021, 48.10000000000043, 40.0000000000003, 34.70000000000029, 40.0000000000003, -13.19999999999965, 30.700000000000163, -24.599999999999547, 57.70000000000041, 30.100000000000154, 12.100000000000046, 61.40000000000044, -28.199999999999584, -352.4999999999999, 81.39999999999918, -275.89999999999986, 40.0000000000003, 97.39999999999817, -404.4, -331.2, 33.400000000000205, 73.2999999999998, 25.200000000000106, 32.500000000000206, 58.9000000000005, -7.299999999999763, 52.00000000000041, 10.300000000000038, 40.0000000000003, 40.0000000000003, 53.50000000000044, 9.000000000000028, 71.49999999999996, 27.50000000000012, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-330.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999753, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 28.100000000000158, 20.000000000000014, 15.799999999999963, 20.000000000000014, -18.399999999999757, -364.0, -113.79999999999998, 2.8999999999999826, 13.699999999999964, 20.000000000000014, 30.500000000000195, -18.999999999999815, 20.000000000000014, 5.299999999999965, 17.899999999999984, 35.30000000000026, 43.40000000000024, 20.000000000000014, -7.599999999999914, -9.399999999999897, 29.00000000000017, -135.40000000000003, 15.799999999999946, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, -360.09999999999997, -53.49999999999978, -84.69999999999997, -91.29999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 32.90000000000021, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.399999999999968, -17.799999999999763, 20.000000000000014, -288.699999999999, 20.000000000000014, -13.599999999999783, 29.000000000000174, -19.89999999999982, -17.79999999999974, -183.70000000000007, -224.2000000000001, 8.299999999999978, 7.0999999999999694, 7.39999999999997, 20.000000000000014, -137.50000000000003, -332.2, 37.40000000000025, 11.599999999999964, -57.70000000000004, -179.50000000000003, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, -3.099999999999965, -26.19999999999976, -36.70000000000003, -11.199999999999832, 22.700000000000053, 20.000000000000014, -91.30000000000004, -187.90000000000057, 20.000000000000014, 20.90000000000003, 20.000000000000014, -18.699999999999754, -24.39999999999975, -1.0000000000000133, 23.900000000000077, 20.000000000000014, -52.29999999999986, 20.000000000000014, 20.000000000000014, 23.6000000000001, 8.89999999999998, 20.000000000000014, 20.000000000000014, 67.69999999999992, 20.000000000000014, 40.70000000000022, 30.8000000000002, 20.000000000000014, -187.90000000000003, -190.00000000000003, 20.000000000000014, -13.599999999999783, -213.10000000000045, -196.00000000000003, -3.0999999999999686, 24.50000000000008, 20.000000000000014, 35.30000000000026, -78.70000000000053, -215.8000000000003, 20.000000000000014, 20.000000000000014, 24.500000000000092, -11.499999999999819, 20.000000000000014, 25.700000000000113, -39.39999999999998, -72.39999999999984, -231.70000000000005, -101.80000000000047, -28.299999999999784, -28.29999999999979, -51.99999999999987, 30.800000000000203, 59.60000000000018, -53.50000000000008, 46.10000000000022, 10.399999999999972, 26.300000000000114, 21.80000000000004, 20.000000000000014, 20.000000000000014, -68.2000000000009, 44.90000000000014, 20.000000000000014, 20.000000000000014, -85.00000000000074, 21.80000000000004, 20.000000000000014, -28.29999999999975, -51.39999999999998, -35.19999999999976, 13.699999999999967, 20.000000000000014, 20.000000000000014, -7.89999999999991, -57.70000000000004, 15.799999999999963, 7.399999999999965, 47.00000000000021, 7.399999999999965, -97.60000000000073, -228.39999999999992, -255.10000000000002, 20.000000000000014, 61.40000000000019, -225.70000000000002, -167.19999999999993, 20.000000000000014, 20.000000000000014, 42.200000000000244, 54.20000000000023, -343.6, -266.8, -307.3, -181.90000000000003, 20.000000000000014, 7.399999999999967, 53.30000000000022, 20.000000000000014, 20.000000000000014, -23.799999999999784, 11.599999999999964, -3.100000000000001, 20.000000000000014, 38.90000000000025, 20.000000000000014, -70.30000000000075, 56.90000000000021, -34.8999999999998, 20.000000000000014, -36.69999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000022, 20.000000000000014, -39.99999999999979, 51.500000000000234, 20.000000000000014, 61.40000000000022, -82.90000000000077, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [166.0, 1.0, 0.0, 0.0, 0.0, 23.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 17.0, 9.0, 11.0, 187.0, 12.0, 3.0, 4.0, 0.0, 0.0, 31.0, 0.0, 14.0, 0.0, 0.0, 11.0, 17.0, 10.0, 4.0, 0.0, 76.0, 0.0, 0.0, 0.0, 0.0, 0.0, 194.0, 19.0, 39.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 18.0, 4.0, 143.0, 0.0, 16.0, 0.0, 49.0, 0.0, 137.0, 0.0, 16.0, 0.0, 6.0, 22.0, 153.0, 2.0, 4.0, 95.0, 0.0, 8.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 26.0, 7.0, 20.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 21.0, 5.0, 28.0, 0.0, 0.0, 5.0, 30.0, 16.0, 9.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 16.0, 176.0, 0.0, 0.0, 11.0, 0.0, 0.0, 14.0, 109.0, 0.0, 0.0, 0.0, 15.0, 0.0, 8.0, 44.0, 0.0, 0.0, 130.0, 0.0, 31.0, 0.0, 36.0, 35.0, 16.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 15.0, 43.0, 0.0, 0.0, 0.0, 50.0, 23.0, 16.0, 28.0, 34.0, 0.0, 24.0, 18.0, 0.0, 0.0, 54.0, 6.0, 1.0, 5.0, 57.0, 0.0, 131.0, 0.0, 0.0, 117.0, 0.0, 0.0, 0.0, 1.0, 0.0, 26.0, 180.0, 133.0, 25.0, 6.0, 0.0, 0.0, 0.0, 29.0, 0.0, 20.0, 4.0, 0.0, 0.0, 9.0, 34.0, 30.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 49.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.415325423964858, "mean_inference_ms": 10.906031651247954, "mean_action_processing_ms": 0.6532634429305397, "mean_env_wait_ms": 1.473080070321476, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01128542423248291, "StateBufferConnector_ms": 0.007914066314697266, "ViewRequirementAgentConnector_ms": 0.3238255977630615}, "num_episodes": 18, "episode_return_max": 97.39999999999817, "episode_return_min": -404.4, "episode_return_mean": -12.132999999999875, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 160.9205615712873, "num_env_steps_trained_throughput_per_sec": 160.9205615712873, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 25020.734, "restore_workers_time_ms": 0.03, "training_step_time_ms": 25020.155, "sample_time_ms": 4135.172, "learn_time_ms": 20837.765, "learn_throughput": 191.959, "synch_weights_time_ms": 41.778}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "3a355_00000", "date": "2024-08-13_02-48-58", "timestamp": 1723531738, "time_this_iter_s": 24.95161008834839, "time_total_s": 5943.307948350906, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5270550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5943.307948350906, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 87.16, "ram_util_percent": 83.38000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.40187730552855305, "cur_kl_coeff": 2.2204460492503132e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3598310825685975, "policy_loss": -0.0015251013410903474, "vf_loss": 2.3613561769641898, "vf_explained_var": 0.0010131412082248264, "kl": 0.0028229729051612103, "entropy": 0.22462327921832048, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7979342864303992, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8417088898401413, "policy_loss": -0.002989088030403884, "vf_loss": 3.8442061293062078, "vf_explained_var": -0.0012039669607051466, "kl": 0.01940902399957271, "entropy": 1.1121945957658153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 97.39999999999817, "episode_reward_min": -404.4, "episode_reward_mean": -21.63299999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -376.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 67.69999999999992, "predator_policy": 194.0}, "policy_reward_mean": {"prey_policy": -31.46649999999998, "predator_policy": 20.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-219.6000000000006, -117.99999999999986, 40.0000000000003, 60.90000000000043, 40.0000000000003, 40.4000000000003, 20.199999999999985, -121.70000000000084, 31.400000000000162, 11.299999999999928, -270.9000000000001, 31.400000000000176, 33.400000000000205, -294.69999999999993, 55.0000000000005, -142.19999999999996, 31.200000000000166, 40.0000000000003, 15.799999999999976, -3.2999999999997236, -20.899999999999714, 42.70000000000034, -179.19999999999968, 40.90000000000031, 27.300000000000104, 2.600000000000187, 48.900000000000446, 13.699999999999928, 52.60000000000049, 47.900000000000475, 87.69999999999875, 60.700000000000465, 50.80000000000049, -277.9, 22.400000000000013, -233.10000000000045, 32.40000000000019, 55.300000000000516, -171.50000000000082, 40.0000000000003, 28.000000000000114, 53.70000000000047, -67.79999999999997, -203.5000000000004, -25.599999999999568, 14.799999999999992, 57.100000000000385, 67.50000000000021, 48.10000000000043, 40.0000000000003, 34.70000000000029, 40.0000000000003, -13.19999999999965, 30.700000000000163, -24.599999999999547, 57.70000000000041, 30.100000000000154, 12.100000000000046, 61.40000000000044, -28.199999999999584, -352.4999999999999, 81.39999999999918, -275.89999999999986, 40.0000000000003, 97.39999999999817, -404.4, -331.2, 33.400000000000205, 73.2999999999998, 25.200000000000106, 32.500000000000206, 58.9000000000005, -7.299999999999763, 52.00000000000041, 10.300000000000038, 40.0000000000003, 40.0000000000003, 53.50000000000044, 9.000000000000028, 71.49999999999996, 27.50000000000012, 40.0000000000003, 26.000000000000124, 40.0000000000003, 17.999999999999975, 58.00000000000052, 52.60000000000048, 40.0000000000003, 3.5000000000000386, 11.399999999999924, -160.89999999999972, 1.5000000000000868, -47.899999999999956, 50.80000000000048, 41.80000000000033, -338.6, -0.6999999999999065, 22.400000000000038, -245.6999999999999, -387.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-360.09999999999997, -53.49999999999978, -84.69999999999997, -91.29999999999984, 20.000000000000014, 20.000000000000014, 20.000000000000014, 32.90000000000021, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.399999999999968, -17.799999999999763, 20.000000000000014, -288.699999999999, 20.000000000000014, -13.599999999999783, 29.000000000000174, -19.89999999999982, -17.79999999999974, -183.70000000000007, -224.2000000000001, 8.299999999999978, 7.0999999999999694, 7.39999999999997, 20.000000000000014, -137.50000000000003, -332.2, 37.40000000000025, 11.599999999999964, -57.70000000000004, -179.50000000000003, 3.1999999999999615, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, -3.099999999999965, -26.19999999999976, -36.70000000000003, -11.199999999999832, 22.700000000000053, 20.000000000000014, -91.30000000000004, -187.90000000000057, 20.000000000000014, 20.90000000000003, 20.000000000000014, -18.699999999999754, -24.39999999999975, -1.0000000000000133, 23.900000000000077, 20.000000000000014, -52.29999999999986, 20.000000000000014, 20.000000000000014, 23.6000000000001, 8.89999999999998, 20.000000000000014, 20.000000000000014, 67.69999999999992, 20.000000000000014, 40.70000000000022, 30.8000000000002, 20.000000000000014, -187.90000000000003, -190.00000000000003, 20.000000000000014, -13.599999999999783, -213.10000000000045, -196.00000000000003, -3.0999999999999686, 24.50000000000008, 20.000000000000014, 35.30000000000026, -78.70000000000053, -215.8000000000003, 20.000000000000014, 20.000000000000014, 24.500000000000092, -11.499999999999819, 20.000000000000014, 25.700000000000113, -39.39999999999998, -72.39999999999984, -231.70000000000005, -101.80000000000047, -28.299999999999784, -28.29999999999979, -51.99999999999987, 30.800000000000203, 59.60000000000018, -53.50000000000008, 46.10000000000022, 10.399999999999972, 26.300000000000114, 21.80000000000004, 20.000000000000014, 20.000000000000014, -68.2000000000009, 44.90000000000014, 20.000000000000014, 20.000000000000014, -85.00000000000074, 21.80000000000004, 20.000000000000014, -28.29999999999975, -51.39999999999998, -35.19999999999976, 13.699999999999967, 20.000000000000014, 20.000000000000014, -7.89999999999991, -57.70000000000004, 15.799999999999963, 7.399999999999965, 47.00000000000021, 7.399999999999965, -97.60000000000073, -228.39999999999992, -255.10000000000002, 20.000000000000014, 61.40000000000019, -225.70000000000002, -167.19999999999993, 20.000000000000014, 20.000000000000014, 42.200000000000244, 54.20000000000023, -343.6, -266.8, -307.3, -181.90000000000003, 20.000000000000014, 7.399999999999967, 53.30000000000022, 20.000000000000014, 20.000000000000014, -23.799999999999784, 11.599999999999964, -3.100000000000001, 20.000000000000014, 38.90000000000025, 20.000000000000014, -70.30000000000075, 56.90000000000021, -34.8999999999998, 20.000000000000014, -36.69999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000022, 20.000000000000014, -39.99999999999979, 51.500000000000234, 20.000000000000014, 61.40000000000022, -82.90000000000077, 20.000000000000014, 20.000000000000014, -9.699999999999939, -7.299999999999891, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999744, 38.000000000000256, 20.000000000000014, 20.000000000000014, 32.600000000000236, 20.000000000000014, 20.000000000000014, -68.50000000000071, 20.000000000000014, 27.20000000000014, -59.800000000000395, -114.39999999999982, -155.5000000000002, 20.000000000000014, -53.50000000000001, -55.59999999999998, -31.29999999999982, 20.000000000000014, 30.800000000000196, 20.000000000000014, 21.80000000000004, -313.9, -183.70000000000002, 20.000000000000014, -57.70000000000025, 20.000000000000014, -28.599999999999767, -148.00000000000003, -231.7, -213.09999999999988, -376.9000000000001], "policy_predator_policy_reward": [0.0, 194.0, 19.0, 39.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 7.0, 0.0, 18.0, 4.0, 143.0, 0.0, 16.0, 0.0, 49.0, 0.0, 137.0, 0.0, 16.0, 0.0, 6.0, 22.0, 153.0, 2.0, 4.0, 95.0, 0.0, 8.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 26.0, 7.0, 20.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 21.0, 5.0, 28.0, 0.0, 0.0, 5.0, 30.0, 16.0, 9.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 16.0, 176.0, 0.0, 0.0, 11.0, 0.0, 0.0, 14.0, 109.0, 0.0, 0.0, 0.0, 15.0, 0.0, 8.0, 44.0, 0.0, 0.0, 130.0, 0.0, 31.0, 0.0, 36.0, 35.0, 16.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 15.0, 43.0, 0.0, 0.0, 0.0, 50.0, 23.0, 16.0, 28.0, 34.0, 0.0, 24.0, 18.0, 0.0, 0.0, 54.0, 6.0, 1.0, 5.0, 57.0, 0.0, 131.0, 0.0, 0.0, 117.0, 0.0, 0.0, 0.0, 1.0, 0.0, 26.0, 180.0, 133.0, 25.0, 6.0, 0.0, 0.0, 0.0, 29.0, 0.0, 20.0, 4.0, 0.0, 0.0, 9.0, 34.0, 30.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 49.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 10.0, 33.0, 11.0, 19.0, 90.0, 0.0, 35.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 14.0, 145.0, 0.0, 37.0, 5.0, 26.0, 6.0, 128.0, 14.0, 189.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4186146188561524, "mean_inference_ms": 10.863107059277056, "mean_action_processing_ms": 0.6565834828145813, "mean_env_wait_ms": 1.4657258497182324, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009703636169433594, "StateBufferConnector_ms": 0.011081218719482422, "ViewRequirementAgentConnector_ms": 0.4234400987625122}, "num_episodes": 18, "episode_return_max": 97.39999999999817, "episode_return_min": -404.4, "episode_return_mean": -21.63299999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 105.96179207308883, "num_env_steps_trained_throughput_per_sec": 105.96179207308883, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 26328.758, "restore_workers_time_ms": 0.03, "training_step_time_ms": 26328.181, "sample_time_ms": 4795.914, "learn_time_ms": 21490.517, "learn_throughput": 186.129, "synch_weights_time_ms": 37.403}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "3a355_00000", "date": "2024-08-13_02-49-36", "timestamp": 1723531776, "time_this_iter_s": 37.8561327457428, "time_total_s": 5981.164081096649, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5240ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 5981.164081096649, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 94.0611111111111, "ram_util_percent": 83.69074074074075}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4147019300195906, "cur_kl_coeff": 1.1102230246251566e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7910667274994825, "policy_loss": -0.0010432169081584092, "vf_loss": 1.7921099434769343, "vf_explained_var": 0.0013317362025932029, "kl": 0.0011271128239971674, "entropy": 0.22333249005060346, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8708585526242301, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.512863837474238, "policy_loss": -0.0012945756003280324, "vf_loss": 2.514002431132806, "vf_explained_var": -0.0025130697028346795, "kl": 0.006155235230006737, "entropy": 1.080604817249157, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 97.39999999999817, "episode_reward_min": -453.59999999999997, "episode_reward_mean": -32.85299999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -376.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 67.69999999999992, "predator_policy": 189.0}, "policy_reward_mean": {"prey_policy": -40.37649999999999, "predator_policy": 23.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-179.19999999999968, 40.90000000000031, 27.300000000000104, 2.600000000000187, 48.900000000000446, 13.699999999999928, 52.60000000000049, 47.900000000000475, 87.69999999999875, 60.700000000000465, 50.80000000000049, -277.9, 22.400000000000013, -233.10000000000045, 32.40000000000019, 55.300000000000516, -171.50000000000082, 40.0000000000003, 28.000000000000114, 53.70000000000047, -67.79999999999997, -203.5000000000004, -25.599999999999568, 14.799999999999992, 57.100000000000385, 67.50000000000021, 48.10000000000043, 40.0000000000003, 34.70000000000029, 40.0000000000003, -13.19999999999965, 30.700000000000163, -24.599999999999547, 57.70000000000041, 30.100000000000154, 12.100000000000046, 61.40000000000044, -28.199999999999584, -352.4999999999999, 81.39999999999918, -275.89999999999986, 40.0000000000003, 97.39999999999817, -404.4, -331.2, 33.400000000000205, 73.2999999999998, 25.200000000000106, 32.500000000000206, 58.9000000000005, -7.299999999999763, 52.00000000000041, 10.300000000000038, 40.0000000000003, 40.0000000000003, 53.50000000000044, 9.000000000000028, 71.49999999999996, 27.50000000000012, 40.0000000000003, 26.000000000000124, 40.0000000000003, 17.999999999999975, 58.00000000000052, 52.60000000000048, 40.0000000000003, 3.5000000000000386, 11.399999999999924, -160.89999999999972, 1.5000000000000868, -47.899999999999956, 50.80000000000048, 41.80000000000033, -338.6, -0.6999999999999065, 22.400000000000038, -245.6999999999999, -387.0000000000003, -364.5000000000001, -85.7000000000015, 43.60000000000044, 61.90000000000049, -453.59999999999997, -449.09999999999997, -360.5, 30.100000000000147, -45.60000000000059, -394.49999999999994, 40.0000000000003, 40.0000000000003, 40.0000000000003, 55.300000000000516, 58.90000000000052, 85.89999999999884, -251.40000000000003, 40.0000000000003, 40.0000000000003, 44.50000000000043, 32.40000000000019, -27.29999999999952], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-91.30000000000004, -187.90000000000057, 20.000000000000014, 20.90000000000003, 20.000000000000014, -18.699999999999754, -24.39999999999975, -1.0000000000000133, 23.900000000000077, 20.000000000000014, -52.29999999999986, 20.000000000000014, 20.000000000000014, 23.6000000000001, 8.89999999999998, 20.000000000000014, 20.000000000000014, 67.69999999999992, 20.000000000000014, 40.70000000000022, 30.8000000000002, 20.000000000000014, -187.90000000000003, -190.00000000000003, 20.000000000000014, -13.599999999999783, -213.10000000000045, -196.00000000000003, -3.0999999999999686, 24.50000000000008, 20.000000000000014, 35.30000000000026, -78.70000000000053, -215.8000000000003, 20.000000000000014, 20.000000000000014, 24.500000000000092, -11.499999999999819, 20.000000000000014, 25.700000000000113, -39.39999999999998, -72.39999999999984, -231.70000000000005, -101.80000000000047, -28.299999999999784, -28.29999999999979, -51.99999999999987, 30.800000000000203, 59.60000000000018, -53.50000000000008, 46.10000000000022, 10.399999999999972, 26.300000000000114, 21.80000000000004, 20.000000000000014, 20.000000000000014, -68.2000000000009, 44.90000000000014, 20.000000000000014, 20.000000000000014, -85.00000000000074, 21.80000000000004, 20.000000000000014, -28.29999999999975, -51.39999999999998, -35.19999999999976, 13.699999999999967, 20.000000000000014, 20.000000000000014, -7.89999999999991, -57.70000000000004, 15.799999999999963, 7.399999999999965, 47.00000000000021, 7.399999999999965, -97.60000000000073, -228.39999999999992, -255.10000000000002, 20.000000000000014, 61.40000000000019, -225.70000000000002, -167.19999999999993, 20.000000000000014, 20.000000000000014, 42.200000000000244, 54.20000000000023, -343.6, -266.8, -307.3, -181.90000000000003, 20.000000000000014, 7.399999999999967, 53.30000000000022, 20.000000000000014, 20.000000000000014, -23.799999999999784, 11.599999999999964, -3.100000000000001, 20.000000000000014, 38.90000000000025, 20.000000000000014, -70.30000000000075, 56.90000000000021, -34.8999999999998, 20.000000000000014, -36.69999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000022, 20.000000000000014, -39.99999999999979, 51.500000000000234, 20.000000000000014, 61.40000000000022, -82.90000000000077, 20.000000000000014, 20.000000000000014, -9.699999999999939, -7.299999999999891, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999744, 38.000000000000256, 20.000000000000014, 20.000000000000014, 32.600000000000236, 20.000000000000014, 20.000000000000014, -68.50000000000071, 20.000000000000014, 27.20000000000014, -59.800000000000395, -114.39999999999982, -155.5000000000002, 20.000000000000014, -53.50000000000001, -55.59999999999998, -31.29999999999982, 20.000000000000014, 30.800000000000196, 20.000000000000014, 21.80000000000004, -313.9, -183.70000000000002, 20.000000000000014, -57.70000000000025, 20.000000000000014, -28.599999999999767, -148.00000000000003, -231.7, -213.09999999999988, -376.9000000000001, -250.29999999999998, -263.2, -68.2000000000009, -116.5000000000006, 20.000000000000014, -3.4000000000000297, 20.000000000000014, 38.90000000000023, -324.4, -305.2, -299.2, -334.9, -354.7, -374.8, 20.000000000000014, 1.0999999999999865, -40.89999999999976, -36.69999999999976, -246.69999999999996, -320.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000026, 38.900000000000254, 20.000000000000014, 28.100000000000147, 57.80000000000018, -255.10000000000002, -301.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.999999999999787, 12.499999999999977, -34.59999999999975, 38.00000000000024, -93.4000000000008, 4.099999999999966], "policy_predator_policy_reward": [0.0, 100.0, 0.0, 0.0, 21.0, 5.0, 28.0, 0.0, 0.0, 5.0, 30.0, 16.0, 9.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 16.0, 176.0, 0.0, 0.0, 11.0, 0.0, 0.0, 14.0, 109.0, 0.0, 0.0, 0.0, 15.0, 0.0, 8.0, 44.0, 0.0, 0.0, 130.0, 0.0, 31.0, 0.0, 36.0, 35.0, 16.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 15.0, 43.0, 0.0, 0.0, 0.0, 50.0, 23.0, 16.0, 28.0, 34.0, 0.0, 24.0, 18.0, 0.0, 0.0, 54.0, 6.0, 1.0, 5.0, 57.0, 0.0, 131.0, 0.0, 0.0, 117.0, 0.0, 0.0, 0.0, 1.0, 0.0, 26.0, 180.0, 133.0, 25.0, 6.0, 0.0, 0.0, 0.0, 29.0, 0.0, 20.0, 4.0, 0.0, 0.0, 9.0, 34.0, 30.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 49.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 10.0, 33.0, 11.0, 19.0, 90.0, 0.0, 35.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 14.0, 145.0, 0.0, 37.0, 5.0, 26.0, 6.0, 128.0, 14.0, 189.0, 148.0, 1.0, 89.0, 10.0, 25.0, 2.0, 3.0, 0.0, 164.0, 12.0, 169.0, 16.0, 181.0, 188.0, 9.0, 0.0, 32.0, 0.0, 0.0, 173.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 152.0, 153.0, 0.0, 0.0, 0.0, 0.0, 28.0, 29.0, 26.0, 3.0, 23.0, 39.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.420118038695484, "mean_inference_ms": 10.813383890404843, "mean_action_processing_ms": 0.6605975946722219, "mean_env_wait_ms": 1.4591636949418478, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009497404098510742, "StateBufferConnector_ms": 0.009782195091247559, "ViewRequirementAgentConnector_ms": 0.4389766454696655}, "num_episodes": 22, "episode_return_max": 97.39999999999817, "episode_return_min": -453.59999999999997, "episode_return_mean": -32.85299999999989, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 159.14586828230387, "num_env_steps_trained_throughput_per_sec": 159.14586828230387, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 26460.318, "restore_workers_time_ms": 0.029, "training_step_time_ms": 26460.233, "sample_time_ms": 4656.772, "learn_time_ms": 21764.809, "learn_throughput": 183.783, "synch_weights_time_ms": 33.873}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "3a355_00000", "date": "2024-08-13_02-50-02", "timestamp": 1723531802, "time_this_iter_s": 25.211427927017212, "time_total_s": 6006.375509023666, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5097ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6006.375509023666, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 87.95428571428572, "ram_util_percent": 83.51142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3570763736017167, "cur_kl_coeff": 5.551115123125783e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3756556954333392, "policy_loss": -0.001023969125426399, "vf_loss": 1.3766796624534345, "vf_explained_var": 0.0013060035844328541, "kl": 0.0012663963614894668, "entropy": 0.18907027764925882, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9032850734377034, "cur_kl_coeff": 0.025341081619262688, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.539060560231486, "policy_loss": -0.0037732416720784923, "vf_loss": 2.5421318677367357, "vf_explained_var": 0.0007672591814919124, "kl": 0.027699426309461806, "entropy": 1.0029622755668781, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 97.39999999999817, "episode_reward_min": -459.6, "episode_reward_mean": -40.27999999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 69.4999999999998, "predator_policy": 189.0}, "policy_reward_mean": {"prey_policy": -45.26499999999999, "predator_policy": 25.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.000000000000114, 53.70000000000047, -67.79999999999997, -203.5000000000004, -25.599999999999568, 14.799999999999992, 57.100000000000385, 67.50000000000021, 48.10000000000043, 40.0000000000003, 34.70000000000029, 40.0000000000003, -13.19999999999965, 30.700000000000163, -24.599999999999547, 57.70000000000041, 30.100000000000154, 12.100000000000046, 61.40000000000044, -28.199999999999584, -352.4999999999999, 81.39999999999918, -275.89999999999986, 40.0000000000003, 97.39999999999817, -404.4, -331.2, 33.400000000000205, 73.2999999999998, 25.200000000000106, 32.500000000000206, 58.9000000000005, -7.299999999999763, 52.00000000000041, 10.300000000000038, 40.0000000000003, 40.0000000000003, 53.50000000000044, 9.000000000000028, 71.49999999999996, 27.50000000000012, 40.0000000000003, 26.000000000000124, 40.0000000000003, 17.999999999999975, 58.00000000000052, 52.60000000000048, 40.0000000000003, 3.5000000000000386, 11.399999999999924, -160.89999999999972, 1.5000000000000868, -47.899999999999956, 50.80000000000048, 41.80000000000033, -338.6, -0.6999999999999065, 22.400000000000038, -245.6999999999999, -387.0000000000003, -364.5000000000001, -85.7000000000015, 43.60000000000044, 61.90000000000049, -453.59999999999997, -449.09999999999997, -360.5, 30.100000000000147, -45.60000000000059, -394.49999999999994, 40.0000000000003, 40.0000000000003, 40.0000000000003, 55.300000000000516, 58.90000000000052, 85.89999999999884, -251.40000000000003, 40.0000000000003, 40.0000000000003, 44.50000000000043, 32.40000000000019, -27.29999999999952, 51.600000000000435, 56.2000000000005, -319.0, 41.600000000000314, 40.0000000000003, -458.5999999999999, 41.90000000000036, 45.20000000000048, 40.0000000000003, -331.89999999999986, 40.0000000000003, 28.30000000000012, 50.80000000000048, 40.90000000000031, -25.099999999999582, 37.80000000000027, 58.70000000000038, -459.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [24.500000000000092, -11.499999999999819, 20.000000000000014, 25.700000000000113, -39.39999999999998, -72.39999999999984, -231.70000000000005, -101.80000000000047, -28.299999999999784, -28.29999999999979, -51.99999999999987, 30.800000000000203, 59.60000000000018, -53.50000000000008, 46.10000000000022, 10.399999999999972, 26.300000000000114, 21.80000000000004, 20.000000000000014, 20.000000000000014, -68.2000000000009, 44.90000000000014, 20.000000000000014, 20.000000000000014, -85.00000000000074, 21.80000000000004, 20.000000000000014, -28.29999999999975, -51.39999999999998, -35.19999999999976, 13.699999999999967, 20.000000000000014, 20.000000000000014, -7.89999999999991, -57.70000000000004, 15.799999999999963, 7.399999999999965, 47.00000000000021, 7.399999999999965, -97.60000000000073, -228.39999999999992, -255.10000000000002, 20.000000000000014, 61.40000000000019, -225.70000000000002, -167.19999999999993, 20.000000000000014, 20.000000000000014, 42.200000000000244, 54.20000000000023, -343.6, -266.8, -307.3, -181.90000000000003, 20.000000000000014, 7.399999999999967, 53.30000000000022, 20.000000000000014, 20.000000000000014, -23.799999999999784, 11.599999999999964, -3.100000000000001, 20.000000000000014, 38.90000000000025, 20.000000000000014, -70.30000000000075, 56.90000000000021, -34.8999999999998, 20.000000000000014, -36.69999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000022, 20.000000000000014, -39.99999999999979, 51.500000000000234, 20.000000000000014, 61.40000000000022, -82.90000000000077, 20.000000000000014, 20.000000000000014, -9.699999999999939, -7.299999999999891, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999744, 38.000000000000256, 20.000000000000014, 20.000000000000014, 32.600000000000236, 20.000000000000014, 20.000000000000014, -68.50000000000071, 20.000000000000014, 27.20000000000014, -59.800000000000395, -114.39999999999982, -155.5000000000002, 20.000000000000014, -53.50000000000001, -55.59999999999998, -31.29999999999982, 20.000000000000014, 30.800000000000196, 20.000000000000014, 21.80000000000004, -313.9, -183.70000000000002, 20.000000000000014, -57.70000000000025, 20.000000000000014, -28.599999999999767, -148.00000000000003, -231.7, -213.09999999999988, -376.9000000000001, -250.29999999999998, -263.2, -68.2000000000009, -116.5000000000006, 20.000000000000014, -3.4000000000000297, 20.000000000000014, 38.90000000000023, -324.4, -305.2, -299.2, -334.9, -354.7, -374.8, 20.000000000000014, 1.0999999999999865, -40.89999999999976, -36.69999999999976, -246.69999999999996, -320.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000026, 38.900000000000254, 20.000000000000014, 28.100000000000147, 57.80000000000018, -255.10000000000002, -301.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.999999999999787, 12.499999999999977, -34.59999999999975, 38.00000000000024, -93.4000000000008, 4.099999999999966, 30.8000000000002, -17.199999999999783, 36.20000000000025, 20.000000000000014, -284.5000000000003, -194.49999999999994, 20.000000000000014, 20.600000000000016, 20.000000000000014, 20.000000000000014, -303.4, -341.19999999999993, 50.600000000000236, -39.69999999999978, -7.299999999999947, 39.50000000000024, 20.000000000000014, 20.000000000000014, -223.89999999999992, -253.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.699999999999868, 20.000000000000014, 30.800000000000196, 20.900000000000027, 20.000000000000014, 20.000000000000014, -105.10000000000072, 20.000000000000014, 15.799999999999963, 69.4999999999998, -56.800000000000225, -387.4, -266.2], "policy_predator_policy_reward": [0.0, 15.0, 0.0, 8.0, 44.0, 0.0, 0.0, 130.0, 0.0, 31.0, 0.0, 36.0, 35.0, 16.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 15.0, 43.0, 0.0, 0.0, 0.0, 50.0, 23.0, 16.0, 28.0, 34.0, 0.0, 24.0, 18.0, 0.0, 0.0, 54.0, 6.0, 1.0, 5.0, 57.0, 0.0, 131.0, 0.0, 0.0, 117.0, 0.0, 0.0, 0.0, 1.0, 0.0, 26.0, 180.0, 133.0, 25.0, 6.0, 0.0, 0.0, 0.0, 29.0, 0.0, 20.0, 4.0, 0.0, 0.0, 9.0, 34.0, 30.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 49.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 10.0, 33.0, 11.0, 19.0, 90.0, 0.0, 35.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 14.0, 145.0, 0.0, 37.0, 5.0, 26.0, 6.0, 128.0, 14.0, 189.0, 148.0, 1.0, 89.0, 10.0, 25.0, 2.0, 3.0, 0.0, 164.0, 12.0, 169.0, 16.0, 181.0, 188.0, 9.0, 0.0, 32.0, 0.0, 0.0, 173.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 152.0, 153.0, 0.0, 0.0, 0.0, 0.0, 28.0, 29.0, 26.0, 3.0, 23.0, 39.0, 21.0, 17.0, 0.0, 0.0, 42.0, 118.0, 0.0, 1.0, 0.0, 0.0, 150.0, 36.0, 0.0, 31.0, 13.0, 0.0, 0.0, 0.0, 0.0, 145.0, 0.0, 0.0, 2.0, 16.0, 0.0, 0.0, 0.0, 0.0, 35.0, 25.0, 0.0, 2.0, 0.0, 46.0, 18.0, 176.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.423254475254256, "mean_inference_ms": 10.77238598734042, "mean_action_processing_ms": 0.663748356506309, "mean_env_wait_ms": 1.452130007932859, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008746981620788574, "StateBufferConnector_ms": 0.009667038917541504, "ViewRequirementAgentConnector_ms": 0.4332383871078491}, "num_episodes": 18, "episode_return_max": 97.39999999999817, "episode_return_min": -459.6, "episode_return_mean": -40.27999999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 155.37011501120753, "num_env_steps_trained_throughput_per_sec": 155.37011501120753, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 26601.179, "restore_workers_time_ms": 0.019, "training_step_time_ms": 26601.103, "sample_time_ms": 4528.283, "learn_time_ms": 22038.986, "learn_throughput": 181.497, "synch_weights_time_ms": 28.812}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "3a355_00000", "date": "2024-08-13_02-50-27", "timestamp": 1723531827, "time_this_iter_s": 25.823029041290283, "time_total_s": 6032.198538064957, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52de940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6032.198538064957, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 87.8135135135135, "ram_util_percent": 83.47837837837837}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4922170131314526, "cur_kl_coeff": 2.7755575615628915e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1410135330977265, "policy_loss": -0.0008482823915848578, "vf_loss": 2.1418618141027985, "vf_explained_var": 0.0020687553617689345, "kl": 0.0023263571237067174, "entropy": 0.18879091740837173, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.864169248252634, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9700842854207155, "policy_loss": -0.0007119848700880846, "vf_loss": 2.9705580061705654, "vf_explained_var": 0.0018916447011251298, "kl": 0.0062680557152708346, "entropy": 1.0018642037633865, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 97.39999999999817, "episode_reward_min": -474.5, "episode_reward_mean": -43.13299999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 69.4999999999998, "predator_policy": 189.0}, "policy_reward_mean": {"prey_policy": -47.36649999999999, "predator_policy": 25.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 97.39999999999817, -404.4, -331.2, 33.400000000000205, 73.2999999999998, 25.200000000000106, 32.500000000000206, 58.9000000000005, -7.299999999999763, 52.00000000000041, 10.300000000000038, 40.0000000000003, 40.0000000000003, 53.50000000000044, 9.000000000000028, 71.49999999999996, 27.50000000000012, 40.0000000000003, 26.000000000000124, 40.0000000000003, 17.999999999999975, 58.00000000000052, 52.60000000000048, 40.0000000000003, 3.5000000000000386, 11.399999999999924, -160.89999999999972, 1.5000000000000868, -47.899999999999956, 50.80000000000048, 41.80000000000033, -338.6, -0.6999999999999065, 22.400000000000038, -245.6999999999999, -387.0000000000003, -364.5000000000001, -85.7000000000015, 43.60000000000044, 61.90000000000049, -453.59999999999997, -449.09999999999997, -360.5, 30.100000000000147, -45.60000000000059, -394.49999999999994, 40.0000000000003, 40.0000000000003, 40.0000000000003, 55.300000000000516, 58.90000000000052, 85.89999999999884, -251.40000000000003, 40.0000000000003, 40.0000000000003, 44.50000000000043, 32.40000000000019, -27.29999999999952, 51.600000000000435, 56.2000000000005, -319.0, 41.600000000000314, 40.0000000000003, -458.5999999999999, 41.90000000000036, 45.20000000000048, 40.0000000000003, -331.89999999999986, 40.0000000000003, 28.30000000000012, 50.80000000000048, 40.90000000000031, -25.099999999999582, 37.80000000000027, 58.70000000000038, -459.6, 10.60000000000008, -15.89999999999949, -330.1000000000003, -134.90000000000038, 40.0000000000003, 1.5000000000002431, 29.000000000000128, -57.29999999999978, 63.40000000000051, 58.50000000000045, 47.00000000000044, -7.299999999999706, 37.5000000000003, -474.5, 11.400000000000048, 0.400000000000193, -59.59999999999996, 40.0000000000003, 34.20000000000021, 90.69999999999854, 40.0000000000003, -86.60000000000173, 42.700000000000394], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 42.200000000000244, 54.20000000000023, -343.6, -266.8, -307.3, -181.90000000000003, 20.000000000000014, 7.399999999999967, 53.30000000000022, 20.000000000000014, 20.000000000000014, -23.799999999999784, 11.599999999999964, -3.100000000000001, 20.000000000000014, 38.90000000000025, 20.000000000000014, -70.30000000000075, 56.90000000000021, -34.8999999999998, 20.000000000000014, -36.69999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 33.50000000000022, 20.000000000000014, -39.99999999999979, 51.500000000000234, 20.000000000000014, 61.40000000000022, -82.90000000000077, 20.000000000000014, 20.000000000000014, -9.699999999999939, -7.299999999999891, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999744, 38.000000000000256, 20.000000000000014, 20.000000000000014, 32.600000000000236, 20.000000000000014, 20.000000000000014, -68.50000000000071, 20.000000000000014, 27.20000000000014, -59.800000000000395, -114.39999999999982, -155.5000000000002, 20.000000000000014, -53.50000000000001, -55.59999999999998, -31.29999999999982, 20.000000000000014, 30.800000000000196, 20.000000000000014, 21.80000000000004, -313.9, -183.70000000000002, 20.000000000000014, -57.70000000000025, 20.000000000000014, -28.599999999999767, -148.00000000000003, -231.7, -213.09999999999988, -376.9000000000001, -250.29999999999998, -263.2, -68.2000000000009, -116.5000000000006, 20.000000000000014, -3.4000000000000297, 20.000000000000014, 38.90000000000023, -324.4, -305.2, -299.2, -334.9, -354.7, -374.8, 20.000000000000014, 1.0999999999999865, -40.89999999999976, -36.69999999999976, -246.69999999999996, -320.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000026, 38.900000000000254, 20.000000000000014, 28.100000000000147, 57.80000000000018, -255.10000000000002, -301.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.999999999999787, 12.499999999999977, -34.59999999999975, 38.00000000000024, -93.4000000000008, 4.099999999999966, 30.8000000000002, -17.199999999999783, 36.20000000000025, 20.000000000000014, -284.5000000000003, -194.49999999999994, 20.000000000000014, 20.600000000000016, 20.000000000000014, 20.000000000000014, -303.4, -341.19999999999993, 50.600000000000236, -39.69999999999978, -7.299999999999947, 39.50000000000024, 20.000000000000014, 20.000000000000014, -223.89999999999992, -253.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.699999999999868, 20.000000000000014, 30.800000000000196, 20.900000000000027, 20.000000000000014, 20.000000000000014, -105.10000000000072, 20.000000000000014, 15.799999999999963, 69.4999999999998, -56.800000000000225, -387.4, -266.2, 13.699999999999964, -24.099999999999746, -34.59999999999975, -7.299999999999891, -280.3, -206.80000000000027, -313.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, -9.399999999999855, -0.9999999999999846, 20.000000000000014, 7.399999999999986, -195.70000000000002, 43.40000000000025, 20.000000000000014, 27.50000000000015, 20.000000000000014, 20.000000000000014, -1.0000000000000329, -19.89999999999978, -12.399999999999844, -8.499999999999929, 20.000000000000014, -328.6, -313.9, -34.59999999999975, 20.000000000000014, 20.000000000000014, -55.60000000000031, -78.70000000000087, -100.89999999999986, 20.000000000000014, 20.000000000000014, 32.60000000000023, -30.39999999999975, 10.399999999999995, 68.29999999999988, 20.000000000000014, 20.000000000000014, -70.30000000000089, -70.30000000000084, 20.000000000000014, -4.3000000000000185], "policy_predator_policy_reward": [0.0, 0.0, 1.0, 0.0, 26.0, 180.0, 133.0, 25.0, 6.0, 0.0, 0.0, 0.0, 29.0, 0.0, 20.0, 4.0, 0.0, 0.0, 9.0, 34.0, 30.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 49.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 10.0, 33.0, 11.0, 19.0, 90.0, 0.0, 35.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 14.0, 145.0, 0.0, 37.0, 5.0, 26.0, 6.0, 128.0, 14.0, 189.0, 148.0, 1.0, 89.0, 10.0, 25.0, 2.0, 3.0, 0.0, 164.0, 12.0, 169.0, 16.0, 181.0, 188.0, 9.0, 0.0, 32.0, 0.0, 0.0, 173.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 152.0, 153.0, 0.0, 0.0, 0.0, 0.0, 28.0, 29.0, 26.0, 3.0, 23.0, 39.0, 21.0, 17.0, 0.0, 0.0, 42.0, 118.0, 0.0, 1.0, 0.0, 0.0, 150.0, 36.0, 0.0, 31.0, 13.0, 0.0, 0.0, 0.0, 0.0, 145.0, 0.0, 0.0, 2.0, 16.0, 0.0, 0.0, 0.0, 0.0, 35.0, 25.0, 0.0, 2.0, 0.0, 46.0, 18.0, 176.0, 0.0, 21.0, 26.0, 0.0, 157.0, 0.0, 159.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 10.0, 28.0, 103.0, 0.0, 0.0, 11.0, 0.0, 0.0, 28.0, 25.0, 0.0, 26.0, 0.0, 166.0, 2.0, 26.0, 0.0, 0.0, 36.0, 0.0, 120.0, 0.0, 0.0, 8.0, 24.0, 11.0, 1.0, 0.0, 0.0, 0.0, 54.0, 27.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4288896132405084, "mean_inference_ms": 10.720970251661624, "mean_action_processing_ms": 0.6678118895938725, "mean_env_wait_ms": 1.441432266175872, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007544040679931641, "StateBufferConnector_ms": 0.009383320808410645, "ViewRequirementAgentConnector_ms": 0.3624464273452759}, "num_episodes": 23, "episode_return_max": 97.39999999999817, "episode_return_min": -474.5, "episode_return_mean": -43.13299999999988, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.57923359355172, "num_env_steps_trained_throughput_per_sec": 154.57923359355172, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 26771.432, "restore_workers_time_ms": 0.018, "training_step_time_ms": 26771.361, "sample_time_ms": 4499.371, "learn_time_ms": 22240.892, "learn_throughput": 179.849, "synch_weights_time_ms": 25.982}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "3a355_00000", "date": "2024-08-13_02-50-53", "timestamp": 1723531853, "time_this_iter_s": 25.93089985847473, "time_total_s": 6058.129437923431, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b551a550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6058.129437923431, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 88.53055555555554, "ram_util_percent": 83.57222222222222}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3934111134420154, "cur_kl_coeff": 1.3877787807814458e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2730466578372572, "policy_loss": -0.0006262333556103012, "vf_loss": 1.273672887950978, "vf_explained_var": 0.0014454479255373515, "kl": 0.0013311220726527297, "entropy": 0.20365722060361235, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9845083068169299, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2178853659718123, "policy_loss": -0.0033880994832586673, "vf_loss": 2.220915244685279, "vf_explained_var": 0.004551802173493401, "kl": 0.00942396551374545, "entropy": 1.0479394854061188, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 148.69999999999862, "episode_reward_min": -474.5, "episode_reward_mean": -37.48599999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 79.09999999999934, "predator_policy": 189.0}, "policy_reward_mean": {"prey_policy": -44.53300000000001, "predator_policy": 25.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 26.000000000000124, 40.0000000000003, 17.999999999999975, 58.00000000000052, 52.60000000000048, 40.0000000000003, 3.5000000000000386, 11.399999999999924, -160.89999999999972, 1.5000000000000868, -47.899999999999956, 50.80000000000048, 41.80000000000033, -338.6, -0.6999999999999065, 22.400000000000038, -245.6999999999999, -387.0000000000003, -364.5000000000001, -85.7000000000015, 43.60000000000044, 61.90000000000049, -453.59999999999997, -449.09999999999997, -360.5, 30.100000000000147, -45.60000000000059, -394.49999999999994, 40.0000000000003, 40.0000000000003, 40.0000000000003, 55.300000000000516, 58.90000000000052, 85.89999999999884, -251.40000000000003, 40.0000000000003, 40.0000000000003, 44.50000000000043, 32.40000000000019, -27.29999999999952, 51.600000000000435, 56.2000000000005, -319.0, 41.600000000000314, 40.0000000000003, -458.5999999999999, 41.90000000000036, 45.20000000000048, 40.0000000000003, -331.89999999999986, 40.0000000000003, 28.30000000000012, 50.80000000000048, 40.90000000000031, -25.099999999999582, 37.80000000000027, 58.70000000000038, -459.6, 10.60000000000008, -15.89999999999949, -330.1000000000003, -134.90000000000038, 40.0000000000003, 1.5000000000002431, 29.000000000000128, -57.29999999999978, 63.40000000000051, 58.50000000000045, 47.00000000000044, -7.299999999999706, 37.5000000000003, -474.5, 11.400000000000048, 0.400000000000193, -59.59999999999996, 40.0000000000003, 34.20000000000021, 90.69999999999854, 40.0000000000003, -86.60000000000173, 42.700000000000394, 37.000000000000256, 94.59999999999832, -8.699999999999871, -273.4, 10.299999999999988, 40.0000000000003, -2.599999999999794, 88.59999999999866, 37.999999999999545, -38.09999999999958, 31.700000000000202, 86.39999999999883, 22.400000000000013, 91.3999999999987, 148.69999999999862, 40.0000000000003, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -9.699999999999939, -7.299999999999891, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999744, 38.000000000000256, 20.000000000000014, 20.000000000000014, 32.600000000000236, 20.000000000000014, 20.000000000000014, -68.50000000000071, 20.000000000000014, 27.20000000000014, -59.800000000000395, -114.39999999999982, -155.5000000000002, 20.000000000000014, -53.50000000000001, -55.59999999999998, -31.29999999999982, 20.000000000000014, 30.800000000000196, 20.000000000000014, 21.80000000000004, -313.9, -183.70000000000002, 20.000000000000014, -57.70000000000025, 20.000000000000014, -28.599999999999767, -148.00000000000003, -231.7, -213.09999999999988, -376.9000000000001, -250.29999999999998, -263.2, -68.2000000000009, -116.5000000000006, 20.000000000000014, -3.4000000000000297, 20.000000000000014, 38.90000000000023, -324.4, -305.2, -299.2, -334.9, -354.7, -374.8, 20.000000000000014, 1.0999999999999865, -40.89999999999976, -36.69999999999976, -246.69999999999996, -320.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000026, 38.900000000000254, 20.000000000000014, 28.100000000000147, 57.80000000000018, -255.10000000000002, -301.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.999999999999787, 12.499999999999977, -34.59999999999975, 38.00000000000024, -93.4000000000008, 4.099999999999966, 30.8000000000002, -17.199999999999783, 36.20000000000025, 20.000000000000014, -284.5000000000003, -194.49999999999994, 20.000000000000014, 20.600000000000016, 20.000000000000014, 20.000000000000014, -303.4, -341.19999999999993, 50.600000000000236, -39.69999999999978, -7.299999999999947, 39.50000000000024, 20.000000000000014, 20.000000000000014, -223.89999999999992, -253.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.699999999999868, 20.000000000000014, 30.800000000000196, 20.900000000000027, 20.000000000000014, 20.000000000000014, -105.10000000000072, 20.000000000000014, 15.799999999999963, 69.4999999999998, -56.800000000000225, -387.4, -266.2, 13.699999999999964, -24.099999999999746, -34.59999999999975, -7.299999999999891, -280.3, -206.80000000000027, -313.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, -9.399999999999855, -0.9999999999999846, 20.000000000000014, 7.399999999999986, -195.70000000000002, 43.40000000000025, 20.000000000000014, 27.50000000000015, 20.000000000000014, 20.000000000000014, -1.0000000000000329, -19.89999999999978, -12.399999999999844, -8.499999999999929, 20.000000000000014, -328.6, -313.9, -34.59999999999975, 20.000000000000014, 20.000000000000014, -55.60000000000031, -78.70000000000087, -100.89999999999986, 20.000000000000014, 20.000000000000014, 32.60000000000023, -30.39999999999975, 10.399999999999995, 68.29999999999988, 20.000000000000014, 20.000000000000014, -70.30000000000089, -70.30000000000084, 20.000000000000014, -4.3000000000000185, 43.40000000000025, -30.39999999999975, 53.90000000000021, 28.70000000000017, 20.000000000000014, -99.70000000000054, -112.29999999999995, -360.1, 20.000000000000014, -36.69999999999979, 20.000000000000014, 20.000000000000014, -64.60000000000083, 20.000000000000014, 68.59999999999984, 20.000000000000014, 50.29999999999961, -106.30000000000008, -129.10000000000073, 20.000000000000014, 20.000000000000014, -16.299999999999798, -3.0999999999999757, 78.49999999999939, -13.599999999999783, 20.000000000000014, 67.39999999999992, 20.000000000000014, 79.09999999999934, 68.59999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 43.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 10.0, 33.0, 11.0, 19.0, 90.0, 0.0, 35.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 14.0, 145.0, 0.0, 37.0, 5.0, 26.0, 6.0, 128.0, 14.0, 189.0, 148.0, 1.0, 89.0, 10.0, 25.0, 2.0, 3.0, 0.0, 164.0, 12.0, 169.0, 16.0, 181.0, 188.0, 9.0, 0.0, 32.0, 0.0, 0.0, 173.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 152.0, 153.0, 0.0, 0.0, 0.0, 0.0, 28.0, 29.0, 26.0, 3.0, 23.0, 39.0, 21.0, 17.0, 0.0, 0.0, 42.0, 118.0, 0.0, 1.0, 0.0, 0.0, 150.0, 36.0, 0.0, 31.0, 13.0, 0.0, 0.0, 0.0, 0.0, 145.0, 0.0, 0.0, 2.0, 16.0, 0.0, 0.0, 0.0, 0.0, 35.0, 25.0, 0.0, 2.0, 0.0, 46.0, 18.0, 176.0, 0.0, 21.0, 26.0, 0.0, 157.0, 0.0, 159.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 10.0, 28.0, 103.0, 0.0, 0.0, 11.0, 0.0, 0.0, 28.0, 25.0, 0.0, 26.0, 0.0, 166.0, 2.0, 26.0, 0.0, 0.0, 36.0, 0.0, 120.0, 0.0, 0.0, 8.0, 24.0, 11.0, 1.0, 0.0, 0.0, 0.0, 54.0, 27.0, 0.0, 24.0, 0.0, 0.0, 12.0, 35.0, 36.0, 181.0, 18.0, 0.0, 27.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 83.0, 11.0, 44.0, 27.0, 0.0, 28.0, 11.0, 0.0, 0.0, 16.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.430511164677079, "mean_inference_ms": 10.67991311009243, "mean_action_processing_ms": 0.6708417235305612, "mean_env_wait_ms": 1.434646932213724, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007506132125854492, "StateBufferConnector_ms": 0.00944983959197998, "ViewRequirementAgentConnector_ms": 0.3758273124694824}, "num_episodes": 18, "episode_return_max": 148.69999999999862, "episode_return_min": -474.5, "episode_return_mean": -37.48599999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 150.85327844048294, "num_env_steps_trained_throughput_per_sec": 150.85327844048294, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 27091.12, "restore_workers_time_ms": 0.018, "training_step_time_ms": 27091.046, "sample_time_ms": 4544.234, "learn_time_ms": 22516.238, "learn_throughput": 177.65, "synch_weights_time_ms": 25.642}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "3a355_00000", "date": "2024-08-13_02-51-20", "timestamp": 1723531880, "time_this_iter_s": 26.563514947891235, "time_total_s": 6084.692952871323, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52ab0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6084.692952871323, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 87.6263157894737, "ram_util_percent": 83.51842105263158}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45873196273845024, "cur_kl_coeff": 6.938893903907229e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8608159329525378, "policy_loss": -0.0010510935036652776, "vf_loss": 1.8618670187299213, "vf_explained_var": 0.0018643801805203553, "kl": 0.0031393908414227133, "entropy": 0.22212499526758042, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8869447069075057, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.179518796211828, "policy_loss": -0.0018956131363415687, "vf_loss": 3.180964347862062, "vf_explained_var": 0.0105544680640811, "kl": 0.01183996897285857, "entropy": 1.013307098263786, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 148.69999999999862, "episode_reward_min": -506.3, "episode_reward_mean": -28.757999999999967, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 79.09999999999934, "predator_policy": 188.0}, "policy_reward_mean": {"prey_policy": -38.82400000000001, "predator_policy": 24.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [61.90000000000049, -453.59999999999997, -449.09999999999997, -360.5, 30.100000000000147, -45.60000000000059, -394.49999999999994, 40.0000000000003, 40.0000000000003, 40.0000000000003, 55.300000000000516, 58.90000000000052, 85.89999999999884, -251.40000000000003, 40.0000000000003, 40.0000000000003, 44.50000000000043, 32.40000000000019, -27.29999999999952, 51.600000000000435, 56.2000000000005, -319.0, 41.600000000000314, 40.0000000000003, -458.5999999999999, 41.90000000000036, 45.20000000000048, 40.0000000000003, -331.89999999999986, 40.0000000000003, 28.30000000000012, 50.80000000000048, 40.90000000000031, -25.099999999999582, 37.80000000000027, 58.70000000000038, -459.6, 10.60000000000008, -15.89999999999949, -330.1000000000003, -134.90000000000038, 40.0000000000003, 1.5000000000002431, 29.000000000000128, -57.29999999999978, 63.40000000000051, 58.50000000000045, 47.00000000000044, -7.299999999999706, 37.5000000000003, -474.5, 11.400000000000048, 0.400000000000193, -59.59999999999996, 40.0000000000003, 34.20000000000021, 90.69999999999854, 40.0000000000003, -86.60000000000173, 42.700000000000394, 37.000000000000256, 94.59999999999832, -8.699999999999871, -273.4, 10.299999999999988, 40.0000000000003, -2.599999999999794, 88.59999999999866, 37.999999999999545, -38.09999999999958, 31.700000000000202, 86.39999999999883, 22.400000000000013, 91.3999999999987, 148.69999999999862, 40.0000000000003, 40.0000000000003, 40.0000000000003, -6.299999999999738, 82.69999999999906, -506.3, 40.0000000000003, 40.0000000000003, 40.0000000000003, 16.999999999999975, 138.09999999999835, -381.8, 31.2000000000002, 59.300000000000345, 40.0000000000003, 16.199999999999918, 20.699999999999992, 39.10000000000035, 71.4999999999999, 50.80000000000048, 42.80000000000036, 50.80000000000048, 76.49999999999959, 82.59999999999907, -353.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 38.90000000000023, -324.4, -305.2, -299.2, -334.9, -354.7, -374.8, 20.000000000000014, 1.0999999999999865, -40.89999999999976, -36.69999999999976, -246.69999999999996, -320.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000026, 38.900000000000254, 20.000000000000014, 28.100000000000147, 57.80000000000018, -255.10000000000002, -301.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.999999999999787, 12.499999999999977, -34.59999999999975, 38.00000000000024, -93.4000000000008, 4.099999999999966, 30.8000000000002, -17.199999999999783, 36.20000000000025, 20.000000000000014, -284.5000000000003, -194.49999999999994, 20.000000000000014, 20.600000000000016, 20.000000000000014, 20.000000000000014, -303.4, -341.19999999999993, 50.600000000000236, -39.69999999999978, -7.299999999999947, 39.50000000000024, 20.000000000000014, 20.000000000000014, -223.89999999999992, -253.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.699999999999868, 20.000000000000014, 30.800000000000196, 20.900000000000027, 20.000000000000014, 20.000000000000014, -105.10000000000072, 20.000000000000014, 15.799999999999963, 69.4999999999998, -56.800000000000225, -387.4, -266.2, 13.699999999999964, -24.099999999999746, -34.59999999999975, -7.299999999999891, -280.3, -206.80000000000027, -313.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, -9.399999999999855, -0.9999999999999846, 20.000000000000014, 7.399999999999986, -195.70000000000002, 43.40000000000025, 20.000000000000014, 27.50000000000015, 20.000000000000014, 20.000000000000014, -1.0000000000000329, -19.89999999999978, -12.399999999999844, -8.499999999999929, 20.000000000000014, -328.6, -313.9, -34.59999999999975, 20.000000000000014, 20.000000000000014, -55.60000000000031, -78.70000000000087, -100.89999999999986, 20.000000000000014, 20.000000000000014, 32.60000000000023, -30.39999999999975, 10.399999999999995, 68.29999999999988, 20.000000000000014, 20.000000000000014, -70.30000000000089, -70.30000000000084, 20.000000000000014, -4.3000000000000185, 43.40000000000025, -30.39999999999975, 53.90000000000021, 28.70000000000017, 20.000000000000014, -99.70000000000054, -112.29999999999995, -360.1, 20.000000000000014, -36.69999999999979, 20.000000000000014, 20.000000000000014, -64.60000000000083, 20.000000000000014, 68.59999999999984, 20.000000000000014, 50.29999999999961, -106.30000000000008, -129.10000000000073, 20.000000000000014, 20.000000000000014, -16.299999999999798, -3.0999999999999757, 78.49999999999939, -13.599999999999783, 20.000000000000014, 67.39999999999992, 20.000000000000014, 79.09999999999934, 68.59999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -78.70000000000081, 25.400000000000098, 62.60000000000017, 1.0999999999999617, -345.4, -334.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -6.099999999999984, -34.89999999999983, 62.30000000000022, 75.79999999999936, -246.70000000000002, -276.1, 9.499999999999968, -13.29999999999984, 18.500000000000075, 15.799999999999962, 20.000000000000014, 20.000000000000014, -95.50000000000082, 13.699999999999966, 20.000000000000014, -40.29999999999976, 58.70000000000022, -55.60000000000018, 20.000000000000014, 51.5000000000002, 20.000000000000014, 30.800000000000196, -17.199999999999854, 20.000000000000014, 20.000000000000014, 30.800000000000196, 16.69999999999997, 57.800000000000225, 50.60000000000018, 20.000000000000014, -292.90000000000026, -244.60000000000002], "policy_predator_policy_reward": [3.0, 0.0, 164.0, 12.0, 169.0, 16.0, 181.0, 188.0, 9.0, 0.0, 32.0, 0.0, 0.0, 173.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 152.0, 153.0, 0.0, 0.0, 0.0, 0.0, 28.0, 29.0, 26.0, 3.0, 23.0, 39.0, 21.0, 17.0, 0.0, 0.0, 42.0, 118.0, 0.0, 1.0, 0.0, 0.0, 150.0, 36.0, 0.0, 31.0, 13.0, 0.0, 0.0, 0.0, 0.0, 145.0, 0.0, 0.0, 2.0, 16.0, 0.0, 0.0, 0.0, 0.0, 35.0, 25.0, 0.0, 2.0, 0.0, 46.0, 18.0, 176.0, 0.0, 21.0, 26.0, 0.0, 157.0, 0.0, 159.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 10.0, 28.0, 103.0, 0.0, 0.0, 11.0, 0.0, 0.0, 28.0, 25.0, 0.0, 26.0, 0.0, 166.0, 2.0, 26.0, 0.0, 0.0, 36.0, 0.0, 120.0, 0.0, 0.0, 8.0, 24.0, 11.0, 1.0, 0.0, 0.0, 0.0, 54.0, 27.0, 0.0, 24.0, 0.0, 0.0, 12.0, 35.0, 36.0, 181.0, 18.0, 0.0, 27.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 83.0, 11.0, 44.0, 27.0, 0.0, 28.0, 11.0, 0.0, 0.0, 16.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 38.0, 9.0, 6.0, 13.0, 174.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 0.0, 141.0, 0.0, 35.0, 0.0, 11.0, 14.0, 0.0, 0.0, 43.0, 55.0, 12.0, 29.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 38.0, 0.0, 0.0, 0.0, 2.0, 0.0, 12.0, 126.0, 58.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.499759591747459, "mean_inference_ms": 10.52106788930625, "mean_action_processing_ms": 0.6723411670296707, "mean_env_wait_ms": 1.4290516395662751, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007032155990600586, "StateBufferConnector_ms": 0.0066699981689453125, "ViewRequirementAgentConnector_ms": 0.24987566471099854}, "num_episodes": 22, "episode_return_max": 148.69999999999862, "episode_return_min": -506.3, "episode_return_mean": -28.757999999999967, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 155.40624570373538, "num_env_steps_trained_throughput_per_sec": 155.40624570373538, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 27323.051, "restore_workers_time_ms": 0.018, "training_step_time_ms": 27322.979, "sample_time_ms": 4574.715, "learn_time_ms": 22718.278, "learn_throughput": 176.07, "synch_weights_time_ms": 25.316}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "3a355_00000", "date": "2024-08-13_02-51-46", "timestamp": 1723531906, "time_this_iter_s": 25.797852993011475, "time_total_s": 6110.490805864334, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dcf310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6110.490805864334, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 86.93611111111112, "ram_util_percent": 83.38333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5355087862423961, "cur_kl_coeff": 3.4694469519536144e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.264404944515733, "policy_loss": -0.0015306832276225564, "vf_loss": 2.265935622005866, "vf_explained_var": 0.008639104782588898, "kl": 0.008432823236685424, "entropy": 0.26007563806084727, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2051221953734519, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8545171222989523, "policy_loss": -0.0013316629649135013, "vf_loss": 3.8555030710482723, "vf_explained_var": 0.007762795497500708, "kl": 0.009095031447164977, "entropy": 1.0549764342408963, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 148.69999999999862, "episode_reward_min": -506.3, "episode_reward_mean": -26.307, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -387.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 79.09999999999934, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": -36.518500000000024, "predator_policy": 23.365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-27.29999999999952, 51.600000000000435, 56.2000000000005, -319.0, 41.600000000000314, 40.0000000000003, -458.5999999999999, 41.90000000000036, 45.20000000000048, 40.0000000000003, -331.89999999999986, 40.0000000000003, 28.30000000000012, 50.80000000000048, 40.90000000000031, -25.099999999999582, 37.80000000000027, 58.70000000000038, -459.6, 10.60000000000008, -15.89999999999949, -330.1000000000003, -134.90000000000038, 40.0000000000003, 1.5000000000002431, 29.000000000000128, -57.29999999999978, 63.40000000000051, 58.50000000000045, 47.00000000000044, -7.299999999999706, 37.5000000000003, -474.5, 11.400000000000048, 0.400000000000193, -59.59999999999996, 40.0000000000003, 34.20000000000021, 90.69999999999854, 40.0000000000003, -86.60000000000173, 42.700000000000394, 37.000000000000256, 94.59999999999832, -8.699999999999871, -273.4, 10.299999999999988, 40.0000000000003, -2.599999999999794, 88.59999999999866, 37.999999999999545, -38.09999999999958, 31.700000000000202, 86.39999999999883, 22.400000000000013, 91.3999999999987, 148.69999999999862, 40.0000000000003, 40.0000000000003, 40.0000000000003, -6.299999999999738, 82.69999999999906, -506.3, 40.0000000000003, 40.0000000000003, 40.0000000000003, 16.999999999999975, 138.09999999999835, -381.8, 31.2000000000002, 59.300000000000345, 40.0000000000003, 16.199999999999918, 20.699999999999992, 39.10000000000035, 71.4999999999999, 50.80000000000048, 42.80000000000036, 50.80000000000048, 76.49999999999959, 82.59999999999907, -353.5, 26.700000000000117, 60.700000000000436, 44.50000000000036, -183.79999999999987, 40.0000000000003, -425.5999999999998, 44.7000000000004, 40.0000000000003, -266.8000000000003, 80.49999999999923, -163.49999999999994, 93.29999999999876, -352.7000000000004, 1.2000000000001647, 34.5000000000002, 83.89999999999903, 5.900000000000075, -304.10000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-93.4000000000008, 4.099999999999966, 30.8000000000002, -17.199999999999783, 36.20000000000025, 20.000000000000014, -284.5000000000003, -194.49999999999994, 20.000000000000014, 20.600000000000016, 20.000000000000014, 20.000000000000014, -303.4, -341.19999999999993, 50.600000000000236, -39.69999999999978, -7.299999999999947, 39.50000000000024, 20.000000000000014, 20.000000000000014, -223.89999999999992, -253.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.699999999999868, 20.000000000000014, 30.800000000000196, 20.900000000000027, 20.000000000000014, 20.000000000000014, -105.10000000000072, 20.000000000000014, 15.799999999999963, 69.4999999999998, -56.800000000000225, -387.4, -266.2, 13.699999999999964, -24.099999999999746, -34.59999999999975, -7.299999999999891, -280.3, -206.80000000000027, -313.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.099999999999958, -9.399999999999855, -0.9999999999999846, 20.000000000000014, 7.399999999999986, -195.70000000000002, 43.40000000000025, 20.000000000000014, 27.50000000000015, 20.000000000000014, 20.000000000000014, -1.0000000000000329, -19.89999999999978, -12.399999999999844, -8.499999999999929, 20.000000000000014, -328.6, -313.9, -34.59999999999975, 20.000000000000014, 20.000000000000014, -55.60000000000031, -78.70000000000087, -100.89999999999986, 20.000000000000014, 20.000000000000014, 32.60000000000023, -30.39999999999975, 10.399999999999995, 68.29999999999988, 20.000000000000014, 20.000000000000014, -70.30000000000089, -70.30000000000084, 20.000000000000014, -4.3000000000000185, 43.40000000000025, -30.39999999999975, 53.90000000000021, 28.70000000000017, 20.000000000000014, -99.70000000000054, -112.29999999999995, -360.1, 20.000000000000014, -36.69999999999979, 20.000000000000014, 20.000000000000014, -64.60000000000083, 20.000000000000014, 68.59999999999984, 20.000000000000014, 50.29999999999961, -106.30000000000008, -129.10000000000073, 20.000000000000014, 20.000000000000014, -16.299999999999798, -3.0999999999999757, 78.49999999999939, -13.599999999999783, 20.000000000000014, 67.39999999999992, 20.000000000000014, 79.09999999999934, 68.59999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -78.70000000000081, 25.400000000000098, 62.60000000000017, 1.0999999999999617, -345.4, -334.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -6.099999999999984, -34.89999999999983, 62.30000000000022, 75.79999999999936, -246.70000000000002, -276.1, 9.499999999999968, -13.29999999999984, 18.500000000000075, 15.799999999999962, 20.000000000000014, 20.000000000000014, -95.50000000000082, 13.699999999999966, 20.000000000000014, -40.29999999999976, 58.70000000000022, -55.60000000000018, 20.000000000000014, 51.5000000000002, 20.000000000000014, 30.800000000000196, -17.199999999999854, 20.000000000000014, 20.000000000000014, 30.800000000000196, 16.69999999999997, 57.800000000000225, 50.60000000000018, 20.000000000000014, -292.90000000000026, -244.60000000000002, 20.000000000000014, -19.299999999999784, 40.700000000000216, 20.000000000000014, 24.50000000000008, 20.000000000000014, -84.99999999999991, -206.8, 20.000000000000014, 20.000000000000014, -271.6, -336.99999999999983, 71.29999999999968, -70.60000000000073, 20.000000000000014, 20.000000000000014, -223.29999999999998, -179.49999999999991, 55.100000000000186, 25.400000000000098, -324.4000000000002, -3.1000000000003496, 20.000000000000014, 65.30000000000005, -292.3000000000001, -240.40000000000032, -59.800000000000566, 20.000000000000014, 20.000000000000014, 9.499999999999977, 33.800000000000225, 40.100000000000215, 20.000000000000014, -45.099999999999795, -298.00000000000017, -192.10000000000002], "policy_predator_policy_reward": [23.0, 39.0, 21.0, 17.0, 0.0, 0.0, 42.0, 118.0, 0.0, 1.0, 0.0, 0.0, 150.0, 36.0, 0.0, 31.0, 13.0, 0.0, 0.0, 0.0, 0.0, 145.0, 0.0, 0.0, 2.0, 16.0, 0.0, 0.0, 0.0, 0.0, 35.0, 25.0, 0.0, 2.0, 0.0, 46.0, 18.0, 176.0, 0.0, 21.0, 26.0, 0.0, 157.0, 0.0, 159.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 10.0, 28.0, 103.0, 0.0, 0.0, 11.0, 0.0, 0.0, 28.0, 25.0, 0.0, 26.0, 0.0, 166.0, 2.0, 26.0, 0.0, 0.0, 36.0, 0.0, 120.0, 0.0, 0.0, 8.0, 24.0, 11.0, 1.0, 0.0, 0.0, 0.0, 54.0, 27.0, 0.0, 24.0, 0.0, 0.0, 12.0, 35.0, 36.0, 181.0, 18.0, 0.0, 27.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 83.0, 11.0, 44.0, 27.0, 0.0, 28.0, 11.0, 0.0, 0.0, 16.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 38.0, 9.0, 6.0, 13.0, 174.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 0.0, 141.0, 0.0, 35.0, 0.0, 11.0, 14.0, 0.0, 0.0, 43.0, 55.0, 12.0, 29.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 38.0, 0.0, 0.0, 0.0, 2.0, 0.0, 12.0, 126.0, 58.0, 0.0, 26.0, 0.0, 0.0, 0.0, 0.0, 6.0, 102.0, 0.0, 0.0, 6.0, 177.0, 13.0, 31.0, 0.0, 0.0, 0.0, 136.0, 0.0, 0.0, 128.0, 36.0, 8.0, 0.0, 0.0, 180.0, 0.0, 41.0, 0.0, 5.0, 10.0, 0.0, 24.0, 7.0, 14.0, 172.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.412622758359293, "mean_inference_ms": 10.550862966919535, "mean_action_processing_ms": 0.6718682450414775, "mean_env_wait_ms": 1.4170697184591807, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007161140441894531, "StateBufferConnector_ms": 0.006804823875427246, "ViewRequirementAgentConnector_ms": 0.27619683742523193}, "num_episodes": 18, "episode_return_max": 148.69999999999862, "episode_return_min": -506.3, "episode_return_mean": -26.307, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 148.47269738886553, "num_env_steps_trained_throughput_per_sec": 148.47269738886553, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 27185.56, "restore_workers_time_ms": 0.018, "training_step_time_ms": 27185.49, "sample_time_ms": 4581.695, "learn_time_ms": 22573.814, "learn_throughput": 177.196, "synch_weights_time_ms": 25.49}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "3a355_00000", "date": "2024-08-13_02-52-13", "timestamp": 1723531933, "time_this_iter_s": 27.012838125228882, "time_total_s": 6137.503643989563, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b551a1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6137.503643989563, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 86.3763157894737, "ram_util_percent": 83.43421052631577}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5736370084422922, "cur_kl_coeff": 3.4694469519536144e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.140538751038294, "policy_loss": -0.0010492252609717151, "vf_loss": 1.1415879759838972, "vf_explained_var": 0.010826215636793268, "kl": 0.0033866909541130845, "entropy": 0.33005413569155195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0383070735093305, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5623148485466285, "policy_loss": -0.0021196571008730977, "vf_loss": 1.563717256746595, "vf_explained_var": -0.007580939518711555, "kl": 0.0188692044037678, "entropy": 0.9949309742009198, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 148.69999999999862, "episode_reward_min": -506.3, "episode_reward_mean": -11.690000000000028, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -360.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 79.09999999999934, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": -27.64000000000002, "predator_policy": 21.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 1.5000000000002431, 29.000000000000128, -57.29999999999978, 63.40000000000051, 58.50000000000045, 47.00000000000044, -7.299999999999706, 37.5000000000003, -474.5, 11.400000000000048, 0.400000000000193, -59.59999999999996, 40.0000000000003, 34.20000000000021, 90.69999999999854, 40.0000000000003, -86.60000000000173, 42.700000000000394, 37.000000000000256, 94.59999999999832, -8.699999999999871, -273.4, 10.299999999999988, 40.0000000000003, -2.599999999999794, 88.59999999999866, 37.999999999999545, -38.09999999999958, 31.700000000000202, 86.39999999999883, 22.400000000000013, 91.3999999999987, 148.69999999999862, 40.0000000000003, 40.0000000000003, 40.0000000000003, -6.299999999999738, 82.69999999999906, -506.3, 40.0000000000003, 40.0000000000003, 40.0000000000003, 16.999999999999975, 138.09999999999835, -381.8, 31.2000000000002, 59.300000000000345, 40.0000000000003, 16.199999999999918, 20.699999999999992, 39.10000000000035, 71.4999999999999, 50.80000000000048, 42.80000000000036, 50.80000000000048, 76.49999999999959, 82.59999999999907, -353.5, 26.700000000000117, 60.700000000000436, 44.50000000000036, -183.79999999999987, 40.0000000000003, -425.5999999999998, 44.7000000000004, 40.0000000000003, -266.8000000000003, 80.49999999999923, -163.49999999999994, 93.29999999999876, -352.7000000000004, 1.2000000000001647, 34.5000000000002, 83.89999999999903, 5.900000000000075, -304.10000000000014, -2.299999999999822, 49.90000000000046, 34.70000000000022, -189.60000000000014, 128.0999999999986, 20.799999999999994, 26.000000000000153, 22.00000000000003, -382.79999999999995, -157.50000000000085, 40.0000000000003, -66.29999999999998, 57.10000000000052, 34.200000000000216, 61.60000000000045, 28.500000000000206, -8.299999999999688, 49.90000000000046, 29.000000000000135, 49.00000000000045, 40.0000000000003, 38.900000000000276, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -3.099999999999958, -9.399999999999855, -0.9999999999999846, 20.000000000000014, 7.399999999999986, -195.70000000000002, 43.40000000000025, 20.000000000000014, 27.50000000000015, 20.000000000000014, 20.000000000000014, -1.0000000000000329, -19.89999999999978, -12.399999999999844, -8.499999999999929, 20.000000000000014, -328.6, -313.9, -34.59999999999975, 20.000000000000014, 20.000000000000014, -55.60000000000031, -78.70000000000087, -100.89999999999986, 20.000000000000014, 20.000000000000014, 32.60000000000023, -30.39999999999975, 10.399999999999995, 68.29999999999988, 20.000000000000014, 20.000000000000014, -70.30000000000089, -70.30000000000084, 20.000000000000014, -4.3000000000000185, 43.40000000000025, -30.39999999999975, 53.90000000000021, 28.70000000000017, 20.000000000000014, -99.70000000000054, -112.29999999999995, -360.1, 20.000000000000014, -36.69999999999979, 20.000000000000014, 20.000000000000014, -64.60000000000083, 20.000000000000014, 68.59999999999984, 20.000000000000014, 50.29999999999961, -106.30000000000008, -129.10000000000073, 20.000000000000014, 20.000000000000014, -16.299999999999798, -3.0999999999999757, 78.49999999999939, -13.599999999999783, 20.000000000000014, 67.39999999999992, 20.000000000000014, 79.09999999999934, 68.59999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -78.70000000000081, 25.400000000000098, 62.60000000000017, 1.0999999999999617, -345.4, -334.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -6.099999999999984, -34.89999999999983, 62.30000000000022, 75.79999999999936, -246.70000000000002, -276.1, 9.499999999999968, -13.29999999999984, 18.500000000000075, 15.799999999999962, 20.000000000000014, 20.000000000000014, -95.50000000000082, 13.699999999999966, 20.000000000000014, -40.29999999999976, 58.70000000000022, -55.60000000000018, 20.000000000000014, 51.5000000000002, 20.000000000000014, 30.800000000000196, -17.199999999999854, 20.000000000000014, 20.000000000000014, 30.800000000000196, 16.69999999999997, 57.800000000000225, 50.60000000000018, 20.000000000000014, -292.90000000000026, -244.60000000000002, 20.000000000000014, -19.299999999999784, 40.700000000000216, 20.000000000000014, 24.50000000000008, 20.000000000000014, -84.99999999999991, -206.8, 20.000000000000014, 20.000000000000014, -271.6, -336.99999999999983, 71.29999999999968, -70.60000000000073, 20.000000000000014, 20.000000000000014, -223.29999999999998, -179.49999999999991, 55.100000000000186, 25.400000000000098, -324.4000000000002, -3.1000000000003496, 20.000000000000014, 65.30000000000005, -292.3000000000001, -240.40000000000032, -59.800000000000566, 20.000000000000014, 20.000000000000014, 9.499999999999977, 33.800000000000225, 40.100000000000215, 20.000000000000014, -45.099999999999795, -298.00000000000017, -192.10000000000002, -51.39999999999988, 1.0999999999999617, 20.000000000000014, 29.90000000000018, -36.699999999999825, -34.59999999999977, -261.4000000000001, -68.20000000000005, 59.000000000000185, 64.10000000000015, 20.000000000000014, -23.19999999999976, 28.10000000000015, -48.099999999999824, 20.000000000000014, -33.9999999999998, -347.5, -262.29999999999995, -89.20000000000084, -253.30000000000013, 20.000000000000014, 20.000000000000014, -108.10000000000004, -23.199999999999875, 37.10000000000026, 20.000000000000014, 3.199999999999965, 20.000000000000014, 41.600000000000215, 20.000000000000014, 44.90000000000024, -51.399999999999814, -85.30000000000084, 20.000000000000014, 29.90000000000018, 20.000000000000014, -19.899999999999743, 29.90000000000018, 29.000000000000163, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 14.0, 0.0, 0.0, 10.0, 28.0, 103.0, 0.0, 0.0, 11.0, 0.0, 0.0, 28.0, 25.0, 0.0, 26.0, 0.0, 166.0, 2.0, 26.0, 0.0, 0.0, 36.0, 0.0, 120.0, 0.0, 0.0, 8.0, 24.0, 11.0, 1.0, 0.0, 0.0, 0.0, 54.0, 27.0, 0.0, 24.0, 0.0, 0.0, 12.0, 35.0, 36.0, 181.0, 18.0, 0.0, 27.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 83.0, 11.0, 44.0, 27.0, 0.0, 28.0, 11.0, 0.0, 0.0, 16.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 38.0, 9.0, 6.0, 13.0, 174.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 0.0, 141.0, 0.0, 35.0, 0.0, 11.0, 14.0, 0.0, 0.0, 43.0, 55.0, 12.0, 29.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 38.0, 0.0, 0.0, 0.0, 2.0, 0.0, 12.0, 126.0, 58.0, 0.0, 26.0, 0.0, 0.0, 0.0, 0.0, 6.0, 102.0, 0.0, 0.0, 6.0, 177.0, 13.0, 31.0, 0.0, 0.0, 0.0, 136.0, 0.0, 0.0, 128.0, 36.0, 8.0, 0.0, 0.0, 180.0, 0.0, 41.0, 0.0, 5.0, 10.0, 0.0, 24.0, 7.0, 14.0, 172.0, 30.0, 18.0, 0.0, 0.0, 53.0, 53.0, 3.0, 137.0, 5.0, 0.0, 24.0, 0.0, 20.0, 26.0, 0.0, 36.0, 175.0, 52.0, 177.0, 8.0, 0.0, 0.0, 53.0, 12.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 35.0, 0.0, 15.0, 42.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.406465683565476, "mean_inference_ms": 10.400847543618578, "mean_action_processing_ms": 0.6728824671743502, "mean_env_wait_ms": 1.4792245054948732, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010146617889404297, "StateBufferConnector_ms": 0.00717473030090332, "ViewRequirementAgentConnector_ms": 0.303669810295105}, "num_episodes": 23, "episode_return_max": 148.69999999999862, "episode_return_min": -506.3, "episode_return_mean": -11.690000000000028, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 147.59331165023104, "num_env_steps_trained_throughput_per_sec": 147.59331165023104, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 27403.199, "restore_workers_time_ms": 0.018, "training_step_time_ms": 27403.129, "sample_time_ms": 4586.429, "learn_time_ms": 22786.986, "learn_throughput": 175.539, "synch_weights_time_ms": 25.092}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "3a355_00000", "date": "2024-08-13_02-52-40", "timestamp": 1723531960, "time_this_iter_s": 27.21379518508911, "time_total_s": 6164.717439174652, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d51160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6164.717439174652, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 86.50769230769231, "ram_util_percent": 83.3897435897436}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6027986320987265, "cur_kl_coeff": 1.7347234759768072e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9113922223212227, "policy_loss": -0.0009795760812247715, "vf_loss": 1.9123717989240374, "vf_explained_var": 0.0035142132529505975, "kl": 0.002226367123467445, "entropy": 0.3172075441590062, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8765723455046851, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.468257303528054, "policy_loss": -0.004036647264067103, "vf_loss": 2.47174059985176, "vf_explained_var": -0.00393316493463264, "kl": 0.014557195150673193, "entropy": 0.9699899767757093, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 148.69999999999862, "episode_reward_min": -506.3, "episode_reward_mean": -7.643000000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -360.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 79.09999999999934, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": -25.361500000000014, "predator_policy": 21.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [42.700000000000394, 37.000000000000256, 94.59999999999832, -8.699999999999871, -273.4, 10.299999999999988, 40.0000000000003, -2.599999999999794, 88.59999999999866, 37.999999999999545, -38.09999999999958, 31.700000000000202, 86.39999999999883, 22.400000000000013, 91.3999999999987, 148.69999999999862, 40.0000000000003, 40.0000000000003, 40.0000000000003, -6.299999999999738, 82.69999999999906, -506.3, 40.0000000000003, 40.0000000000003, 40.0000000000003, 16.999999999999975, 138.09999999999835, -381.8, 31.2000000000002, 59.300000000000345, 40.0000000000003, 16.199999999999918, 20.699999999999992, 39.10000000000035, 71.4999999999999, 50.80000000000048, 42.80000000000036, 50.80000000000048, 76.49999999999959, 82.59999999999907, -353.5, 26.700000000000117, 60.700000000000436, 44.50000000000036, -183.79999999999987, 40.0000000000003, -425.5999999999998, 44.7000000000004, 40.0000000000003, -266.8000000000003, 80.49999999999923, -163.49999999999994, 93.29999999999876, -352.7000000000004, 1.2000000000001647, 34.5000000000002, 83.89999999999903, 5.900000000000075, -304.10000000000014, -2.299999999999822, 49.90000000000046, 34.70000000000022, -189.60000000000014, 128.0999999999986, 20.799999999999994, 26.000000000000153, 22.00000000000003, -382.79999999999995, -157.50000000000085, 40.0000000000003, -66.29999999999998, 57.10000000000052, 34.200000000000216, 61.60000000000045, 28.500000000000206, -8.299999999999688, 49.90000000000046, 29.000000000000135, 49.00000000000045, 40.0000000000003, 38.900000000000276, 40.0000000000003, 41.80000000000033, 28.100000000000126, 36.70000000000025, 49.90000000000046, 40.0000000000003, -43.39999999999996, 40.0000000000003, 38.800000000000296, 38.90000000000028, -7.699999999999719, -171.0, -50.79999999999998, 54.90000000000035, 28.800000000000125, 16.199999999999964, 25.70000000000012, 6.099999999999961, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -4.3000000000000185, 43.40000000000025, -30.39999999999975, 53.90000000000021, 28.70000000000017, 20.000000000000014, -99.70000000000054, -112.29999999999995, -360.1, 20.000000000000014, -36.69999999999979, 20.000000000000014, 20.000000000000014, -64.60000000000083, 20.000000000000014, 68.59999999999984, 20.000000000000014, 50.29999999999961, -106.30000000000008, -129.10000000000073, 20.000000000000014, 20.000000000000014, -16.299999999999798, -3.0999999999999757, 78.49999999999939, -13.599999999999783, 20.000000000000014, 67.39999999999992, 20.000000000000014, 79.09999999999934, 68.59999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -78.70000000000081, 25.400000000000098, 62.60000000000017, 1.0999999999999617, -345.4, -334.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -6.099999999999984, -34.89999999999983, 62.30000000000022, 75.79999999999936, -246.70000000000002, -276.1, 9.499999999999968, -13.29999999999984, 18.500000000000075, 15.799999999999962, 20.000000000000014, 20.000000000000014, -95.50000000000082, 13.699999999999966, 20.000000000000014, -40.29999999999976, 58.70000000000022, -55.60000000000018, 20.000000000000014, 51.5000000000002, 20.000000000000014, 30.800000000000196, -17.199999999999854, 20.000000000000014, 20.000000000000014, 30.800000000000196, 16.69999999999997, 57.800000000000225, 50.60000000000018, 20.000000000000014, -292.90000000000026, -244.60000000000002, 20.000000000000014, -19.299999999999784, 40.700000000000216, 20.000000000000014, 24.50000000000008, 20.000000000000014, -84.99999999999991, -206.8, 20.000000000000014, 20.000000000000014, -271.6, -336.99999999999983, 71.29999999999968, -70.60000000000073, 20.000000000000014, 20.000000000000014, -223.29999999999998, -179.49999999999991, 55.100000000000186, 25.400000000000098, -324.4000000000002, -3.1000000000003496, 20.000000000000014, 65.30000000000005, -292.3000000000001, -240.40000000000032, -59.800000000000566, 20.000000000000014, 20.000000000000014, 9.499999999999977, 33.800000000000225, 40.100000000000215, 20.000000000000014, -45.099999999999795, -298.00000000000017, -192.10000000000002, -51.39999999999988, 1.0999999999999617, 20.000000000000014, 29.90000000000018, -36.699999999999825, -34.59999999999977, -261.4000000000001, -68.20000000000005, 59.000000000000185, 64.10000000000015, 20.000000000000014, -23.19999999999976, 28.10000000000015, -48.099999999999824, 20.000000000000014, -33.9999999999998, -347.5, -262.29999999999995, -89.20000000000084, -253.30000000000013, 20.000000000000014, 20.000000000000014, -108.10000000000004, -23.199999999999875, 37.10000000000026, 20.000000000000014, 3.199999999999965, 20.000000000000014, 41.600000000000215, 20.000000000000014, 44.90000000000024, -51.399999999999814, -85.30000000000084, 20.000000000000014, 29.90000000000018, 20.000000000000014, -19.899999999999743, 29.90000000000018, 29.000000000000163, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.80000000000004, -109.90000000000063, 20.000000000000014, 13.699999999999969, 20.000000000000014, 29.90000000000018, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.59999999999975, -80.80000000000072, 20.000000000000014, 20.000000000000014, -8.7999999999999, 32.60000000000023, 20.000000000000014, 17.899999999999988, 12.199999999999978, -82.90000000000082, -154.29999999999984, -99.70000000000003, -10.599999999999879, -131.2000000000005, -30.39999999999975, 47.300000000000146, 31.700000000000188, -31.89999999999977, -28.29999999999975, 21.500000000000036, 20.000000000000014, -25.29999999999979, -88.90000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [27.0, 0.0, 24.0, 0.0, 0.0, 12.0, 35.0, 36.0, 181.0, 18.0, 0.0, 27.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 83.0, 11.0, 44.0, 27.0, 0.0, 28.0, 11.0, 0.0, 0.0, 16.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 38.0, 9.0, 6.0, 13.0, 174.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 0.0, 141.0, 0.0, 35.0, 0.0, 11.0, 14.0, 0.0, 0.0, 43.0, 55.0, 12.0, 29.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 38.0, 0.0, 0.0, 0.0, 2.0, 0.0, 12.0, 126.0, 58.0, 0.0, 26.0, 0.0, 0.0, 0.0, 0.0, 6.0, 102.0, 0.0, 0.0, 6.0, 177.0, 13.0, 31.0, 0.0, 0.0, 0.0, 136.0, 0.0, 0.0, 128.0, 36.0, 8.0, 0.0, 0.0, 180.0, 0.0, 41.0, 0.0, 5.0, 10.0, 0.0, 24.0, 7.0, 14.0, 172.0, 30.0, 18.0, 0.0, 0.0, 53.0, 53.0, 3.0, 137.0, 5.0, 0.0, 24.0, 0.0, 20.0, 26.0, 0.0, 36.0, 175.0, 52.0, 177.0, 8.0, 0.0, 0.0, 53.0, 12.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 35.0, 0.0, 15.0, 42.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 52.0, 66.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 72.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 1.0, 14.0, 49.0, 61.0, 22.0, 91.0, 0.0, 38.0, 0.0, 29.0, 0.0, 23.0, 0.0, 0.0, 31.0, 35.0, 40.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.399224709314684, "mean_inference_ms": 10.424936203726086, "mean_action_processing_ms": 0.673086427026511, "mean_env_wait_ms": 1.3966289935722676, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012595176696777344, "StateBufferConnector_ms": 0.007206439971923828, "ViewRequirementAgentConnector_ms": 0.3208177089691162}, "num_episodes": 18, "episode_return_max": 148.69999999999862, "episode_return_min": -506.3, "episode_return_mean": -7.643000000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 133.66196369355362, "num_env_steps_trained_throughput_per_sec": 133.66196369355362, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 27558.598, "restore_workers_time_ms": 0.018, "training_step_time_ms": 27558.53, "sample_time_ms": 4528.033, "learn_time_ms": 23002.702, "learn_throughput": 173.893, "synch_weights_time_ms": 23.621}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "3a355_00000", "date": "2024-08-13_02-53-10", "timestamp": 1723531990, "time_this_iter_s": 30.00726819038391, "time_total_s": 6194.724707365036, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3df6c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6194.724707365036, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 89.15714285714286, "ram_util_percent": 83.54285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45302595075554947, "cur_kl_coeff": 8.673617379884036e-20, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5219070630729514, "policy_loss": -0.0017846164501779688, "vf_loss": 2.523691682083897, "vf_explained_var": 0.0032327159687324807, "kl": 0.003650002005370721, "entropy": 0.2654938921884254, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7766399732736683, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5914861867036767, "policy_loss": -0.0010015890058918447, "vf_loss": 3.5922051220343856, "vf_explained_var": -0.0001254179174937899, "kl": 0.0074356809779712275, "entropy": 1.009726302081315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 138.09999999999835, "episode_reward_min": -506.3, "episode_reward_mean": -18.05499999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 75.79999999999936, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -32.7925, "predator_policy": 23.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, -6.299999999999738, 82.69999999999906, -506.3, 40.0000000000003, 40.0000000000003, 40.0000000000003, 16.999999999999975, 138.09999999999835, -381.8, 31.2000000000002, 59.300000000000345, 40.0000000000003, 16.199999999999918, 20.699999999999992, 39.10000000000035, 71.4999999999999, 50.80000000000048, 42.80000000000036, 50.80000000000048, 76.49999999999959, 82.59999999999907, -353.5, 26.700000000000117, 60.700000000000436, 44.50000000000036, -183.79999999999987, 40.0000000000003, -425.5999999999998, 44.7000000000004, 40.0000000000003, -266.8000000000003, 80.49999999999923, -163.49999999999994, 93.29999999999876, -352.7000000000004, 1.2000000000001647, 34.5000000000002, 83.89999999999903, 5.900000000000075, -304.10000000000014, -2.299999999999822, 49.90000000000046, 34.70000000000022, -189.60000000000014, 128.0999999999986, 20.799999999999994, 26.000000000000153, 22.00000000000003, -382.79999999999995, -157.50000000000085, 40.0000000000003, -66.29999999999998, 57.10000000000052, 34.200000000000216, 61.60000000000045, 28.500000000000206, -8.299999999999688, 49.90000000000046, 29.000000000000135, 49.00000000000045, 40.0000000000003, 38.900000000000276, 40.0000000000003, 41.80000000000033, 28.100000000000126, 36.70000000000025, 49.90000000000046, 40.0000000000003, -43.39999999999996, 40.0000000000003, 38.800000000000296, 38.90000000000028, -7.699999999999719, -171.0, -50.79999999999998, 54.90000000000035, 28.800000000000125, 16.199999999999964, 25.70000000000012, 6.099999999999961, 40.0000000000003, 5.900000000000118, 71.49999999999996, 50.80000000000048, 66.10000000000035, -363.60000000000014, 4.200000000000095, -142.09999999999985, 31.20000000000017, -180.00000000000068, 7.799999999999997, 0.9000000000004107, -193.00000000000054, 48.10000000000043, 40.0000000000003, 37.80000000000027, -142.09999999999988, 42.40000000000042, 61.90000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -78.70000000000081, 25.400000000000098, 62.60000000000017, 1.0999999999999617, -345.4, -334.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -6.099999999999984, -34.89999999999983, 62.30000000000022, 75.79999999999936, -246.70000000000002, -276.1, 9.499999999999968, -13.29999999999984, 18.500000000000075, 15.799999999999962, 20.000000000000014, 20.000000000000014, -95.50000000000082, 13.699999999999966, 20.000000000000014, -40.29999999999976, 58.70000000000022, -55.60000000000018, 20.000000000000014, 51.5000000000002, 20.000000000000014, 30.800000000000196, -17.199999999999854, 20.000000000000014, 20.000000000000014, 30.800000000000196, 16.69999999999997, 57.800000000000225, 50.60000000000018, 20.000000000000014, -292.90000000000026, -244.60000000000002, 20.000000000000014, -19.299999999999784, 40.700000000000216, 20.000000000000014, 24.50000000000008, 20.000000000000014, -84.99999999999991, -206.8, 20.000000000000014, 20.000000000000014, -271.6, -336.99999999999983, 71.29999999999968, -70.60000000000073, 20.000000000000014, 20.000000000000014, -223.29999999999998, -179.49999999999991, 55.100000000000186, 25.400000000000098, -324.4000000000002, -3.1000000000003496, 20.000000000000014, 65.30000000000005, -292.3000000000001, -240.40000000000032, -59.800000000000566, 20.000000000000014, 20.000000000000014, 9.499999999999977, 33.800000000000225, 40.100000000000215, 20.000000000000014, -45.099999999999795, -298.00000000000017, -192.10000000000002, -51.39999999999988, 1.0999999999999617, 20.000000000000014, 29.90000000000018, -36.699999999999825, -34.59999999999977, -261.4000000000001, -68.20000000000005, 59.000000000000185, 64.10000000000015, 20.000000000000014, -23.19999999999976, 28.10000000000015, -48.099999999999824, 20.000000000000014, -33.9999999999998, -347.5, -262.29999999999995, -89.20000000000084, -253.30000000000013, 20.000000000000014, 20.000000000000014, -108.10000000000004, -23.199999999999875, 37.10000000000026, 20.000000000000014, 3.199999999999965, 20.000000000000014, 41.600000000000215, 20.000000000000014, 44.90000000000024, -51.399999999999814, -85.30000000000084, 20.000000000000014, 29.90000000000018, 20.000000000000014, -19.899999999999743, 29.90000000000018, 29.000000000000163, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.80000000000004, -109.90000000000063, 20.000000000000014, 13.699999999999969, 20.000000000000014, 29.90000000000018, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.59999999999975, -80.80000000000072, 20.000000000000014, 20.000000000000014, -8.7999999999999, 32.60000000000023, 20.000000000000014, 17.899999999999988, 12.199999999999978, -82.90000000000082, -154.29999999999984, -99.70000000000003, -10.599999999999879, -131.2000000000005, -30.39999999999975, 47.300000000000146, 31.700000000000188, -31.89999999999977, -28.29999999999975, 21.500000000000036, 20.000000000000014, -25.29999999999979, -88.90000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -45.09999999999977, 51.500000000000234, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 46.10000000000024, -163.60000000000002, -400.0, -14.499999999999822, -28.29999999999975, -144.69999999999993, -219.4, 20.000000000000014, 3.1999999999999633, -400.0, 20.000000000000014, -68.20000000000077, 20.000000000000014, -7.300000000000004, -23.79999999999982, -239.20000000000013, -92.80000000000042, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -190.30000000000018, -59.80000000000003, 20.000000000000014, -1.6000000000000387, 20.000000000000014, 38.90000000000023], "policy_predator_policy_reward": [0.0, 0.0, 38.0, 9.0, 6.0, 13.0, 174.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 0.0, 141.0, 0.0, 35.0, 0.0, 11.0, 14.0, 0.0, 0.0, 43.0, 55.0, 12.0, 29.0, 36.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 38.0, 0.0, 0.0, 0.0, 2.0, 0.0, 12.0, 126.0, 58.0, 0.0, 26.0, 0.0, 0.0, 0.0, 0.0, 6.0, 102.0, 0.0, 0.0, 6.0, 177.0, 13.0, 31.0, 0.0, 0.0, 0.0, 136.0, 0.0, 0.0, 128.0, 36.0, 8.0, 0.0, 0.0, 180.0, 0.0, 41.0, 0.0, 5.0, 10.0, 0.0, 24.0, 7.0, 14.0, 172.0, 30.0, 18.0, 0.0, 0.0, 53.0, 53.0, 3.0, 137.0, 5.0, 0.0, 24.0, 0.0, 20.0, 26.0, 0.0, 36.0, 175.0, 52.0, 177.0, 8.0, 0.0, 0.0, 53.0, 12.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 35.0, 0.0, 15.0, 42.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 52.0, 66.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 72.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 1.0, 14.0, 49.0, 61.0, 22.0, 91.0, 0.0, 38.0, 0.0, 29.0, 0.0, 23.0, 0.0, 0.0, 31.0, 35.0, 40.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 200.0, 0.0, 47.0, 108.0, 114.0, 0.0, 8.0, 200.0, 0.0, 25.0, 31.0, 0.0, 32.0, 139.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 35.0, 73.0, 0.0, 24.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.392514139399603, "mean_inference_ms": 10.369928869432403, "mean_action_processing_ms": 0.6735073248838455, "mean_env_wait_ms": 1.3881811186813604, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013747692108154297, "StateBufferConnector_ms": 0.006995201110839844, "ViewRequirementAgentConnector_ms": 0.31067049503326416}, "num_episodes": 18, "episode_return_max": 138.09999999999835, "episode_return_min": -506.3, "episode_return_mean": -18.05499999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 145.82666823990903, "num_env_steps_trained_throughput_per_sec": 145.82666823990903, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 27815.88, "restore_workers_time_ms": 0.018, "training_step_time_ms": 27815.815, "sample_time_ms": 4465.433, "learn_time_ms": 23321.493, "learn_throughput": 171.516, "synch_weights_time_ms": 23.696}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "3a355_00000", "date": "2024-08-13_02-53-38", "timestamp": 1723532018, "time_this_iter_s": 27.48664689064026, "time_total_s": 6222.211354255676, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52ab280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6222.211354255676, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 87.46923076923078, "ram_util_percent": 83.57435897435896}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5414240289932837, "cur_kl_coeff": 4.336808689942018e-20, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6163885353418885, "policy_loss": -0.0016727517698965375, "vf_loss": 1.6180612804082335, "vf_explained_var": 0.0019267658707956788, "kl": 0.002501569869917379, "entropy": 0.356414694823916, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.123461543271939, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9949569399710054, "policy_loss": -0.0005282207638537757, "vf_loss": 1.9952326455444256, "vf_explained_var": -0.008268356480926433, "kl": 0.006642975915865728, "entropy": 1.0391154081733138, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 128.0999999999986, "episode_reward_min": -425.5999999999998, "episode_reward_mean": -20.900999999999918, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 71.29999999999968, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -36.20049999999999, "predator_policy": 25.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-353.5, 26.700000000000117, 60.700000000000436, 44.50000000000036, -183.79999999999987, 40.0000000000003, -425.5999999999998, 44.7000000000004, 40.0000000000003, -266.8000000000003, 80.49999999999923, -163.49999999999994, 93.29999999999876, -352.7000000000004, 1.2000000000001647, 34.5000000000002, 83.89999999999903, 5.900000000000075, -304.10000000000014, -2.299999999999822, 49.90000000000046, 34.70000000000022, -189.60000000000014, 128.0999999999986, 20.799999999999994, 26.000000000000153, 22.00000000000003, -382.79999999999995, -157.50000000000085, 40.0000000000003, -66.29999999999998, 57.10000000000052, 34.200000000000216, 61.60000000000045, 28.500000000000206, -8.299999999999688, 49.90000000000046, 29.000000000000135, 49.00000000000045, 40.0000000000003, 38.900000000000276, 40.0000000000003, 41.80000000000033, 28.100000000000126, 36.70000000000025, 49.90000000000046, 40.0000000000003, -43.39999999999996, 40.0000000000003, 38.800000000000296, 38.90000000000028, -7.699999999999719, -171.0, -50.79999999999998, 54.90000000000035, 28.800000000000125, 16.199999999999964, 25.70000000000012, 6.099999999999961, 40.0000000000003, 5.900000000000118, 71.49999999999996, 50.80000000000048, 66.10000000000035, -363.60000000000014, 4.200000000000095, -142.09999999999985, 31.20000000000017, -180.00000000000068, 7.799999999999997, 0.9000000000004107, -193.00000000000054, 48.10000000000043, 40.0000000000003, 37.80000000000027, -142.09999999999988, 42.40000000000042, 61.90000000000048, 75.9999999999996, -8.39999999999966, 48.10000000000043, -244.9000000000002, 41.900000000000325, -23.999999999999517, 9.999999999999954, -8.399999999999958, 26.600000000000087, -40.90000000000134, 18.99999999999996, 14.699999999999969, 44.600000000000406, -1.5999999999997434, -73.70000000000006, 16.99999999999998, 40.0000000000003, 66.10000000000035, -153.6000000000005, 44.90000000000045, -88.6, -4.499999999999787], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-292.90000000000026, -244.60000000000002, 20.000000000000014, -19.299999999999784, 40.700000000000216, 20.000000000000014, 24.50000000000008, 20.000000000000014, -84.99999999999991, -206.8, 20.000000000000014, 20.000000000000014, -271.6, -336.99999999999983, 71.29999999999968, -70.60000000000073, 20.000000000000014, 20.000000000000014, -223.29999999999998, -179.49999999999991, 55.100000000000186, 25.400000000000098, -324.4000000000002, -3.1000000000003496, 20.000000000000014, 65.30000000000005, -292.3000000000001, -240.40000000000032, -59.800000000000566, 20.000000000000014, 20.000000000000014, 9.499999999999977, 33.800000000000225, 40.100000000000215, 20.000000000000014, -45.099999999999795, -298.00000000000017, -192.10000000000002, -51.39999999999988, 1.0999999999999617, 20.000000000000014, 29.90000000000018, -36.699999999999825, -34.59999999999977, -261.4000000000001, -68.20000000000005, 59.000000000000185, 64.10000000000015, 20.000000000000014, -23.19999999999976, 28.10000000000015, -48.099999999999824, 20.000000000000014, -33.9999999999998, -347.5, -262.29999999999995, -89.20000000000084, -253.30000000000013, 20.000000000000014, 20.000000000000014, -108.10000000000004, -23.199999999999875, 37.10000000000026, 20.000000000000014, 3.199999999999965, 20.000000000000014, 41.600000000000215, 20.000000000000014, 44.90000000000024, -51.399999999999814, -85.30000000000084, 20.000000000000014, 29.90000000000018, 20.000000000000014, -19.899999999999743, 29.90000000000018, 29.000000000000163, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.80000000000004, -109.90000000000063, 20.000000000000014, 13.699999999999969, 20.000000000000014, 29.90000000000018, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.59999999999975, -80.80000000000072, 20.000000000000014, 20.000000000000014, -8.7999999999999, 32.60000000000023, 20.000000000000014, 17.899999999999988, 12.199999999999978, -82.90000000000082, -154.29999999999984, -99.70000000000003, -10.599999999999879, -131.2000000000005, -30.39999999999975, 47.300000000000146, 31.700000000000188, -31.89999999999977, -28.29999999999975, 21.500000000000036, 20.000000000000014, -25.29999999999979, -88.90000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -45.09999999999977, 51.500000000000234, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 46.10000000000024, -163.60000000000002, -400.0, -14.499999999999822, -28.29999999999975, -144.69999999999993, -219.4, 20.000000000000014, 3.1999999999999633, -400.0, 20.000000000000014, -68.20000000000077, 20.000000000000014, -7.300000000000004, -23.79999999999982, -239.20000000000013, -92.80000000000042, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -190.30000000000018, -59.80000000000003, 20.000000000000014, -1.6000000000000387, 20.000000000000014, 38.90000000000023, 20.000000000000014, 56.00000000000021, -15.699999999999811, -36.699999999999754, 20.000000000000014, 28.100000000000147, -376.9, -127.00000000000001, 26.300000000000114, 11.599999999999964, -36.699999999999754, -22.299999999999763, -53.500000000000036, -11.499999999999819, -72.40000000000028, 20.000000000000014, -6.399999999999908, 20.000000000000014, -47.79999999999981, -36.09999999999983, -16.599999999999753, 11.599999999999964, 17.899999999999977, -26.199999999999747, 11.599999999999975, 20.000000000000014, -14.799999999999764, -38.799999999999756, -40.90000000000003, -80.79999999999978, -24.099999999999746, -1.9000000000000283, 20.000000000000014, 20.000000000000014, 20.000000000000014, 46.10000000000024, -349.6, 20.000000000000014, -28.8999999999998, 39.80000000000025, -113.79999999999988, -122.80000000000061, 14.599999999999968, -66.10000000000079], "policy_predator_policy_reward": [126.0, 58.0, 0.0, 26.0, 0.0, 0.0, 0.0, 0.0, 6.0, 102.0, 0.0, 0.0, 6.0, 177.0, 13.0, 31.0, 0.0, 0.0, 0.0, 136.0, 0.0, 0.0, 128.0, 36.0, 8.0, 0.0, 0.0, 180.0, 0.0, 41.0, 0.0, 5.0, 10.0, 0.0, 24.0, 7.0, 14.0, 172.0, 30.0, 18.0, 0.0, 0.0, 53.0, 53.0, 3.0, 137.0, 5.0, 0.0, 24.0, 0.0, 20.0, 26.0, 0.0, 36.0, 175.0, 52.0, 177.0, 8.0, 0.0, 0.0, 53.0, 12.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 35.0, 0.0, 15.0, 42.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 52.0, 66.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 72.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 1.0, 14.0, 49.0, 61.0, 22.0, 91.0, 0.0, 38.0, 0.0, 29.0, 0.0, 23.0, 0.0, 0.0, 31.0, 35.0, 40.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 200.0, 0.0, 47.0, 108.0, 114.0, 0.0, 8.0, 200.0, 0.0, 25.0, 31.0, 0.0, 32.0, 139.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 35.0, 73.0, 0.0, 24.0, 3.0, 0.0, 0.0, 0.0, 27.0, 17.0, 0.0, 0.0, 189.0, 70.0, 4.0, 0.0, 35.0, 0.0, 29.0, 46.0, 0.0, 44.0, 13.0, 0.0, 0.0, 43.0, 24.0, 0.0, 0.0, 23.0, 0.0, 13.0, 25.0, 27.0, 0.0, 48.0, 22.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 176.0, 34.0, 0.0, 9.0, 139.0, 23.0, 24.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3827360731390415, "mean_inference_ms": 10.305770244699811, "mean_action_processing_ms": 0.6738513052074907, "mean_env_wait_ms": 1.379899439220448, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014791131019592285, "StateBufferConnector_ms": 0.008812665939331055, "ViewRequirementAgentConnector_ms": 0.30162930488586426}, "num_episodes": 22, "episode_return_max": 128.0999999999986, "episode_return_min": -425.5999999999998, "episode_return_mean": -20.900999999999918, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 147.99592091549837, "num_env_steps_trained_throughput_per_sec": 147.99592091549837, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 26743.712, "restore_workers_time_ms": 0.018, "training_step_time_ms": 26743.646, "sample_time_ms": 3705.462, "learn_time_ms": 23009.859, "learn_throughput": 173.839, "synch_weights_time_ms": 23.226}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "3a355_00000", "date": "2024-08-13_02-54-05", "timestamp": 1723532045, "time_this_iter_s": 27.07665205001831, "time_total_s": 6249.288006305695, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52dea60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6249.288006305695, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 88.02368421052631, "ram_util_percent": 83.40526315789474}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4948149033797481, "cur_kl_coeff": 2.168404344971009e-20, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.719884578702311, "policy_loss": -0.0013641667999475012, "vf_loss": 2.7212487401785674, "vf_explained_var": 0.0009398132089584593, "kl": 0.0019528962193406162, "entropy": 0.2950393785008047, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.862537764140932, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3588087179673414, "policy_loss": -0.004023470915484405, "vf_loss": 3.362137778978499, "vf_explained_var": -0.004930067409283269, "kl": 0.01826836053141837, "entropy": 0.9456319611539286, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 128.0999999999986, "episode_reward_min": -472.20000000000005, "episode_reward_mean": -14.788999999999895, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 64.10000000000015, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -32.92449999999998, "predator_policy": 25.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-304.10000000000014, -2.299999999999822, 49.90000000000046, 34.70000000000022, -189.60000000000014, 128.0999999999986, 20.799999999999994, 26.000000000000153, 22.00000000000003, -382.79999999999995, -157.50000000000085, 40.0000000000003, -66.29999999999998, 57.10000000000052, 34.200000000000216, 61.60000000000045, 28.500000000000206, -8.299999999999688, 49.90000000000046, 29.000000000000135, 49.00000000000045, 40.0000000000003, 38.900000000000276, 40.0000000000003, 41.80000000000033, 28.100000000000126, 36.70000000000025, 49.90000000000046, 40.0000000000003, -43.39999999999996, 40.0000000000003, 38.800000000000296, 38.90000000000028, -7.699999999999719, -171.0, -50.79999999999998, 54.90000000000035, 28.800000000000125, 16.199999999999964, 25.70000000000012, 6.099999999999961, 40.0000000000003, 5.900000000000118, 71.49999999999996, 50.80000000000048, 66.10000000000035, -363.60000000000014, 4.200000000000095, -142.09999999999985, 31.20000000000017, -180.00000000000068, 7.799999999999997, 0.9000000000004107, -193.00000000000054, 48.10000000000043, 40.0000000000003, 37.80000000000027, -142.09999999999988, 42.40000000000042, 61.90000000000048, 75.9999999999996, -8.39999999999966, 48.10000000000043, -244.9000000000002, 41.900000000000325, -23.999999999999517, 9.999999999999954, -8.399999999999958, 26.600000000000087, -40.90000000000134, 18.99999999999996, 14.699999999999969, 44.600000000000406, -1.5999999999997434, -73.70000000000006, 16.99999999999998, 40.0000000000003, 66.10000000000035, -153.6000000000005, 44.90000000000045, -88.6, -4.499999999999787, 31.400000000000176, 52.60000000000044, 39.50000000000029, -10.299999999999788, -472.20000000000005, -278.9999999999999, -236.40000000000035, 19.099999999999962, 44.500000000000384, 23.20000000000004, 18.399999999999974, 104.79999999999816, -6.199999999999731, 42.10000000000033, 0.4000000000000722, 56.200000000000394, -1.7999999999997578, -5.0999999999997705], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-298.00000000000017, -192.10000000000002, -51.39999999999988, 1.0999999999999617, 20.000000000000014, 29.90000000000018, -36.699999999999825, -34.59999999999977, -261.4000000000001, -68.20000000000005, 59.000000000000185, 64.10000000000015, 20.000000000000014, -23.19999999999976, 28.10000000000015, -48.099999999999824, 20.000000000000014, -33.9999999999998, -347.5, -262.29999999999995, -89.20000000000084, -253.30000000000013, 20.000000000000014, 20.000000000000014, -108.10000000000004, -23.199999999999875, 37.10000000000026, 20.000000000000014, 3.199999999999965, 20.000000000000014, 41.600000000000215, 20.000000000000014, 44.90000000000024, -51.399999999999814, -85.30000000000084, 20.000000000000014, 29.90000000000018, 20.000000000000014, -19.899999999999743, 29.90000000000018, 29.000000000000163, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.80000000000004, -109.90000000000063, 20.000000000000014, 13.699999999999969, 20.000000000000014, 29.90000000000018, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.59999999999975, -80.80000000000072, 20.000000000000014, 20.000000000000014, -8.7999999999999, 32.60000000000023, 20.000000000000014, 17.899999999999988, 12.199999999999978, -82.90000000000082, -154.29999999999984, -99.70000000000003, -10.599999999999879, -131.2000000000005, -30.39999999999975, 47.300000000000146, 31.700000000000188, -31.89999999999977, -28.29999999999975, 21.500000000000036, 20.000000000000014, -25.29999999999979, -88.90000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -45.09999999999977, 51.500000000000234, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 46.10000000000024, -163.60000000000002, -400.0, -14.499999999999822, -28.29999999999975, -144.69999999999993, -219.4, 20.000000000000014, 3.1999999999999633, -400.0, 20.000000000000014, -68.20000000000077, 20.000000000000014, -7.300000000000004, -23.79999999999982, -239.20000000000013, -92.80000000000042, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -190.30000000000018, -59.80000000000003, 20.000000000000014, -1.6000000000000387, 20.000000000000014, 38.90000000000023, 20.000000000000014, 56.00000000000021, -15.699999999999811, -36.699999999999754, 20.000000000000014, 28.100000000000147, -376.9, -127.00000000000001, 26.300000000000114, 11.599999999999964, -36.699999999999754, -22.299999999999763, -53.500000000000036, -11.499999999999819, -72.40000000000028, 20.000000000000014, -6.399999999999908, 20.000000000000014, -47.79999999999981, -36.09999999999983, -16.599999999999753, 11.599999999999964, 17.899999999999977, -26.199999999999747, 11.599999999999975, 20.000000000000014, -14.799999999999764, -38.799999999999756, -40.90000000000003, -80.79999999999978, -24.099999999999746, -1.9000000000000283, 20.000000000000014, 20.000000000000014, 20.000000000000014, 46.10000000000024, -349.6, 20.000000000000014, -28.8999999999998, 39.80000000000025, -113.79999999999988, -122.80000000000061, 14.599999999999968, -66.10000000000079, -97.60000000000082, 20.000000000000014, -6.399999999999979, 20.000000000000014, 3.4999999999999654, 20.000000000000014, -42.999999999999815, -43.29999999999987, -324.4, -311.8, -148.30000000000004, -279.70000000000016, -313.6000000000002, -101.80000000000004, 10.99999999999997, -19.899999999999743, -17.79999999999974, 44.30000000000024, 20.000000000000014, -59.80000000000062, -29.799999999999784, 3.1999999999999704, 47.000000000000234, 57.800000000000225, -11.199999999999855, -21.99999999999978, 19.1, 20.000000000000014, -55.60000000000011, 20.000000000000014, -24.099999999999824, 44.30000000000021, -59.80000000000062, 20.000000000000014, -47.19999999999976, -7.899999999999945], "policy_predator_policy_reward": [14.0, 172.0, 30.0, 18.0, 0.0, 0.0, 53.0, 53.0, 3.0, 137.0, 5.0, 0.0, 24.0, 0.0, 20.0, 26.0, 0.0, 36.0, 175.0, 52.0, 177.0, 8.0, 0.0, 0.0, 53.0, 12.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 35.0, 0.0, 15.0, 42.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 52.0, 66.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 72.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 1.0, 14.0, 49.0, 61.0, 22.0, 91.0, 0.0, 38.0, 0.0, 29.0, 0.0, 23.0, 0.0, 0.0, 31.0, 35.0, 40.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 200.0, 0.0, 47.0, 108.0, 114.0, 0.0, 8.0, 200.0, 0.0, 25.0, 31.0, 0.0, 32.0, 139.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 35.0, 73.0, 0.0, 24.0, 3.0, 0.0, 0.0, 0.0, 27.0, 17.0, 0.0, 0.0, 189.0, 70.0, 4.0, 0.0, 35.0, 0.0, 29.0, 46.0, 0.0, 44.0, 13.0, 0.0, 0.0, 43.0, 24.0, 0.0, 0.0, 23.0, 0.0, 13.0, 25.0, 27.0, 0.0, 48.0, 22.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 176.0, 34.0, 0.0, 9.0, 139.0, 23.0, 24.0, 53.0, 56.0, 23.0, 16.0, 6.0, 10.0, 44.0, 32.0, 0.0, 164.0, 49.0, 100.0, 140.0, 39.0, 16.0, 12.0, 18.0, 0.0, 31.0, 32.0, 16.0, 29.0, 0.0, 0.0, 26.0, 1.0, 0.0, 3.0, 0.0, 36.0, 29.0, 7.0, 0.0, 38.0, 0.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.377516422048394, "mean_inference_ms": 10.254255050148403, "mean_action_processing_ms": 0.6742801715773306, "mean_env_wait_ms": 1.3721474252424455, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02668297290802002, "StateBufferConnector_ms": 0.01147615909576416, "ViewRequirementAgentConnector_ms": 0.31385529041290283}, "num_episodes": 18, "episode_return_max": 128.0999999999986, "episode_return_min": -472.20000000000005, "episode_return_mean": -14.788999999999895, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 149.85280235468358, "num_env_steps_trained_throughput_per_sec": 149.85280235468358, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 26899.581, "restore_workers_time_ms": 0.018, "training_step_time_ms": 26899.514, "sample_time_ms": 3756.401, "learn_time_ms": 23113.741, "learn_throughput": 173.057, "synch_weights_time_ms": 24.233}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "3a355_00000", "date": "2024-08-13_02-54-32", "timestamp": 1723532072, "time_this_iter_s": 26.776700019836426, "time_total_s": 6276.064706325531, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d4ad30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6276.064706325531, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 87.62894736842105, "ram_util_percent": 83.3921052631579}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47949938771349415, "cur_kl_coeff": 1.0842021724855045e-20, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6365482797067632, "policy_loss": -0.0008843256342939283, "vf_loss": 1.6374326085918165, "vf_explained_var": 0.0019812022252057595, "kl": 0.0031390350717501667, "entropy": 0.28124501658652823, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9054256252510838, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3297036409062684, "policy_loss": -0.0014677771765039002, "vf_loss": 2.3308551234543007, "vf_explained_var": 0.00014425153454775531, "kl": 0.008321082925060508, "entropy": 0.8603539021242232, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 104.79999999999816, "episode_reward_min": -553.8, "episode_reward_mean": -12.974999999999916, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.0000000000002, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -31.487499999999976, "predator_policy": 25.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 41.80000000000033, 28.100000000000126, 36.70000000000025, 49.90000000000046, 40.0000000000003, -43.39999999999996, 40.0000000000003, 38.800000000000296, 38.90000000000028, -7.699999999999719, -171.0, -50.79999999999998, 54.90000000000035, 28.800000000000125, 16.199999999999964, 25.70000000000012, 6.099999999999961, 40.0000000000003, 5.900000000000118, 71.49999999999996, 50.80000000000048, 66.10000000000035, -363.60000000000014, 4.200000000000095, -142.09999999999985, 31.20000000000017, -180.00000000000068, 7.799999999999997, 0.9000000000004107, -193.00000000000054, 48.10000000000043, 40.0000000000003, 37.80000000000027, -142.09999999999988, 42.40000000000042, 61.90000000000048, 75.9999999999996, -8.39999999999966, 48.10000000000043, -244.9000000000002, 41.900000000000325, -23.999999999999517, 9.999999999999954, -8.399999999999958, 26.600000000000087, -40.90000000000134, 18.99999999999996, 14.699999999999969, 44.600000000000406, -1.5999999999997434, -73.70000000000006, 16.99999999999998, 40.0000000000003, 66.10000000000035, -153.6000000000005, 44.90000000000045, -88.6, -4.499999999999787, 31.400000000000176, 52.60000000000044, 39.50000000000029, -10.299999999999788, -472.20000000000005, -278.9999999999999, -236.40000000000035, 19.099999999999962, 44.500000000000384, 23.20000000000004, 18.399999999999974, 104.79999999999816, -6.199999999999731, 42.10000000000033, 0.4000000000000722, 56.200000000000394, -1.7999999999997578, -5.0999999999997705, 40.0000000000003, 32.300000000000175, -120.20000000000041, 40.0000000000003, -4.799999999999736, 19.39999999999997, 1.500000000000165, 21.600000000000005, 52.90000000000038, 103.09999999999837, 11.299999999999999, -20.499999999999538, 39.20000000000033, 49.60000000000046, -266.69999999999993, -553.8, 61.399999999999864, 89.69999999999854, -24.099999999999675, 57.10000000000051, 40.0000000000003, 73.99999999999953, 37.2000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 21.80000000000004, -109.90000000000063, 20.000000000000014, 13.699999999999969, 20.000000000000014, 29.90000000000018, 20.000000000000014, 20.000000000000014, 20.000000000000014, -34.59999999999975, -80.80000000000072, 20.000000000000014, 20.000000000000014, -8.7999999999999, 32.60000000000023, 20.000000000000014, 17.899999999999988, 12.199999999999978, -82.90000000000082, -154.29999999999984, -99.70000000000003, -10.599999999999879, -131.2000000000005, -30.39999999999975, 47.300000000000146, 31.700000000000188, -31.89999999999977, -28.29999999999975, 21.500000000000036, 20.000000000000014, -25.29999999999979, -88.90000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -45.09999999999977, 51.500000000000234, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 46.10000000000024, -163.60000000000002, -400.0, -14.499999999999822, -28.29999999999975, -144.69999999999993, -219.4, 20.000000000000014, 3.1999999999999633, -400.0, 20.000000000000014, -68.20000000000077, 20.000000000000014, -7.300000000000004, -23.79999999999982, -239.20000000000013, -92.80000000000042, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -190.30000000000018, -59.80000000000003, 20.000000000000014, -1.6000000000000387, 20.000000000000014, 38.90000000000023, 20.000000000000014, 56.00000000000021, -15.699999999999811, -36.699999999999754, 20.000000000000014, 28.100000000000147, -376.9, -127.00000000000001, 26.300000000000114, 11.599999999999964, -36.699999999999754, -22.299999999999763, -53.500000000000036, -11.499999999999819, -72.40000000000028, 20.000000000000014, -6.399999999999908, 20.000000000000014, -47.79999999999981, -36.09999999999983, -16.599999999999753, 11.599999999999964, 17.899999999999977, -26.199999999999747, 11.599999999999975, 20.000000000000014, -14.799999999999764, -38.799999999999756, -40.90000000000003, -80.79999999999978, -24.099999999999746, -1.9000000000000283, 20.000000000000014, 20.000000000000014, 20.000000000000014, 46.10000000000024, -349.6, 20.000000000000014, -28.8999999999998, 39.80000000000025, -113.79999999999988, -122.80000000000061, 14.599999999999968, -66.10000000000079, -97.60000000000082, 20.000000000000014, -6.399999999999979, 20.000000000000014, 3.4999999999999654, 20.000000000000014, -42.999999999999815, -43.29999999999987, -324.4, -311.8, -148.30000000000004, -279.70000000000016, -313.6000000000002, -101.80000000000004, 10.99999999999997, -19.899999999999743, -17.79999999999974, 44.30000000000024, 20.000000000000014, -59.80000000000062, -29.799999999999784, 3.1999999999999704, 47.000000000000234, 57.800000000000225, -11.199999999999855, -21.99999999999978, 19.1, 20.000000000000014, -55.60000000000011, 20.000000000000014, -24.099999999999824, 44.30000000000021, -59.80000000000062, 20.000000000000014, -47.19999999999976, -7.899999999999945, 20.000000000000014, 20.000000000000014, 5.299999999999981, 20.000000000000014, -254.50000000000006, -36.69999999999981, 20.000000000000014, 20.000000000000014, -33.699999999999754, -24.099999999999802, -34.29999999999978, 22.700000000000053, 20.000000000000014, -53.50000000000012, -18.39999999999975, 20.000000000000014, 47.00000000000024, -33.09999999999984, 62.0000000000002, 37.10000000000025, -44.499999999999794, 15.799999999999962, -57.70000000000048, -17.79999999999977, 5.299999999999972, 20.90000000000003, 23.600000000000072, 20.000000000000014, -265.59999999999997, -231.09999999999997, -400.0, -353.8, 27.200000000000138, 24.200000000000166, 58.70000000000022, 7.999999999999977, -42.99999999999984, -78.10000000000053, 20.000000000000014, 37.10000000000026, 20.000000000000014, 20.000000000000014, 35.000000000000135, 20.000000000000014, -14.799999999999836, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 52.0, 66.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 72.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 1.0, 14.0, 49.0, 61.0, 22.0, 91.0, 0.0, 38.0, 0.0, 29.0, 0.0, 23.0, 0.0, 0.0, 31.0, 35.0, 40.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 200.0, 0.0, 47.0, 108.0, 114.0, 0.0, 8.0, 200.0, 0.0, 25.0, 31.0, 0.0, 32.0, 139.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 35.0, 73.0, 0.0, 24.0, 3.0, 0.0, 0.0, 0.0, 27.0, 17.0, 0.0, 0.0, 189.0, 70.0, 4.0, 0.0, 35.0, 0.0, 29.0, 46.0, 0.0, 44.0, 13.0, 0.0, 0.0, 43.0, 24.0, 0.0, 0.0, 23.0, 0.0, 13.0, 25.0, 27.0, 0.0, 48.0, 22.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 176.0, 34.0, 0.0, 9.0, 139.0, 23.0, 24.0, 53.0, 56.0, 23.0, 16.0, 6.0, 10.0, 44.0, 32.0, 0.0, 164.0, 49.0, 100.0, 140.0, 39.0, 16.0, 12.0, 18.0, 0.0, 31.0, 32.0, 16.0, 29.0, 0.0, 0.0, 26.0, 1.0, 0.0, 3.0, 0.0, 36.0, 29.0, 7.0, 0.0, 38.0, 0.0, 50.0, 0.0, 0.0, 0.0, 7.0, 27.0, 144.0, 0.0, 0.0, 21.0, 32.0, 8.0, 23.0, 35.0, 0.0, 0.0, 20.0, 0.0, 39.0, 4.0, 0.0, 2.0, 38.0, 37.0, 18.0, 0.0, 13.0, 6.0, 0.0, 124.0, 106.0, 200.0, 0.0, 10.0, 0.0, 15.0, 8.0, 49.0, 48.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 32.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.372955604290648, "mean_inference_ms": 10.18893073671572, "mean_action_processing_ms": 0.6747459572214619, "mean_env_wait_ms": 1.3607367594805841, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.024756908416748047, "StateBufferConnector_ms": 0.011187553405761719, "ViewRequirementAgentConnector_ms": 0.3001517057418823}, "num_episodes": 23, "episode_return_max": 104.79999999999816, "episode_return_min": -553.8, "episode_return_mean": -12.974999999999916, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 151.41917252152763, "num_env_steps_trained_throughput_per_sec": 151.41917252152763, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 26966.757, "restore_workers_time_ms": 0.018, "training_step_time_ms": 26966.689, "sample_time_ms": 3786.374, "learn_time_ms": 23150.313, "learn_throughput": 172.784, "synch_weights_time_ms": 24.64}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "3a355_00000", "date": "2024-08-13_02-54-58", "timestamp": 1723532098, "time_this_iter_s": 26.47386598587036, "time_total_s": 6302.538572311401, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d4af70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6302.538572311401, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 88.9108108108108, "ram_util_percent": 83.4378378378378}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47226917533174395, "cur_kl_coeff": 5.4210108624275225e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.076694105604969, "policy_loss": -0.00048770036058076635, "vf_loss": 2.077181805441619, "vf_explained_var": 0.002608647390648171, "kl": 0.0011394306836695262, "entropy": 0.270624758287397, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8613706059182289, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0556339050726917, "policy_loss": -0.005131307690744362, "vf_loss": 3.0601779410448025, "vf_explained_var": 0.0028051202259366474, "kl": 0.01544948730803656, "entropy": 0.7659831867016181, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 129.09999999999854, "episode_reward_min": -553.8, "episode_reward_mean": -10.551999999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 99.19999999999938, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -30.015999999999977, "predator_policy": 24.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 5.900000000000118, 71.49999999999996, 50.80000000000048, 66.10000000000035, -363.60000000000014, 4.200000000000095, -142.09999999999985, 31.20000000000017, -180.00000000000068, 7.799999999999997, 0.9000000000004107, -193.00000000000054, 48.10000000000043, 40.0000000000003, 37.80000000000027, -142.09999999999988, 42.40000000000042, 61.90000000000048, 75.9999999999996, -8.39999999999966, 48.10000000000043, -244.9000000000002, 41.900000000000325, -23.999999999999517, 9.999999999999954, -8.399999999999958, 26.600000000000087, -40.90000000000134, 18.99999999999996, 14.699999999999969, 44.600000000000406, -1.5999999999997434, -73.70000000000006, 16.99999999999998, 40.0000000000003, 66.10000000000035, -153.6000000000005, 44.90000000000045, -88.6, -4.499999999999787, 31.400000000000176, 52.60000000000044, 39.50000000000029, -10.299999999999788, -472.20000000000005, -278.9999999999999, -236.40000000000035, 19.099999999999962, 44.500000000000384, 23.20000000000004, 18.399999999999974, 104.79999999999816, -6.199999999999731, 42.10000000000033, 0.4000000000000722, 56.200000000000394, -1.7999999999997578, -5.0999999999997705, 40.0000000000003, 32.300000000000175, -120.20000000000041, 40.0000000000003, -4.799999999999736, 19.39999999999997, 1.500000000000165, 21.600000000000005, 52.90000000000038, 103.09999999999837, 11.299999999999999, -20.499999999999538, 39.20000000000033, 49.60000000000046, -266.69999999999993, -553.8, 61.399999999999864, 89.69999999999854, -24.099999999999675, 57.10000000000051, 40.0000000000003, 73.99999999999953, 37.2000000000003, 67.80000000000004, 40.0000000000003, -75.19999999999999, 129.09999999999854, 100.29999999999822, 3.2000000000001414, 40.0000000000003, -10.000000000000108, -8.39999999999966, 40.0000000000003, 29.300000000000143, 105.69999999999843, 12.999999999999915, -191.49999999999994, 8.09999999999998, 103.89999999999873, 11.900000000000032, 48.10000000000043], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, -45.09999999999977, 51.500000000000234, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 46.10000000000024, -163.60000000000002, -400.0, -14.499999999999822, -28.29999999999975, -144.69999999999993, -219.4, 20.000000000000014, 3.1999999999999633, -400.0, 20.000000000000014, -68.20000000000077, 20.000000000000014, -7.300000000000004, -23.79999999999982, -239.20000000000013, -92.80000000000042, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, -190.30000000000018, -59.80000000000003, 20.000000000000014, -1.6000000000000387, 20.000000000000014, 38.90000000000023, 20.000000000000014, 56.00000000000021, -15.699999999999811, -36.699999999999754, 20.000000000000014, 28.100000000000147, -376.9, -127.00000000000001, 26.300000000000114, 11.599999999999964, -36.699999999999754, -22.299999999999763, -53.500000000000036, -11.499999999999819, -72.40000000000028, 20.000000000000014, -6.399999999999908, 20.000000000000014, -47.79999999999981, -36.09999999999983, -16.599999999999753, 11.599999999999964, 17.899999999999977, -26.199999999999747, 11.599999999999975, 20.000000000000014, -14.799999999999764, -38.799999999999756, -40.90000000000003, -80.79999999999978, -24.099999999999746, -1.9000000000000283, 20.000000000000014, 20.000000000000014, 20.000000000000014, 46.10000000000024, -349.6, 20.000000000000014, -28.8999999999998, 39.80000000000025, -113.79999999999988, -122.80000000000061, 14.599999999999968, -66.10000000000079, -97.60000000000082, 20.000000000000014, -6.399999999999979, 20.000000000000014, 3.4999999999999654, 20.000000000000014, -42.999999999999815, -43.29999999999987, -324.4, -311.8, -148.30000000000004, -279.70000000000016, -313.6000000000002, -101.80000000000004, 10.99999999999997, -19.899999999999743, -17.79999999999974, 44.30000000000024, 20.000000000000014, -59.80000000000062, -29.799999999999784, 3.1999999999999704, 47.000000000000234, 57.800000000000225, -11.199999999999855, -21.99999999999978, 19.1, 20.000000000000014, -55.60000000000011, 20.000000000000014, -24.099999999999824, 44.30000000000021, -59.80000000000062, 20.000000000000014, -47.19999999999976, -7.899999999999945, 20.000000000000014, 20.000000000000014, 5.299999999999981, 20.000000000000014, -254.50000000000006, -36.69999999999981, 20.000000000000014, 20.000000000000014, -33.699999999999754, -24.099999999999802, -34.29999999999978, 22.700000000000053, 20.000000000000014, -53.50000000000012, -18.39999999999975, 20.000000000000014, 47.00000000000024, -33.09999999999984, 62.0000000000002, 37.10000000000025, -44.499999999999794, 15.799999999999962, -57.70000000000048, -17.79999999999977, 5.299999999999972, 20.90000000000003, 23.600000000000072, 20.000000000000014, -265.59999999999997, -231.09999999999997, -400.0, -353.8, 27.200000000000138, 24.200000000000166, 58.70000000000022, 7.999999999999977, -42.99999999999984, -78.10000000000053, 20.000000000000014, 37.10000000000026, 20.000000000000014, 20.000000000000014, 35.000000000000135, 20.000000000000014, -14.799999999999836, 20.000000000000014, -9.39999999999994, 63.20000000000015, 20.000000000000014, 20.000000000000014, -226.6000000000002, 25.400000000000098, 97.39999999999935, 31.700000000000212, 41.60000000000025, 58.70000000000022, -5.199999999999955, -22.59999999999978, 20.000000000000014, 20.000000000000014, -56.499999999999964, -53.500000000000014, -72.40000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -12.699999999999829, 29.000000000000163, 76.69999999999929, -11.499999999999904, 9.49999999999998, -253.0, -101.5, 20.000000000000014, -40.89999999999978, 99.19999999999938, -13.299999999999798, -36.09999999999976, 20.000000000000014, 28.100000000000147, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 200.0, 0.0, 47.0, 108.0, 114.0, 0.0, 8.0, 200.0, 0.0, 25.0, 31.0, 0.0, 32.0, 139.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 35.0, 73.0, 0.0, 24.0, 3.0, 0.0, 0.0, 0.0, 27.0, 17.0, 0.0, 0.0, 189.0, 70.0, 4.0, 0.0, 35.0, 0.0, 29.0, 46.0, 0.0, 44.0, 13.0, 0.0, 0.0, 43.0, 24.0, 0.0, 0.0, 23.0, 0.0, 13.0, 25.0, 27.0, 0.0, 48.0, 22.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 176.0, 34.0, 0.0, 9.0, 139.0, 23.0, 24.0, 53.0, 56.0, 23.0, 16.0, 6.0, 10.0, 44.0, 32.0, 0.0, 164.0, 49.0, 100.0, 140.0, 39.0, 16.0, 12.0, 18.0, 0.0, 31.0, 32.0, 16.0, 29.0, 0.0, 0.0, 26.0, 1.0, 0.0, 3.0, 0.0, 36.0, 29.0, 7.0, 0.0, 38.0, 0.0, 50.0, 0.0, 0.0, 0.0, 7.0, 27.0, 144.0, 0.0, 0.0, 21.0, 32.0, 8.0, 23.0, 35.0, 0.0, 0.0, 20.0, 0.0, 39.0, 4.0, 0.0, 2.0, 38.0, 37.0, 18.0, 0.0, 13.0, 6.0, 0.0, 124.0, 106.0, 200.0, 0.0, 10.0, 0.0, 15.0, 8.0, 49.0, 48.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 32.0, 0.0, 14.0, 0.0, 0.0, 0.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 8.0, 92.0, 0.0, 44.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 15.0, 130.0, 33.0, 29.0, 0.0, 0.0, 18.0, 28.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3679719640612626, "mean_inference_ms": 10.139481757760985, "mean_action_processing_ms": 0.6752512057912234, "mean_env_wait_ms": 1.3533871494825664, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02254319190979004, "StateBufferConnector_ms": 0.011307001113891602, "ViewRequirementAgentConnector_ms": 0.31270694732666016}, "num_episodes": 18, "episode_return_max": 129.09999999999854, "episode_return_min": -553.8, "episode_return_mean": -10.551999999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 144.3533494596529, "num_env_steps_trained_throughput_per_sec": 144.3533494596529, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 27150.065, "restore_workers_time_ms": 0.018, "training_step_time_ms": 27149.999, "sample_time_ms": 3766.414, "learn_time_ms": 23350.931, "learn_throughput": 171.299, "synch_weights_time_ms": 27.766}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "3a355_00000", "date": "2024-08-13_02-55-26", "timestamp": 1723532126, "time_this_iter_s": 27.763123989105225, "time_total_s": 6330.301696300507, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52405e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6330.301696300507, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 89.39230769230768, "ram_util_percent": 83.2128205128205}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6280025811580123, "cur_kl_coeff": 2.7105054312137612e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.266859536574631, "policy_loss": -0.001799250987885648, "vf_loss": 2.268658789629659, "vf_explained_var": 0.003342420430410476, "kl": 0.002326668251033538, "entropy": 0.31351915499363, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9701050359006754, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.525573886008489, "policy_loss": -0.002692866562890313, "vf_loss": 4.527930253649515, "vf_explained_var": 0.04033551503110815, "kl": 0.008852309604690167, "entropy": 0.6428339286456033, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 268.60000000000093, "episode_reward_min": -553.8, "episode_reward_mean": 0.9029999999999678, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 156.8, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -25.388500000000004, "predator_policy": 25.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-244.9000000000002, 41.900000000000325, -23.999999999999517, 9.999999999999954, -8.399999999999958, 26.600000000000087, -40.90000000000134, 18.99999999999996, 14.699999999999969, 44.600000000000406, -1.5999999999997434, -73.70000000000006, 16.99999999999998, 40.0000000000003, 66.10000000000035, -153.6000000000005, 44.90000000000045, -88.6, -4.499999999999787, 31.400000000000176, 52.60000000000044, 39.50000000000029, -10.299999999999788, -472.20000000000005, -278.9999999999999, -236.40000000000035, 19.099999999999962, 44.500000000000384, 23.20000000000004, 18.399999999999974, 104.79999999999816, -6.199999999999731, 42.10000000000033, 0.4000000000000722, 56.200000000000394, -1.7999999999997578, -5.0999999999997705, 40.0000000000003, 32.300000000000175, -120.20000000000041, 40.0000000000003, -4.799999999999736, 19.39999999999997, 1.500000000000165, 21.600000000000005, 52.90000000000038, 103.09999999999837, 11.299999999999999, -20.499999999999538, 39.20000000000033, 49.60000000000046, -266.69999999999993, -553.8, 61.399999999999864, 89.69999999999854, -24.099999999999675, 57.10000000000051, 40.0000000000003, 73.99999999999953, 37.2000000000003, 67.80000000000004, 40.0000000000003, -75.19999999999999, 129.09999999999854, 100.29999999999822, 3.2000000000001414, 40.0000000000003, -10.000000000000108, -8.39999999999966, 40.0000000000003, 29.300000000000143, 105.69999999999843, 12.999999999999915, -191.49999999999994, 8.09999999999998, 103.89999999999873, 11.900000000000032, 48.10000000000043, -268.99999999999994, 90.7999999999999, 44.30000000000039, 40.0000000000003, -20.000000000000654, 268.60000000000093, -45.19999999999958, 62.60000000000046, 41.30000000000034, 40.0000000000003, 134.99999999999977, 195.69999999999905, -3.999999999999794, 77.59999999999934, -68.89999999999968, -25.999999999999545, 74.59999999999961, 15.599999999999925, -224.30000000000004, 94.10000000000005, 82.29999999999903, 143.89999999999898], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-376.9, -127.00000000000001, 26.300000000000114, 11.599999999999964, -36.699999999999754, -22.299999999999763, -53.500000000000036, -11.499999999999819, -72.40000000000028, 20.000000000000014, -6.399999999999908, 20.000000000000014, -47.79999999999981, -36.09999999999983, -16.599999999999753, 11.599999999999964, 17.899999999999977, -26.199999999999747, 11.599999999999975, 20.000000000000014, -14.799999999999764, -38.799999999999756, -40.90000000000003, -80.79999999999978, -24.099999999999746, -1.9000000000000283, 20.000000000000014, 20.000000000000014, 20.000000000000014, 46.10000000000024, -349.6, 20.000000000000014, -28.8999999999998, 39.80000000000025, -113.79999999999988, -122.80000000000061, 14.599999999999968, -66.10000000000079, -97.60000000000082, 20.000000000000014, -6.399999999999979, 20.000000000000014, 3.4999999999999654, 20.000000000000014, -42.999999999999815, -43.29999999999987, -324.4, -311.8, -148.30000000000004, -279.70000000000016, -313.6000000000002, -101.80000000000004, 10.99999999999997, -19.899999999999743, -17.79999999999974, 44.30000000000024, 20.000000000000014, -59.80000000000062, -29.799999999999784, 3.1999999999999704, 47.000000000000234, 57.800000000000225, -11.199999999999855, -21.99999999999978, 19.1, 20.000000000000014, -55.60000000000011, 20.000000000000014, -24.099999999999824, 44.30000000000021, -59.80000000000062, 20.000000000000014, -47.19999999999976, -7.899999999999945, 20.000000000000014, 20.000000000000014, 5.299999999999981, 20.000000000000014, -254.50000000000006, -36.69999999999981, 20.000000000000014, 20.000000000000014, -33.699999999999754, -24.099999999999802, -34.29999999999978, 22.700000000000053, 20.000000000000014, -53.50000000000012, -18.39999999999975, 20.000000000000014, 47.00000000000024, -33.09999999999984, 62.0000000000002, 37.10000000000025, -44.499999999999794, 15.799999999999962, -57.70000000000048, -17.79999999999977, 5.299999999999972, 20.90000000000003, 23.600000000000072, 20.000000000000014, -265.59999999999997, -231.09999999999997, -400.0, -353.8, 27.200000000000138, 24.200000000000166, 58.70000000000022, 7.999999999999977, -42.99999999999984, -78.10000000000053, 20.000000000000014, 37.10000000000026, 20.000000000000014, 20.000000000000014, 35.000000000000135, 20.000000000000014, -14.799999999999836, 20.000000000000014, -9.39999999999994, 63.20000000000015, 20.000000000000014, 20.000000000000014, -226.6000000000002, 25.400000000000098, 97.39999999999935, 31.700000000000212, 41.60000000000025, 58.70000000000022, -5.199999999999955, -22.59999999999978, 20.000000000000014, 20.000000000000014, -56.499999999999964, -53.500000000000014, -72.40000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -12.699999999999829, 29.000000000000163, 76.69999999999929, -11.499999999999904, 9.49999999999998, -253.0, -101.5, 20.000000000000014, -40.89999999999978, 99.19999999999938, -13.299999999999798, -36.09999999999976, 20.000000000000014, 28.100000000000147, 20.000000000000014, -295.0, -274.0, 154.99999999999997, -173.2000000000006, -0.400000000000033, 13.69999999999997, 20.000000000000014, 20.000000000000014, -10.600000000000307, -132.39999999999992, 126.1999999999999, 142.39999999999978, -63.99999999999982, -59.200000000000415, -7.299999999999891, 56.900000000000226, 5.299999999999965, 29.000000000000163, 20.000000000000014, 20.000000000000014, -59.80000000000062, 156.8, 39.80000000000021, 155.89999999999984, 20.000000000000014, -64.00000000000004, 61.400000000000134, -47.79999999999984, -76.60000000000004, -91.30000000000078, 20.000000000000014, -106.0000000000008, -61.90000000000058, 60.500000000000185, 20.000000000000014, -51.39999999999982, -269.8, -149.50000000000003, 127.99999999999999, -82.90000000000086, 20.000000000000014, 62.30000000000015, 5.299999999999965, 131.59999999999965], "policy_predator_policy_reward": [189.0, 70.0, 4.0, 0.0, 35.0, 0.0, 29.0, 46.0, 0.0, 44.0, 13.0, 0.0, 0.0, 43.0, 24.0, 0.0, 0.0, 23.0, 0.0, 13.0, 25.0, 27.0, 0.0, 48.0, 22.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 176.0, 34.0, 0.0, 9.0, 139.0, 23.0, 24.0, 53.0, 56.0, 23.0, 16.0, 6.0, 10.0, 44.0, 32.0, 0.0, 164.0, 49.0, 100.0, 140.0, 39.0, 16.0, 12.0, 18.0, 0.0, 31.0, 32.0, 16.0, 29.0, 0.0, 0.0, 26.0, 1.0, 0.0, 3.0, 0.0, 36.0, 29.0, 7.0, 0.0, 38.0, 0.0, 50.0, 0.0, 0.0, 0.0, 7.0, 27.0, 144.0, 0.0, 0.0, 21.0, 32.0, 8.0, 23.0, 35.0, 0.0, 0.0, 20.0, 0.0, 39.0, 4.0, 0.0, 2.0, 38.0, 37.0, 18.0, 0.0, 13.0, 6.0, 0.0, 124.0, 106.0, 200.0, 0.0, 10.0, 0.0, 15.0, 8.0, 49.0, 48.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 32.0, 0.0, 14.0, 0.0, 0.0, 0.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 8.0, 92.0, 0.0, 44.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 15.0, 130.0, 33.0, 29.0, 0.0, 0.0, 18.0, 28.0, 0.0, 0.0, 0.0, 160.0, 140.0, 43.0, 66.0, 3.0, 28.0, 0.0, 0.0, 76.0, 47.0, 0.0, 0.0, 78.0, 0.0, 0.0, 13.0, 4.0, 3.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 0.0, 40.0, 53.0, 11.0, 0.0, 99.0, 60.0, 0.0, 37.0, 39.0, 17.0, 30.0, 66.0, 129.0, 4.0, 45.0, 0.0, 0.0, 7.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4328886801018186, "mean_inference_ms": 10.001780392264404, "mean_action_processing_ms": 0.6765075309837247, "mean_env_wait_ms": 1.3490398393954768, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021077990531921387, "StateBufferConnector_ms": 0.011141538619995117, "ViewRequirementAgentConnector_ms": 0.2885887622833252}, "num_episodes": 22, "episode_return_max": 268.60000000000093, "episode_return_min": -553.8, "episode_return_mean": 0.9029999999999678, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 152.7941595551025, "num_env_steps_trained_throughput_per_sec": 152.7941595551025, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 27116.381, "restore_workers_time_ms": 0.019, "training_step_time_ms": 27116.317, "sample_time_ms": 3763.729, "learn_time_ms": 23317.267, "learn_throughput": 171.547, "synch_weights_time_ms": 30.265}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "3a355_00000", "date": "2024-08-13_02-55-53", "timestamp": 1723532153, "time_this_iter_s": 26.267066717147827, "time_total_s": 6356.568763017654, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b551a3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6356.568763017654, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 87.47837837837838, "ram_util_percent": 83.15135135135137}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6394686037191638, "cur_kl_coeff": 1.3552527156068806e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.306380794351063, "policy_loss": -0.0018187094253128168, "vf_loss": 1.3081995020310084, "vf_explained_var": 0.004328015967020913, "kl": 0.002888621967492577, "entropy": 0.2824563757767753, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2415933964567052, "cur_kl_coeff": 0.03801162242889404, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1176564439894663, "policy_loss": -0.00044001131860549173, "vf_loss": 3.1180061905472365, "vf_explained_var": 0.07141501805769704, "kl": 0.002374632414546414, "entropy": 0.6629301293817147, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 268.60000000000093, "episode_reward_min": -553.8, "episode_reward_mean": 15.002999999999954, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999994, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -16.388500000000022, "predator_policy": 23.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.499999999999787, 31.400000000000176, 52.60000000000044, 39.50000000000029, -10.299999999999788, -472.20000000000005, -278.9999999999999, -236.40000000000035, 19.099999999999962, 44.500000000000384, 23.20000000000004, 18.399999999999974, 104.79999999999816, -6.199999999999731, 42.10000000000033, 0.4000000000000722, 56.200000000000394, -1.7999999999997578, -5.0999999999997705, 40.0000000000003, 32.300000000000175, -120.20000000000041, 40.0000000000003, -4.799999999999736, 19.39999999999997, 1.500000000000165, 21.600000000000005, 52.90000000000038, 103.09999999999837, 11.299999999999999, -20.499999999999538, 39.20000000000033, 49.60000000000046, -266.69999999999993, -553.8, 61.399999999999864, 89.69999999999854, -24.099999999999675, 57.10000000000051, 40.0000000000003, 73.99999999999953, 37.2000000000003, 67.80000000000004, 40.0000000000003, -75.19999999999999, 129.09999999999854, 100.29999999999822, 3.2000000000001414, 40.0000000000003, -10.000000000000108, -8.39999999999966, 40.0000000000003, 29.300000000000143, 105.69999999999843, 12.999999999999915, -191.49999999999994, 8.09999999999998, 103.89999999999873, 11.900000000000032, 48.10000000000043, -268.99999999999994, 90.7999999999999, 44.30000000000039, 40.0000000000003, -20.000000000000654, 268.60000000000093, -45.19999999999958, 62.60000000000046, 41.30000000000034, 40.0000000000003, 134.99999999999977, 195.69999999999905, -3.999999999999794, 77.59999999999934, -68.89999999999968, -25.999999999999545, 74.59999999999961, 15.599999999999925, -224.30000000000004, 94.10000000000005, 82.29999999999903, 143.89999999999898, 16.899999999999974, 143.4999999999988, 35.600000000000236, 40.0000000000003, 201.09999999999923, -24.899999999999544, -34.9999999999999, 52.60000000000051, 34.800000000000225, 54.100000000000314, -43.49999999999997, 65.50000000000021, 40.0000000000003, 174.9999999999995, 112.19999999999925, 199.79999999999922, -34.79999999999961, 66.19999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [14.599999999999968, -66.10000000000079, -97.60000000000082, 20.000000000000014, -6.399999999999979, 20.000000000000014, 3.4999999999999654, 20.000000000000014, -42.999999999999815, -43.29999999999987, -324.4, -311.8, -148.30000000000004, -279.70000000000016, -313.6000000000002, -101.80000000000004, 10.99999999999997, -19.899999999999743, -17.79999999999974, 44.30000000000024, 20.000000000000014, -59.80000000000062, -29.799999999999784, 3.1999999999999704, 47.000000000000234, 57.800000000000225, -11.199999999999855, -21.99999999999978, 19.1, 20.000000000000014, -55.60000000000011, 20.000000000000014, -24.099999999999824, 44.30000000000021, -59.80000000000062, 20.000000000000014, -47.19999999999976, -7.899999999999945, 20.000000000000014, 20.000000000000014, 5.299999999999981, 20.000000000000014, -254.50000000000006, -36.69999999999981, 20.000000000000014, 20.000000000000014, -33.699999999999754, -24.099999999999802, -34.29999999999978, 22.700000000000053, 20.000000000000014, -53.50000000000012, -18.39999999999975, 20.000000000000014, 47.00000000000024, -33.09999999999984, 62.0000000000002, 37.10000000000025, -44.499999999999794, 15.799999999999962, -57.70000000000048, -17.79999999999977, 5.299999999999972, 20.90000000000003, 23.600000000000072, 20.000000000000014, -265.59999999999997, -231.09999999999997, -400.0, -353.8, 27.200000000000138, 24.200000000000166, 58.70000000000022, 7.999999999999977, -42.99999999999984, -78.10000000000053, 20.000000000000014, 37.10000000000026, 20.000000000000014, 20.000000000000014, 35.000000000000135, 20.000000000000014, -14.799999999999836, 20.000000000000014, -9.39999999999994, 63.20000000000015, 20.000000000000014, 20.000000000000014, -226.6000000000002, 25.400000000000098, 97.39999999999935, 31.700000000000212, 41.60000000000025, 58.70000000000022, -5.199999999999955, -22.59999999999978, 20.000000000000014, 20.000000000000014, -56.499999999999964, -53.500000000000014, -72.40000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -12.699999999999829, 29.000000000000163, 76.69999999999929, -11.499999999999904, 9.49999999999998, -253.0, -101.5, 20.000000000000014, -40.89999999999978, 99.19999999999938, -13.299999999999798, -36.09999999999976, 20.000000000000014, 28.100000000000147, 20.000000000000014, -295.0, -274.0, 154.99999999999997, -173.2000000000006, -0.400000000000033, 13.69999999999997, 20.000000000000014, 20.000000000000014, -10.600000000000307, -132.39999999999992, 126.1999999999999, 142.39999999999978, -63.99999999999982, -59.200000000000415, -7.299999999999891, 56.900000000000226, 5.299999999999965, 29.000000000000163, 20.000000000000014, 20.000000000000014, -59.80000000000062, 156.8, 39.80000000000021, 155.89999999999984, 20.000000000000014, -64.00000000000004, 61.400000000000134, -47.79999999999984, -76.60000000000004, -91.30000000000078, 20.000000000000014, -106.0000000000008, -61.90000000000058, 60.500000000000185, 20.000000000000014, -51.39999999999982, -269.8, -149.50000000000003, 127.99999999999999, -82.90000000000086, 20.000000000000014, 62.30000000000015, 5.299999999999965, 131.59999999999965, -24.099999999999746, 20.000000000000014, 20.000000000000014, 123.49999999999953, 11.599999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.09999999999994, -15.699999999999843, -68.2000000000009, -21.999999999999744, -42.99999999999976, 29.000000000000163, 23.60000000000007, 6.799999999999967, 20.000000000000014, -8.800000000000013, 17.899999999999988, -366.7, 135.2, 20.000000000000014, 6.499999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.0, 39.19999999999999, 20.000000000000014, 128.59999999999985, 54.20000000000016, -82.90000000000086, -19.899999999999743, 165.19999999999982, -211.0000000000005], "policy_predator_policy_reward": [23.0, 24.0, 53.0, 56.0, 23.0, 16.0, 6.0, 10.0, 44.0, 32.0, 0.0, 164.0, 49.0, 100.0, 140.0, 39.0, 16.0, 12.0, 18.0, 0.0, 31.0, 32.0, 16.0, 29.0, 0.0, 0.0, 26.0, 1.0, 0.0, 3.0, 0.0, 36.0, 29.0, 7.0, 0.0, 38.0, 0.0, 50.0, 0.0, 0.0, 0.0, 7.0, 27.0, 144.0, 0.0, 0.0, 21.0, 32.0, 8.0, 23.0, 35.0, 0.0, 0.0, 20.0, 0.0, 39.0, 4.0, 0.0, 2.0, 38.0, 37.0, 18.0, 0.0, 13.0, 6.0, 0.0, 124.0, 106.0, 200.0, 0.0, 10.0, 0.0, 15.0, 8.0, 49.0, 48.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 32.0, 0.0, 14.0, 0.0, 0.0, 0.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 8.0, 92.0, 0.0, 44.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 15.0, 130.0, 33.0, 29.0, 0.0, 0.0, 18.0, 28.0, 0.0, 0.0, 0.0, 160.0, 140.0, 43.0, 66.0, 3.0, 28.0, 0.0, 0.0, 76.0, 47.0, 0.0, 0.0, 78.0, 0.0, 0.0, 13.0, 4.0, 3.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 0.0, 40.0, 53.0, 11.0, 0.0, 99.0, 60.0, 0.0, 37.0, 39.0, 17.0, 30.0, 66.0, 129.0, 4.0, 45.0, 0.0, 0.0, 7.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 30.0, 0.0, 0.0, 8.0, 0.0, 45.0, 0.0, 172.0, 16.0, 38.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 52.0, 0.0, 17.0, 19.0, 49.0, 33.0, 79.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3558257280595694, "mean_inference_ms": 10.03542736666062, "mean_action_processing_ms": 0.6762049412738435, "mean_env_wait_ms": 1.3389946641222041, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.044405221939086914, "StateBufferConnector_ms": 0.010791897773742676, "ViewRequirementAgentConnector_ms": 0.30441713333129883}, "num_episodes": 18, "episode_return_max": 268.60000000000093, "episode_return_min": -553.8, "episode_return_mean": 15.002999999999954, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 158.1715934829127, "num_env_steps_trained_throughput_per_sec": 158.1715934829127, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 27071.381, "restore_workers_time_ms": 0.019, "training_step_time_ms": 27071.316, "sample_time_ms": 3793.924, "learn_time_ms": 23238.948, "learn_throughput": 172.125, "synch_weights_time_ms": 32.388}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "3a355_00000", "date": "2024-08-13_02-56-18", "timestamp": 1723532178, "time_this_iter_s": 25.366991996765137, "time_total_s": 6381.93575501442, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b551a550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6381.93575501442, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 85.04166666666667, "ram_util_percent": 83.22500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.632054289844301, "cur_kl_coeff": 6.776263578034403e-22, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9915150315042527, "policy_loss": -0.001713308748153467, "vf_loss": 1.9932283414734735, "vf_explained_var": 0.0015791442028429143, "kl": 0.0027275829788411384, "entropy": 0.33443204857527264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4107542505142865, "cur_kl_coeff": 0.01900581121444702, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.379023306584232, "policy_loss": -0.0003225706792411902, "vf_loss": 3.379315494607996, "vf_explained_var": 0.0362688455632124, "kl": 0.0015987933512757529, "entropy": 0.6995239571604148, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 322.60000000000133, "episode_reward_min": -553.8, "episode_reward_mean": 35.82399999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999994, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -4.063000000000045, "predator_policy": 21.975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.799999999999736, 19.39999999999997, 1.500000000000165, 21.600000000000005, 52.90000000000038, 103.09999999999837, 11.299999999999999, -20.499999999999538, 39.20000000000033, 49.60000000000046, -266.69999999999993, -553.8, 61.399999999999864, 89.69999999999854, -24.099999999999675, 57.10000000000051, 40.0000000000003, 73.99999999999953, 37.2000000000003, 67.80000000000004, 40.0000000000003, -75.19999999999999, 129.09999999999854, 100.29999999999822, 3.2000000000001414, 40.0000000000003, -10.000000000000108, -8.39999999999966, 40.0000000000003, 29.300000000000143, 105.69999999999843, 12.999999999999915, -191.49999999999994, 8.09999999999998, 103.89999999999873, 11.900000000000032, 48.10000000000043, -268.99999999999994, 90.7999999999999, 44.30000000000039, 40.0000000000003, -20.000000000000654, 268.60000000000093, -45.19999999999958, 62.60000000000046, 41.30000000000034, 40.0000000000003, 134.99999999999977, 195.69999999999905, -3.999999999999794, 77.59999999999934, -68.89999999999968, -25.999999999999545, 74.59999999999961, 15.599999999999925, -224.30000000000004, 94.10000000000005, 82.29999999999903, 143.89999999999898, 16.899999999999974, 143.4999999999988, 35.600000000000236, 40.0000000000003, 201.09999999999923, -24.899999999999544, -34.9999999999999, 52.60000000000051, 34.800000000000225, 54.100000000000314, -43.49999999999997, 65.50000000000021, 40.0000000000003, 174.9999999999995, 112.19999999999925, 199.79999999999922, -34.79999999999961, 66.19999999999999, 40.0000000000003, 40.0000000000003, 40.0000000000003, 17.700000000000188, 137.89999999999876, 54.700000000000486, 191.69999999999902, 112.99999999999928, -27.099999999999547, 163.2999999999989, -36.4999999999998, 5.700000000000111, -198.09999999999994, -0.6000000000000827, 24.30000000000006, 169.4999999999995, 19.99999999999998, 322.60000000000133, 119.19999999999862, 40.0000000000003, 21.99999999999997, 63.799999999999535, 167.79999999999913], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-33.699999999999754, -24.099999999999802, -34.29999999999978, 22.700000000000053, 20.000000000000014, -53.50000000000012, -18.39999999999975, 20.000000000000014, 47.00000000000024, -33.09999999999984, 62.0000000000002, 37.10000000000025, -44.499999999999794, 15.799999999999962, -57.70000000000048, -17.79999999999977, 5.299999999999972, 20.90000000000003, 23.600000000000072, 20.000000000000014, -265.59999999999997, -231.09999999999997, -400.0, -353.8, 27.200000000000138, 24.200000000000166, 58.70000000000022, 7.999999999999977, -42.99999999999984, -78.10000000000053, 20.000000000000014, 37.10000000000026, 20.000000000000014, 20.000000000000014, 35.000000000000135, 20.000000000000014, -14.799999999999836, 20.000000000000014, -9.39999999999994, 63.20000000000015, 20.000000000000014, 20.000000000000014, -226.6000000000002, 25.400000000000098, 97.39999999999935, 31.700000000000212, 41.60000000000025, 58.70000000000022, -5.199999999999955, -22.59999999999978, 20.000000000000014, 20.000000000000014, -56.499999999999964, -53.500000000000014, -72.40000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -12.699999999999829, 29.000000000000163, 76.69999999999929, -11.499999999999904, 9.49999999999998, -253.0, -101.5, 20.000000000000014, -40.89999999999978, 99.19999999999938, -13.299999999999798, -36.09999999999976, 20.000000000000014, 28.100000000000147, 20.000000000000014, -295.0, -274.0, 154.99999999999997, -173.2000000000006, -0.400000000000033, 13.69999999999997, 20.000000000000014, 20.000000000000014, -10.600000000000307, -132.39999999999992, 126.1999999999999, 142.39999999999978, -63.99999999999982, -59.200000000000415, -7.299999999999891, 56.900000000000226, 5.299999999999965, 29.000000000000163, 20.000000000000014, 20.000000000000014, -59.80000000000062, 156.8, 39.80000000000021, 155.89999999999984, 20.000000000000014, -64.00000000000004, 61.400000000000134, -47.79999999999984, -76.60000000000004, -91.30000000000078, 20.000000000000014, -106.0000000000008, -61.90000000000058, 60.500000000000185, 20.000000000000014, -51.39999999999982, -269.8, -149.50000000000003, 127.99999999999999, -82.90000000000086, 20.000000000000014, 62.30000000000015, 5.299999999999965, 131.59999999999965, -24.099999999999746, 20.000000000000014, 20.000000000000014, 123.49999999999953, 11.599999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.09999999999994, -15.699999999999843, -68.2000000000009, -21.999999999999744, -42.99999999999976, 29.000000000000163, 23.60000000000007, 6.799999999999967, 20.000000000000014, -8.800000000000013, 17.899999999999988, -366.7, 135.2, 20.000000000000014, 6.499999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.0, 39.19999999999999, 20.000000000000014, 128.59999999999985, 54.20000000000016, -82.90000000000086, -19.899999999999743, 165.19999999999982, -211.0000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999981, -49.60000000000019, 20.000000000000014, 116.8999999999995, 22.700000000000067, 20.000000000000014, 32.90000000000023, 156.79999999999978, 83.59999999999972, 25.400000000000098, -108.10000000000079, 20.000000000000014, 143.29999999999964, 20.000000000000014, -145.90000000000057, 13.399999999999974, 27.20000000000013, -71.5000000000005, -324.4, -93.70000000000013, -87.1000000000004, 9.499999999999977, 25.70000000000011, -30.39999999999977, 170.3, -59.80000000000035, 13.699999999999946, -15.699999999999761, 158.5999999999999, 163.99999999999977, 99.19999999999936, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.0, 20.000000000000014, 62.89999999999992, -87.10000000000082, 147.79999999999978, 20.000000000000014], "policy_predator_policy_reward": [21.0, 32.0, 8.0, 23.0, 35.0, 0.0, 0.0, 20.0, 0.0, 39.0, 4.0, 0.0, 2.0, 38.0, 37.0, 18.0, 0.0, 13.0, 6.0, 0.0, 124.0, 106.0, 200.0, 0.0, 10.0, 0.0, 15.0, 8.0, 49.0, 48.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 32.0, 0.0, 14.0, 0.0, 0.0, 0.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 8.0, 92.0, 0.0, 44.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 15.0, 130.0, 33.0, 29.0, 0.0, 0.0, 18.0, 28.0, 0.0, 0.0, 0.0, 160.0, 140.0, 43.0, 66.0, 3.0, 28.0, 0.0, 0.0, 76.0, 47.0, 0.0, 0.0, 78.0, 0.0, 0.0, 13.0, 4.0, 3.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 0.0, 40.0, 53.0, 11.0, 0.0, 99.0, 60.0, 0.0, 37.0, 39.0, 17.0, 30.0, 66.0, 129.0, 4.0, 45.0, 0.0, 0.0, 7.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 30.0, 0.0, 0.0, 8.0, 0.0, 45.0, 0.0, 172.0, 16.0, 38.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 52.0, 0.0, 17.0, 19.0, 49.0, 33.0, 79.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 55.0, 0.0, 1.0, 12.0, 0.0, 0.0, 2.0, 4.0, 0.0, 61.0, 0.0, 0.0, 0.0, 0.0, 96.0, 50.0, 0.0, 56.0, 164.0, 39.0, 38.0, 2.0, 27.0, 21.0, 38.0, 5.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 85.0, 51.0, 37.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.352029150344751, "mean_inference_ms": 9.908167201703286, "mean_action_processing_ms": 0.677519203986147, "mean_env_wait_ms": 1.3964422870408386, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03239703178405762, "StateBufferConnector_ms": 0.01304781436920166, "ViewRequirementAgentConnector_ms": 0.3022381067276001}, "num_episodes": 23, "episode_return_max": 322.60000000000133, "episode_return_min": -553.8, "episode_return_mean": 35.82399999999991, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 164.37239802368077, "num_env_steps_trained_throughput_per_sec": 164.37239802368077, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 26810.782, "restore_workers_time_ms": 0.019, "training_step_time_ms": 26810.712, "sample_time_ms": 3897.364, "learn_time_ms": 22868.791, "learn_throughput": 174.911, "synch_weights_time_ms": 36.467}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": false, "training_iteration": 100, "trial_id": "3a355_00000", "date": "2024-08-13_02-56-43", "timestamp": 1723532203, "time_this_iter_s": 24.43653106689453, "time_total_s": 6406.372286081314, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52393a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6406.372286081314, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 83.86285714285714, "ram_util_percent": 83.21428571428572}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5094194235802485, "cur_kl_coeff": 3.3881317890172015e-22, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2532506703384338, "policy_loss": -0.0007061305135567352, "vf_loss": 1.2539568013142026, "vf_explained_var": 0.001361389229537318, "kl": 0.0017365758493115035, "entropy": 0.3465641066983894, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 189945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0449285160966966, "cur_kl_coeff": 0.00950290560722351, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3696437696931225, "policy_loss": -0.0012274522641082368, "vf_loss": 2.370839711566451, "vf_explained_var": 0.02542360992658706, "kl": 0.0033163435090727495, "entropy": 0.7135533772763751, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 189945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000}, "env_runners": {"episode_reward_max": 322.60000000000133, "episode_reward_min": -268.99999999999994, "episode_reward_mean": 48.04299999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999994, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": 3.6964999999999235, "predator_policy": 20.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.2000000000003, 67.80000000000004, 40.0000000000003, -75.19999999999999, 129.09999999999854, 100.29999999999822, 3.2000000000001414, 40.0000000000003, -10.000000000000108, -8.39999999999966, 40.0000000000003, 29.300000000000143, 105.69999999999843, 12.999999999999915, -191.49999999999994, 8.09999999999998, 103.89999999999873, 11.900000000000032, 48.10000000000043, -268.99999999999994, 90.7999999999999, 44.30000000000039, 40.0000000000003, -20.000000000000654, 268.60000000000093, -45.19999999999958, 62.60000000000046, 41.30000000000034, 40.0000000000003, 134.99999999999977, 195.69999999999905, -3.999999999999794, 77.59999999999934, -68.89999999999968, -25.999999999999545, 74.59999999999961, 15.599999999999925, -224.30000000000004, 94.10000000000005, 82.29999999999903, 143.89999999999898, 16.899999999999974, 143.4999999999988, 35.600000000000236, 40.0000000000003, 201.09999999999923, -24.899999999999544, -34.9999999999999, 52.60000000000051, 34.800000000000225, 54.100000000000314, -43.49999999999997, 65.50000000000021, 40.0000000000003, 174.9999999999995, 112.19999999999925, 199.79999999999922, -34.79999999999961, 66.19999999999999, 40.0000000000003, 40.0000000000003, 40.0000000000003, 17.700000000000188, 137.89999999999876, 54.700000000000486, 191.69999999999902, 112.99999999999928, -27.099999999999547, 163.2999999999989, -36.4999999999998, 5.700000000000111, -198.09999999999994, -0.6000000000000827, 24.30000000000006, 169.4999999999995, 19.99999999999998, 322.60000000000133, 119.19999999999862, 40.0000000000003, 21.99999999999997, 63.799999999999535, 167.79999999999913, 112.39999999999893, 5.599999999999943, 40.0000000000003, 40.0000000000003, 32.40000000000019, 40.0000000000003, 138.99999999999923, -43.599999999999746, 149.79999999999902, 40.0000000000003, 20.499999999999986, 195.69999999999922, -2.899999999999716, -20.59999999999951, 30.100000000000147, 142.5999999999987, 215.29999999999902, -163.50000000000054], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-14.799999999999836, 20.000000000000014, -9.39999999999994, 63.20000000000015, 20.000000000000014, 20.000000000000014, -226.6000000000002, 25.400000000000098, 97.39999999999935, 31.700000000000212, 41.60000000000025, 58.70000000000022, -5.199999999999955, -22.59999999999978, 20.000000000000014, 20.000000000000014, -56.499999999999964, -53.500000000000014, -72.40000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -12.699999999999829, 29.000000000000163, 76.69999999999929, -11.499999999999904, 9.49999999999998, -253.0, -101.5, 20.000000000000014, -40.89999999999978, 99.19999999999938, -13.299999999999798, -36.09999999999976, 20.000000000000014, 28.100000000000147, 20.000000000000014, -295.0, -274.0, 154.99999999999997, -173.2000000000006, -0.400000000000033, 13.69999999999997, 20.000000000000014, 20.000000000000014, -10.600000000000307, -132.39999999999992, 126.1999999999999, 142.39999999999978, -63.99999999999982, -59.200000000000415, -7.299999999999891, 56.900000000000226, 5.299999999999965, 29.000000000000163, 20.000000000000014, 20.000000000000014, -59.80000000000062, 156.8, 39.80000000000021, 155.89999999999984, 20.000000000000014, -64.00000000000004, 61.400000000000134, -47.79999999999984, -76.60000000000004, -91.30000000000078, 20.000000000000014, -106.0000000000008, -61.90000000000058, 60.500000000000185, 20.000000000000014, -51.39999999999982, -269.8, -149.50000000000003, 127.99999999999999, -82.90000000000086, 20.000000000000014, 62.30000000000015, 5.299999999999965, 131.59999999999965, -24.099999999999746, 20.000000000000014, 20.000000000000014, 123.49999999999953, 11.599999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.09999999999994, -15.699999999999843, -68.2000000000009, -21.999999999999744, -42.99999999999976, 29.000000000000163, 23.60000000000007, 6.799999999999967, 20.000000000000014, -8.800000000000013, 17.899999999999988, -366.7, 135.2, 20.000000000000014, 6.499999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.0, 39.19999999999999, 20.000000000000014, 128.59999999999985, 54.20000000000016, -82.90000000000086, -19.899999999999743, 165.19999999999982, -211.0000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999981, -49.60000000000019, 20.000000000000014, 116.8999999999995, 22.700000000000067, 20.000000000000014, 32.90000000000023, 156.79999999999978, 83.59999999999972, 25.400000000000098, -108.10000000000079, 20.000000000000014, 143.29999999999964, 20.000000000000014, -145.90000000000057, 13.399999999999974, 27.20000000000013, -71.5000000000005, -324.4, -93.70000000000013, -87.1000000000004, 9.499999999999977, 25.70000000000011, -30.39999999999977, 170.3, -59.80000000000035, 13.699999999999946, -15.699999999999761, 158.5999999999999, 163.99999999999977, 99.19999999999936, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.0, 20.000000000000014, 62.89999999999992, -87.10000000000082, 147.79999999999978, 20.000000000000014, 76.39999999999952, 20.000000000000014, -93.40000000000049, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999686, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.99999999999973, -172.60000000000025, 20.000000000000014, 129.79999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -20.49999999999975, 20.000000000000014, 175.6999999999999, 20.000000000000014, -47.19999999999976, 5.299999999999965, -5.1999999999999265, -72.40000000000089, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 115.39999999999947, 88.99999999999932, 125.2999999999997, 20.000000000000014, -368.5], "policy_predator_policy_reward": [32.0, 0.0, 14.0, 0.0, 0.0, 0.0, 86.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 8.0, 92.0, 0.0, 44.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 15.0, 130.0, 33.0, 29.0, 0.0, 0.0, 18.0, 28.0, 0.0, 0.0, 0.0, 160.0, 140.0, 43.0, 66.0, 3.0, 28.0, 0.0, 0.0, 76.0, 47.0, 0.0, 0.0, 78.0, 0.0, 0.0, 13.0, 4.0, 3.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 0.0, 40.0, 53.0, 11.0, 0.0, 99.0, 60.0, 0.0, 37.0, 39.0, 17.0, 30.0, 66.0, 129.0, 4.0, 45.0, 0.0, 0.0, 7.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 30.0, 0.0, 0.0, 8.0, 0.0, 45.0, 0.0, 172.0, 16.0, 38.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 52.0, 0.0, 17.0, 19.0, 49.0, 33.0, 79.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 55.0, 0.0, 1.0, 12.0, 0.0, 0.0, 2.0, 4.0, 0.0, 61.0, 0.0, 0.0, 0.0, 0.0, 96.0, 50.0, 0.0, 56.0, 164.0, 39.0, 38.0, 2.0, 27.0, 21.0, 38.0, 5.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 85.0, 51.0, 37.0, 0.0, 0.0, 16.0, 0.0, 40.0, 39.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 18.0, 0.0, 48.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 32.0, 7.0, 44.0, 13.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 185.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.349396442264794, "mean_inference_ms": 9.945385930805369, "mean_action_processing_ms": 0.6792255064724765, "mean_env_wait_ms": 1.323435985125235, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.031929731369018555, "StateBufferConnector_ms": 0.013213276863098145, "ViewRequirementAgentConnector_ms": 0.36160778999328613}, "num_episodes": 18, "episode_return_max": 322.60000000000133, "episode_return_min": -268.99999999999994, "episode_return_mean": 48.04299999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000, "num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 160.08556972596713, "num_env_steps_trained_throughput_per_sec": 160.08556972596713, "timesteps_total": 404000, "num_env_steps_sampled_lifetime": 404000, "num_agent_steps_sampled_lifetime": 1616000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1616000, "timers": {"training_iteration_time_ms": 26599.297, "restore_workers_time_ms": 0.02, "training_step_time_ms": 26599.224, "sample_time_ms": 4176.82, "learn_time_ms": 22373.33, "learn_throughput": 178.784, "synch_weights_time_ms": 41.167}, "counters": {"num_env_steps_sampled": 404000, "num_env_steps_trained": 404000, "num_agent_steps_sampled": 1616000, "num_agent_steps_trained": 1616000}, "done": false, "training_iteration": 101, "trial_id": "3a355_00000", "date": "2024-08-13_02-57-08", "timestamp": 1723532228, "time_this_iter_s": 25.682470083236694, "time_total_s": 6432.054756164551, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52deaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6432.054756164551, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 83.29444444444445, "ram_util_percent": 82.97222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7092892635909338, "cur_kl_coeff": 1.6940658945086008e-22, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.495381286661461, "policy_loss": -0.0013104665268054872, "vf_loss": 3.4966917561475563, "vf_explained_var": 0.0012550916936662463, "kl": 0.0019878760240164385, "entropy": 0.38532414828974104, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 191835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4036197548781437, "cur_kl_coeff": 0.004751452803611755, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.13857863012445, "policy_loss": -0.0006653764122535312, "vf_loss": 4.139225376472272, "vf_explained_var": -0.006203661046961628, "kl": 0.003923974670292954, "entropy": 0.6391524859206387, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 191835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000}, "env_runners": {"episode_reward_max": 322.60000000000133, "episode_reward_min": -268.99999999999994, "episode_reward_mean": 52.99599999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999994, "predator_policy": 185.0}, "policy_reward_mean": {"prey_policy": 3.442999999999918, "predator_policy": 23.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [48.10000000000043, -268.99999999999994, 90.7999999999999, 44.30000000000039, 40.0000000000003, -20.000000000000654, 268.60000000000093, -45.19999999999958, 62.60000000000046, 41.30000000000034, 40.0000000000003, 134.99999999999977, 195.69999999999905, -3.999999999999794, 77.59999999999934, -68.89999999999968, -25.999999999999545, 74.59999999999961, 15.599999999999925, -224.30000000000004, 94.10000000000005, 82.29999999999903, 143.89999999999898, 16.899999999999974, 143.4999999999988, 35.600000000000236, 40.0000000000003, 201.09999999999923, -24.899999999999544, -34.9999999999999, 52.60000000000051, 34.800000000000225, 54.100000000000314, -43.49999999999997, 65.50000000000021, 40.0000000000003, 174.9999999999995, 112.19999999999925, 199.79999999999922, -34.79999999999961, 66.19999999999999, 40.0000000000003, 40.0000000000003, 40.0000000000003, 17.700000000000188, 137.89999999999876, 54.700000000000486, 191.69999999999902, 112.99999999999928, -27.099999999999547, 163.2999999999989, -36.4999999999998, 5.700000000000111, -198.09999999999994, -0.6000000000000827, 24.30000000000006, 169.4999999999995, 19.99999999999998, 322.60000000000133, 119.19999999999862, 40.0000000000003, 21.99999999999997, 63.799999999999535, 167.79999999999913, 112.39999999999893, 5.599999999999943, 40.0000000000003, 40.0000000000003, 32.40000000000019, 40.0000000000003, 138.99999999999923, -43.599999999999746, 149.79999999999902, 40.0000000000003, 20.499999999999986, 195.69999999999922, -2.899999999999716, -20.59999999999951, 30.100000000000147, 142.5999999999987, 215.29999999999902, -163.50000000000054, 88.69999999999868, 40.0000000000003, 109.59999999999877, 201.0999999999992, 70.59999999999992, -23.400000000000034, -105.20000000000138, 23.900000000000123, 117.49999999999989, 114.69999999999877, 40.0000000000003, 13.599999999999962, 65.79999999999974, 14.89999999999989, -20.300000000000026, 40.0000000000003, 29.69999999999991, 118.49999999999918], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [28.100000000000147, 20.000000000000014, -295.0, -274.0, 154.99999999999997, -173.2000000000006, -0.400000000000033, 13.69999999999997, 20.000000000000014, 20.000000000000014, -10.600000000000307, -132.39999999999992, 126.1999999999999, 142.39999999999978, -63.99999999999982, -59.200000000000415, -7.299999999999891, 56.900000000000226, 5.299999999999965, 29.000000000000163, 20.000000000000014, 20.000000000000014, -59.80000000000062, 156.8, 39.80000000000021, 155.89999999999984, 20.000000000000014, -64.00000000000004, 61.400000000000134, -47.79999999999984, -76.60000000000004, -91.30000000000078, 20.000000000000014, -106.0000000000008, -61.90000000000058, 60.500000000000185, 20.000000000000014, -51.39999999999982, -269.8, -149.50000000000003, 127.99999999999999, -82.90000000000086, 20.000000000000014, 62.30000000000015, 5.299999999999965, 131.59999999999965, -24.099999999999746, 20.000000000000014, 20.000000000000014, 123.49999999999953, 11.599999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.09999999999994, -15.699999999999843, -68.2000000000009, -21.999999999999744, -42.99999999999976, 29.000000000000163, 23.60000000000007, 6.799999999999967, 20.000000000000014, -8.800000000000013, 17.899999999999988, -366.7, 135.2, 20.000000000000014, 6.499999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.0, 39.19999999999999, 20.000000000000014, 128.59999999999985, 54.20000000000016, -82.90000000000086, -19.899999999999743, 165.19999999999982, -211.0000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999981, -49.60000000000019, 20.000000000000014, 116.8999999999995, 22.700000000000067, 20.000000000000014, 32.90000000000023, 156.79999999999978, 83.59999999999972, 25.400000000000098, -108.10000000000079, 20.000000000000014, 143.29999999999964, 20.000000000000014, -145.90000000000057, 13.399999999999974, 27.20000000000013, -71.5000000000005, -324.4, -93.70000000000013, -87.1000000000004, 9.499999999999977, 25.70000000000011, -30.39999999999977, 170.3, -59.80000000000035, 13.699999999999946, -15.699999999999761, 158.5999999999999, 163.99999999999977, 99.19999999999936, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.0, 20.000000000000014, 62.89999999999992, -87.10000000000082, 147.79999999999978, 20.000000000000014, 76.39999999999952, 20.000000000000014, -93.40000000000049, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999686, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.99999999999973, -172.60000000000025, 20.000000000000014, 129.79999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -20.49999999999975, 20.000000000000014, 175.6999999999999, 20.000000000000014, -47.19999999999976, 5.299999999999965, -5.1999999999999265, -72.40000000000089, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 115.39999999999947, 88.99999999999932, 125.2999999999997, 20.000000000000014, -368.5, 64.70000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 88.09999999999943, 181.0999999999999, 20.000000000000014, 50.600000000000186, 20.000000000000014, -162.40000000000003, 20.000000000000014, -28.29999999999975, -208.90000000000052, 20.000000000000014, -96.1000000000005, -253.0, 159.4999999999999, 74.89999999999942, 3.800000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, -30.39999999999977, 29.600000000000023, -86.80000000000024, 20.000000000000014, -81.10000000000001, -206.80000000000027, 63.49999999999986, 20.000000000000014, 20.000000000000014, -78.70000000000007, -55.59999999999994, 51.800000000000026, 22.700000000000063], "policy_predator_policy_reward": [0.0, 0.0, 160.0, 140.0, 43.0, 66.0, 3.0, 28.0, 0.0, 0.0, 76.0, 47.0, 0.0, 0.0, 78.0, 0.0, 0.0, 13.0, 4.0, 3.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 0.0, 40.0, 53.0, 11.0, 0.0, 99.0, 60.0, 0.0, 37.0, 39.0, 17.0, 30.0, 66.0, 129.0, 4.0, 45.0, 0.0, 0.0, 7.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 30.0, 0.0, 0.0, 8.0, 0.0, 45.0, 0.0, 172.0, 16.0, 38.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 52.0, 0.0, 17.0, 19.0, 49.0, 33.0, 79.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 55.0, 0.0, 1.0, 12.0, 0.0, 0.0, 2.0, 4.0, 0.0, 61.0, 0.0, 0.0, 0.0, 0.0, 96.0, 50.0, 0.0, 56.0, 164.0, 39.0, 38.0, 2.0, 27.0, 21.0, 38.0, 5.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 85.0, 51.0, 37.0, 0.0, 0.0, 16.0, 0.0, 40.0, 39.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 18.0, 0.0, 48.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 32.0, 7.0, 44.0, 13.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 185.0, 0.0, 4.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 29.0, 90.0, 65.0, 67.0, 52.0, 48.0, 69.0, 142.0, 36.0, 0.0, 0.0, 0.0, 0.0, 24.0, 56.0, 67.0, 76.0, 0.0, 0.0, 123.0, 0.0, 0.0, 59.0, 105.0, 44.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.350873599236375, "mean_inference_ms": 9.920926138413366, "mean_action_processing_ms": 0.6829873840500537, "mean_env_wait_ms": 1.3193364729662167, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03176259994506836, "StateBufferConnector_ms": 0.013238310813903809, "ViewRequirementAgentConnector_ms": 0.3825511932373047}, "num_episodes": 18, "episode_return_max": 322.60000000000133, "episode_return_min": -268.99999999999994, "episode_return_mean": 52.99599999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000, "num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 147.62889419541608, "num_env_steps_trained_throughput_per_sec": 147.62889419541608, "timesteps_total": 408000, "num_env_steps_sampled_lifetime": 408000, "num_agent_steps_sampled_lifetime": 1632000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1632000, "timers": {"training_iteration_time_ms": 26316.181, "restore_workers_time_ms": 0.043, "training_step_time_ms": 26316.071, "sample_time_ms": 4664.106, "learn_time_ms": 21603.303, "learn_throughput": 185.157, "synch_weights_time_ms": 40.539}, "counters": {"num_env_steps_sampled": 408000, "num_env_steps_trained": 408000, "num_agent_steps_sampled": 1632000, "num_agent_steps_trained": 1632000}, "done": false, "training_iteration": 102, "trial_id": "3a355_00000", "date": "2024-08-13_02-57-36", "timestamp": 1723532256, "time_this_iter_s": 27.17276096343994, "time_total_s": 6459.227517127991, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d519d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6459.227517127991, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 84.82631578947367, "ram_util_percent": 83.48684210526316}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7926418773790516, "cur_kl_coeff": 8.470329472543004e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9572142231401313, "policy_loss": -0.0040817628628155465, "vf_loss": 2.961295991158359, "vf_explained_var": 0.0028357215028591257, "kl": 0.007407059186202469, "entropy": 0.40228071026701145, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 193725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1556876694044425, "cur_kl_coeff": 0.0023757264018058775, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.801172288385018, "policy_loss": -0.0007650021441458236, "vf_loss": 3.8019314762145755, "vf_explained_var": -0.0009947889380984836, "kl": 0.0024480433052903273, "entropy": 0.699446216336003, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 193725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000}, "env_runners": {"episode_reward_max": 322.60000000000133, "episode_reward_min": -198.09999999999994, "episode_reward_mean": 59.56699999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.09999999999994, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": 8.088499999999918, "predator_policy": 21.695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [143.89999999999898, 16.899999999999974, 143.4999999999988, 35.600000000000236, 40.0000000000003, 201.09999999999923, -24.899999999999544, -34.9999999999999, 52.60000000000051, 34.800000000000225, 54.100000000000314, -43.49999999999997, 65.50000000000021, 40.0000000000003, 174.9999999999995, 112.19999999999925, 199.79999999999922, -34.79999999999961, 66.19999999999999, 40.0000000000003, 40.0000000000003, 40.0000000000003, 17.700000000000188, 137.89999999999876, 54.700000000000486, 191.69999999999902, 112.99999999999928, -27.099999999999547, 163.2999999999989, -36.4999999999998, 5.700000000000111, -198.09999999999994, -0.6000000000000827, 24.30000000000006, 169.4999999999995, 19.99999999999998, 322.60000000000133, 119.19999999999862, 40.0000000000003, 21.99999999999997, 63.799999999999535, 167.79999999999913, 112.39999999999893, 5.599999999999943, 40.0000000000003, 40.0000000000003, 32.40000000000019, 40.0000000000003, 138.99999999999923, -43.599999999999746, 149.79999999999902, 40.0000000000003, 20.499999999999986, 195.69999999999922, -2.899999999999716, -20.59999999999951, 30.100000000000147, 142.5999999999987, 215.29999999999902, -163.50000000000054, 88.69999999999868, 40.0000000000003, 109.59999999999877, 201.0999999999992, 70.59999999999992, -23.400000000000034, -105.20000000000138, 23.900000000000123, 117.49999999999989, 114.69999999999877, 40.0000000000003, 13.599999999999962, 65.79999999999974, 14.89999999999989, -20.300000000000026, 40.0000000000003, 29.69999999999991, 118.49999999999918, 40.0000000000003, 135.1999999999992, 67.00000000000028, -114.10000000000025, 27.900000000000283, 40.0000000000003, 14.299999999999946, 191.19999999999908, 5.0000000000000515, 94.99999999999864, 84.19999999999914, 34.200000000000216, -104.20000000000076, 161.39999999999952, 187.09999999999926, 149.8999999999994, 113.19999999999888, 35.600000000000236, 16.49999999999998, 35.60000000000022, 46.50000000000005, 48.800000000000416], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [5.299999999999965, 131.59999999999965, -24.099999999999746, 20.000000000000014, 20.000000000000014, 123.49999999999953, 11.599999999999968, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 181.09999999999994, -15.699999999999843, -68.2000000000009, -21.999999999999744, -42.99999999999976, 29.000000000000163, 23.60000000000007, 6.799999999999967, 20.000000000000014, -8.800000000000013, 17.899999999999988, -366.7, 135.2, 20.000000000000014, 6.499999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.0, 39.19999999999999, 20.000000000000014, 128.59999999999985, 54.20000000000016, -82.90000000000086, -19.899999999999743, 165.19999999999982, -211.0000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999981, -49.60000000000019, 20.000000000000014, 116.8999999999995, 22.700000000000067, 20.000000000000014, 32.90000000000023, 156.79999999999978, 83.59999999999972, 25.400000000000098, -108.10000000000079, 20.000000000000014, 143.29999999999964, 20.000000000000014, -145.90000000000057, 13.399999999999974, 27.20000000000013, -71.5000000000005, -324.4, -93.70000000000013, -87.1000000000004, 9.499999999999977, 25.70000000000011, -30.39999999999977, 170.3, -59.80000000000035, 13.699999999999946, -15.699999999999761, 158.5999999999999, 163.99999999999977, 99.19999999999936, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.0, 20.000000000000014, 62.89999999999992, -87.10000000000082, 147.79999999999978, 20.000000000000014, 76.39999999999952, 20.000000000000014, -93.40000000000049, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999686, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.99999999999973, -172.60000000000025, 20.000000000000014, 129.79999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -20.49999999999975, 20.000000000000014, 175.6999999999999, 20.000000000000014, -47.19999999999976, 5.299999999999965, -5.1999999999999265, -72.40000000000089, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 115.39999999999947, 88.99999999999932, 125.2999999999997, 20.000000000000014, -368.5, 64.70000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 88.09999999999943, 181.0999999999999, 20.000000000000014, 50.600000000000186, 20.000000000000014, -162.40000000000003, 20.000000000000014, -28.29999999999975, -208.90000000000052, 20.000000000000014, -96.1000000000005, -253.0, 159.4999999999999, 74.89999999999942, 3.800000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, -30.39999999999977, 29.600000000000023, -86.80000000000024, 20.000000000000014, -81.10000000000001, -206.80000000000027, 63.49999999999986, 20.000000000000014, 20.000000000000014, -78.70000000000007, -55.59999999999994, 51.800000000000026, 22.700000000000063, 20.000000000000014, 20.000000000000014, 43.39999999999998, 36.799999999999784, 33.500000000000114, 33.50000000000024, 74.89999999999942, -379.0, 20.000000000000014, -3.1000000000000014, 20.000000000000014, 20.000000000000014, -76.60000000000082, 29.900000000000198, 170.2999999999998, 20.90000000000003, -100.00000000000028, 20.000000000000014, -7.300000000000004, 89.2999999999993, 27.50000000000005, -7.2999999999999226, 15.799999999999962, 7.399999999999965, -169.00000000000048, -152.20000000000027, 20.000000000000014, 127.40000000000003, 20.000000000000014, 151.1, 130.09999999999988, 15.799999999999963, 72.19999999999959, 20.000000000000014, 11.599999999999966, 20.000000000000014, -0.7000000000000365, -110.80000000000061, 11.599999999999977, 20.000000000000014, -226.0, 132.49999999999977, 20.000000000000014, 9.799999999999981], "policy_predator_policy_reward": [7.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 30.0, 0.0, 0.0, 8.0, 0.0, 45.0, 0.0, 172.0, 16.0, 38.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 52.0, 0.0, 17.0, 19.0, 49.0, 33.0, 79.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 55.0, 0.0, 1.0, 12.0, 0.0, 0.0, 2.0, 4.0, 0.0, 61.0, 0.0, 0.0, 0.0, 0.0, 96.0, 50.0, 0.0, 56.0, 164.0, 39.0, 38.0, 2.0, 27.0, 21.0, 38.0, 5.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 85.0, 51.0, 37.0, 0.0, 0.0, 16.0, 0.0, 40.0, 39.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 18.0, 0.0, 48.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 32.0, 7.0, 44.0, 13.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 185.0, 0.0, 4.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 29.0, 90.0, 65.0, 67.0, 52.0, 48.0, 69.0, 142.0, 36.0, 0.0, 0.0, 0.0, 0.0, 24.0, 56.0, 67.0, 76.0, 0.0, 0.0, 123.0, 0.0, 0.0, 59.0, 105.0, 44.0, 0.0, 0.0, 0.0, 43.0, 12.0, 0.0, 0.0, 190.0, 0.0, 11.0, 0.0, 0.0, 0.0, 46.0, 15.0, 0.0, 0.0, 0.0, 85.0, 13.0, 0.0, 60.0, 4.0, 5.0, 6.0, 132.0, 85.0, 0.0, 14.0, 0.0, 16.0, 2.0, 2.0, 16.0, 5.0, 0.0, 4.0, 67.0, 61.0, 0.0, 4.0, 129.0, 11.0, 19.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3557816650927235, "mean_inference_ms": 9.904038424930011, "mean_action_processing_ms": 0.6886503295451095, "mean_env_wait_ms": 1.317343962984016, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03474438190460205, "StateBufferConnector_ms": 0.014998793601989746, "ViewRequirementAgentConnector_ms": 0.44518017768859863}, "num_episodes": 22, "episode_return_max": 322.60000000000133, "episode_return_min": -198.09999999999994, "episode_return_mean": 59.56699999999978, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000, "num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 147.4831636910532, "num_env_steps_trained_throughput_per_sec": 147.4831636910532, "timesteps_total": 412000, "num_env_steps_sampled_lifetime": 412000, "num_agent_steps_sampled_lifetime": 1648000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1648000, "timers": {"training_iteration_time_ms": 26285.372, "restore_workers_time_ms": 0.043, "training_step_time_ms": 26285.263, "sample_time_ms": 5065.435, "learn_time_ms": 21171.886, "learn_throughput": 188.93, "synch_weights_time_ms": 40.58}, "counters": {"num_env_steps_sampled": 412000, "num_env_steps_trained": 412000, "num_agent_steps_sampled": 1648000, "num_agent_steps_trained": 1648000}, "done": false, "training_iteration": 103, "trial_id": "3a355_00000", "date": "2024-08-13_02-58-03", "timestamp": 1723532283, "time_this_iter_s": 27.201183080673218, "time_total_s": 6486.428700208664, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5267310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6486.428700208664, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 85.18205128205128, "ram_util_percent": 83.12820512820515}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8555575716195913, "cur_kl_coeff": 8.470329472543004e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.056183924372234, "policy_loss": -0.002711060965216901, "vf_loss": 3.0588949836120403, "vf_explained_var": 0.003049469751025003, "kl": 0.006341753694997057, "entropy": 0.4461848421702309, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 195615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3599857947143612, "cur_kl_coeff": 0.0011878632009029388, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.352417569564133, "policy_loss": -0.002242867952636468, "vf_loss": 4.35465280479855, "vf_explained_var": 0.025144082276278703, "kl": 0.006440173534076023, "entropy": 0.6703459680395782, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 195615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000}, "env_runners": {"episode_reward_max": 322.60000000000133, "episode_reward_min": -198.09999999999994, "episode_reward_mean": 54.91799999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -379.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.0999999999999, "predator_policy": 190.0}, "policy_reward_mean": {"prey_policy": 1.768999999999895, "predator_policy": 25.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [66.19999999999999, 40.0000000000003, 40.0000000000003, 40.0000000000003, 17.700000000000188, 137.89999999999876, 54.700000000000486, 191.69999999999902, 112.99999999999928, -27.099999999999547, 163.2999999999989, -36.4999999999998, 5.700000000000111, -198.09999999999994, -0.6000000000000827, 24.30000000000006, 169.4999999999995, 19.99999999999998, 322.60000000000133, 119.19999999999862, 40.0000000000003, 21.99999999999997, 63.799999999999535, 167.79999999999913, 112.39999999999893, 5.599999999999943, 40.0000000000003, 40.0000000000003, 32.40000000000019, 40.0000000000003, 138.99999999999923, -43.599999999999746, 149.79999999999902, 40.0000000000003, 20.499999999999986, 195.69999999999922, -2.899999999999716, -20.59999999999951, 30.100000000000147, 142.5999999999987, 215.29999999999902, -163.50000000000054, 88.69999999999868, 40.0000000000003, 109.59999999999877, 201.0999999999992, 70.59999999999992, -23.400000000000034, -105.20000000000138, 23.900000000000123, 117.49999999999989, 114.69999999999877, 40.0000000000003, 13.599999999999962, 65.79999999999974, 14.89999999999989, -20.300000000000026, 40.0000000000003, 29.69999999999991, 118.49999999999918, 40.0000000000003, 135.1999999999992, 67.00000000000028, -114.10000000000025, 27.900000000000283, 40.0000000000003, 14.299999999999946, 191.19999999999908, 5.0000000000000515, 94.99999999999864, 84.19999999999914, 34.200000000000216, -104.20000000000076, 161.39999999999952, 187.09999999999926, 149.8999999999994, 113.19999999999888, 35.600000000000236, 16.49999999999998, 35.60000000000022, 46.50000000000005, 48.800000000000416, 64.10000000000035, 40.0000000000003, 34.50000000000022, 91.29999999999852, 65.10000000000002, 54.00000000000015, 71.39999999999962, 40.0000000000003, -94.20000000000095, 32.300000000000196, -98.10000000000005, 238.89999999999958, -68.90000000000103, -3.599999999999918, -74.40000000000006, 18.600000000000062, 194.7999999999994, 106.0999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [165.19999999999982, -211.0000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999981, -49.60000000000019, 20.000000000000014, 116.8999999999995, 22.700000000000067, 20.000000000000014, 32.90000000000023, 156.79999999999978, 83.59999999999972, 25.400000000000098, -108.10000000000079, 20.000000000000014, 143.29999999999964, 20.000000000000014, -145.90000000000057, 13.399999999999974, 27.20000000000013, -71.5000000000005, -324.4, -93.70000000000013, -87.1000000000004, 9.499999999999977, 25.70000000000011, -30.39999999999977, 170.3, -59.80000000000035, 13.699999999999946, -15.699999999999761, 158.5999999999999, 163.99999999999977, 99.19999999999936, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.0, 20.000000000000014, 62.89999999999992, -87.10000000000082, 147.79999999999978, 20.000000000000014, 76.39999999999952, 20.000000000000014, -93.40000000000049, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999686, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.99999999999973, -172.60000000000025, 20.000000000000014, 129.79999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -20.49999999999975, 20.000000000000014, 175.6999999999999, 20.000000000000014, -47.19999999999976, 5.299999999999965, -5.1999999999999265, -72.40000000000089, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 115.39999999999947, 88.99999999999932, 125.2999999999997, 20.000000000000014, -368.5, 64.70000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 88.09999999999943, 181.0999999999999, 20.000000000000014, 50.600000000000186, 20.000000000000014, -162.40000000000003, 20.000000000000014, -28.29999999999975, -208.90000000000052, 20.000000000000014, -96.1000000000005, -253.0, 159.4999999999999, 74.89999999999942, 3.800000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, -30.39999999999977, 29.600000000000023, -86.80000000000024, 20.000000000000014, -81.10000000000001, -206.80000000000027, 63.49999999999986, 20.000000000000014, 20.000000000000014, -78.70000000000007, -55.59999999999994, 51.800000000000026, 22.700000000000063, 20.000000000000014, 20.000000000000014, 43.39999999999998, 36.799999999999784, 33.500000000000114, 33.50000000000024, 74.89999999999942, -379.0, 20.000000000000014, -3.1000000000000014, 20.000000000000014, 20.000000000000014, -76.60000000000082, 29.900000000000198, 170.2999999999998, 20.90000000000003, -100.00000000000028, 20.000000000000014, -7.300000000000004, 89.2999999999993, 27.50000000000005, -7.2999999999999226, 15.799999999999962, 7.399999999999965, -169.00000000000048, -152.20000000000027, 20.000000000000014, 127.40000000000003, 20.000000000000014, 151.1, 130.09999999999988, 15.799999999999963, 72.19999999999959, 20.000000000000014, 11.599999999999966, 20.000000000000014, -0.7000000000000365, -110.80000000000061, 11.599999999999977, 20.000000000000014, -226.0, 132.49999999999977, 20.000000000000014, 9.799999999999981, -66.1000000000009, 84.19999999999936, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 71.29999999999968, 20.000000000000014, 139.7, -160.6000000000004, -49.0, 20.000000000000014, 72.79999999999978, -135.40000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -236.20000000000044, 5.2999999999999705, 20.000000000000014, 20.000000000000014, -273.1, 120.7999999999997, 118.09999999999985, 20.000000000000014, -244.9000000000004, -267.70000000000005, 127.09999999999977, 20.000000000000014, -198.40000000000003, -55.599999999999866, 3.1999999999999686, 174.8, 20.000000000000014, 96.49999999999935, -222.39999999999995], "policy_predator_policy_reward": [33.0, 79.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 55.0, 0.0, 1.0, 12.0, 0.0, 0.0, 2.0, 4.0, 0.0, 61.0, 0.0, 0.0, 0.0, 0.0, 96.0, 50.0, 0.0, 56.0, 164.0, 39.0, 38.0, 2.0, 27.0, 21.0, 38.0, 5.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 85.0, 51.0, 37.0, 0.0, 0.0, 16.0, 0.0, 40.0, 39.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 18.0, 0.0, 48.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 32.0, 7.0, 44.0, 13.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 185.0, 0.0, 4.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 29.0, 90.0, 65.0, 67.0, 52.0, 48.0, 69.0, 142.0, 36.0, 0.0, 0.0, 0.0, 0.0, 24.0, 56.0, 67.0, 76.0, 0.0, 0.0, 123.0, 0.0, 0.0, 59.0, 105.0, 44.0, 0.0, 0.0, 0.0, 43.0, 12.0, 0.0, 0.0, 190.0, 0.0, 11.0, 0.0, 0.0, 0.0, 46.0, 15.0, 0.0, 0.0, 0.0, 85.0, 13.0, 0.0, 60.0, 4.0, 5.0, 6.0, 132.0, 85.0, 0.0, 14.0, 0.0, 16.0, 2.0, 2.0, 16.0, 5.0, 0.0, 4.0, 67.0, 61.0, 0.0, 4.0, 129.0, 11.0, 19.0, 0.0, 0.0, 46.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 86.0, 0.0, 83.0, 41.0, 93.0, 0.0, 0.0, 79.0, 43.0, 0.0, 7.0, 91.0, 64.0, 0.0, 0.0, 37.0, 119.0, 137.0, 0.0, 8.0, 96.0, 71.0, 0.0, 0.0, 0.0, 116.0, 116.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.363795665393914, "mean_inference_ms": 9.895986060557666, "mean_action_processing_ms": 0.6943221439957781, "mean_env_wait_ms": 1.3154117711859066, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013858318328857422, "StateBufferConnector_ms": 0.01354372501373291, "ViewRequirementAgentConnector_ms": 0.4822041988372803}, "num_episodes": 18, "episode_return_max": 322.60000000000133, "episode_return_min": -198.09999999999994, "episode_return_mean": 54.91799999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000, "num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 138.56921254741155, "num_env_steps_trained_throughput_per_sec": 138.56921254741155, "timesteps_total": 416000, "num_env_steps_sampled_lifetime": 416000, "num_agent_steps_sampled_lifetime": 1664000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1664000, "timers": {"training_iteration_time_ms": 26469.239, "restore_workers_time_ms": 0.043, "training_step_time_ms": 26469.132, "sample_time_ms": 5356.338, "learn_time_ms": 21064.838, "learn_throughput": 189.89, "synch_weights_time_ms": 40.783}, "counters": {"num_env_steps_sampled": 416000, "num_env_steps_trained": 416000, "num_agent_steps_sampled": 1664000, "num_agent_steps_trained": 1664000}, "done": false, "training_iteration": 104, "trial_id": "3a355_00000", "date": "2024-08-13_02-58-32", "timestamp": 1723532312, "time_this_iter_s": 28.91171097755432, "time_total_s": 6515.340411186218, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d4af70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6515.340411186218, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 86.79756097560977, "ram_util_percent": 83.23414634146341}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7963470416409629, "cur_kl_coeff": 8.470329472543004e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.311762724099336, "policy_loss": -0.0015927898367403676, "vf_loss": 3.3133555162520634, "vf_explained_var": -0.0013120271856822666, "kl": 0.002969546157620914, "entropy": 0.3908160236146715, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 197505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1481185786071277, "cur_kl_coeff": 0.0011878632009029388, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.954608515204576, "policy_loss": -0.00011671785395789557, "vf_loss": 3.954723612467448, "vf_explained_var": 0.006476566715845986, "kl": 0.0013614416911656858, "entropy": 0.6850706697771789, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 197505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000}, "env_runners": {"episode_reward_max": 238.89999999999958, "episode_reward_min": -177.80000000000067, "episode_reward_mean": 47.300999999999746, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 181.0999999999999, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -6.119500000000082, "predator_policy": 29.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [167.79999999999913, 112.39999999999893, 5.599999999999943, 40.0000000000003, 40.0000000000003, 32.40000000000019, 40.0000000000003, 138.99999999999923, -43.599999999999746, 149.79999999999902, 40.0000000000003, 20.499999999999986, 195.69999999999922, -2.899999999999716, -20.59999999999951, 30.100000000000147, 142.5999999999987, 215.29999999999902, -163.50000000000054, 88.69999999999868, 40.0000000000003, 109.59999999999877, 201.0999999999992, 70.59999999999992, -23.400000000000034, -105.20000000000138, 23.900000000000123, 117.49999999999989, 114.69999999999877, 40.0000000000003, 13.599999999999962, 65.79999999999974, 14.89999999999989, -20.300000000000026, 40.0000000000003, 29.69999999999991, 118.49999999999918, 40.0000000000003, 135.1999999999992, 67.00000000000028, -114.10000000000025, 27.900000000000283, 40.0000000000003, 14.299999999999946, 191.19999999999908, 5.0000000000000515, 94.99999999999864, 84.19999999999914, 34.200000000000216, -104.20000000000076, 161.39999999999952, 187.09999999999926, 149.8999999999994, 113.19999999999888, 35.600000000000236, 16.49999999999998, 35.60000000000022, 46.50000000000005, 48.800000000000416, 64.10000000000035, 40.0000000000003, 34.50000000000022, 91.29999999999852, 65.10000000000002, 54.00000000000015, 71.39999999999962, 40.0000000000003, -94.20000000000095, 32.300000000000196, -98.10000000000005, 238.89999999999958, -68.90000000000103, -3.599999999999918, -74.40000000000006, 18.600000000000062, 194.7999999999994, 106.0999999999992, 40.0000000000003, 17.999999999999975, -21.799999999999578, 2.7000000000000095, 144.59999999999957, 40.0000000000003, 175.8999999999993, -155.00000000000074, -164.00000000000057, 51.00000000000042, 121.3999999999995, 5.899999999999933, 174.09999999999928, -27.899999999999743, 186.59999999999962, -177.80000000000067, 169.89999999999944, -10.099999999999937, 42.30000000000003, -30.399999999999913, -58.40000000000032, 105.69999999999894, -5.099999999999714], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [147.79999999999978, 20.000000000000014, 76.39999999999952, 20.000000000000014, -93.40000000000049, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999686, 24.50000000000008, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.99999999999973, -172.60000000000025, 20.000000000000014, 129.79999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -20.49999999999975, 20.000000000000014, 175.6999999999999, 20.000000000000014, -47.19999999999976, 5.299999999999965, -5.1999999999999265, -72.40000000000089, 20.000000000000014, 1.0999999999999865, 27.20000000000013, 115.39999999999947, 88.99999999999932, 125.2999999999997, 20.000000000000014, -368.5, 64.70000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 88.09999999999943, 181.0999999999999, 20.000000000000014, 50.600000000000186, 20.000000000000014, -162.40000000000003, 20.000000000000014, -28.29999999999975, -208.90000000000052, 20.000000000000014, -96.1000000000005, -253.0, 159.4999999999999, 74.89999999999942, 3.800000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, -30.39999999999977, 29.600000000000023, -86.80000000000024, 20.000000000000014, -81.10000000000001, -206.80000000000027, 63.49999999999986, 20.000000000000014, 20.000000000000014, -78.70000000000007, -55.59999999999994, 51.800000000000026, 22.700000000000063, 20.000000000000014, 20.000000000000014, 43.39999999999998, 36.799999999999784, 33.500000000000114, 33.50000000000024, 74.89999999999942, -379.0, 20.000000000000014, -3.1000000000000014, 20.000000000000014, 20.000000000000014, -76.60000000000082, 29.900000000000198, 170.2999999999998, 20.90000000000003, -100.00000000000028, 20.000000000000014, -7.300000000000004, 89.2999999999993, 27.50000000000005, -7.2999999999999226, 15.799999999999962, 7.399999999999965, -169.00000000000048, -152.20000000000027, 20.000000000000014, 127.40000000000003, 20.000000000000014, 151.1, 130.09999999999988, 15.799999999999963, 72.19999999999959, 20.000000000000014, 11.599999999999966, 20.000000000000014, -0.7000000000000365, -110.80000000000061, 11.599999999999977, 20.000000000000014, -226.0, 132.49999999999977, 20.000000000000014, 9.799999999999981, -66.1000000000009, 84.19999999999936, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 71.29999999999968, 20.000000000000014, 139.7, -160.6000000000004, -49.0, 20.000000000000014, 72.79999999999978, -135.40000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -236.20000000000044, 5.2999999999999705, 20.000000000000014, 20.000000000000014, -273.1, 120.7999999999997, 118.09999999999985, 20.000000000000014, -244.9000000000004, -267.70000000000005, 127.09999999999977, 20.000000000000014, -198.40000000000003, -55.599999999999866, 3.1999999999999686, 174.8, 20.000000000000014, 96.49999999999935, -222.39999999999995, 20.000000000000014, 20.000000000000014, -21.999999999999744, 20.000000000000014, 20.000000000000014, -122.80000000000075, 20.000000000000014, -55.29999999999995, -45.400000000000006, 118.99999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.8999999999999, -364.30000000000007, 26.300000000000114, -400.0, 20.000000000000014, 0.1999999999999901, -5.19999999999998, 20.000000000000014, 76.4, 7.399999999999963, -32.49999999999981, 20.000000000000014, 136.09999999999994, -278.1999999999987, 50.30000000000015, 110.59999999999961, 14.0, 6.199999999999976, -400.0, 144.2, 13.69999999999997, -154.30000000000038, 3.199999999999974, 67.39999999999999, -108.10000000000004, -279.39999999999986, 20.000000000000014, -40.89999999999976, -140.50000000000037, 20.000000000000014, 85.6999999999995, -66.1000000000009, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 16.0, 0.0, 40.0, 39.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 18.0, 0.0, 48.0, 61.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 32.0, 7.0, 44.0, 13.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 185.0, 0.0, 4.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 29.0, 90.0, 65.0, 67.0, 52.0, 48.0, 69.0, 142.0, 36.0, 0.0, 0.0, 0.0, 0.0, 24.0, 56.0, 67.0, 76.0, 0.0, 0.0, 123.0, 0.0, 0.0, 59.0, 105.0, 44.0, 0.0, 0.0, 0.0, 43.0, 12.0, 0.0, 0.0, 190.0, 0.0, 11.0, 0.0, 0.0, 0.0, 46.0, 15.0, 0.0, 0.0, 0.0, 85.0, 13.0, 0.0, 60.0, 4.0, 5.0, 6.0, 132.0, 85.0, 0.0, 14.0, 0.0, 16.0, 2.0, 2.0, 16.0, 5.0, 0.0, 4.0, 67.0, 61.0, 0.0, 4.0, 129.0, 11.0, 19.0, 0.0, 0.0, 46.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 86.0, 0.0, 83.0, 41.0, 93.0, 0.0, 0.0, 79.0, 43.0, 0.0, 7.0, 91.0, 64.0, 0.0, 0.0, 37.0, 119.0, 137.0, 0.0, 8.0, 96.0, 71.0, 0.0, 0.0, 0.0, 116.0, 116.0, 0.0, 0.0, 0.0, 20.0, 46.0, 35.0, 38.0, 0.0, 0.0, 71.0, 0.0, 0.0, 0.0, 0.0, 0.0, 183.0, 200.0, 16.0, 22.0, 34.0, 25.0, 0.0, 21.0, 10.0, 10.0, 8.0, 142.0, 58.0, 0.0, 62.0, 16.0, 200.0, 12.0, 0.0, 62.0, 79.0, 22.0, 61.0, 122.0, 107.0, 94.0, 29.0, 0.0, 0.0, 41.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3768036826570964, "mean_inference_ms": 9.885457892361547, "mean_action_processing_ms": 0.7012936353150988, "mean_env_wait_ms": 1.311459691339654, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013747215270996094, "StateBufferConnector_ms": 0.0118790864944458, "ViewRequirementAgentConnector_ms": 0.5056607723236084}, "num_episodes": 23, "episode_return_max": 238.89999999999958, "episode_return_min": -177.80000000000067, "episode_return_mean": 47.300999999999746, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000, "num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 147.9896834603436, "num_env_steps_trained_throughput_per_sec": 147.9896834603436, "timesteps_total": 420000, "num_env_steps_sampled_lifetime": 420000, "num_agent_steps_sampled_lifetime": 1680000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1680000, "timers": {"training_iteration_time_ms": 26502.844, "restore_workers_time_ms": 0.042, "training_step_time_ms": 26502.736, "sample_time_ms": 5457.353, "learn_time_ms": 20998.556, "learn_throughput": 190.489, "synch_weights_time_ms": 39.855}, "counters": {"num_env_steps_sampled": 420000, "num_env_steps_trained": 420000, "num_agent_steps_sampled": 1680000, "num_agent_steps_trained": 1680000}, "done": false, "training_iteration": 105, "trial_id": "3a355_00000", "date": "2024-08-13_02-58-59", "timestamp": 1723532339, "time_this_iter_s": 27.085390090942383, "time_total_s": 6542.425801277161, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52dea60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6542.425801277161, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 86.48157894736842, "ram_util_percent": 83.20263157894739}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8787471519024284, "cur_kl_coeff": 4.235164736271502e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5932553138051713, "policy_loss": -0.0022909827069650408, "vf_loss": 2.595546294772436, "vf_explained_var": 0.0017892154436262827, "kl": 0.0023756359388973957, "entropy": 0.4229817487102337, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 199395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2350422391520133, "cur_kl_coeff": 0.0005939316004514694, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.186180753808804, "policy_loss": -0.0008809838546858854, "vf_loss": 4.187059915507281, "vf_explained_var": 0.04378084552981866, "kl": 0.0030361418719196584, "entropy": 0.5936759545689537, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 199395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000}, "env_runners": {"episode_reward_max": 255.59999999999974, "episode_reward_min": -177.80000000000067, "episode_reward_mean": 51.94099999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 182.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -5.669500000000079, "predator_policy": 31.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-163.50000000000054, 88.69999999999868, 40.0000000000003, 109.59999999999877, 201.0999999999992, 70.59999999999992, -23.400000000000034, -105.20000000000138, 23.900000000000123, 117.49999999999989, 114.69999999999877, 40.0000000000003, 13.599999999999962, 65.79999999999974, 14.89999999999989, -20.300000000000026, 40.0000000000003, 29.69999999999991, 118.49999999999918, 40.0000000000003, 135.1999999999992, 67.00000000000028, -114.10000000000025, 27.900000000000283, 40.0000000000003, 14.299999999999946, 191.19999999999908, 5.0000000000000515, 94.99999999999864, 84.19999999999914, 34.200000000000216, -104.20000000000076, 161.39999999999952, 187.09999999999926, 149.8999999999994, 113.19999999999888, 35.600000000000236, 16.49999999999998, 35.60000000000022, 46.50000000000005, 48.800000000000416, 64.10000000000035, 40.0000000000003, 34.50000000000022, 91.29999999999852, 65.10000000000002, 54.00000000000015, 71.39999999999962, 40.0000000000003, -94.20000000000095, 32.300000000000196, -98.10000000000005, 238.89999999999958, -68.90000000000103, -3.599999999999918, -74.40000000000006, 18.600000000000062, 194.7999999999994, 106.0999999999992, 40.0000000000003, 17.999999999999975, -21.799999999999578, 2.7000000000000095, 144.59999999999957, 40.0000000000003, 175.8999999999993, -155.00000000000074, -164.00000000000057, 51.00000000000042, 121.3999999999995, 5.899999999999933, 174.09999999999928, -27.899999999999743, 186.59999999999962, -177.80000000000067, 169.89999999999944, -10.099999999999937, 42.30000000000003, -30.399999999999913, -58.40000000000032, 105.69999999999894, -5.099999999999714, -1.7999999999999745, 116.69999999999916, 55.300000000000516, 255.59999999999974, 100.69999999999885, 193.8999999999991, 201.99999999999935, -41.499999999999886, 1.5000000000000069, 114.6999999999993, 30.000000000000238, 172.39999999999915, 26.80000000000009, 139.2999999999993, 40.0000000000003, 159.89999999999955, 42.50000000000039, 160.0999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -368.5, 64.70000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999964, 88.09999999999943, 181.0999999999999, 20.000000000000014, 50.600000000000186, 20.000000000000014, -162.40000000000003, 20.000000000000014, -28.29999999999975, -208.90000000000052, 20.000000000000014, -96.1000000000005, -253.0, 159.4999999999999, 74.89999999999942, 3.800000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, -30.39999999999977, 29.600000000000023, -86.80000000000024, 20.000000000000014, -81.10000000000001, -206.80000000000027, 63.49999999999986, 20.000000000000014, 20.000000000000014, -78.70000000000007, -55.59999999999994, 51.800000000000026, 22.700000000000063, 20.000000000000014, 20.000000000000014, 43.39999999999998, 36.799999999999784, 33.500000000000114, 33.50000000000024, 74.89999999999942, -379.0, 20.000000000000014, -3.1000000000000014, 20.000000000000014, 20.000000000000014, -76.60000000000082, 29.900000000000198, 170.2999999999998, 20.90000000000003, -100.00000000000028, 20.000000000000014, -7.300000000000004, 89.2999999999993, 27.50000000000005, -7.2999999999999226, 15.799999999999962, 7.399999999999965, -169.00000000000048, -152.20000000000027, 20.000000000000014, 127.40000000000003, 20.000000000000014, 151.1, 130.09999999999988, 15.799999999999963, 72.19999999999959, 20.000000000000014, 11.599999999999966, 20.000000000000014, -0.7000000000000365, -110.80000000000061, 11.599999999999977, 20.000000000000014, -226.0, 132.49999999999977, 20.000000000000014, 9.799999999999981, -66.1000000000009, 84.19999999999936, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 71.29999999999968, 20.000000000000014, 139.7, -160.6000000000004, -49.0, 20.000000000000014, 72.79999999999978, -135.40000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -236.20000000000044, 5.2999999999999705, 20.000000000000014, 20.000000000000014, -273.1, 120.7999999999997, 118.09999999999985, 20.000000000000014, -244.9000000000004, -267.70000000000005, 127.09999999999977, 20.000000000000014, -198.40000000000003, -55.599999999999866, 3.1999999999999686, 174.8, 20.000000000000014, 96.49999999999935, -222.39999999999995, 20.000000000000014, 20.000000000000014, -21.999999999999744, 20.000000000000014, 20.000000000000014, -122.80000000000075, 20.000000000000014, -55.29999999999995, -45.400000000000006, 118.99999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.8999999999999, -364.30000000000007, 26.300000000000114, -400.0, 20.000000000000014, 0.1999999999999901, -5.19999999999998, 20.000000000000014, 76.4, 7.399999999999963, -32.49999999999981, 20.000000000000014, 136.09999999999994, -278.1999999999987, 50.30000000000015, 110.59999999999961, 14.0, 6.199999999999976, -400.0, 144.2, 13.69999999999997, -154.30000000000038, 3.199999999999974, 67.39999999999999, -108.10000000000004, -279.39999999999986, 20.000000000000014, -40.89999999999976, -140.50000000000037, 20.000000000000014, 85.6999999999995, -66.1000000000009, 20.000000000000014, -30.399999999999913, -126.40000000000032, 81.19999999999965, 9.499999999999968, 20.000000000000014, 35.30000000000026, 82.3999999999997, 153.2, 64.70000000000009, 20.000000000000014, 20.000000000000014, 173.89999999999984, 182.0, 20.000000000000014, -113.2, -70.30000000000089, -175.30000000000044, 60.799999999999976, -36.699999999999754, 124.39999999999972, -3.0999999999999615, -7.8999999999999595, 21.200000000000035, 129.19999999999987, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 98.2999999999998, 20.000000000000014, 20.000000000000014, -69.10000000000085, 182.0, 20.000000000000014, -41.49999999999987, 167.6, -32.49999999999975], "policy_predator_policy_reward": [185.0, 0.0, 4.0, 0.0, 0.0, 0.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 29.0, 90.0, 65.0, 67.0, 52.0, 48.0, 69.0, 142.0, 36.0, 0.0, 0.0, 0.0, 0.0, 24.0, 56.0, 67.0, 76.0, 0.0, 0.0, 123.0, 0.0, 0.0, 59.0, 105.0, 44.0, 0.0, 0.0, 0.0, 43.0, 12.0, 0.0, 0.0, 190.0, 0.0, 11.0, 0.0, 0.0, 0.0, 46.0, 15.0, 0.0, 0.0, 0.0, 85.0, 13.0, 0.0, 60.0, 4.0, 5.0, 6.0, 132.0, 85.0, 0.0, 14.0, 0.0, 16.0, 2.0, 2.0, 16.0, 5.0, 0.0, 4.0, 67.0, 61.0, 0.0, 4.0, 129.0, 11.0, 19.0, 0.0, 0.0, 46.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 86.0, 0.0, 83.0, 41.0, 93.0, 0.0, 0.0, 79.0, 43.0, 0.0, 7.0, 91.0, 64.0, 0.0, 0.0, 37.0, 119.0, 137.0, 0.0, 8.0, 96.0, 71.0, 0.0, 0.0, 0.0, 116.0, 116.0, 0.0, 0.0, 0.0, 20.0, 46.0, 35.0, 38.0, 0.0, 0.0, 71.0, 0.0, 0.0, 0.0, 0.0, 0.0, 183.0, 200.0, 16.0, 22.0, 34.0, 25.0, 0.0, 21.0, 10.0, 10.0, 8.0, 142.0, 58.0, 0.0, 62.0, 16.0, 200.0, 12.0, 0.0, 62.0, 79.0, 22.0, 61.0, 122.0, 107.0, 94.0, 29.0, 0.0, 0.0, 41.0, 0.0, 66.0, 89.0, 21.0, 5.0, 0.0, 0.0, 20.0, 0.0, 15.0, 1.0, 0.0, 0.0, 0.0, 0.0, 99.0, 43.0, 23.0, 93.0, 27.0, 0.0, 11.0, 30.0, 12.0, 10.0, 12.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 47.0, 30.0, 34.0, 25.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.385051055024893, "mean_inference_ms": 9.875079618906485, "mean_action_processing_ms": 0.7062859914986768, "mean_env_wait_ms": 1.3092367769198632, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014884471893310547, "StateBufferConnector_ms": 0.016723990440368652, "ViewRequirementAgentConnector_ms": 0.47149479389190674}, "num_episodes": 18, "episode_return_max": 255.59999999999974, "episode_return_min": -177.80000000000067, "episode_return_mean": 51.94099999999973, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000, "num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 139.04973406883897, "num_env_steps_trained_throughput_per_sec": 139.04973406883897, "timesteps_total": 424000, "num_env_steps_sampled_lifetime": 424000, "num_agent_steps_sampled_lifetime": 1696000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1696000, "timers": {"training_iteration_time_ms": 26737.839, "restore_workers_time_ms": 0.042, "training_step_time_ms": 26737.731, "sample_time_ms": 5647.255, "learn_time_ms": 21044.01, "learn_throughput": 190.078, "synch_weights_time_ms": 39.688}, "counters": {"num_env_steps_sampled": 424000, "num_env_steps_trained": 424000, "num_agent_steps_sampled": 1696000, "num_agent_steps_trained": 1696000}, "done": false, "training_iteration": 106, "trial_id": "3a355_00000", "date": "2024-08-13_02-59-28", "timestamp": 1723532368, "time_this_iter_s": 28.837215900421143, "time_total_s": 6571.263017177582, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52043a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6571.263017177582, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 87.34, "ram_util_percent": 83.1}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7601471326693341, "cur_kl_coeff": 2.117582368135751e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.872683167331433, "policy_loss": -0.0016912331235491567, "vf_loss": 3.8743744052907148, "vf_explained_var": -0.0009630290919510776, "kl": 0.002776058195762379, "entropy": 0.3171729367482599, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 201285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4005177430059543, "cur_kl_coeff": 0.0002969658002257347, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.723882884827871, "policy_loss": -0.0014748157243485804, "vf_loss": 5.72535685130528, "vf_explained_var": 0.017096756185804095, "kl": 0.003100007075492882, "entropy": 0.6159359615315836, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 201285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000}, "env_runners": {"episode_reward_max": 255.59999999999974, "episode_reward_min": -398.1999999999989, "episode_reward_mean": 43.68099999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -12.44950000000008, "predator_policy": 34.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-114.10000000000025, 27.900000000000283, 40.0000000000003, 14.299999999999946, 191.19999999999908, 5.0000000000000515, 94.99999999999864, 84.19999999999914, 34.200000000000216, -104.20000000000076, 161.39999999999952, 187.09999999999926, 149.8999999999994, 113.19999999999888, 35.600000000000236, 16.49999999999998, 35.60000000000022, 46.50000000000005, 48.800000000000416, 64.10000000000035, 40.0000000000003, 34.50000000000022, 91.29999999999852, 65.10000000000002, 54.00000000000015, 71.39999999999962, 40.0000000000003, -94.20000000000095, 32.300000000000196, -98.10000000000005, 238.89999999999958, -68.90000000000103, -3.599999999999918, -74.40000000000006, 18.600000000000062, 194.7999999999994, 106.0999999999992, 40.0000000000003, 17.999999999999975, -21.799999999999578, 2.7000000000000095, 144.59999999999957, 40.0000000000003, 175.8999999999993, -155.00000000000074, -164.00000000000057, 51.00000000000042, 121.3999999999995, 5.899999999999933, 174.09999999999928, -27.899999999999743, 186.59999999999962, -177.80000000000067, 169.89999999999944, -10.099999999999937, 42.30000000000003, -30.399999999999913, -58.40000000000032, 105.69999999999894, -5.099999999999714, -1.7999999999999745, 116.69999999999916, 55.300000000000516, 255.59999999999974, 100.69999999999885, 193.8999999999991, 201.99999999999935, -41.499999999999886, 1.5000000000000069, 114.6999999999993, 30.000000000000238, 172.39999999999915, 26.80000000000009, 139.2999999999993, 40.0000000000003, 159.89999999999955, 42.50000000000039, 160.0999999999996, 97.5999999999999, -398.1999999999989, -207.9000000000005, 40.0000000000003, 15.60000000000003, -324.1, 51.59999999999954, 30.70000000000019, 73.49999999999883, 7.199999999999983, 77.19999999999925, 7.000000000000021, 40.0000000000003, 34.500000000000014, 40.0000000000003, 172.2999999999995, -84.29999999999978, 62.600000000000264, 213.69999999999922, 40.0000000000003, 121.99999999999949, 81.39999999999938], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [74.89999999999942, -379.0, 20.000000000000014, -3.1000000000000014, 20.000000000000014, 20.000000000000014, -76.60000000000082, 29.900000000000198, 170.2999999999998, 20.90000000000003, -100.00000000000028, 20.000000000000014, -7.300000000000004, 89.2999999999993, 27.50000000000005, -7.2999999999999226, 15.799999999999962, 7.399999999999965, -169.00000000000048, -152.20000000000027, 20.000000000000014, 127.40000000000003, 20.000000000000014, 151.1, 130.09999999999988, 15.799999999999963, 72.19999999999959, 20.000000000000014, 11.599999999999966, 20.000000000000014, -0.7000000000000365, -110.80000000000061, 11.599999999999977, 20.000000000000014, -226.0, 132.49999999999977, 20.000000000000014, 9.799999999999981, -66.1000000000009, 84.19999999999936, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 71.29999999999968, 20.000000000000014, 139.7, -160.6000000000004, -49.0, 20.000000000000014, 72.79999999999978, -135.40000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -236.20000000000044, 5.2999999999999705, 20.000000000000014, 20.000000000000014, -273.1, 120.7999999999997, 118.09999999999985, 20.000000000000014, -244.9000000000004, -267.70000000000005, 127.09999999999977, 20.000000000000014, -198.40000000000003, -55.599999999999866, 3.1999999999999686, 174.8, 20.000000000000014, 96.49999999999935, -222.39999999999995, 20.000000000000014, 20.000000000000014, -21.999999999999744, 20.000000000000014, 20.000000000000014, -122.80000000000075, 20.000000000000014, -55.29999999999995, -45.400000000000006, 118.99999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.8999999999999, -364.30000000000007, 26.300000000000114, -400.0, 20.000000000000014, 0.1999999999999901, -5.19999999999998, 20.000000000000014, 76.4, 7.399999999999963, -32.49999999999981, 20.000000000000014, 136.09999999999994, -278.1999999999987, 50.30000000000015, 110.59999999999961, 14.0, 6.199999999999976, -400.0, 144.2, 13.69999999999997, -154.30000000000038, 3.199999999999974, 67.39999999999999, -108.10000000000004, -279.39999999999986, 20.000000000000014, -40.89999999999976, -140.50000000000037, 20.000000000000014, 85.6999999999995, -66.1000000000009, 20.000000000000014, -30.399999999999913, -126.40000000000032, 81.19999999999965, 9.499999999999968, 20.000000000000014, 35.30000000000026, 82.3999999999997, 153.2, 64.70000000000009, 20.000000000000014, 20.000000000000014, 173.89999999999984, 182.0, 20.000000000000014, -113.2, -70.30000000000089, -175.30000000000044, 60.799999999999976, -36.699999999999754, 124.39999999999972, -3.0999999999999615, -7.8999999999999595, 21.200000000000035, 129.19999999999987, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 98.2999999999998, 20.000000000000014, 20.000000000000014, -69.10000000000085, 182.0, 20.000000000000014, -41.49999999999987, 167.6, -32.49999999999975, 139.7, -108.10000000000063, -240.40000000000043, -353.7999999999995, -209.5000000000003, -219.4000000000002, 20.000000000000014, 20.000000000000014, 89.29999999999998, -186.6999999999999, -400.0, -186.09999999999997, 54.1999999999999, -97.6000000000002, -22.299999999999812, 20.000000000000014, 20.000000000000014, 18.499999999999517, -38.799999999999756, -253.0, -34.0, 9.200000000000188, -42.9999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.099999999999994, -157.60000000000008, 20.000000000000014, 20.000000000000014, -17.799999999999805, 172.1, -217.3000000000005, 20.000000000000014, 38.00000000000013, 11.599999999999946, -112.30000000000078, 200.0, 20.000000000000014, 20.000000000000014, 53.0, 20.000000000000014, 61.40000000000006, 20.000000000000014], "policy_predator_policy_reward": [190.0, 0.0, 11.0, 0.0, 0.0, 0.0, 46.0, 15.0, 0.0, 0.0, 0.0, 85.0, 13.0, 0.0, 60.0, 4.0, 5.0, 6.0, 132.0, 85.0, 0.0, 14.0, 0.0, 16.0, 2.0, 2.0, 16.0, 5.0, 0.0, 4.0, 67.0, 61.0, 0.0, 4.0, 129.0, 11.0, 19.0, 0.0, 0.0, 46.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 86.0, 0.0, 83.0, 41.0, 93.0, 0.0, 0.0, 79.0, 43.0, 0.0, 7.0, 91.0, 64.0, 0.0, 0.0, 37.0, 119.0, 137.0, 0.0, 8.0, 96.0, 71.0, 0.0, 0.0, 0.0, 116.0, 116.0, 0.0, 0.0, 0.0, 20.0, 46.0, 35.0, 38.0, 0.0, 0.0, 71.0, 0.0, 0.0, 0.0, 0.0, 0.0, 183.0, 200.0, 16.0, 22.0, 34.0, 25.0, 0.0, 21.0, 10.0, 10.0, 8.0, 142.0, 58.0, 0.0, 62.0, 16.0, 200.0, 12.0, 0.0, 62.0, 79.0, 22.0, 61.0, 122.0, 107.0, 94.0, 29.0, 0.0, 0.0, 41.0, 0.0, 66.0, 89.0, 21.0, 5.0, 0.0, 0.0, 20.0, 0.0, 15.0, 1.0, 0.0, 0.0, 0.0, 0.0, 99.0, 43.0, 23.0, 93.0, 27.0, 0.0, 11.0, 30.0, 12.0, 10.0, 12.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 47.0, 30.0, 34.0, 25.0, 0.0, 61.0, 5.0, 0.0, 196.0, 148.0, 73.0, 0.0, 0.0, 40.0, 73.0, 62.0, 200.0, 39.0, 56.0, 33.0, 0.0, 35.0, 0.0, 130.0, 169.0, 78.0, 24.0, 30.0, 0.0, 0.0, 0.0, 79.0, 88.0, 0.0, 0.0, 18.0, 0.0, 75.0, 38.0, 13.0, 0.0, 63.0, 63.0, 0.0, 0.0, 22.0, 27.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4572144924919406, "mean_inference_ms": 9.782136803005203, "mean_action_processing_ms": 0.7114868572055809, "mean_env_wait_ms": 1.3094351520344487, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014917850494384766, "StateBufferConnector_ms": 0.016649842262268066, "ViewRequirementAgentConnector_ms": 0.43658924102783203}, "num_episodes": 22, "episode_return_max": 255.59999999999974, "episode_return_min": -398.1999999999989, "episode_return_mean": 43.68099999999978, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000, "num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 135.45549101854138, "num_env_steps_trained_throughput_per_sec": 135.45549101854138, "timesteps_total": 428000, "num_env_steps_sampled_lifetime": 428000, "num_agent_steps_sampled_lifetime": 1712000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1712000, "timers": {"training_iteration_time_ms": 26919.86, "restore_workers_time_ms": 0.042, "training_step_time_ms": 26919.751, "sample_time_ms": 5871.31, "learn_time_ms": 21002.754, "learn_throughput": 190.451, "synch_weights_time_ms": 37.657}, "counters": {"num_env_steps_sampled": 428000, "num_env_steps_trained": 428000, "num_agent_steps_sampled": 1712000, "num_agent_steps_trained": 1712000}, "done": false, "training_iteration": 107, "trial_id": "3a355_00000", "date": "2024-08-13_02-59-58", "timestamp": 1723532398, "time_this_iter_s": 29.624788761138916, "time_total_s": 6600.887805938721, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d7a430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6600.887805938721, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 87.7, "ram_util_percent": 83.20952380952382}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6495549881269062, "cur_kl_coeff": 1.0587911840678755e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.857212812181503, "policy_loss": -0.0013803152437691414, "vf_loss": 2.8585931291025153, "vf_explained_var": -0.0011324521410402168, "kl": 0.0031882152279811148, "entropy": 0.34023561208809494, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 203175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.381799959892003, "cur_kl_coeff": 0.00014848290011286734, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.751156972325037, "policy_loss": -0.0009693323635796785, "vf_loss": 4.752125818262655, "vf_explained_var": 0.056486378586481485, "kl": 0.0032637056193935664, "entropy": 0.6948138955093566, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 203175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000}, "env_runners": {"episode_reward_max": 346.0000000000007, "episode_reward_min": -398.1999999999989, "episode_reward_mean": 45.42299999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -11.873500000000059, "predator_policy": 34.585}, "custom_metrics": {}, "hist_stats": {"episode_reward": [48.800000000000416, 64.10000000000035, 40.0000000000003, 34.50000000000022, 91.29999999999852, 65.10000000000002, 54.00000000000015, 71.39999999999962, 40.0000000000003, -94.20000000000095, 32.300000000000196, -98.10000000000005, 238.89999999999958, -68.90000000000103, -3.599999999999918, -74.40000000000006, 18.600000000000062, 194.7999999999994, 106.0999999999992, 40.0000000000003, 17.999999999999975, -21.799999999999578, 2.7000000000000095, 144.59999999999957, 40.0000000000003, 175.8999999999993, -155.00000000000074, -164.00000000000057, 51.00000000000042, 121.3999999999995, 5.899999999999933, 174.09999999999928, -27.899999999999743, 186.59999999999962, -177.80000000000067, 169.89999999999944, -10.099999999999937, 42.30000000000003, -30.399999999999913, -58.40000000000032, 105.69999999999894, -5.099999999999714, -1.7999999999999745, 116.69999999999916, 55.300000000000516, 255.59999999999974, 100.69999999999885, 193.8999999999991, 201.99999999999935, -41.499999999999886, 1.5000000000000069, 114.6999999999993, 30.000000000000238, 172.39999999999915, 26.80000000000009, 139.2999999999993, 40.0000000000003, 159.89999999999955, 42.50000000000039, 160.0999999999996, 97.5999999999999, -398.1999999999989, -207.9000000000005, 40.0000000000003, 15.60000000000003, -324.1, 51.59999999999954, 30.70000000000019, 73.49999999999883, 7.199999999999983, 77.19999999999925, 7.000000000000021, 40.0000000000003, 34.500000000000014, 40.0000000000003, 172.2999999999995, -84.29999999999978, 62.600000000000264, 213.69999999999922, 40.0000000000003, 121.99999999999949, 81.39999999999938, -45.79999999999983, -180.00000000000065, 40.0000000000003, 65.20000000000041, 120.59999999999948, 133.09999999999977, 40.0000000000003, 346.0000000000007, -135.60000000000068, 335.70000000000005, -112.29999999999977, -55.29999999999981, 236.2999999999997, -10.599999999999765, -50.699999999999676, 135.29999999999973, 187.5999999999994, 143.99999999999946], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 9.799999999999981, -66.1000000000009, 84.19999999999936, 20.000000000000014, 20.000000000000014, 9.499999999999966, 20.000000000000014, 71.29999999999968, 20.000000000000014, 139.7, -160.6000000000004, -49.0, 20.000000000000014, 72.79999999999978, -135.40000000000052, 20.000000000000014, 20.000000000000014, 20.000000000000014, -236.20000000000044, 5.2999999999999705, 20.000000000000014, 20.000000000000014, -273.1, 120.7999999999997, 118.09999999999985, 20.000000000000014, -244.9000000000004, -267.70000000000005, 127.09999999999977, 20.000000000000014, -198.40000000000003, -55.599999999999866, 3.1999999999999686, 174.8, 20.000000000000014, 96.49999999999935, -222.39999999999995, 20.000000000000014, 20.000000000000014, -21.999999999999744, 20.000000000000014, 20.000000000000014, -122.80000000000075, 20.000000000000014, -55.29999999999995, -45.400000000000006, 118.99999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.8999999999999, -364.30000000000007, 26.300000000000114, -400.0, 20.000000000000014, 0.1999999999999901, -5.19999999999998, 20.000000000000014, 76.4, 7.399999999999963, -32.49999999999981, 20.000000000000014, 136.09999999999994, -278.1999999999987, 50.30000000000015, 110.59999999999961, 14.0, 6.199999999999976, -400.0, 144.2, 13.69999999999997, -154.30000000000038, 3.199999999999974, 67.39999999999999, -108.10000000000004, -279.39999999999986, 20.000000000000014, -40.89999999999976, -140.50000000000037, 20.000000000000014, 85.6999999999995, -66.1000000000009, 20.000000000000014, -30.399999999999913, -126.40000000000032, 81.19999999999965, 9.499999999999968, 20.000000000000014, 35.30000000000026, 82.3999999999997, 153.2, 64.70000000000009, 20.000000000000014, 20.000000000000014, 173.89999999999984, 182.0, 20.000000000000014, -113.2, -70.30000000000089, -175.30000000000044, 60.799999999999976, -36.699999999999754, 124.39999999999972, -3.0999999999999615, -7.8999999999999595, 21.200000000000035, 129.19999999999987, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 98.2999999999998, 20.000000000000014, 20.000000000000014, -69.10000000000085, 182.0, 20.000000000000014, -41.49999999999987, 167.6, -32.49999999999975, 139.7, -108.10000000000063, -240.40000000000043, -353.7999999999995, -209.5000000000003, -219.4000000000002, 20.000000000000014, 20.000000000000014, 89.29999999999998, -186.6999999999999, -400.0, -186.09999999999997, 54.1999999999999, -97.6000000000002, -22.299999999999812, 20.000000000000014, 20.000000000000014, 18.499999999999517, -38.799999999999756, -253.0, -34.0, 9.200000000000188, -42.9999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.099999999999994, -157.60000000000008, 20.000000000000014, 20.000000000000014, -17.799999999999805, 172.1, -217.3000000000005, 20.000000000000014, 38.00000000000013, 11.599999999999946, -112.30000000000078, 200.0, 20.000000000000014, 20.000000000000014, 53.0, 20.000000000000014, 61.40000000000006, 20.000000000000014, 20.000000000000014, -143.80000000000055, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 45.200000000000244, 20.000000000000014, 19.099999999999994, 33.50000000000024, 88.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999983, 200.0, -322.59999999999945, 20.000000000000014, 181.1, 152.6, -17.499999999999822, -227.8, -17.799999999999976, -149.50000000000006, 200.0, -21.699999999999996, 20.000000000000014, -76.60000000000065, 17.899999999999977, -160.60000000000034, 92.30000000000005, 20.000000000000014, 167.6, 20.000000000000014, 20.000000000000014, 86.0], "policy_predator_policy_reward": [19.0, 0.0, 0.0, 46.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 86.0, 0.0, 83.0, 41.0, 93.0, 0.0, 0.0, 79.0, 43.0, 0.0, 7.0, 91.0, 64.0, 0.0, 0.0, 37.0, 119.0, 137.0, 0.0, 8.0, 96.0, 71.0, 0.0, 0.0, 0.0, 116.0, 116.0, 0.0, 0.0, 0.0, 20.0, 46.0, 35.0, 38.0, 0.0, 0.0, 71.0, 0.0, 0.0, 0.0, 0.0, 0.0, 183.0, 200.0, 16.0, 22.0, 34.0, 25.0, 0.0, 21.0, 10.0, 10.0, 8.0, 142.0, 58.0, 0.0, 62.0, 16.0, 200.0, 12.0, 0.0, 62.0, 79.0, 22.0, 61.0, 122.0, 107.0, 94.0, 29.0, 0.0, 0.0, 41.0, 0.0, 66.0, 89.0, 21.0, 5.0, 0.0, 0.0, 20.0, 0.0, 15.0, 1.0, 0.0, 0.0, 0.0, 0.0, 99.0, 43.0, 23.0, 93.0, 27.0, 0.0, 11.0, 30.0, 12.0, 10.0, 12.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 47.0, 30.0, 34.0, 25.0, 0.0, 61.0, 5.0, 0.0, 196.0, 148.0, 73.0, 0.0, 0.0, 40.0, 73.0, 62.0, 200.0, 39.0, 56.0, 33.0, 0.0, 35.0, 0.0, 130.0, 169.0, 78.0, 24.0, 30.0, 0.0, 0.0, 0.0, 79.0, 88.0, 0.0, 0.0, 18.0, 0.0, 75.0, 38.0, 13.0, 0.0, 63.0, 63.0, 0.0, 0.0, 22.0, 27.0, 0.0, 0.0, 78.0, 0.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 167.0, 2.0, 0.0, 15.0, 118.0, 94.0, 18.0, 58.0, 0.0, 8.0, 38.0, 92.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 38.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3945943376439796, "mean_inference_ms": 9.83323693189198, "mean_action_processing_ms": 0.7136481399814258, "mean_env_wait_ms": 1.3024782870327583, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012143969535827637, "StateBufferConnector_ms": 0.01505577564239502, "ViewRequirementAgentConnector_ms": 0.40824997425079346}, "num_episodes": 18, "episode_return_max": 346.0000000000007, "episode_return_min": -398.1999999999989, "episode_return_mean": 45.42299999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000, "num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 133.98341244897273, "num_env_steps_trained_throughput_per_sec": 133.98341244897273, "timesteps_total": 432000, "num_env_steps_sampled_lifetime": 432000, "num_agent_steps_sampled_lifetime": 1728000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1728000, "timers": {"training_iteration_time_ms": 27287.403, "restore_workers_time_ms": 0.042, "training_step_time_ms": 27287.296, "sample_time_ms": 5963.625, "learn_time_ms": 21279.938, "learn_throughput": 187.97, "synch_weights_time_ms": 36.06}, "counters": {"num_env_steps_sampled": 432000, "num_env_steps_trained": 432000, "num_agent_steps_sampled": 1728000, "num_agent_steps_trained": 1728000}, "done": false, "training_iteration": 108, "trial_id": "3a355_00000", "date": "2024-08-13_03-00-28", "timestamp": 1723532428, "time_this_iter_s": 29.926560163497925, "time_total_s": 6630.814366102219, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5239dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6630.814366102219, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 88.2953488372093, "ram_util_percent": 83.03023255813953}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8078990297697524, "cur_kl_coeff": 5.2939559203393774e-24, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1321810141442312, "policy_loss": -0.0031862279905311803, "vf_loss": 3.1353672338541223, "vf_explained_var": 0.0007149798844857191, "kl": 0.003636842293809199, "entropy": 0.36105808387042354, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 205065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6488527199105611, "cur_kl_coeff": 7.424145005643367e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.377119655836196, "policy_loss": -0.0012289046263075853, "vf_loss": 4.378348175432317, "vf_explained_var": 0.04039711548537804, "kl": 0.003989674393280123, "entropy": 0.6291742711470871, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 205065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000}, "env_runners": {"episode_reward_max": 346.0000000000007, "episode_reward_min": -398.1999999999989, "episode_reward_mean": 52.43799999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -8.266000000000044, "predator_policy": 34.485}, "custom_metrics": {}, "hist_stats": {"episode_reward": [106.0999999999992, 40.0000000000003, 17.999999999999975, -21.799999999999578, 2.7000000000000095, 144.59999999999957, 40.0000000000003, 175.8999999999993, -155.00000000000074, -164.00000000000057, 51.00000000000042, 121.3999999999995, 5.899999999999933, 174.09999999999928, -27.899999999999743, 186.59999999999962, -177.80000000000067, 169.89999999999944, -10.099999999999937, 42.30000000000003, -30.399999999999913, -58.40000000000032, 105.69999999999894, -5.099999999999714, -1.7999999999999745, 116.69999999999916, 55.300000000000516, 255.59999999999974, 100.69999999999885, 193.8999999999991, 201.99999999999935, -41.499999999999886, 1.5000000000000069, 114.6999999999993, 30.000000000000238, 172.39999999999915, 26.80000000000009, 139.2999999999993, 40.0000000000003, 159.89999999999955, 42.50000000000039, 160.0999999999996, 97.5999999999999, -398.1999999999989, -207.9000000000005, 40.0000000000003, 15.60000000000003, -324.1, 51.59999999999954, 30.70000000000019, 73.49999999999883, 7.199999999999983, 77.19999999999925, 7.000000000000021, 40.0000000000003, 34.500000000000014, 40.0000000000003, 172.2999999999995, -84.29999999999978, 62.600000000000264, 213.69999999999922, 40.0000000000003, 121.99999999999949, 81.39999999999938, -45.79999999999983, -180.00000000000065, 40.0000000000003, 65.20000000000041, 120.59999999999948, 133.09999999999977, 40.0000000000003, 346.0000000000007, -135.60000000000068, 335.70000000000005, -112.29999999999977, -55.29999999999981, 236.2999999999997, -10.599999999999765, -50.699999999999676, 135.29999999999973, 187.5999999999994, 143.99999999999946, -10.899999999999714, 178.79999999999941, -1.9999999999998859, 41.80000000000033, 134.4999999999997, -257.2999999999958, 189.19999999999973, 149.19999999999965, -26.599999999999696, 95.49999999999989, 32.20000000000022, 17.29999999999998, 119.8999999999998, 168.99999999999952, 86.9000000000001, 158.99999999999935, 239.59999999999988, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [96.49999999999935, -222.39999999999995, 20.000000000000014, 20.000000000000014, -21.999999999999744, 20.000000000000014, 20.000000000000014, -122.80000000000075, 20.000000000000014, -55.29999999999995, -45.400000000000006, 118.99999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, 155.8999999999999, -364.30000000000007, 26.300000000000114, -400.0, 20.000000000000014, 0.1999999999999901, -5.19999999999998, 20.000000000000014, 76.4, 7.399999999999963, -32.49999999999981, 20.000000000000014, 136.09999999999994, -278.1999999999987, 50.30000000000015, 110.59999999999961, 14.0, 6.199999999999976, -400.0, 144.2, 13.69999999999997, -154.30000000000038, 3.199999999999974, 67.39999999999999, -108.10000000000004, -279.39999999999986, 20.000000000000014, -40.89999999999976, -140.50000000000037, 20.000000000000014, 85.6999999999995, -66.1000000000009, 20.000000000000014, -30.399999999999913, -126.40000000000032, 81.19999999999965, 9.499999999999968, 20.000000000000014, 35.30000000000026, 82.3999999999997, 153.2, 64.70000000000009, 20.000000000000014, 20.000000000000014, 173.89999999999984, 182.0, 20.000000000000014, -113.2, -70.30000000000089, -175.30000000000044, 60.799999999999976, -36.699999999999754, 124.39999999999972, -3.0999999999999615, -7.8999999999999595, 21.200000000000035, 129.19999999999987, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 98.2999999999998, 20.000000000000014, 20.000000000000014, -69.10000000000085, 182.0, 20.000000000000014, -41.49999999999987, 167.6, -32.49999999999975, 139.7, -108.10000000000063, -240.40000000000043, -353.7999999999995, -209.5000000000003, -219.4000000000002, 20.000000000000014, 20.000000000000014, 89.29999999999998, -186.6999999999999, -400.0, -186.09999999999997, 54.1999999999999, -97.6000000000002, -22.299999999999812, 20.000000000000014, 20.000000000000014, 18.499999999999517, -38.799999999999756, -253.0, -34.0, 9.200000000000188, -42.9999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.099999999999994, -157.60000000000008, 20.000000000000014, 20.000000000000014, -17.799999999999805, 172.1, -217.3000000000005, 20.000000000000014, 38.00000000000013, 11.599999999999946, -112.30000000000078, 200.0, 20.000000000000014, 20.000000000000014, 53.0, 20.000000000000014, 61.40000000000006, 20.000000000000014, 20.000000000000014, -143.80000000000055, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 45.200000000000244, 20.000000000000014, 19.099999999999994, 33.50000000000024, 88.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999983, 200.0, -322.59999999999945, 20.000000000000014, 181.1, 152.6, -17.499999999999822, -227.8, -17.799999999999976, -149.50000000000006, 200.0, -21.699999999999996, 20.000000000000014, -76.60000000000065, 17.899999999999977, -160.60000000000034, 92.30000000000005, 20.000000000000014, 167.6, 20.000000000000014, 20.000000000000014, 86.0, -124.90000000000072, 20.000000000000014, -9.399999999999878, 162.1999999999999, 20.000000000000014, -61.00000000000047, 21.800000000000047, 20.000000000000014, 20.000000000000014, 114.49999999999999, -206.8000000000005, -158.50000000000054, 125.29999999999986, 53.90000000000002, 140.0, -38.799999999999756, 20.000000000000014, -190.60000000000053, -87.10000000000085, 113.59999999999995, -17.799999999999798, 20.000000000000014, -261.09999999999866, 34.4000000000002, -114.40000000000077, 152.3, 170.3, -28.299999999999756, 35.90000000000011, 20.000000000000014, 38.0, 20.000000000000014, 140.0, 47.60000000000004, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [116.0, 116.0, 0.0, 0.0, 0.0, 20.0, 46.0, 35.0, 38.0, 0.0, 0.0, 71.0, 0.0, 0.0, 0.0, 0.0, 0.0, 183.0, 200.0, 16.0, 22.0, 34.0, 25.0, 0.0, 21.0, 10.0, 10.0, 8.0, 142.0, 58.0, 0.0, 62.0, 16.0, 200.0, 12.0, 0.0, 62.0, 79.0, 22.0, 61.0, 122.0, 107.0, 94.0, 29.0, 0.0, 0.0, 41.0, 0.0, 66.0, 89.0, 21.0, 5.0, 0.0, 0.0, 20.0, 0.0, 15.0, 1.0, 0.0, 0.0, 0.0, 0.0, 99.0, 43.0, 23.0, 93.0, 27.0, 0.0, 11.0, 30.0, 12.0, 10.0, 12.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 47.0, 30.0, 34.0, 25.0, 0.0, 61.0, 5.0, 0.0, 196.0, 148.0, 73.0, 0.0, 0.0, 40.0, 73.0, 62.0, 200.0, 39.0, 56.0, 33.0, 0.0, 35.0, 0.0, 130.0, 169.0, 78.0, 24.0, 30.0, 0.0, 0.0, 0.0, 79.0, 88.0, 0.0, 0.0, 18.0, 0.0, 75.0, 38.0, 13.0, 0.0, 63.0, 63.0, 0.0, 0.0, 22.0, 27.0, 0.0, 0.0, 78.0, 0.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 167.0, 2.0, 0.0, 15.0, 118.0, 94.0, 18.0, 58.0, 0.0, 8.0, 38.0, 92.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 38.0, 69.0, 25.0, 26.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 108.0, 0.0, 10.0, 28.0, 20.0, 102.0, 42.0, 18.0, 51.0, 0.0, 30.0, 136.0, 108.0, 60.0, 22.0, 27.0, 0.0, 0.0, 31.0, 53.0, 48.0, 14.0, 38.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.395832622926208, "mean_inference_ms": 9.80516853722518, "mean_action_processing_ms": 0.7157057860311125, "mean_env_wait_ms": 1.2978671205252374, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009057879447937012, "StateBufferConnector_ms": 0.015647172927856445, "ViewRequirementAgentConnector_ms": 0.3656604290008545}, "num_episodes": 18, "episode_return_max": 346.0000000000007, "episode_return_min": -398.1999999999989, "episode_return_mean": 52.43799999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000, "num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.41858263033419, "num_env_steps_trained_throughput_per_sec": 131.41858263033419, "timesteps_total": 436000, "num_env_steps_sampled_lifetime": 436000, "num_agent_steps_sampled_lifetime": 1744000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1744000, "timers": {"training_iteration_time_ms": 27802.213, "restore_workers_time_ms": 0.042, "training_step_time_ms": 27802.106, "sample_time_ms": 5982.95, "learn_time_ms": 21777.177, "learn_throughput": 183.679, "synch_weights_time_ms": 35.161}, "counters": {"num_env_steps_sampled": 436000, "num_env_steps_trained": 436000, "num_agent_steps_sampled": 1744000, "num_agent_steps_trained": 1744000}, "done": false, "training_iteration": 109, "trial_id": "3a355_00000", "date": "2024-08-13_03-00-58", "timestamp": 1723532458, "time_this_iter_s": 30.495266914367676, "time_total_s": 6661.309633016586, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d518b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6661.309633016586, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 88.44418604651163, "ram_util_percent": 83.23023255813953}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.694445647941853, "cur_kl_coeff": 2.6469779601696887e-24, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.846091852490864, "policy_loss": -0.0012983812337061243, "vf_loss": 3.8473902238109123, "vf_explained_var": 7.552072484657248e-05, "kl": 0.003200249803546559, "entropy": 0.3651169217295117, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 206955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8564398658732888, "cur_kl_coeff": 3.7120725028216836e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.2763814936239255, "policy_loss": -0.0003912529178830997, "vf_loss": 5.276772743305832, "vf_explained_var": 0.05088353567022495, "kl": 0.0017450456626498692, "entropy": 0.6242125493824167, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 206955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000}, "env_runners": {"episode_reward_max": 346.0000000000007, "episode_reward_min": -398.1999999999989, "episode_reward_mean": 56.988999999999905, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -5.345500000000044, "predator_policy": 33.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-5.099999999999714, -1.7999999999999745, 116.69999999999916, 55.300000000000516, 255.59999999999974, 100.69999999999885, 193.8999999999991, 201.99999999999935, -41.499999999999886, 1.5000000000000069, 114.6999999999993, 30.000000000000238, 172.39999999999915, 26.80000000000009, 139.2999999999993, 40.0000000000003, 159.89999999999955, 42.50000000000039, 160.0999999999996, 97.5999999999999, -398.1999999999989, -207.9000000000005, 40.0000000000003, 15.60000000000003, -324.1, 51.59999999999954, 30.70000000000019, 73.49999999999883, 7.199999999999983, 77.19999999999925, 7.000000000000021, 40.0000000000003, 34.500000000000014, 40.0000000000003, 172.2999999999995, -84.29999999999978, 62.600000000000264, 213.69999999999922, 40.0000000000003, 121.99999999999949, 81.39999999999938, -45.79999999999983, -180.00000000000065, 40.0000000000003, 65.20000000000041, 120.59999999999948, 133.09999999999977, 40.0000000000003, 346.0000000000007, -135.60000000000068, 335.70000000000005, -112.29999999999977, -55.29999999999981, 236.2999999999997, -10.599999999999765, -50.699999999999676, 135.29999999999973, 187.5999999999994, 143.99999999999946, -10.899999999999714, 178.79999999999941, -1.9999999999998859, 41.80000000000033, 134.4999999999997, -257.2999999999958, 189.19999999999973, 149.19999999999965, -26.599999999999696, 95.49999999999989, 32.20000000000022, 17.29999999999998, 119.8999999999998, 168.99999999999952, 86.9000000000001, 158.99999999999935, 239.59999999999988, 40.0000000000003, -12.000000000000194, -55.09999999999977, 196.59999999999937, 35.50000000000002, 153.9999999999995, 149.29999999999987, -56.39999999999972, -10.999999999999622, 142.29999999999967, -38.09999999999986, -97.50000000000101, -14.499999999999709, 137.59999999999968, 125.99999999999926, 105.29999999999882, -152.50000000000045, 151.99999999999966, 145.99999999999957, 79.39999999999992, 73.0, 55.10000000000051, 40.0000000000003, 38.9000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-66.1000000000009, 20.000000000000014, -30.399999999999913, -126.40000000000032, 81.19999999999965, 9.499999999999968, 20.000000000000014, 35.30000000000026, 82.3999999999997, 153.2, 64.70000000000009, 20.000000000000014, 20.000000000000014, 173.89999999999984, 182.0, 20.000000000000014, -113.2, -70.30000000000089, -175.30000000000044, 60.799999999999976, -36.699999999999754, 124.39999999999972, -3.0999999999999615, -7.8999999999999595, 21.200000000000035, 129.19999999999987, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 98.2999999999998, 20.000000000000014, 20.000000000000014, -69.10000000000085, 182.0, 20.000000000000014, -41.49999999999987, 167.6, -32.49999999999975, 139.7, -108.10000000000063, -240.40000000000043, -353.7999999999995, -209.5000000000003, -219.4000000000002, 20.000000000000014, 20.000000000000014, 89.29999999999998, -186.6999999999999, -400.0, -186.09999999999997, 54.1999999999999, -97.6000000000002, -22.299999999999812, 20.000000000000014, 20.000000000000014, 18.499999999999517, -38.799999999999756, -253.0, -34.0, 9.200000000000188, -42.9999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.099999999999994, -157.60000000000008, 20.000000000000014, 20.000000000000014, -17.799999999999805, 172.1, -217.3000000000005, 20.000000000000014, 38.00000000000013, 11.599999999999946, -112.30000000000078, 200.0, 20.000000000000014, 20.000000000000014, 53.0, 20.000000000000014, 61.40000000000006, 20.000000000000014, 20.000000000000014, -143.80000000000055, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 45.200000000000244, 20.000000000000014, 19.099999999999994, 33.50000000000024, 88.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999983, 200.0, -322.59999999999945, 20.000000000000014, 181.1, 152.6, -17.499999999999822, -227.8, -17.799999999999976, -149.50000000000006, 200.0, -21.699999999999996, 20.000000000000014, -76.60000000000065, 17.899999999999977, -160.60000000000034, 92.30000000000005, 20.000000000000014, 167.6, 20.000000000000014, 20.000000000000014, 86.0, -124.90000000000072, 20.000000000000014, -9.399999999999878, 162.1999999999999, 20.000000000000014, -61.00000000000047, 21.800000000000047, 20.000000000000014, 20.000000000000014, 114.49999999999999, -206.8000000000005, -158.50000000000054, 125.29999999999986, 53.90000000000002, 140.0, -38.799999999999756, 20.000000000000014, -190.60000000000053, -87.10000000000085, 113.59999999999995, -17.799999999999798, 20.000000000000014, -261.09999999999866, 34.4000000000002, -114.40000000000077, 152.3, 170.3, -28.299999999999756, 35.90000000000011, 20.000000000000014, 38.0, 20.000000000000014, 140.0, 47.60000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -148.0, -177.0999999999999, 20.000000000000014, 176.6, 20.000000000000014, 183.8, -301.3, 119.0, 20.000000000000014, -81.10000000000016, 64.4, 20.000000000000014, -189.39999999999992, -9.399999999999855, -97.60000000000082, -74.20000000000056, 147.5, 20.000000000000014, -129.10000000000002, -242.5000000000004, 20.000000000000014, 20.000000000000014, -305.499999999999, 149.0, -72.40000000000086, 59.0, 20.000000000000014, 20.000000000000014, 56.30000000000007, -347.5000000000001, 20.000000000000014, 98.0, 20.000000000000014, 89.0, 20.000000000000014, -227.80000000000007, 189.19999999999996, -55.0, 20.000000000000014, 20.000000000000014, 34.10000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.900000000000013], "policy_predator_policy_reward": [41.0, 0.0, 66.0, 89.0, 21.0, 5.0, 0.0, 0.0, 20.0, 0.0, 15.0, 1.0, 0.0, 0.0, 0.0, 0.0, 99.0, 43.0, 23.0, 93.0, 27.0, 0.0, 11.0, 30.0, 12.0, 10.0, 12.0, 0.0, 0.0, 21.0, 0.0, 0.0, 0.0, 47.0, 30.0, 34.0, 25.0, 0.0, 61.0, 5.0, 0.0, 196.0, 148.0, 73.0, 0.0, 0.0, 40.0, 73.0, 62.0, 200.0, 39.0, 56.0, 33.0, 0.0, 35.0, 0.0, 130.0, 169.0, 78.0, 24.0, 30.0, 0.0, 0.0, 0.0, 79.0, 88.0, 0.0, 0.0, 18.0, 0.0, 75.0, 38.0, 13.0, 0.0, 63.0, 63.0, 0.0, 0.0, 22.0, 27.0, 0.0, 0.0, 78.0, 0.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 167.0, 2.0, 0.0, 15.0, 118.0, 94.0, 18.0, 58.0, 0.0, 8.0, 38.0, 92.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 38.0, 69.0, 25.0, 26.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 108.0, 0.0, 10.0, 28.0, 20.0, 102.0, 42.0, 18.0, 51.0, 0.0, 30.0, 136.0, 108.0, 60.0, 22.0, 27.0, 0.0, 0.0, 31.0, 53.0, 48.0, 14.0, 38.0, 0.0, 0.0, 0.0, 116.0, 74.0, 28.0, 0.0, 0.0, 0.0, 153.0, 15.0, 0.0, 101.0, 65.0, 0.0, 113.0, 48.0, 48.0, 1.0, 68.0, 0.0, 71.0, 0.0, 125.0, 117.0, 154.0, 37.0, 24.0, 47.0, 0.0, 19.0, 10.0, 0.0, 175.0, 32.0, 2.0, 0.0, 37.0, 111.0, 7.0, 83.0, 25.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.397173062266518, "mean_inference_ms": 9.767715337086265, "mean_action_processing_ms": 0.7181263009767812, "mean_env_wait_ms": 1.2904274414059052, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010113239288330078, "StateBufferConnector_ms": 0.016119837760925293, "ViewRequirementAgentConnector_ms": 0.36512577533721924}, "num_episodes": 23, "episode_return_max": 346.0000000000007, "episode_return_min": -398.1999999999989, "episode_return_mean": 56.988999999999905, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000, "num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 134.83575902770724, "num_env_steps_trained_throughput_per_sec": 134.83575902770724, "timesteps_total": 440000, "num_env_steps_sampled_lifetime": 440000, "num_agent_steps_sampled_lifetime": 1760000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1760000, "timers": {"training_iteration_time_ms": 28335.286, "restore_workers_time_ms": 0.042, "training_step_time_ms": 28335.183, "sample_time_ms": 5903.214, "learn_time_ms": 22390.58, "learn_throughput": 178.647, "synch_weights_time_ms": 36.338}, "counters": {"num_env_steps_sampled": 440000, "num_env_steps_trained": 440000, "num_agent_steps_sampled": 1760000, "num_agent_steps_trained": 1760000}, "done": false, "training_iteration": 110, "trial_id": "3a355_00000", "date": "2024-08-13_03-01-28", "timestamp": 1723532488, "time_this_iter_s": 29.753560781478882, "time_total_s": 6691.063193798065, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b523e1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6691.063193798065, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 87.41428571428571, "ram_util_percent": 83.10952380952382}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8038788302589661, "cur_kl_coeff": 1.3234889800848444e-24, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3116376001368124, "policy_loss": -0.0023163770262654574, "vf_loss": 3.313953973250414, "vf_explained_var": 0.00021530225794151348, "kl": 0.0033347239910796527, "entropy": 0.3426952572963225, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 208845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4532746098501972, "cur_kl_coeff": 1.8560362514108418e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.527405858670593, "policy_loss": -0.0008186536141370654, "vf_loss": 4.528224485513395, "vf_explained_var": -0.010921594705531206, "kl": 0.00397075991131504, "entropy": 0.5949660238765535, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 208845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000}, "env_runners": {"episode_reward_max": 346.0000000000007, "episode_reward_min": -398.1999999999989, "episode_reward_mean": 47.26799999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -14.431000000000022, "predator_policy": 38.065}, "custom_metrics": {}, "hist_stats": {"episode_reward": [160.0999999999996, 97.5999999999999, -398.1999999999989, -207.9000000000005, 40.0000000000003, 15.60000000000003, -324.1, 51.59999999999954, 30.70000000000019, 73.49999999999883, 7.199999999999983, 77.19999999999925, 7.000000000000021, 40.0000000000003, 34.500000000000014, 40.0000000000003, 172.2999999999995, -84.29999999999978, 62.600000000000264, 213.69999999999922, 40.0000000000003, 121.99999999999949, 81.39999999999938, -45.79999999999983, -180.00000000000065, 40.0000000000003, 65.20000000000041, 120.59999999999948, 133.09999999999977, 40.0000000000003, 346.0000000000007, -135.60000000000068, 335.70000000000005, -112.29999999999977, -55.29999999999981, 236.2999999999997, -10.599999999999765, -50.699999999999676, 135.29999999999973, 187.5999999999994, 143.99999999999946, -10.899999999999714, 178.79999999999941, -1.9999999999998859, 41.80000000000033, 134.4999999999997, -257.2999999999958, 189.19999999999973, 149.19999999999965, -26.599999999999696, 95.49999999999989, 32.20000000000022, 17.29999999999998, 119.8999999999998, 168.99999999999952, 86.9000000000001, 158.99999999999935, 239.59999999999988, 40.0000000000003, -12.000000000000194, -55.09999999999977, 196.59999999999937, 35.50000000000002, 153.9999999999995, 149.29999999999987, -56.39999999999972, -10.999999999999622, 142.29999999999967, -38.09999999999986, -97.50000000000101, -14.499999999999709, 137.59999999999968, 125.99999999999926, 105.29999999999882, -152.50000000000045, 151.99999999999966, 145.99999999999957, 79.39999999999992, 73.0, 55.10000000000051, 40.0000000000003, 38.9000000000003, 40.0000000000003, 215.29999999999927, 193.99999999999994, -96.60000000000055, 149.69999999999965, 41.00000000000029, 245.1999999999997, 40.0000000000003, -37.19999999999969, -249.1, 142.8999999999996, 76.69999999999948, 40.0000000000003, 14.300000000000116, -275.19999999999993, 33.400000000000205, -104.80000000000098, 161.1999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [167.6, -32.49999999999975, 139.7, -108.10000000000063, -240.40000000000043, -353.7999999999995, -209.5000000000003, -219.4000000000002, 20.000000000000014, 20.000000000000014, 89.29999999999998, -186.6999999999999, -400.0, -186.09999999999997, 54.1999999999999, -97.6000000000002, -22.299999999999812, 20.000000000000014, 20.000000000000014, 18.499999999999517, -38.799999999999756, -253.0, -34.0, 9.200000000000188, -42.9999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.099999999999994, -157.60000000000008, 20.000000000000014, 20.000000000000014, -17.799999999999805, 172.1, -217.3000000000005, 20.000000000000014, 38.00000000000013, 11.599999999999946, -112.30000000000078, 200.0, 20.000000000000014, 20.000000000000014, 53.0, 20.000000000000014, 61.40000000000006, 20.000000000000014, 20.000000000000014, -143.80000000000055, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 45.200000000000244, 20.000000000000014, 19.099999999999994, 33.50000000000024, 88.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999983, 200.0, -322.59999999999945, 20.000000000000014, 181.1, 152.6, -17.499999999999822, -227.8, -17.799999999999976, -149.50000000000006, 200.0, -21.699999999999996, 20.000000000000014, -76.60000000000065, 17.899999999999977, -160.60000000000034, 92.30000000000005, 20.000000000000014, 167.6, 20.000000000000014, 20.000000000000014, 86.0, -124.90000000000072, 20.000000000000014, -9.399999999999878, 162.1999999999999, 20.000000000000014, -61.00000000000047, 21.800000000000047, 20.000000000000014, 20.000000000000014, 114.49999999999999, -206.8000000000005, -158.50000000000054, 125.29999999999986, 53.90000000000002, 140.0, -38.799999999999756, 20.000000000000014, -190.60000000000053, -87.10000000000085, 113.59999999999995, -17.799999999999798, 20.000000000000014, -261.09999999999866, 34.4000000000002, -114.40000000000077, 152.3, 170.3, -28.299999999999756, 35.90000000000011, 20.000000000000014, 38.0, 20.000000000000014, 140.0, 47.60000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -148.0, -177.0999999999999, 20.000000000000014, 176.6, 20.000000000000014, 183.8, -301.3, 119.0, 20.000000000000014, -81.10000000000016, 64.4, 20.000000000000014, -189.39999999999992, -9.399999999999855, -97.60000000000082, -74.20000000000056, 147.5, 20.000000000000014, -129.10000000000002, -242.5000000000004, 20.000000000000014, 20.000000000000014, -305.499999999999, 149.0, -72.40000000000086, 59.0, 20.000000000000014, 20.000000000000014, 56.30000000000007, -347.5000000000001, 20.000000000000014, 98.0, 20.000000000000014, 89.0, 20.000000000000014, -227.80000000000007, 189.19999999999996, -55.0, 20.000000000000014, 20.000000000000014, 34.10000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 194.3, 20.000000000000014, -1.0, 127.99999999999999, -65.80000000000001, -290.79999999999995, 149.0, -49.29999999999989, 20.000000000000014, 8.00000000000006, 151.4, 93.79999999999971, 20.000000000000014, 20.000000000000014, -278.1999999999987, 20.000000000000014, -258.1, -307.0, 20.000000000000014, 119.9, 20.000000000000014, -49.29999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, -84.7, -334.0, -119.20000000000056, 7.399999999999965, 20.000000000000014, -118.60000000000076, -248.20000000000022, -15.699999999999747, 143.9], "policy_predator_policy_reward": [25.0, 0.0, 61.0, 5.0, 0.0, 196.0, 148.0, 73.0, 0.0, 0.0, 40.0, 73.0, 62.0, 200.0, 39.0, 56.0, 33.0, 0.0, 35.0, 0.0, 130.0, 169.0, 78.0, 24.0, 30.0, 0.0, 0.0, 0.0, 79.0, 88.0, 0.0, 0.0, 18.0, 0.0, 75.0, 38.0, 13.0, 0.0, 63.0, 63.0, 0.0, 0.0, 22.0, 27.0, 0.0, 0.0, 78.0, 0.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 167.0, 2.0, 0.0, 15.0, 118.0, 94.0, 18.0, 58.0, 0.0, 8.0, 38.0, 92.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 38.0, 69.0, 25.0, 26.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 108.0, 0.0, 10.0, 28.0, 20.0, 102.0, 42.0, 18.0, 51.0, 0.0, 30.0, 136.0, 108.0, 60.0, 22.0, 27.0, 0.0, 0.0, 31.0, 53.0, 48.0, 14.0, 38.0, 0.0, 0.0, 0.0, 116.0, 74.0, 28.0, 0.0, 0.0, 0.0, 153.0, 15.0, 0.0, 101.0, 65.0, 0.0, 113.0, 48.0, 48.0, 1.0, 68.0, 0.0, 71.0, 0.0, 125.0, 117.0, 154.0, 37.0, 24.0, 47.0, 0.0, 19.0, 10.0, 0.0, 175.0, 32.0, 2.0, 0.0, 37.0, 111.0, 7.0, 83.0, 25.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 67.0, 0.0, 160.0, 100.0, 33.0, 17.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.0, 135.0, 181.0, 135.0, 0.0, 3.0, 72.0, 34.0, 0.0, 0.0, 15.0, 64.0, 0.0, 178.0, 0.0, 6.0, 155.0, 107.0, 17.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.39628620909066, "mean_inference_ms": 9.737370565101912, "mean_action_processing_ms": 0.7197662670817517, "mean_env_wait_ms": 1.2855128169720587, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010473370552062988, "StateBufferConnector_ms": 0.009250640869140625, "ViewRequirementAgentConnector_ms": 0.37110650539398193}, "num_episodes": 18, "episode_return_max": 346.0000000000007, "episode_return_min": -398.1999999999989, "episode_return_mean": 47.26799999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000, "num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 132.39057078153337, "num_env_steps_trained_throughput_per_sec": 132.39057078153337, "timesteps_total": 444000, "num_env_steps_sampled_lifetime": 444000, "num_agent_steps_sampled_lifetime": 1776000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1776000, "timers": {"training_iteration_time_ms": 28857.985, "restore_workers_time_ms": 0.041, "training_step_time_ms": 28857.883, "sample_time_ms": 5726.369, "learn_time_ms": 23090.449, "learn_throughput": 173.232, "synch_weights_time_ms": 35.882}, "counters": {"num_env_steps_sampled": 444000, "num_env_steps_trained": 444000, "num_agent_steps_sampled": 1776000, "num_agent_steps_trained": 1776000}, "done": false, "training_iteration": 111, "trial_id": "3a355_00000", "date": "2024-08-13_03-01-58", "timestamp": 1723532518, "time_this_iter_s": 30.28134822845459, "time_total_s": 6721.34454202652, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b523eee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6721.34454202652, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 88.2, "ram_util_percent": 83.03488372093022}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7449254555125085, "cur_kl_coeff": 6.617444900424222e-25, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5154533405152577, "policy_loss": -0.0019774669703717033, "vf_loss": 2.5174308107012795, "vf_explained_var": -0.0005805914048795347, "kl": 0.0040809099088825245, "entropy": 0.468287082087426, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 210735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4624909770551813, "cur_kl_coeff": 9.280181257054209e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.535500138272684, "policy_loss": -0.0016545740628821982, "vf_loss": 4.537154720447681, "vf_explained_var": 0.07239956004279001, "kl": 0.00729076748551608, "entropy": 0.4984399193651462, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 210735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000}, "env_runners": {"episode_reward_max": 346.0000000000007, "episode_reward_min": -275.19999999999993, "episode_reward_mean": 58.097999999999914, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -4.576000000000041, "predator_policy": 33.625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [81.39999999999938, -45.79999999999983, -180.00000000000065, 40.0000000000003, 65.20000000000041, 120.59999999999948, 133.09999999999977, 40.0000000000003, 346.0000000000007, -135.60000000000068, 335.70000000000005, -112.29999999999977, -55.29999999999981, 236.2999999999997, -10.599999999999765, -50.699999999999676, 135.29999999999973, 187.5999999999994, 143.99999999999946, -10.899999999999714, 178.79999999999941, -1.9999999999998859, 41.80000000000033, 134.4999999999997, -257.2999999999958, 189.19999999999973, 149.19999999999965, -26.599999999999696, 95.49999999999989, 32.20000000000022, 17.29999999999998, 119.8999999999998, 168.99999999999952, 86.9000000000001, 158.99999999999935, 239.59999999999988, 40.0000000000003, -12.000000000000194, -55.09999999999977, 196.59999999999937, 35.50000000000002, 153.9999999999995, 149.29999999999987, -56.39999999999972, -10.999999999999622, 142.29999999999967, -38.09999999999986, -97.50000000000101, -14.499999999999709, 137.59999999999968, 125.99999999999926, 105.29999999999882, -152.50000000000045, 151.99999999999966, 145.99999999999957, 79.39999999999992, 73.0, 55.10000000000051, 40.0000000000003, 38.9000000000003, 40.0000000000003, 215.29999999999927, 193.99999999999994, -96.60000000000055, 149.69999999999965, 41.00000000000029, 245.1999999999997, 40.0000000000003, -37.19999999999969, -249.1, 142.8999999999996, 76.69999999999948, 40.0000000000003, 14.300000000000116, -275.19999999999993, 33.400000000000205, -104.80000000000098, 161.1999999999996, 17.899999999999956, 41.80000000000033, 233.1999999999992, 307.30000000000064, 35.59999999999974, -56.00000000000071, -64.50000000000105, 297.3, 134.4999999999997, 176.79999999999947, 29.00000000000015, 40.0000000000003, -41.899999999999814, -111.80000000000018, 48.10000000000043, -77.70000000000107, 132.6999999999983, 195.0, -38.299999999999635, 40.0000000000003, 40.0000000000003, -24.899999999999842], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [61.40000000000006, 20.000000000000014, 20.000000000000014, -143.80000000000055, 20.000000000000014, -400.0, 20.000000000000014, 20.000000000000014, 45.200000000000244, 20.000000000000014, 19.099999999999994, 33.50000000000024, 88.10000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.99999999999983, 200.0, -322.59999999999945, 20.000000000000014, 181.1, 152.6, -17.499999999999822, -227.8, -17.799999999999976, -149.50000000000006, 200.0, -21.699999999999996, 20.000000000000014, -76.60000000000065, 17.899999999999977, -160.60000000000034, 92.30000000000005, 20.000000000000014, 167.6, 20.000000000000014, 20.000000000000014, 86.0, -124.90000000000072, 20.000000000000014, -9.399999999999878, 162.1999999999999, 20.000000000000014, -61.00000000000047, 21.800000000000047, 20.000000000000014, 20.000000000000014, 114.49999999999999, -206.8000000000005, -158.50000000000054, 125.29999999999986, 53.90000000000002, 140.0, -38.799999999999756, 20.000000000000014, -190.60000000000053, -87.10000000000085, 113.59999999999995, -17.799999999999798, 20.000000000000014, -261.09999999999866, 34.4000000000002, -114.40000000000077, 152.3, 170.3, -28.299999999999756, 35.90000000000011, 20.000000000000014, 38.0, 20.000000000000014, 140.0, 47.60000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -148.0, -177.0999999999999, 20.000000000000014, 176.6, 20.000000000000014, 183.8, -301.3, 119.0, 20.000000000000014, -81.10000000000016, 64.4, 20.000000000000014, -189.39999999999992, -9.399999999999855, -97.60000000000082, -74.20000000000056, 147.5, 20.000000000000014, -129.10000000000002, -242.5000000000004, 20.000000000000014, 20.000000000000014, -305.499999999999, 149.0, -72.40000000000086, 59.0, 20.000000000000014, 20.000000000000014, 56.30000000000007, -347.5000000000001, 20.000000000000014, 98.0, 20.000000000000014, 89.0, 20.000000000000014, -227.80000000000007, 189.19999999999996, -55.0, 20.000000000000014, 20.000000000000014, 34.10000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 194.3, 20.000000000000014, -1.0, 127.99999999999999, -65.80000000000001, -290.79999999999995, 149.0, -49.29999999999989, 20.000000000000014, 8.00000000000006, 151.4, 93.79999999999971, 20.000000000000014, 20.000000000000014, -278.1999999999987, 20.000000000000014, -258.1, -307.0, 20.000000000000014, 119.9, 20.000000000000014, -49.29999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, -84.7, -334.0, -119.20000000000056, 7.399999999999965, 20.000000000000014, -118.60000000000076, -248.20000000000022, -15.699999999999747, 143.9, -195.10000000000045, 20.000000000000014, 20.000000000000014, 21.800000000000043, 72.19999999999962, 134.0, 172.99999999999983, 134.29999999999998, 85.09999999999994, -179.50000000000003, -55.60000000000022, -69.40000000000063, 20.000000000000014, -179.5000000000005, 139.7, 152.6, 20.000000000000014, 114.49999999999999, 156.8, 20.000000000000014, -1.000000000000031, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.600000000000023, -118.30000000000061, 20.000000000000014, -269.80000000000007, 20.000000000000014, 28.100000000000147, 20.000000000000014, -204.70000000000053, 56.00000000000023, 76.69999999999929, 74.0, 50.0, -32.50000000000004, -86.80000000000075, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -103.90000000000003], "policy_predator_policy_reward": [0.0, 0.0, 78.0, 0.0, 200.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 35.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 167.0, 2.0, 0.0, 15.0, 118.0, 94.0, 18.0, 58.0, 0.0, 8.0, 38.0, 92.0, 0.0, 23.0, 0.0, 0.0, 0.0, 0.0, 38.0, 69.0, 25.0, 26.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 108.0, 0.0, 10.0, 28.0, 20.0, 102.0, 42.0, 18.0, 51.0, 0.0, 30.0, 136.0, 108.0, 60.0, 22.0, 27.0, 0.0, 0.0, 31.0, 53.0, 48.0, 14.0, 38.0, 0.0, 0.0, 0.0, 116.0, 74.0, 28.0, 0.0, 0.0, 0.0, 153.0, 15.0, 0.0, 101.0, 65.0, 0.0, 113.0, 48.0, 48.0, 1.0, 68.0, 0.0, 71.0, 0.0, 125.0, 117.0, 154.0, 37.0, 24.0, 47.0, 0.0, 19.0, 10.0, 0.0, 175.0, 32.0, 2.0, 0.0, 37.0, 111.0, 7.0, 83.0, 25.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 67.0, 0.0, 160.0, 100.0, 33.0, 17.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.0, 135.0, 181.0, 135.0, 0.0, 3.0, 72.0, 34.0, 0.0, 0.0, 15.0, 64.0, 0.0, 178.0, 0.0, 6.0, 155.0, 107.0, 17.0, 16.0, 90.0, 103.0, 0.0, 0.0, 5.0, 22.0, 0.0, 0.0, 95.0, 35.0, 69.0, 0.0, 0.0, 95.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 74.0, 16.0, 138.0, 0.0, 0.0, 0.0, 0.0, 107.0, 0.0, 0.0, 8.0, 63.0, 81.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3912184998701957, "mean_inference_ms": 9.6974437000332, "mean_action_processing_ms": 0.7210786372446018, "mean_env_wait_ms": 1.2804540663348574, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010862350463867188, "StateBufferConnector_ms": 0.015207290649414062, "ViewRequirementAgentConnector_ms": 0.3746563196182251}, "num_episodes": 22, "episode_return_max": 346.0000000000007, "episode_return_min": -275.19999999999993, "episode_return_mean": 58.097999999999914, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000, "num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 137.33391585236842, "num_env_steps_trained_throughput_per_sec": 137.33391585236842, "timesteps_total": 448000, "num_env_steps_sampled_lifetime": 448000, "num_agent_steps_sampled_lifetime": 1792000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1792000, "timers": {"training_iteration_time_ms": 29061.086, "restore_workers_time_ms": 0.019, "training_step_time_ms": 29061.021, "sample_time_ms": 5296.688, "learn_time_ms": 23719.363, "learn_throughput": 168.639, "synch_weights_time_ms": 40.097}, "counters": {"num_env_steps_sampled": 448000, "num_env_steps_trained": 448000, "num_agent_steps_sampled": 1792000, "num_agent_steps_trained": 1792000}, "done": false, "training_iteration": 112, "trial_id": "3a355_00000", "date": "2024-08-13_03-02-28", "timestamp": 1723532548, "time_this_iter_s": 29.184386014938354, "time_total_s": 6750.528928041458, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dbe040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6750.528928041458, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 87.6390243902439, "ram_util_percent": 83.16829268292683}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7529280176001881, "cur_kl_coeff": 3.308722450212111e-25, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7227362428077315, "policy_loss": -0.0015848634584693525, "vf_loss": 1.724321106722746, "vf_explained_var": 0.0013340352704285315, "kl": 0.0029873653610469797, "entropy": 0.36191473068699004, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 212625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5073519507235793, "cur_kl_coeff": 9.280181257054209e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.964583926856833, "policy_loss": -0.0019205950386575843, "vf_loss": 4.966504528535106, "vf_explained_var": 0.11028075240276478, "kl": 0.0037414809785580204, "entropy": 0.4702026142960503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 212625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000}, "env_runners": {"episode_reward_max": 307.30000000000064, "episode_reward_min": -275.19999999999993, "episode_reward_mean": 65.28499999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.3, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 0.4774999999999545, "predator_policy": 32.165}, "custom_metrics": {}, "hist_stats": {"episode_reward": [143.99999999999946, -10.899999999999714, 178.79999999999941, -1.9999999999998859, 41.80000000000033, 134.4999999999997, -257.2999999999958, 189.19999999999973, 149.19999999999965, -26.599999999999696, 95.49999999999989, 32.20000000000022, 17.29999999999998, 119.8999999999998, 168.99999999999952, 86.9000000000001, 158.99999999999935, 239.59999999999988, 40.0000000000003, -12.000000000000194, -55.09999999999977, 196.59999999999937, 35.50000000000002, 153.9999999999995, 149.29999999999987, -56.39999999999972, -10.999999999999622, 142.29999999999967, -38.09999999999986, -97.50000000000101, -14.499999999999709, 137.59999999999968, 125.99999999999926, 105.29999999999882, -152.50000000000045, 151.99999999999966, 145.99999999999957, 79.39999999999992, 73.0, 55.10000000000051, 40.0000000000003, 38.9000000000003, 40.0000000000003, 215.29999999999927, 193.99999999999994, -96.60000000000055, 149.69999999999965, 41.00000000000029, 245.1999999999997, 40.0000000000003, -37.19999999999969, -249.1, 142.8999999999996, 76.69999999999948, 40.0000000000003, 14.300000000000116, -275.19999999999993, 33.400000000000205, -104.80000000000098, 161.1999999999996, 17.899999999999956, 41.80000000000033, 233.1999999999992, 307.30000000000064, 35.59999999999974, -56.00000000000071, -64.50000000000105, 297.3, 134.4999999999997, 176.79999999999947, 29.00000000000015, 40.0000000000003, -41.899999999999814, -111.80000000000018, 48.10000000000043, -77.70000000000107, 132.6999999999983, 195.0, -38.299999999999635, 40.0000000000003, 40.0000000000003, -24.899999999999842, 208.2999999999993, 238.1999999999997, 54.400000000000276, -151.30000000000064, -35.89999999999962, 127.29999999999976, 184.19999999999942, 182.19999999999942, 136.89999999999964, 164.49999999999955, 203.99999999999932, 40.0000000000003, 193.99999999999943, 40.0000000000003, -15.00000000000001, 86.30000000000013, 151.49999999999966, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 86.0, -124.90000000000072, 20.000000000000014, -9.399999999999878, 162.1999999999999, 20.000000000000014, -61.00000000000047, 21.800000000000047, 20.000000000000014, 20.000000000000014, 114.49999999999999, -206.8000000000005, -158.50000000000054, 125.29999999999986, 53.90000000000002, 140.0, -38.799999999999756, 20.000000000000014, -190.60000000000053, -87.10000000000085, 113.59999999999995, -17.799999999999798, 20.000000000000014, -261.09999999999866, 34.4000000000002, -114.40000000000077, 152.3, 170.3, -28.299999999999756, 35.90000000000011, 20.000000000000014, 38.0, 20.000000000000014, 140.0, 47.60000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, -148.0, -177.0999999999999, 20.000000000000014, 176.6, 20.000000000000014, 183.8, -301.3, 119.0, 20.000000000000014, -81.10000000000016, 64.4, 20.000000000000014, -189.39999999999992, -9.399999999999855, -97.60000000000082, -74.20000000000056, 147.5, 20.000000000000014, -129.10000000000002, -242.5000000000004, 20.000000000000014, 20.000000000000014, -305.499999999999, 149.0, -72.40000000000086, 59.0, 20.000000000000014, 20.000000000000014, 56.30000000000007, -347.5000000000001, 20.000000000000014, 98.0, 20.000000000000014, 89.0, 20.000000000000014, -227.80000000000007, 189.19999999999996, -55.0, 20.000000000000014, 20.000000000000014, 34.10000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 194.3, 20.000000000000014, -1.0, 127.99999999999999, -65.80000000000001, -290.79999999999995, 149.0, -49.29999999999989, 20.000000000000014, 8.00000000000006, 151.4, 93.79999999999971, 20.000000000000014, 20.000000000000014, -278.1999999999987, 20.000000000000014, -258.1, -307.0, 20.000000000000014, 119.9, 20.000000000000014, -49.29999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, -84.7, -334.0, -119.20000000000056, 7.399999999999965, 20.000000000000014, -118.60000000000076, -248.20000000000022, -15.699999999999747, 143.9, -195.10000000000045, 20.000000000000014, 20.000000000000014, 21.800000000000043, 72.19999999999962, 134.0, 172.99999999999983, 134.29999999999998, 85.09999999999994, -179.50000000000003, -55.60000000000022, -69.40000000000063, 20.000000000000014, -179.5000000000005, 139.7, 152.6, 20.000000000000014, 114.49999999999999, 156.8, 20.000000000000014, -1.000000000000031, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.600000000000023, -118.30000000000061, 20.000000000000014, -269.80000000000007, 20.000000000000014, 28.100000000000147, 20.000000000000014, -204.70000000000053, 56.00000000000023, 76.69999999999929, 74.0, 50.0, -32.50000000000004, -86.80000000000075, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -103.90000000000003, 188.3, 20.000000000000014, 125.0, 78.1999999999997, 34.39999999999999, 20.000000000000014, 22.700000000000053, -400.0, 20.000000000000014, -124.90000000000063, 20.000000000000014, 107.29999999999998, 147.2, 20.000000000000014, 162.2, 20.000000000000014, 20.000000000000014, 101.90000000000009, 197.3, -80.79999999999984, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 160.1, -360.1, -84.10000000000085, 106.39999999999998, 20.000000000000014, 99.5, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 38.0, 69.0, 25.0, 26.0, 0.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 108.0, 0.0, 10.0, 28.0, 20.0, 102.0, 42.0, 18.0, 51.0, 0.0, 30.0, 136.0, 108.0, 60.0, 22.0, 27.0, 0.0, 0.0, 31.0, 53.0, 48.0, 14.0, 38.0, 0.0, 0.0, 0.0, 116.0, 74.0, 28.0, 0.0, 0.0, 0.0, 153.0, 15.0, 0.0, 101.0, 65.0, 0.0, 113.0, 48.0, 48.0, 1.0, 68.0, 0.0, 71.0, 0.0, 125.0, 117.0, 154.0, 37.0, 24.0, 47.0, 0.0, 19.0, 10.0, 0.0, 175.0, 32.0, 2.0, 0.0, 37.0, 111.0, 7.0, 83.0, 25.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 67.0, 0.0, 160.0, 100.0, 33.0, 17.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.0, 135.0, 181.0, 135.0, 0.0, 3.0, 72.0, 34.0, 0.0, 0.0, 15.0, 64.0, 0.0, 178.0, 0.0, 6.0, 155.0, 107.0, 17.0, 16.0, 90.0, 103.0, 0.0, 0.0, 5.0, 22.0, 0.0, 0.0, 95.0, 35.0, 69.0, 0.0, 0.0, 95.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 74.0, 16.0, 138.0, 0.0, 0.0, 0.0, 0.0, 107.0, 0.0, 0.0, 8.0, 63.0, 81.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 26.0, 200.0, 0.0, 69.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 15.0, 16.0, 32.0, 8.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 181.0, 4.0, 48.0, 16.0, 20.0, 12.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3889075626853535, "mean_inference_ms": 9.666985513979844, "mean_action_processing_ms": 0.7224042236426247, "mean_env_wait_ms": 1.2755050357831743, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015211343765258789, "StateBufferConnector_ms": 0.01540517807006836, "ViewRequirementAgentConnector_ms": 0.4659745693206787}, "num_episodes": 18, "episode_return_max": 307.30000000000064, "episode_return_min": -275.19999999999993, "episode_return_mean": 65.28499999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000, "num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 134.8480238452154, "num_env_steps_trained_throughput_per_sec": 134.8480238452154, "timesteps_total": 452000, "num_env_steps_sampled_lifetime": 452000, "num_agent_steps_sampled_lifetime": 1808000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1808000, "timers": {"training_iteration_time_ms": 29315.215, "restore_workers_time_ms": 0.02, "training_step_time_ms": 29315.132, "sample_time_ms": 5058.341, "learn_time_ms": 24209.417, "learn_throughput": 165.225, "synch_weights_time_ms": 41.665}, "counters": {"num_env_steps_sampled": 452000, "num_env_steps_trained": 452000, "num_agent_steps_sampled": 1808000, "num_agent_steps_trained": 1808000}, "done": false, "training_iteration": 113, "trial_id": "3a355_00000", "date": "2024-08-13_03-02-58", "timestamp": 1723532578, "time_this_iter_s": 29.7358078956604, "time_total_s": 6780.2647359371185, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5239ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6780.2647359371185, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 87.16666666666667, "ram_util_percent": 83.24047619047619}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8867098186224226, "cur_kl_coeff": 1.6543612251060554e-25, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.131827969021267, "policy_loss": -0.0018400667319024998, "vf_loss": 3.1336680386432265, "vf_explained_var": -9.004470532533353e-05, "kl": 0.002404388652309964, "entropy": 0.33611310750403733, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 214515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3214641412690518, "cur_kl_coeff": 4.6400906285271045e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.4903475850978225, "policy_loss": -0.0005704748286574921, "vf_loss": 4.490918061468336, "vf_explained_var": 0.010043195662675081, "kl": 0.003705464514631149, "entropy": 0.5668052879275468, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 214515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000}, "env_runners": {"episode_reward_max": 307.30000000000064, "episode_reward_min": -275.19999999999993, "episode_reward_mean": 60.52099999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -2.579500000000037, "predator_policy": 32.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [153.9999999999995, 149.29999999999987, -56.39999999999972, -10.999999999999622, 142.29999999999967, -38.09999999999986, -97.50000000000101, -14.499999999999709, 137.59999999999968, 125.99999999999926, 105.29999999999882, -152.50000000000045, 151.99999999999966, 145.99999999999957, 79.39999999999992, 73.0, 55.10000000000051, 40.0000000000003, 38.9000000000003, 40.0000000000003, 215.29999999999927, 193.99999999999994, -96.60000000000055, 149.69999999999965, 41.00000000000029, 245.1999999999997, 40.0000000000003, -37.19999999999969, -249.1, 142.8999999999996, 76.69999999999948, 40.0000000000003, 14.300000000000116, -275.19999999999993, 33.400000000000205, -104.80000000000098, 161.1999999999996, 17.899999999999956, 41.80000000000033, 233.1999999999992, 307.30000000000064, 35.59999999999974, -56.00000000000071, -64.50000000000105, 297.3, 134.4999999999997, 176.79999999999947, 29.00000000000015, 40.0000000000003, -41.899999999999814, -111.80000000000018, 48.10000000000043, -77.70000000000107, 132.6999999999983, 195.0, -38.299999999999635, 40.0000000000003, 40.0000000000003, -24.899999999999842, 208.2999999999993, 238.1999999999997, 54.400000000000276, -151.30000000000064, -35.89999999999962, 127.29999999999976, 184.19999999999942, 182.19999999999942, 136.89999999999964, 164.49999999999955, 203.99999999999932, 40.0000000000003, 193.99999999999943, 40.0000000000003, -15.00000000000001, 86.30000000000013, 151.49999999999966, 40.0000000000003, 72.39999999999989, 191.9999999999996, 35.600000000000236, 12.500000000000059, -57.899999999999956, -72.30000000000013, 21.300000000000043, 37.80000000000027, 125.29999999999976, -34.59999999999959, 90.0, 99.99999999999991, 81.69999999999895, -84.20000000000005, 87.99999999999994, -54.59999999999991, 221.79999999999913, 96.99999999999989, -175.60000000000065, 165.99999999999952, 305.90000000000003, -7.300000000000054, 27.900000000000116], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [119.0, 20.000000000000014, -81.10000000000016, 64.4, 20.000000000000014, -189.39999999999992, -9.399999999999855, -97.60000000000082, -74.20000000000056, 147.5, 20.000000000000014, -129.10000000000002, -242.5000000000004, 20.000000000000014, 20.000000000000014, -305.499999999999, 149.0, -72.40000000000086, 59.0, 20.000000000000014, 20.000000000000014, 56.30000000000007, -347.5000000000001, 20.000000000000014, 98.0, 20.000000000000014, 89.0, 20.000000000000014, -227.80000000000007, 189.19999999999996, -55.0, 20.000000000000014, 20.000000000000014, 34.10000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 194.3, 20.000000000000014, -1.0, 127.99999999999999, -65.80000000000001, -290.79999999999995, 149.0, -49.29999999999989, 20.000000000000014, 8.00000000000006, 151.4, 93.79999999999971, 20.000000000000014, 20.000000000000014, -278.1999999999987, 20.000000000000014, -258.1, -307.0, 20.000000000000014, 119.9, 20.000000000000014, -49.29999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, -84.7, -334.0, -119.20000000000056, 7.399999999999965, 20.000000000000014, -118.60000000000076, -248.20000000000022, -15.699999999999747, 143.9, -195.10000000000045, 20.000000000000014, 20.000000000000014, 21.800000000000043, 72.19999999999962, 134.0, 172.99999999999983, 134.29999999999998, 85.09999999999994, -179.50000000000003, -55.60000000000022, -69.40000000000063, 20.000000000000014, -179.5000000000005, 139.7, 152.6, 20.000000000000014, 114.49999999999999, 156.8, 20.000000000000014, -1.000000000000031, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.600000000000023, -118.30000000000061, 20.000000000000014, -269.80000000000007, 20.000000000000014, 28.100000000000147, 20.000000000000014, -204.70000000000053, 56.00000000000023, 76.69999999999929, 74.0, 50.0, -32.50000000000004, -86.80000000000075, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -103.90000000000003, 188.3, 20.000000000000014, 125.0, 78.1999999999997, 34.39999999999999, 20.000000000000014, 22.700000000000053, -400.0, 20.000000000000014, -124.90000000000063, 20.000000000000014, 107.29999999999998, 147.2, 20.000000000000014, 162.2, 20.000000000000014, 20.000000000000014, 101.90000000000009, 197.3, -80.79999999999984, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 160.1, -360.1, -84.10000000000085, 106.39999999999998, 20.000000000000014, 99.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.40000000000023, 37.999999999999986, 131.0, 20.000000000000014, 11.599999999999973, -7.299999999999891, -5.1999999999999265, 11.599999999999968, -158.50000000000003, 3.199999999999974, -188.5000000000003, -15.69999999999986, 20.000000000000014, 20.000000000000014, 15.799999999999962, 20.000000000000014, 104.29999999999998, 20.000000000000014, -139.6000000000007, -385.0, 200.0, 20.000000000000014, 20.0, 4.700000000000071, 20.000000000000014, 42.80000000000016, -358.0, 200.0, -232.00000000000006, 20.000000000000014, -160.60000000000002, 39.80000000000024, 173.0, -5.200000000000028, 90.19999999999997, 20.000000000000014, -391.6, 146.0, 20.000000000000014, 125.9, 158.0, -238.30000000000004, 20.000000000000014, -3.099999999999972, 20.000000000000014], "policy_predator_policy_reward": [15.0, 0.0, 101.0, 65.0, 0.0, 113.0, 48.0, 48.0, 1.0, 68.0, 0.0, 71.0, 0.0, 125.0, 117.0, 154.0, 37.0, 24.0, 47.0, 0.0, 19.0, 10.0, 0.0, 175.0, 32.0, 2.0, 0.0, 37.0, 111.0, 7.0, 83.0, 25.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 67.0, 0.0, 160.0, 100.0, 33.0, 17.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.0, 135.0, 181.0, 135.0, 0.0, 3.0, 72.0, 34.0, 0.0, 0.0, 15.0, 64.0, 0.0, 178.0, 0.0, 6.0, 155.0, 107.0, 17.0, 16.0, 90.0, 103.0, 0.0, 0.0, 5.0, 22.0, 0.0, 0.0, 95.0, 35.0, 69.0, 0.0, 0.0, 95.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 74.0, 16.0, 138.0, 0.0, 0.0, 0.0, 0.0, 107.0, 0.0, 0.0, 8.0, 63.0, 81.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 26.0, 200.0, 0.0, 69.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 15.0, 16.0, 32.0, 8.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 181.0, 4.0, 48.0, 16.0, 20.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 4.0, 0.0, 12.0, 13.0, 89.0, 0.0, 0.0, 113.0, 0.0, 17.0, 0.0, 2.0, 0.0, 1.0, 76.0, 9.0, 80.0, 195.0, 60.0, 0.0, 27.0, 30.0, 180.0, 51.0, 0.0, 120.0, 0.0, 86.0, 0.0, 9.0, 0.0, 12.0, 0.0, 196.0, 0.0, 0.0, 1.0, 21.0, 106.0, 105.0, 0.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.389321747976819, "mean_inference_ms": 9.57098710263279, "mean_action_processing_ms": 0.725465252763435, "mean_env_wait_ms": 1.3273319438173907, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.025386691093444824, "StateBufferConnector_ms": 0.019159674644470215, "ViewRequirementAgentConnector_ms": 0.521937370300293}, "num_episodes": 23, "episode_return_max": 307.30000000000064, "episode_return_min": -275.19999999999993, "episode_return_mean": 60.52099999999983, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000, "num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 136.71644970832352, "num_env_steps_trained_throughput_per_sec": 136.71644970832352, "timesteps_total": 456000, "num_env_steps_sampled_lifetime": 456000, "num_agent_steps_sampled_lifetime": 1824000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1824000, "timers": {"training_iteration_time_ms": 29354.335, "restore_workers_time_ms": 0.022, "training_step_time_ms": 29354.248, "sample_time_ms": 4968.297, "learn_time_ms": 24338.888, "learn_throughput": 164.346, "synch_weights_time_ms": 41.303}, "counters": {"num_env_steps_sampled": 456000, "num_env_steps_trained": 456000, "num_agent_steps_sampled": 1824000, "num_agent_steps_trained": 1824000}, "done": false, "training_iteration": 114, "trial_id": "3a355_00000", "date": "2024-08-13_03-03-27", "timestamp": 1723532607, "time_this_iter_s": 29.330626010894775, "time_total_s": 6809.595361948013, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52405e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6809.595361948013, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 86.93658536585365, "ram_util_percent": 83.30243902439025}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8194916685028051, "cur_kl_coeff": 8.271806125530277e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7220098641183643, "policy_loss": -0.001545012857957137, "vf_loss": 2.7235548688621116, "vf_explained_var": 0.0006269177431782717, "kl": 0.0027548692900147276, "entropy": 0.33924585895405873, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 216405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4261363327108993, "cur_kl_coeff": 2.3200453142635523e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.5374506055993375, "policy_loss": -0.00032278434127056726, "vf_loss": 5.537773389917202, "vf_explained_var": 0.07420325755442261, "kl": 0.001389389968297197, "entropy": 0.5452414500650274, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 216405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000}, "env_runners": {"episode_reward_max": 307.30000000000064, "episode_reward_min": -275.19999999999993, "episode_reward_mean": 64.85999999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 1.2799999999999625, "predator_policy": 31.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.9000000000003, 40.0000000000003, 215.29999999999927, 193.99999999999994, -96.60000000000055, 149.69999999999965, 41.00000000000029, 245.1999999999997, 40.0000000000003, -37.19999999999969, -249.1, 142.8999999999996, 76.69999999999948, 40.0000000000003, 14.300000000000116, -275.19999999999993, 33.400000000000205, -104.80000000000098, 161.1999999999996, 17.899999999999956, 41.80000000000033, 233.1999999999992, 307.30000000000064, 35.59999999999974, -56.00000000000071, -64.50000000000105, 297.3, 134.4999999999997, 176.79999999999947, 29.00000000000015, 40.0000000000003, -41.899999999999814, -111.80000000000018, 48.10000000000043, -77.70000000000107, 132.6999999999983, 195.0, -38.299999999999635, 40.0000000000003, 40.0000000000003, -24.899999999999842, 208.2999999999993, 238.1999999999997, 54.400000000000276, -151.30000000000064, -35.89999999999962, 127.29999999999976, 184.19999999999942, 182.19999999999942, 136.89999999999964, 164.49999999999955, 203.99999999999932, 40.0000000000003, 193.99999999999943, 40.0000000000003, -15.00000000000001, 86.30000000000013, 151.49999999999966, 40.0000000000003, 72.39999999999989, 191.9999999999996, 35.600000000000236, 12.500000000000059, -57.899999999999956, -72.30000000000013, 21.300000000000043, 37.80000000000027, 125.29999999999976, -34.59999999999959, 90.0, 99.99999999999991, 81.69999999999895, -84.20000000000005, 87.99999999999994, -54.59999999999991, 221.79999999999913, 96.99999999999989, -175.60000000000065, 165.99999999999952, 305.90000000000003, -7.300000000000054, 27.900000000000116, -79.90000000000018, 115.59999999999977, 208.29999999999933, -108.60000000000016, 40.0000000000003, 40.0000000000003, 241.50000000000009, 28.50000000000003, 269.4999999999996, 111.49999999999982, 66.99999999999926, 46.0, 114.99999999999983, 235.4999999999994, -12.799999999999736, 40.0000000000003, 26.800000000000143, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 194.3, 20.000000000000014, -1.0, 127.99999999999999, -65.80000000000001, -290.79999999999995, 149.0, -49.29999999999989, 20.000000000000014, 8.00000000000006, 151.4, 93.79999999999971, 20.000000000000014, 20.000000000000014, -278.1999999999987, 20.000000000000014, -258.1, -307.0, 20.000000000000014, 119.9, 20.000000000000014, -49.29999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, -84.7, -334.0, -119.20000000000056, 7.399999999999965, 20.000000000000014, -118.60000000000076, -248.20000000000022, -15.699999999999747, 143.9, -195.10000000000045, 20.000000000000014, 20.000000000000014, 21.800000000000043, 72.19999999999962, 134.0, 172.99999999999983, 134.29999999999998, 85.09999999999994, -179.50000000000003, -55.60000000000022, -69.40000000000063, 20.000000000000014, -179.5000000000005, 139.7, 152.6, 20.000000000000014, 114.49999999999999, 156.8, 20.000000000000014, -1.000000000000031, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.600000000000023, -118.30000000000061, 20.000000000000014, -269.80000000000007, 20.000000000000014, 28.100000000000147, 20.000000000000014, -204.70000000000053, 56.00000000000023, 76.69999999999929, 74.0, 50.0, -32.50000000000004, -86.80000000000075, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -103.90000000000003, 188.3, 20.000000000000014, 125.0, 78.1999999999997, 34.39999999999999, 20.000000000000014, 22.700000000000053, -400.0, 20.000000000000014, -124.90000000000063, 20.000000000000014, 107.29999999999998, 147.2, 20.000000000000014, 162.2, 20.000000000000014, 20.000000000000014, 101.90000000000009, 197.3, -80.79999999999984, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 160.1, -360.1, -84.10000000000085, 106.39999999999998, 20.000000000000014, 99.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.40000000000023, 37.999999999999986, 131.0, 20.000000000000014, 11.599999999999973, -7.299999999999891, -5.1999999999999265, 11.599999999999968, -158.50000000000003, 3.199999999999974, -188.5000000000003, -15.69999999999986, 20.000000000000014, 20.000000000000014, 15.799999999999962, 20.000000000000014, 104.29999999999998, 20.000000000000014, -139.6000000000007, -385.0, 200.0, 20.000000000000014, 20.0, 4.700000000000071, 20.000000000000014, 42.80000000000016, -358.0, 200.0, -232.00000000000006, 20.000000000000014, -160.60000000000002, 39.80000000000024, 173.0, -5.200000000000028, 90.19999999999997, 20.000000000000014, -391.6, 146.0, 20.000000000000014, 125.9, 158.0, -238.30000000000004, 20.000000000000014, -3.099999999999972, 20.000000000000014, -13.599999999999818, -196.3000000000001, 155.0, -93.40000000000003, 20.000000000000014, 188.3, -400.0, 73.39999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 122.0, 93.49999999999999, 185.0, -326.5, 197.3, 72.1999999999996, -158.50000000000057, 164.0, -172.0, 20.000000000000014, -331.0, 200.0, 98.29999999999998, 13.69999999999995, 200.0, 0.50000000000001, -36.699999999999754, -24.099999999999895, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 13.70000000000001, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 67.0, 0.0, 160.0, 100.0, 33.0, 17.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.0, 135.0, 181.0, 135.0, 0.0, 3.0, 72.0, 34.0, 0.0, 0.0, 15.0, 64.0, 0.0, 178.0, 0.0, 6.0, 155.0, 107.0, 17.0, 16.0, 90.0, 103.0, 0.0, 0.0, 5.0, 22.0, 0.0, 0.0, 95.0, 35.0, 69.0, 0.0, 0.0, 95.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 74.0, 16.0, 138.0, 0.0, 0.0, 0.0, 0.0, 107.0, 0.0, 0.0, 8.0, 63.0, 81.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 26.0, 200.0, 0.0, 69.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 15.0, 16.0, 32.0, 8.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 181.0, 4.0, 48.0, 16.0, 20.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 4.0, 0.0, 12.0, 13.0, 89.0, 0.0, 0.0, 113.0, 0.0, 17.0, 0.0, 2.0, 0.0, 1.0, 76.0, 9.0, 80.0, 195.0, 60.0, 0.0, 27.0, 30.0, 180.0, 51.0, 0.0, 120.0, 0.0, 86.0, 0.0, 9.0, 0.0, 12.0, 0.0, 196.0, 0.0, 0.0, 1.0, 21.0, 106.0, 105.0, 0.0, 11.0, 127.0, 3.0, 0.0, 54.0, 0.0, 0.0, 18.0, 200.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 5.0, 165.0, 0.0, 0.0, 84.0, 22.0, 124.0, 95.0, 177.0, 0.0, 3.0, 0.0, 35.0, 0.0, 44.0, 4.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3898246374829473, "mean_inference_ms": 9.61563397918242, "mean_action_processing_ms": 0.7273400447141611, "mean_env_wait_ms": 1.2655015573213295, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.025673389434814453, "StateBufferConnector_ms": 0.019243240356445312, "ViewRequirementAgentConnector_ms": 0.5237419605255127}, "num_episodes": 18, "episode_return_max": 307.30000000000064, "episode_return_min": -275.19999999999993, "episode_return_mean": 64.85999999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000, "num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.61314631981625, "num_env_steps_trained_throughput_per_sec": 129.61314631981625, "timesteps_total": 460000, "num_env_steps_sampled_lifetime": 460000, "num_agent_steps_sampled_lifetime": 1840000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1840000, "timers": {"training_iteration_time_ms": 29737.551, "restore_workers_time_ms": 0.022, "training_step_time_ms": 29737.465, "sample_time_ms": 5105.55, "learn_time_ms": 24583.001, "learn_throughput": 162.714, "synch_weights_time_ms": 43.143}, "counters": {"num_env_steps_sampled": 460000, "num_env_steps_trained": 460000, "num_agent_steps_sampled": 1840000, "num_agent_steps_trained": 1840000}, "done": false, "training_iteration": 115, "trial_id": "3a355_00000", "date": "2024-08-13_03-03-58", "timestamp": 1723532638, "time_this_iter_s": 31.004425287246704, "time_total_s": 6840.59978723526, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52f7e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6840.59978723526, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 87.14318181818182, "ram_util_percent": 83.25227272727274}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7013163304202771, "cur_kl_coeff": 4.1359030627651386e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5518886405639547, "policy_loss": -0.0025688223120702244, "vf_loss": 1.5544574562203948, "vf_explained_var": 0.002850846575681495, "kl": 0.014714770754319153, "entropy": 0.31099785865930024, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 218295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.152494624982435, "cur_kl_coeff": 1.1600226571317761e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.9188745846824045, "policy_loss": -0.0008749294465545703, "vf_loss": 5.919749517541714, "vf_explained_var": 0.13446883981820767, "kl": 0.002357663449816849, "entropy": 0.5523389918148203, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 218295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000}, "env_runners": {"episode_reward_max": 307.30000000000064, "episode_reward_min": -454.8999999999999, "episode_reward_mean": 75.49699999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 10.833499999999958, "predator_policy": 26.915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [307.30000000000064, 35.59999999999974, -56.00000000000071, -64.50000000000105, 297.3, 134.4999999999997, 176.79999999999947, 29.00000000000015, 40.0000000000003, -41.899999999999814, -111.80000000000018, 48.10000000000043, -77.70000000000107, 132.6999999999983, 195.0, -38.299999999999635, 40.0000000000003, 40.0000000000003, -24.899999999999842, 208.2999999999993, 238.1999999999997, 54.400000000000276, -151.30000000000064, -35.89999999999962, 127.29999999999976, 184.19999999999942, 182.19999999999942, 136.89999999999964, 164.49999999999955, 203.99999999999932, 40.0000000000003, 193.99999999999943, 40.0000000000003, -15.00000000000001, 86.30000000000013, 151.49999999999966, 40.0000000000003, 72.39999999999989, 191.9999999999996, 35.600000000000236, 12.500000000000059, -57.899999999999956, -72.30000000000013, 21.300000000000043, 37.80000000000027, 125.29999999999976, -34.59999999999959, 90.0, 99.99999999999991, 81.69999999999895, -84.20000000000005, 87.99999999999994, -54.59999999999991, 221.79999999999913, 96.99999999999989, -175.60000000000065, 165.99999999999952, 305.90000000000003, -7.300000000000054, 27.900000000000116, -79.90000000000018, 115.59999999999977, 208.29999999999933, -108.60000000000016, 40.0000000000003, 40.0000000000003, 241.50000000000009, 28.50000000000003, 269.4999999999996, 111.49999999999982, 66.99999999999926, 46.0, 114.99999999999983, 235.4999999999994, -12.799999999999736, 40.0000000000003, 26.800000000000143, 40.0000000000003, 203.79999999999933, 184.89999999999944, 219.99999999999926, 147.39999999999964, 40.0000000000003, 175.89999999999947, 175.00000000000006, 183.79999999999936, -454.8999999999999, 36.70000000000025, 189.3999999999994, 248.79999999999998, 183.09999999999943, -272.09999999999997, 48.10000000000011, 219.99999999999926, -41.399999999999864, -159.9, 188.1999999999994, 214.99999999999923, 153.39999999999955, 141.0999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [172.99999999999983, 134.29999999999998, 85.09999999999994, -179.50000000000003, -55.60000000000022, -69.40000000000063, 20.000000000000014, -179.5000000000005, 139.7, 152.6, 20.000000000000014, 114.49999999999999, 156.8, 20.000000000000014, -1.000000000000031, 20.000000000000014, 20.000000000000014, 20.000000000000014, -13.600000000000023, -118.30000000000061, 20.000000000000014, -269.80000000000007, 20.000000000000014, 28.100000000000147, 20.000000000000014, -204.70000000000053, 56.00000000000023, 76.69999999999929, 74.0, 50.0, -32.50000000000004, -86.80000000000075, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -103.90000000000003, 188.3, 20.000000000000014, 125.0, 78.1999999999997, 34.39999999999999, 20.000000000000014, 22.700000000000053, -400.0, 20.000000000000014, -124.90000000000063, 20.000000000000014, 107.29999999999998, 147.2, 20.000000000000014, 162.2, 20.000000000000014, 20.000000000000014, 101.90000000000009, 197.3, -80.79999999999984, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 160.1, -360.1, -84.10000000000085, 106.39999999999998, 20.000000000000014, 99.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.40000000000023, 37.999999999999986, 131.0, 20.000000000000014, 11.599999999999973, -7.299999999999891, -5.1999999999999265, 11.599999999999968, -158.50000000000003, 3.199999999999974, -188.5000000000003, -15.69999999999986, 20.000000000000014, 20.000000000000014, 15.799999999999962, 20.000000000000014, 104.29999999999998, 20.000000000000014, -139.6000000000007, -385.0, 200.0, 20.000000000000014, 20.0, 4.700000000000071, 20.000000000000014, 42.80000000000016, -358.0, 200.0, -232.00000000000006, 20.000000000000014, -160.60000000000002, 39.80000000000024, 173.0, -5.200000000000028, 90.19999999999997, 20.000000000000014, -391.6, 146.0, 20.000000000000014, 125.9, 158.0, -238.30000000000004, 20.000000000000014, -3.099999999999972, 20.000000000000014, -13.599999999999818, -196.3000000000001, 155.0, -93.40000000000003, 20.000000000000014, 188.3, -400.0, 73.39999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 122.0, 93.49999999999999, 185.0, -326.5, 197.3, 72.1999999999996, -158.50000000000057, 164.0, -172.0, 20.000000000000014, -331.0, 200.0, 98.29999999999998, 13.69999999999995, 200.0, 0.50000000000001, -36.699999999999754, -24.099999999999895, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 13.70000000000001, 20.000000000000014, 20.000000000000014, 183.8, 20.000000000000014, 20.000000000000014, 164.9, 200.0, 20.000000000000014, 200.0, -118.6000000000007, 20.000000000000014, 20.000000000000014, 155.9, 20.000000000000014, 63.800000000000026, 54.19999999999998, 20.000000000000014, 147.79999999999995, -259.3, -391.6, 20.000000000000014, 13.699999999999967, 20.000000000000014, 169.4, 131.6, 117.19999999999999, 163.1, 20.000000000000014, -337.0, -105.10000000000028, -187.90000000000038, 137.0, 20.000000000000014, 200.0, 20.000000000000014, -135.40000000000003, -78.70000000000005, -173.20000000000005, 200.0, -143.8000000000006, 23.000000000000075, 167.0, 20.000000000000014, 133.39999999999998, 82.1, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 95.0, 35.0, 69.0, 0.0, 0.0, 95.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 74.0, 16.0, 138.0, 0.0, 0.0, 0.0, 0.0, 107.0, 0.0, 0.0, 8.0, 63.0, 81.0, 0.0, 0.0, 0.0, 0.0, 0.0, 59.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 26.0, 200.0, 0.0, 69.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 15.0, 16.0, 32.0, 8.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 181.0, 4.0, 48.0, 16.0, 20.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 4.0, 0.0, 12.0, 13.0, 89.0, 0.0, 0.0, 113.0, 0.0, 17.0, 0.0, 2.0, 0.0, 1.0, 76.0, 9.0, 80.0, 195.0, 60.0, 0.0, 27.0, 30.0, 180.0, 51.0, 0.0, 120.0, 0.0, 86.0, 0.0, 9.0, 0.0, 12.0, 0.0, 196.0, 0.0, 0.0, 1.0, 21.0, 106.0, 105.0, 0.0, 11.0, 127.0, 3.0, 0.0, 54.0, 0.0, 0.0, 18.0, 200.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 5.0, 165.0, 0.0, 0.0, 84.0, 22.0, 124.0, 95.0, 177.0, 0.0, 3.0, 0.0, 35.0, 0.0, 44.0, 4.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 57.0, 6.0, 10.0, 0.0, 196.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 170.0, 25.0, 74.0, 0.0, 0.0, 74.0, 0.0, 92.0, 0.0, 67.0, 65.0, 25.0, 0.0, 0.0, 0.0, 0.0, 39.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4599636242359417, "mean_inference_ms": 9.546658421398536, "mean_action_processing_ms": 0.7341856794848681, "mean_env_wait_ms": 1.2677064813882588, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.038163065910339355, "StateBufferConnector_ms": 0.019394636154174805, "ViewRequirementAgentConnector_ms": 0.8399012088775635}, "num_episodes": 22, "episode_return_max": 307.30000000000064, "episode_return_min": -454.8999999999999, "episode_return_mean": 75.49699999999983, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000, "num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 85.03981646558584, "num_env_steps_trained_throughput_per_sec": 85.03981646558584, "timesteps_total": 464000, "num_env_steps_sampled_lifetime": 464000, "num_agent_steps_sampled_lifetime": 1856000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1856000, "timers": {"training_iteration_time_ms": 31564.561, "restore_workers_time_ms": 0.023, "training_step_time_ms": 31564.474, "sample_time_ms": 5923.418, "learn_time_ms": 25588.553, "learn_throughput": 156.32, "synch_weights_time_ms": 45.98}, "counters": {"num_env_steps_sampled": 464000, "num_env_steps_trained": 464000, "num_agent_steps_sampled": 1856000, "num_agent_steps_trained": 1856000}, "done": false, "training_iteration": 116, "trial_id": "3a355_00000", "date": "2024-08-13_03-04-45", "timestamp": 1723532685, "time_this_iter_s": 47.10708999633789, "time_total_s": 6887.706877231598, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5075d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6887.706877231598, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 94.3, "ram_util_percent": 83.12121212121212}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7314660793298451, "cur_kl_coeff": 4.1359030627651386e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1320659716924033, "policy_loss": -0.002196217216699133, "vf_loss": 3.1342621881495076, "vf_explained_var": -0.00030652950049708127, "kl": 0.004276758682678776, "entropy": 0.39797956856785627, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 220185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.5983104733168765, "cur_kl_coeff": 5.800113285658881e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.0316871168752195, "policy_loss": -0.0006596567148648242, "vf_loss": 6.032346780464132, "vf_explained_var": 0.05897478527492947, "kl": 0.002276236377078583, "entropy": 0.6051554405657703, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 220185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000}, "env_runners": {"episode_reward_max": 351.0, "episode_reward_min": -454.8999999999999, "episode_reward_mean": 78.57899999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 8.049499999999966, "predator_policy": 31.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-24.899999999999842, 208.2999999999993, 238.1999999999997, 54.400000000000276, -151.30000000000064, -35.89999999999962, 127.29999999999976, 184.19999999999942, 182.19999999999942, 136.89999999999964, 164.49999999999955, 203.99999999999932, 40.0000000000003, 193.99999999999943, 40.0000000000003, -15.00000000000001, 86.30000000000013, 151.49999999999966, 40.0000000000003, 72.39999999999989, 191.9999999999996, 35.600000000000236, 12.500000000000059, -57.899999999999956, -72.30000000000013, 21.300000000000043, 37.80000000000027, 125.29999999999976, -34.59999999999959, 90.0, 99.99999999999991, 81.69999999999895, -84.20000000000005, 87.99999999999994, -54.59999999999991, 221.79999999999913, 96.99999999999989, -175.60000000000065, 165.99999999999952, 305.90000000000003, -7.300000000000054, 27.900000000000116, -79.90000000000018, 115.59999999999977, 208.29999999999933, -108.60000000000016, 40.0000000000003, 40.0000000000003, 241.50000000000009, 28.50000000000003, 269.4999999999996, 111.49999999999982, 66.99999999999926, 46.0, 114.99999999999983, 235.4999999999994, -12.799999999999736, 40.0000000000003, 26.800000000000143, 40.0000000000003, 203.79999999999933, 184.89999999999944, 219.99999999999926, 147.39999999999964, 40.0000000000003, 175.89999999999947, 175.00000000000006, 183.79999999999936, -454.8999999999999, 36.70000000000025, 189.3999999999994, 248.79999999999998, 183.09999999999943, -272.09999999999997, 48.10000000000011, 219.99999999999926, -41.399999999999864, -159.9, 188.1999999999994, 214.99999999999923, 153.39999999999955, 141.0999999999997, 83.29999999999995, 237.69999999999968, 40.0000000000003, -175.60000000000068, 112.89999999999938, 97.19999999999996, 181.9, -64.80000000000035, 40.0000000000003, 185.79999999999941, 226.4999999999998, 185.79999999999941, -14.799999999999722, -240.20000000000053, 40.0000000000003, -24.09999999999996, 351.0, 131.7], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -103.90000000000003, 188.3, 20.000000000000014, 125.0, 78.1999999999997, 34.39999999999999, 20.000000000000014, 22.700000000000053, -400.0, 20.000000000000014, -124.90000000000063, 20.000000000000014, 107.29999999999998, 147.2, 20.000000000000014, 162.2, 20.000000000000014, 20.000000000000014, 101.90000000000009, 197.3, -80.79999999999984, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 161.0, 20.000000000000014, 20.000000000000014, 160.1, -360.1, -84.10000000000085, 106.39999999999998, 20.000000000000014, 99.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 52.40000000000023, 37.999999999999986, 131.0, 20.000000000000014, 11.599999999999973, -7.299999999999891, -5.1999999999999265, 11.599999999999968, -158.50000000000003, 3.199999999999974, -188.5000000000003, -15.69999999999986, 20.000000000000014, 20.000000000000014, 15.799999999999962, 20.000000000000014, 104.29999999999998, 20.000000000000014, -139.6000000000007, -385.0, 200.0, 20.000000000000014, 20.0, 4.700000000000071, 20.000000000000014, 42.80000000000016, -358.0, 200.0, -232.00000000000006, 20.000000000000014, -160.60000000000002, 39.80000000000024, 173.0, -5.200000000000028, 90.19999999999997, 20.000000000000014, -391.6, 146.0, 20.000000000000014, 125.9, 158.0, -238.30000000000004, 20.000000000000014, -3.099999999999972, 20.000000000000014, -13.599999999999818, -196.3000000000001, 155.0, -93.40000000000003, 20.000000000000014, 188.3, -400.0, 73.39999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 122.0, 93.49999999999999, 185.0, -326.5, 197.3, 72.1999999999996, -158.50000000000057, 164.0, -172.0, 20.000000000000014, -331.0, 200.0, 98.29999999999998, 13.69999999999995, 200.0, 0.50000000000001, -36.699999999999754, -24.099999999999895, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 13.70000000000001, 20.000000000000014, 20.000000000000014, 183.8, 20.000000000000014, 20.000000000000014, 164.9, 200.0, 20.000000000000014, 200.0, -118.6000000000007, 20.000000000000014, 20.000000000000014, 155.9, 20.000000000000014, 63.800000000000026, 54.19999999999998, 20.000000000000014, 147.79999999999995, -259.3, -391.6, 20.000000000000014, 13.699999999999967, 20.000000000000014, 169.4, 131.6, 117.19999999999999, 163.1, 20.000000000000014, -337.0, -105.10000000000028, -187.90000000000038, 137.0, 20.000000000000014, 200.0, 20.000000000000014, -135.40000000000003, -78.70000000000005, -173.20000000000005, 200.0, -143.8000000000006, 23.000000000000075, 167.0, 20.000000000000014, 133.39999999999998, 82.1, 20.000000000000014, 188.0, -225.70000000000002, 200.0, -82.30000000000032, 20.000000000000014, 20.000000000000014, 20.000000000000014, -391.5999999999999, 92.89999999999978, 20.000000000000014, 15.799999999999962, 79.39999999999998, 102.19999999999999, 76.69999999999999, -158.50000000000003, -175.30000000000044, 20.000000000000014, 20.000000000000014, 20.000000000000014, 165.8, 69.4999999999998, 110.0, 165.8, 20.000000000000014, 55.40000000000016, -188.20000000000056, -152.2000000000005, -334.0, 20.000000000000014, 20.000000000000014, -341.19999999999993, 145.09999999999965, 182.0, 149.0, -400.0, 184.7], "policy_predator_policy_reward": [59.0, 0.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 26.0, 200.0, 0.0, 69.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 15.0, 16.0, 32.0, 8.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 181.0, 4.0, 48.0, 16.0, 20.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 4.0, 0.0, 12.0, 13.0, 89.0, 0.0, 0.0, 113.0, 0.0, 17.0, 0.0, 2.0, 0.0, 1.0, 76.0, 9.0, 80.0, 195.0, 60.0, 0.0, 27.0, 30.0, 180.0, 51.0, 0.0, 120.0, 0.0, 86.0, 0.0, 9.0, 0.0, 12.0, 0.0, 196.0, 0.0, 0.0, 1.0, 21.0, 106.0, 105.0, 0.0, 11.0, 127.0, 3.0, 0.0, 54.0, 0.0, 0.0, 18.0, 200.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 5.0, 165.0, 0.0, 0.0, 84.0, 22.0, 124.0, 95.0, 177.0, 0.0, 3.0, 0.0, 35.0, 0.0, 44.0, 4.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 57.0, 6.0, 10.0, 0.0, 196.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 170.0, 25.0, 74.0, 0.0, 0.0, 74.0, 0.0, 92.0, 0.0, 67.0, 65.0, 25.0, 0.0, 0.0, 0.0, 0.0, 39.0, 117.0, 4.0, 55.0, 65.0, 0.0, 0.0, 0.0, 196.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 100.0, 169.0, 0.0, 0.0, 0.0, 0.0, 36.0, 11.0, 0.0, 0.0, 45.0, 73.0, 192.0, 54.0, 0.0, 0.0, 21.0, 151.0, 7.0, 13.0, 147.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.408794991765225, "mean_inference_ms": 9.617830010149191, "mean_action_processing_ms": 0.7384626135079928, "mean_env_wait_ms": 1.2641291331053817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0391840934753418, "StateBufferConnector_ms": 0.02088749408721924, "ViewRequirementAgentConnector_ms": 0.8531897068023682}, "num_episodes": 18, "episode_return_max": 351.0, "episode_return_min": -454.8999999999999, "episode_return_mean": 78.57899999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000, "num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 116.0761221518267, "num_env_steps_trained_throughput_per_sec": 116.0761221518267, "timesteps_total": 468000, "num_env_steps_sampled_lifetime": 468000, "num_agent_steps_sampled_lifetime": 1872000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1872000, "timers": {"training_iteration_time_ms": 32057.577, "restore_workers_time_ms": 0.023, "training_step_time_ms": 32057.489, "sample_time_ms": 5915.483, "learn_time_ms": 26089.137, "learn_throughput": 153.321, "synch_weights_time_ms": 47.352}, "counters": {"num_env_steps_sampled": 468000, "num_env_steps_trained": 468000, "num_agent_steps_sampled": 1872000, "num_agent_steps_trained": 1872000}, "done": false, "training_iteration": 117, "trial_id": "3a355_00000", "date": "2024-08-13_03-05-20", "timestamp": 1723532720, "time_this_iter_s": 34.577656745910645, "time_total_s": 6922.2845339775085, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dbe310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6922.2845339775085, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 89.74081632653062, "ram_util_percent": 83.35714285714286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.748531609927378, "cur_kl_coeff": 2.0679515313825693e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.219309482372627, "policy_loss": -0.0019110314438375768, "vf_loss": 3.221220507823601, "vf_explained_var": -0.0004416742652812332, "kl": 0.003724524768559934, "entropy": 0.341820084583507, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 222075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.472932437338211, "cur_kl_coeff": 2.9000566428294403e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.392211454885977, "policy_loss": -4.825401489460279e-05, "vf_loss": 6.392259714843104, "vf_explained_var": 0.13594905819211686, "kl": 0.002263614630736003, "entropy": 0.5795209191148243, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 222075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000}, "env_runners": {"episode_reward_max": 351.0, "episode_reward_min": -454.8999999999999, "episode_reward_mean": 70.88999999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 1.384999999999976, "predator_policy": 34.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 72.39999999999989, 191.9999999999996, 35.600000000000236, 12.500000000000059, -57.899999999999956, -72.30000000000013, 21.300000000000043, 37.80000000000027, 125.29999999999976, -34.59999999999959, 90.0, 99.99999999999991, 81.69999999999895, -84.20000000000005, 87.99999999999994, -54.59999999999991, 221.79999999999913, 96.99999999999989, -175.60000000000065, 165.99999999999952, 305.90000000000003, -7.300000000000054, 27.900000000000116, -79.90000000000018, 115.59999999999977, 208.29999999999933, -108.60000000000016, 40.0000000000003, 40.0000000000003, 241.50000000000009, 28.50000000000003, 269.4999999999996, 111.49999999999982, 66.99999999999926, 46.0, 114.99999999999983, 235.4999999999994, -12.799999999999736, 40.0000000000003, 26.800000000000143, 40.0000000000003, 203.79999999999933, 184.89999999999944, 219.99999999999926, 147.39999999999964, 40.0000000000003, 175.89999999999947, 175.00000000000006, 183.79999999999936, -454.8999999999999, 36.70000000000025, 189.3999999999994, 248.79999999999998, 183.09999999999943, -272.09999999999997, 48.10000000000011, 219.99999999999926, -41.399999999999864, -159.9, 188.1999999999994, 214.99999999999923, 153.39999999999955, 141.0999999999997, 83.29999999999995, 237.69999999999968, 40.0000000000003, -175.60000000000068, 112.89999999999938, 97.19999999999996, 181.9, -64.80000000000035, 40.0000000000003, 185.79999999999941, 226.4999999999998, 185.79999999999941, -14.799999999999722, -240.20000000000053, 40.0000000000003, -24.09999999999996, 351.0, 131.7, -55.00000000000058, 210.9999999999993, 189.49999999999946, -26.3999999999998, 310.4, -239.30000000000024, 112.0999999999998, 138.99999999999966, 40.0000000000003, 164.49999999999955, 40.0000000000003, -104.10000000000008, 198.19999999999936, -415.9999999999977, -64.50000000000001, 129.0, 193.39999999999978, 193.99999999999952], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 52.40000000000023, 37.999999999999986, 131.0, 20.000000000000014, 11.599999999999973, -7.299999999999891, -5.1999999999999265, 11.599999999999968, -158.50000000000003, 3.199999999999974, -188.5000000000003, -15.69999999999986, 20.000000000000014, 20.000000000000014, 15.799999999999962, 20.000000000000014, 104.29999999999998, 20.000000000000014, -139.6000000000007, -385.0, 200.0, 20.000000000000014, 20.0, 4.700000000000071, 20.000000000000014, 42.80000000000016, -358.0, 200.0, -232.00000000000006, 20.000000000000014, -160.60000000000002, 39.80000000000024, 173.0, -5.200000000000028, 90.19999999999997, 20.000000000000014, -391.6, 146.0, 20.000000000000014, 125.9, 158.0, -238.30000000000004, 20.000000000000014, -3.099999999999972, 20.000000000000014, -13.599999999999818, -196.3000000000001, 155.0, -93.40000000000003, 20.000000000000014, 188.3, -400.0, 73.39999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 122.0, 93.49999999999999, 185.0, -326.5, 197.3, 72.1999999999996, -158.50000000000057, 164.0, -172.0, 20.000000000000014, -331.0, 200.0, 98.29999999999998, 13.69999999999995, 200.0, 0.50000000000001, -36.699999999999754, -24.099999999999895, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 13.70000000000001, 20.000000000000014, 20.000000000000014, 183.8, 20.000000000000014, 20.000000000000014, 164.9, 200.0, 20.000000000000014, 200.0, -118.6000000000007, 20.000000000000014, 20.000000000000014, 155.9, 20.000000000000014, 63.800000000000026, 54.19999999999998, 20.000000000000014, 147.79999999999995, -259.3, -391.6, 20.000000000000014, 13.699999999999967, 20.000000000000014, 169.4, 131.6, 117.19999999999999, 163.1, 20.000000000000014, -337.0, -105.10000000000028, -187.90000000000038, 137.0, 20.000000000000014, 200.0, 20.000000000000014, -135.40000000000003, -78.70000000000005, -173.20000000000005, 200.0, -143.8000000000006, 23.000000000000075, 167.0, 20.000000000000014, 133.39999999999998, 82.1, 20.000000000000014, 188.0, -225.70000000000002, 200.0, -82.30000000000032, 20.000000000000014, 20.000000000000014, 20.000000000000014, -391.5999999999999, 92.89999999999978, 20.000000000000014, 15.799999999999962, 79.39999999999998, 102.19999999999999, 76.69999999999999, -158.50000000000003, -175.30000000000044, 20.000000000000014, 20.000000000000014, 20.000000000000014, 165.8, 69.4999999999998, 110.0, 165.8, 20.000000000000014, 55.40000000000016, -188.20000000000056, -152.2000000000005, -334.0, 20.000000000000014, 20.000000000000014, -341.19999999999993, 145.09999999999965, 182.0, 149.0, -400.0, 184.7, 20.000000000000014, -169.0000000000006, 20.000000000000014, 191.0, -83.50000000000054, 200.0, 71.29999999999963, -204.70000000000036, 100.7, 178.7, -385.0, -112.30000000000004, 165.8, -120.70000000000003, 20.000000000000014, 118.99999999999999, 20.000000000000014, 20.000000000000014, 171.2, -36.699999999999775, 20.000000000000014, 20.000000000000014, 7.399999999999965, -242.50000000000017, 162.2, 20.000000000000014, -334.8999999999994, -255.09999999999883, -143.80000000000004, -15.699999999999747, 86.0, -121.0, 93.50000000000003, 71.89999999999975, 110.0, 17.000000000000064], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 4.0, 0.0, 12.0, 13.0, 89.0, 0.0, 0.0, 113.0, 0.0, 17.0, 0.0, 2.0, 0.0, 1.0, 76.0, 9.0, 80.0, 195.0, 60.0, 0.0, 27.0, 30.0, 180.0, 51.0, 0.0, 120.0, 0.0, 86.0, 0.0, 9.0, 0.0, 12.0, 0.0, 196.0, 0.0, 0.0, 1.0, 21.0, 106.0, 105.0, 0.0, 11.0, 127.0, 3.0, 0.0, 54.0, 0.0, 0.0, 18.0, 200.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 5.0, 165.0, 0.0, 0.0, 84.0, 22.0, 124.0, 95.0, 177.0, 0.0, 3.0, 0.0, 35.0, 0.0, 44.0, 4.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 57.0, 6.0, 10.0, 0.0, 196.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 170.0, 25.0, 74.0, 0.0, 0.0, 74.0, 0.0, 92.0, 0.0, 67.0, 65.0, 25.0, 0.0, 0.0, 0.0, 0.0, 39.0, 117.0, 4.0, 55.0, 65.0, 0.0, 0.0, 0.0, 196.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 100.0, 169.0, 0.0, 0.0, 0.0, 0.0, 36.0, 11.0, 0.0, 0.0, 45.0, 73.0, 192.0, 54.0, 0.0, 0.0, 21.0, 151.0, 7.0, 13.0, 147.0, 200.0, 64.0, 30.0, 0.0, 0.0, 63.0, 10.0, 0.0, 107.0, 0.0, 31.0, 195.0, 63.0, 67.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 4.0, 0.0, 0.0, 125.0, 6.0, 8.0, 8.0, 0.0, 174.0, 95.0, 0.0, 92.0, 72.0, 28.0, 0.0, 45.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4178417611805285, "mean_inference_ms": 9.618298585282927, "mean_action_processing_ms": 0.7433740394961539, "mean_env_wait_ms": 1.263170441519187, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04019272327423096, "StateBufferConnector_ms": 0.02084803581237793, "ViewRequirementAgentConnector_ms": 0.7709165811538696}, "num_episodes": 18, "episode_return_max": 351.0, "episode_return_min": -454.8999999999999, "episode_return_mean": 70.88999999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000, "num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 122.80775929503032, "num_env_steps_trained_throughput_per_sec": 122.80775929503032, "timesteps_total": 472000, "num_env_steps_sampled_lifetime": 472000, "num_agent_steps_sampled_lifetime": 1888000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1888000, "timers": {"training_iteration_time_ms": 32329.256, "restore_workers_time_ms": 0.023, "training_step_time_ms": 32329.165, "sample_time_ms": 5916.324, "learn_time_ms": 26359.302, "learn_throughput": 151.749, "synch_weights_time_ms": 47.461}, "counters": {"num_env_steps_sampled": 472000, "num_env_steps_trained": 472000, "num_agent_steps_sampled": 1888000, "num_agent_steps_trained": 1888000}, "done": false, "training_iteration": 118, "trial_id": "3a355_00000", "date": "2024-08-13_03-05-53", "timestamp": 1723532753, "time_this_iter_s": 32.655462980270386, "time_total_s": 6954.939996957779, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b523ee50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6954.939996957779, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 89.7086956521739, "ram_util_percent": 83.2282608695652}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0357029123714676, "cur_kl_coeff": 1.0339757656912847e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.426838619368417, "policy_loss": -0.0023701739357045244, "vf_loss": 2.429208785768539, "vf_explained_var": 0.0011165842177375915, "kl": 0.0039004601612776225, "entropy": 0.41369236515312596, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 223965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.991634201254479, "cur_kl_coeff": 1.4500283214147202e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.440014766763758, "policy_loss": -0.0006105050572721416, "vf_loss": 6.440625278028862, "vf_explained_var": 0.12832303832447717, "kl": 0.0021142309047868344, "entropy": 0.5437880835362843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 223965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000}, "env_runners": {"episode_reward_max": 352.5, "episode_reward_min": -454.8999999999999, "episode_reward_mean": 88.45699999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 11.838499999999968, "predator_policy": 32.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [27.900000000000116, -79.90000000000018, 115.59999999999977, 208.29999999999933, -108.60000000000016, 40.0000000000003, 40.0000000000003, 241.50000000000009, 28.50000000000003, 269.4999999999996, 111.49999999999982, 66.99999999999926, 46.0, 114.99999999999983, 235.4999999999994, -12.799999999999736, 40.0000000000003, 26.800000000000143, 40.0000000000003, 203.79999999999933, 184.89999999999944, 219.99999999999926, 147.39999999999964, 40.0000000000003, 175.89999999999947, 175.00000000000006, 183.79999999999936, -454.8999999999999, 36.70000000000025, 189.3999999999994, 248.79999999999998, 183.09999999999943, -272.09999999999997, 48.10000000000011, 219.99999999999926, -41.399999999999864, -159.9, 188.1999999999994, 214.99999999999923, 153.39999999999955, 141.0999999999997, 83.29999999999995, 237.69999999999968, 40.0000000000003, -175.60000000000068, 112.89999999999938, 97.19999999999996, 181.9, -64.80000000000035, 40.0000000000003, 185.79999999999941, 226.4999999999998, 185.79999999999941, -14.799999999999722, -240.20000000000053, 40.0000000000003, -24.09999999999996, 351.0, 131.7, -55.00000000000058, 210.9999999999993, 189.49999999999946, -26.3999999999998, 310.4, -239.30000000000024, 112.0999999999998, 138.99999999999966, 40.0000000000003, 164.49999999999955, 40.0000000000003, -104.10000000000008, 198.19999999999936, -415.9999999999977, -64.50000000000001, 129.0, 193.39999999999978, 193.99999999999952, 141.49999999999957, -141.7999999999998, 216.0, -200.40000000000106, 352.5, 103.19999999999987, 40.0000000000003, 305.0, 40.0000000000003, 77.4999999999995, 352.3000000000012, 241.19999999999962, 53.300000000000395, 147.79999999999964, 215.99999999999926, 33.0, -88.29999999999995, 124.19999999999985, 344.3, 256.3, 48.10000000000029, 256.8999999999995, 38.900000000000276], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-3.099999999999972, 20.000000000000014, -13.599999999999818, -196.3000000000001, 155.0, -93.40000000000003, 20.000000000000014, 188.3, -400.0, 73.39999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 122.0, 93.49999999999999, 185.0, -326.5, 197.3, 72.1999999999996, -158.50000000000057, 164.0, -172.0, 20.000000000000014, -331.0, 200.0, 98.29999999999998, 13.69999999999995, 200.0, 0.50000000000001, -36.699999999999754, -24.099999999999895, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 13.70000000000001, 20.000000000000014, 20.000000000000014, 183.8, 20.000000000000014, 20.000000000000014, 164.9, 200.0, 20.000000000000014, 200.0, -118.6000000000007, 20.000000000000014, 20.000000000000014, 155.9, 20.000000000000014, 63.800000000000026, 54.19999999999998, 20.000000000000014, 147.79999999999995, -259.3, -391.6, 20.000000000000014, 13.699999999999967, 20.000000000000014, 169.4, 131.6, 117.19999999999999, 163.1, 20.000000000000014, -337.0, -105.10000000000028, -187.90000000000038, 137.0, 20.000000000000014, 200.0, 20.000000000000014, -135.40000000000003, -78.70000000000005, -173.20000000000005, 200.0, -143.8000000000006, 23.000000000000075, 167.0, 20.000000000000014, 133.39999999999998, 82.1, 20.000000000000014, 188.0, -225.70000000000002, 200.0, -82.30000000000032, 20.000000000000014, 20.000000000000014, 20.000000000000014, -391.5999999999999, 92.89999999999978, 20.000000000000014, 15.799999999999962, 79.39999999999998, 102.19999999999999, 76.69999999999999, -158.50000000000003, -175.30000000000044, 20.000000000000014, 20.000000000000014, 20.000000000000014, 165.8, 69.4999999999998, 110.0, 165.8, 20.000000000000014, 55.40000000000016, -188.20000000000056, -152.2000000000005, -334.0, 20.000000000000014, 20.000000000000014, -341.19999999999993, 145.09999999999965, 182.0, 149.0, -400.0, 184.7, 20.000000000000014, -169.0000000000006, 20.000000000000014, 191.0, -83.50000000000054, 200.0, 71.29999999999963, -204.70000000000036, 100.7, 178.7, -385.0, -112.30000000000004, 165.8, -120.70000000000003, 20.000000000000014, 118.99999999999999, 20.000000000000014, 20.000000000000014, 171.2, -36.699999999999775, 20.000000000000014, 20.000000000000014, 7.399999999999965, -242.50000000000017, 162.2, 20.000000000000014, -334.8999999999994, -255.09999999999883, -143.80000000000004, -15.699999999999747, 86.0, -121.0, 93.50000000000003, 71.89999999999975, 110.0, 17.000000000000064, 173.0, -95.50000000000034, -93.40000000000003, -135.39999999999998, -124.0, 161.0, -227.8000000000003, -118.60000000000076, 145.4, 190.1, -110.20000000000064, 151.4, 20.000000000000014, 20.000000000000014, 152.0, 137.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.500000000000206, 152.2999999999997, 200.0, 45.50000000000011, 166.7, 54.200000000000195, -19.899999999999885, 136.4, -34.59999999999975, 194.0, 20.000000000000014, -346.0, 197.0, -34.30000000000001, -400.0, 136.1, -40.89999999999976, 131.0, 179.3, 134.29999999999998, 83.0, 20.000000000000014, 28.10000000000015, 105.49999999999997, 151.3999999999997, 17.899999999999988, 20.000000000000014], "policy_predator_policy_reward": [0.0, 11.0, 127.0, 3.0, 0.0, 54.0, 0.0, 0.0, 18.0, 200.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 5.0, 165.0, 0.0, 0.0, 84.0, 22.0, 124.0, 95.0, 177.0, 0.0, 3.0, 0.0, 35.0, 0.0, 44.0, 4.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 57.0, 6.0, 10.0, 0.0, 196.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 170.0, 25.0, 74.0, 0.0, 0.0, 74.0, 0.0, 92.0, 0.0, 67.0, 65.0, 25.0, 0.0, 0.0, 0.0, 0.0, 39.0, 117.0, 4.0, 55.0, 65.0, 0.0, 0.0, 0.0, 196.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 100.0, 169.0, 0.0, 0.0, 0.0, 0.0, 36.0, 11.0, 0.0, 0.0, 45.0, 73.0, 192.0, 54.0, 0.0, 0.0, 21.0, 151.0, 7.0, 13.0, 147.0, 200.0, 64.0, 30.0, 0.0, 0.0, 63.0, 10.0, 0.0, 107.0, 0.0, 31.0, 195.0, 63.0, 67.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 4.0, 0.0, 0.0, 125.0, 6.0, 8.0, 8.0, 0.0, 174.0, 95.0, 0.0, 92.0, 72.0, 28.0, 0.0, 45.0, 22.0, 9.0, 55.0, 54.0, 33.0, 86.0, 93.0, 46.0, 100.0, 17.0, 0.0, 0.0, 62.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 10.0, 19.0, 7.0, 12.0, 20.0, 26.0, 0.0, 2.0, 182.0, 0.0, 200.0, 146.0, 0.0, 29.0, 20.0, 14.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4287843201739676, "mean_inference_ms": 9.61490742930842, "mean_action_processing_ms": 0.7491688227992479, "mean_env_wait_ms": 1.2605786679644213, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.032243967056274414, "StateBufferConnector_ms": 0.016630053520202637, "ViewRequirementAgentConnector_ms": 0.7672102451324463}, "num_episodes": 23, "episode_return_max": 352.5, "episode_return_min": -454.8999999999999, "episode_return_mean": 88.45699999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000, "num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 119.41409453380462, "num_env_steps_trained_throughput_per_sec": 119.41409453380462, "timesteps_total": 476000, "num_env_steps_sampled_lifetime": 476000, "num_agent_steps_sampled_lifetime": 1904000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1904000, "timers": {"training_iteration_time_ms": 32635.235, "restore_workers_time_ms": 0.023, "training_step_time_ms": 32635.144, "sample_time_ms": 5941.935, "learn_time_ms": 26640.828, "learn_throughput": 150.145, "synch_weights_time_ms": 45.867}, "counters": {"num_env_steps_sampled": 476000, "num_env_steps_trained": 476000, "num_agent_steps_sampled": 1904000, "num_agent_steps_trained": 1904000}, "done": false, "training_iteration": 119, "trial_id": "3a355_00000", "date": "2024-08-13_03-06-26", "timestamp": 1723532786, "time_this_iter_s": 33.570993185043335, "time_total_s": 6988.510990142822, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5293a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 6988.510990142822, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 88.71063829787234, "ram_util_percent": 83.17659574468085}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.01059646134181, "cur_kl_coeff": 5.169878828456423e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1718552576801766, "policy_loss": -0.0029085403621177037, "vf_loss": 2.174763797515284, "vf_explained_var": 0.0005427172575047407, "kl": 0.003700278996201165, "entropy": 0.3814146456895051, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 225855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.916274746874022, "cur_kl_coeff": 7.250141607073601e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.0851190765068015, "policy_loss": 0.00018519446877122083, "vf_loss": 5.084933883677084, "vf_explained_var": 0.2503292457451896, "kl": 0.0021781784574817194, "entropy": 0.7252266868081673, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 225855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": -454.8999999999999, "episode_reward_mean": 89.60999999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 14.134999999999955, "predator_policy": 30.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [147.39999999999964, 40.0000000000003, 175.89999999999947, 175.00000000000006, 183.79999999999936, -454.8999999999999, 36.70000000000025, 189.3999999999994, 248.79999999999998, 183.09999999999943, -272.09999999999997, 48.10000000000011, 219.99999999999926, -41.399999999999864, -159.9, 188.1999999999994, 214.99999999999923, 153.39999999999955, 141.0999999999997, 83.29999999999995, 237.69999999999968, 40.0000000000003, -175.60000000000068, 112.89999999999938, 97.19999999999996, 181.9, -64.80000000000035, 40.0000000000003, 185.79999999999941, 226.4999999999998, 185.79999999999941, -14.799999999999722, -240.20000000000053, 40.0000000000003, -24.09999999999996, 351.0, 131.7, -55.00000000000058, 210.9999999999993, 189.49999999999946, -26.3999999999998, 310.4, -239.30000000000024, 112.0999999999998, 138.99999999999966, 40.0000000000003, 164.49999999999955, 40.0000000000003, -104.10000000000008, 198.19999999999936, -415.9999999999977, -64.50000000000001, 129.0, 193.39999999999978, 193.99999999999952, 141.49999999999957, -141.7999999999998, 216.0, -200.40000000000106, 352.5, 103.19999999999987, 40.0000000000003, 305.0, 40.0000000000003, 77.4999999999995, 352.3000000000012, 241.19999999999962, 53.300000000000395, 147.79999999999964, 215.99999999999926, 33.0, -88.29999999999995, 124.19999999999985, 344.3, 256.3, 48.10000000000029, 256.8999999999995, 38.900000000000276, 180.39999999999944, 109.19999999999973, -86.30000000000159, 40.0000000000003, 40.0000000000003, 43.800000000000445, 157.9999999999996, 174.9999999999995, 195.7999999999994, 219.99999999999926, 212.79999999999984, -3.9999999999997455, 20.199999999999996, 394.6, 89.39999999999989, -80.40000000000141, -1.499999999999782, 92.1999999999999, 203.89999999999932, -114.00000000000102, 219.99999999999926, 66.70000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, -118.6000000000007, 20.000000000000014, 20.000000000000014, 155.9, 20.000000000000014, 63.800000000000026, 54.19999999999998, 20.000000000000014, 147.79999999999995, -259.3, -391.6, 20.000000000000014, 13.699999999999967, 20.000000000000014, 169.4, 131.6, 117.19999999999999, 163.1, 20.000000000000014, -337.0, -105.10000000000028, -187.90000000000038, 137.0, 20.000000000000014, 200.0, 20.000000000000014, -135.40000000000003, -78.70000000000005, -173.20000000000005, 200.0, -143.8000000000006, 23.000000000000075, 167.0, 20.000000000000014, 133.39999999999998, 82.1, 20.000000000000014, 188.0, -225.70000000000002, 200.0, -82.30000000000032, 20.000000000000014, 20.000000000000014, 20.000000000000014, -391.5999999999999, 92.89999999999978, 20.000000000000014, 15.799999999999962, 79.39999999999998, 102.19999999999999, 76.69999999999999, -158.50000000000003, -175.30000000000044, 20.000000000000014, 20.000000000000014, 20.000000000000014, 165.8, 69.4999999999998, 110.0, 165.8, 20.000000000000014, 55.40000000000016, -188.20000000000056, -152.2000000000005, -334.0, 20.000000000000014, 20.000000000000014, -341.19999999999993, 145.09999999999965, 182.0, 149.0, -400.0, 184.7, 20.000000000000014, -169.0000000000006, 20.000000000000014, 191.0, -83.50000000000054, 200.0, 71.29999999999963, -204.70000000000036, 100.7, 178.7, -385.0, -112.30000000000004, 165.8, -120.70000000000003, 20.000000000000014, 118.99999999999999, 20.000000000000014, 20.000000000000014, 171.2, -36.699999999999775, 20.000000000000014, 20.000000000000014, 7.399999999999965, -242.50000000000017, 162.2, 20.000000000000014, -334.8999999999994, -255.09999999999883, -143.80000000000004, -15.699999999999747, 86.0, -121.0, 93.50000000000003, 71.89999999999975, 110.0, 17.000000000000064, 173.0, -95.50000000000034, -93.40000000000003, -135.39999999999998, -124.0, 161.0, -227.8000000000003, -118.60000000000076, 145.4, 190.1, -110.20000000000064, 151.4, 20.000000000000014, 20.000000000000014, 152.0, 137.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.500000000000206, 152.2999999999997, 200.0, 45.50000000000011, 166.7, 54.200000000000195, -19.899999999999885, 136.4, -34.59999999999975, 194.0, 20.000000000000014, -346.0, 197.0, -34.30000000000001, -400.0, 136.1, -40.89999999999976, 131.0, 179.3, 134.29999999999998, 83.0, 20.000000000000014, 28.10000000000015, 105.49999999999997, 151.3999999999997, 17.899999999999988, 20.000000000000014, 160.4, 20.000000000000014, 83.0, -56.79999999999991, -82.90000000000086, -72.40000000000074, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -41.49999999999981, 35.30000000000026, 107.0, 20.000000000000014, 20.000000000000014, 155.0, -26.200000000000017, 200.0, 20.000000000000014, 200.0, 158.9, -6.100000000000165, 20.000000000000014, -64.00000000000088, 20.000000000000014, -17.799999999999784, 195.5, 199.1, -28.29999999999987, 94.69999999999997, -103.60000000000065, -101.80000000000076, -47.20000000000003, 13.699999999999976, -150.10000000000048, 161.3, 184.1, 15.799999999999962, -273.99999999999864, 20.000000000000014, 20.000000000000014, 200.0, -162.70000000000047, 142.39999999999998], "policy_predator_policy_reward": [66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 57.0, 6.0, 10.0, 0.0, 196.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 170.0, 25.0, 74.0, 0.0, 0.0, 74.0, 0.0, 92.0, 0.0, 67.0, 65.0, 25.0, 0.0, 0.0, 0.0, 0.0, 39.0, 117.0, 4.0, 55.0, 65.0, 0.0, 0.0, 0.0, 196.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 100.0, 169.0, 0.0, 0.0, 0.0, 0.0, 36.0, 11.0, 0.0, 0.0, 45.0, 73.0, 192.0, 54.0, 0.0, 0.0, 21.0, 151.0, 7.0, 13.0, 147.0, 200.0, 64.0, 30.0, 0.0, 0.0, 63.0, 10.0, 0.0, 107.0, 0.0, 31.0, 195.0, 63.0, 67.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 4.0, 0.0, 0.0, 125.0, 6.0, 8.0, 8.0, 0.0, 174.0, 95.0, 0.0, 92.0, 72.0, 28.0, 0.0, 45.0, 22.0, 9.0, 55.0, 54.0, 33.0, 86.0, 93.0, 46.0, 100.0, 17.0, 0.0, 0.0, 62.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 10.0, 19.0, 7.0, 12.0, 20.0, 26.0, 0.0, 2.0, 182.0, 0.0, 200.0, 146.0, 0.0, 29.0, 20.0, 14.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 67.0, 16.0, 0.0, 69.0, 0.0, 0.0, 0.0, 0.0, 19.0, 31.0, 31.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 56.0, 4.0, 0.0, 40.0, 18.0, 0.0, 0.0, 0.0, 23.0, 0.0, 58.0, 67.0, 0.0, 32.0, 81.0, 0.0, 0.0, 4.0, 0.0, 140.0, 0.0, 0.0, 87.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4924842102478437, "mean_inference_ms": 9.53961772450411, "mean_action_processing_ms": 0.7541959215279712, "mean_env_wait_ms": 1.261678352928029, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.032186031341552734, "StateBufferConnector_ms": 0.01505887508392334, "ViewRequirementAgentConnector_ms": 0.7349565029144287}, "num_episodes": 22, "episode_return_max": 394.6, "episode_return_min": -454.8999999999999, "episode_return_mean": 89.60999999999984, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000, "num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 127.56724734501661, "num_env_steps_trained_throughput_per_sec": 127.56724734501661, "timesteps_total": 480000, "num_env_steps_sampled_lifetime": 480000, "num_agent_steps_sampled_lifetime": 1920000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1920000, "timers": {"training_iteration_time_ms": 32804.264, "restore_workers_time_ms": 0.024, "training_step_time_ms": 32804.173, "sample_time_ms": 5988.548, "learn_time_ms": 26768.177, "learn_throughput": 149.431, "synch_weights_time_ms": 41.233}, "counters": {"num_env_steps_sampled": 480000, "num_env_steps_trained": 480000, "num_agent_steps_sampled": 1920000, "num_agent_steps_trained": 1920000}, "done": false, "training_iteration": 120, "trial_id": "3a355_00000", "date": "2024-08-13_03-06-58", "timestamp": 1723532818, "time_this_iter_s": 31.483537197113037, "time_total_s": 7019.994527339935, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3dbe310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7019.994527339935, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 88.16444444444444, "ram_util_percent": 83.15333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7356436729628257, "cur_kl_coeff": 2.5849394142282116e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0370232056057644, "policy_loss": -0.0010435922881933274, "vf_loss": 2.0380667884198447, "vf_explained_var": 6.141791898737509e-05, "kl": 0.0023787470788585066, "entropy": 0.3191856325697647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 227745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.584988278237285, "cur_kl_coeff": 3.6250708035368004e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.440592007031516, "policy_loss": -0.000939708893685035, "vf_loss": 4.441531719354095, "vf_explained_var": 0.24320936644518817, "kl": 0.0021469437531634007, "entropy": 0.8137450998737699, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 227745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": -415.9999999999977, "episode_reward_mean": 93.32399999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 16.906999999999957, "predator_policy": 29.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [141.0999999999997, 83.29999999999995, 237.69999999999968, 40.0000000000003, -175.60000000000068, 112.89999999999938, 97.19999999999996, 181.9, -64.80000000000035, 40.0000000000003, 185.79999999999941, 226.4999999999998, 185.79999999999941, -14.799999999999722, -240.20000000000053, 40.0000000000003, -24.09999999999996, 351.0, 131.7, -55.00000000000058, 210.9999999999993, 189.49999999999946, -26.3999999999998, 310.4, -239.30000000000024, 112.0999999999998, 138.99999999999966, 40.0000000000003, 164.49999999999955, 40.0000000000003, -104.10000000000008, 198.19999999999936, -415.9999999999977, -64.50000000000001, 129.0, 193.39999999999978, 193.99999999999952, 141.49999999999957, -141.7999999999998, 216.0, -200.40000000000106, 352.5, 103.19999999999987, 40.0000000000003, 305.0, 40.0000000000003, 77.4999999999995, 352.3000000000012, 241.19999999999962, 53.300000000000395, 147.79999999999964, 215.99999999999926, 33.0, -88.29999999999995, 124.19999999999985, 344.3, 256.3, 48.10000000000029, 256.8999999999995, 38.900000000000276, 180.39999999999944, 109.19999999999973, -86.30000000000159, 40.0000000000003, 40.0000000000003, 43.800000000000445, 157.9999999999996, 174.9999999999995, 195.7999999999994, 219.99999999999926, 212.79999999999984, -3.9999999999997455, 20.199999999999996, 394.6, 89.39999999999989, -80.40000000000141, -1.499999999999782, 92.1999999999999, 203.89999999999932, -114.00000000000102, 219.99999999999926, 66.70000000000005, 217.99999999999926, 102.69999999999987, -17.899999999999515, 165.0999999999995, 315.4, 8.100000000000103, 179.99999999999935, -77.40000000000029, 219.99999999999926, 219.99999999999926, 174.09999999999948, 14.699999999999946, 31.200000000000287, -134.90000000000123, 40.0000000000003, 17.399999999999935, 40.0000000000003, 131.39999999999972], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [82.1, 20.000000000000014, 188.0, -225.70000000000002, 200.0, -82.30000000000032, 20.000000000000014, 20.000000000000014, 20.000000000000014, -391.5999999999999, 92.89999999999978, 20.000000000000014, 15.799999999999962, 79.39999999999998, 102.19999999999999, 76.69999999999999, -158.50000000000003, -175.30000000000044, 20.000000000000014, 20.000000000000014, 20.000000000000014, 165.8, 69.4999999999998, 110.0, 165.8, 20.000000000000014, 55.40000000000016, -188.20000000000056, -152.2000000000005, -334.0, 20.000000000000014, 20.000000000000014, -341.19999999999993, 145.09999999999965, 182.0, 149.0, -400.0, 184.7, 20.000000000000014, -169.0000000000006, 20.000000000000014, 191.0, -83.50000000000054, 200.0, 71.29999999999963, -204.70000000000036, 100.7, 178.7, -385.0, -112.30000000000004, 165.8, -120.70000000000003, 20.000000000000014, 118.99999999999999, 20.000000000000014, 20.000000000000014, 171.2, -36.699999999999775, 20.000000000000014, 20.000000000000014, 7.399999999999965, -242.50000000000017, 162.2, 20.000000000000014, -334.8999999999994, -255.09999999999883, -143.80000000000004, -15.699999999999747, 86.0, -121.0, 93.50000000000003, 71.89999999999975, 110.0, 17.000000000000064, 173.0, -95.50000000000034, -93.40000000000003, -135.39999999999998, -124.0, 161.0, -227.8000000000003, -118.60000000000076, 145.4, 190.1, -110.20000000000064, 151.4, 20.000000000000014, 20.000000000000014, 152.0, 137.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.500000000000206, 152.2999999999997, 200.0, 45.50000000000011, 166.7, 54.200000000000195, -19.899999999999885, 136.4, -34.59999999999975, 194.0, 20.000000000000014, -346.0, 197.0, -34.30000000000001, -400.0, 136.1, -40.89999999999976, 131.0, 179.3, 134.29999999999998, 83.0, 20.000000000000014, 28.10000000000015, 105.49999999999997, 151.3999999999997, 17.899999999999988, 20.000000000000014, 160.4, 20.000000000000014, 83.0, -56.79999999999991, -82.90000000000086, -72.40000000000074, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -41.49999999999981, 35.30000000000026, 107.0, 20.000000000000014, 20.000000000000014, 155.0, -26.200000000000017, 200.0, 20.000000000000014, 200.0, 158.9, -6.100000000000165, 20.000000000000014, -64.00000000000088, 20.000000000000014, -17.799999999999784, 195.5, 199.1, -28.29999999999987, 94.69999999999997, -103.60000000000065, -101.80000000000076, -47.20000000000003, 13.699999999999976, -150.10000000000048, 161.3, 184.1, 15.799999999999962, -273.99999999999864, 20.000000000000014, 20.000000000000014, 200.0, -162.70000000000047, 142.39999999999998, 20.000000000000014, 197.0, -131.20000000000073, 146.9, -55.600000000000335, -28.299999999999763, 127.10000000000002, 20.000000000000014, 152.3, 163.1, 20.000000000000014, -40.89999999999976, 20.000000000000014, 140.0, 20.000000000000014, -234.40000000000015, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 154.1, -37.299999999999805, 20.000000000000014, 5.299999999999957, 17.900000000000006, -156.4000000000001, -137.50000000000068, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999767, 20.000000000000014, 20.000000000000014, -200.50000000000054, 164.9], "policy_predator_policy_reward": [0.0, 39.0, 117.0, 4.0, 55.0, 65.0, 0.0, 0.0, 0.0, 196.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 100.0, 169.0, 0.0, 0.0, 0.0, 0.0, 36.0, 11.0, 0.0, 0.0, 45.0, 73.0, 192.0, 54.0, 0.0, 0.0, 21.0, 151.0, 7.0, 13.0, 147.0, 200.0, 64.0, 30.0, 0.0, 0.0, 63.0, 10.0, 0.0, 107.0, 0.0, 31.0, 195.0, 63.0, 67.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 4.0, 0.0, 0.0, 125.0, 6.0, 8.0, 8.0, 0.0, 174.0, 95.0, 0.0, 92.0, 72.0, 28.0, 0.0, 45.0, 22.0, 9.0, 55.0, 54.0, 33.0, 86.0, 93.0, 46.0, 100.0, 17.0, 0.0, 0.0, 62.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 10.0, 19.0, 7.0, 12.0, 20.0, 26.0, 0.0, 2.0, 182.0, 0.0, 200.0, 146.0, 0.0, 29.0, 20.0, 14.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 67.0, 16.0, 0.0, 69.0, 0.0, 0.0, 0.0, 0.0, 19.0, 31.0, 31.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 56.0, 4.0, 0.0, 40.0, 18.0, 0.0, 0.0, 0.0, 23.0, 0.0, 58.0, 67.0, 0.0, 32.0, 81.0, 0.0, 0.0, 4.0, 0.0, 140.0, 0.0, 0.0, 87.0, 0.0, 0.0, 1.0, 72.0, 15.0, 17.0, 49.0, 0.0, 18.0, 0.0, 0.0, 0.0, 29.0, 0.0, 20.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 25.0, 0.0, 8.0, 131.0, 28.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 83.0, 84.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4319347545347556, "mean_inference_ms": 9.579959218090693, "mean_action_processing_ms": 0.7546835712150284, "mean_env_wait_ms": 1.2551421217697327, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0224151611328125, "StateBufferConnector_ms": 0.009297847747802734, "ViewRequirementAgentConnector_ms": 0.4150584936141968}, "num_episodes": 18, "episode_return_max": 394.6, "episode_return_min": -415.9999999999977, "episode_return_mean": 93.32399999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000, "num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 132.73938294427305, "num_env_steps_trained_throughput_per_sec": 132.73938294427305, "timesteps_total": 484000, "num_env_steps_sampled_lifetime": 484000, "num_agent_steps_sampled_lifetime": 1936000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1936000, "timers": {"training_iteration_time_ms": 32796.324, "restore_workers_time_ms": 0.023, "training_step_time_ms": 32796.235, "sample_time_ms": 5935.318, "learn_time_ms": 26816.236, "learn_throughput": 149.163, "synch_weights_time_ms": 38.669}, "counters": {"num_env_steps_sampled": 484000, "num_env_steps_trained": 484000, "num_agent_steps_sampled": 1936000, "num_agent_steps_trained": 1936000}, "done": false, "training_iteration": 121, "trial_id": "3a355_00000", "date": "2024-08-13_03-07-28", "timestamp": 1723532848, "time_this_iter_s": 30.21907925605774, "time_total_s": 7050.213606595993, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5204040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7050.213606595993, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 88.38333333333333, "ram_util_percent": 83.06190476190476}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7703221622992444, "cur_kl_coeff": 1.2924697071141058e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.193376734900096, "policy_loss": -0.0010606374847825872, "vf_loss": 2.1944373725583315, "vf_explained_var": 0.00036842053529446717, "kl": 0.003804503875264703, "entropy": 0.3224457936390998, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 229635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.557360411596992, "cur_kl_coeff": 1.8125354017684002e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.316278537745198, "policy_loss": -0.0009113656518310703, "vf_loss": 4.317189884816528, "vf_explained_var": 0.07670987825545053, "kl": 0.0007423133350950098, "entropy": 0.7641043270075762, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 229635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": -415.9999999999977, "episode_reward_mean": 90.5719999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 18.355999999999966, "predator_policy": 26.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.7, -55.00000000000058, 210.9999999999993, 189.49999999999946, -26.3999999999998, 310.4, -239.30000000000024, 112.0999999999998, 138.99999999999966, 40.0000000000003, 164.49999999999955, 40.0000000000003, -104.10000000000008, 198.19999999999936, -415.9999999999977, -64.50000000000001, 129.0, 193.39999999999978, 193.99999999999952, 141.49999999999957, -141.7999999999998, 216.0, -200.40000000000106, 352.5, 103.19999999999987, 40.0000000000003, 305.0, 40.0000000000003, 77.4999999999995, 352.3000000000012, 241.19999999999962, 53.300000000000395, 147.79999999999964, 215.99999999999926, 33.0, -88.29999999999995, 124.19999999999985, 344.3, 256.3, 48.10000000000029, 256.8999999999995, 38.900000000000276, 180.39999999999944, 109.19999999999973, -86.30000000000159, 40.0000000000003, 40.0000000000003, 43.800000000000445, 157.9999999999996, 174.9999999999995, 195.7999999999994, 219.99999999999926, 212.79999999999984, -3.9999999999997455, 20.199999999999996, 394.6, 89.39999999999989, -80.40000000000141, -1.499999999999782, 92.1999999999999, 203.89999999999932, -114.00000000000102, 219.99999999999926, 66.70000000000005, 217.99999999999926, 102.69999999999987, -17.899999999999515, 165.0999999999995, 315.4, 8.100000000000103, 179.99999999999935, -77.40000000000029, 219.99999999999926, 219.99999999999926, 174.09999999999948, 14.699999999999946, 31.200000000000287, -134.90000000000123, 40.0000000000003, 17.399999999999935, 40.0000000000003, 131.39999999999972, -104.10000000000053, 145.19999999999962, 40.0000000000003, 174.4999999999995, 183.99999999999932, 38.900000000000276, 40.0000000000003, 40.0000000000003, 215.99999999999926, 199.59999999999937, -93.00000000000004, -51.00000000000044, 40.0000000000003, 208.99999999999932, 40.0000000000003, 177.69999999999945, -74.40000000000117, -93.90000000000032], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-400.0, 184.7, 20.000000000000014, -169.0000000000006, 20.000000000000014, 191.0, -83.50000000000054, 200.0, 71.29999999999963, -204.70000000000036, 100.7, 178.7, -385.0, -112.30000000000004, 165.8, -120.70000000000003, 20.000000000000014, 118.99999999999999, 20.000000000000014, 20.000000000000014, 171.2, -36.699999999999775, 20.000000000000014, 20.000000000000014, 7.399999999999965, -242.50000000000017, 162.2, 20.000000000000014, -334.8999999999994, -255.09999999999883, -143.80000000000004, -15.699999999999747, 86.0, -121.0, 93.50000000000003, 71.89999999999975, 110.0, 17.000000000000064, 173.0, -95.50000000000034, -93.40000000000003, -135.39999999999998, -124.0, 161.0, -227.8000000000003, -118.60000000000076, 145.4, 190.1, -110.20000000000064, 151.4, 20.000000000000014, 20.000000000000014, 152.0, 137.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.500000000000206, 152.2999999999997, 200.0, 45.50000000000011, 166.7, 54.200000000000195, -19.899999999999885, 136.4, -34.59999999999975, 194.0, 20.000000000000014, -346.0, 197.0, -34.30000000000001, -400.0, 136.1, -40.89999999999976, 131.0, 179.3, 134.29999999999998, 83.0, 20.000000000000014, 28.10000000000015, 105.49999999999997, 151.3999999999997, 17.899999999999988, 20.000000000000014, 160.4, 20.000000000000014, 83.0, -56.79999999999991, -82.90000000000086, -72.40000000000074, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -41.49999999999981, 35.30000000000026, 107.0, 20.000000000000014, 20.000000000000014, 155.0, -26.200000000000017, 200.0, 20.000000000000014, 200.0, 158.9, -6.100000000000165, 20.000000000000014, -64.00000000000088, 20.000000000000014, -17.799999999999784, 195.5, 199.1, -28.29999999999987, 94.69999999999997, -103.60000000000065, -101.80000000000076, -47.20000000000003, 13.699999999999976, -150.10000000000048, 161.3, 184.1, 15.799999999999962, -273.99999999999864, 20.000000000000014, 20.000000000000014, 200.0, -162.70000000000047, 142.39999999999998, 20.000000000000014, 197.0, -131.20000000000073, 146.9, -55.600000000000335, -28.299999999999763, 127.10000000000002, 20.000000000000014, 152.3, 163.1, 20.000000000000014, -40.89999999999976, 20.000000000000014, 140.0, 20.000000000000014, -234.40000000000015, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 154.1, -37.299999999999805, 20.000000000000014, 5.299999999999957, 17.900000000000006, -156.4000000000001, -137.50000000000068, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999767, 20.000000000000014, 20.000000000000014, -200.50000000000054, 164.9, 20.000000000000014, -264.0999999999996, -9.399999999999855, 140.6, 20.000000000000014, 20.000000000000014, 151.7, 15.799999999999963, 20.000000000000014, 146.0, 17.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 194.0, 13.699999999999964, 182.9, -400.0, 64.99999999999996, -0.9999999999999992, -148.00000000000068, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 157.7, -198.40000000000052, 20.000000000000014, 20.000000000000014, -262.89999999999986], "policy_predator_policy_reward": [147.0, 200.0, 64.0, 30.0, 0.0, 0.0, 63.0, 10.0, 0.0, 107.0, 0.0, 31.0, 195.0, 63.0, 67.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 4.0, 0.0, 0.0, 125.0, 6.0, 8.0, 8.0, 0.0, 174.0, 95.0, 0.0, 92.0, 72.0, 28.0, 0.0, 45.0, 22.0, 9.0, 55.0, 54.0, 33.0, 86.0, 93.0, 46.0, 100.0, 17.0, 0.0, 0.0, 62.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 10.0, 19.0, 7.0, 12.0, 20.0, 26.0, 0.0, 2.0, 182.0, 0.0, 200.0, 146.0, 0.0, 29.0, 20.0, 14.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 67.0, 16.0, 0.0, 69.0, 0.0, 0.0, 0.0, 0.0, 19.0, 31.0, 31.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 56.0, 4.0, 0.0, 40.0, 18.0, 0.0, 0.0, 0.0, 23.0, 0.0, 58.0, 67.0, 0.0, 32.0, 81.0, 0.0, 0.0, 4.0, 0.0, 140.0, 0.0, 0.0, 87.0, 0.0, 0.0, 1.0, 72.0, 15.0, 17.0, 49.0, 0.0, 18.0, 0.0, 0.0, 0.0, 29.0, 0.0, 20.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 25.0, 0.0, 8.0, 131.0, 28.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 83.0, 84.0, 140.0, 0.0, 14.0, 0.0, 0.0, 0.0, 5.0, 2.0, 13.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 42.0, 200.0, 18.0, 80.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.0, 0.0, 103.0, 46.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4287007283371587, "mean_inference_ms": 9.551327532556897, "mean_action_processing_ms": 0.7554683898258954, "mean_env_wait_ms": 1.2508425837824364, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021062612533569336, "StateBufferConnector_ms": 0.007592558860778809, "ViewRequirementAgentConnector_ms": 0.3889436721801758}, "num_episodes": 18, "episode_return_max": 394.6, "episode_return_min": -415.9999999999977, "episode_return_mean": 90.5719999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000, "num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 137.7175337700355, "num_env_steps_trained_throughput_per_sec": 137.7175337700355, "timesteps_total": 488000, "num_env_steps_sampled_lifetime": 488000, "num_agent_steps_sampled_lifetime": 1952000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1952000, "timers": {"training_iteration_time_ms": 32788.211, "restore_workers_time_ms": 0.023, "training_step_time_ms": 32788.122, "sample_time_ms": 5938.484, "learn_time_ms": 26804.188, "learn_throughput": 149.23, "synch_weights_time_ms": 39.146}, "counters": {"num_env_steps_sampled": 488000, "num_env_steps_trained": 488000, "num_agent_steps_sampled": 1952000, "num_agent_steps_trained": 1952000}, "done": false, "training_iteration": 122, "trial_id": "3a355_00000", "date": "2024-08-13_03-07-57", "timestamp": 1723532877, "time_this_iter_s": 29.120296955108643, "time_total_s": 7079.333903551102, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b551af70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7079.333903551102, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 87.57317073170732, "ram_util_percent": 83.40243902439023}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6528292060292588, "cur_kl_coeff": 6.462348535570529e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.653027929136993, "policy_loss": -0.0007742760918551573, "vf_loss": 2.6538022072857648, "vf_explained_var": -0.0001845376832144601, "kl": 0.0021039022799514344, "entropy": 0.30648428529658645, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 231525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.950346182893823, "cur_kl_coeff": 9.062677008842001e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.244694624754487, "policy_loss": -0.0011939637675861675, "vf_loss": 6.245888573278195, "vf_explained_var": 0.289386512110473, "kl": 0.00393227067906285, "entropy": 0.7437995156913838, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 231525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000}, "env_runners": {"episode_reward_max": 394.6, "episode_reward_min": -455.1, "episode_reward_mean": 94.35699999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 22.218499999999977, "predator_policy": 24.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [352.5, 103.19999999999987, 40.0000000000003, 305.0, 40.0000000000003, 77.4999999999995, 352.3000000000012, 241.19999999999962, 53.300000000000395, 147.79999999999964, 215.99999999999926, 33.0, -88.29999999999995, 124.19999999999985, 344.3, 256.3, 48.10000000000029, 256.8999999999995, 38.900000000000276, 180.39999999999944, 109.19999999999973, -86.30000000000159, 40.0000000000003, 40.0000000000003, 43.800000000000445, 157.9999999999996, 174.9999999999995, 195.7999999999994, 219.99999999999926, 212.79999999999984, -3.9999999999997455, 20.199999999999996, 394.6, 89.39999999999989, -80.40000000000141, -1.499999999999782, 92.1999999999999, 203.89999999999932, -114.00000000000102, 219.99999999999926, 66.70000000000005, 217.99999999999926, 102.69999999999987, -17.899999999999515, 165.0999999999995, 315.4, 8.100000000000103, 179.99999999999935, -77.40000000000029, 219.99999999999926, 219.99999999999926, 174.09999999999948, 14.699999999999946, 31.200000000000287, -134.90000000000123, 40.0000000000003, 17.399999999999935, 40.0000000000003, 131.39999999999972, -104.10000000000053, 145.19999999999962, 40.0000000000003, 174.4999999999995, 183.99999999999932, 38.900000000000276, 40.0000000000003, 40.0000000000003, 215.99999999999926, 199.59999999999937, -93.00000000000004, -51.00000000000044, 40.0000000000003, 208.99999999999932, 40.0000000000003, 177.69999999999945, -74.40000000000117, -93.90000000000032, 21.30000000000001, 219.99999999999926, 59.20000000000006, 314.500000000001, -69.00000000000009, 40.0000000000003, 135.3999999999998, 179.19999999999945, -77.70000000000115, -19.399999999999835, 219.99999999999926, 310.0, 17.599999999999973, 116.19999999999868, 192.4999999999994, -455.1, 304.6000000000009, -24.0, 135.99999999999972, 158.49999999999957, 20.199999999999978, 74.599999999999, -333.30000000000024], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [145.4, 190.1, -110.20000000000064, 151.4, 20.000000000000014, 20.000000000000014, 152.0, 137.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 51.500000000000206, 152.2999999999997, 200.0, 45.50000000000011, 166.7, 54.200000000000195, -19.899999999999885, 136.4, -34.59999999999975, 194.0, 20.000000000000014, -346.0, 197.0, -34.30000000000001, -400.0, 136.1, -40.89999999999976, 131.0, 179.3, 134.29999999999998, 83.0, 20.000000000000014, 28.10000000000015, 105.49999999999997, 151.3999999999997, 17.899999999999988, 20.000000000000014, 160.4, 20.000000000000014, 83.0, -56.79999999999991, -82.90000000000086, -72.40000000000074, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -41.49999999999981, 35.30000000000026, 107.0, 20.000000000000014, 20.000000000000014, 155.0, -26.200000000000017, 200.0, 20.000000000000014, 200.0, 158.9, -6.100000000000165, 20.000000000000014, -64.00000000000088, 20.000000000000014, -17.799999999999784, 195.5, 199.1, -28.29999999999987, 94.69999999999997, -103.60000000000065, -101.80000000000076, -47.20000000000003, 13.699999999999976, -150.10000000000048, 161.3, 184.1, 15.799999999999962, -273.99999999999864, 20.000000000000014, 20.000000000000014, 200.0, -162.70000000000047, 142.39999999999998, 20.000000000000014, 197.0, -131.20000000000073, 146.9, -55.600000000000335, -28.299999999999763, 127.10000000000002, 20.000000000000014, 152.3, 163.1, 20.000000000000014, -40.89999999999976, 20.000000000000014, 140.0, 20.000000000000014, -234.40000000000015, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 154.1, -37.299999999999805, 20.000000000000014, 5.299999999999957, 17.900000000000006, -156.4000000000001, -137.50000000000068, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999767, 20.000000000000014, 20.000000000000014, -200.50000000000054, 164.9, 20.000000000000014, -264.0999999999996, -9.399999999999855, 140.6, 20.000000000000014, 20.000000000000014, 151.7, 15.799999999999963, 20.000000000000014, 146.0, 17.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 194.0, 13.699999999999964, 182.9, -400.0, 64.99999999999996, -0.9999999999999992, -148.00000000000068, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 157.7, -198.40000000000052, 20.000000000000014, 20.000000000000014, -262.89999999999986, 20.000000000000014, -15.699999999999811, 20.000000000000014, 200.0, -286.5999999999988, 174.8, 192.8, 121.6999999999995, 20.000000000000014, -385.0, 20.000000000000014, 20.000000000000014, -36.699999999999754, 145.1, 152.0, 3.199999999999981, 20.000000000000014, -204.7000000000005, 20.000000000000014, -93.40000000000018, 20.000000000000014, 200.0, 200.0, -55.0, 91.09999999999962, -158.50000000000003, 17.899999999999988, 92.29999999999941, 9.500000000000007, 167.0, -339.1, -337.0, 105.4999999999996, 199.1, 176.0, -400.0, 171.2, -89.19999999999979, -74.50000000000003, 182.0, 20.000000000000014, -17.79999999999974, 20.000000000000014, 2.5999999999997385, -133.3, -400.0], "policy_predator_policy_reward": [17.0, 0.0, 0.0, 62.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 1.0, 5.0, 0.0, 0.0, 10.0, 19.0, 7.0, 12.0, 20.0, 26.0, 0.0, 2.0, 182.0, 0.0, 200.0, 146.0, 0.0, 29.0, 20.0, 14.0, 39.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 67.0, 16.0, 0.0, 69.0, 0.0, 0.0, 0.0, 0.0, 19.0, 31.0, 31.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 56.0, 4.0, 0.0, 40.0, 18.0, 0.0, 0.0, 0.0, 23.0, 0.0, 58.0, 67.0, 0.0, 32.0, 81.0, 0.0, 0.0, 4.0, 0.0, 140.0, 0.0, 0.0, 87.0, 0.0, 0.0, 1.0, 72.0, 15.0, 17.0, 49.0, 0.0, 18.0, 0.0, 0.0, 0.0, 29.0, 0.0, 20.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 25.0, 0.0, 8.0, 131.0, 28.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 83.0, 84.0, 140.0, 0.0, 14.0, 0.0, 0.0, 0.0, 5.0, 2.0, 13.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 42.0, 200.0, 18.0, 80.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.0, 0.0, 103.0, 46.0, 0.0, 17.0, 0.0, 0.0, 142.0, 29.0, 0.0, 0.0, 114.0, 182.0, 0.0, 0.0, 27.0, 0.0, 0.0, 24.0, 0.0, 107.0, 0.0, 54.0, 0.0, 0.0, 85.0, 80.0, 0.0, 85.0, 0.0, 6.0, 0.0, 16.0, 170.0, 51.0, 0.0, 0.0, 0.0, 200.0, 2.0, 52.0, 8.0, 43.0, 0.0, 18.0, 0.0, 52.0, 0.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.425234643746498, "mean_inference_ms": 9.45837724943034, "mean_action_processing_ms": 0.7569656526499118, "mean_env_wait_ms": 1.2989083019638406, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0164945125579834, "StateBufferConnector_ms": 0.021056771278381348, "ViewRequirementAgentConnector_ms": 0.42672884464263916}, "num_episodes": 23, "episode_return_max": 394.6, "episode_return_min": -455.1, "episode_return_mean": 94.35699999999979, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000, "num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 131.61636218925628, "num_env_steps_trained_throughput_per_sec": 131.61636218925628, "timesteps_total": 492000, "num_env_steps_sampled_lifetime": 492000, "num_agent_steps_sampled_lifetime": 1968000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1968000, "timers": {"training_iteration_time_ms": 32861.044, "restore_workers_time_ms": 0.022, "training_step_time_ms": 32860.972, "sample_time_ms": 5878.737, "learn_time_ms": 26929.394, "learn_throughput": 148.537, "synch_weights_time_ms": 46.849}, "counters": {"num_env_steps_sampled": 492000, "num_env_steps_trained": 492000, "num_agent_steps_sampled": 1968000, "num_agent_steps_trained": 1968000}, "done": false, "training_iteration": 123, "trial_id": "3a355_00000", "date": "2024-08-13_03-08-28", "timestamp": 1723532908, "time_this_iter_s": 30.490312099456787, "time_total_s": 7109.8242156505585, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5239dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7109.8242156505585, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 87.35909090909091, "ram_util_percent": 83.175}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8989485760529836, "cur_kl_coeff": 3.2311742677852645e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.938712978741479, "policy_loss": -0.0014503887539148016, "vf_loss": 2.9401633629723203, "vf_explained_var": 0.0009382694486587766, "kl": 0.0023162375662272696, "entropy": 0.32784471224855494, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 233415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 9.069916097701542, "cur_kl_coeff": 4.5313385044210005e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.758813544682094, "policy_loss": -0.0016681159374663833, "vf_loss": 6.760481658057561, "vf_explained_var": 0.3048676908646942, "kl": 0.002930426368324171, "entropy": 0.6801334731793277, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 233415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -455.1, "episode_reward_mean": 85.22199999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 17.00599999999997, "predator_policy": 25.605}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.900000000000276, 180.39999999999944, 109.19999999999973, -86.30000000000159, 40.0000000000003, 40.0000000000003, 43.800000000000445, 157.9999999999996, 174.9999999999995, 195.7999999999994, 219.99999999999926, 212.79999999999984, -3.9999999999997455, 20.199999999999996, 394.6, 89.39999999999989, -80.40000000000141, -1.499999999999782, 92.1999999999999, 203.89999999999932, -114.00000000000102, 219.99999999999926, 66.70000000000005, 217.99999999999926, 102.69999999999987, -17.899999999999515, 165.0999999999995, 315.4, 8.100000000000103, 179.99999999999935, -77.40000000000029, 219.99999999999926, 219.99999999999926, 174.09999999999948, 14.699999999999946, 31.200000000000287, -134.90000000000123, 40.0000000000003, 17.399999999999935, 40.0000000000003, 131.39999999999972, -104.10000000000053, 145.19999999999962, 40.0000000000003, 174.4999999999995, 183.99999999999932, 38.900000000000276, 40.0000000000003, 40.0000000000003, 215.99999999999926, 199.59999999999937, -93.00000000000004, -51.00000000000044, 40.0000000000003, 208.99999999999932, 40.0000000000003, 177.69999999999945, -74.40000000000117, -93.90000000000032, 21.30000000000001, 219.99999999999926, 59.20000000000006, 314.500000000001, -69.00000000000009, 40.0000000000003, 135.3999999999998, 179.19999999999945, -77.70000000000115, -19.399999999999835, 219.99999999999926, 310.0, 17.599999999999973, 116.19999999999868, 192.4999999999994, -455.1, 304.6000000000009, -24.0, 135.99999999999972, 158.49999999999957, 20.199999999999978, 74.599999999999, -333.30000000000024, 318.6, -185.70000000000093, 138.99999999999966, 193.99999999999966, 40.0000000000003, 39.80000000000009, 127.49999999999972, 133.1999999999997, -381.0, 138.09999999999968, 122.79999999999865, 195.9999999999994, 400.0, 219.99999999999926, 9.500000000000034, 128.19999999999976, 189.79999999999941, 159.99999999999957], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [17.899999999999988, 20.000000000000014, 160.4, 20.000000000000014, 83.0, -56.79999999999991, -82.90000000000086, -72.40000000000074, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -41.49999999999981, 35.30000000000026, 107.0, 20.000000000000014, 20.000000000000014, 155.0, -26.200000000000017, 200.0, 20.000000000000014, 200.0, 158.9, -6.100000000000165, 20.000000000000014, -64.00000000000088, 20.000000000000014, -17.799999999999784, 195.5, 199.1, -28.29999999999987, 94.69999999999997, -103.60000000000065, -101.80000000000076, -47.20000000000003, 13.699999999999976, -150.10000000000048, 161.3, 184.1, 15.799999999999962, -273.99999999999864, 20.000000000000014, 20.000000000000014, 200.0, -162.70000000000047, 142.39999999999998, 20.000000000000014, 197.0, -131.20000000000073, 146.9, -55.600000000000335, -28.299999999999763, 127.10000000000002, 20.000000000000014, 152.3, 163.1, 20.000000000000014, -40.89999999999976, 20.000000000000014, 140.0, 20.000000000000014, -234.40000000000015, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 154.1, -37.299999999999805, 20.000000000000014, 5.299999999999957, 17.900000000000006, -156.4000000000001, -137.50000000000068, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999767, 20.000000000000014, 20.000000000000014, -200.50000000000054, 164.9, 20.000000000000014, -264.0999999999996, -9.399999999999855, 140.6, 20.000000000000014, 20.000000000000014, 151.7, 15.799999999999963, 20.000000000000014, 146.0, 17.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 194.0, 13.699999999999964, 182.9, -400.0, 64.99999999999996, -0.9999999999999992, -148.00000000000068, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 157.7, -198.40000000000052, 20.000000000000014, 20.000000000000014, -262.89999999999986, 20.000000000000014, -15.699999999999811, 20.000000000000014, 200.0, -286.5999999999988, 174.8, 192.8, 121.6999999999995, 20.000000000000014, -385.0, 20.000000000000014, 20.000000000000014, -36.699999999999754, 145.1, 152.0, 3.199999999999981, 20.000000000000014, -204.7000000000005, 20.000000000000014, -93.40000000000018, 20.000000000000014, 200.0, 200.0, -55.0, 91.09999999999962, -158.50000000000003, 17.899999999999988, 92.29999999999941, 9.500000000000007, 167.0, -339.1, -337.0, 105.4999999999996, 199.1, 176.0, -400.0, 171.2, -89.19999999999979, -74.50000000000003, 182.0, 20.000000000000014, -17.79999999999974, 20.000000000000014, 2.5999999999997385, -133.3, -400.0, 113.0, 176.6, -338.7999999999995, -82.8999999999998, 20.000000000000014, 118.99999999999999, 189.2, -110.20000000000024, 20.000000000000014, 20.000000000000014, 15.799999999999963, -67.0, 155.9, -72.40000000000003, 126.19999999999999, -48.99999999999989, -274.0, -267.99999999999994, 180.2, -108.09999999999982, 102.79999999999939, 20.000000000000014, 164.0, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, -156.40000000000066, 74.89999999999942, 20.000000000000014, 108.19999999999999, 167.0, 15.800000000000002, 176.0, -64.00000000000001], "policy_predator_policy_reward": [0.0, 1.0, 0.0, 0.0, 67.0, 16.0, 0.0, 69.0, 0.0, 0.0, 0.0, 0.0, 19.0, 31.0, 31.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 56.0, 4.0, 0.0, 40.0, 18.0, 0.0, 0.0, 0.0, 23.0, 0.0, 58.0, 67.0, 0.0, 32.0, 81.0, 0.0, 0.0, 4.0, 0.0, 140.0, 0.0, 0.0, 87.0, 0.0, 0.0, 1.0, 72.0, 15.0, 17.0, 49.0, 0.0, 18.0, 0.0, 0.0, 0.0, 29.0, 0.0, 20.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 25.0, 0.0, 8.0, 131.0, 28.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 83.0, 84.0, 140.0, 0.0, 14.0, 0.0, 0.0, 0.0, 5.0, 2.0, 13.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 42.0, 200.0, 18.0, 80.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.0, 0.0, 103.0, 46.0, 0.0, 17.0, 0.0, 0.0, 142.0, 29.0, 0.0, 0.0, 114.0, 182.0, 0.0, 0.0, 27.0, 0.0, 0.0, 24.0, 0.0, 107.0, 0.0, 54.0, 0.0, 0.0, 85.0, 80.0, 0.0, 85.0, 0.0, 6.0, 0.0, 16.0, 170.0, 51.0, 0.0, 0.0, 0.0, 200.0, 2.0, 52.0, 8.0, 43.0, 0.0, 18.0, 0.0, 52.0, 0.0, 200.0, 0.0, 29.0, 73.0, 163.0, 0.0, 0.0, 61.0, 54.0, 0.0, 0.0, 72.0, 19.0, 44.0, 0.0, 56.0, 0.0, 140.0, 21.0, 5.0, 61.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 27.0, 0.0, 0.0, 7.0, 0.0, 43.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4236730599425873, "mean_inference_ms": 9.494385668722959, "mean_action_processing_ms": 0.7573896917565066, "mean_env_wait_ms": 1.2412204270739136, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014789342880249023, "StateBufferConnector_ms": 0.021056175231933594, "ViewRequirementAgentConnector_ms": 0.42266225814819336}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -455.1, "episode_return_mean": 85.22199999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000, "num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 129.49188738406045, "num_env_steps_trained_throughput_per_sec": 129.49188738406045, "timesteps_total": 496000, "num_env_steps_sampled_lifetime": 496000, "num_agent_steps_sampled_lifetime": 1984000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1984000, "timers": {"training_iteration_time_ms": 33024.278, "restore_workers_time_ms": 0.022, "training_step_time_ms": 33024.205, "sample_time_ms": 5885.654, "learn_time_ms": 27084.237, "learn_throughput": 147.687, "synch_weights_time_ms": 47.772}, "counters": {"num_env_steps_sampled": 496000, "num_env_steps_trained": 496000, "num_agent_steps_sampled": 1984000, "num_agent_steps_trained": 1984000}, "done": false, "training_iteration": 124, "trial_id": "3a355_00000", "date": "2024-08-13_03-08-59", "timestamp": 1723532939, "time_this_iter_s": 30.95678973197937, "time_total_s": 7140.781005382538, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5293a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7140.781005382538, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 86.77272727272728, "ram_util_percent": 82.91818181818184}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9353258435688322, "cur_kl_coeff": 1.6155871338926323e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.777108654206392, "policy_loss": -0.0022941239022960264, "vf_loss": 2.779402784064964, "vf_explained_var": 0.002187451136806024, "kl": 0.003454620603028861, "entropy": 0.31272012261013504, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 235305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.509766677668486, "cur_kl_coeff": 2.2656692522105003e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.125339052412245, "policy_loss": -0.0009454040388975825, "vf_loss": 7.126284471390739, "vf_explained_var": 0.3858558388298782, "kl": 0.0040641281392789445, "entropy": 0.7360726856050037, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 235305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -455.1, "episode_reward_mean": 84.81699999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 14.943499999999963, "predator_policy": 27.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [66.70000000000005, 217.99999999999926, 102.69999999999987, -17.899999999999515, 165.0999999999995, 315.4, 8.100000000000103, 179.99999999999935, -77.40000000000029, 219.99999999999926, 219.99999999999926, 174.09999999999948, 14.699999999999946, 31.200000000000287, -134.90000000000123, 40.0000000000003, 17.399999999999935, 40.0000000000003, 131.39999999999972, -104.10000000000053, 145.19999999999962, 40.0000000000003, 174.4999999999995, 183.99999999999932, 38.900000000000276, 40.0000000000003, 40.0000000000003, 215.99999999999926, 199.59999999999937, -93.00000000000004, -51.00000000000044, 40.0000000000003, 208.99999999999932, 40.0000000000003, 177.69999999999945, -74.40000000000117, -93.90000000000032, 21.30000000000001, 219.99999999999926, 59.20000000000006, 314.500000000001, -69.00000000000009, 40.0000000000003, 135.3999999999998, 179.19999999999945, -77.70000000000115, -19.399999999999835, 219.99999999999926, 310.0, 17.599999999999973, 116.19999999999868, 192.4999999999994, -455.1, 304.6000000000009, -24.0, 135.99999999999972, 158.49999999999957, 20.199999999999978, 74.599999999999, -333.30000000000024, 318.6, -185.70000000000093, 138.99999999999966, 193.99999999999966, 40.0000000000003, 39.80000000000009, 127.49999999999972, 133.1999999999997, -381.0, 138.09999999999968, 122.79999999999865, 195.9999999999994, 400.0, 219.99999999999926, 9.500000000000034, 128.19999999999976, 189.79999999999941, 159.99999999999957, 391.0, 92.49999999999999, -276.8, 40.0000000000003, 195.99999999999937, 388.3, 379.8, 350.50000000000006, 95.19999999999993, 38.00000000000031, -240.2000000000007, 219.99999999999926, 201.29999999999936, 53.700000000000045, -287.4999999999998, 209.99999999999932, -23.7999999999996, 20.699999999999832, 136.79999999999964, 207.39999999999932, 10.29999999999992, -95.70000000000111], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-162.70000000000047, 142.39999999999998, 20.000000000000014, 197.0, -131.20000000000073, 146.9, -55.600000000000335, -28.299999999999763, 127.10000000000002, 20.000000000000014, 152.3, 163.1, 20.000000000000014, -40.89999999999976, 20.000000000000014, 140.0, 20.000000000000014, -234.40000000000015, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 154.1, -37.299999999999805, 20.000000000000014, 5.299999999999957, 17.900000000000006, -156.4000000000001, -137.50000000000068, 20.000000000000014, 20.000000000000014, 20.000000000000014, -25.599999999999767, 20.000000000000014, 20.000000000000014, -200.50000000000054, 164.9, 20.000000000000014, -264.0999999999996, -9.399999999999855, 140.6, 20.000000000000014, 20.000000000000014, 151.7, 15.799999999999963, 20.000000000000014, 146.0, 17.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 194.0, 13.699999999999964, 182.9, -400.0, 64.99999999999996, -0.9999999999999992, -148.00000000000068, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 157.7, -198.40000000000052, 20.000000000000014, 20.000000000000014, -262.89999999999986, 20.000000000000014, -15.699999999999811, 20.000000000000014, 200.0, -286.5999999999988, 174.8, 192.8, 121.6999999999995, 20.000000000000014, -385.0, 20.000000000000014, 20.000000000000014, -36.699999999999754, 145.1, 152.0, 3.199999999999981, 20.000000000000014, -204.7000000000005, 20.000000000000014, -93.40000000000018, 20.000000000000014, 200.0, 200.0, -55.0, 91.09999999999962, -158.50000000000003, 17.899999999999988, 92.29999999999941, 9.500000000000007, 167.0, -339.1, -337.0, 105.4999999999996, 199.1, 176.0, -400.0, 171.2, -89.19999999999979, -74.50000000000003, 182.0, 20.000000000000014, -17.79999999999974, 20.000000000000014, 2.5999999999997385, -133.3, -400.0, 113.0, 176.6, -338.7999999999995, -82.8999999999998, 20.000000000000014, 118.99999999999999, 189.2, -110.20000000000024, 20.000000000000014, 20.000000000000014, 15.799999999999963, -67.0, 155.9, -72.40000000000003, 126.19999999999999, -48.99999999999989, -274.0, -267.99999999999994, 180.2, -108.09999999999982, 102.79999999999939, 20.000000000000014, 164.0, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, -156.40000000000066, 74.89999999999942, 20.000000000000014, 108.19999999999999, 167.0, 15.800000000000002, 176.0, -64.00000000000001, 200.0, 191.0, -118.60000000000068, 145.1, -198.40000000000003, -198.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 188.3, 194.0, 183.8, 200.0, 150.5, -227.8, 200.0, 20.000000000000014, -1.000000000000028, -223.60000000000048, -169.60000000000056, 200.0, 20.000000000000014, 200.0, -15.699999999999918, 191.0, -280.3, -257.19999999999993, -217.29999999999987, 20.000000000000014, 185.0, -101.80000000000071, 20.000000000000014, -94.0, 13.699999999999948, 138.79999999999998, -22.000000000000025, 187.4, 20.000000000000014, -36.69999999999986, 20.000000000000014, -68.20000000000059, -125.50000000000051], "policy_predator_policy_reward": [87.0, 0.0, 0.0, 1.0, 72.0, 15.0, 17.0, 49.0, 0.0, 18.0, 0.0, 0.0, 0.0, 29.0, 0.0, 20.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 25.0, 0.0, 8.0, 131.0, 28.0, 0.0, 0.0, 23.0, 0.0, 0.0, 0.0, 83.0, 84.0, 140.0, 0.0, 14.0, 0.0, 0.0, 0.0, 5.0, 2.0, 13.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 42.0, 200.0, 18.0, 80.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.0, 0.0, 103.0, 46.0, 0.0, 17.0, 0.0, 0.0, 142.0, 29.0, 0.0, 0.0, 114.0, 182.0, 0.0, 0.0, 27.0, 0.0, 0.0, 24.0, 0.0, 107.0, 0.0, 54.0, 0.0, 0.0, 85.0, 80.0, 0.0, 85.0, 0.0, 6.0, 0.0, 16.0, 170.0, 51.0, 0.0, 0.0, 0.0, 200.0, 2.0, 52.0, 8.0, 43.0, 0.0, 18.0, 0.0, 52.0, 0.0, 200.0, 0.0, 29.0, 73.0, 163.0, 0.0, 0.0, 61.0, 54.0, 0.0, 0.0, 72.0, 19.0, 44.0, 0.0, 56.0, 0.0, 140.0, 21.0, 5.0, 61.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 27.0, 0.0, 0.0, 7.0, 0.0, 43.0, 5.0, 0.0, 0.0, 0.0, 66.0, 15.0, 105.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 118.0, 4.0, 15.0, 112.0, 41.0, 0.0, 0.0, 17.0, 0.0, 143.0, 0.0, 120.0, 67.0, 5.0, 0.0, 0.0, 58.0, 3.0, 98.0, 20.0, 0.0, 0.0, 0.0, 27.0, 0.0, 3.0, 95.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4222692351743005, "mean_inference_ms": 9.472583947574964, "mean_action_processing_ms": 0.7592993027064953, "mean_env_wait_ms": 1.2384781431701988, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010782957077026367, "StateBufferConnector_ms": 0.021584391593933105, "ViewRequirementAgentConnector_ms": 0.5190984010696411}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -455.1, "episode_return_mean": 84.81699999999974, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000, "num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 117.27610696486192, "num_env_steps_trained_throughput_per_sec": 117.27610696486192, "timesteps_total": 500000, "num_env_steps_sampled_lifetime": 500000, "num_agent_steps_sampled_lifetime": 2000000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2000000, "timers": {"training_iteration_time_ms": 33348.926, "restore_workers_time_ms": 0.022, "training_step_time_ms": 33348.852, "sample_time_ms": 5931.017, "learn_time_ms": 27364.914, "learn_throughput": 146.173, "synch_weights_time_ms": 46.164}, "counters": {"num_env_steps_sampled": 500000, "num_env_steps_trained": 500000, "num_agent_steps_sampled": 2000000, "num_agent_steps_trained": 2000000}, "done": false, "training_iteration": 125, "trial_id": "3a355_00000", "date": "2024-08-13_03-09-33", "timestamp": 1723532973, "time_this_iter_s": 34.17463827133179, "time_total_s": 7174.95564365387, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52fd3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7174.95564365387, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 88.48541666666667, "ram_util_percent": 83.13125000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8164511298731206, "cur_kl_coeff": 8.077935669463161e-29, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2332857993544724, "policy_loss": -0.001357369885592667, "vf_loss": 3.2346431652704877, "vf_explained_var": -0.0006185519316839794, "kl": 0.0025760730676907765, "entropy": 0.31397435706916943, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 237195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.74241734596472, "cur_kl_coeff": 1.1328346261052501e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.696919412461538, "policy_loss": -0.0006841017737142032, "vf_loss": 7.69760350323228, "vf_explained_var": 0.37705375312497375, "kl": 0.0024446245669448924, "entropy": 0.758105919285426, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 237195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -455.1, "episode_reward_mean": 85.50599999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 12.442999999999966, "predator_policy": 30.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.39999999999972, -104.10000000000053, 145.19999999999962, 40.0000000000003, 174.4999999999995, 183.99999999999932, 38.900000000000276, 40.0000000000003, 40.0000000000003, 215.99999999999926, 199.59999999999937, -93.00000000000004, -51.00000000000044, 40.0000000000003, 208.99999999999932, 40.0000000000003, 177.69999999999945, -74.40000000000117, -93.90000000000032, 21.30000000000001, 219.99999999999926, 59.20000000000006, 314.500000000001, -69.00000000000009, 40.0000000000003, 135.3999999999998, 179.19999999999945, -77.70000000000115, -19.399999999999835, 219.99999999999926, 310.0, 17.599999999999973, 116.19999999999868, 192.4999999999994, -455.1, 304.6000000000009, -24.0, 135.99999999999972, 158.49999999999957, 20.199999999999978, 74.599999999999, -333.30000000000024, 318.6, -185.70000000000093, 138.99999999999966, 193.99999999999966, 40.0000000000003, 39.80000000000009, 127.49999999999972, 133.1999999999997, -381.0, 138.09999999999968, 122.79999999999865, 195.9999999999994, 400.0, 219.99999999999926, 9.500000000000034, 128.19999999999976, 189.79999999999941, 159.99999999999957, 391.0, 92.49999999999999, -276.8, 40.0000000000003, 195.99999999999937, 388.3, 379.8, 350.50000000000006, 95.19999999999993, 38.00000000000031, -240.2000000000007, 219.99999999999926, 201.29999999999936, 53.700000000000045, -287.4999999999998, 209.99999999999932, -23.7999999999996, 20.699999999999832, 136.79999999999964, 207.39999999999932, 10.29999999999992, -95.70000000000111, 157.89999999999955, 40.0000000000003, 300.0, -427.79999999999995, 219.99999999999926, 239.69999999999993, 171.69999999999948, 134.19999999999982, 400.0, 175.89999999999947, 379.3, 127.9999999999997, -54.59999999999988, -175.20000000000002, 194.49999999999937, -62.29999999999983, -123.40000000000018, -45.79999999999987], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-200.50000000000054, 164.9, 20.000000000000014, -264.0999999999996, -9.399999999999855, 140.6, 20.000000000000014, 20.000000000000014, 151.7, 15.799999999999963, 20.000000000000014, 146.0, 17.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 194.0, 13.699999999999964, 182.9, -400.0, 64.99999999999996, -0.9999999999999992, -148.00000000000068, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 157.7, -198.40000000000052, 20.000000000000014, 20.000000000000014, -262.89999999999986, 20.000000000000014, -15.699999999999811, 20.000000000000014, 200.0, -286.5999999999988, 174.8, 192.8, 121.6999999999995, 20.000000000000014, -385.0, 20.000000000000014, 20.000000000000014, -36.699999999999754, 145.1, 152.0, 3.199999999999981, 20.000000000000014, -204.7000000000005, 20.000000000000014, -93.40000000000018, 20.000000000000014, 200.0, 200.0, -55.0, 91.09999999999962, -158.50000000000003, 17.899999999999988, 92.29999999999941, 9.500000000000007, 167.0, -339.1, -337.0, 105.4999999999996, 199.1, 176.0, -400.0, 171.2, -89.19999999999979, -74.50000000000003, 182.0, 20.000000000000014, -17.79999999999974, 20.000000000000014, 2.5999999999997385, -133.3, -400.0, 113.0, 176.6, -338.7999999999995, -82.8999999999998, 20.000000000000014, 118.99999999999999, 189.2, -110.20000000000024, 20.000000000000014, 20.000000000000014, 15.799999999999963, -67.0, 155.9, -72.40000000000003, 126.19999999999999, -48.99999999999989, -274.0, -267.99999999999994, 180.2, -108.09999999999982, 102.79999999999939, 20.000000000000014, 164.0, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, -156.40000000000066, 74.89999999999942, 20.000000000000014, 108.19999999999999, 167.0, 15.800000000000002, 176.0, -64.00000000000001, 200.0, 191.0, -118.60000000000068, 145.1, -198.40000000000003, -198.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 188.3, 194.0, 183.8, 200.0, 150.5, -227.8, 200.0, 20.000000000000014, -1.000000000000028, -223.60000000000048, -169.60000000000056, 200.0, 20.000000000000014, 200.0, -15.699999999999918, 191.0, -280.3, -257.19999999999993, -217.29999999999987, 20.000000000000014, 185.0, -101.80000000000071, 20.000000000000014, -94.0, 13.699999999999948, 138.79999999999998, -22.000000000000025, 187.4, 20.000000000000014, -36.69999999999986, 20.000000000000014, -68.20000000000059, -125.50000000000051, 20.000000000000014, 137.89999999999998, 20.000000000000014, 20.000000000000014, 158.0, 71.0, -400.0, -269.8, 200.0, 20.000000000000014, 131.0, 85.69999999999997, 155.0, 13.699999999999953, -185.80000000000027, 200.0, 200.0, 200.0, 155.9, 20.000000000000014, 200.0, 179.3, 118.99999999999999, -1.000000000000015, 20.000000000000014, -160.60000000000002, -355.9, -175.3, 9.49999999999999, 170.0, -95.50000000000045, -59.799999999999955, -244.60000000000042, -17.800000000000047, -143.80000000000024, 20.000000000000014], "policy_predator_policy_reward": [83.0, 84.0, 140.0, 0.0, 14.0, 0.0, 0.0, 0.0, 5.0, 2.0, 13.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 42.0, 200.0, 18.0, 80.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 104.0, 0.0, 103.0, 46.0, 0.0, 17.0, 0.0, 0.0, 142.0, 29.0, 0.0, 0.0, 114.0, 182.0, 0.0, 0.0, 27.0, 0.0, 0.0, 24.0, 0.0, 107.0, 0.0, 54.0, 0.0, 0.0, 85.0, 80.0, 0.0, 85.0, 0.0, 6.0, 0.0, 16.0, 170.0, 51.0, 0.0, 0.0, 0.0, 200.0, 2.0, 52.0, 8.0, 43.0, 0.0, 18.0, 0.0, 52.0, 0.0, 200.0, 0.0, 29.0, 73.0, 163.0, 0.0, 0.0, 61.0, 54.0, 0.0, 0.0, 72.0, 19.0, 44.0, 0.0, 56.0, 0.0, 140.0, 21.0, 5.0, 61.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 27.0, 0.0, 0.0, 7.0, 0.0, 43.0, 5.0, 0.0, 0.0, 0.0, 66.0, 15.0, 105.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 118.0, 4.0, 15.0, 112.0, 41.0, 0.0, 0.0, 17.0, 0.0, 143.0, 0.0, 120.0, 67.0, 5.0, 0.0, 0.0, 58.0, 3.0, 98.0, 20.0, 0.0, 0.0, 0.0, 27.0, 0.0, 3.0, 95.0, 0.0, 0.0, 0.0, 0.0, 38.0, 33.0, 170.0, 72.0, 0.0, 0.0, 23.0, 0.0, 2.0, 1.0, 73.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 86.0, 179.0, 177.0, 15.0, 0.0, 47.0, 46.0, 0.0, 139.0, 78.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.423244086273032, "mean_inference_ms": 9.457187941885781, "mean_action_processing_ms": 0.7614712961374225, "mean_env_wait_ms": 1.235876899128211, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010795950889587402, "StateBufferConnector_ms": 0.021755456924438477, "ViewRequirementAgentConnector_ms": 0.5246797800064087}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -455.1, "episode_return_mean": 85.50599999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000, "num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 122.96390244949266, "num_env_steps_trained_throughput_per_sec": 122.96390244949266, "timesteps_total": 504000, "num_env_steps_sampled_lifetime": 504000, "num_agent_steps_sampled_lifetime": 2016000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2016000, "timers": {"training_iteration_time_ms": 31898.234, "restore_workers_time_ms": 0.026, "training_step_time_ms": 31898.157, "sample_time_ms": 5134.078, "learn_time_ms": 26714.046, "learn_throughput": 149.734, "synch_weights_time_ms": 43.827}, "counters": {"num_env_steps_sampled": 504000, "num_env_steps_trained": 504000, "num_agent_steps_sampled": 2016000, "num_agent_steps_trained": 2016000}, "done": false, "training_iteration": 126, "trial_id": "3a355_00000", "date": "2024-08-13_03-10-06", "timestamp": 1723533006, "time_this_iter_s": 32.58241391181946, "time_total_s": 7207.538057565689, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52a3790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7207.538057565689, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 89.0108695652174, "ram_util_percent": 83.1086956521739}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0162992751787578, "cur_kl_coeff": 4.0389678347315807e-29, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.301786738350278, "policy_loss": -0.0024312498343605844, "vf_loss": 5.304217986833482, "vf_explained_var": 0.0022352953751881917, "kl": 0.00218383885099956, "entropy": 0.2975786139015798, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 239085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.112243406758422, "cur_kl_coeff": 5.664173130526251e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.593392189722213, "policy_loss": 0.0007260643841363687, "vf_loss": 8.592666125928284, "vf_explained_var": 0.44221675452731907, "kl": 0.0033734057840039667, "entropy": 0.7082683355246903, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 239085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -455.1, "episode_reward_mean": 91.41199999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 10.21099999999996, "predator_policy": 35.495}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-93.90000000000032, 21.30000000000001, 219.99999999999926, 59.20000000000006, 314.500000000001, -69.00000000000009, 40.0000000000003, 135.3999999999998, 179.19999999999945, -77.70000000000115, -19.399999999999835, 219.99999999999926, 310.0, 17.599999999999973, 116.19999999999868, 192.4999999999994, -455.1, 304.6000000000009, -24.0, 135.99999999999972, 158.49999999999957, 20.199999999999978, 74.599999999999, -333.30000000000024, 318.6, -185.70000000000093, 138.99999999999966, 193.99999999999966, 40.0000000000003, 39.80000000000009, 127.49999999999972, 133.1999999999997, -381.0, 138.09999999999968, 122.79999999999865, 195.9999999999994, 400.0, 219.99999999999926, 9.500000000000034, 128.19999999999976, 189.79999999999941, 159.99999999999957, 391.0, 92.49999999999999, -276.8, 40.0000000000003, 195.99999999999937, 388.3, 379.8, 350.50000000000006, 95.19999999999993, 38.00000000000031, -240.2000000000007, 219.99999999999926, 201.29999999999936, 53.700000000000045, -287.4999999999998, 209.99999999999932, -23.7999999999996, 20.699999999999832, 136.79999999999964, 207.39999999999932, 10.29999999999992, -95.70000000000111, 157.89999999999955, 40.0000000000003, 300.0, -427.79999999999995, 219.99999999999926, 239.69999999999993, 171.69999999999948, 134.19999999999982, 400.0, 175.89999999999947, 379.3, 127.9999999999997, -54.59999999999988, -175.20000000000002, 194.49999999999937, -62.29999999999983, -123.40000000000018, -45.79999999999987, 35.499999999999986, 113.9999999999998, 272.19999999999965, -150.30000000000004, 227.9, 335.90000000000003, 174.5999999999996, -80.60000000000008, 19.10000000000045, -91.50000000000023, 219.99999999999926, -248.30000000000004, 186.69999999999982, 15.800000000000177, 303.70000000000084, 366.70000000000005, 178.19999999999948, 64.80000000000021], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -262.89999999999986, 20.000000000000014, -15.699999999999811, 20.000000000000014, 200.0, -286.5999999999988, 174.8, 192.8, 121.6999999999995, 20.000000000000014, -385.0, 20.000000000000014, 20.000000000000014, -36.699999999999754, 145.1, 152.0, 3.199999999999981, 20.000000000000014, -204.7000000000005, 20.000000000000014, -93.40000000000018, 20.000000000000014, 200.0, 200.0, -55.0, 91.09999999999962, -158.50000000000003, 17.899999999999988, 92.29999999999941, 9.500000000000007, 167.0, -339.1, -337.0, 105.4999999999996, 199.1, 176.0, -400.0, 171.2, -89.19999999999979, -74.50000000000003, 182.0, 20.000000000000014, -17.79999999999974, 20.000000000000014, 2.5999999999997385, -133.3, -400.0, 113.0, 176.6, -338.7999999999995, -82.8999999999998, 20.000000000000014, 118.99999999999999, 189.2, -110.20000000000024, 20.000000000000014, 20.000000000000014, 15.799999999999963, -67.0, 155.9, -72.40000000000003, 126.19999999999999, -48.99999999999989, -274.0, -267.99999999999994, 180.2, -108.09999999999982, 102.79999999999939, 20.000000000000014, 164.0, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, -156.40000000000066, 74.89999999999942, 20.000000000000014, 108.19999999999999, 167.0, 15.800000000000002, 176.0, -64.00000000000001, 200.0, 191.0, -118.60000000000068, 145.1, -198.40000000000003, -198.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 188.3, 194.0, 183.8, 200.0, 150.5, -227.8, 200.0, 20.000000000000014, -1.000000000000028, -223.60000000000048, -169.60000000000056, 200.0, 20.000000000000014, 200.0, -15.699999999999918, 191.0, -280.3, -257.19999999999993, -217.29999999999987, 20.000000000000014, 185.0, -101.80000000000071, 20.000000000000014, -94.0, 13.699999999999948, 138.79999999999998, -22.000000000000025, 187.4, 20.000000000000014, -36.69999999999986, 20.000000000000014, -68.20000000000059, -125.50000000000051, 20.000000000000014, 137.89999999999998, 20.000000000000014, 20.000000000000014, 158.0, 71.0, -400.0, -269.8, 200.0, 20.000000000000014, 131.0, 85.69999999999997, 155.0, 13.699999999999953, -185.80000000000027, 200.0, 200.0, 200.0, 155.9, 20.000000000000014, 200.0, 179.3, 118.99999999999999, -1.000000000000015, 20.000000000000014, -160.60000000000002, -355.9, -175.3, 9.49999999999999, 170.0, -95.50000000000045, -59.799999999999955, -244.60000000000042, -17.800000000000047, -143.80000000000024, 20.000000000000014, 128.59999999999997, -276.1, 187.4, -219.4000000000005, 194.6, 77.59999999999997, -181.60000000000002, -141.7000000000001, -121.0, 191.9, 155.9, 149.0, -22.0, 152.6, 23.60000000000008, -236.20000000000002, 43.10000000000024, -64.00000000000006, -141.70000000000024, -185.8, 20.000000000000014, 200.0, -257.20000000000005, -255.10000000000002, -133.3, 161.0, -124.0, -26.200000000000024, 135.19999999999962, 168.5, 166.7, 200.0, -59.79999999999979, 200.0, 126.19999999999999, -135.40000000000072], "policy_predator_policy_reward": [103.0, 46.0, 0.0, 17.0, 0.0, 0.0, 142.0, 29.0, 0.0, 0.0, 114.0, 182.0, 0.0, 0.0, 27.0, 0.0, 0.0, 24.0, 0.0, 107.0, 0.0, 54.0, 0.0, 0.0, 85.0, 80.0, 0.0, 85.0, 0.0, 6.0, 0.0, 16.0, 170.0, 51.0, 0.0, 0.0, 0.0, 200.0, 2.0, 52.0, 8.0, 43.0, 0.0, 18.0, 0.0, 52.0, 0.0, 200.0, 0.0, 29.0, 73.0, 163.0, 0.0, 0.0, 61.0, 54.0, 0.0, 0.0, 72.0, 19.0, 44.0, 0.0, 56.0, 0.0, 140.0, 21.0, 5.0, 61.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 27.0, 0.0, 0.0, 7.0, 0.0, 43.0, 5.0, 0.0, 0.0, 0.0, 66.0, 15.0, 105.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 118.0, 4.0, 15.0, 112.0, 41.0, 0.0, 0.0, 17.0, 0.0, 143.0, 0.0, 120.0, 67.0, 5.0, 0.0, 0.0, 58.0, 3.0, 98.0, 20.0, 0.0, 0.0, 0.0, 27.0, 0.0, 3.0, 95.0, 0.0, 0.0, 0.0, 0.0, 38.0, 33.0, 170.0, 72.0, 0.0, 0.0, 23.0, 0.0, 2.0, 1.0, 73.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 86.0, 179.0, 177.0, 15.0, 0.0, 47.0, 46.0, 0.0, 139.0, 78.0, 0.0, 100.0, 83.0, 34.0, 112.0, 0.0, 0.0, 96.0, 77.0, 104.0, 53.0, 16.0, 15.0, 20.0, 24.0, 86.0, 46.0, 0.0, 40.0, 107.0, 129.0, 0.0, 0.0, 132.0, 132.0, 86.0, 73.0, 66.0, 100.0, 0.0, 0.0, 0.0, 0.0, 2.0, 36.0, 6.0, 68.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.424730026013858, "mean_inference_ms": 9.443603418790616, "mean_action_processing_ms": 0.7638941215209993, "mean_env_wait_ms": 1.2334912963938054, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010872364044189453, "StateBufferConnector_ms": 0.02390742301940918, "ViewRequirementAgentConnector_ms": 0.5501679182052612}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -455.1, "episode_return_mean": 91.41199999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000, "num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 6.633776966000175, "num_env_steps_trained_throughput_per_sec": 6.633776966000175, "timesteps_total": 508000, "num_env_steps_sampled_lifetime": 508000, "num_agent_steps_sampled_lifetime": 2032000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2032000, "timers": {"training_iteration_time_ms": 88749.695, "restore_workers_time_ms": 0.025, "training_step_time_ms": 88749.617, "sample_time_ms": 5030.66, "learn_time_ms": 83670.917, "learn_throughput": 47.806, "synch_weights_time_ms": 41.747}, "counters": {"num_env_steps_sampled": 508000, "num_env_steps_trained": 508000, "num_agent_steps_sampled": 2032000, "num_agent_steps_trained": 2032000}, "done": false, "training_iteration": 127, "trial_id": "3a355_00000", "date": "2024-08-13_03-20-09", "timestamp": 1723533609, "time_this_iter_s": 603.0138459205627, "time_total_s": 7810.551903486252, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52935e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7810.551903486252, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 94.73181818181818, "ram_util_percent": 83.35909090909091}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9668466472594196, "cur_kl_coeff": 2.0194839173657903e-29, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.755762303695477, "policy_loss": -0.0014368023824380346, "vf_loss": 3.7571991013471413, "vf_explained_var": 0.006053195050153783, "kl": 0.0023286354827232354, "entropy": 0.30380684301335975, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 240975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.992335585989649, "cur_kl_coeff": 2.8320865652631253e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.064642823688567, "policy_loss": -0.0004326165606952691, "vf_loss": 8.065075448202709, "vf_explained_var": 0.4693496984148782, "kl": 0.0014434388701668839, "entropy": 0.7763303946565698, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 240975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -427.79999999999995, "episode_reward_mean": 101.8509999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 15.675499999999948, "predator_policy": 35.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-333.30000000000024, 318.6, -185.70000000000093, 138.99999999999966, 193.99999999999966, 40.0000000000003, 39.80000000000009, 127.49999999999972, 133.1999999999997, -381.0, 138.09999999999968, 122.79999999999865, 195.9999999999994, 400.0, 219.99999999999926, 9.500000000000034, 128.19999999999976, 189.79999999999941, 159.99999999999957, 391.0, 92.49999999999999, -276.8, 40.0000000000003, 195.99999999999937, 388.3, 379.8, 350.50000000000006, 95.19999999999993, 38.00000000000031, -240.2000000000007, 219.99999999999926, 201.29999999999936, 53.700000000000045, -287.4999999999998, 209.99999999999932, -23.7999999999996, 20.699999999999832, 136.79999999999964, 207.39999999999932, 10.29999999999992, -95.70000000000111, 157.89999999999955, 40.0000000000003, 300.0, -427.79999999999995, 219.99999999999926, 239.69999999999993, 171.69999999999948, 134.19999999999982, 400.0, 175.89999999999947, 379.3, 127.9999999999997, -54.59999999999988, -175.20000000000002, 194.49999999999937, -62.29999999999983, -123.40000000000018, -45.79999999999987, 35.499999999999986, 113.9999999999998, 272.19999999999965, -150.30000000000004, 227.9, 335.90000000000003, 174.5999999999996, -80.60000000000008, 19.10000000000045, -91.50000000000023, 219.99999999999926, -248.30000000000004, 186.69999999999982, 15.800000000000177, 303.70000000000084, 366.70000000000005, 178.19999999999948, 64.80000000000021, -191.99999999999994, 80.80000000000001, 257.79999999999933, 181.49999999999946, 372.1, 339.90000000000003, -12.199999999999994, -145.70000000000016, 183.69999999999942, -141.40000000000003, 121.69999999999973, 189.69999999999948, 108.59999999999982, -94.80000000000027, 162.29999999999956, 124.59999999999971, 356.8, 106.1999999999999, 199.29999999999936, 86.79999999999998, 229.0, 157.39999999999958, 152.49999999999957], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-133.3, -400.0, 113.0, 176.6, -338.7999999999995, -82.8999999999998, 20.000000000000014, 118.99999999999999, 189.2, -110.20000000000024, 20.000000000000014, 20.000000000000014, 15.799999999999963, -67.0, 155.9, -72.40000000000003, 126.19999999999999, -48.99999999999989, -274.0, -267.99999999999994, 180.2, -108.09999999999982, 102.79999999999939, 20.000000000000014, 164.0, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, -156.40000000000066, 74.89999999999942, 20.000000000000014, 108.19999999999999, 167.0, 15.800000000000002, 176.0, -64.00000000000001, 200.0, 191.0, -118.60000000000068, 145.1, -198.40000000000003, -198.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 188.3, 194.0, 183.8, 200.0, 150.5, -227.8, 200.0, 20.000000000000014, -1.000000000000028, -223.60000000000048, -169.60000000000056, 200.0, 20.000000000000014, 200.0, -15.699999999999918, 191.0, -280.3, -257.19999999999993, -217.29999999999987, 20.000000000000014, 185.0, -101.80000000000071, 20.000000000000014, -94.0, 13.699999999999948, 138.79999999999998, -22.000000000000025, 187.4, 20.000000000000014, -36.69999999999986, 20.000000000000014, -68.20000000000059, -125.50000000000051, 20.000000000000014, 137.89999999999998, 20.000000000000014, 20.000000000000014, 158.0, 71.0, -400.0, -269.8, 200.0, 20.000000000000014, 131.0, 85.69999999999997, 155.0, 13.699999999999953, -185.80000000000027, 200.0, 200.0, 200.0, 155.9, 20.000000000000014, 200.0, 179.3, 118.99999999999999, -1.000000000000015, 20.000000000000014, -160.60000000000002, -355.9, -175.3, 9.49999999999999, 170.0, -95.50000000000045, -59.799999999999955, -244.60000000000042, -17.800000000000047, -143.80000000000024, 20.000000000000014, 128.59999999999997, -276.1, 187.4, -219.4000000000005, 194.6, 77.59999999999997, -181.60000000000002, -141.7000000000001, -121.0, 191.9, 155.9, 149.0, -22.0, 152.6, 23.60000000000008, -236.20000000000002, 43.10000000000024, -64.00000000000006, -141.70000000000024, -185.8, 20.000000000000014, 200.0, -257.20000000000005, -255.10000000000002, -133.3, 161.0, -124.0, -26.200000000000024, 135.19999999999962, 168.5, 166.7, 200.0, -59.79999999999979, 200.0, 126.19999999999999, -135.40000000000072, -133.3, -162.70000000000002, -173.20000000000002, 134.0, 173.9, 83.89999999999927, -53.499999999999766, 200.0, 200.0, 172.1, 176.0, 155.9, 20.000000000000014, -131.20000000000022, -7.3000000000000504, -282.4000000000002, -175.30000000000055, 200.0, -59.799999999999805, -202.6, 150.2, -74.50000000000027, -7.3000000000000504, 167.0, 131.0, -177.4000000000002, -251.20000000000007, 7.399999999999967, -99.70000000000053, 200.0, -36.69999999999992, 134.29999999999998, 171.2, 185.6, -122.80000000000004, 131.0, 179.3, 20.000000000000014, 155.0, -194.20000000000002, -118.0, 200.0, 1.099999999999983, 122.30000000000001, 132.5, 20.000000000000014], "policy_predator_policy_reward": [0.0, 200.0, 0.0, 29.0, 73.0, 163.0, 0.0, 0.0, 61.0, 54.0, 0.0, 0.0, 72.0, 19.0, 44.0, 0.0, 56.0, 0.0, 140.0, 21.0, 5.0, 61.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 64.0, 27.0, 0.0, 0.0, 7.0, 0.0, 43.0, 5.0, 0.0, 0.0, 0.0, 66.0, 15.0, 105.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 118.0, 4.0, 15.0, 112.0, 41.0, 0.0, 0.0, 17.0, 0.0, 143.0, 0.0, 120.0, 67.0, 5.0, 0.0, 0.0, 58.0, 3.0, 98.0, 20.0, 0.0, 0.0, 0.0, 27.0, 0.0, 3.0, 95.0, 0.0, 0.0, 0.0, 0.0, 38.0, 33.0, 170.0, 72.0, 0.0, 0.0, 23.0, 0.0, 2.0, 1.0, 73.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 86.0, 179.0, 177.0, 15.0, 0.0, 47.0, 46.0, 0.0, 139.0, 78.0, 0.0, 100.0, 83.0, 34.0, 112.0, 0.0, 0.0, 96.0, 77.0, 104.0, 53.0, 16.0, 15.0, 20.0, 24.0, 86.0, 46.0, 0.0, 40.0, 107.0, 129.0, 0.0, 0.0, 132.0, 132.0, 86.0, 73.0, 66.0, 100.0, 0.0, 0.0, 0.0, 0.0, 2.0, 36.0, 6.0, 68.0, 17.0, 87.0, 30.0, 90.0, 0.0, 0.0, 15.0, 20.0, 0.0, 0.0, 8.0, 0.0, 34.0, 65.0, 144.0, 0.0, 80.0, 79.0, 118.0, 3.0, 46.0, 0.0, 6.0, 24.0, 62.0, 93.0, 48.0, 101.0, 6.0, 56.0, 27.0, 0.0, 0.0, 0.0, 83.0, 15.0, 0.0, 0.0, 24.0, 102.0, 88.0, 59.0, 34.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.425872821882605, "mean_inference_ms": 9.419124891383403, "mean_action_processing_ms": 0.7659632458525694, "mean_env_wait_ms": 1.2286430518568277, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009719610214233398, "StateBufferConnector_ms": 0.01108849048614502, "ViewRequirementAgentConnector_ms": 0.46312975883483887}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -427.79999999999995, "episode_return_mean": 101.8509999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000, "num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 241.73168894504488, "num_env_steps_trained_throughput_per_sec": 241.73168894504488, "timesteps_total": 512000, "num_env_steps_sampled_lifetime": 512000, "num_agent_steps_sampled_lifetime": 2048000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2048000, "timers": {"training_iteration_time_ms": 87147.299, "restore_workers_time_ms": 0.025, "training_step_time_ms": 87147.224, "sample_time_ms": 4780.405, "learn_time_ms": 82319.761, "learn_throughput": 48.591, "synch_weights_time_ms": 40.833}, "counters": {"num_env_steps_sampled": 512000, "num_env_steps_trained": 512000, "num_agent_steps_sampled": 2048000, "num_agent_steps_trained": 2048000}, "done": false, "training_iteration": 128, "trial_id": "3a355_00000", "date": "2024-08-13_03-20-26", "timestamp": 1723533626, "time_this_iter_s": 16.615431785583496, "time_total_s": 7827.167335271835, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b523e4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 7827.167335271835, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 85.63913043478261, "ram_util_percent": 83.48260869565217}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1298504503079192, "cur_kl_coeff": 1.0097419586828952e-29, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.782758148637398, "policy_loss": -0.00259075719720275, "vf_loss": 4.785348902177558, "vf_explained_var": 0.009183113442526923, "kl": 0.0031293594751366388, "entropy": 0.3525032231889704, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 242865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 18.884058685655948, "cur_kl_coeff": 1.4160432826315627e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.141068491355452, "policy_loss": -0.0014189173021506537, "vf_loss": 7.142487422246782, "vf_explained_var": 0.5428138346268386, "kl": 0.00607761398154902, "entropy": 0.9448687162348833, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 242865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -427.79999999999995, "episode_reward_mean": 103.29599999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 179.0}, "policy_reward_mean": {"prey_policy": 15.862999999999952, "predator_policy": 35.785}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 195.99999999999937, 388.3, 379.8, 350.50000000000006, 95.19999999999993, 38.00000000000031, -240.2000000000007, 219.99999999999926, 201.29999999999936, 53.700000000000045, -287.4999999999998, 209.99999999999932, -23.7999999999996, 20.699999999999832, 136.79999999999964, 207.39999999999932, 10.29999999999992, -95.70000000000111, 157.89999999999955, 40.0000000000003, 300.0, -427.79999999999995, 219.99999999999926, 239.69999999999993, 171.69999999999948, 134.19999999999982, 400.0, 175.89999999999947, 379.3, 127.9999999999997, -54.59999999999988, -175.20000000000002, 194.49999999999937, -62.29999999999983, -123.40000000000018, -45.79999999999987, 35.499999999999986, 113.9999999999998, 272.19999999999965, -150.30000000000004, 227.9, 335.90000000000003, 174.5999999999996, -80.60000000000008, 19.10000000000045, -91.50000000000023, 219.99999999999926, -248.30000000000004, 186.69999999999982, 15.800000000000177, 303.70000000000084, 366.70000000000005, 178.19999999999948, 64.80000000000021, -191.99999999999994, 80.80000000000001, 257.79999999999933, 181.49999999999946, 372.1, 339.90000000000003, -12.199999999999994, -145.70000000000016, 183.69999999999942, -141.40000000000003, 121.69999999999973, 189.69999999999948, 108.59999999999982, -94.80000000000027, 162.29999999999956, 124.59999999999971, 356.8, 106.1999999999999, 199.29999999999936, 86.79999999999998, 229.0, 157.39999999999958, 152.49999999999957, 141.89999999999964, -134.90000000000066, -73.300000000001, 195.7999999999994, 148.3999999999998, 199.89999999999938, 310.89999999999986, 150.69999999999962, 219.99999999999926, -10.600000000000051, 136.79999999999973, 51.30000000000004, -58.79999999999974, 70.60000000000004, 216.69999999999928, 207.39999999999932, -177.6999999999999, 187.9999999999993, 186.69999999999942, -24.900000000000055, 33.300000000000274, 29.500000000000206], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 164.0, 200.0, 188.3, 194.0, 183.8, 200.0, 150.5, -227.8, 200.0, 20.000000000000014, -1.000000000000028, -223.60000000000048, -169.60000000000056, 200.0, 20.000000000000014, 200.0, -15.699999999999918, 191.0, -280.3, -257.19999999999993, -217.29999999999987, 20.000000000000014, 185.0, -101.80000000000071, 20.000000000000014, -94.0, 13.699999999999948, 138.79999999999998, -22.000000000000025, 187.4, 20.000000000000014, -36.69999999999986, 20.000000000000014, -68.20000000000059, -125.50000000000051, 20.000000000000014, 137.89999999999998, 20.000000000000014, 20.000000000000014, 158.0, 71.0, -400.0, -269.8, 200.0, 20.000000000000014, 131.0, 85.69999999999997, 155.0, 13.699999999999953, -185.80000000000027, 200.0, 200.0, 200.0, 155.9, 20.000000000000014, 200.0, 179.3, 118.99999999999999, -1.000000000000015, 20.000000000000014, -160.60000000000002, -355.9, -175.3, 9.49999999999999, 170.0, -95.50000000000045, -59.799999999999955, -244.60000000000042, -17.800000000000047, -143.80000000000024, 20.000000000000014, 128.59999999999997, -276.1, 187.4, -219.4000000000005, 194.6, 77.59999999999997, -181.60000000000002, -141.7000000000001, -121.0, 191.9, 155.9, 149.0, -22.0, 152.6, 23.60000000000008, -236.20000000000002, 43.10000000000024, -64.00000000000006, -141.70000000000024, -185.8, 20.000000000000014, 200.0, -257.20000000000005, -255.10000000000002, -133.3, 161.0, -124.0, -26.200000000000024, 135.19999999999962, 168.5, 166.7, 200.0, -59.79999999999979, 200.0, 126.19999999999999, -135.40000000000072, -133.3, -162.70000000000002, -173.20000000000002, 134.0, 173.9, 83.89999999999927, -53.499999999999766, 200.0, 200.0, 172.1, 176.0, 155.9, 20.000000000000014, -131.20000000000022, -7.3000000000000504, -282.4000000000002, -175.30000000000055, 200.0, -59.799999999999805, -202.6, 150.2, -74.50000000000027, -7.3000000000000504, 167.0, 131.0, -177.4000000000002, -251.20000000000007, 7.399999999999967, -99.70000000000053, 200.0, -36.69999999999992, 134.29999999999998, 171.2, 185.6, -122.80000000000004, 131.0, 179.3, 20.000000000000014, 155.0, -194.20000000000002, -118.0, 200.0, 1.099999999999983, 122.30000000000001, 132.5, 20.000000000000014, 116.0, -24.09999999999988, -11.499999999999826, -282.39999999999986, -1.0000000000000382, -175.3000000000006, 200.0, -26.20000000000001, -139.60000000000002, 164.0, 200.0, -24.099999999999913, 198.2, 112.69999999999999, 200.0, -112.30000000000078, 200.0, 20.000000000000014, -45.10000000000003, -11.49999999999985, 161.0, -89.20000000000005, -267.7, 173.0, -124.90000000000046, -19.900000000000016, -261.4000000000003, 194.0, 200.0, 13.70000000000001, 20.000000000000014, 187.4, -150.40000000000003, -175.3, 20.000000000000014, 152.0, 20.000000000000014, 166.7, -116.50000000000003, -9.399999999999855, 13.699999999999946, -9.400000000000034, -116.50000000000003, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 5.0, 118.0, 4.0, 15.0, 112.0, 41.0, 0.0, 0.0, 17.0, 0.0, 143.0, 0.0, 120.0, 67.0, 5.0, 0.0, 0.0, 58.0, 3.0, 98.0, 20.0, 0.0, 0.0, 0.0, 27.0, 0.0, 3.0, 95.0, 0.0, 0.0, 0.0, 0.0, 38.0, 33.0, 170.0, 72.0, 0.0, 0.0, 23.0, 0.0, 2.0, 1.0, 73.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 86.0, 179.0, 177.0, 15.0, 0.0, 47.0, 46.0, 0.0, 139.0, 78.0, 0.0, 100.0, 83.0, 34.0, 112.0, 0.0, 0.0, 96.0, 77.0, 104.0, 53.0, 16.0, 15.0, 20.0, 24.0, 86.0, 46.0, 0.0, 40.0, 107.0, 129.0, 0.0, 0.0, 132.0, 132.0, 86.0, 73.0, 66.0, 100.0, 0.0, 0.0, 0.0, 0.0, 2.0, 36.0, 6.0, 68.0, 17.0, 87.0, 30.0, 90.0, 0.0, 0.0, 15.0, 20.0, 0.0, 0.0, 8.0, 0.0, 34.0, 65.0, 144.0, 0.0, 80.0, 79.0, 118.0, 3.0, 46.0, 0.0, 6.0, 24.0, 62.0, 93.0, 48.0, 101.0, 6.0, 56.0, 27.0, 0.0, 0.0, 0.0, 83.0, 15.0, 0.0, 0.0, 24.0, 102.0, 88.0, 59.0, 34.0, 0.0, 0.0, 0.0, 30.0, 20.0, 77.0, 82.0, 26.0, 77.0, 22.0, 0.0, 80.0, 44.0, 21.0, 3.0, 0.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 46.0, 0.0, 65.0, 146.0, 0.0, 21.0, 65.0, 98.0, 40.0, 0.0, 3.0, 0.0, 0.0, 61.0, 87.0, 16.0, 0.0, 0.0, 0.0, 33.0, 68.0, 12.0, 17.0, 65.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4757176673815637, "mean_inference_ms": 9.326362529342147, "mean_action_processing_ms": 0.7672429172334554, "mean_env_wait_ms": 1.2271766909652595, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007106184959411621, "StateBufferConnector_ms": 0.00989377498626709, "ViewRequirementAgentConnector_ms": 0.3687492609024048}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -427.79999999999995, "episode_return_mean": 103.29599999999978, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000, "num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.063894194096883, "num_env_steps_trained_throughput_per_sec": 4.063894194096883, "timesteps_total": 516000, "num_env_steps_sampled_lifetime": 516000, "num_agent_steps_sampled_lifetime": 2064000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2064000, "timers": {"training_iteration_time_ms": 182225.37, "restore_workers_time_ms": 0.025, "training_step_time_ms": 182225.296, "sample_time_ms": 4555.346, "learn_time_ms": 177622.709, "learn_throughput": 22.52, "synch_weights_time_ms": 41.462}, "counters": {"num_env_steps_sampled": 516000, "num_env_steps_trained": 516000, "num_agent_steps_sampled": 2064000, "num_agent_steps_trained": 2064000}, "done": false, "training_iteration": 129, "trial_id": "3a355_00000", "date": "2024-08-13_03-36-50", "timestamp": 1723534610, "time_this_iter_s": 984.3735842704773, "time_total_s": 8811.540919542313, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52a3550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 8811.540919542313, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 94.72045454545454, "ram_util_percent": 83.14318181818182}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8371893823974662, "cur_kl_coeff": 5.048709793414476e-30, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3352398887513175, "policy_loss": -0.0026110174586483964, "vf_loss": 3.3378509034555424, "vf_explained_var": -0.0016350838242384493, "kl": 0.005328310819340158, "entropy": 0.3187214484921208, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 244755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 21.08118429984996, "cur_kl_coeff": 1.4160432826315627e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.382058505911045, "policy_loss": -0.00040025973727029785, "vf_loss": 7.382458758732629, "vf_explained_var": 0.602849716547305, "kl": 0.004782951274072129, "entropy": 0.8289750922609258, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 244755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -427.79999999999995, "episode_reward_mean": 102.93199999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 14.485999999999956, "predator_policy": 36.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-95.70000000000111, 157.89999999999955, 40.0000000000003, 300.0, -427.79999999999995, 219.99999999999926, 239.69999999999993, 171.69999999999948, 134.19999999999982, 400.0, 175.89999999999947, 379.3, 127.9999999999997, -54.59999999999988, -175.20000000000002, 194.49999999999937, -62.29999999999983, -123.40000000000018, -45.79999999999987, 35.499999999999986, 113.9999999999998, 272.19999999999965, -150.30000000000004, 227.9, 335.90000000000003, 174.5999999999996, -80.60000000000008, 19.10000000000045, -91.50000000000023, 219.99999999999926, -248.30000000000004, 186.69999999999982, 15.800000000000177, 303.70000000000084, 366.70000000000005, 178.19999999999948, 64.80000000000021, -191.99999999999994, 80.80000000000001, 257.79999999999933, 181.49999999999946, 372.1, 339.90000000000003, -12.199999999999994, -145.70000000000016, 183.69999999999942, -141.40000000000003, 121.69999999999973, 189.69999999999948, 108.59999999999982, -94.80000000000027, 162.29999999999956, 124.59999999999971, 356.8, 106.1999999999999, 199.29999999999936, 86.79999999999998, 229.0, 157.39999999999958, 152.49999999999957, 141.89999999999964, -134.90000000000066, -73.300000000001, 195.7999999999994, 148.3999999999998, 199.89999999999938, 310.89999999999986, 150.69999999999962, 219.99999999999926, -10.600000000000051, 136.79999999999973, 51.30000000000004, -58.79999999999974, 70.60000000000004, 216.69999999999928, 207.39999999999932, -177.6999999999999, 187.9999999999993, 186.69999999999942, -24.900000000000055, 33.300000000000274, 29.500000000000206, 343.0, 166.09999999999954, 140.99999999999892, -22.899999999999515, 187.59999999999957, 356.0, 366.7, 40.0000000000003, 132.99999999999974, -217.70000000000007, 178.99999999999926, 112.5999999999998, -240.50000000000037, 162.3999999999999, 65.80000000000004, 40.0000000000003, 108.69999999999982, 39.29999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-68.20000000000059, -125.50000000000051, 20.000000000000014, 137.89999999999998, 20.000000000000014, 20.000000000000014, 158.0, 71.0, -400.0, -269.8, 200.0, 20.000000000000014, 131.0, 85.69999999999997, 155.0, 13.699999999999953, -185.80000000000027, 200.0, 200.0, 200.0, 155.9, 20.000000000000014, 200.0, 179.3, 118.99999999999999, -1.000000000000015, 20.000000000000014, -160.60000000000002, -355.9, -175.3, 9.49999999999999, 170.0, -95.50000000000045, -59.799999999999955, -244.60000000000042, -17.800000000000047, -143.80000000000024, 20.000000000000014, 128.59999999999997, -276.1, 187.4, -219.4000000000005, 194.6, 77.59999999999997, -181.60000000000002, -141.7000000000001, -121.0, 191.9, 155.9, 149.0, -22.0, 152.6, 23.60000000000008, -236.20000000000002, 43.10000000000024, -64.00000000000006, -141.70000000000024, -185.8, 20.000000000000014, 200.0, -257.20000000000005, -255.10000000000002, -133.3, 161.0, -124.0, -26.200000000000024, 135.19999999999962, 168.5, 166.7, 200.0, -59.79999999999979, 200.0, 126.19999999999999, -135.40000000000072, -133.3, -162.70000000000002, -173.20000000000002, 134.0, 173.9, 83.89999999999927, -53.499999999999766, 200.0, 200.0, 172.1, 176.0, 155.9, 20.000000000000014, -131.20000000000022, -7.3000000000000504, -282.4000000000002, -175.30000000000055, 200.0, -59.799999999999805, -202.6, 150.2, -74.50000000000027, -7.3000000000000504, 167.0, 131.0, -177.4000000000002, -251.20000000000007, 7.399999999999967, -99.70000000000053, 200.0, -36.69999999999992, 134.29999999999998, 171.2, 185.6, -122.80000000000004, 131.0, 179.3, 20.000000000000014, 155.0, -194.20000000000002, -118.0, 200.0, 1.099999999999983, 122.30000000000001, 132.5, 20.000000000000014, 116.0, -24.09999999999988, -11.499999999999826, -282.39999999999986, -1.0000000000000382, -175.3000000000006, 200.0, -26.20000000000001, -139.60000000000002, 164.0, 200.0, -24.099999999999913, 198.2, 112.69999999999999, 200.0, -112.30000000000078, 200.0, 20.000000000000014, -45.10000000000003, -11.49999999999985, 161.0, -89.20000000000005, -267.7, 173.0, -124.90000000000046, -19.900000000000016, -261.4000000000003, 194.0, 200.0, 13.70000000000001, 20.000000000000014, 187.4, -150.40000000000003, -175.3, 20.000000000000014, 152.0, 20.000000000000014, 166.7, -116.50000000000003, -9.399999999999855, 13.699999999999946, -9.400000000000034, -116.50000000000003, 20.000000000000014, 152.0, 170.0, -82.90000000000003, 200.0, 112.9999999999996, 20.000000000000014, -45.09999999999976, -17.79999999999979, 200.0, -93.39999999999995, 182.0, 161.0, 200.0, 157.7, 20.000000000000014, 20.000000000000014, -85.00000000000043, 158.0, -263.5, -89.20000000000005, 20.000000000000014, 134.0, -97.60000000000002, 150.2, -95.50000000000009, -400.0, -156.40000000000003, 165.8, -181.60000000000002, 151.4, 20.000000000000014, 20.000000000000014, 139.1, -114.40000000000023, 37.999999999999986, -15.699999999999747], "policy_predator_policy_reward": [3.0, 95.0, 0.0, 0.0, 0.0, 0.0, 38.0, 33.0, 170.0, 72.0, 0.0, 0.0, 23.0, 0.0, 2.0, 1.0, 73.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 86.0, 179.0, 177.0, 15.0, 0.0, 47.0, 46.0, 0.0, 139.0, 78.0, 0.0, 100.0, 83.0, 34.0, 112.0, 0.0, 0.0, 96.0, 77.0, 104.0, 53.0, 16.0, 15.0, 20.0, 24.0, 86.0, 46.0, 0.0, 40.0, 107.0, 129.0, 0.0, 0.0, 132.0, 132.0, 86.0, 73.0, 66.0, 100.0, 0.0, 0.0, 0.0, 0.0, 2.0, 36.0, 6.0, 68.0, 17.0, 87.0, 30.0, 90.0, 0.0, 0.0, 15.0, 20.0, 0.0, 0.0, 8.0, 0.0, 34.0, 65.0, 144.0, 0.0, 80.0, 79.0, 118.0, 3.0, 46.0, 0.0, 6.0, 24.0, 62.0, 93.0, 48.0, 101.0, 6.0, 56.0, 27.0, 0.0, 0.0, 0.0, 83.0, 15.0, 0.0, 0.0, 24.0, 102.0, 88.0, 59.0, 34.0, 0.0, 0.0, 0.0, 30.0, 20.0, 77.0, 82.0, 26.0, 77.0, 22.0, 0.0, 80.0, 44.0, 21.0, 3.0, 0.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 46.0, 0.0, 65.0, 146.0, 0.0, 21.0, 65.0, 98.0, 40.0, 0.0, 3.0, 0.0, 0.0, 61.0, 87.0, 16.0, 0.0, 0.0, 0.0, 33.0, 68.0, 12.0, 17.0, 65.0, 61.0, 21.0, 0.0, 49.0, 0.0, 8.0, 0.0, 40.0, 0.0, 54.0, 27.0, 13.0, 0.0, 9.0, 0.0, 0.0, 0.0, 45.0, 15.0, 0.0, 135.0, 22.0, 3.0, 53.0, 7.0, 200.0, 55.0, 83.0, 70.0, 0.0, 96.0, 0.0, 0.0, 11.0, 73.0, 17.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4157010491349604, "mean_inference_ms": 9.35459445578455, "mean_action_processing_ms": 0.7660032936200616, "mean_env_wait_ms": 1.220071806043012, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006394386291503906, "StateBufferConnector_ms": 0.008900165557861328, "ViewRequirementAgentConnector_ms": 0.2803593873977661}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -427.79999999999995, "episode_return_mean": 102.93199999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000, "num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 229.35817994453478, "num_env_steps_trained_throughput_per_sec": 229.35817994453478, "timesteps_total": 520000, "num_env_steps_sampled_lifetime": 520000, "num_agent_steps_sampled_lifetime": 2080000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2080000, "timers": {"training_iteration_time_ms": 180833.766, "restore_workers_time_ms": 0.024, "training_step_time_ms": 180833.693, "sample_time_ms": 4400.036, "learn_time_ms": 176386.847, "learn_throughput": 22.677, "synch_weights_time_ms": 40.493}, "counters": {"num_env_steps_sampled": 520000, "num_env_steps_trained": 520000, "num_agent_steps_sampled": 2080000, "num_agent_steps_trained": 2080000}, "done": false, "training_iteration": 130, "trial_id": "3a355_00000", "date": "2024-08-13_03-37-08", "timestamp": 1723534628, "time_this_iter_s": 17.49323272705078, "time_total_s": 8829.034152269363, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52a35e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 8829.034152269363, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 85.675, "ram_util_percent": 83.50833333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9862111626596993, "cur_kl_coeff": 5.048709793414476e-30, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4809697464029625, "policy_loss": -0.0022090844612903697, "vf_loss": 3.483178824217862, "vf_explained_var": 0.0009595104941615352, "kl": 0.003755414173666797, "entropy": 0.3327652291803764, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 246645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 22.23454623214467, "cur_kl_coeff": 7.080216413157813e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.668564057224011, "policy_loss": -0.00011148685774218942, "vf_loss": 6.66867555234798, "vf_explained_var": 0.569230936412458, "kl": 0.0014603778382248813, "entropy": 0.8296474638439361, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 246645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000}, "env_runners": {"episode_reward_max": 372.1, "episode_reward_min": -248.30000000000004, "episode_reward_mean": 107.9869999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 17.193499999999965, "predator_policy": 36.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-45.79999999999987, 35.499999999999986, 113.9999999999998, 272.19999999999965, -150.30000000000004, 227.9, 335.90000000000003, 174.5999999999996, -80.60000000000008, 19.10000000000045, -91.50000000000023, 219.99999999999926, -248.30000000000004, 186.69999999999982, 15.800000000000177, 303.70000000000084, 366.70000000000005, 178.19999999999948, 64.80000000000021, -191.99999999999994, 80.80000000000001, 257.79999999999933, 181.49999999999946, 372.1, 339.90000000000003, -12.199999999999994, -145.70000000000016, 183.69999999999942, -141.40000000000003, 121.69999999999973, 189.69999999999948, 108.59999999999982, -94.80000000000027, 162.29999999999956, 124.59999999999971, 356.8, 106.1999999999999, 199.29999999999936, 86.79999999999998, 229.0, 157.39999999999958, 152.49999999999957, 141.89999999999964, -134.90000000000066, -73.300000000001, 195.7999999999994, 148.3999999999998, 199.89999999999938, 310.89999999999986, 150.69999999999962, 219.99999999999926, -10.600000000000051, 136.79999999999973, 51.30000000000004, -58.79999999999974, 70.60000000000004, 216.69999999999928, 207.39999999999932, -177.6999999999999, 187.9999999999993, 186.69999999999942, -24.900000000000055, 33.300000000000274, 29.500000000000206, 343.0, 166.09999999999954, 140.99999999999892, -22.899999999999515, 187.59999999999957, 356.0, 366.7, 40.0000000000003, 132.99999999999974, -217.70000000000007, 178.99999999999926, 112.5999999999998, -240.50000000000037, 162.3999999999999, 65.80000000000004, 40.0000000000003, 108.69999999999982, 39.29999999999996, 157.29999999999959, 367.6, 40.70000000000021, 22.89999999999978, 219.99999999999926, 136.59999999999985, 37.800000000000296, 363.1, 209.9999999999993, 190.9999999999994, -169.80000000000055, -129.7000000000005, 146.49999999999963, 40.0000000000003, 187.19999999999942, 120.39999999999996, 188.79999999999941, -22.700000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-143.80000000000024, 20.000000000000014, 128.59999999999997, -276.1, 187.4, -219.4000000000005, 194.6, 77.59999999999997, -181.60000000000002, -141.7000000000001, -121.0, 191.9, 155.9, 149.0, -22.0, 152.6, 23.60000000000008, -236.20000000000002, 43.10000000000024, -64.00000000000006, -141.70000000000024, -185.8, 20.000000000000014, 200.0, -257.20000000000005, -255.10000000000002, -133.3, 161.0, -124.0, -26.200000000000024, 135.19999999999962, 168.5, 166.7, 200.0, -59.79999999999979, 200.0, 126.19999999999999, -135.40000000000072, -133.3, -162.70000000000002, -173.20000000000002, 134.0, 173.9, 83.89999999999927, -53.499999999999766, 200.0, 200.0, 172.1, 176.0, 155.9, 20.000000000000014, -131.20000000000022, -7.3000000000000504, -282.4000000000002, -175.30000000000055, 200.0, -59.799999999999805, -202.6, 150.2, -74.50000000000027, -7.3000000000000504, 167.0, 131.0, -177.4000000000002, -251.20000000000007, 7.399999999999967, -99.70000000000053, 200.0, -36.69999999999992, 134.29999999999998, 171.2, 185.6, -122.80000000000004, 131.0, 179.3, 20.000000000000014, 155.0, -194.20000000000002, -118.0, 200.0, 1.099999999999983, 122.30000000000001, 132.5, 20.000000000000014, 116.0, -24.09999999999988, -11.499999999999826, -282.39999999999986, -1.0000000000000382, -175.3000000000006, 200.0, -26.20000000000001, -139.60000000000002, 164.0, 200.0, -24.099999999999913, 198.2, 112.69999999999999, 200.0, -112.30000000000078, 200.0, 20.000000000000014, -45.10000000000003, -11.49999999999985, 161.0, -89.20000000000005, -267.7, 173.0, -124.90000000000046, -19.900000000000016, -261.4000000000003, 194.0, 200.0, 13.70000000000001, 20.000000000000014, 187.4, -150.40000000000003, -175.3, 20.000000000000014, 152.0, 20.000000000000014, 166.7, -116.50000000000003, -9.399999999999855, 13.699999999999946, -9.400000000000034, -116.50000000000003, 20.000000000000014, 152.0, 170.0, -82.90000000000003, 200.0, 112.9999999999996, 20.000000000000014, -45.09999999999976, -17.79999999999979, 200.0, -93.39999999999995, 182.0, 161.0, 200.0, 157.7, 20.000000000000014, 20.000000000000014, -85.00000000000043, 158.0, -263.5, -89.20000000000005, 20.000000000000014, 134.0, -97.60000000000002, 150.2, -95.50000000000009, -400.0, -156.40000000000003, 165.8, -181.60000000000002, 151.4, 20.000000000000014, 20.000000000000014, 139.1, -114.40000000000023, 37.999999999999986, -15.699999999999747, 200.0, -99.70000000000063, 200.0, 167.6, -7.300000000000005, 20.000000000000014, -24.09999999999979, -61.0, 200.0, 20.000000000000014, 188.0, -198.40000000000026, 15.799999999999946, 20.000000000000014, 200.0, 163.1, 185.0, 20.000000000000014, 137.0, 20.000000000000014, -336.99999999999966, -17.80000000000001, -24.099999999999746, -370.6000000000001, -61.9000000000002, 169.4, 20.000000000000014, 20.000000000000014, 164.0, 3.1999999999999615, -244.59999999999997, 200.0, 13.699999999999964, 172.1, -204.70000000000016, 20.000000000000014], "policy_predator_policy_reward": [78.0, 0.0, 100.0, 83.0, 34.0, 112.0, 0.0, 0.0, 96.0, 77.0, 104.0, 53.0, 16.0, 15.0, 20.0, 24.0, 86.0, 46.0, 0.0, 40.0, 107.0, 129.0, 0.0, 0.0, 132.0, 132.0, 86.0, 73.0, 66.0, 100.0, 0.0, 0.0, 0.0, 0.0, 2.0, 36.0, 6.0, 68.0, 17.0, 87.0, 30.0, 90.0, 0.0, 0.0, 15.0, 20.0, 0.0, 0.0, 8.0, 0.0, 34.0, 65.0, 144.0, 0.0, 80.0, 79.0, 118.0, 3.0, 46.0, 0.0, 6.0, 24.0, 62.0, 93.0, 48.0, 101.0, 6.0, 56.0, 27.0, 0.0, 0.0, 0.0, 83.0, 15.0, 0.0, 0.0, 24.0, 102.0, 88.0, 59.0, 34.0, 0.0, 0.0, 0.0, 30.0, 20.0, 77.0, 82.0, 26.0, 77.0, 22.0, 0.0, 80.0, 44.0, 21.0, 3.0, 0.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 46.0, 0.0, 65.0, 146.0, 0.0, 21.0, 65.0, 98.0, 40.0, 0.0, 3.0, 0.0, 0.0, 61.0, 87.0, 16.0, 0.0, 0.0, 0.0, 33.0, 68.0, 12.0, 17.0, 65.0, 61.0, 21.0, 0.0, 49.0, 0.0, 8.0, 0.0, 40.0, 0.0, 54.0, 27.0, 13.0, 0.0, 9.0, 0.0, 0.0, 0.0, 45.0, 15.0, 0.0, 135.0, 22.0, 3.0, 53.0, 7.0, 200.0, 55.0, 83.0, 70.0, 0.0, 96.0, 0.0, 0.0, 11.0, 73.0, 17.0, 0.0, 49.0, 8.0, 0.0, 0.0, 0.0, 28.0, 87.0, 21.0, 0.0, 0.0, 43.0, 104.0, 2.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 15.0, 185.0, 0.0, 79.0, 186.0, 0.0, 39.0, 0.0, 0.0, 14.0, 6.0, 39.0, 126.0, 3.0, 0.0, 55.0, 107.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.4077636854122675, "mean_inference_ms": 9.31521675214441, "mean_action_processing_ms": 0.7644273137983092, "mean_env_wait_ms": 1.2145494083976507, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005678772926330566, "StateBufferConnector_ms": 0.009728431701660156, "ViewRequirementAgentConnector_ms": 0.23001980781555176}, "num_episodes": 18, "episode_return_max": 372.1, "episode_return_min": -248.30000000000004, "episode_return_mean": 107.9869999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000, "num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 3.928865588805516, "num_env_steps_trained_throughput_per_sec": 3.928865588805516, "timesteps_total": 524000, "num_env_steps_sampled_lifetime": 524000, "num_agent_steps_sampled_lifetime": 2096000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2096000, "timers": {"training_iteration_time_ms": 279630.9, "restore_workers_time_ms": 0.023, "training_step_time_ms": 279630.829, "sample_time_ms": 4180.221, "learn_time_ms": 275403.831, "learn_throughput": 14.524, "synch_weights_time_ms": 40.071}, "counters": {"num_env_steps_sampled": 524000, "num_env_steps_trained": 524000, "num_agent_steps_sampled": 2096000, "num_agent_steps_trained": 2096000}, "done": false, "training_iteration": 131, "trial_id": "3a355_00000", "date": "2024-08-13_03-54-06", "timestamp": 1723535646, "time_this_iter_s": 1018.2059669494629, "time_total_s": 9847.240119218826, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5f9b9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9847.240119218826, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 86.82666666666665, "ram_util_percent": 83.01666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0299132222260432, "cur_kl_coeff": 2.524354896707238e-30, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3485996038194688, "policy_loss": -0.0030184866631374, "vf_loss": 3.3516180925268344, "vf_explained_var": 0.0023859719750742433, "kl": 0.003962691232574652, "entropy": 0.31167008586661527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 248535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 31.41441419998174, "cur_kl_coeff": 3.5401082065789066e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.1569199657944775, "policy_loss": -0.0006806458931702076, "vf_loss": 6.157600616273426, "vf_explained_var": 0.46839801782653445, "kl": 0.0016180719604790884, "entropy": 0.8744557442173125, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 248535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000}, "env_runners": {"episode_reward_max": 396.0, "episode_reward_min": -240.50000000000037, "episode_reward_mean": 115.96099999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 24.810499999999955, "predator_policy": 33.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [372.1, 339.90000000000003, -12.199999999999994, -145.70000000000016, 183.69999999999942, -141.40000000000003, 121.69999999999973, 189.69999999999948, 108.59999999999982, -94.80000000000027, 162.29999999999956, 124.59999999999971, 356.8, 106.1999999999999, 199.29999999999936, 86.79999999999998, 229.0, 157.39999999999958, 152.49999999999957, 141.89999999999964, -134.90000000000066, -73.300000000001, 195.7999999999994, 148.3999999999998, 199.89999999999938, 310.89999999999986, 150.69999999999962, 219.99999999999926, -10.600000000000051, 136.79999999999973, 51.30000000000004, -58.79999999999974, 70.60000000000004, 216.69999999999928, 207.39999999999932, -177.6999999999999, 187.9999999999993, 186.69999999999942, -24.900000000000055, 33.300000000000274, 29.500000000000206, 343.0, 166.09999999999954, 140.99999999999892, -22.899999999999515, 187.59999999999957, 356.0, 366.7, 40.0000000000003, 132.99999999999974, -217.70000000000007, 178.99999999999926, 112.5999999999998, -240.50000000000037, 162.3999999999999, 65.80000000000004, 40.0000000000003, 108.69999999999982, 39.29999999999996, 157.29999999999959, 367.6, 40.70000000000021, 22.89999999999978, 219.99999999999926, 136.59999999999985, 37.800000000000296, 363.1, 209.9999999999993, 190.9999999999994, -169.80000000000055, -129.7000000000005, 146.49999999999963, 40.0000000000003, 187.19999999999942, 120.39999999999996, 188.79999999999941, -22.700000000000003, 97.7, 358.0, 238.89999999999918, 6.69999999999993, 20.79999999999998, 155.79999999999959, 207.39999999999975, 40.0000000000003, 120.0999999999998, 249.0, -43.89999999999974, 219.99999999999926, 137.09999999999883, -13.5, 40.0000000000003, 347.0, 396.0, 200.89999999999944, 33.400000000000205, -22.199999999999548, 122.69999999999979, 96.89999999999986, 15.30000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 172.1, 176.0, 155.9, 20.000000000000014, -131.20000000000022, -7.3000000000000504, -282.4000000000002, -175.30000000000055, 200.0, -59.799999999999805, -202.6, 150.2, -74.50000000000027, -7.3000000000000504, 167.0, 131.0, -177.4000000000002, -251.20000000000007, 7.399999999999967, -99.70000000000053, 200.0, -36.69999999999992, 134.29999999999998, 171.2, 185.6, -122.80000000000004, 131.0, 179.3, 20.000000000000014, 155.0, -194.20000000000002, -118.0, 200.0, 1.099999999999983, 122.30000000000001, 132.5, 20.000000000000014, 116.0, -24.09999999999988, -11.499999999999826, -282.39999999999986, -1.0000000000000382, -175.3000000000006, 200.0, -26.20000000000001, -139.60000000000002, 164.0, 200.0, -24.099999999999913, 198.2, 112.69999999999999, 200.0, -112.30000000000078, 200.0, 20.000000000000014, -45.10000000000003, -11.49999999999985, 161.0, -89.20000000000005, -267.7, 173.0, -124.90000000000046, -19.900000000000016, -261.4000000000003, 194.0, 200.0, 13.70000000000001, 20.000000000000014, 187.4, -150.40000000000003, -175.3, 20.000000000000014, 152.0, 20.000000000000014, 166.7, -116.50000000000003, -9.399999999999855, 13.699999999999946, -9.400000000000034, -116.50000000000003, 20.000000000000014, 152.0, 170.0, -82.90000000000003, 200.0, 112.9999999999996, 20.000000000000014, -45.09999999999976, -17.79999999999979, 200.0, -93.39999999999995, 182.0, 161.0, 200.0, 157.7, 20.000000000000014, 20.000000000000014, -85.00000000000043, 158.0, -263.5, -89.20000000000005, 20.000000000000014, 134.0, -97.60000000000002, 150.2, -95.50000000000009, -400.0, -156.40000000000003, 165.8, -181.60000000000002, 151.4, 20.000000000000014, 20.000000000000014, 139.1, -114.40000000000023, 37.999999999999986, -15.699999999999747, 200.0, -99.70000000000063, 200.0, 167.6, -7.300000000000005, 20.000000000000014, -24.09999999999979, -61.0, 200.0, 20.000000000000014, 188.0, -198.40000000000026, 15.799999999999946, 20.000000000000014, 200.0, 163.1, 185.0, 20.000000000000014, 137.0, 20.000000000000014, -336.99999999999966, -17.80000000000001, -24.099999999999746, -370.6000000000001, -61.9000000000002, 169.4, 20.000000000000014, 20.000000000000014, 164.0, 3.1999999999999615, -244.59999999999997, 200.0, 13.699999999999964, 172.1, -204.70000000000016, 20.000000000000014, -299.2, 173.9, 158.0, 173.0, 46.1000000000002, 183.8, 20.000000000000014, -157.3000000000006, -34.59999999999982, 13.399999999999972, -89.20000000000067, 161.0, 159.5, 38.89999999999996, 20.000000000000014, 20.000000000000014, 169.4, -112.30000000000078, -79.0, 185.0, 20.000000000000014, -397.9, 20.000000000000014, 200.0, 114.19999999999953, 17.900000000000002, -9.400000000000041, -81.10000000000014, 20.000000000000014, 20.000000000000014, 161.0, 173.0, 194.0, 200.0, -45.09999999999987, 200.0, 7.399999999999965, 20.000000000000014, -110.20000000000078, 20.000000000000014, -175.30000000000013, 179.0, 85.69999999999997, 3.1999999999999615, 20.000000000000014, -36.69999999999996], "policy_predator_policy_reward": [0.0, 0.0, 8.0, 0.0, 34.0, 65.0, 144.0, 0.0, 80.0, 79.0, 118.0, 3.0, 46.0, 0.0, 6.0, 24.0, 62.0, 93.0, 48.0, 101.0, 6.0, 56.0, 27.0, 0.0, 0.0, 0.0, 83.0, 15.0, 0.0, 0.0, 24.0, 102.0, 88.0, 59.0, 34.0, 0.0, 0.0, 0.0, 30.0, 20.0, 77.0, 82.0, 26.0, 77.0, 22.0, 0.0, 80.0, 44.0, 21.0, 3.0, 0.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 46.0, 0.0, 65.0, 146.0, 0.0, 21.0, 65.0, 98.0, 40.0, 0.0, 3.0, 0.0, 0.0, 61.0, 87.0, 16.0, 0.0, 0.0, 0.0, 33.0, 68.0, 12.0, 17.0, 65.0, 61.0, 21.0, 0.0, 49.0, 0.0, 8.0, 0.0, 40.0, 0.0, 54.0, 27.0, 13.0, 0.0, 9.0, 0.0, 0.0, 0.0, 45.0, 15.0, 0.0, 135.0, 22.0, 3.0, 53.0, 7.0, 200.0, 55.0, 83.0, 70.0, 0.0, 96.0, 0.0, 0.0, 11.0, 73.0, 17.0, 0.0, 49.0, 8.0, 0.0, 0.0, 0.0, 28.0, 87.0, 21.0, 0.0, 0.0, 43.0, 104.0, 2.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 15.0, 185.0, 0.0, 79.0, 186.0, 0.0, 39.0, 0.0, 0.0, 14.0, 6.0, 39.0, 126.0, 3.0, 0.0, 55.0, 107.0, 71.0, 152.0, 15.0, 12.0, 9.0, 0.0, 87.0, 57.0, 17.0, 25.0, 52.0, 32.0, 0.0, 9.0, 0.0, 0.0, 0.0, 63.0, 64.0, 79.0, 189.0, 145.0, 0.0, 0.0, 5.0, 0.0, 51.0, 26.0, 0.0, 0.0, 13.0, 0.0, 0.0, 2.0, 26.0, 20.0, 6.0, 0.0, 6.0, 62.0, 93.0, 26.0, 8.0, 0.0, 27.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3981209788903866, "mean_inference_ms": 9.212095349868651, "mean_action_processing_ms": 0.7630631321368694, "mean_env_wait_ms": 1.2574292760848487, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004770874977111816, "StateBufferConnector_ms": 0.006623625755310059, "ViewRequirementAgentConnector_ms": 0.18425965309143066}, "num_episodes": 23, "episode_return_max": 396.0, "episode_return_min": -240.50000000000037, "episode_return_mean": 115.96099999999979, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000, "num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 162.01708157792544, "num_env_steps_trained_throughput_per_sec": 162.01708157792544, "timesteps_total": 528000, "num_env_steps_sampled_lifetime": 528000, "num_agent_steps_sampled_lifetime": 2112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2112000, "timers": {"training_iteration_time_ms": 279195.279, "restore_workers_time_ms": 0.023, "training_step_time_ms": 279195.21, "sample_time_ms": 4256.928, "learn_time_ms": 274895.059, "learn_throughput": 14.551, "synch_weights_time_ms": 36.018}, "counters": {"num_env_steps_sampled": 528000, "num_env_steps_trained": 528000, "num_agent_steps_sampled": 2112000, "num_agent_steps_trained": 2112000}, "done": false, "training_iteration": 132, "trial_id": "3a355_00000", "date": "2024-08-13_03-54-31", "timestamp": 1723535671, "time_this_iter_s": 24.77365207672119, "time_total_s": 9872.013771295547, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52f73a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9872.013771295547, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 92.18857142857142, "ram_util_percent": 82.19428571428573}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9367932056742055, "cur_kl_coeff": 1.262177448353619e-30, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.1896659340808, "policy_loss": -0.002097511551929293, "vf_loss": 2.191763447075294, "vf_explained_var": 0.007129658372313888, "kl": 0.0022500360923392794, "entropy": 0.2971930509206479, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 250425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 29.806536437846997, "cur_kl_coeff": 1.7700541032894533e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.791891916971358, "policy_loss": 9.349106278802668e-05, "vf_loss": 5.791798424342322, "vf_explained_var": 0.7255808662800561, "kl": 0.002395259326472147, "entropy": 0.8070032907856836, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 250425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000}, "env_runners": {"episode_reward_max": 396.0, "episode_reward_min": -240.50000000000037, "episode_reward_mean": 115.3969999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 27.00349999999996, "predator_policy": 30.695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [152.49999999999957, 141.89999999999964, -134.90000000000066, -73.300000000001, 195.7999999999994, 148.3999999999998, 199.89999999999938, 310.89999999999986, 150.69999999999962, 219.99999999999926, -10.600000000000051, 136.79999999999973, 51.30000000000004, -58.79999999999974, 70.60000000000004, 216.69999999999928, 207.39999999999932, -177.6999999999999, 187.9999999999993, 186.69999999999942, -24.900000000000055, 33.300000000000274, 29.500000000000206, 343.0, 166.09999999999954, 140.99999999999892, -22.899999999999515, 187.59999999999957, 356.0, 366.7, 40.0000000000003, 132.99999999999974, -217.70000000000007, 178.99999999999926, 112.5999999999998, -240.50000000000037, 162.3999999999999, 65.80000000000004, 40.0000000000003, 108.69999999999982, 39.29999999999996, 157.29999999999959, 367.6, 40.70000000000021, 22.89999999999978, 219.99999999999926, 136.59999999999985, 37.800000000000296, 363.1, 209.9999999999993, 190.9999999999994, -169.80000000000055, -129.7000000000005, 146.49999999999963, 40.0000000000003, 187.19999999999942, 120.39999999999996, 188.79999999999941, -22.700000000000003, 97.7, 358.0, 238.89999999999918, 6.69999999999993, 20.79999999999998, 155.79999999999959, 207.39999999999975, 40.0000000000003, 120.0999999999998, 249.0, -43.89999999999974, 219.99999999999926, 137.09999999999883, -13.5, 40.0000000000003, 347.0, 396.0, 200.89999999999944, 33.400000000000205, -22.199999999999548, 122.69999999999979, 96.89999999999986, 15.30000000000007, -70.0, 127.39999999999972, 134.1999999999997, 186.09999999999943, -114.20000000000022, 362.2000000000004, 13.600000000000012, 52.60000000000028, 226.8999999999992, 182.49999999999946, 32.9000000000002, 315.500000000001, 156.49999999999957, -0.3000000000000028, 183.89999999999944, 189.99999999999937, 109.79999999999981, 197.99999999999937], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [132.5, 20.000000000000014, 116.0, -24.09999999999988, -11.499999999999826, -282.39999999999986, -1.0000000000000382, -175.3000000000006, 200.0, -26.20000000000001, -139.60000000000002, 164.0, 200.0, -24.099999999999913, 198.2, 112.69999999999999, 200.0, -112.30000000000078, 200.0, 20.000000000000014, -45.10000000000003, -11.49999999999985, 161.0, -89.20000000000005, -267.7, 173.0, -124.90000000000046, -19.900000000000016, -261.4000000000003, 194.0, 200.0, 13.70000000000001, 20.000000000000014, 187.4, -150.40000000000003, -175.3, 20.000000000000014, 152.0, 20.000000000000014, 166.7, -116.50000000000003, -9.399999999999855, 13.699999999999946, -9.400000000000034, -116.50000000000003, 20.000000000000014, 152.0, 170.0, -82.90000000000003, 200.0, 112.9999999999996, 20.000000000000014, -45.09999999999976, -17.79999999999979, 200.0, -93.39999999999995, 182.0, 161.0, 200.0, 157.7, 20.000000000000014, 20.000000000000014, -85.00000000000043, 158.0, -263.5, -89.20000000000005, 20.000000000000014, 134.0, -97.60000000000002, 150.2, -95.50000000000009, -400.0, -156.40000000000003, 165.8, -181.60000000000002, 151.4, 20.000000000000014, 20.000000000000014, 139.1, -114.40000000000023, 37.999999999999986, -15.699999999999747, 200.0, -99.70000000000063, 200.0, 167.6, -7.300000000000005, 20.000000000000014, -24.09999999999979, -61.0, 200.0, 20.000000000000014, 188.0, -198.40000000000026, 15.799999999999946, 20.000000000000014, 200.0, 163.1, 185.0, 20.000000000000014, 137.0, 20.000000000000014, -336.99999999999966, -17.80000000000001, -24.099999999999746, -370.6000000000001, -61.9000000000002, 169.4, 20.000000000000014, 20.000000000000014, 164.0, 3.1999999999999615, -244.59999999999997, 200.0, 13.699999999999964, 172.1, -204.70000000000016, 20.000000000000014, -299.2, 173.9, 158.0, 173.0, 46.1000000000002, 183.8, 20.000000000000014, -157.3000000000006, -34.59999999999982, 13.399999999999972, -89.20000000000067, 161.0, 159.5, 38.89999999999996, 20.000000000000014, 20.000000000000014, 169.4, -112.30000000000078, -79.0, 185.0, 20.000000000000014, -397.9, 20.000000000000014, 200.0, 114.19999999999953, 17.900000000000002, -9.400000000000041, -81.10000000000014, 20.000000000000014, 20.000000000000014, 161.0, 173.0, 194.0, 200.0, -45.09999999999987, 200.0, 7.399999999999965, 20.000000000000014, -110.20000000000078, 20.000000000000014, -175.30000000000013, 179.0, 85.69999999999997, 3.1999999999999615, 20.000000000000014, -36.69999999999996, -181.60000000000022, 11.599999999999966, 200.0, -160.60000000000065, -143.80000000000055, 200.0, 176.0, 1.099999999999983, -112.29999999999995, -166.90000000000012, 200.0, 162.1999999999999, -30.39999999999975, 20.000000000000014, 20.000000000000014, 32.599999999999994, 52.400000000000205, 168.5, -32.49999999999978, 164.0, 7.399999999999988, 9.499999999999964, 143.9, 158.59999999999974, 146.0, -32.4999999999999, -91.30000000000044, 20.000000000000014, 189.2, -28.29999999999977, -135.40000000000072, 196.4, -110.2000000000005, 137.0, 20.000000000000014, 167.0], "policy_predator_policy_reward": [0.0, 0.0, 30.0, 20.0, 77.0, 82.0, 26.0, 77.0, 22.0, 0.0, 80.0, 44.0, 21.0, 3.0, 0.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 46.0, 0.0, 65.0, 146.0, 0.0, 21.0, 65.0, 98.0, 40.0, 0.0, 3.0, 0.0, 0.0, 61.0, 87.0, 16.0, 0.0, 0.0, 0.0, 33.0, 68.0, 12.0, 17.0, 65.0, 61.0, 21.0, 0.0, 49.0, 0.0, 8.0, 0.0, 40.0, 0.0, 54.0, 27.0, 13.0, 0.0, 9.0, 0.0, 0.0, 0.0, 45.0, 15.0, 0.0, 135.0, 22.0, 3.0, 53.0, 7.0, 200.0, 55.0, 83.0, 70.0, 0.0, 96.0, 0.0, 0.0, 11.0, 73.0, 17.0, 0.0, 49.0, 8.0, 0.0, 0.0, 0.0, 28.0, 87.0, 21.0, 0.0, 0.0, 43.0, 104.0, 2.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 15.0, 185.0, 0.0, 79.0, 186.0, 0.0, 39.0, 0.0, 0.0, 14.0, 6.0, 39.0, 126.0, 3.0, 0.0, 55.0, 107.0, 71.0, 152.0, 15.0, 12.0, 9.0, 0.0, 87.0, 57.0, 17.0, 25.0, 52.0, 32.0, 0.0, 9.0, 0.0, 0.0, 0.0, 63.0, 64.0, 79.0, 189.0, 145.0, 0.0, 0.0, 5.0, 0.0, 51.0, 26.0, 0.0, 0.0, 13.0, 0.0, 0.0, 2.0, 26.0, 20.0, 6.0, 0.0, 6.0, 62.0, 93.0, 26.0, 8.0, 0.0, 27.0, 5.0, 67.0, 33.0, 76.0, 12.0, 78.0, 0.0, 9.0, 0.0, 58.0, 107.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 6.0, 14.0, 37.0, 10.0, 6.0, 0.0, 13.0, 3.0, 40.0, 47.0, 24.0, 23.0, 0.0, 55.0, 74.0, 62.0, 21.0, 11.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3901783988211753, "mean_inference_ms": 9.230445846994398, "mean_action_processing_ms": 0.7605554522004823, "mean_env_wait_ms": 1.2022011490221984, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004395723342895508, "StateBufferConnector_ms": 0.005678892135620117, "ViewRequirementAgentConnector_ms": 0.1929922103881836}, "num_episodes": 18, "episode_return_max": 396.0, "episode_return_min": -240.50000000000037, "episode_return_mean": 115.3969999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000, "num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 254.54674611077016, "num_env_steps_trained_throughput_per_sec": 254.54674611077016, "timesteps_total": 532000, "num_env_steps_sampled_lifetime": 532000, "num_agent_steps_sampled_lifetime": 2128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2128000, "timers": {"training_iteration_time_ms": 277727.566, "restore_workers_time_ms": 0.027, "training_step_time_ms": 277727.491, "sample_time_ms": 3988.203, "learn_time_ms": 273705.797, "learn_throughput": 14.614, "synch_weights_time_ms": 26.694}, "counters": {"num_env_steps_sampled": 532000, "num_env_steps_trained": 532000, "num_agent_steps_sampled": 2128000, "num_agent_steps_trained": 2128000}, "done": false, "training_iteration": 133, "trial_id": "3a355_00000", "date": "2024-08-13_03-54-47", "timestamp": 1723535687, "time_this_iter_s": 15.778167009353638, "time_total_s": 9887.791938304901, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5204310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9887.791938304901, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 81.6590909090909, "ram_util_percent": 80.19090909090909}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8524318148771292, "cur_kl_coeff": 6.310887241768095e-31, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3781915397871107, "policy_loss": -0.0021746074206752592, "vf_loss": 2.3803661484566945, "vf_explained_var": 0.002784919738769531, "kl": 0.0032933225875250733, "entropy": 0.29428230133006184, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 252315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 27.997830373742595, "cur_kl_coeff": 8.850270516447267e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.598776316264319, "policy_loss": -0.0009665991487622103, "vf_loss": 5.599742906055753, "vf_explained_var": 0.48959841141625055, "kl": 0.0009087066703876103, "entropy": 0.7589919438753179, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 252315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000}, "env_runners": {"episode_reward_max": 396.0, "episode_reward_min": -510.0999999999991, "episode_reward_mean": 114.16599999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 26.902999999999956, "predator_policy": 30.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.500000000000206, 343.0, 166.09999999999954, 140.99999999999892, -22.899999999999515, 187.59999999999957, 356.0, 366.7, 40.0000000000003, 132.99999999999974, -217.70000000000007, 178.99999999999926, 112.5999999999998, -240.50000000000037, 162.3999999999999, 65.80000000000004, 40.0000000000003, 108.69999999999982, 39.29999999999996, 157.29999999999959, 367.6, 40.70000000000021, 22.89999999999978, 219.99999999999926, 136.59999999999985, 37.800000000000296, 363.1, 209.9999999999993, 190.9999999999994, -169.80000000000055, -129.7000000000005, 146.49999999999963, 40.0000000000003, 187.19999999999942, 120.39999999999996, 188.79999999999941, -22.700000000000003, 97.7, 358.0, 238.89999999999918, 6.69999999999993, 20.79999999999998, 155.79999999999959, 207.39999999999975, 40.0000000000003, 120.0999999999998, 249.0, -43.89999999999974, 219.99999999999926, 137.09999999999883, -13.5, 40.0000000000003, 347.0, 396.0, 200.89999999999944, 33.400000000000205, -22.199999999999548, 122.69999999999979, 96.89999999999986, 15.30000000000007, -70.0, 127.39999999999972, 134.1999999999997, 186.09999999999943, -114.20000000000022, 362.2000000000004, 13.600000000000012, 52.60000000000028, 226.8999999999992, 182.49999999999946, 32.9000000000002, 315.500000000001, 156.49999999999957, -0.3000000000000028, 183.89999999999944, 189.99999999999937, 109.79999999999981, 197.99999999999937, 191.9999999999994, 92.99999999999983, 40.0000000000003, -4.399999999999936, 386.10000000000025, -55.19999999999994, 197.99999999999937, 200.19999999999936, 174.7, -14.999999999999565, -40.29999999999991, -139.39999999999964, -510.0999999999991, 112.19999999999982, 363.1, 35.60000000000022, 118.49999999999977, 316.40000000000003, 40.0000000000003, -36.99999999999955, 188.29999999999944, 350.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-116.50000000000003, 20.000000000000014, 152.0, 170.0, -82.90000000000003, 200.0, 112.9999999999996, 20.000000000000014, -45.09999999999976, -17.79999999999979, 200.0, -93.39999999999995, 182.0, 161.0, 200.0, 157.7, 20.000000000000014, 20.000000000000014, -85.00000000000043, 158.0, -263.5, -89.20000000000005, 20.000000000000014, 134.0, -97.60000000000002, 150.2, -95.50000000000009, -400.0, -156.40000000000003, 165.8, -181.60000000000002, 151.4, 20.000000000000014, 20.000000000000014, 139.1, -114.40000000000023, 37.999999999999986, -15.699999999999747, 200.0, -99.70000000000063, 200.0, 167.6, -7.300000000000005, 20.000000000000014, -24.09999999999979, -61.0, 200.0, 20.000000000000014, 188.0, -198.40000000000026, 15.799999999999946, 20.000000000000014, 200.0, 163.1, 185.0, 20.000000000000014, 137.0, 20.000000000000014, -336.99999999999966, -17.80000000000001, -24.099999999999746, -370.6000000000001, -61.9000000000002, 169.4, 20.000000000000014, 20.000000000000014, 164.0, 3.1999999999999615, -244.59999999999997, 200.0, 13.699999999999964, 172.1, -204.70000000000016, 20.000000000000014, -299.2, 173.9, 158.0, 173.0, 46.1000000000002, 183.8, 20.000000000000014, -157.3000000000006, -34.59999999999982, 13.399999999999972, -89.20000000000067, 161.0, 159.5, 38.89999999999996, 20.000000000000014, 20.000000000000014, 169.4, -112.30000000000078, -79.0, 185.0, 20.000000000000014, -397.9, 20.000000000000014, 200.0, 114.19999999999953, 17.900000000000002, -9.400000000000041, -81.10000000000014, 20.000000000000014, 20.000000000000014, 161.0, 173.0, 194.0, 200.0, -45.09999999999987, 200.0, 7.399999999999965, 20.000000000000014, -110.20000000000078, 20.000000000000014, -175.30000000000013, 179.0, 85.69999999999997, 3.1999999999999615, 20.000000000000014, -36.69999999999996, -181.60000000000022, 11.599999999999966, 200.0, -160.60000000000065, -143.80000000000055, 200.0, 176.0, 1.099999999999983, -112.29999999999995, -166.90000000000012, 200.0, 162.1999999999999, -30.39999999999975, 20.000000000000014, 20.000000000000014, 32.599999999999994, 52.400000000000205, 168.5, -32.49999999999978, 164.0, 7.399999999999988, 9.499999999999964, 143.9, 158.59999999999974, 146.0, -32.4999999999999, -91.30000000000044, 20.000000000000014, 189.2, -28.29999999999977, -135.40000000000072, 196.4, -110.2000000000005, 137.0, 20.000000000000014, 167.0, 158.0, 20.000000000000014, 69.80000000000014, -17.799999999999812, 20.000000000000014, 20.000000000000014, 14.599999999999966, -169.00000000000043, 190.09999999999994, 194.0, -391.0, 138.79999999999998, -21.999999999999872, 200.0, 20.000000000000014, 180.2, -13.299999999999997, 95.0, -78.70000000000083, 13.699999999999966, 20.000000000000014, -133.30000000000007, -185.80000000000058, -55.60000000000004, -339.09999999999945, -357.99999999999966, 200.0, -185.79999999999995, 163.1, 200.0, 20.000000000000014, 11.599999999999975, 155.0, -116.49999999999989, 161.0, 142.39999999999998, 20.000000000000014, 20.000000000000014, 15.799999999999963, -122.80000000000075, 5.299999999999965, 164.0, 179.0, 164.9], "policy_predator_policy_reward": [65.0, 61.0, 21.0, 0.0, 49.0, 0.0, 8.0, 0.0, 40.0, 0.0, 54.0, 27.0, 13.0, 0.0, 9.0, 0.0, 0.0, 0.0, 45.0, 15.0, 0.0, 135.0, 22.0, 3.0, 53.0, 7.0, 200.0, 55.0, 83.0, 70.0, 0.0, 96.0, 0.0, 0.0, 11.0, 73.0, 17.0, 0.0, 49.0, 8.0, 0.0, 0.0, 0.0, 28.0, 87.0, 21.0, 0.0, 0.0, 43.0, 104.0, 2.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 15.0, 185.0, 0.0, 79.0, 186.0, 0.0, 39.0, 0.0, 0.0, 14.0, 6.0, 39.0, 126.0, 3.0, 0.0, 55.0, 107.0, 71.0, 152.0, 15.0, 12.0, 9.0, 0.0, 87.0, 57.0, 17.0, 25.0, 52.0, 32.0, 0.0, 9.0, 0.0, 0.0, 0.0, 63.0, 64.0, 79.0, 189.0, 145.0, 0.0, 0.0, 5.0, 0.0, 51.0, 26.0, 0.0, 0.0, 13.0, 0.0, 0.0, 2.0, 26.0, 20.0, 6.0, 0.0, 6.0, 62.0, 93.0, 26.0, 8.0, 0.0, 27.0, 5.0, 67.0, 33.0, 76.0, 12.0, 78.0, 0.0, 9.0, 0.0, 58.0, 107.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 6.0, 14.0, 37.0, 10.0, 6.0, 0.0, 13.0, 3.0, 40.0, 47.0, 24.0, 23.0, 0.0, 55.0, 74.0, 62.0, 21.0, 11.0, 0.0, 14.0, 0.0, 30.0, 11.0, 0.0, 0.0, 127.0, 23.0, 0.0, 2.0, 197.0, 0.0, 20.0, 0.0, 0.0, 0.0, 93.0, 0.0, 0.0, 50.0, 17.0, 56.0, 102.0, 0.0, 187.0, 0.0, 0.0, 98.0, 0.0, 0.0, 4.0, 0.0, 32.0, 48.0, 13.0, 0.0, 0.0, 0.0, 36.0, 34.0, 12.0, 7.0, 0.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3789439586841, "mean_inference_ms": 9.185197546183497, "mean_action_processing_ms": 0.7584822272105157, "mean_env_wait_ms": 1.196971494595482, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004392027854919434, "StateBufferConnector_ms": 0.005690097808837891, "ViewRequirementAgentConnector_ms": 0.20193636417388916}, "num_episodes": 22, "episode_return_max": 396.0, "episode_return_min": -510.0999999999991, "episode_return_mean": 114.16599999999985, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000, "num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 257.7532815878172, "num_env_steps_trained_throughput_per_sec": 257.7532815878172, "timesteps_total": 536000, "num_env_steps_sampled_lifetime": 536000, "num_agent_steps_sampled_lifetime": 2144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2144000, "timers": {"training_iteration_time_ms": 276190.439, "restore_workers_time_ms": 0.025, "training_step_time_ms": 276190.369, "sample_time_ms": 3602.234, "learn_time_ms": 272554.927, "learn_throughput": 14.676, "synch_weights_time_ms": 25.898}, "counters": {"num_env_steps_sampled": 536000, "num_env_steps_trained": 536000, "num_agent_steps_sampled": 2144000, "num_agent_steps_trained": 2144000}, "done": false, "training_iteration": 134, "trial_id": "3a355_00000", "date": "2024-08-13_03-55-02", "timestamp": 1723535702, "time_this_iter_s": 15.615190029144287, "time_total_s": 9903.407128334045, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52931f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9903.407128334045, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 79.7681818181818, "ram_util_percent": 79.88636363636364}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9801442562784782, "cur_kl_coeff": 3.1554436208840474e-31, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.805296459147539, "policy_loss": -0.002505050366744399, "vf_loss": 2.80780150713744, "vf_explained_var": -0.002346509095852968, "kl": 0.002821011417357127, "entropy": 0.31759626846464856, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 254205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 38.537632508031905, "cur_kl_coeff": 4.425135258223633e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.934085004291838, "policy_loss": -0.00015722778268532935, "vf_loss": 4.934242227342394, "vf_explained_var": 0.4501173261612181, "kl": 0.001412181169511204, "entropy": 0.8875894844216644, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 254205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000}, "env_runners": {"episode_reward_max": 396.0, "episode_reward_min": -510.0999999999991, "episode_reward_mean": 107.90999999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 24.28999999999995, "predator_policy": 29.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [39.29999999999996, 157.29999999999959, 367.6, 40.70000000000021, 22.89999999999978, 219.99999999999926, 136.59999999999985, 37.800000000000296, 363.1, 209.9999999999993, 190.9999999999994, -169.80000000000055, -129.7000000000005, 146.49999999999963, 40.0000000000003, 187.19999999999942, 120.39999999999996, 188.79999999999941, -22.700000000000003, 97.7, 358.0, 238.89999999999918, 6.69999999999993, 20.79999999999998, 155.79999999999959, 207.39999999999975, 40.0000000000003, 120.0999999999998, 249.0, -43.89999999999974, 219.99999999999926, 137.09999999999883, -13.5, 40.0000000000003, 347.0, 396.0, 200.89999999999944, 33.400000000000205, -22.199999999999548, 122.69999999999979, 96.89999999999986, 15.30000000000007, -70.0, 127.39999999999972, 134.1999999999997, 186.09999999999943, -114.20000000000022, 362.2000000000004, 13.600000000000012, 52.60000000000028, 226.8999999999992, 182.49999999999946, 32.9000000000002, 315.500000000001, 156.49999999999957, -0.3000000000000028, 183.89999999999944, 189.99999999999937, 109.79999999999981, 197.99999999999937, 191.9999999999994, 92.99999999999983, 40.0000000000003, -4.399999999999936, 386.10000000000025, -55.19999999999994, 197.99999999999937, 200.19999999999936, 174.7, -14.999999999999565, -40.29999999999991, -139.39999999999964, -510.0999999999991, 112.19999999999982, 363.1, 35.60000000000022, 118.49999999999977, 316.40000000000003, 40.0000000000003, -36.99999999999955, 188.29999999999944, 350.9, 219.99999999999926, 368.8, 126.39999999999975, -178.90000000000012, 219.99999999999926, 180.69999999999956, 146.09999999999965, -128.0000000000008, 12.000000000000007, -216.60000000000042, 205.3999999999993, 166.09999999999954, 40.0000000000003, 40.0000000000003, 164.99999999999966, 92.6999999999999, -151.80000000000132, 16.799999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [37.999999999999986, -15.699999999999747, 200.0, -99.70000000000063, 200.0, 167.6, -7.300000000000005, 20.000000000000014, -24.09999999999979, -61.0, 200.0, 20.000000000000014, 188.0, -198.40000000000026, 15.799999999999946, 20.000000000000014, 200.0, 163.1, 185.0, 20.000000000000014, 137.0, 20.000000000000014, -336.99999999999966, -17.80000000000001, -24.099999999999746, -370.6000000000001, -61.9000000000002, 169.4, 20.000000000000014, 20.000000000000014, 164.0, 3.1999999999999615, -244.59999999999997, 200.0, 13.699999999999964, 172.1, -204.70000000000016, 20.000000000000014, -299.2, 173.9, 158.0, 173.0, 46.1000000000002, 183.8, 20.000000000000014, -157.3000000000006, -34.59999999999982, 13.399999999999972, -89.20000000000067, 161.0, 159.5, 38.89999999999996, 20.000000000000014, 20.000000000000014, 169.4, -112.30000000000078, -79.0, 185.0, 20.000000000000014, -397.9, 20.000000000000014, 200.0, 114.19999999999953, 17.900000000000002, -9.400000000000041, -81.10000000000014, 20.000000000000014, 20.000000000000014, 161.0, 173.0, 194.0, 200.0, -45.09999999999987, 200.0, 7.399999999999965, 20.000000000000014, -110.20000000000078, 20.000000000000014, -175.30000000000013, 179.0, 85.69999999999997, 3.1999999999999615, 20.000000000000014, -36.69999999999996, -181.60000000000022, 11.599999999999966, 200.0, -160.60000000000065, -143.80000000000055, 200.0, 176.0, 1.099999999999983, -112.29999999999995, -166.90000000000012, 200.0, 162.1999999999999, -30.39999999999975, 20.000000000000014, 20.000000000000014, 32.599999999999994, 52.400000000000205, 168.5, -32.49999999999978, 164.0, 7.399999999999988, 9.499999999999964, 143.9, 158.59999999999974, 146.0, -32.4999999999999, -91.30000000000044, 20.000000000000014, 189.2, -28.29999999999977, -135.40000000000072, 196.4, -110.2000000000005, 137.0, 20.000000000000014, 167.0, 158.0, 20.000000000000014, 69.80000000000014, -17.799999999999812, 20.000000000000014, 20.000000000000014, 14.599999999999966, -169.00000000000043, 190.09999999999994, 194.0, -391.0, 138.79999999999998, -21.999999999999872, 200.0, 20.000000000000014, 180.2, -13.299999999999997, 95.0, -78.70000000000083, 13.699999999999966, 20.000000000000014, -133.30000000000007, -185.80000000000058, -55.60000000000004, -339.09999999999945, -357.99999999999966, 200.0, -185.79999999999995, 163.1, 200.0, 20.000000000000014, 11.599999999999975, 155.0, -116.49999999999989, 161.0, 142.39999999999998, 20.000000000000014, 20.000000000000014, 15.799999999999963, -122.80000000000075, 5.299999999999965, 164.0, 179.0, 164.9, 20.000000000000014, 200.0, 192.8, 164.0, 106.39999999999998, 20.000000000000014, -154.3000000000001, -223.6, 200.0, 20.000000000000014, -91.30000000000005, 200.0, -61.900000000000055, 164.0, -315.99999999999955, 20.000000000000014, 106.39999999999998, -198.40000000000003, -179.50000000000014, -195.10000000000022, 172.1, 23.30000000000008, -82.90000000000086, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 187.4, -114.39999999999986, 20.000000000000014, 52.70000000000014, -221.50000000000043, -70.30000000000089, -42.99999999999977, 15.799999999999963], "policy_predator_policy_reward": [17.0, 0.0, 49.0, 8.0, 0.0, 0.0, 0.0, 28.0, 87.0, 21.0, 0.0, 0.0, 43.0, 104.0, 2.0, 0.0, 0.0, 0.0, 5.0, 0.0, 19.0, 15.0, 185.0, 0.0, 79.0, 186.0, 0.0, 39.0, 0.0, 0.0, 14.0, 6.0, 39.0, 126.0, 3.0, 0.0, 55.0, 107.0, 71.0, 152.0, 15.0, 12.0, 9.0, 0.0, 87.0, 57.0, 17.0, 25.0, 52.0, 32.0, 0.0, 9.0, 0.0, 0.0, 0.0, 63.0, 64.0, 79.0, 189.0, 145.0, 0.0, 0.0, 5.0, 0.0, 51.0, 26.0, 0.0, 0.0, 13.0, 0.0, 0.0, 2.0, 26.0, 20.0, 6.0, 0.0, 6.0, 62.0, 93.0, 26.0, 8.0, 0.0, 27.0, 5.0, 67.0, 33.0, 76.0, 12.0, 78.0, 0.0, 9.0, 0.0, 58.0, 107.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 6.0, 14.0, 37.0, 10.0, 6.0, 0.0, 13.0, 3.0, 40.0, 47.0, 24.0, 23.0, 0.0, 55.0, 74.0, 62.0, 21.0, 11.0, 0.0, 14.0, 0.0, 30.0, 11.0, 0.0, 0.0, 127.0, 23.0, 0.0, 2.0, 197.0, 0.0, 20.0, 0.0, 0.0, 0.0, 93.0, 0.0, 0.0, 50.0, 17.0, 56.0, 102.0, 0.0, 187.0, 0.0, 0.0, 98.0, 0.0, 0.0, 4.0, 0.0, 32.0, 48.0, 13.0, 0.0, 0.0, 0.0, 36.0, 34.0, 12.0, 7.0, 0.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 83.0, 116.0, 0.0, 0.0, 52.0, 20.0, 5.0, 39.0, 102.0, 66.0, 0.0, 104.0, 0.0, 158.0, 0.0, 10.0, 0.0, 49.0, 0.0, 0.0, 0.0, 0.0, 54.0, 38.0, 20.0, 0.0, 124.0, 16.0, 27.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.370243999772663, "mean_inference_ms": 9.147591772672786, "mean_action_processing_ms": 0.756656448596513, "mean_env_wait_ms": 1.1918068388810152, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0048645734786987305, "StateBufferConnector_ms": 0.0055084228515625, "ViewRequirementAgentConnector_ms": 0.1833643913269043}, "num_episodes": 18, "episode_return_max": 396.0, "episode_return_min": -510.0999999999991, "episode_return_mean": 107.90999999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000, "num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 257.7189891179992, "num_env_steps_trained_throughput_per_sec": 257.7189891179992, "timesteps_total": 540000, "num_env_steps_sampled_lifetime": 540000, "num_agent_steps_sampled_lifetime": 2160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2160000, "timers": {"training_iteration_time_ms": 274331.763, "restore_workers_time_ms": 0.025, "training_step_time_ms": 274331.693, "sample_time_ms": 3140.863, "learn_time_ms": 271159.03, "learn_throughput": 14.751, "synch_weights_time_ms": 25.034}, "counters": {"num_env_steps_sampled": 540000, "num_env_steps_trained": 540000, "num_agent_steps_sampled": 2160000, "num_agent_steps_trained": 2160000}, "done": false, "training_iteration": 135, "trial_id": "3a355_00000", "date": "2024-08-13_03-55-18", "timestamp": 1723535718, "time_this_iter_s": 15.574083089828491, "time_total_s": 9918.981211423874, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52fdf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 9918.981211423874, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 79.86818181818184, "ram_util_percent": 79.99545454545455}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.896350556028583, "cur_kl_coeff": 1.5777218104420237e-31, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.256587025349733, "policy_loss": -0.0026840783394478933, "vf_loss": 2.259271105824324, "vf_explained_var": 0.0016686954195537264, "kl": 0.003032663398867008, "entropy": 0.36787803158873605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 256095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 42.31389950192164, "cur_kl_coeff": 2.2125676291118167e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.697365581800067, "policy_loss": -0.0011608939982517056, "vf_loss": 4.698526467721929, "vf_explained_var": 0.4511366350625558, "kl": 0.0044875840098488095, "entropy": 0.9497144595655814, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 256095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000}, "env_runners": {"episode_reward_max": 396.0, "episode_reward_min": -510.0999999999991, "episode_reward_mean": 101.74599999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 22.042999999999946, "predator_policy": 28.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-22.700000000000003, 97.7, 358.0, 238.89999999999918, 6.69999999999993, 20.79999999999998, 155.79999999999959, 207.39999999999975, 40.0000000000003, 120.0999999999998, 249.0, -43.89999999999974, 219.99999999999926, 137.09999999999883, -13.5, 40.0000000000003, 347.0, 396.0, 200.89999999999944, 33.400000000000205, -22.199999999999548, 122.69999999999979, 96.89999999999986, 15.30000000000007, -70.0, 127.39999999999972, 134.1999999999997, 186.09999999999943, -114.20000000000022, 362.2000000000004, 13.600000000000012, 52.60000000000028, 226.8999999999992, 182.49999999999946, 32.9000000000002, 315.500000000001, 156.49999999999957, -0.3000000000000028, 183.89999999999944, 189.99999999999937, 109.79999999999981, 197.99999999999937, 191.9999999999994, 92.99999999999983, 40.0000000000003, -4.399999999999936, 386.10000000000025, -55.19999999999994, 197.99999999999937, 200.19999999999936, 174.7, -14.999999999999565, -40.29999999999991, -139.39999999999964, -510.0999999999991, 112.19999999999982, 363.1, 35.60000000000022, 118.49999999999977, 316.40000000000003, 40.0000000000003, -36.99999999999955, 188.29999999999944, 350.9, 219.99999999999926, 368.8, 126.39999999999975, -178.90000000000012, 219.99999999999926, 180.69999999999956, 146.09999999999965, -128.0000000000008, 12.000000000000007, -216.60000000000042, 205.3999999999993, 166.09999999999954, 40.0000000000003, 40.0000000000003, 164.99999999999966, 92.6999999999999, -151.80000000000132, 16.799999999999926, 77.39999999999999, 14.599999999999667, 31.1, -236.70000000000002, 164.1999999999989, 208.29999999999933, 98.99999999999864, 139.89999999999964, 40.0000000000003, 201.99999999999937, 153.1999999999996, 183.99999999999943, 195.59999999999928, 201.99999999999935, 40.0000000000003, -22.299999999999564, 219.99999999999926, -159.00000000000054], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-204.70000000000016, 20.000000000000014, -299.2, 173.9, 158.0, 173.0, 46.1000000000002, 183.8, 20.000000000000014, -157.3000000000006, -34.59999999999982, 13.399999999999972, -89.20000000000067, 161.0, 159.5, 38.89999999999996, 20.000000000000014, 20.000000000000014, 169.4, -112.30000000000078, -79.0, 185.0, 20.000000000000014, -397.9, 20.000000000000014, 200.0, 114.19999999999953, 17.900000000000002, -9.400000000000041, -81.10000000000014, 20.000000000000014, 20.000000000000014, 161.0, 173.0, 194.0, 200.0, -45.09999999999987, 200.0, 7.399999999999965, 20.000000000000014, -110.20000000000078, 20.000000000000014, -175.30000000000013, 179.0, 85.69999999999997, 3.1999999999999615, 20.000000000000014, -36.69999999999996, -181.60000000000022, 11.599999999999966, 200.0, -160.60000000000065, -143.80000000000055, 200.0, 176.0, 1.099999999999983, -112.29999999999995, -166.90000000000012, 200.0, 162.1999999999999, -30.39999999999975, 20.000000000000014, 20.000000000000014, 32.599999999999994, 52.400000000000205, 168.5, -32.49999999999978, 164.0, 7.399999999999988, 9.499999999999964, 143.9, 158.59999999999974, 146.0, -32.4999999999999, -91.30000000000044, 20.000000000000014, 189.2, -28.29999999999977, -135.40000000000072, 196.4, -110.2000000000005, 137.0, 20.000000000000014, 167.0, 158.0, 20.000000000000014, 69.80000000000014, -17.799999999999812, 20.000000000000014, 20.000000000000014, 14.599999999999966, -169.00000000000043, 190.09999999999994, 194.0, -391.0, 138.79999999999998, -21.999999999999872, 200.0, 20.000000000000014, 180.2, -13.299999999999997, 95.0, -78.70000000000083, 13.699999999999966, 20.000000000000014, -133.30000000000007, -185.80000000000058, -55.60000000000004, -339.09999999999945, -357.99999999999966, 200.0, -185.79999999999995, 163.1, 200.0, 20.000000000000014, 11.599999999999975, 155.0, -116.49999999999989, 161.0, 142.39999999999998, 20.000000000000014, 20.000000000000014, 15.799999999999963, -122.80000000000075, 5.299999999999965, 164.0, 179.0, 164.9, 20.000000000000014, 200.0, 192.8, 164.0, 106.39999999999998, 20.000000000000014, -154.3000000000001, -223.6, 200.0, 20.000000000000014, -91.30000000000005, 200.0, -61.900000000000055, 164.0, -315.99999999999955, 20.000000000000014, 106.39999999999998, -198.40000000000003, -179.50000000000014, -195.10000000000022, 172.1, 23.30000000000008, -82.90000000000086, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 187.4, -114.39999999999986, 20.000000000000014, 52.70000000000014, -221.50000000000043, -70.30000000000089, -42.99999999999977, 15.799999999999963, -248.79999999999998, 198.2, -19.900000000000013, 12.500000000000192, -253.00000000000017, 154.1, -259.2999999999995, -261.4, 20.000000000000014, 144.19999999999965, 20.000000000000014, 188.3, 91.09999999999931, -3.099999999999958, 20.000000000000014, 119.89999999999998, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, -38.80000000000003, 164.0, 164.0, 20.000000000000014, 170.0, 11.599999999999964, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 17.899999999999977, -110.20000000000078, 20.000000000000014, 200.0, 20.000000000000014, -382.0], "policy_predator_policy_reward": [55.0, 107.0, 71.0, 152.0, 15.0, 12.0, 9.0, 0.0, 87.0, 57.0, 17.0, 25.0, 52.0, 32.0, 0.0, 9.0, 0.0, 0.0, 0.0, 63.0, 64.0, 79.0, 189.0, 145.0, 0.0, 0.0, 5.0, 0.0, 51.0, 26.0, 0.0, 0.0, 13.0, 0.0, 0.0, 2.0, 26.0, 20.0, 6.0, 0.0, 6.0, 62.0, 93.0, 26.0, 8.0, 0.0, 27.0, 5.0, 67.0, 33.0, 76.0, 12.0, 78.0, 0.0, 9.0, 0.0, 58.0, 107.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 6.0, 14.0, 37.0, 10.0, 6.0, 0.0, 13.0, 3.0, 40.0, 47.0, 24.0, 23.0, 0.0, 55.0, 74.0, 62.0, 21.0, 11.0, 0.0, 14.0, 0.0, 30.0, 11.0, 0.0, 0.0, 127.0, 23.0, 0.0, 2.0, 197.0, 0.0, 20.0, 0.0, 0.0, 0.0, 93.0, 0.0, 0.0, 50.0, 17.0, 56.0, 102.0, 0.0, 187.0, 0.0, 0.0, 98.0, 0.0, 0.0, 4.0, 0.0, 32.0, 48.0, 13.0, 0.0, 0.0, 0.0, 36.0, 34.0, 12.0, 7.0, 0.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 83.0, 116.0, 0.0, 0.0, 52.0, 20.0, 5.0, 39.0, 102.0, 66.0, 0.0, 104.0, 0.0, 158.0, 0.0, 10.0, 0.0, 49.0, 0.0, 0.0, 0.0, 0.0, 54.0, 38.0, 20.0, 0.0, 124.0, 16.0, 27.0, 17.0, 21.0, 107.0, 22.0, 0.0, 0.0, 130.0, 156.0, 128.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 28.0, 0.0, 0.0, 4.0, 10.0, 0.0, 9.0, 0.0, 0.0, 63.0, 7.0, 0.0, 0.0, 12.0, 191.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.362490406970335, "mean_inference_ms": 9.112586399346107, "mean_action_processing_ms": 0.7550877300134384, "mean_env_wait_ms": 1.1869762516144886, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0067234039306640625, "StateBufferConnector_ms": 0.004014372825622559, "ViewRequirementAgentConnector_ms": 0.1949366331100464}, "num_episodes": 18, "episode_return_max": 396.0, "episode_return_min": -510.0999999999991, "episode_return_mean": 101.74599999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000, "num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.158760101507094, "num_env_steps_trained_throughput_per_sec": 4.158760101507094, "timesteps_total": 544000, "num_env_steps_sampled_lifetime": 544000, "num_agent_steps_sampled_lifetime": 2176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2176000, "timers": {"training_iteration_time_ms": 367261.289, "restore_workers_time_ms": 0.021, "training_step_time_ms": 367261.223, "sample_time_ms": 2913.906, "learn_time_ms": 364316.344, "learn_throughput": 10.979, "synch_weights_time_ms": 24.507}, "counters": {"num_env_steps_sampled": 544000, "num_env_steps_trained": 544000, "num_agent_steps_sampled": 2176000, "num_agent_steps_trained": 2176000}, "done": false, "training_iteration": 136, "trial_id": "3a355_00000", "date": "2024-08-13_04-11-20", "timestamp": 1723536680, "time_this_iter_s": 961.963849067688, "time_total_s": 10880.945060491562, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d513a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 10880.945060491562, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 89.03333333333332, "ram_util_percent": 82.88055555555556}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9230777074972157, "cur_kl_coeff": 7.888609052210118e-32, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7775430612778538, "policy_loss": -0.001700267071402065, "vf_loss": 1.779243327196313, "vf_explained_var": 0.002592626450553773, "kl": 0.00134499511449517, "entropy": 0.31448718955119453, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 257985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 46.989382730968416, "cur_kl_coeff": 1.1062838145559083e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.35721994808742, "policy_loss": 0.00017793058471941443, "vf_loss": 4.357042023239943, "vf_explained_var": 0.44295674634988974, "kl": 0.0007815526045780297, "entropy": 0.8593080226706449, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 257985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000}, "env_runners": {"episode_reward_max": 386.10000000000025, "episode_reward_min": -510.0999999999991, "episode_reward_mean": 96.18099999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 22.995499999999947, "predator_policy": 25.095}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.30000000000007, -70.0, 127.39999999999972, 134.1999999999997, 186.09999999999943, -114.20000000000022, 362.2000000000004, 13.600000000000012, 52.60000000000028, 226.8999999999992, 182.49999999999946, 32.9000000000002, 315.500000000001, 156.49999999999957, -0.3000000000000028, 183.89999999999944, 189.99999999999937, 109.79999999999981, 197.99999999999937, 191.9999999999994, 92.99999999999983, 40.0000000000003, -4.399999999999936, 386.10000000000025, -55.19999999999994, 197.99999999999937, 200.19999999999936, 174.7, -14.999999999999565, -40.29999999999991, -139.39999999999964, -510.0999999999991, 112.19999999999982, 363.1, 35.60000000000022, 118.49999999999977, 316.40000000000003, 40.0000000000003, -36.99999999999955, 188.29999999999944, 350.9, 219.99999999999926, 368.8, 126.39999999999975, -178.90000000000012, 219.99999999999926, 180.69999999999956, 146.09999999999965, -128.0000000000008, 12.000000000000007, -216.60000000000042, 205.3999999999993, 166.09999999999954, 40.0000000000003, 40.0000000000003, 164.99999999999966, 92.6999999999999, -151.80000000000132, 16.799999999999926, 77.39999999999999, 14.599999999999667, 31.1, -236.70000000000002, 164.1999999999989, 208.29999999999933, 98.99999999999864, 139.89999999999964, 40.0000000000003, 201.99999999999937, 153.1999999999996, 183.99999999999943, 195.59999999999928, 201.99999999999935, 40.0000000000003, -22.299999999999564, 219.99999999999926, -159.00000000000054, 313.4, 219.99999999999926, 189.9999999999994, 220.8999999999992, 255.09999999999948, 40.0000000000003, -35.60000000000024, 208.89999999999986, 33.400000000000205, 43.600000000000364, 111.99999999999989, -18.899999999999693, -97.70000000000152, 138.59999999999965, 219.99999999999926, 210.9999999999993, -8.200000000000001, 188.29999999999941, 198.8999999999994, -70.00000000000121, -0.8999999999997998, 40.0000000000003, 26.80000000000009], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -36.69999999999996, -181.60000000000022, 11.599999999999966, 200.0, -160.60000000000065, -143.80000000000055, 200.0, 176.0, 1.099999999999983, -112.29999999999995, -166.90000000000012, 200.0, 162.1999999999999, -30.39999999999975, 20.000000000000014, 20.000000000000014, 32.599999999999994, 52.400000000000205, 168.5, -32.49999999999978, 164.0, 7.399999999999988, 9.499999999999964, 143.9, 158.59999999999974, 146.0, -32.4999999999999, -91.30000000000044, 20.000000000000014, 189.2, -28.29999999999977, -135.40000000000072, 196.4, -110.2000000000005, 137.0, 20.000000000000014, 167.0, 158.0, 20.000000000000014, 69.80000000000014, -17.799999999999812, 20.000000000000014, 20.000000000000014, 14.599999999999966, -169.00000000000043, 190.09999999999994, 194.0, -391.0, 138.79999999999998, -21.999999999999872, 200.0, 20.000000000000014, 180.2, -13.299999999999997, 95.0, -78.70000000000083, 13.699999999999966, 20.000000000000014, -133.30000000000007, -185.80000000000058, -55.60000000000004, -339.09999999999945, -357.99999999999966, 200.0, -185.79999999999995, 163.1, 200.0, 20.000000000000014, 11.599999999999975, 155.0, -116.49999999999989, 161.0, 142.39999999999998, 20.000000000000014, 20.000000000000014, 15.799999999999963, -122.80000000000075, 5.299999999999965, 164.0, 179.0, 164.9, 20.000000000000014, 200.0, 192.8, 164.0, 106.39999999999998, 20.000000000000014, -154.3000000000001, -223.6, 200.0, 20.000000000000014, -91.30000000000005, 200.0, -61.900000000000055, 164.0, -315.99999999999955, 20.000000000000014, 106.39999999999998, -198.40000000000003, -179.50000000000014, -195.10000000000022, 172.1, 23.30000000000008, -82.90000000000086, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 187.4, -114.39999999999986, 20.000000000000014, 52.70000000000014, -221.50000000000043, -70.30000000000089, -42.99999999999977, 15.799999999999963, -248.79999999999998, 198.2, -19.900000000000013, 12.500000000000192, -253.00000000000017, 154.1, -259.2999999999995, -261.4, 20.000000000000014, 144.19999999999965, 20.000000000000014, 188.3, 91.09999999999931, -3.099999999999958, 20.000000000000014, 119.89999999999998, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, -38.80000000000003, 164.0, 164.0, 20.000000000000014, 170.0, 11.599999999999964, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 17.899999999999977, -110.20000000000078, 20.000000000000014, 200.0, 20.000000000000014, -382.0, 187.4, 89.0, 20.000000000000014, 200.0, 155.0, 20.000000000000014, 188.3, 32.600000000000236, 55.09999999999996, 200.0, 20.000000000000014, 20.000000000000014, -196.0, 28.40000000000019, 191.0, -33.10000000000056, 20.000000000000014, 7.39999999999997, 23.600000000000076, 20.000000000000014, 20.000000000000014, 91.99999999999997, -166.90000000000046, 20.000000000000014, -101.80000000000072, -103.90000000000079, -33.69999999999982, 143.3, 200.0, 20.000000000000014, 20.000000000000014, 191.0, -240.40000000000038, 108.19999999999999, 5.299999999999986, 173.0, 39.80000000000025, 157.1, -190.00000000000057, 20.000000000000014, 17.899999999999988, -101.80000000000081, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 20.000000000000014], "policy_predator_policy_reward": [27.0, 5.0, 67.0, 33.0, 76.0, 12.0, 78.0, 0.0, 9.0, 0.0, 58.0, 107.0, 0.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 6.0, 14.0, 37.0, 10.0, 6.0, 0.0, 13.0, 3.0, 40.0, 47.0, 24.0, 23.0, 0.0, 55.0, 74.0, 62.0, 21.0, 11.0, 0.0, 14.0, 0.0, 30.0, 11.0, 0.0, 0.0, 127.0, 23.0, 0.0, 2.0, 197.0, 0.0, 20.0, 0.0, 0.0, 0.0, 93.0, 0.0, 0.0, 50.0, 17.0, 56.0, 102.0, 0.0, 187.0, 0.0, 0.0, 98.0, 0.0, 0.0, 4.0, 0.0, 32.0, 48.0, 13.0, 0.0, 0.0, 0.0, 36.0, 34.0, 12.0, 7.0, 0.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 83.0, 116.0, 0.0, 0.0, 52.0, 20.0, 5.0, 39.0, 102.0, 66.0, 0.0, 104.0, 0.0, 158.0, 0.0, 10.0, 0.0, 49.0, 0.0, 0.0, 0.0, 0.0, 54.0, 38.0, 20.0, 0.0, 124.0, 16.0, 27.0, 17.0, 21.0, 107.0, 22.0, 0.0, 0.0, 130.0, 156.0, 128.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 28.0, 0.0, 0.0, 4.0, 10.0, 0.0, 9.0, 0.0, 0.0, 63.0, 7.0, 0.0, 0.0, 12.0, 191.0, 37.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 132.0, 3.0, 48.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 50.0, 78.0, 71.0, 37.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 53.0, 71.0, 1.0, 9.0, 0.0, 2.0, 42.0, 58.0, 44.0, 39.0, 0.0, 0.0, 12.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3530144851980137, "mean_inference_ms": 9.064172142821311, "mean_action_processing_ms": 0.7525514840011246, "mean_env_wait_ms": 1.17940741242146, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007907748222351074, "StateBufferConnector_ms": 0.004600405693054199, "ViewRequirementAgentConnector_ms": 0.2194918394088745}, "num_episodes": 23, "episode_return_max": 386.10000000000025, "episode_return_min": -510.0999999999991, "episode_return_mean": 96.18099999999977, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000, "num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.288660274999079, "num_env_steps_trained_throughput_per_sec": 4.288660274999079, "timesteps_total": 548000, "num_env_steps_sampled_lifetime": 548000, "num_agent_steps_sampled_lifetime": 2192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2192000, "timers": {"training_iteration_time_ms": 400233.034, "restore_workers_time_ms": 0.02, "training_step_time_ms": 400232.969, "sample_time_ms": 2779.516, "learn_time_ms": 397415.462, "learn_throughput": 10.065, "synch_weights_time_ms": 30.105}, "counters": {"num_env_steps_sampled": 548000, "num_env_steps_trained": 548000, "num_agent_steps_sampled": 2192000, "num_agent_steps_trained": 2192000}, "done": false, "training_iteration": 137, "trial_id": "3a355_00000", "date": "2024-08-13_04-26-53", "timestamp": 1723537613, "time_this_iter_s": 933.2293560504913, "time_total_s": 11814.174416542053, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52f7ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11814.174416542053, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 87.11111111111111, "ram_util_percent": 85.4088888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0732165277910926, "cur_kl_coeff": 3.944304526105059e-32, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.187865784180858, "policy_loss": -0.0022916513817907167, "vf_loss": 2.19015743205787, "vf_explained_var": 0.00910796012197222, "kl": 0.0024447225273763395, "entropy": 0.3060266619636899, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 259875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 32.75138027559197, "cur_kl_coeff": 5.531419072779542e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.285641963015157, "policy_loss": -0.0009201237946630471, "vf_loss": 4.286562094360432, "vf_explained_var": 0.5888126574180744, "kl": 0.002484753140371252, "entropy": 0.7053699324055324, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 259875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000}, "env_runners": {"episode_reward_max": 386.10000000000025, "episode_reward_min": -510.0999999999991, "episode_reward_mean": 95.61999999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -391.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 21.094999999999946, "predator_policy": 26.715}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-4.399999999999936, 386.10000000000025, -55.19999999999994, 197.99999999999937, 200.19999999999936, 174.7, -14.999999999999565, -40.29999999999991, -139.39999999999964, -510.0999999999991, 112.19999999999982, 363.1, 35.60000000000022, 118.49999999999977, 316.40000000000003, 40.0000000000003, -36.99999999999955, 188.29999999999944, 350.9, 219.99999999999926, 368.8, 126.39999999999975, -178.90000000000012, 219.99999999999926, 180.69999999999956, 146.09999999999965, -128.0000000000008, 12.000000000000007, -216.60000000000042, 205.3999999999993, 166.09999999999954, 40.0000000000003, 40.0000000000003, 164.99999999999966, 92.6999999999999, -151.80000000000132, 16.799999999999926, 77.39999999999999, 14.599999999999667, 31.1, -236.70000000000002, 164.1999999999989, 208.29999999999933, 98.99999999999864, 139.89999999999964, 40.0000000000003, 201.99999999999937, 153.1999999999996, 183.99999999999943, 195.59999999999928, 201.99999999999935, 40.0000000000003, -22.299999999999564, 219.99999999999926, -159.00000000000054, 313.4, 219.99999999999926, 189.9999999999994, 220.8999999999992, 255.09999999999948, 40.0000000000003, -35.60000000000024, 208.89999999999986, 33.400000000000205, 43.600000000000364, 111.99999999999989, -18.899999999999693, -97.70000000000152, 138.59999999999965, 219.99999999999926, 210.9999999999993, -8.200000000000001, 188.29999999999941, 198.8999999999994, -70.00000000000121, -0.8999999999997998, 40.0000000000003, 26.80000000000009, 200.89999999999932, -162.89999999999995, 305.5, 31.999999999999837, 218.89999999999975, 5.900000000000068, 219.99999999999926, 277.5, 219.99999999999926, -77.0, 192.89999999999938, 174.19999999999948, 85.69999999999993, 27.400000000000077, 5.600000000000165, 211.3999999999993, 114.4999999999998, 291.1, -0.49999999999992073, 46.00000000000002, 127.89999999999878, 54.800000000000054], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [14.599999999999966, -169.00000000000043, 190.09999999999994, 194.0, -391.0, 138.79999999999998, -21.999999999999872, 200.0, 20.000000000000014, 180.2, -13.299999999999997, 95.0, -78.70000000000083, 13.699999999999966, 20.000000000000014, -133.30000000000007, -185.80000000000058, -55.60000000000004, -339.09999999999945, -357.99999999999966, 200.0, -185.79999999999995, 163.1, 200.0, 20.000000000000014, 11.599999999999975, 155.0, -116.49999999999989, 161.0, 142.39999999999998, 20.000000000000014, 20.000000000000014, 15.799999999999963, -122.80000000000075, 5.299999999999965, 164.0, 179.0, 164.9, 20.000000000000014, 200.0, 192.8, 164.0, 106.39999999999998, 20.000000000000014, -154.3000000000001, -223.6, 200.0, 20.000000000000014, -91.30000000000005, 200.0, -61.900000000000055, 164.0, -315.99999999999955, 20.000000000000014, 106.39999999999998, -198.40000000000003, -179.50000000000014, -195.10000000000022, 172.1, 23.30000000000008, -82.90000000000086, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 187.4, -114.39999999999986, 20.000000000000014, 52.70000000000014, -221.50000000000043, -70.30000000000089, -42.99999999999977, 15.799999999999963, -248.79999999999998, 198.2, -19.900000000000013, 12.500000000000192, -253.00000000000017, 154.1, -259.2999999999995, -261.4, 20.000000000000014, 144.19999999999965, 20.000000000000014, 188.3, 91.09999999999931, -3.099999999999958, 20.000000000000014, 119.89999999999998, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, -38.80000000000003, 164.0, 164.0, 20.000000000000014, 170.0, 11.599999999999964, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 17.899999999999977, -110.20000000000078, 20.000000000000014, 200.0, 20.000000000000014, -382.0, 187.4, 89.0, 20.000000000000014, 200.0, 155.0, 20.000000000000014, 188.3, 32.600000000000236, 55.09999999999996, 200.0, 20.000000000000014, 20.000000000000014, -196.0, 28.40000000000019, 191.0, -33.10000000000056, 20.000000000000014, 7.39999999999997, 23.600000000000076, 20.000000000000014, 20.000000000000014, 91.99999999999997, -166.90000000000046, 20.000000000000014, -101.80000000000072, -103.90000000000079, -33.69999999999982, 143.3, 200.0, 20.000000000000014, 20.000000000000014, 191.0, -240.40000000000038, 108.19999999999999, 5.299999999999986, 173.0, 39.80000000000025, 157.1, -190.00000000000057, 20.000000000000014, 17.899999999999988, -101.80000000000081, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 200.0, -45.09999999999983, -99.6999999999999, -215.20000000000002, 161.3, 144.2, -14.799999999999997, -47.199999999999804, 38.90000000000009, 152.0, 20.000000000000014, -45.09999999999979, 20.000000000000014, 200.0, 107.0, 132.5, 20.000000000000014, 200.0, -13.0, -316.0, 195.5, -55.60000000000032, 172.1, -19.899999999999743, -72.40000000000032, 109.09999999999998, 136.1, -225.7000000000003, -69.40000000000032, 20.000000000000014, 7.399999999999965, 197.0, -114.40000000000062, 164.9, 137.89999999999998, 153.2, 20.000000000000014, -107.50000000000068, 131.6, -181.60000000000028, 109.09999999999948, 12.79999999999996, 148.7, -217.9000000000003], "policy_predator_policy_reward": [127.0, 23.0, 0.0, 2.0, 197.0, 0.0, 20.0, 0.0, 0.0, 0.0, 93.0, 0.0, 0.0, 50.0, 17.0, 56.0, 102.0, 0.0, 187.0, 0.0, 0.0, 98.0, 0.0, 0.0, 4.0, 0.0, 32.0, 48.0, 13.0, 0.0, 0.0, 0.0, 36.0, 34.0, 12.0, 7.0, 0.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 83.0, 116.0, 0.0, 0.0, 52.0, 20.0, 5.0, 39.0, 102.0, 66.0, 0.0, 104.0, 0.0, 158.0, 0.0, 10.0, 0.0, 49.0, 0.0, 0.0, 0.0, 0.0, 54.0, 38.0, 20.0, 0.0, 124.0, 16.0, 27.0, 17.0, 21.0, 107.0, 22.0, 0.0, 0.0, 130.0, 156.0, 128.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 28.0, 0.0, 0.0, 4.0, 10.0, 0.0, 9.0, 0.0, 0.0, 63.0, 7.0, 0.0, 0.0, 12.0, 191.0, 37.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 132.0, 3.0, 48.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 50.0, 78.0, 71.0, 37.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 53.0, 71.0, 1.0, 9.0, 0.0, 2.0, 42.0, 58.0, 44.0, 39.0, 0.0, 0.0, 12.0, 0.0, 3.0, 43.0, 0.0, 152.0, 0.0, 0.0, 32.0, 62.0, 0.0, 28.0, 0.0, 31.0, 0.0, 0.0, 30.0, 8.0, 0.0, 0.0, 68.0, 184.0, 23.0, 30.0, 6.0, 16.0, 5.0, 44.0, 27.0, 90.0, 55.0, 0.0, 0.0, 7.0, 64.0, 0.0, 0.0, 0.0, 42.0, 45.0, 0.0, 96.0, 0.0, 6.0, 0.0, 124.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.399048075254771, "mean_inference_ms": 8.978179053722762, "mean_action_processing_ms": 0.7531811395646071, "mean_env_wait_ms": 1.1781021373243015, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013479948043823242, "StateBufferConnector_ms": 0.0045043230056762695, "ViewRequirementAgentConnector_ms": 0.3661353588104248}, "num_episodes": 22, "episode_return_max": 386.10000000000025, "episode_return_min": -510.0999999999991, "episode_return_mean": 95.61999999999976, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000, "num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 162.27973737659423, "num_env_steps_trained_throughput_per_sec": 162.27973737659423, "timesteps_total": 552000, "num_env_steps_sampled_lifetime": 552000, "num_agent_steps_sampled_lifetime": 2208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2208000, "timers": {"training_iteration_time_ms": 401043.188, "restore_workers_time_ms": 0.021, "training_step_time_ms": 401043.121, "sample_time_ms": 3593.087, "learn_time_ms": 397409.815, "learn_throughput": 10.065, "synch_weights_time_ms": 30.322}, "counters": {"num_env_steps_sampled": 552000, "num_env_steps_trained": 552000, "num_agent_steps_sampled": 2208000, "num_agent_steps_trained": 2208000}, "done": false, "training_iteration": 138, "trial_id": "3a355_00000", "date": "2024-08-13_04-27-18", "timestamp": 1723537638, "time_this_iter_s": 24.72526788711548, "time_total_s": 11838.899684429169, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52fdf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 11838.899684429169, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 87.05142857142857, "ram_util_percent": 83.7742857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9767007422904489, "cur_kl_coeff": 1.9721522630525296e-32, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.251514631225949, "policy_loss": -0.002867658933250125, "vf_loss": 2.254382294574112, "vf_explained_var": 0.0028519166209710336, "kl": 0.0026970966859128226, "entropy": 0.3100899113233758, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 261765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 56.13588173070912, "cur_kl_coeff": 2.765709536389771e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.835744422705716, "policy_loss": -0.001979144176754056, "vf_loss": 4.837723565353918, "vf_explained_var": 0.31335579399709346, "kl": 0.013810938638361539, "entropy": 0.9430647517638232, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 261765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000}, "env_runners": {"episode_reward_max": 368.8, "episode_reward_min": -236.70000000000002, "episode_reward_mean": 96.14799999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": 21.553999999999952, "predator_policy": 26.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [350.9, 219.99999999999926, 368.8, 126.39999999999975, -178.90000000000012, 219.99999999999926, 180.69999999999956, 146.09999999999965, -128.0000000000008, 12.000000000000007, -216.60000000000042, 205.3999999999993, 166.09999999999954, 40.0000000000003, 40.0000000000003, 164.99999999999966, 92.6999999999999, -151.80000000000132, 16.799999999999926, 77.39999999999999, 14.599999999999667, 31.1, -236.70000000000002, 164.1999999999989, 208.29999999999933, 98.99999999999864, 139.89999999999964, 40.0000000000003, 201.99999999999937, 153.1999999999996, 183.99999999999943, 195.59999999999928, 201.99999999999935, 40.0000000000003, -22.299999999999564, 219.99999999999926, -159.00000000000054, 313.4, 219.99999999999926, 189.9999999999994, 220.8999999999992, 255.09999999999948, 40.0000000000003, -35.60000000000024, 208.89999999999986, 33.400000000000205, 43.600000000000364, 111.99999999999989, -18.899999999999693, -97.70000000000152, 138.59999999999965, 219.99999999999926, 210.9999999999993, -8.200000000000001, 188.29999999999941, 198.8999999999994, -70.00000000000121, -0.8999999999997998, 40.0000000000003, 26.80000000000009, 200.89999999999932, -162.89999999999995, 305.5, 31.999999999999837, 218.89999999999975, 5.900000000000068, 219.99999999999926, 277.5, 219.99999999999926, -77.0, 192.89999999999938, 174.19999999999948, 85.69999999999993, 27.400000000000077, 5.600000000000165, 211.3999999999993, 114.4999999999998, 291.1, -0.49999999999992073, 46.00000000000002, 127.89999999999878, 54.800000000000054, -48.999999999999794, 41.8000000000004, -168.29999999999998, 118.1, 216.79999999999927, -35.89999999999966, 145.89999999999964, 132.5, 252.39999999999907, 16.899999999999935, 209.7999999999993, 39.90000000000021, 195.69999999999936, 171.19999999999965, -22.199999999999676, 40.0000000000003, 38.9000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [179.0, 164.9, 20.000000000000014, 200.0, 192.8, 164.0, 106.39999999999998, 20.000000000000014, -154.3000000000001, -223.6, 200.0, 20.000000000000014, -91.30000000000005, 200.0, -61.900000000000055, 164.0, -315.99999999999955, 20.000000000000014, 106.39999999999998, -198.40000000000003, -179.50000000000014, -195.10000000000022, 172.1, 23.30000000000008, -82.90000000000086, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 187.4, -114.39999999999986, 20.000000000000014, 52.70000000000014, -221.50000000000043, -70.30000000000089, -42.99999999999977, 15.799999999999963, -248.79999999999998, 198.2, -19.900000000000013, 12.500000000000192, -253.00000000000017, 154.1, -259.2999999999995, -261.4, 20.000000000000014, 144.19999999999965, 20.000000000000014, 188.3, 91.09999999999931, -3.099999999999958, 20.000000000000014, 119.89999999999998, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, -38.80000000000003, 164.0, 164.0, 20.000000000000014, 170.0, 11.599999999999964, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 17.899999999999977, -110.20000000000078, 20.000000000000014, 200.0, 20.000000000000014, -382.0, 187.4, 89.0, 20.000000000000014, 200.0, 155.0, 20.000000000000014, 188.3, 32.600000000000236, 55.09999999999996, 200.0, 20.000000000000014, 20.000000000000014, -196.0, 28.40000000000019, 191.0, -33.10000000000056, 20.000000000000014, 7.39999999999997, 23.600000000000076, 20.000000000000014, 20.000000000000014, 91.99999999999997, -166.90000000000046, 20.000000000000014, -101.80000000000072, -103.90000000000079, -33.69999999999982, 143.3, 200.0, 20.000000000000014, 20.000000000000014, 191.0, -240.40000000000038, 108.19999999999999, 5.299999999999986, 173.0, 39.80000000000025, 157.1, -190.00000000000057, 20.000000000000014, 17.899999999999988, -101.80000000000081, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 200.0, -45.09999999999983, -99.6999999999999, -215.20000000000002, 161.3, 144.2, -14.799999999999997, -47.199999999999804, 38.90000000000009, 152.0, 20.000000000000014, -45.09999999999979, 20.000000000000014, 200.0, 107.0, 132.5, 20.000000000000014, 200.0, -13.0, -316.0, 195.5, -55.60000000000032, 172.1, -19.899999999999743, -72.40000000000032, 109.09999999999998, 136.1, -225.7000000000003, -69.40000000000032, 20.000000000000014, 7.399999999999965, 197.0, -114.40000000000062, 164.9, 137.89999999999998, 153.2, 20.000000000000014, -107.50000000000068, 131.6, -181.60000000000028, 109.09999999999948, 12.79999999999996, 148.7, -217.9000000000003, -89.20000000000043, -38.79999999999991, -23.19999999999986, 20.000000000000014, -177.40000000000003, -103.89999999999986, -193.90000000000006, 176.0, 200.0, -17.199999999999818, -124.90000000000055, 20.000000000000014, 17.899999999999988, 92.0, 156.5, -400.0, 200.0, 52.40000000000023, 20.000000000000014, -24.09999999999978, -110.2000000000007, 200.0, 9.499999999999968, 25.400000000000006, 175.7, 20.000000000000014, 51.5000000000001, 82.69999999999973, -40.89999999999983, -28.299999999999855, 20.000000000000014, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 83.0, 116.0, 0.0, 0.0, 52.0, 20.0, 5.0, 39.0, 102.0, 66.0, 0.0, 104.0, 0.0, 158.0, 0.0, 10.0, 0.0, 49.0, 0.0, 0.0, 0.0, 0.0, 54.0, 38.0, 20.0, 0.0, 124.0, 16.0, 27.0, 17.0, 21.0, 107.0, 22.0, 0.0, 0.0, 130.0, 156.0, 128.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 28.0, 0.0, 0.0, 4.0, 10.0, 0.0, 9.0, 0.0, 0.0, 63.0, 7.0, 0.0, 0.0, 12.0, 191.0, 37.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 132.0, 3.0, 48.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 50.0, 78.0, 71.0, 37.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 53.0, 71.0, 1.0, 9.0, 0.0, 2.0, 42.0, 58.0, 44.0, 39.0, 0.0, 0.0, 12.0, 0.0, 3.0, 43.0, 0.0, 152.0, 0.0, 0.0, 32.0, 62.0, 0.0, 28.0, 0.0, 31.0, 0.0, 0.0, 30.0, 8.0, 0.0, 0.0, 68.0, 184.0, 23.0, 30.0, 6.0, 16.0, 5.0, 44.0, 27.0, 90.0, 55.0, 0.0, 0.0, 7.0, 64.0, 0.0, 0.0, 0.0, 42.0, 45.0, 0.0, 96.0, 0.0, 6.0, 0.0, 124.0, 13.0, 66.0, 0.0, 45.0, 94.0, 19.0, 128.0, 8.0, 10.0, 24.0, 55.0, 14.0, 36.0, 0.0, 189.0, 187.0, 0.0, 0.0, 21.0, 0.0, 62.0, 58.0, 0.0, 5.0, 0.0, 0.0, 25.0, 12.0, 39.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3467553872522746, "mean_inference_ms": 9.015957812136252, "mean_action_processing_ms": 0.752894071613935, "mean_env_wait_ms": 1.1727110052987826, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022878408432006836, "StateBufferConnector_ms": 0.004741311073303223, "ViewRequirementAgentConnector_ms": 0.3629486560821533}, "num_episodes": 18, "episode_return_max": 368.8, "episode_return_min": -236.70000000000002, "episode_return_mean": 96.14799999999973, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000, "num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.169945086469748, "num_env_steps_trained_throughput_per_sec": 4.169945086469748, "timesteps_total": 556000, "num_env_steps_sampled_lifetime": 556000, "num_agent_steps_sampled_lifetime": 2224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2224000, "timers": {"training_iteration_time_ms": 398539.952, "restore_workers_time_ms": 0.02, "training_step_time_ms": 398539.887, "sample_time_ms": 3936.593, "learn_time_ms": 394561.835, "learn_throughput": 10.138, "synch_weights_time_ms": 30.859}, "counters": {"num_env_steps_sampled": 556000, "num_env_steps_trained": 556000, "num_agent_steps_sampled": 2224000, "num_agent_steps_trained": 2224000}, "done": false, "training_iteration": 139, "trial_id": "3a355_00000", "date": "2024-08-13_04-43-18", "timestamp": 1723538598, "time_this_iter_s": 959.3598248958588, "time_total_s": 12798.259509325027, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5f9b0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12798.259509325027, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 87.4625, "ram_util_percent": 83.475}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0976320529465007, "cur_kl_coeff": 9.860761315262648e-33, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6894475230779598, "policy_loss": -0.0031646714198388277, "vf_loss": 1.6926121974748278, "vf_explained_var": 0.010057794448559877, "kl": 0.002755754624784769, "entropy": 0.28285548015246315, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 263655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 47.45701140304091, "cur_kl_coeff": 2.765709536389771e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.377491139861011, "policy_loss": -0.003302700188079918, "vf_loss": 5.38079385530381, "vf_explained_var": 0.4530564826947671, "kl": 0.004191615948772464, "entropy": 0.8706019211383093, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 263655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000}, "env_runners": {"episode_reward_max": 324.2, "episode_reward_min": -260.29999999999995, "episode_reward_mean": 100.32699999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 191.0}, "policy_reward_mean": {"prey_policy": 25.30849999999994, "predator_policy": 24.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.799999999999926, 77.39999999999999, 14.599999999999667, 31.1, -236.70000000000002, 164.1999999999989, 208.29999999999933, 98.99999999999864, 139.89999999999964, 40.0000000000003, 201.99999999999937, 153.1999999999996, 183.99999999999943, 195.59999999999928, 201.99999999999935, 40.0000000000003, -22.299999999999564, 219.99999999999926, -159.00000000000054, 313.4, 219.99999999999926, 189.9999999999994, 220.8999999999992, 255.09999999999948, 40.0000000000003, -35.60000000000024, 208.89999999999986, 33.400000000000205, 43.600000000000364, 111.99999999999989, -18.899999999999693, -97.70000000000152, 138.59999999999965, 219.99999999999926, 210.9999999999993, -8.200000000000001, 188.29999999999941, 198.8999999999994, -70.00000000000121, -0.8999999999997998, 40.0000000000003, 26.80000000000009, 200.89999999999932, -162.89999999999995, 305.5, 31.999999999999837, 218.89999999999975, 5.900000000000068, 219.99999999999926, 277.5, 219.99999999999926, -77.0, 192.89999999999938, 174.19999999999948, 85.69999999999993, 27.400000000000077, 5.600000000000165, 211.3999999999993, 114.4999999999998, 291.1, -0.49999999999992073, 46.00000000000002, 127.89999999999878, 54.800000000000054, -48.999999999999794, 41.8000000000004, -168.29999999999998, 118.1, 216.79999999999927, -35.89999999999966, 145.89999999999964, 132.5, 252.39999999999907, 16.899999999999935, 209.7999999999993, 39.90000000000021, 195.69999999999936, 171.19999999999965, -22.199999999999676, 40.0000000000003, 38.9000000000003, 40.0000000000003, 57.10000000000022, 315.70000000000005, 217.29999999999924, 324.2, -17.000000000000057, 101.19999999999851, 65.9000000000001, 323.3000000000013, 193.8999999999991, 212.49999999999957, 111.09999999999988, 162.19999999999865, 187.9999999999994, -108.20000000000104, 207.99999999999932, 32.30000000000018, -50.50000000000069, -260.29999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-42.99999999999977, 15.799999999999963, -248.79999999999998, 198.2, -19.900000000000013, 12.500000000000192, -253.00000000000017, 154.1, -259.2999999999995, -261.4, 20.000000000000014, 144.19999999999965, 20.000000000000014, 188.3, 91.09999999999931, -3.099999999999958, 20.000000000000014, 119.89999999999998, 20.000000000000014, 20.000000000000014, 173.0, 20.000000000000014, -38.80000000000003, 164.0, 164.0, 20.000000000000014, 170.0, 11.599999999999964, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 17.899999999999977, -110.20000000000078, 20.000000000000014, 200.0, 20.000000000000014, -382.0, 187.4, 89.0, 20.000000000000014, 200.0, 155.0, 20.000000000000014, 188.3, 32.600000000000236, 55.09999999999996, 200.0, 20.000000000000014, 20.000000000000014, -196.0, 28.40000000000019, 191.0, -33.10000000000056, 20.000000000000014, 7.39999999999997, 23.600000000000076, 20.000000000000014, 20.000000000000014, 91.99999999999997, -166.90000000000046, 20.000000000000014, -101.80000000000072, -103.90000000000079, -33.69999999999982, 143.3, 200.0, 20.000000000000014, 20.000000000000014, 191.0, -240.40000000000038, 108.19999999999999, 5.299999999999986, 173.0, 39.80000000000025, 157.1, -190.00000000000057, 20.000000000000014, 17.899999999999988, -101.80000000000081, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 200.0, -45.09999999999983, -99.6999999999999, -215.20000000000002, 161.3, 144.2, -14.799999999999997, -47.199999999999804, 38.90000000000009, 152.0, 20.000000000000014, -45.09999999999979, 20.000000000000014, 200.0, 107.0, 132.5, 20.000000000000014, 200.0, -13.0, -316.0, 195.5, -55.60000000000032, 172.1, -19.899999999999743, -72.40000000000032, 109.09999999999998, 136.1, -225.7000000000003, -69.40000000000032, 20.000000000000014, 7.399999999999965, 197.0, -114.40000000000062, 164.9, 137.89999999999998, 153.2, 20.000000000000014, -107.50000000000068, 131.6, -181.60000000000028, 109.09999999999948, 12.79999999999996, 148.7, -217.9000000000003, -89.20000000000043, -38.79999999999991, -23.19999999999986, 20.000000000000014, -177.40000000000003, -103.89999999999986, -193.90000000000006, 176.0, 200.0, -17.199999999999818, -124.90000000000055, 20.000000000000014, 17.899999999999988, 92.0, 156.5, -400.0, 200.0, 52.40000000000023, 20.000000000000014, -24.09999999999978, -110.2000000000007, 200.0, 9.499999999999968, 25.400000000000006, 175.7, 20.000000000000014, 51.5000000000001, 82.69999999999973, -40.89999999999983, -28.299999999999855, 20.000000000000014, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, -151.60000000000053, 109.69999999999962, 85.70000000000005, 200.0, 135.2, 82.09999999999926, 132.2, 164.0, 78.49999999999997, -200.5, 20.000000000000014, 81.19999999999925, 20.000000000000014, -48.09999999999989, 128.59999999999957, 193.7, 20.000000000000014, 173.89999999999984, 100.40000000000005, 79.09999999999954, 91.09999999999997, 20.000000000000014, 60.50000000000022, 91.69999999999952, 140.0, 20.000000000000014, -86.19999999999986, -90.99999999999984, 182.0, 20.000000000000014, 20.000000000000014, 5.299999999999965, -74.50000000000085, -64.00000000000078, -121.90000000000006, -282.4], "policy_predator_policy_reward": [27.0, 17.0, 21.0, 107.0, 22.0, 0.0, 0.0, 130.0, 156.0, 128.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 28.0, 0.0, 0.0, 4.0, 10.0, 0.0, 9.0, 0.0, 0.0, 63.0, 7.0, 0.0, 0.0, 12.0, 191.0, 37.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 132.0, 3.0, 48.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 50.0, 78.0, 71.0, 37.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 53.0, 71.0, 1.0, 9.0, 0.0, 2.0, 42.0, 58.0, 44.0, 39.0, 0.0, 0.0, 12.0, 0.0, 3.0, 43.0, 0.0, 152.0, 0.0, 0.0, 32.0, 62.0, 0.0, 28.0, 0.0, 31.0, 0.0, 0.0, 30.0, 8.0, 0.0, 0.0, 68.0, 184.0, 23.0, 30.0, 6.0, 16.0, 5.0, 44.0, 27.0, 90.0, 55.0, 0.0, 0.0, 7.0, 64.0, 0.0, 0.0, 0.0, 42.0, 45.0, 0.0, 96.0, 0.0, 6.0, 0.0, 124.0, 13.0, 66.0, 0.0, 45.0, 94.0, 19.0, 128.0, 8.0, 10.0, 24.0, 55.0, 14.0, 36.0, 0.0, 189.0, 187.0, 0.0, 0.0, 21.0, 0.0, 62.0, 58.0, 0.0, 5.0, 0.0, 0.0, 25.0, 12.0, 39.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 84.0, 15.0, 30.0, 0.0, 0.0, 0.0, 0.0, 28.0, 10.0, 95.0, 0.0, 0.0, 35.0, 59.0, 0.0, 1.0, 0.0, 0.0, 5.0, 28.0, 0.0, 0.0, 10.0, 0.0, 10.0, 18.0, 69.0, 0.0, 6.0, 0.0, 0.0, 7.0, 34.0, 54.0, 0.0, 144.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3493927786820614, "mean_inference_ms": 9.007566299100365, "mean_action_processing_ms": 0.7546662331942875, "mean_env_wait_ms": 1.1712261974678695, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02965855598449707, "StateBufferConnector_ms": 0.0049953460693359375, "ViewRequirementAgentConnector_ms": 0.5199823379516602}, "num_episodes": 18, "episode_return_max": 324.2, "episode_return_min": -260.29999999999995, "episode_return_mean": 100.32699999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000, "num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 147.71625310155454, "num_env_steps_trained_throughput_per_sec": 147.71625310155454, "timesteps_total": 560000, "num_env_steps_sampled_lifetime": 560000, "num_agent_steps_sampled_lifetime": 2240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2240000, "timers": {"training_iteration_time_ms": 399503.85, "restore_workers_time_ms": 0.021, "training_step_time_ms": 399503.783, "sample_time_ms": 4682.364, "learn_time_ms": 394779.395, "learn_throughput": 10.132, "synch_weights_time_ms": 31.231}, "counters": {"num_env_steps_sampled": 560000, "num_env_steps_trained": 560000, "num_agent_steps_sampled": 2240000, "num_agent_steps_trained": 2240000}, "done": false, "training_iteration": 140, "trial_id": "3a355_00000", "date": "2024-08-13_04-43-45", "timestamp": 1723538625, "time_this_iter_s": 27.190722942352295, "time_total_s": 12825.45023226738, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fdd8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12825.45023226738, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 92.82894736842104, "ram_util_percent": 83.79473684210527}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7503298139721943, "cur_kl_coeff": 4.930380657631324e-33, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.946092671187466, "policy_loss": -0.0006921366548224811, "vf_loss": 2.946784805999231, "vf_explained_var": 0.00896022430172673, "kl": 0.0031096697579774206, "entropy": 0.304219705339462, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 265545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 45.292157853595796, "cur_kl_coeff": 1.3828547681948854e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.520489408351757, "policy_loss": -0.0014196306030960784, "vf_loss": 6.521909030530819, "vf_explained_var": 0.3168080323272281, "kl": 0.002941313752729515, "entropy": 0.9729078050012941, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 265545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000}, "env_runners": {"episode_reward_max": 324.2, "episode_reward_min": -311.7000000000006, "episode_reward_mean": 91.14999999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -744.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 839.0}, "policy_reward_mean": {"prey_policy": 16.76999999999992, "predator_policy": 28.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [255.09999999999948, 40.0000000000003, -35.60000000000024, 208.89999999999986, 33.400000000000205, 43.600000000000364, 111.99999999999989, -18.899999999999693, -97.70000000000152, 138.59999999999965, 219.99999999999926, 210.9999999999993, -8.200000000000001, 188.29999999999941, 198.8999999999994, -70.00000000000121, -0.8999999999997998, 40.0000000000003, 26.80000000000009, 200.89999999999932, -162.89999999999995, 305.5, 31.999999999999837, 218.89999999999975, 5.900000000000068, 219.99999999999926, 277.5, 219.99999999999926, -77.0, 192.89999999999938, 174.19999999999948, 85.69999999999993, 27.400000000000077, 5.600000000000165, 211.3999999999993, 114.4999999999998, 291.1, -0.49999999999992073, 46.00000000000002, 127.89999999999878, 54.800000000000054, -48.999999999999794, 41.8000000000004, -168.29999999999998, 118.1, 216.79999999999927, -35.89999999999966, 145.89999999999964, 132.5, 252.39999999999907, 16.899999999999935, 209.7999999999993, 39.90000000000021, 195.69999999999936, 171.19999999999965, -22.199999999999676, 40.0000000000003, 38.9000000000003, 40.0000000000003, 57.10000000000022, 315.70000000000005, 217.29999999999924, 324.2, -17.000000000000057, 101.19999999999851, 65.9000000000001, 323.3000000000013, 193.8999999999991, 212.49999999999957, 111.09999999999988, 162.19999999999865, 187.9999999999994, -108.20000000000104, 207.99999999999932, 32.30000000000018, -50.50000000000069, -260.29999999999995, 5.899999999999942, 276.5999999999998, 33.200000000000195, 199.29999999999907, 49.900000000000404, 142.4999999999997, 288.7000000000005, 250.60000000000002, -72.5000000000012, 213.69999999999965, 79.39999999999938, 113.89999999999948, 320.1000000000013, 26.499999999999517, 129.89999999999944, 40.0000000000003, -151.30000000000064, 41.90000000000035, -248.2, 92.69999999999871, 81.19999999999914, -5.599999999999882, -311.7000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [55.09999999999996, 200.0, 20.000000000000014, 20.000000000000014, -196.0, 28.40000000000019, 191.0, -33.10000000000056, 20.000000000000014, 7.39999999999997, 23.600000000000076, 20.000000000000014, 20.000000000000014, 91.99999999999997, -166.90000000000046, 20.000000000000014, -101.80000000000072, -103.90000000000079, -33.69999999999982, 143.3, 200.0, 20.000000000000014, 20.000000000000014, 191.0, -240.40000000000038, 108.19999999999999, 5.299999999999986, 173.0, 39.80000000000025, 157.1, -190.00000000000057, 20.000000000000014, 17.899999999999988, -101.80000000000081, 20.000000000000014, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 200.0, -45.09999999999983, -99.6999999999999, -215.20000000000002, 161.3, 144.2, -14.799999999999997, -47.199999999999804, 38.90000000000009, 152.0, 20.000000000000014, -45.09999999999979, 20.000000000000014, 200.0, 107.0, 132.5, 20.000000000000014, 200.0, -13.0, -316.0, 195.5, -55.60000000000032, 172.1, -19.899999999999743, -72.40000000000032, 109.09999999999998, 136.1, -225.7000000000003, -69.40000000000032, 20.000000000000014, 7.399999999999965, 197.0, -114.40000000000062, 164.9, 137.89999999999998, 153.2, 20.000000000000014, -107.50000000000068, 131.6, -181.60000000000028, 109.09999999999948, 12.79999999999996, 148.7, -217.9000000000003, -89.20000000000043, -38.79999999999991, -23.19999999999986, 20.000000000000014, -177.40000000000003, -103.89999999999986, -193.90000000000006, 176.0, 200.0, -17.199999999999818, -124.90000000000055, 20.000000000000014, 17.899999999999988, 92.0, 156.5, -400.0, 200.0, 52.40000000000023, 20.000000000000014, -24.09999999999978, -110.2000000000007, 200.0, 9.499999999999968, 25.400000000000006, 175.7, 20.000000000000014, 51.5000000000001, 82.69999999999973, -40.89999999999983, -28.299999999999855, 20.000000000000014, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, -151.60000000000053, 109.69999999999962, 85.70000000000005, 200.0, 135.2, 82.09999999999926, 132.2, 164.0, 78.49999999999997, -200.5, 20.000000000000014, 81.19999999999925, 20.000000000000014, -48.09999999999989, 128.59999999999957, 193.7, 20.000000000000014, 173.89999999999984, 100.40000000000005, 79.09999999999954, 91.09999999999997, 20.000000000000014, 60.50000000000022, 91.69999999999952, 140.0, 20.000000000000014, -86.19999999999986, -90.99999999999984, 182.0, 20.000000000000014, 20.000000000000014, 5.299999999999965, -74.50000000000085, -64.00000000000078, -121.90000000000006, -282.4, -45.09999999999981, 20.000000000000014, 71.59999999999964, 200.0, 14.599999999999964, 11.599999999999964, 25.400000000000098, 173.89999999999984, 20.000000000000014, 29.900000000000194, 20.000000000000014, 90.5, 83.6, 151.09999999999988, 131.6, 74.0, -200.50000000000054, 20.000000000000014, 48.19999999999979, 120.50000000000006, 20.000000000000014, 58.40000000000022, 157.69999999999982, -101.80000000000024, 113.89999999999961, 198.2, -26.20000000000004, -73.2999999999999, 164.89999999999984, -85.00000000000082, 20.000000000000014, 20.000000000000014, -225.70000000000024, -55.59999999999991, 17.9, 4.99999999999997, -744.0, -343.1999999999998, 20.000000000000014, 61.700000000000166, 19.700000000000028, 33.50000000000024, -74.50000000000061, 17.899999999999988, -219.40000000000035, -238.30000000000027], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 132.0, 3.0, 48.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 50.0, 78.0, 71.0, 37.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 53.0, 71.0, 1.0, 9.0, 0.0, 2.0, 42.0, 58.0, 44.0, 39.0, 0.0, 0.0, 12.0, 0.0, 3.0, 43.0, 0.0, 152.0, 0.0, 0.0, 32.0, 62.0, 0.0, 28.0, 0.0, 31.0, 0.0, 0.0, 30.0, 8.0, 0.0, 0.0, 68.0, 184.0, 23.0, 30.0, 6.0, 16.0, 5.0, 44.0, 27.0, 90.0, 55.0, 0.0, 0.0, 7.0, 64.0, 0.0, 0.0, 0.0, 42.0, 45.0, 0.0, 96.0, 0.0, 6.0, 0.0, 124.0, 13.0, 66.0, 0.0, 45.0, 94.0, 19.0, 128.0, 8.0, 10.0, 24.0, 55.0, 14.0, 36.0, 0.0, 189.0, 187.0, 0.0, 0.0, 21.0, 0.0, 62.0, 58.0, 0.0, 5.0, 0.0, 0.0, 25.0, 12.0, 39.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 84.0, 15.0, 30.0, 0.0, 0.0, 0.0, 0.0, 28.0, 10.0, 95.0, 0.0, 0.0, 35.0, 59.0, 0.0, 1.0, 0.0, 0.0, 5.0, 28.0, 0.0, 0.0, 10.0, 0.0, 10.0, 18.0, 69.0, 0.0, 6.0, 0.0, 0.0, 7.0, 34.0, 54.0, 0.0, 144.0, 31.0, 0.0, 5.0, 0.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 30.0, 24.0, 33.0, 12.0, 23.0, 85.0, 23.0, 22.0, 1.0, 0.0, 0.0, 58.0, 0.0, 8.0, 55.0, 71.0, 48.0, 2.0, 0.0, 0.0, 0.0, 130.0, 10.0, 9.0, 839.0, 0.0, 0.0, 11.0, 0.0, 28.0, 6.0, 45.0, 83.0, 63.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.353390166444802, "mean_inference_ms": 8.945462346995212, "mean_action_processing_ms": 0.7576306438851, "mean_env_wait_ms": 1.2154060996577485, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02768874168395996, "StateBufferConnector_ms": 0.005024433135986328, "ViewRequirementAgentConnector_ms": 0.5598944425582886}, "num_episodes": 23, "episode_return_max": 324.2, "episode_return_min": -311.7000000000006, "episode_return_mean": 91.14999999999976, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000, "num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 231.19704702181744, "num_env_steps_trained_throughput_per_sec": 231.19704702181744, "timesteps_total": 564000, "num_env_steps_sampled_lifetime": 564000, "num_agent_steps_sampled_lifetime": 2256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2256000, "timers": {"training_iteration_time_ms": 299423.417, "restore_workers_time_ms": 0.021, "training_step_time_ms": 299423.345, "sample_time_ms": 4833.763, "learn_time_ms": 294549.3, "learn_throughput": 13.58, "synch_weights_time_ms": 29.733}, "counters": {"num_env_steps_sampled": 564000, "num_env_steps_trained": 564000, "num_agent_steps_sampled": 2256000, "num_agent_steps_trained": 2256000}, "done": false, "training_iteration": 141, "trial_id": "3a355_00000", "date": "2024-08-13_04-44-03", "timestamp": 1723538643, "time_this_iter_s": 17.35716199874878, "time_total_s": 12842.807394266129, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52fdf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12842.807394266129, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 80.204, "ram_util_percent": 83.764}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9779588332882634, "cur_kl_coeff": 2.465190328815662e-33, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9144375297758316, "policy_loss": -0.0028972246400795127, "vf_loss": 3.917334759424603, "vf_explained_var": 0.023094605611114906, "kl": 0.00324056235926056, "entropy": 0.26363725033859725, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 267435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 32.41784778846004, "cur_kl_coeff": 6.914273840974427e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.4431214396915735, "policy_loss": -0.0021410943114903397, "vf_loss": 5.445262543738834, "vf_explained_var": 0.5448078574957671, "kl": 0.0032399819934989054, "entropy": 0.8792147458545745, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 267435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000}, "env_runners": {"episode_reward_max": 346.0, "episode_reward_min": -311.7000000000006, "episode_reward_mean": 89.43299999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -744.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 839.0}, "policy_reward_mean": {"prey_policy": 13.456499999999933, "predator_policy": 31.26}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.80000000000009, 200.89999999999932, -162.89999999999995, 305.5, 31.999999999999837, 218.89999999999975, 5.900000000000068, 219.99999999999926, 277.5, 219.99999999999926, -77.0, 192.89999999999938, 174.19999999999948, 85.69999999999993, 27.400000000000077, 5.600000000000165, 211.3999999999993, 114.4999999999998, 291.1, -0.49999999999992073, 46.00000000000002, 127.89999999999878, 54.800000000000054, -48.999999999999794, 41.8000000000004, -168.29999999999998, 118.1, 216.79999999999927, -35.89999999999966, 145.89999999999964, 132.5, 252.39999999999907, 16.899999999999935, 209.7999999999993, 39.90000000000021, 195.69999999999936, 171.19999999999965, -22.199999999999676, 40.0000000000003, 38.9000000000003, 40.0000000000003, 57.10000000000022, 315.70000000000005, 217.29999999999924, 324.2, -17.000000000000057, 101.19999999999851, 65.9000000000001, 323.3000000000013, 193.8999999999991, 212.49999999999957, 111.09999999999988, 162.19999999999865, 187.9999999999994, -108.20000000000104, 207.99999999999932, 32.30000000000018, -50.50000000000069, -260.29999999999995, 5.899999999999942, 276.5999999999998, 33.200000000000195, 199.29999999999907, 49.900000000000404, 142.4999999999997, 288.7000000000005, 250.60000000000002, -72.5000000000012, 213.69999999999965, 79.39999999999938, 113.89999999999948, 320.1000000000013, 26.499999999999517, 129.89999999999944, 40.0000000000003, -151.30000000000064, 41.90000000000035, -248.2, 92.69999999999871, 81.19999999999914, -5.599999999999882, -311.7000000000006, -300.6, -11.699999999999733, 123.7999999999987, 66.30000000000007, -22.69999999999986, 156.49999999999963, 101.8999999999999, -183.39999999999972, 346.0, 112.6999999999998, 112.29999999999976, 40.0000000000003, 127.3999999999997, 144.3999999999996, 211.1999999999993, 213.9999999999993, 199.29999999999913, -150.6000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.1999999999999265, 20.000000000000014, 200.0, -45.09999999999983, -99.6999999999999, -215.20000000000002, 161.3, 144.2, -14.799999999999997, -47.199999999999804, 38.90000000000009, 152.0, 20.000000000000014, -45.09999999999979, 20.000000000000014, 200.0, 107.0, 132.5, 20.000000000000014, 200.0, -13.0, -316.0, 195.5, -55.60000000000032, 172.1, -19.899999999999743, -72.40000000000032, 109.09999999999998, 136.1, -225.7000000000003, -69.40000000000032, 20.000000000000014, 7.399999999999965, 197.0, -114.40000000000062, 164.9, 137.89999999999998, 153.2, 20.000000000000014, -107.50000000000068, 131.6, -181.60000000000028, 109.09999999999948, 12.79999999999996, 148.7, -217.9000000000003, -89.20000000000043, -38.79999999999991, -23.19999999999986, 20.000000000000014, -177.40000000000003, -103.89999999999986, -193.90000000000006, 176.0, 200.0, -17.199999999999818, -124.90000000000055, 20.000000000000014, 17.899999999999988, 92.0, 156.5, -400.0, 200.0, 52.40000000000023, 20.000000000000014, -24.09999999999978, -110.2000000000007, 200.0, 9.499999999999968, 25.400000000000006, 175.7, 20.000000000000014, 51.5000000000001, 82.69999999999973, -40.89999999999983, -28.299999999999855, 20.000000000000014, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, -151.60000000000053, 109.69999999999962, 85.70000000000005, 200.0, 135.2, 82.09999999999926, 132.2, 164.0, 78.49999999999997, -200.5, 20.000000000000014, 81.19999999999925, 20.000000000000014, -48.09999999999989, 128.59999999999957, 193.7, 20.000000000000014, 173.89999999999984, 100.40000000000005, 79.09999999999954, 91.09999999999997, 20.000000000000014, 60.50000000000022, 91.69999999999952, 140.0, 20.000000000000014, -86.19999999999986, -90.99999999999984, 182.0, 20.000000000000014, 20.000000000000014, 5.299999999999965, -74.50000000000085, -64.00000000000078, -121.90000000000006, -282.4, -45.09999999999981, 20.000000000000014, 71.59999999999964, 200.0, 14.599999999999964, 11.599999999999964, 25.400000000000098, 173.89999999999984, 20.000000000000014, 29.900000000000194, 20.000000000000014, 90.5, 83.6, 151.09999999999988, 131.6, 74.0, -200.50000000000054, 20.000000000000014, 48.19999999999979, 120.50000000000006, 20.000000000000014, 58.40000000000022, 157.69999999999982, -101.80000000000024, 113.89999999999961, 198.2, -26.20000000000004, -73.2999999999999, 164.89999999999984, -85.00000000000082, 20.000000000000014, 20.000000000000014, -225.70000000000024, -55.59999999999991, 17.9, 4.99999999999997, -744.0, -343.1999999999998, 20.000000000000014, 61.700000000000166, 19.700000000000028, 33.50000000000024, -74.50000000000061, 17.899999999999988, -219.40000000000035, -238.30000000000027, -229.89999999999998, -225.70000000000002, 20.000000000000014, -78.70000000000064, 20.000000000000014, 99.79999999999944, -217.3000000000001, 158.6, -99.70000000000003, 20.000000000000014, 161.0, -74.50000000000026, -72.70000000000081, 113.59999999999998, -242.50000000000043, -145.89999999999986, 155.0, 164.0, -171.09999999999994, 192.8, -175.29999999999987, 194.59999999999997, 20.000000000000014, 20.000000000000014, -184.59999999999994, 200.0, 124.39999999999998, 20.000000000000014, 200.0, 3.1999999999999633, 191.0, 20.000000000000014, 179.29999999999987, 20.000000000000014, -360.1, 3.4999999999999716], "policy_predator_policy_reward": [12.0, 0.0, 3.0, 43.0, 0.0, 152.0, 0.0, 0.0, 32.0, 62.0, 0.0, 28.0, 0.0, 31.0, 0.0, 0.0, 30.0, 8.0, 0.0, 0.0, 68.0, 184.0, 23.0, 30.0, 6.0, 16.0, 5.0, 44.0, 27.0, 90.0, 55.0, 0.0, 0.0, 7.0, 64.0, 0.0, 0.0, 0.0, 42.0, 45.0, 0.0, 96.0, 0.0, 6.0, 0.0, 124.0, 13.0, 66.0, 0.0, 45.0, 94.0, 19.0, 128.0, 8.0, 10.0, 24.0, 55.0, 14.0, 36.0, 0.0, 189.0, 187.0, 0.0, 0.0, 21.0, 0.0, 62.0, 58.0, 0.0, 5.0, 0.0, 0.0, 25.0, 12.0, 39.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 84.0, 15.0, 30.0, 0.0, 0.0, 0.0, 0.0, 28.0, 10.0, 95.0, 0.0, 0.0, 35.0, 59.0, 0.0, 1.0, 0.0, 0.0, 5.0, 28.0, 0.0, 0.0, 10.0, 0.0, 10.0, 18.0, 69.0, 0.0, 6.0, 0.0, 0.0, 7.0, 34.0, 54.0, 0.0, 144.0, 31.0, 0.0, 5.0, 0.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 30.0, 24.0, 33.0, 12.0, 23.0, 85.0, 23.0, 22.0, 1.0, 0.0, 0.0, 58.0, 0.0, 8.0, 55.0, 71.0, 48.0, 2.0, 0.0, 0.0, 0.0, 130.0, 10.0, 9.0, 839.0, 0.0, 0.0, 11.0, 0.0, 28.0, 6.0, 45.0, 83.0, 63.0, 119.0, 36.0, 2.0, 45.0, 4.0, 0.0, 12.0, 113.0, 0.0, 57.0, 42.0, 28.0, 44.0, 17.0, 108.0, 97.0, 12.0, 15.0, 11.0, 80.0, 27.0, 66.0, 0.0, 0.0, 108.0, 4.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 0.0, 25.0, 181.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.355685336984205, "mean_inference_ms": 8.988244858599996, "mean_action_processing_ms": 0.7585346001414159, "mean_env_wait_ms": 1.1672389632499292, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027308106422424316, "StateBufferConnector_ms": 0.005576133728027344, "ViewRequirementAgentConnector_ms": 0.5272303819656372}, "num_episodes": 18, "episode_return_max": 346.0, "episode_return_min": -311.7000000000006, "episode_return_mean": 89.43299999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000, "num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 253.40826097878252, "num_env_steps_trained_throughput_per_sec": 253.40826097878252, "timesteps_total": 568000, "num_env_steps_sampled_lifetime": 568000, "num_agent_steps_sampled_lifetime": 2272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2272000, "timers": {"training_iteration_time_ms": 298533.023, "restore_workers_time_ms": 0.021, "training_step_time_ms": 298532.94, "sample_time_ms": 4550.7, "learn_time_ms": 293943.302, "learn_throughput": 13.608, "synch_weights_time_ms": 29.031}, "counters": {"num_env_steps_sampled": 568000, "num_env_steps_trained": 568000, "num_agent_steps_sampled": 2272000, "num_agent_steps_trained": 2272000}, "done": false, "training_iteration": 142, "trial_id": "3a355_00000", "date": "2024-08-13_04-44-18", "timestamp": 1723538658, "time_this_iter_s": 15.824213981628418, "time_total_s": 12858.631608247757, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5f9b310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12858.631608247757, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 78.34090909090908, "ram_util_percent": 83.09545454545454}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9521061674982467, "cur_kl_coeff": 1.232595164407831e-33, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.897069624429027, "policy_loss": -0.0014229694893830038, "vf_loss": 2.8984925994797357, "vf_explained_var": 0.009155345278442221, "kl": 0.0021128852458906387, "entropy": 0.1913769669278904, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 269325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 37.20860343711086, "cur_kl_coeff": 3.4571369204872135e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.272421581530697, "policy_loss": 0.00022747785459080385, "vf_loss": 6.272194108508882, "vf_explained_var": 0.2901297589458486, "kl": 0.0009755769688820208, "entropy": 0.8075343103005141, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 269325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -434.09999999999997, "episode_reward_mean": 65.75899999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -744.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 839.0}, "policy_reward_mean": {"prey_policy": -2.80050000000007, "predator_policy": 35.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [54.800000000000054, -48.999999999999794, 41.8000000000004, -168.29999999999998, 118.1, 216.79999999999927, -35.89999999999966, 145.89999999999964, 132.5, 252.39999999999907, 16.899999999999935, 209.7999999999993, 39.90000000000021, 195.69999999999936, 171.19999999999965, -22.199999999999676, 40.0000000000003, 38.9000000000003, 40.0000000000003, 57.10000000000022, 315.70000000000005, 217.29999999999924, 324.2, -17.000000000000057, 101.19999999999851, 65.9000000000001, 323.3000000000013, 193.8999999999991, 212.49999999999957, 111.09999999999988, 162.19999999999865, 187.9999999999994, -108.20000000000104, 207.99999999999932, 32.30000000000018, -50.50000000000069, -260.29999999999995, 5.899999999999942, 276.5999999999998, 33.200000000000195, 199.29999999999907, 49.900000000000404, 142.4999999999997, 288.7000000000005, 250.60000000000002, -72.5000000000012, 213.69999999999965, 79.39999999999938, 113.89999999999948, 320.1000000000013, 26.499999999999517, 129.89999999999944, 40.0000000000003, -151.30000000000064, 41.90000000000035, -248.2, 92.69999999999871, 81.19999999999914, -5.599999999999882, -311.7000000000006, -300.6, -11.699999999999733, 123.7999999999987, 66.30000000000007, -22.69999999999986, 156.49999999999963, 101.8999999999999, -183.39999999999972, 346.0, 112.6999999999998, 112.29999999999976, 40.0000000000003, 127.3999999999997, 144.3999999999996, 211.1999999999993, 213.9999999999993, 199.29999999999913, -150.6000000000002, 126.0, 400.0, -434.09999999999997, -21.299999999999898, 165.99999999999986, 21.30000000000004, 29.000000000000128, 282.0, 209.4999999999999, -6.000000000000107, -413.9, 120.09999999999863, 29.000000000000142, -1.4000000000000372, 2.4000000000000803, 138.29999999999967, 185.79999999999941, -173.40000000000063, -306.1, 32.500000000000185, -24.499999999999922, -184.80000000000038], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [148.7, -217.9000000000003, -89.20000000000043, -38.79999999999991, -23.19999999999986, 20.000000000000014, -177.40000000000003, -103.89999999999986, -193.90000000000006, 176.0, 200.0, -17.199999999999818, -124.90000000000055, 20.000000000000014, 17.899999999999988, 92.0, 156.5, -400.0, 200.0, 52.40000000000023, 20.000000000000014, -24.09999999999978, -110.2000000000007, 200.0, 9.499999999999968, 25.400000000000006, 175.7, 20.000000000000014, 51.5000000000001, 82.69999999999973, -40.89999999999983, -28.299999999999855, 20.000000000000014, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, -151.60000000000053, 109.69999999999962, 85.70000000000005, 200.0, 135.2, 82.09999999999926, 132.2, 164.0, 78.49999999999997, -200.5, 20.000000000000014, 81.19999999999925, 20.000000000000014, -48.09999999999989, 128.59999999999957, 193.7, 20.000000000000014, 173.89999999999984, 100.40000000000005, 79.09999999999954, 91.09999999999997, 20.000000000000014, 60.50000000000022, 91.69999999999952, 140.0, 20.000000000000014, -86.19999999999986, -90.99999999999984, 182.0, 20.000000000000014, 20.000000000000014, 5.299999999999965, -74.50000000000085, -64.00000000000078, -121.90000000000006, -282.4, -45.09999999999981, 20.000000000000014, 71.59999999999964, 200.0, 14.599999999999964, 11.599999999999964, 25.400000000000098, 173.89999999999984, 20.000000000000014, 29.900000000000194, 20.000000000000014, 90.5, 83.6, 151.09999999999988, 131.6, 74.0, -200.50000000000054, 20.000000000000014, 48.19999999999979, 120.50000000000006, 20.000000000000014, 58.40000000000022, 157.69999999999982, -101.80000000000024, 113.89999999999961, 198.2, -26.20000000000004, -73.2999999999999, 164.89999999999984, -85.00000000000082, 20.000000000000014, 20.000000000000014, -225.70000000000024, -55.59999999999991, 17.9, 4.99999999999997, -744.0, -343.1999999999998, 20.000000000000014, 61.700000000000166, 19.700000000000028, 33.50000000000024, -74.50000000000061, 17.899999999999988, -219.40000000000035, -238.30000000000027, -229.89999999999998, -225.70000000000002, 20.000000000000014, -78.70000000000064, 20.000000000000014, 99.79999999999944, -217.3000000000001, 158.6, -99.70000000000003, 20.000000000000014, 161.0, -74.50000000000026, -72.70000000000081, 113.59999999999998, -242.50000000000043, -145.89999999999986, 155.0, 164.0, -171.09999999999994, 192.8, -175.29999999999987, 194.59999999999997, 20.000000000000014, 20.000000000000014, -184.59999999999994, 200.0, 124.39999999999998, 20.000000000000014, 200.0, 3.1999999999999633, 191.0, 20.000000000000014, 179.29999999999987, 20.000000000000014, -360.1, 3.4999999999999716, 128.0, -238.0, 200.0, 200.0, -234.10000000000002, -400.0, 116.29999999999964, -286.5999999999999, 48.79999999999997, 117.19999999999999, 20.000000000000014, -15.699999999999822, -0.9999999999999846, 20.000000000000014, 149.6, 109.4, 69.49999999999997, 110.0, -198.70000000000007, 73.69999999999946, -368.5, -387.4, 20.000000000000014, 100.09999999999937, 13.699999999999967, 5.299999999999974, -187.8999999999999, 87.49999999999997, -97.60000000000068, -0.9999999999999846, 127.1, 3.1999999999999615, 165.8, 20.000000000000014, 20.000000000000014, -387.4, -196.3, -227.7999999999999, 15.799999999999963, 13.699999999999964, -352.0, 108.49999999999963, -45.10000000000003, -354.7], "policy_predator_policy_reward": [0.0, 124.0, 13.0, 66.0, 0.0, 45.0, 94.0, 19.0, 128.0, 8.0, 10.0, 24.0, 55.0, 14.0, 36.0, 0.0, 189.0, 187.0, 0.0, 0.0, 21.0, 0.0, 62.0, 58.0, 0.0, 5.0, 0.0, 0.0, 25.0, 12.0, 39.0, 8.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 84.0, 15.0, 30.0, 0.0, 0.0, 0.0, 0.0, 28.0, 10.0, 95.0, 0.0, 0.0, 35.0, 59.0, 0.0, 1.0, 0.0, 0.0, 5.0, 28.0, 0.0, 0.0, 10.0, 0.0, 10.0, 18.0, 69.0, 0.0, 6.0, 0.0, 0.0, 7.0, 34.0, 54.0, 0.0, 144.0, 31.0, 0.0, 5.0, 0.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 30.0, 24.0, 33.0, 12.0, 23.0, 85.0, 23.0, 22.0, 1.0, 0.0, 0.0, 58.0, 0.0, 8.0, 55.0, 71.0, 48.0, 2.0, 0.0, 0.0, 0.0, 130.0, 10.0, 9.0, 839.0, 0.0, 0.0, 11.0, 0.0, 28.0, 6.0, 45.0, 83.0, 63.0, 119.0, 36.0, 2.0, 45.0, 4.0, 0.0, 12.0, 113.0, 0.0, 57.0, 42.0, 28.0, 44.0, 17.0, 108.0, 97.0, 12.0, 15.0, 11.0, 80.0, 27.0, 66.0, 0.0, 0.0, 108.0, 4.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 0.0, 25.0, 181.0, 148.0, 88.0, 0.0, 0.0, 200.0, 0.0, 146.0, 3.0, 0.0, 0.0, 15.0, 2.0, 10.0, 0.0, 23.0, 0.0, 0.0, 30.0, 119.0, 0.0, 157.0, 185.0, 0.0, 0.0, 0.0, 10.0, 12.0, 87.0, 50.0, 51.0, 4.0, 4.0, 0.0, 0.0, 194.0, 0.0, 14.0, 104.0, 0.0, 3.0, 163.0, 56.0, 184.0, 31.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.351794426807288, "mean_inference_ms": 8.961959464586112, "mean_action_processing_ms": 0.7583223172090497, "mean_env_wait_ms": 1.164055483552709, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022893190383911133, "StateBufferConnector_ms": 0.005075335502624512, "ViewRequirementAgentConnector_ms": 0.379663348197937}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -434.09999999999997, "episode_return_mean": 65.75899999999979, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000, "num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 227.5661301210096, "num_env_steps_trained_throughput_per_sec": 227.5661301210096, "timesteps_total": 572000, "num_env_steps_sampled_lifetime": 572000, "num_agent_steps_sampled_lifetime": 2288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2288000, "timers": {"training_iteration_time_ms": 298719.331, "restore_workers_time_ms": 0.016, "training_step_time_ms": 298719.256, "sample_time_ms": 4528.249, "learn_time_ms": 294153.047, "learn_throughput": 13.598, "synch_weights_time_ms": 28.158}, "counters": {"num_env_steps_sampled": 572000, "num_env_steps_trained": 572000, "num_agent_steps_sampled": 2288000, "num_agent_steps_trained": 2288000}, "done": false, "training_iteration": 143, "trial_id": "3a355_00000", "date": "2024-08-13_04-44-36", "timestamp": 1723538676, "time_this_iter_s": 17.651428937911987, "time_total_s": 12876.283037185669, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b3d51e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12876.283037185669, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 78.512, "ram_util_percent": 83.568}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.081133788504771, "cur_kl_coeff": 6.162975822039155e-34, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8878912674686896, "policy_loss": -0.002604337377971403, "vf_loss": 2.890495601974467, "vf_explained_var": 0.013147535368248269, "kl": 0.003031134248583644, "entropy": 0.2199025200157569, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 271215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 51.732262715366154, "cur_kl_coeff": 1.7285684602436068e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.440267720802751, "policy_loss": -0.0001278853005724688, "vf_loss": 6.44039561004235, "vf_explained_var": 0.4395413378874461, "kl": 0.0019582671496937726, "entropy": 1.0038160396000695, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 271215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -434.09999999999997, "episode_reward_mean": 56.070999999999756, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -744.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 839.0}, "policy_reward_mean": {"prey_policy": -7.924500000000083, "predator_policy": 35.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 57.10000000000022, 315.70000000000005, 217.29999999999924, 324.2, -17.000000000000057, 101.19999999999851, 65.9000000000001, 323.3000000000013, 193.8999999999991, 212.49999999999957, 111.09999999999988, 162.19999999999865, 187.9999999999994, -108.20000000000104, 207.99999999999932, 32.30000000000018, -50.50000000000069, -260.29999999999995, 5.899999999999942, 276.5999999999998, 33.200000000000195, 199.29999999999907, 49.900000000000404, 142.4999999999997, 288.7000000000005, 250.60000000000002, -72.5000000000012, 213.69999999999965, 79.39999999999938, 113.89999999999948, 320.1000000000013, 26.499999999999517, 129.89999999999944, 40.0000000000003, -151.30000000000064, 41.90000000000035, -248.2, 92.69999999999871, 81.19999999999914, -5.599999999999882, -311.7000000000006, -300.6, -11.699999999999733, 123.7999999999987, 66.30000000000007, -22.69999999999986, 156.49999999999963, 101.8999999999999, -183.39999999999972, 346.0, 112.6999999999998, 112.29999999999976, 40.0000000000003, 127.3999999999997, 144.3999999999996, 211.1999999999993, 213.9999999999993, 199.29999999999913, -150.6000000000002, 126.0, 400.0, -434.09999999999997, -21.299999999999898, 165.99999999999986, 21.30000000000004, 29.000000000000128, 282.0, 209.4999999999999, -6.000000000000107, -413.9, 120.09999999999863, 29.000000000000142, -1.4000000000000372, 2.4000000000000803, 138.29999999999967, 185.79999999999941, -173.40000000000063, -306.1, 32.500000000000185, -24.499999999999922, -184.80000000000038, 62.90000000000018, -316.20000000000005, 214.4999999999993, 37.80000000000027, 83.79999999999956, 40.0000000000003, -297.2000000000008, 1.9999999999997164, -7.499999999999883, 106.59999999999968, 162.3999999999989, -20.399999999999608, 319.0000000000009, 143.99999999999963, 90.39999999999858, 151.59999999999883, -250.60000000000008, -92.60000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -151.60000000000053, 109.69999999999962, 85.70000000000005, 200.0, 135.2, 82.09999999999926, 132.2, 164.0, 78.49999999999997, -200.5, 20.000000000000014, 81.19999999999925, 20.000000000000014, -48.09999999999989, 128.59999999999957, 193.7, 20.000000000000014, 173.89999999999984, 100.40000000000005, 79.09999999999954, 91.09999999999997, 20.000000000000014, 60.50000000000022, 91.69999999999952, 140.0, 20.000000000000014, -86.19999999999986, -90.99999999999984, 182.0, 20.000000000000014, 20.000000000000014, 5.299999999999965, -74.50000000000085, -64.00000000000078, -121.90000000000006, -282.4, -45.09999999999981, 20.000000000000014, 71.59999999999964, 200.0, 14.599999999999964, 11.599999999999964, 25.400000000000098, 173.89999999999984, 20.000000000000014, 29.900000000000194, 20.000000000000014, 90.5, 83.6, 151.09999999999988, 131.6, 74.0, -200.50000000000054, 20.000000000000014, 48.19999999999979, 120.50000000000006, 20.000000000000014, 58.40000000000022, 157.69999999999982, -101.80000000000024, 113.89999999999961, 198.2, -26.20000000000004, -73.2999999999999, 164.89999999999984, -85.00000000000082, 20.000000000000014, 20.000000000000014, -225.70000000000024, -55.59999999999991, 17.9, 4.99999999999997, -744.0, -343.1999999999998, 20.000000000000014, 61.700000000000166, 19.700000000000028, 33.50000000000024, -74.50000000000061, 17.899999999999988, -219.40000000000035, -238.30000000000027, -229.89999999999998, -225.70000000000002, 20.000000000000014, -78.70000000000064, 20.000000000000014, 99.79999999999944, -217.3000000000001, 158.6, -99.70000000000003, 20.000000000000014, 161.0, -74.50000000000026, -72.70000000000081, 113.59999999999998, -242.50000000000043, -145.89999999999986, 155.0, 164.0, -171.09999999999994, 192.8, -175.29999999999987, 194.59999999999997, 20.000000000000014, 20.000000000000014, -184.59999999999994, 200.0, 124.39999999999998, 20.000000000000014, 200.0, 3.1999999999999633, 191.0, 20.000000000000014, 179.29999999999987, 20.000000000000014, -360.1, 3.4999999999999716, 128.0, -238.0, 200.0, 200.0, -234.10000000000002, -400.0, 116.29999999999964, -286.5999999999999, 48.79999999999997, 117.19999999999999, 20.000000000000014, -15.699999999999822, -0.9999999999999846, 20.000000000000014, 149.6, 109.4, 69.49999999999997, 110.0, -198.70000000000007, 73.69999999999946, -368.5, -387.4, 20.000000000000014, 100.09999999999937, 13.699999999999967, 5.299999999999974, -187.8999999999999, 87.49999999999997, -97.60000000000068, -0.9999999999999846, 127.1, 3.1999999999999615, 165.8, 20.000000000000014, 20.000000000000014, -387.4, -196.3, -227.7999999999999, 15.799999999999963, 13.699999999999964, -352.0, 108.49999999999963, -45.10000000000003, -354.7, 20.000000000000014, 26.900000000000013, -292.9, -175.30000000000004, 9.500000000000007, 200.0, 20.000000000000014, 15.799999999999962, 113.29999999999953, -305.5, 20.000000000000014, 20.000000000000014, -206.79999999999987, -198.39999999999986, -127.0, 20.000000000000014, 39.500000000000206, -127.00000000000054, 152.59999999999997, -127.00000000000051, 20.000000000000014, 142.39999999999964, 43.40000000000025, -143.8000000000007, 165.79999999999978, 153.2, 175.7, -78.70000000000005, 70.39999999999975, 20.000000000000014, 20.000000000000014, 131.59999999999957, -400.0, -52.59999999999988, 42.49999999999998, -276.1], "policy_predator_policy_reward": [0.0, 0.0, 84.0, 15.0, 30.0, 0.0, 0.0, 0.0, 0.0, 28.0, 10.0, 95.0, 0.0, 0.0, 35.0, 59.0, 0.0, 1.0, 0.0, 0.0, 5.0, 28.0, 0.0, 0.0, 10.0, 0.0, 10.0, 18.0, 69.0, 0.0, 6.0, 0.0, 0.0, 7.0, 34.0, 54.0, 0.0, 144.0, 31.0, 0.0, 5.0, 0.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 30.0, 24.0, 33.0, 12.0, 23.0, 85.0, 23.0, 22.0, 1.0, 0.0, 0.0, 58.0, 0.0, 8.0, 55.0, 71.0, 48.0, 2.0, 0.0, 0.0, 0.0, 130.0, 10.0, 9.0, 839.0, 0.0, 0.0, 11.0, 0.0, 28.0, 6.0, 45.0, 83.0, 63.0, 119.0, 36.0, 2.0, 45.0, 4.0, 0.0, 12.0, 113.0, 0.0, 57.0, 42.0, 28.0, 44.0, 17.0, 108.0, 97.0, 12.0, 15.0, 11.0, 80.0, 27.0, 66.0, 0.0, 0.0, 108.0, 4.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 0.0, 25.0, 181.0, 148.0, 88.0, 0.0, 0.0, 200.0, 0.0, 146.0, 3.0, 0.0, 0.0, 15.0, 2.0, 10.0, 0.0, 23.0, 0.0, 0.0, 30.0, 119.0, 0.0, 157.0, 185.0, 0.0, 0.0, 0.0, 10.0, 12.0, 87.0, 50.0, 51.0, 4.0, 4.0, 0.0, 0.0, 194.0, 0.0, 14.0, 104.0, 0.0, 3.0, 163.0, 56.0, 184.0, 31.0, 10.0, 6.0, 0.0, 152.0, 0.0, 5.0, 2.0, 0.0, 152.0, 124.0, 0.0, 0.0, 79.0, 29.0, 109.0, 0.0, 80.0, 0.0, 81.0, 0.0, 0.0, 0.0, 78.0, 2.0, 0.0, 0.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 200.0, 0.0, 141.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3473624171415852, "mean_inference_ms": 8.935422838972933, "mean_action_processing_ms": 0.7574688911520252, "mean_env_wait_ms": 1.16042141018632, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013498902320861816, "StateBufferConnector_ms": 0.004861116409301758, "ViewRequirementAgentConnector_ms": 0.38462090492248535}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -434.09999999999997, "episode_return_mean": 56.070999999999756, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000, "num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 224.4251822332561, "num_env_steps_trained_throughput_per_sec": 224.4251822332561, "timesteps_total": 576000, "num_env_steps_sampled_lifetime": 576000, "num_agent_steps_sampled_lifetime": 2304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2304000, "timers": {"training_iteration_time_ms": 298949.79, "restore_workers_time_ms": 0.017, "training_step_time_ms": 298949.716, "sample_time_ms": 4512.329, "learn_time_ms": 294400.78, "learn_throughput": 13.587, "synch_weights_time_ms": 28.033}, "counters": {"num_env_steps_sampled": 576000, "num_env_steps_trained": 576000, "num_agent_steps_sampled": 2304000, "num_agent_steps_trained": 2304000}, "done": false, "training_iteration": 144, "trial_id": "3a355_00000", "date": "2024-08-13_04-44-54", "timestamp": 1723538694, "time_this_iter_s": 17.88891100883484, "time_total_s": 12894.171948194504, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5f9bf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12894.171948194504, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 81.608, "ram_util_percent": 83.472}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9401588756689634, "cur_kl_coeff": 3.0814879110195775e-34, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.622316418942951, "policy_loss": -0.0011973994961451916, "vf_loss": 2.6235138150750013, "vf_explained_var": 0.016641202647849997, "kl": 0.0009156046726314936, "entropy": 0.17979473074671454, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 273105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 38.91810188113697, "cur_kl_coeff": 8.642842301218034e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.957213252183622, "policy_loss": -0.0003514208713861764, "vf_loss": 5.957564665274646, "vf_explained_var": 0.5720407368014099, "kl": 0.0016457724166140232, "entropy": 0.8835806413617714, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 273105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -434.09999999999997, "episode_reward_mean": 41.893999999999785, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -744.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 839.0}, "policy_reward_mean": {"prey_policy": -17.118000000000062, "predator_policy": 38.065}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-260.29999999999995, 5.899999999999942, 276.5999999999998, 33.200000000000195, 199.29999999999907, 49.900000000000404, 142.4999999999997, 288.7000000000005, 250.60000000000002, -72.5000000000012, 213.69999999999965, 79.39999999999938, 113.89999999999948, 320.1000000000013, 26.499999999999517, 129.89999999999944, 40.0000000000003, -151.30000000000064, 41.90000000000035, -248.2, 92.69999999999871, 81.19999999999914, -5.599999999999882, -311.7000000000006, -300.6, -11.699999999999733, 123.7999999999987, 66.30000000000007, -22.69999999999986, 156.49999999999963, 101.8999999999999, -183.39999999999972, 346.0, 112.6999999999998, 112.29999999999976, 40.0000000000003, 127.3999999999997, 144.3999999999996, 211.1999999999993, 213.9999999999993, 199.29999999999913, -150.6000000000002, 126.0, 400.0, -434.09999999999997, -21.299999999999898, 165.99999999999986, 21.30000000000004, 29.000000000000128, 282.0, 209.4999999999999, -6.000000000000107, -413.9, 120.09999999999863, 29.000000000000142, -1.4000000000000372, 2.4000000000000803, 138.29999999999967, 185.79999999999941, -173.40000000000063, -306.1, 32.500000000000185, -24.499999999999922, -184.80000000000038, 62.90000000000018, -316.20000000000005, 214.4999999999993, 37.80000000000027, 83.79999999999956, 40.0000000000003, -297.2000000000008, 1.9999999999997164, -7.499999999999883, 106.59999999999968, 162.3999999999989, -20.399999999999608, 319.0000000000009, 143.99999999999963, 90.39999999999858, 151.59999999999883, -250.60000000000008, -92.60000000000014, -145.89999999999986, 40.0000000000003, 150.69999999999882, 2.1000000000000156, -8.699999999999935, 201.09999999999914, -315.6000000000002, 40.0000000000003, 141.99999999999966, 40.0000000000003, 17.69999999999923, 113.09999999999982, 219.99999999999926, 246.7, 226.69999999999948, 219.99999999999926, -285.0, 54.40000000000032], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-121.90000000000006, -282.4, -45.09999999999981, 20.000000000000014, 71.59999999999964, 200.0, 14.599999999999964, 11.599999999999964, 25.400000000000098, 173.89999999999984, 20.000000000000014, 29.900000000000194, 20.000000000000014, 90.5, 83.6, 151.09999999999988, 131.6, 74.0, -200.50000000000054, 20.000000000000014, 48.19999999999979, 120.50000000000006, 20.000000000000014, 58.40000000000022, 157.69999999999982, -101.80000000000024, 113.89999999999961, 198.2, -26.20000000000004, -73.2999999999999, 164.89999999999984, -85.00000000000082, 20.000000000000014, 20.000000000000014, -225.70000000000024, -55.59999999999991, 17.9, 4.99999999999997, -744.0, -343.1999999999998, 20.000000000000014, 61.700000000000166, 19.700000000000028, 33.50000000000024, -74.50000000000061, 17.899999999999988, -219.40000000000035, -238.30000000000027, -229.89999999999998, -225.70000000000002, 20.000000000000014, -78.70000000000064, 20.000000000000014, 99.79999999999944, -217.3000000000001, 158.6, -99.70000000000003, 20.000000000000014, 161.0, -74.50000000000026, -72.70000000000081, 113.59999999999998, -242.50000000000043, -145.89999999999986, 155.0, 164.0, -171.09999999999994, 192.8, -175.29999999999987, 194.59999999999997, 20.000000000000014, 20.000000000000014, -184.59999999999994, 200.0, 124.39999999999998, 20.000000000000014, 200.0, 3.1999999999999633, 191.0, 20.000000000000014, 179.29999999999987, 20.000000000000014, -360.1, 3.4999999999999716, 128.0, -238.0, 200.0, 200.0, -234.10000000000002, -400.0, 116.29999999999964, -286.5999999999999, 48.79999999999997, 117.19999999999999, 20.000000000000014, -15.699999999999822, -0.9999999999999846, 20.000000000000014, 149.6, 109.4, 69.49999999999997, 110.0, -198.70000000000007, 73.69999999999946, -368.5, -387.4, 20.000000000000014, 100.09999999999937, 13.699999999999967, 5.299999999999974, -187.8999999999999, 87.49999999999997, -97.60000000000068, -0.9999999999999846, 127.1, 3.1999999999999615, 165.8, 20.000000000000014, 20.000000000000014, -387.4, -196.3, -227.7999999999999, 15.799999999999963, 13.699999999999964, -352.0, 108.49999999999963, -45.10000000000003, -354.7, 20.000000000000014, 26.900000000000013, -292.9, -175.30000000000004, 9.500000000000007, 200.0, 20.000000000000014, 15.799999999999962, 113.29999999999953, -305.5, 20.000000000000014, 20.000000000000014, -206.79999999999987, -198.39999999999986, -127.0, 20.000000000000014, 39.500000000000206, -127.00000000000054, 152.59999999999997, -127.00000000000051, 20.000000000000014, 142.39999999999964, 43.40000000000025, -143.8000000000007, 165.79999999999978, 153.2, 175.7, -78.70000000000005, 70.39999999999975, 20.000000000000014, 20.000000000000014, 131.59999999999957, -400.0, -52.59999999999988, 42.49999999999998, -276.1, -95.50000000000003, -114.40000000000003, 20.000000000000014, 20.000000000000014, 130.69999999999956, 20.000000000000014, 78.49999999999997, -261.4, 145.1, -311.8000000000002, 181.09999999999988, 20.000000000000014, -124.90000000000003, -393.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 83.0, 20.000000000000014, 20.000000000000014, 40.09999999999955, -108.39999999999992, -145.90000000000018, 170.0, 20.000000000000014, 200.0, 112.7, 101.00000000000007, 163.1, 38.59999999999982, 20.000000000000014, 200.0, -154.3, -267.7, 20.000000000000014, 34.40000000000016], "policy_predator_policy_reward": [0.0, 144.0, 31.0, 0.0, 5.0, 0.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 30.0, 24.0, 33.0, 12.0, 23.0, 85.0, 23.0, 22.0, 1.0, 0.0, 0.0, 58.0, 0.0, 8.0, 55.0, 71.0, 48.0, 2.0, 0.0, 0.0, 0.0, 130.0, 10.0, 9.0, 839.0, 0.0, 0.0, 11.0, 0.0, 28.0, 6.0, 45.0, 83.0, 63.0, 119.0, 36.0, 2.0, 45.0, 4.0, 0.0, 12.0, 113.0, 0.0, 57.0, 42.0, 28.0, 44.0, 17.0, 108.0, 97.0, 12.0, 15.0, 11.0, 80.0, 27.0, 66.0, 0.0, 0.0, 108.0, 4.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 0.0, 25.0, 181.0, 148.0, 88.0, 0.0, 0.0, 200.0, 0.0, 146.0, 3.0, 0.0, 0.0, 15.0, 2.0, 10.0, 0.0, 23.0, 0.0, 0.0, 30.0, 119.0, 0.0, 157.0, 185.0, 0.0, 0.0, 0.0, 10.0, 12.0, 87.0, 50.0, 51.0, 4.0, 4.0, 0.0, 0.0, 194.0, 0.0, 14.0, 104.0, 0.0, 3.0, 163.0, 56.0, 184.0, 31.0, 10.0, 6.0, 0.0, 152.0, 0.0, 5.0, 2.0, 0.0, 152.0, 124.0, 0.0, 0.0, 79.0, 29.0, 109.0, 0.0, 80.0, 0.0, 81.0, 0.0, 0.0, 0.0, 78.0, 2.0, 0.0, 0.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 200.0, 0.0, 141.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 115.0, 67.0, 91.0, 0.0, 0.0, 155.0, 48.0, 0.0, 0.0, 0.0, 39.0, 0.0, 0.0, 0.0, 86.0, 79.0, 10.0, 0.0, 0.0, 0.0, 33.0, 0.0, 25.0, 0.0, 0.0, 137.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3389731749411533, "mean_inference_ms": 8.897824314296018, "mean_action_processing_ms": 0.755162428326665, "mean_env_wait_ms": 1.155215015212418, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008481025695800781, "StateBufferConnector_ms": 0.005162715911865234, "ViewRequirementAgentConnector_ms": 0.2195146083831787}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -434.09999999999997, "episode_return_mean": 41.893999999999785, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000, "num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 230.54673749647716, "num_env_steps_trained_throughput_per_sec": 230.54673749647716, "timesteps_total": 580000, "num_env_steps_sampled_lifetime": 580000, "num_agent_steps_sampled_lifetime": 2320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2320000, "timers": {"training_iteration_time_ms": 299132.718, "restore_workers_time_ms": 0.016, "training_step_time_ms": 299132.633, "sample_time_ms": 4495.85, "learn_time_ms": 294599.258, "learn_throughput": 13.578, "synch_weights_time_ms": 28.728}, "counters": {"num_env_steps_sampled": 580000, "num_env_steps_trained": 580000, "num_agent_steps_sampled": 2320000, "num_agent_steps_trained": 2320000}, "done": false, "training_iteration": 145, "trial_id": "3a355_00000", "date": "2024-08-13_04-45-12", "timestamp": 1723538712, "time_this_iter_s": 17.40661597251892, "time_total_s": 12911.578564167023, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fd6f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12911.578564167023, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 79.75999999999999, "ram_util_percent": 83.456}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8529243421381113, "cur_kl_coeff": 1.5407439555097888e-34, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.546617709455036, "policy_loss": -0.0010774386721471, "vf_loss": 2.547695144332906, "vf_explained_var": 0.008967222896202531, "kl": 0.0021922718157230837, "entropy": 0.1948959752483658, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 274995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 32.186521307690434, "cur_kl_coeff": 4.321421150609017e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.875360292858548, "policy_loss": -0.0014240863693572542, "vf_loss": 4.876784394027064, "vf_explained_var": 0.6530723396117094, "kl": 0.0040912118581557496, "entropy": 0.7767261080640965, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 274995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -444.5999999999999, "episode_reward_mean": 39.975999999999814, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -17.047000000000057, "predator_policy": 37.035}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-311.7000000000006, -300.6, -11.699999999999733, 123.7999999999987, 66.30000000000007, -22.69999999999986, 156.49999999999963, 101.8999999999999, -183.39999999999972, 346.0, 112.6999999999998, 112.29999999999976, 40.0000000000003, 127.3999999999997, 144.3999999999996, 211.1999999999993, 213.9999999999993, 199.29999999999913, -150.6000000000002, 126.0, 400.0, -434.09999999999997, -21.299999999999898, 165.99999999999986, 21.30000000000004, 29.000000000000128, 282.0, 209.4999999999999, -6.000000000000107, -413.9, 120.09999999999863, 29.000000000000142, -1.4000000000000372, 2.4000000000000803, 138.29999999999967, 185.79999999999941, -173.40000000000063, -306.1, 32.500000000000185, -24.499999999999922, -184.80000000000038, 62.90000000000018, -316.20000000000005, 214.4999999999993, 37.80000000000027, 83.79999999999956, 40.0000000000003, -297.2000000000008, 1.9999999999997164, -7.499999999999883, 106.59999999999968, 162.3999999999989, -20.399999999999608, 319.0000000000009, 143.99999999999963, 90.39999999999858, 151.59999999999883, -250.60000000000008, -92.60000000000014, -145.89999999999986, 40.0000000000003, 150.69999999999882, 2.1000000000000156, -8.699999999999935, 201.09999999999914, -315.6000000000002, 40.0000000000003, 141.99999999999966, 40.0000000000003, 17.69999999999923, 113.09999999999982, 219.99999999999926, 246.7, 226.69999999999948, 219.99999999999926, -285.0, 54.40000000000032, -352.69999999999936, 40.0000000000003, 31.200000000000188, 37.80000000000028, 95.79999999999987, -427.0000000000001, -444.5999999999999, 154.89999999999958, 0.0, 376.0, 211.8999999999993, 96.99999999999993, -32.59999999999976, 187.60000000000008, 235.3, 77.39999999999999, 394.0, 185.9999999999994, 201.09999999999934, 62.399999999999594, 139.7999999999997, 110.19999999999989, 74.80000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-219.40000000000035, -238.30000000000027, -229.89999999999998, -225.70000000000002, 20.000000000000014, -78.70000000000064, 20.000000000000014, 99.79999999999944, -217.3000000000001, 158.6, -99.70000000000003, 20.000000000000014, 161.0, -74.50000000000026, -72.70000000000081, 113.59999999999998, -242.50000000000043, -145.89999999999986, 155.0, 164.0, -171.09999999999994, 192.8, -175.29999999999987, 194.59999999999997, 20.000000000000014, 20.000000000000014, -184.59999999999994, 200.0, 124.39999999999998, 20.000000000000014, 200.0, 3.1999999999999633, 191.0, 20.000000000000014, 179.29999999999987, 20.000000000000014, -360.1, 3.4999999999999716, 128.0, -238.0, 200.0, 200.0, -234.10000000000002, -400.0, 116.29999999999964, -286.5999999999999, 48.79999999999997, 117.19999999999999, 20.000000000000014, -15.699999999999822, -0.9999999999999846, 20.000000000000014, 149.6, 109.4, 69.49999999999997, 110.0, -198.70000000000007, 73.69999999999946, -368.5, -387.4, 20.000000000000014, 100.09999999999937, 13.699999999999967, 5.299999999999974, -187.8999999999999, 87.49999999999997, -97.60000000000068, -0.9999999999999846, 127.1, 3.1999999999999615, 165.8, 20.000000000000014, 20.000000000000014, -387.4, -196.3, -227.7999999999999, 15.799999999999963, 13.699999999999964, -352.0, 108.49999999999963, -45.10000000000003, -354.7, 20.000000000000014, 26.900000000000013, -292.9, -175.30000000000004, 9.500000000000007, 200.0, 20.000000000000014, 15.799999999999962, 113.29999999999953, -305.5, 20.000000000000014, 20.000000000000014, -206.79999999999987, -198.39999999999986, -127.0, 20.000000000000014, 39.500000000000206, -127.00000000000054, 152.59999999999997, -127.00000000000051, 20.000000000000014, 142.39999999999964, 43.40000000000025, -143.8000000000007, 165.79999999999978, 153.2, 175.7, -78.70000000000005, 70.39999999999975, 20.000000000000014, 20.000000000000014, 131.59999999999957, -400.0, -52.59999999999988, 42.49999999999998, -276.1, -95.50000000000003, -114.40000000000003, 20.000000000000014, 20.000000000000014, 130.69999999999956, 20.000000000000014, 78.49999999999997, -261.4, 145.1, -311.8000000000002, 181.09999999999988, 20.000000000000014, -124.90000000000003, -393.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 83.0, 20.000000000000014, 20.000000000000014, 40.09999999999955, -108.39999999999992, -145.90000000000018, 170.0, 20.000000000000014, 200.0, 112.7, 101.00000000000007, 163.1, 38.59999999999982, 20.000000000000014, 200.0, -154.3, -267.7, 20.000000000000014, 34.40000000000016, -208.90000000000023, -332.7999999999999, 20.000000000000014, 20.000000000000014, -32.80000000000002, 20.000000000000014, 17.899999999999984, 17.900000000000013, 173.0, -236.20000000000033, -286.5999999999999, -345.40000000000003, -244.60000000000002, -400.0, -66.10000000000001, 170.0, -400.0, 200.0, 200.0, 164.0, 20.000000000000014, 191.9, 8.0, 20.000000000000014, 20.000000000000014, -118.60000000000045, 76.69999999999996, 110.89999999999998, 131.6, 103.69999999999997, -248.80000000000024, 198.2, 200.0, 191.0, 149.0, 20.000000000000014, 181.1, 20.000000000000014, -198.4, 156.79999999999973, 117.19999999999999, 17.59999999999998, 20.000000000000014, 90.19999999999997, 200.0, -257.2], "policy_predator_policy_reward": [83.0, 63.0, 119.0, 36.0, 2.0, 45.0, 4.0, 0.0, 12.0, 113.0, 0.0, 57.0, 42.0, 28.0, 44.0, 17.0, 108.0, 97.0, 12.0, 15.0, 11.0, 80.0, 27.0, 66.0, 0.0, 0.0, 108.0, 4.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 0.0, 25.0, 181.0, 148.0, 88.0, 0.0, 0.0, 200.0, 0.0, 146.0, 3.0, 0.0, 0.0, 15.0, 2.0, 10.0, 0.0, 23.0, 0.0, 0.0, 30.0, 119.0, 0.0, 157.0, 185.0, 0.0, 0.0, 0.0, 10.0, 12.0, 87.0, 50.0, 51.0, 4.0, 4.0, 0.0, 0.0, 194.0, 0.0, 14.0, 104.0, 0.0, 3.0, 163.0, 56.0, 184.0, 31.0, 10.0, 6.0, 0.0, 152.0, 0.0, 5.0, 2.0, 0.0, 152.0, 124.0, 0.0, 0.0, 79.0, 29.0, 109.0, 0.0, 80.0, 0.0, 81.0, 0.0, 0.0, 0.0, 78.0, 2.0, 0.0, 0.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 200.0, 0.0, 141.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 115.0, 67.0, 91.0, 0.0, 0.0, 155.0, 48.0, 0.0, 0.0, 0.0, 39.0, 0.0, 0.0, 0.0, 86.0, 79.0, 10.0, 0.0, 0.0, 0.0, 33.0, 0.0, 25.0, 0.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 189.0, 0.0, 0.0, 34.0, 10.0, 0.0, 2.0, 68.0, 91.0, 180.0, 25.0, 0.0, 200.0, 41.0, 10.0, 200.0, 0.0, 12.0, 0.0, 0.0, 0.0, 10.0, 59.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 3.0, 0.0, 0.0, 17.0, 0.0, 0.0, 104.0, 0.0, 0.0, 5.0, 0.0, 0.0, 132.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3285604947110063, "mean_inference_ms": 8.848306573998055, "mean_action_processing_ms": 0.7519010422036004, "mean_env_wait_ms": 1.1478343473176897, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008685827255249023, "StateBufferConnector_ms": 0.006657719612121582, "ViewRequirementAgentConnector_ms": 0.18515276908874512}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -444.5999999999999, "episode_return_mean": 39.975999999999814, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000, "num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 221.86278072778467, "num_env_steps_trained_throughput_per_sec": 221.86278072778467, "timesteps_total": 584000, "num_env_steps_sampled_lifetime": 584000, "num_agent_steps_sampled_lifetime": 2336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2336000, "timers": {"training_iteration_time_ms": 204753.12, "restore_workers_time_ms": 0.016, "training_step_time_ms": 204753.038, "sample_time_ms": 4387.957, "learn_time_ms": 200328.439, "learn_throughput": 19.967, "synch_weights_time_ms": 28.023}, "counters": {"num_env_steps_sampled": 584000, "num_env_steps_trained": 584000, "num_agent_steps_sampled": 2336000, "num_agent_steps_trained": 2336000}, "done": false, "training_iteration": 146, "trial_id": "3a355_00000", "date": "2024-08-13_04-45-30", "timestamp": 1723538730, "time_this_iter_s": 18.081509828567505, "time_total_s": 12929.66007399559, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fbcca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12929.66007399559, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 81.492, "ram_util_percent": 83.31200000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.928267033346904, "cur_kl_coeff": 7.703719777548944e-35, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.342997330711001, "policy_loss": -0.0018971602215613953, "vf_loss": 4.344894484363536, "vf_explained_var": 0.00475766485330289, "kl": 0.0016145071407094548, "entropy": 0.2365503739821848, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 276885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 38.73599956694734, "cur_kl_coeff": 2.1607105753045084e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.074353377528922, "policy_loss": -0.0006811502841720112, "vf_loss": 6.0750345207396, "vf_explained_var": 0.45881591871301963, "kl": 0.0013415564622306494, "entropy": 0.8314768247818821, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 276885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000}, "env_runners": {"episode_reward_max": 394.0, "episode_reward_min": -444.5999999999999, "episode_reward_mean": 37.962999999999845, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -20.513500000000064, "predator_policy": 39.495}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-21.299999999999898, 165.99999999999986, 21.30000000000004, 29.000000000000128, 282.0, 209.4999999999999, -6.000000000000107, -413.9, 120.09999999999863, 29.000000000000142, -1.4000000000000372, 2.4000000000000803, 138.29999999999967, 185.79999999999941, -173.40000000000063, -306.1, 32.500000000000185, -24.499999999999922, -184.80000000000038, 62.90000000000018, -316.20000000000005, 214.4999999999993, 37.80000000000027, 83.79999999999956, 40.0000000000003, -297.2000000000008, 1.9999999999997164, -7.499999999999883, 106.59999999999968, 162.3999999999989, -20.399999999999608, 319.0000000000009, 143.99999999999963, 90.39999999999858, 151.59999999999883, -250.60000000000008, -92.60000000000014, -145.89999999999986, 40.0000000000003, 150.69999999999882, 2.1000000000000156, -8.699999999999935, 201.09999999999914, -315.6000000000002, 40.0000000000003, 141.99999999999966, 40.0000000000003, 17.69999999999923, 113.09999999999982, 219.99999999999926, 246.7, 226.69999999999948, 219.99999999999926, -285.0, 54.40000000000032, -352.69999999999936, 40.0000000000003, 31.200000000000188, 37.80000000000028, 95.79999999999987, -427.0000000000001, -444.5999999999999, 154.89999999999958, 0.0, 376.0, 211.8999999999993, 96.99999999999993, -32.59999999999976, 187.60000000000008, 235.3, 77.39999999999999, 394.0, 185.9999999999994, 201.09999999999934, 62.399999999999594, 139.7999999999997, 110.19999999999989, 74.80000000000001, 40.0000000000003, -214.3, -138.6000000000002, 193.99999999999926, 146.39999999999966, 197.99999999999937, -313.4000000000008, 80.29999999999998, 151.5999999999996, 326.0, 22.999999999999975, 87.59999999999994, -282.69999999999675, 36.70000000000025, 212.79999999999927, 70.40000000000003, 107.79999999999944, 50.600000000000094, -76.60000000000096, 169.39999999999952, -13.899999999999569, 10.600000000000119], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [116.29999999999964, -286.5999999999999, 48.79999999999997, 117.19999999999999, 20.000000000000014, -15.699999999999822, -0.9999999999999846, 20.000000000000014, 149.6, 109.4, 69.49999999999997, 110.0, -198.70000000000007, 73.69999999999946, -368.5, -387.4, 20.000000000000014, 100.09999999999937, 13.699999999999967, 5.299999999999974, -187.8999999999999, 87.49999999999997, -97.60000000000068, -0.9999999999999846, 127.1, 3.1999999999999615, 165.8, 20.000000000000014, 20.000000000000014, -387.4, -196.3, -227.7999999999999, 15.799999999999963, 13.699999999999964, -352.0, 108.49999999999963, -45.10000000000003, -354.7, 20.000000000000014, 26.900000000000013, -292.9, -175.30000000000004, 9.500000000000007, 200.0, 20.000000000000014, 15.799999999999962, 113.29999999999953, -305.5, 20.000000000000014, 20.000000000000014, -206.79999999999987, -198.39999999999986, -127.0, 20.000000000000014, 39.500000000000206, -127.00000000000054, 152.59999999999997, -127.00000000000051, 20.000000000000014, 142.39999999999964, 43.40000000000025, -143.8000000000007, 165.79999999999978, 153.2, 175.7, -78.70000000000005, 70.39999999999975, 20.000000000000014, 20.000000000000014, 131.59999999999957, -400.0, -52.59999999999988, 42.49999999999998, -276.1, -95.50000000000003, -114.40000000000003, 20.000000000000014, 20.000000000000014, 130.69999999999956, 20.000000000000014, 78.49999999999997, -261.4, 145.1, -311.8000000000002, 181.09999999999988, 20.000000000000014, -124.90000000000003, -393.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 83.0, 20.000000000000014, 20.000000000000014, 40.09999999999955, -108.39999999999992, -145.90000000000018, 170.0, 20.000000000000014, 200.0, 112.7, 101.00000000000007, 163.1, 38.59999999999982, 20.000000000000014, 200.0, -154.3, -267.7, 20.000000000000014, 34.40000000000016, -208.90000000000023, -332.7999999999999, 20.000000000000014, 20.000000000000014, -32.80000000000002, 20.000000000000014, 17.899999999999984, 17.900000000000013, 173.0, -236.20000000000033, -286.5999999999999, -345.40000000000003, -244.60000000000002, -400.0, -66.10000000000001, 170.0, -400.0, 200.0, 200.0, 164.0, 20.000000000000014, 191.9, 8.0, 20.000000000000014, 20.000000000000014, -118.60000000000045, 76.69999999999996, 110.89999999999998, 131.6, 103.69999999999997, -248.80000000000024, 198.2, 200.0, 191.0, 149.0, 20.000000000000014, 181.1, 20.000000000000014, -198.4, 156.79999999999973, 117.19999999999999, 17.59999999999998, 20.000000000000014, 90.19999999999997, 200.0, -257.2, 20.000000000000014, 20.000000000000014, -211.0, -385.3, -292.90000000000015, 5.300000000000004, 161.0, 20.000000000000014, 149.0, -55.600000000000335, 200.0, -21.99999999999996, -255.1000000000003, -238.30000000000044, 200.0, -246.70000000000027, 116.29999999999973, 8.300000000000004, 89.0, 200.0, 20.000000000000014, -18.999999999999766, -160.60000000000002, 162.2, -227.80000000000047, -187.90000000000057, 13.699999999999964, 20.000000000000014, -26.19999999999977, 200.0, -265.6, 200.0, -360.1, 110.89999999999944, 72.19999999999985, -160.60000000000002, -148.00000000000043, -34.599999999999774, -76.60000000000004, 200.0, -82.90000000000086, 20.000000000000014, -318.1000000000002, 94.69999999999997], "policy_predator_policy_reward": [146.0, 3.0, 0.0, 0.0, 15.0, 2.0, 10.0, 0.0, 23.0, 0.0, 0.0, 30.0, 119.0, 0.0, 157.0, 185.0, 0.0, 0.0, 0.0, 10.0, 12.0, 87.0, 50.0, 51.0, 4.0, 4.0, 0.0, 0.0, 194.0, 0.0, 14.0, 104.0, 0.0, 3.0, 163.0, 56.0, 184.0, 31.0, 10.0, 6.0, 0.0, 152.0, 0.0, 5.0, 2.0, 0.0, 152.0, 124.0, 0.0, 0.0, 79.0, 29.0, 109.0, 0.0, 80.0, 0.0, 81.0, 0.0, 0.0, 0.0, 78.0, 2.0, 0.0, 0.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 200.0, 0.0, 141.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 115.0, 67.0, 91.0, 0.0, 0.0, 155.0, 48.0, 0.0, 0.0, 0.0, 39.0, 0.0, 0.0, 0.0, 86.0, 79.0, 10.0, 0.0, 0.0, 0.0, 33.0, 0.0, 25.0, 0.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 189.0, 0.0, 0.0, 34.0, 10.0, 0.0, 2.0, 68.0, 91.0, 180.0, 25.0, 0.0, 200.0, 41.0, 10.0, 200.0, 0.0, 12.0, 0.0, 0.0, 0.0, 10.0, 59.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 3.0, 0.0, 0.0, 17.0, 0.0, 0.0, 104.0, 0.0, 0.0, 5.0, 0.0, 0.0, 132.0, 0.0, 0.0, 0.0, 193.0, 189.0, 0.0, 149.0, 13.0, 0.0, 17.0, 36.0, 11.0, 9.0, 57.0, 123.0, 69.0, 58.0, 0.0, 27.0, 37.0, 0.0, 0.0, 22.0, 86.0, 0.0, 69.0, 64.0, 3.0, 0.0, 22.0, 17.0, 134.0, 2.0, 176.0, 181.0, 40.0, 99.0, 105.0, 1.0, 46.0, 0.0, 49.0, 0.0, 148.0, 86.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3662069465996107, "mean_inference_ms": 8.75243051514035, "mean_action_processing_ms": 0.750164642364808, "mean_env_wait_ms": 1.1447124039699934, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008108735084533691, "StateBufferConnector_ms": 0.005810141563415527, "ViewRequirementAgentConnector_ms": 0.19677090644836426}, "num_episodes": 22, "episode_return_max": 394.0, "episode_return_min": -444.5999999999999, "episode_return_mean": 37.962999999999845, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000, "num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 216.3447132471371, "num_env_steps_trained_throughput_per_sec": 216.3447132471371, "timesteps_total": 588000, "num_env_steps_sampled_lifetime": 588000, "num_agent_steps_sampled_lifetime": 2352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2352000, "timers": {"training_iteration_time_ms": 113332.801, "restore_workers_time_ms": 0.016, "training_step_time_ms": 113332.719, "sample_time_ms": 4266.696, "learn_time_ms": 109036.622, "learn_throughput": 36.685, "synch_weights_time_ms": 21.901}, "counters": {"num_env_steps_sampled": 588000, "num_env_steps_trained": 588000, "num_agent_steps_sampled": 2352000, "num_agent_steps_trained": 2352000}, "done": false, "training_iteration": 147, "trial_id": "3a355_00000", "date": "2024-08-13_04-45-48", "timestamp": 1723538748, "time_this_iter_s": 18.560168981552124, "time_total_s": 12948.220242977142, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5293550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 12948.220242977142, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 80.99259259259259, "ram_util_percent": 83.46666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.053462462694872, "cur_kl_coeff": 3.851859888774472e-35, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0980448007583616, "policy_loss": -0.0011930683500838107, "vf_loss": 2.099237864894211, "vf_explained_var": 0.013561486094086259, "kl": 0.0013877750041508862, "entropy": 0.21845285141909565, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 278775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 34.26537776434863, "cur_kl_coeff": 1.0803552876522542e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.078251785449881, "policy_loss": -0.0008411328559593549, "vf_loss": 6.079092915852865, "vf_explained_var": 0.5907821507996353, "kl": 0.0016456542437526108, "entropy": 0.6152435002030519, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 278775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -444.5999999999999, "episode_reward_mean": 52.215999999999866, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -9.562000000000047, "predator_policy": 35.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-184.80000000000038, 62.90000000000018, -316.20000000000005, 214.4999999999993, 37.80000000000027, 83.79999999999956, 40.0000000000003, -297.2000000000008, 1.9999999999997164, -7.499999999999883, 106.59999999999968, 162.3999999999989, -20.399999999999608, 319.0000000000009, 143.99999999999963, 90.39999999999858, 151.59999999999883, -250.60000000000008, -92.60000000000014, -145.89999999999986, 40.0000000000003, 150.69999999999882, 2.1000000000000156, -8.699999999999935, 201.09999999999914, -315.6000000000002, 40.0000000000003, 141.99999999999966, 40.0000000000003, 17.69999999999923, 113.09999999999982, 219.99999999999926, 246.7, 226.69999999999948, 219.99999999999926, -285.0, 54.40000000000032, -352.69999999999936, 40.0000000000003, 31.200000000000188, 37.80000000000028, 95.79999999999987, -427.0000000000001, -444.5999999999999, 154.89999999999958, 0.0, 376.0, 211.8999999999993, 96.99999999999993, -32.59999999999976, 187.60000000000008, 235.3, 77.39999999999999, 394.0, 185.9999999999994, 201.09999999999934, 62.399999999999594, 139.7999999999997, 110.19999999999989, 74.80000000000001, 40.0000000000003, -214.3, -138.6000000000002, 193.99999999999926, 146.39999999999966, 197.99999999999937, -313.4000000000008, 80.29999999999998, 151.5999999999996, 326.0, 22.999999999999975, 87.59999999999994, -282.69999999999675, 36.70000000000025, 212.79999999999927, 70.40000000000003, 107.79999999999944, 50.600000000000094, -76.60000000000096, 169.39999999999952, -13.899999999999569, 10.600000000000119, 40.0000000000003, 181.89999999999944, 139.19999999999973, -16.0, 40.0000000000003, 197.99999999999926, 400.0, 332.6, -218.0999999999999, 34.50000000000029, 107.49999999999991, 41.90000000000034, 21.60000000000003, -398.5, 400.0, 219.99999999999926, 40.0000000000003, 129.99999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-45.10000000000003, -354.7, 20.000000000000014, 26.900000000000013, -292.9, -175.30000000000004, 9.500000000000007, 200.0, 20.000000000000014, 15.799999999999962, 113.29999999999953, -305.5, 20.000000000000014, 20.000000000000014, -206.79999999999987, -198.39999999999986, -127.0, 20.000000000000014, 39.500000000000206, -127.00000000000054, 152.59999999999997, -127.00000000000051, 20.000000000000014, 142.39999999999964, 43.40000000000025, -143.8000000000007, 165.79999999999978, 153.2, 175.7, -78.70000000000005, 70.39999999999975, 20.000000000000014, 20.000000000000014, 131.59999999999957, -400.0, -52.59999999999988, 42.49999999999998, -276.1, -95.50000000000003, -114.40000000000003, 20.000000000000014, 20.000000000000014, 130.69999999999956, 20.000000000000014, 78.49999999999997, -261.4, 145.1, -311.8000000000002, 181.09999999999988, 20.000000000000014, -124.90000000000003, -393.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 83.0, 20.000000000000014, 20.000000000000014, 40.09999999999955, -108.39999999999992, -145.90000000000018, 170.0, 20.000000000000014, 200.0, 112.7, 101.00000000000007, 163.1, 38.59999999999982, 20.000000000000014, 200.0, -154.3, -267.7, 20.000000000000014, 34.40000000000016, -208.90000000000023, -332.7999999999999, 20.000000000000014, 20.000000000000014, -32.80000000000002, 20.000000000000014, 17.899999999999984, 17.900000000000013, 173.0, -236.20000000000033, -286.5999999999999, -345.40000000000003, -244.60000000000002, -400.0, -66.10000000000001, 170.0, -400.0, 200.0, 200.0, 164.0, 20.000000000000014, 191.9, 8.0, 20.000000000000014, 20.000000000000014, -118.60000000000045, 76.69999999999996, 110.89999999999998, 131.6, 103.69999999999997, -248.80000000000024, 198.2, 200.0, 191.0, 149.0, 20.000000000000014, 181.1, 20.000000000000014, -198.4, 156.79999999999973, 117.19999999999999, 17.59999999999998, 20.000000000000014, 90.19999999999997, 200.0, -257.2, 20.000000000000014, 20.000000000000014, -211.0, -385.3, -292.90000000000015, 5.300000000000004, 161.0, 20.000000000000014, 149.0, -55.600000000000335, 200.0, -21.99999999999996, -255.1000000000003, -238.30000000000044, 200.0, -246.70000000000027, 116.29999999999973, 8.300000000000004, 89.0, 200.0, 20.000000000000014, -18.999999999999766, -160.60000000000002, 162.2, -227.80000000000047, -187.90000000000057, 13.699999999999964, 20.000000000000014, -26.19999999999977, 200.0, -265.6, 200.0, -360.1, 110.89999999999944, 72.19999999999985, -160.60000000000002, -148.00000000000043, -34.599999999999774, -76.60000000000004, 200.0, -82.90000000000086, 20.000000000000014, -318.1000000000002, 94.69999999999997, 20.000000000000014, 20.000000000000014, 198.2, -49.299999999999905, -34.59999999999977, 147.8, -400.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 200.0, 200.0, 188.0, 140.6, -183.69999999999985, -135.40000000000003, 20.000000000000014, 9.499999999999956, 20.000000000000014, 87.49999999999997, 7.3999999999999755, 21.500000000000036, -3.099999999999919, -49.29999999999997, -297.1, -303.4, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.99999999999997], "policy_predator_policy_reward": [184.0, 31.0, 10.0, 6.0, 0.0, 152.0, 0.0, 5.0, 2.0, 0.0, 152.0, 124.0, 0.0, 0.0, 79.0, 29.0, 109.0, 0.0, 80.0, 0.0, 81.0, 0.0, 0.0, 0.0, 78.0, 2.0, 0.0, 0.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 200.0, 0.0, 141.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 115.0, 67.0, 91.0, 0.0, 0.0, 155.0, 48.0, 0.0, 0.0, 0.0, 39.0, 0.0, 0.0, 0.0, 86.0, 79.0, 10.0, 0.0, 0.0, 0.0, 33.0, 0.0, 25.0, 0.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 189.0, 0.0, 0.0, 34.0, 10.0, 0.0, 2.0, 68.0, 91.0, 180.0, 25.0, 0.0, 200.0, 41.0, 10.0, 200.0, 0.0, 12.0, 0.0, 0.0, 0.0, 10.0, 59.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 3.0, 0.0, 0.0, 17.0, 0.0, 0.0, 104.0, 0.0, 0.0, 5.0, 0.0, 0.0, 132.0, 0.0, 0.0, 0.0, 193.0, 189.0, 0.0, 149.0, 13.0, 0.0, 17.0, 36.0, 11.0, 9.0, 57.0, 123.0, 69.0, 58.0, 0.0, 27.0, 37.0, 0.0, 0.0, 22.0, 86.0, 0.0, 69.0, 64.0, 3.0, 0.0, 22.0, 17.0, 134.0, 2.0, 176.0, 181.0, 40.0, 99.0, 105.0, 1.0, 46.0, 0.0, 49.0, 0.0, 148.0, 86.0, 0.0, 0.0, 33.0, 0.0, 26.0, 0.0, 8.0, 200.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 4.0, 74.0, 27.0, 0.0, 5.0, 0.0, 0.0, 12.0, 1.0, 0.0, 74.0, 151.0, 51.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3096028597226113, "mean_inference_ms": 8.76772681884136, "mean_action_processing_ms": 0.7465872545026423, "mean_env_wait_ms": 1.137354659650696, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007620811462402344, "StateBufferConnector_ms": 0.005895376205444336, "ViewRequirementAgentConnector_ms": 0.20031583309173584}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -444.5999999999999, "episode_return_mean": 52.215999999999866, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000, "num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 3.958432026148341, "num_env_steps_trained_throughput_per_sec": 3.958432026148341, "timesteps_total": 592000, "num_env_steps_sampled_lifetime": 592000, "num_agent_steps_sampled_lifetime": 2368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2368000, "timers": {"training_iteration_time_ms": 211918.032, "restore_workers_time_ms": 0.016, "training_step_time_ms": 211917.953, "sample_time_ms": 3470.282, "learn_time_ms": 208420.288, "learn_throughput": 19.192, "synch_weights_time_ms": 22.146}, "counters": {"num_env_steps_sampled": 592000, "num_env_steps_trained": 592000, "num_agent_steps_sampled": 2368000, "num_agent_steps_trained": 2368000}, "done": false, "training_iteration": 148, "trial_id": "3a355_00000", "date": "2024-08-13_05-02-39", "timestamp": 1723539759, "time_this_iter_s": 1010.572164773941, "time_total_s": 13958.792407751083, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fdd8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 13958.792407751083, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 90.005, "ram_util_percent": 83.1525}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8742198639603519, "cur_kl_coeff": 1.925929944387236e-35, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.669654514171459, "policy_loss": -0.000662889775558912, "vf_loss": 2.6703174032862225, "vf_explained_var": 0.012007060662779227, "kl": 0.001644655817811501, "entropy": 0.19823223199478532, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 280665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 48.60947110028494, "cur_kl_coeff": 5.401776438261271e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.700862213921925, "policy_loss": -0.0020888130205175865, "vf_loss": 5.702951039460601, "vf_explained_var": 0.6933000836422835, "kl": 0.0018780607998354192, "entropy": 0.717513016922764, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 280665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -444.5999999999999, "episode_reward_mean": 64.1309999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -1.2595000000000391, "predator_policy": 33.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-92.60000000000014, -145.89999999999986, 40.0000000000003, 150.69999999999882, 2.1000000000000156, -8.699999999999935, 201.09999999999914, -315.6000000000002, 40.0000000000003, 141.99999999999966, 40.0000000000003, 17.69999999999923, 113.09999999999982, 219.99999999999926, 246.7, 226.69999999999948, 219.99999999999926, -285.0, 54.40000000000032, -352.69999999999936, 40.0000000000003, 31.200000000000188, 37.80000000000028, 95.79999999999987, -427.0000000000001, -444.5999999999999, 154.89999999999958, 0.0, 376.0, 211.8999999999993, 96.99999999999993, -32.59999999999976, 187.60000000000008, 235.3, 77.39999999999999, 394.0, 185.9999999999994, 201.09999999999934, 62.399999999999594, 139.7999999999997, 110.19999999999989, 74.80000000000001, 40.0000000000003, -214.3, -138.6000000000002, 193.99999999999926, 146.39999999999966, 197.99999999999937, -313.4000000000008, 80.29999999999998, 151.5999999999996, 326.0, 22.999999999999975, 87.59999999999994, -282.69999999999675, 36.70000000000025, 212.79999999999927, 70.40000000000003, 107.79999999999944, 50.600000000000094, -76.60000000000096, 169.39999999999952, -13.899999999999569, 10.600000000000119, 40.0000000000003, 181.89999999999944, 139.19999999999973, -16.0, 40.0000000000003, 197.99999999999926, 400.0, 332.6, -218.0999999999999, 34.50000000000029, 107.49999999999991, 41.90000000000034, 21.60000000000003, -398.5, 400.0, 219.99999999999926, 40.0000000000003, 129.99999999999974, 40.0000000000003, 204.59999999999934, -78.80000000000118, 352.0, -16.599999999999632, 40.0000000000003, 219.99999999999926, 177.8000000000002, 40.0000000000003, 40.0000000000003, 40.0000000000003, 205.79999999999933, 31.90000000000002, -51.19999999999998, -99.70000000000019, 322.0, 31.200000000000188, 30.800000000000175], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [42.49999999999998, -276.1, -95.50000000000003, -114.40000000000003, 20.000000000000014, 20.000000000000014, 130.69999999999956, 20.000000000000014, 78.49999999999997, -261.4, 145.1, -311.8000000000002, 181.09999999999988, 20.000000000000014, -124.90000000000003, -393.70000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 83.0, 20.000000000000014, 20.000000000000014, 40.09999999999955, -108.39999999999992, -145.90000000000018, 170.0, 20.000000000000014, 200.0, 112.7, 101.00000000000007, 163.1, 38.59999999999982, 20.000000000000014, 200.0, -154.3, -267.7, 20.000000000000014, 34.40000000000016, -208.90000000000023, -332.7999999999999, 20.000000000000014, 20.000000000000014, -32.80000000000002, 20.000000000000014, 17.899999999999984, 17.900000000000013, 173.0, -236.20000000000033, -286.5999999999999, -345.40000000000003, -244.60000000000002, -400.0, -66.10000000000001, 170.0, -400.0, 200.0, 200.0, 164.0, 20.000000000000014, 191.9, 8.0, 20.000000000000014, 20.000000000000014, -118.60000000000045, 76.69999999999996, 110.89999999999998, 131.6, 103.69999999999997, -248.80000000000024, 198.2, 200.0, 191.0, 149.0, 20.000000000000014, 181.1, 20.000000000000014, -198.4, 156.79999999999973, 117.19999999999999, 17.59999999999998, 20.000000000000014, 90.19999999999997, 200.0, -257.2, 20.000000000000014, 20.000000000000014, -211.0, -385.3, -292.90000000000015, 5.300000000000004, 161.0, 20.000000000000014, 149.0, -55.600000000000335, 200.0, -21.99999999999996, -255.1000000000003, -238.30000000000044, 200.0, -246.70000000000027, 116.29999999999973, 8.300000000000004, 89.0, 200.0, 20.000000000000014, -18.999999999999766, -160.60000000000002, 162.2, -227.80000000000047, -187.90000000000057, 13.699999999999964, 20.000000000000014, -26.19999999999977, 200.0, -265.6, 200.0, -360.1, 110.89999999999944, 72.19999999999985, -160.60000000000002, -148.00000000000043, -34.599999999999774, -76.60000000000004, 200.0, -82.90000000000086, 20.000000000000014, -318.1000000000002, 94.69999999999997, 20.000000000000014, 20.000000000000014, 198.2, -49.299999999999905, -34.59999999999977, 147.8, -400.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 200.0, 200.0, 188.0, 140.6, -183.69999999999985, -135.40000000000003, 20.000000000000014, 9.499999999999956, 20.000000000000014, 87.49999999999997, 7.3999999999999755, 21.500000000000036, -3.099999999999919, -49.29999999999997, -297.1, -303.4, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.99999999999997, 20.000000000000014, 20.000000000000014, -9.400000000000023, 200.0, 3.1999999999999615, -190.0000000000005, 128.0, 200.0, 20.000000000000014, -118.60000000000068, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 64.70000000000013, 97.10000000000011, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 182.0, 200.0, -339.09999999999985, -324.4000000000001, 99.19999999999997, 20.000000000000014, -246.70000000000002, 173.0, 110.0, 20.000000000000014, 3.1999999999999775, -131.20000000000005, 29.0], "policy_predator_policy_reward": [0.0, 141.0, 64.0, 0.0, 0.0, 0.0, 0.0, 0.0, 70.0, 115.0, 67.0, 91.0, 0.0, 0.0, 155.0, 48.0, 0.0, 0.0, 0.0, 39.0, 0.0, 0.0, 0.0, 86.0, 79.0, 10.0, 0.0, 0.0, 0.0, 33.0, 0.0, 25.0, 0.0, 0.0, 137.0, 0.0, 0.0, 0.0, 0.0, 189.0, 0.0, 0.0, 34.0, 10.0, 0.0, 2.0, 68.0, 91.0, 180.0, 25.0, 0.0, 200.0, 41.0, 10.0, 200.0, 0.0, 12.0, 0.0, 0.0, 0.0, 10.0, 59.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 3.0, 0.0, 0.0, 17.0, 0.0, 0.0, 104.0, 0.0, 0.0, 5.0, 0.0, 0.0, 132.0, 0.0, 0.0, 0.0, 193.0, 189.0, 0.0, 149.0, 13.0, 0.0, 17.0, 36.0, 11.0, 9.0, 57.0, 123.0, 69.0, 58.0, 0.0, 27.0, 37.0, 0.0, 0.0, 22.0, 86.0, 0.0, 69.0, 64.0, 3.0, 0.0, 22.0, 17.0, 134.0, 2.0, 176.0, 181.0, 40.0, 99.0, 105.0, 1.0, 46.0, 0.0, 49.0, 0.0, 148.0, 86.0, 0.0, 0.0, 33.0, 0.0, 26.0, 0.0, 8.0, 200.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 4.0, 74.0, 27.0, 0.0, 5.0, 0.0, 0.0, 12.0, 1.0, 0.0, 74.0, 151.0, 51.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 108.0, 0.0, 24.0, 0.0, 66.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 171.0, 87.0, 87.0, 127.0, 0.0, 9.0, 30.0, 0.0, 8.0, 61.0, 72.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.3016792922373464, "mean_inference_ms": 8.73211139082099, "mean_action_processing_ms": 0.7443696727332773, "mean_env_wait_ms": 1.1324207102041401, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008370637893676758, "StateBufferConnector_ms": 0.007696986198425293, "ViewRequirementAgentConnector_ms": 0.18830907344818115}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -444.5999999999999, "episode_return_mean": 64.1309999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000, "num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 226.47491866102172, "num_env_steps_trained_throughput_per_sec": 226.47491866102172, "timesteps_total": 596000, "num_env_steps_sampled_lifetime": 596000, "num_agent_steps_sampled_lifetime": 2384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2384000, "timers": {"training_iteration_time_ms": 117759.708, "restore_workers_time_ms": 0.016, "training_step_time_ms": 117759.628, "sample_time_ms": 3155.435, "learn_time_ms": 114578.135, "learn_throughput": 34.911, "synch_weights_time_ms": 21.341}, "counters": {"num_env_steps_sampled": 596000, "num_env_steps_trained": 596000, "num_agent_steps_sampled": 2384000, "num_agent_steps_trained": 2384000}, "done": false, "training_iteration": 149, "trial_id": "3a355_00000", "date": "2024-08-13_05-02-57", "timestamp": 1723539777, "time_this_iter_s": 17.707782983779907, "time_total_s": 13976.500190734863, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52fdf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 13976.500190734863, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 85.24000000000002, "ram_util_percent": 83.244}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9739058875138797, "cur_kl_coeff": 9.62964972193618e-36, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6154387610299246, "policy_loss": -0.002034925330903322, "vf_loss": 3.6174736938779315, "vf_explained_var": 0.006625559941801445, "kl": 0.0020567044266845617, "entropy": 0.21997351804896006, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 282555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 42.4263367717859, "cur_kl_coeff": 2.7008882191306356e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.390972744220148, "policy_loss": -0.0005806584379305599, "vf_loss": 5.391553392990557, "vf_explained_var": 0.5095250580992018, "kl": 0.005023280036791928, "entropy": 0.7241352745149502, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 282555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -444.5999999999999, "episode_reward_mean": 77.7109999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 3.3304999999999616, "predator_policy": 35.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [95.79999999999987, -427.0000000000001, -444.5999999999999, 154.89999999999958, 0.0, 376.0, 211.8999999999993, 96.99999999999993, -32.59999999999976, 187.60000000000008, 235.3, 77.39999999999999, 394.0, 185.9999999999994, 201.09999999999934, 62.399999999999594, 139.7999999999997, 110.19999999999989, 74.80000000000001, 40.0000000000003, -214.3, -138.6000000000002, 193.99999999999926, 146.39999999999966, 197.99999999999937, -313.4000000000008, 80.29999999999998, 151.5999999999996, 326.0, 22.999999999999975, 87.59999999999994, -282.69999999999675, 36.70000000000025, 212.79999999999927, 70.40000000000003, 107.79999999999944, 50.600000000000094, -76.60000000000096, 169.39999999999952, -13.899999999999569, 10.600000000000119, 40.0000000000003, 181.89999999999944, 139.19999999999973, -16.0, 40.0000000000003, 197.99999999999926, 400.0, 332.6, -218.0999999999999, 34.50000000000029, 107.49999999999991, 41.90000000000034, 21.60000000000003, -398.5, 400.0, 219.99999999999926, 40.0000000000003, 129.99999999999974, 40.0000000000003, 204.59999999999934, -78.80000000000118, 352.0, -16.599999999999632, 40.0000000000003, 219.99999999999926, 177.8000000000002, 40.0000000000003, 40.0000000000003, 40.0000000000003, 205.79999999999933, 31.90000000000002, -51.19999999999998, -99.70000000000019, 322.0, 31.200000000000188, 30.800000000000175, 319.60000000000036, 34.50000000000022, -219.50000000000063, 160.90000000000003, 105.69999999999993, 213.49999999999943, 400.0, 212.2999999999993, 128.1999999999997, 38.900000000000276, -138.20000000000041, -31.49999999999985, 127.9999999999998, 16.499999999999936, 25.1000000000002, 217.99999999999926, 205.70000000000005, 159.09999999999957, 185.9999999999994, -433.3999999999999, 175.4999999999996, -147.50000000000006, 223.60000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [173.0, -236.20000000000033, -286.5999999999999, -345.40000000000003, -244.60000000000002, -400.0, -66.10000000000001, 170.0, -400.0, 200.0, 200.0, 164.0, 20.000000000000014, 191.9, 8.0, 20.000000000000014, 20.000000000000014, -118.60000000000045, 76.69999999999996, 110.89999999999998, 131.6, 103.69999999999997, -248.80000000000024, 198.2, 200.0, 191.0, 149.0, 20.000000000000014, 181.1, 20.000000000000014, -198.4, 156.79999999999973, 117.19999999999999, 17.59999999999998, 20.000000000000014, 90.19999999999997, 200.0, -257.2, 20.000000000000014, 20.000000000000014, -211.0, -385.3, -292.90000000000015, 5.300000000000004, 161.0, 20.000000000000014, 149.0, -55.600000000000335, 200.0, -21.99999999999996, -255.1000000000003, -238.30000000000044, 200.0, -246.70000000000027, 116.29999999999973, 8.300000000000004, 89.0, 200.0, 20.000000000000014, -18.999999999999766, -160.60000000000002, 162.2, -227.80000000000047, -187.90000000000057, 13.699999999999964, 20.000000000000014, -26.19999999999977, 200.0, -265.6, 200.0, -360.1, 110.89999999999944, 72.19999999999985, -160.60000000000002, -148.00000000000043, -34.599999999999774, -76.60000000000004, 200.0, -82.90000000000086, 20.000000000000014, -318.1000000000002, 94.69999999999997, 20.000000000000014, 20.000000000000014, 198.2, -49.299999999999905, -34.59999999999977, 147.8, -400.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 200.0, 200.0, 188.0, 140.6, -183.69999999999985, -135.40000000000003, 20.000000000000014, 9.499999999999956, 20.000000000000014, 87.49999999999997, 7.3999999999999755, 21.500000000000036, -3.099999999999919, -49.29999999999997, -297.1, -303.4, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.99999999999997, 20.000000000000014, 20.000000000000014, -9.400000000000023, 200.0, 3.1999999999999615, -190.0000000000005, 128.0, 200.0, 20.000000000000014, -118.60000000000068, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 64.70000000000013, 97.10000000000011, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 182.0, 200.0, -339.09999999999985, -324.4000000000001, 99.19999999999997, 20.000000000000014, -246.70000000000002, 173.0, 110.0, 20.000000000000014, 3.1999999999999775, -131.20000000000005, 29.0, 131.5999999999999, 182.0, 9.499999999999964, 20.000000000000014, -381.1, -93.39999999999986, -93.09999999999994, 164.0, 85.69999999999997, 20.000000000000014, -74.50000000000061, 200.0, 200.0, 200.0, 200.0, 5.299999999999963, 1.0999999999999692, 118.09999999999998, 20.000000000000014, 17.899999999999988, 20.000000000000014, -320.2, 20.000000000000014, -116.50000000000003, 20.000000000000014, 62.0, -74.5000000000006, 20.000000000000014, -112.30000000000004, 7.399999999999966, 197.0, 20.000000000000014, 200.0, -280.3, 175.4, -49.29999999999981, 149.0, 20.000000000000014, -387.4, -274.0, 200.0, -116.49999999999991, -246.70000000000002, -143.8, 104.59999999999998, 118.99999999999999], "policy_predator_policy_reward": [68.0, 91.0, 180.0, 25.0, 0.0, 200.0, 41.0, 10.0, 200.0, 0.0, 12.0, 0.0, 0.0, 0.0, 10.0, 59.0, 66.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 3.0, 0.0, 0.0, 17.0, 0.0, 0.0, 104.0, 0.0, 0.0, 5.0, 0.0, 0.0, 132.0, 0.0, 0.0, 0.0, 193.0, 189.0, 0.0, 149.0, 13.0, 0.0, 17.0, 36.0, 11.0, 9.0, 57.0, 123.0, 69.0, 58.0, 0.0, 27.0, 37.0, 0.0, 0.0, 22.0, 86.0, 0.0, 69.0, 64.0, 3.0, 0.0, 22.0, 17.0, 134.0, 2.0, 176.0, 181.0, 40.0, 99.0, 105.0, 1.0, 46.0, 0.0, 49.0, 0.0, 148.0, 86.0, 0.0, 0.0, 33.0, 0.0, 26.0, 0.0, 8.0, 200.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 4.0, 74.0, 27.0, 0.0, 5.0, 0.0, 0.0, 12.0, 1.0, 0.0, 74.0, 151.0, 51.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 108.0, 0.0, 24.0, 0.0, 66.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 171.0, 87.0, 87.0, 127.0, 0.0, 9.0, 30.0, 0.0, 8.0, 61.0, 72.0, 0.0, 6.0, 0.0, 5.0, 121.0, 134.0, 90.0, 0.0, 0.0, 0.0, 45.0, 43.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 162.0, 65.0, 0.0, 46.0, 0.0, 40.0, 31.0, 61.0, 69.0, 0.0, 1.0, 143.0, 143.0, 33.0, 0.0, 17.0, 0.0, 195.0, 33.0, 36.0, 56.0, 116.0, 127.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2919578947739088, "mean_inference_ms": 8.638424846654551, "mean_action_processing_ms": 0.7423362131176663, "mean_env_wait_ms": 1.169710343093424, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00621187686920166, "StateBufferConnector_ms": 0.007346630096435547, "ViewRequirementAgentConnector_ms": 0.17101716995239258}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -444.5999999999999, "episode_return_mean": 77.7109999999999, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000, "num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.62026822167195, "num_env_steps_trained_throughput_per_sec": 200.62026822167195, "timesteps_total": 600000, "num_env_steps_sampled_lifetime": 600000, "num_agent_steps_sampled_lifetime": 2400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2400000, "timers": {"training_iteration_time_ms": 117045.63, "restore_workers_time_ms": 0.016, "training_step_time_ms": 117045.55, "sample_time_ms": 2284.638, "learn_time_ms": 114734.64, "learn_throughput": 34.863, "synch_weights_time_ms": 22.275}, "counters": {"num_env_steps_sampled": 600000, "num_env_steps_trained": 600000, "num_agent_steps_sampled": 2400000, "num_agent_steps_trained": 2400000}, "done": false, "training_iteration": 150, "trial_id": "3a355_00000", "date": "2024-08-13_05-03-17", "timestamp": 1723539797, "time_this_iter_s": 19.991388082504272, "time_total_s": 13996.491578817368, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fbca60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 13996.491578817368, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 88.07857142857142, "ram_util_percent": 83.27142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9191497739660677, "cur_kl_coeff": 4.81482486096809e-36, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1242580310377495, "policy_loss": -0.0019064655576748822, "vf_loss": 3.1261644968280087, "vf_explained_var": 0.004336774538433741, "kl": 0.0023877357252756245, "entropy": 0.20711350224163166, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 284445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 30.416330202404783, "cur_kl_coeff": 2.7008882191306356e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.758146691196179, "policy_loss": -0.0005931981201111167, "vf_loss": 4.758739896299978, "vf_explained_var": 0.5078313974476365, "kl": 0.0010746574727855363, "entropy": 0.6350665747646301, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 284445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -433.3999999999999, "episode_reward_mean": 82.84599999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 5.977999999999961, "predator_policy": 35.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [74.80000000000001, 40.0000000000003, -214.3, -138.6000000000002, 193.99999999999926, 146.39999999999966, 197.99999999999937, -313.4000000000008, 80.29999999999998, 151.5999999999996, 326.0, 22.999999999999975, 87.59999999999994, -282.69999999999675, 36.70000000000025, 212.79999999999927, 70.40000000000003, 107.79999999999944, 50.600000000000094, -76.60000000000096, 169.39999999999952, -13.899999999999569, 10.600000000000119, 40.0000000000003, 181.89999999999944, 139.19999999999973, -16.0, 40.0000000000003, 197.99999999999926, 400.0, 332.6, -218.0999999999999, 34.50000000000029, 107.49999999999991, 41.90000000000034, 21.60000000000003, -398.5, 400.0, 219.99999999999926, 40.0000000000003, 129.99999999999974, 40.0000000000003, 204.59999999999934, -78.80000000000118, 352.0, -16.599999999999632, 40.0000000000003, 219.99999999999926, 177.8000000000002, 40.0000000000003, 40.0000000000003, 40.0000000000003, 205.79999999999933, 31.90000000000002, -51.19999999999998, -99.70000000000019, 322.0, 31.200000000000188, 30.800000000000175, 319.60000000000036, 34.50000000000022, -219.50000000000063, 160.90000000000003, 105.69999999999993, 213.49999999999943, 400.0, 212.2999999999993, 128.1999999999997, 38.900000000000276, -138.20000000000041, -31.49999999999985, 127.9999999999998, 16.499999999999936, 25.1000000000002, 217.99999999999926, 205.70000000000005, 159.09999999999957, 185.9999999999994, -433.3999999999999, 175.4999999999996, -147.50000000000006, 223.60000000000002, 209.1999999999993, 400.0, -6.0, 53.20000000000005, 315.8999999999999, 218.89999999999927, -314.0000000000004, 396.0, -75.10000000000088, 45.100000000000264, 72.60000000000002, 245.19999999999942, 95.80000000000001, 148.99999999999963, 325.3, 219.99999999999926, -109.8000000000005, -102.59999999999988], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, -257.2, 20.000000000000014, 20.000000000000014, -211.0, -385.3, -292.90000000000015, 5.300000000000004, 161.0, 20.000000000000014, 149.0, -55.600000000000335, 200.0, -21.99999999999996, -255.1000000000003, -238.30000000000044, 200.0, -246.70000000000027, 116.29999999999973, 8.300000000000004, 89.0, 200.0, 20.000000000000014, -18.999999999999766, -160.60000000000002, 162.2, -227.80000000000047, -187.90000000000057, 13.699999999999964, 20.000000000000014, -26.19999999999977, 200.0, -265.6, 200.0, -360.1, 110.89999999999944, 72.19999999999985, -160.60000000000002, -148.00000000000043, -34.599999999999774, -76.60000000000004, 200.0, -82.90000000000086, 20.000000000000014, -318.1000000000002, 94.69999999999997, 20.000000000000014, 20.000000000000014, 198.2, -49.299999999999905, -34.59999999999977, 147.8, -400.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 200.0, 200.0, 188.0, 140.6, -183.69999999999985, -135.40000000000003, 20.000000000000014, 9.499999999999956, 20.000000000000014, 87.49999999999997, 7.3999999999999755, 21.500000000000036, -3.099999999999919, -49.29999999999997, -297.1, -303.4, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.99999999999997, 20.000000000000014, 20.000000000000014, -9.400000000000023, 200.0, 3.1999999999999615, -190.0000000000005, 128.0, 200.0, 20.000000000000014, -118.60000000000068, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 64.70000000000013, 97.10000000000011, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 182.0, 200.0, -339.09999999999985, -324.4000000000001, 99.19999999999997, 20.000000000000014, -246.70000000000002, 173.0, 110.0, 20.000000000000014, 3.1999999999999775, -131.20000000000005, 29.0, 131.5999999999999, 182.0, 9.499999999999964, 20.000000000000014, -381.1, -93.39999999999986, -93.09999999999994, 164.0, 85.69999999999997, 20.000000000000014, -74.50000000000061, 200.0, 200.0, 200.0, 200.0, 5.299999999999963, 1.0999999999999692, 118.09999999999998, 20.000000000000014, 17.899999999999988, 20.000000000000014, -320.2, 20.000000000000014, -116.50000000000003, 20.000000000000014, 62.0, -74.5000000000006, 20.000000000000014, -112.30000000000004, 7.399999999999966, 197.0, 20.000000000000014, 200.0, -280.3, 175.4, -49.29999999999981, 149.0, 20.000000000000014, -387.4, -274.0, 200.0, -116.49999999999991, -246.70000000000002, -143.8, 104.59999999999998, 118.99999999999999, 20.000000000000014, 189.2, 200.0, 200.0, 164.0, -370.0, -181.59999999999988, 129.8, 119.89999999999998, 194.0, 200.0, 17.899999999999988, -223.6000000000002, -303.40000000000026, 194.0, 200.0, 20.000000000000014, -213.1000000000004, -141.7000000000007, 93.79999999999998, -261.4, 200.0, 45.199999999999974, 200.0, 20.000000000000014, 75.79999999999997, -85.0, 176.0, 175.7, 149.6, 20.000000000000014, 200.0, -284.8, 20.000000000000014, -112.30000000000004, -112.30000000000004], "policy_predator_policy_reward": [132.0, 0.0, 0.0, 0.0, 193.0, 189.0, 0.0, 149.0, 13.0, 0.0, 17.0, 36.0, 11.0, 9.0, 57.0, 123.0, 69.0, 58.0, 0.0, 27.0, 37.0, 0.0, 0.0, 22.0, 86.0, 0.0, 69.0, 64.0, 3.0, 0.0, 22.0, 17.0, 134.0, 2.0, 176.0, 181.0, 40.0, 99.0, 105.0, 1.0, 46.0, 0.0, 49.0, 0.0, 148.0, 86.0, 0.0, 0.0, 33.0, 0.0, 26.0, 0.0, 8.0, 200.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 4.0, 74.0, 27.0, 0.0, 5.0, 0.0, 0.0, 12.0, 1.0, 0.0, 74.0, 151.0, 51.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 108.0, 0.0, 24.0, 0.0, 66.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 171.0, 87.0, 87.0, 127.0, 0.0, 9.0, 30.0, 0.0, 8.0, 61.0, 72.0, 0.0, 6.0, 0.0, 5.0, 121.0, 134.0, 90.0, 0.0, 0.0, 0.0, 45.0, 43.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 162.0, 65.0, 0.0, 46.0, 0.0, 40.0, 31.0, 61.0, 69.0, 0.0, 1.0, 143.0, 143.0, 33.0, 0.0, 17.0, 0.0, 195.0, 33.0, 36.0, 56.0, 116.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 200.0, 79.0, 26.0, 2.0, 0.0, 1.0, 0.0, 97.0, 116.0, 0.0, 2.0, 78.0, 40.0, 58.0, 35.0, 134.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 155.0, 63.0, 59.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.284253001571569, "mean_inference_ms": 8.652157024282495, "mean_action_processing_ms": 0.739375864409631, "mean_env_wait_ms": 1.1209120341515983, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006003856658935547, "StateBufferConnector_ms": 0.005774259567260742, "ViewRequirementAgentConnector_ms": 0.17044436931610107}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -433.3999999999999, "episode_return_mean": 82.84599999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000, "num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 241.47358216301643, "num_env_steps_trained_throughput_per_sec": 241.47358216301643, "timesteps_total": 604000, "num_env_steps_sampled_lifetime": 604000, "num_agent_steps_sampled_lifetime": 2416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2416000, "timers": {"training_iteration_time_ms": 116972.0, "restore_workers_time_ms": 0.016, "training_step_time_ms": 116971.925, "sample_time_ms": 2162.931, "learn_time_ms": 114779.826, "learn_throughput": 34.849, "synch_weights_time_ms": 24.86}, "counters": {"num_env_steps_sampled": 604000, "num_env_steps_trained": 604000, "num_agent_steps_sampled": 2416000, "num_agent_steps_trained": 2416000}, "done": false, "training_iteration": 151, "trial_id": "3a355_00000", "date": "2024-08-13_05-03-33", "timestamp": 1723539813, "time_this_iter_s": 16.647886753082275, "time_total_s": 14013.13946557045, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73a6670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14013.13946557045, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 81.23913043478261, "ram_util_percent": 83.55652173913042}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7677886612358548, "cur_kl_coeff": 2.407412430484045e-36, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.747504134026785, "policy_loss": -0.0008417725305580509, "vf_loss": 2.748345908412227, "vf_explained_var": 0.009976553916931152, "kl": 0.0016182739602634433, "entropy": 0.2103853116038615, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 286335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 62.552796454404394, "cur_kl_coeff": 1.3504441095653178e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.251422255884402, "policy_loss": -0.0008369931860003995, "vf_loss": 5.252259256473924, "vf_explained_var": 0.48167369504454277, "kl": 0.0015755481913784118, "entropy": 0.801440754643193, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 286335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -444.5999999999997, "episode_reward_mean": 89.17899999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 12.20449999999997, "predator_policy": 32.385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.600000000000119, 40.0000000000003, 181.89999999999944, 139.19999999999973, -16.0, 40.0000000000003, 197.99999999999926, 400.0, 332.6, -218.0999999999999, 34.50000000000029, 107.49999999999991, 41.90000000000034, 21.60000000000003, -398.5, 400.0, 219.99999999999926, 40.0000000000003, 129.99999999999974, 40.0000000000003, 204.59999999999934, -78.80000000000118, 352.0, -16.599999999999632, 40.0000000000003, 219.99999999999926, 177.8000000000002, 40.0000000000003, 40.0000000000003, 40.0000000000003, 205.79999999999933, 31.90000000000002, -51.19999999999998, -99.70000000000019, 322.0, 31.200000000000188, 30.800000000000175, 319.60000000000036, 34.50000000000022, -219.50000000000063, 160.90000000000003, 105.69999999999993, 213.49999999999943, 400.0, 212.2999999999993, 128.1999999999997, 38.900000000000276, -138.20000000000041, -31.49999999999985, 127.9999999999998, 16.499999999999936, 25.1000000000002, 217.99999999999926, 205.70000000000005, 159.09999999999957, 185.9999999999994, -433.3999999999999, 175.4999999999996, -147.50000000000006, 223.60000000000002, 209.1999999999993, 400.0, -6.0, 53.20000000000005, 315.8999999999999, 218.89999999999927, -314.0000000000004, 396.0, -75.10000000000088, 45.100000000000264, 72.60000000000002, 245.19999999999942, 95.80000000000001, 148.99999999999963, 325.3, 219.99999999999926, -109.8000000000005, -102.59999999999988, 178.29999999999947, 400.0, -41.3999999999998, 305.6, 201.9999999999999, -319.9999999999999, -444.5999999999997, 42.00000000000033, 46.3000000000004, -57.89999999999991, -0.699999999999807, 103.69999999999877, -98.40000000000114, 219.99999999999926, 117.39999999999984, 212.2999999999993, 76.69999999999996, -13.500000000000004, 317.1999999999999, -143.6000000000006, 125.49999999999977, 336.29999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-318.1000000000002, 94.69999999999997, 20.000000000000014, 20.000000000000014, 198.2, -49.299999999999905, -34.59999999999977, 147.8, -400.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 200.0, 200.0, 188.0, 140.6, -183.69999999999985, -135.40000000000003, 20.000000000000014, 9.499999999999956, 20.000000000000014, 87.49999999999997, 7.3999999999999755, 21.500000000000036, -3.099999999999919, -49.29999999999997, -297.1, -303.4, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.99999999999997, 20.000000000000014, 20.000000000000014, -9.400000000000023, 200.0, 3.1999999999999615, -190.0000000000005, 128.0, 200.0, 20.000000000000014, -118.60000000000068, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 64.70000000000013, 97.10000000000011, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 182.0, 200.0, -339.09999999999985, -324.4000000000001, 99.19999999999997, 20.000000000000014, -246.70000000000002, 173.0, 110.0, 20.000000000000014, 3.1999999999999775, -131.20000000000005, 29.0, 131.5999999999999, 182.0, 9.499999999999964, 20.000000000000014, -381.1, -93.39999999999986, -93.09999999999994, 164.0, 85.69999999999997, 20.000000000000014, -74.50000000000061, 200.0, 200.0, 200.0, 200.0, 5.299999999999963, 1.0999999999999692, 118.09999999999998, 20.000000000000014, 17.899999999999988, 20.000000000000014, -320.2, 20.000000000000014, -116.50000000000003, 20.000000000000014, 62.0, -74.5000000000006, 20.000000000000014, -112.30000000000004, 7.399999999999966, 197.0, 20.000000000000014, 200.0, -280.3, 175.4, -49.29999999999981, 149.0, 20.000000000000014, -387.4, -274.0, 200.0, -116.49999999999991, -246.70000000000002, -143.8, 104.59999999999998, 118.99999999999999, 20.000000000000014, 189.2, 200.0, 200.0, 164.0, -370.0, -181.59999999999988, 129.8, 119.89999999999998, 194.0, 200.0, 17.899999999999988, -223.6000000000002, -303.40000000000026, 194.0, 200.0, 20.000000000000014, -213.1000000000004, -141.7000000000007, 93.79999999999998, -261.4, 200.0, 45.199999999999974, 200.0, 20.000000000000014, 75.79999999999997, -85.0, 176.0, 175.7, 149.6, 20.000000000000014, 200.0, -284.8, 20.000000000000014, -112.30000000000004, -112.30000000000004, 77.29999999999947, 32.0, 200.0, 200.0, 20.000000000000014, -135.40000000000035, 164.0, 122.6, 114.49999999999999, 87.49999999999986, -236.20000000000005, -395.79999999999995, -376.89999999999986, -309.6999999999998, -91.00000000000001, 29.000000000000206, 20.000000000000014, 26.300000000000114, -109.0, -82.90000000000049, 20.000000000000014, -57.70000000000042, -19.899999999999785, 104.5999999999994, -173.2000000000005, -89.20000000000066, 20.000000000000014, 200.0, 97.39999999999998, 20.000000000000014, 5.299999999999978, 200.0, 146.89999999999998, -152.20000000000002, 186.5, -400.0, 200.0, 117.19999999999999, -40.900000000000034, -246.70000000000027, 20.000000000000014, 105.49999999999997, 170.3, 149.0], "policy_predator_policy_reward": [148.0, 86.0, 0.0, 0.0, 33.0, 0.0, 26.0, 0.0, 8.0, 200.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 4.0, 74.0, 27.0, 0.0, 5.0, 0.0, 0.0, 12.0, 1.0, 0.0, 74.0, 151.0, 51.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 108.0, 0.0, 24.0, 0.0, 66.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 171.0, 87.0, 87.0, 127.0, 0.0, 9.0, 30.0, 0.0, 8.0, 61.0, 72.0, 0.0, 6.0, 0.0, 5.0, 121.0, 134.0, 90.0, 0.0, 0.0, 0.0, 45.0, 43.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 162.0, 65.0, 0.0, 46.0, 0.0, 40.0, 31.0, 61.0, 69.0, 0.0, 1.0, 143.0, 143.0, 33.0, 0.0, 17.0, 0.0, 195.0, 33.0, 36.0, 56.0, 116.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 200.0, 79.0, 26.0, 2.0, 0.0, 1.0, 0.0, 97.0, 116.0, 0.0, 2.0, 78.0, 40.0, 58.0, 35.0, 134.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 155.0, 63.0, 59.0, 13.0, 56.0, 0.0, 0.0, 74.0, 0.0, 7.0, 12.0, 0.0, 0.0, 198.0, 114.0, 50.0, 192.0, 56.0, 48.0, 0.0, 0.0, 0.0, 134.0, 0.0, 37.0, 0.0, 19.0, 87.0, 77.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 82.0, 0.0, 200.0, 0.0, 0.0, 144.0, 0.0, 0.0, 0.0, 0.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2734992600367696, "mean_inference_ms": 8.609039281151068, "mean_action_processing_ms": 0.7366177785734687, "mean_env_wait_ms": 1.1155590105877087, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006048679351806641, "StateBufferConnector_ms": 0.005665898323059082, "ViewRequirementAgentConnector_ms": 0.16105496883392334}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -444.5999999999997, "episode_return_mean": 89.17899999999987, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000, "num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 253.98894286536503, "num_env_steps_trained_throughput_per_sec": 253.98894286536503, "timesteps_total": 608000, "num_env_steps_sampled_lifetime": 608000, "num_agent_steps_sampled_lifetime": 2432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2432000, "timers": {"training_iteration_time_ms": 116968.391, "restore_workers_time_ms": 0.017, "training_step_time_ms": 116968.326, "sample_time_ms": 2166.328, "learn_time_ms": 114769.909, "learn_throughput": 34.852, "synch_weights_time_ms": 27.531}, "counters": {"num_env_steps_sampled": 608000, "num_env_steps_trained": 608000, "num_agent_steps_sampled": 2432000, "num_agent_steps_trained": 2432000}, "done": false, "training_iteration": 152, "trial_id": "3a355_00000", "date": "2024-08-13_05-03-49", "timestamp": 1723539829, "time_this_iter_s": 15.822160959243774, "time_total_s": 14028.961626529694, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fbcdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14028.961626529694, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 79.24782608695652, "ram_util_percent": 83.4695652173913}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8103694249476705, "cur_kl_coeff": 1.2037062152420225e-36, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.614071373523228, "policy_loss": -0.001960994557492317, "vf_loss": 2.616032361164295, "vf_explained_var": 0.004506087555456414, "kl": 0.0019223760493124146, "entropy": 0.1633727306569064, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 288225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 45.66696456809523, "cur_kl_coeff": 6.752220547826589e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.55457595403863, "policy_loss": 0.00020217859191159723, "vf_loss": 4.554373779372564, "vf_explained_var": 0.4510534783204397, "kl": 0.0013486005040919185, "entropy": 0.6596269803703146, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 288225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -444.5999999999997, "episode_reward_mean": 93.10099999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 11.460499999999957, "predator_policy": 35.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [129.99999999999974, 40.0000000000003, 204.59999999999934, -78.80000000000118, 352.0, -16.599999999999632, 40.0000000000003, 219.99999999999926, 177.8000000000002, 40.0000000000003, 40.0000000000003, 40.0000000000003, 205.79999999999933, 31.90000000000002, -51.19999999999998, -99.70000000000019, 322.0, 31.200000000000188, 30.800000000000175, 319.60000000000036, 34.50000000000022, -219.50000000000063, 160.90000000000003, 105.69999999999993, 213.49999999999943, 400.0, 212.2999999999993, 128.1999999999997, 38.900000000000276, -138.20000000000041, -31.49999999999985, 127.9999999999998, 16.499999999999936, 25.1000000000002, 217.99999999999926, 205.70000000000005, 159.09999999999957, 185.9999999999994, -433.3999999999999, 175.4999999999996, -147.50000000000006, 223.60000000000002, 209.1999999999993, 400.0, -6.0, 53.20000000000005, 315.8999999999999, 218.89999999999927, -314.0000000000004, 396.0, -75.10000000000088, 45.100000000000264, 72.60000000000002, 245.19999999999942, 95.80000000000001, 148.99999999999963, 325.3, 219.99999999999926, -109.8000000000005, -102.59999999999988, 178.29999999999947, 400.0, -41.3999999999998, 305.6, 201.9999999999999, -319.9999999999999, -444.5999999999997, 42.00000000000033, 46.3000000000004, -57.89999999999991, -0.699999999999807, 103.69999999999877, -98.40000000000114, 219.99999999999926, 117.39999999999984, 212.2999999999993, 76.69999999999996, -13.500000000000004, 317.1999999999999, -143.6000000000006, 125.49999999999977, 336.29999999999995, 268.20000000000005, 203.99999999999935, 194.99999999999935, 68.80000000000015, 155.79999999999953, -197.0, 81.19999999999999, 35.600000000000236, 40.0000000000003, 324.3999999999999, 199.99999999999935, 182.09999999999945, -186.10000000000002, -74.40000000000066, 92.89999999999881, 262.29999999999967, -24.29999999999987, 338.90000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 109.99999999999997, 20.000000000000014, 20.000000000000014, -9.400000000000023, 200.0, 3.1999999999999615, -190.0000000000005, 128.0, 200.0, 20.000000000000014, -118.60000000000068, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 64.70000000000013, 97.10000000000011, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 15.799999999999963, 182.0, 200.0, -339.09999999999985, -324.4000000000001, 99.19999999999997, 20.000000000000014, -246.70000000000002, 173.0, 110.0, 20.000000000000014, 3.1999999999999775, -131.20000000000005, 29.0, 131.5999999999999, 182.0, 9.499999999999964, 20.000000000000014, -381.1, -93.39999999999986, -93.09999999999994, 164.0, 85.69999999999997, 20.000000000000014, -74.50000000000061, 200.0, 200.0, 200.0, 200.0, 5.299999999999963, 1.0999999999999692, 118.09999999999998, 20.000000000000014, 17.899999999999988, 20.000000000000014, -320.2, 20.000000000000014, -116.50000000000003, 20.000000000000014, 62.0, -74.5000000000006, 20.000000000000014, -112.30000000000004, 7.399999999999966, 197.0, 20.000000000000014, 200.0, -280.3, 175.4, -49.29999999999981, 149.0, 20.000000000000014, -387.4, -274.0, 200.0, -116.49999999999991, -246.70000000000002, -143.8, 104.59999999999998, 118.99999999999999, 20.000000000000014, 189.2, 200.0, 200.0, 164.0, -370.0, -181.59999999999988, 129.8, 119.89999999999998, 194.0, 200.0, 17.899999999999988, -223.6000000000002, -303.40000000000026, 194.0, 200.0, 20.000000000000014, -213.1000000000004, -141.7000000000007, 93.79999999999998, -261.4, 200.0, 45.199999999999974, 200.0, 20.000000000000014, 75.79999999999997, -85.0, 176.0, 175.7, 149.6, 20.000000000000014, 200.0, -284.8, 20.000000000000014, -112.30000000000004, -112.30000000000004, 77.29999999999947, 32.0, 200.0, 200.0, 20.000000000000014, -135.40000000000035, 164.0, 122.6, 114.49999999999999, 87.49999999999986, -236.20000000000005, -395.79999999999995, -376.89999999999986, -309.6999999999998, -91.00000000000001, 29.000000000000206, 20.000000000000014, 26.300000000000114, -109.0, -82.90000000000049, 20.000000000000014, -57.70000000000042, -19.899999999999785, 104.5999999999994, -173.2000000000005, -89.20000000000066, 20.000000000000014, 200.0, 97.39999999999998, 20.000000000000014, 5.299999999999978, 200.0, 146.89999999999998, -152.20000000000002, 186.5, -400.0, 200.0, 117.19999999999999, -40.900000000000034, -246.70000000000027, 20.000000000000014, 105.49999999999997, 170.3, 149.0, 149.0, 102.19999999999999, 164.0, 20.000000000000014, 200.0, -85.00000000000082, 48.80000000000024, 20.000000000000014, 161.3, -47.499999999999865, -179.5, -347.50000000000006, 184.7, -332.5, 20.000000000000014, 11.59999999999997, 20.000000000000014, 20.000000000000014, 124.39999999999998, 200.0, 20.000000000000014, 170.0, 20.000000000000014, 157.1, -274.0, -192.10000000000002, -223.60000000000048, -35.80000000000018, 20.000000000000014, 71.8999999999996, 62.30000000000012, 200.0, -280.3, 20.000000000000014, 161.0, 164.9], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 108.0, 0.0, 24.0, 0.0, 66.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 171.0, 87.0, 87.0, 127.0, 0.0, 9.0, 30.0, 0.0, 8.0, 61.0, 72.0, 0.0, 6.0, 0.0, 5.0, 121.0, 134.0, 90.0, 0.0, 0.0, 0.0, 45.0, 43.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 162.0, 65.0, 0.0, 46.0, 0.0, 40.0, 31.0, 61.0, 69.0, 0.0, 1.0, 143.0, 143.0, 33.0, 0.0, 17.0, 0.0, 195.0, 33.0, 36.0, 56.0, 116.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 200.0, 79.0, 26.0, 2.0, 0.0, 1.0, 0.0, 97.0, 116.0, 0.0, 2.0, 78.0, 40.0, 58.0, 35.0, 134.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 155.0, 63.0, 59.0, 13.0, 56.0, 0.0, 0.0, 74.0, 0.0, 7.0, 12.0, 0.0, 0.0, 198.0, 114.0, 50.0, 192.0, 56.0, 48.0, 0.0, 0.0, 0.0, 134.0, 0.0, 37.0, 0.0, 19.0, 87.0, 77.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 82.0, 0.0, 200.0, 0.0, 0.0, 144.0, 0.0, 0.0, 0.0, 0.0, 17.0, 17.0, 0.0, 10.0, 10.0, 44.0, 36.0, 0.0, 0.0, 42.0, 0.0, 155.0, 175.0, 176.0, 53.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 5.0, 0.0, 140.0, 140.0, 69.0, 116.0, 0.0, 1.0, 0.0, 0.0, 143.0, 93.0, 0.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2662755602261084, "mean_inference_ms": 8.57557114208777, "mean_action_processing_ms": 0.7347020658486355, "mean_env_wait_ms": 1.1109007325500417, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015450477600097656, "StateBufferConnector_ms": 0.005687594413757324, "ViewRequirementAgentConnector_ms": 0.21317815780639648}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -444.5999999999997, "episode_return_mean": 93.10099999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000, "num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 217.37963361877544, "num_env_steps_trained_throughput_per_sec": 217.37963361877544, "timesteps_total": 612000, "num_env_steps_sampled_lifetime": 612000, "num_agent_steps_sampled_lifetime": 2448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2448000, "timers": {"training_iteration_time_ms": 117050.759, "restore_workers_time_ms": 0.017, "training_step_time_ms": 117050.694, "sample_time_ms": 2324.428, "learn_time_ms": 114694.059, "learn_throughput": 34.875, "synch_weights_time_ms": 27.935}, "counters": {"num_env_steps_sampled": 612000, "num_env_steps_trained": 612000, "num_agent_steps_sampled": 2448000, "num_agent_steps_trained": 2448000}, "done": false, "training_iteration": 153, "trial_id": "3a355_00000", "date": "2024-08-13_05-04-08", "timestamp": 1723539848, "time_this_iter_s": 18.451335906982422, "time_total_s": 14047.412962436676, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73a6820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14047.412962436676, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 79.94615384615386, "ram_util_percent": 83.15384615384616}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.787033870863536, "cur_kl_coeff": 6.018531076210112e-37, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.765794303555968, "policy_loss": -0.0009789938198294117, "vf_loss": 2.766773308269561, "vf_explained_var": 0.006405008343792466, "kl": 0.0010668360829366725, "entropy": 0.1488784657939086, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 290115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 35.21268524496013, "cur_kl_coeff": 3.3761102739132945e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.891361662824318, "policy_loss": 0.00013323233810268225, "vf_loss": 3.8912284465063185, "vf_explained_var": 0.4986849935912581, "kl": 0.001247068049591089, "entropy": 0.6833733345465686, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 290115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -444.5999999999997, "episode_reward_mean": 111.82499999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 19.737499999999958, "predator_policy": 36.175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.800000000000175, 319.60000000000036, 34.50000000000022, -219.50000000000063, 160.90000000000003, 105.69999999999993, 213.49999999999943, 400.0, 212.2999999999993, 128.1999999999997, 38.900000000000276, -138.20000000000041, -31.49999999999985, 127.9999999999998, 16.499999999999936, 25.1000000000002, 217.99999999999926, 205.70000000000005, 159.09999999999957, 185.9999999999994, -433.3999999999999, 175.4999999999996, -147.50000000000006, 223.60000000000002, 209.1999999999993, 400.0, -6.0, 53.20000000000005, 315.8999999999999, 218.89999999999927, -314.0000000000004, 396.0, -75.10000000000088, 45.100000000000264, 72.60000000000002, 245.19999999999942, 95.80000000000001, 148.99999999999963, 325.3, 219.99999999999926, -109.8000000000005, -102.59999999999988, 178.29999999999947, 400.0, -41.3999999999998, 305.6, 201.9999999999999, -319.9999999999999, -444.5999999999997, 42.00000000000033, 46.3000000000004, -57.89999999999991, -0.699999999999807, 103.69999999999877, -98.40000000000114, 219.99999999999926, 117.39999999999984, 212.2999999999993, 76.69999999999996, -13.500000000000004, 317.1999999999999, -143.6000000000006, 125.49999999999977, 336.29999999999995, 268.20000000000005, 203.99999999999935, 194.99999999999935, 68.80000000000015, 155.79999999999953, -197.0, 81.19999999999999, 35.600000000000236, 40.0000000000003, 324.3999999999999, 199.99999999999935, 182.09999999999945, -186.10000000000002, -74.40000000000066, 92.89999999999881, 262.29999999999967, -24.29999999999987, 338.90000000000003, 391.9000000000002, 219.99999999999926, 118.19999999999976, 197.99999999999937, 76.80000000000004, 228.39999999999944, 57.90000000000009, 202.49999999999935, -82.09999999999985, 206.69999999999996, 322.5999999999999, 176.70000000000002, 40.0000000000003, 400.0, 284.8000000000004, 154.29999999999956, 335.70000000000005, 168.99999999999952], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-131.20000000000005, 29.0, 131.5999999999999, 182.0, 9.499999999999964, 20.000000000000014, -381.1, -93.39999999999986, -93.09999999999994, 164.0, 85.69999999999997, 20.000000000000014, -74.50000000000061, 200.0, 200.0, 200.0, 200.0, 5.299999999999963, 1.0999999999999692, 118.09999999999998, 20.000000000000014, 17.899999999999988, 20.000000000000014, -320.2, 20.000000000000014, -116.50000000000003, 20.000000000000014, 62.0, -74.5000000000006, 20.000000000000014, -112.30000000000004, 7.399999999999966, 197.0, 20.000000000000014, 200.0, -280.3, 175.4, -49.29999999999981, 149.0, 20.000000000000014, -387.4, -274.0, 200.0, -116.49999999999991, -246.70000000000002, -143.8, 104.59999999999998, 118.99999999999999, 20.000000000000014, 189.2, 200.0, 200.0, 164.0, -370.0, -181.59999999999988, 129.8, 119.89999999999998, 194.0, 200.0, 17.899999999999988, -223.6000000000002, -303.40000000000026, 194.0, 200.0, 20.000000000000014, -213.1000000000004, -141.7000000000007, 93.79999999999998, -261.4, 200.0, 45.199999999999974, 200.0, 20.000000000000014, 75.79999999999997, -85.0, 176.0, 175.7, 149.6, 20.000000000000014, 200.0, -284.8, 20.000000000000014, -112.30000000000004, -112.30000000000004, 77.29999999999947, 32.0, 200.0, 200.0, 20.000000000000014, -135.40000000000035, 164.0, 122.6, 114.49999999999999, 87.49999999999986, -236.20000000000005, -395.79999999999995, -376.89999999999986, -309.6999999999998, -91.00000000000001, 29.000000000000206, 20.000000000000014, 26.300000000000114, -109.0, -82.90000000000049, 20.000000000000014, -57.70000000000042, -19.899999999999785, 104.5999999999994, -173.2000000000005, -89.20000000000066, 20.000000000000014, 200.0, 97.39999999999998, 20.000000000000014, 5.299999999999978, 200.0, 146.89999999999998, -152.20000000000002, 186.5, -400.0, 200.0, 117.19999999999999, -40.900000000000034, -246.70000000000027, 20.000000000000014, 105.49999999999997, 170.3, 149.0, 149.0, 102.19999999999999, 164.0, 20.000000000000014, 200.0, -85.00000000000082, 48.80000000000024, 20.000000000000014, 161.3, -47.499999999999865, -179.5, -347.50000000000006, 184.7, -332.5, 20.000000000000014, 11.59999999999997, 20.000000000000014, 20.000000000000014, 124.39999999999998, 200.0, 20.000000000000014, 170.0, 20.000000000000014, 157.1, -274.0, -192.10000000000002, -223.60000000000048, -35.80000000000018, 20.000000000000014, 71.8999999999996, 62.30000000000012, 200.0, -280.3, 20.000000000000014, 161.0, 164.9, 200.0, 191.89999999999995, 200.0, 20.000000000000014, 153.2, -85.00000000000009, 20.000000000000014, 167.0, -208.0, 138.79999999999998, 72.19999999999955, 153.2, 77.3, -144.40000000000055, 24.50000000000008, 167.0, -53.50000000000002, -76.60000000000004, -238.3, 200.0, 122.6, 200.0, -322.29999999999995, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 128.89999999999998, 155.89999999999972, 20.000000000000014, 134.29999999999998, 148.7, 167.0, 169.4, -30.399999999999764], "policy_predator_policy_reward": [61.0, 72.0, 0.0, 6.0, 0.0, 5.0, 121.0, 134.0, 90.0, 0.0, 0.0, 0.0, 45.0, 43.0, 0.0, 0.0, 7.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 162.0, 65.0, 0.0, 46.0, 0.0, 40.0, 31.0, 61.0, 69.0, 0.0, 1.0, 143.0, 143.0, 33.0, 0.0, 17.0, 0.0, 195.0, 33.0, 36.0, 56.0, 116.0, 127.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 200.0, 79.0, 26.0, 2.0, 0.0, 1.0, 0.0, 97.0, 116.0, 0.0, 2.0, 78.0, 40.0, 58.0, 35.0, 134.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 155.0, 63.0, 59.0, 13.0, 56.0, 0.0, 0.0, 74.0, 0.0, 7.0, 12.0, 0.0, 0.0, 198.0, 114.0, 50.0, 192.0, 56.0, 48.0, 0.0, 0.0, 0.0, 134.0, 0.0, 37.0, 0.0, 19.0, 87.0, 77.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 82.0, 0.0, 200.0, 0.0, 0.0, 144.0, 0.0, 0.0, 0.0, 0.0, 17.0, 17.0, 0.0, 10.0, 10.0, 44.0, 36.0, 0.0, 0.0, 42.0, 0.0, 155.0, 175.0, 176.0, 53.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 5.0, 0.0, 140.0, 140.0, 69.0, 116.0, 0.0, 1.0, 0.0, 0.0, 143.0, 93.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 11.0, 0.0, 136.0, 10.0, 0.0, 3.0, 86.0, 39.0, 0.0, 11.0, 46.0, 2.0, 122.0, 123.0, 0.0, 0.0, 160.0, 139.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 9.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.259627430278463, "mean_inference_ms": 8.543519558666908, "mean_action_processing_ms": 0.7329422435314186, "mean_env_wait_ms": 1.1064485847252155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014873743057250977, "StateBufferConnector_ms": 0.004076957702636719, "ViewRequirementAgentConnector_ms": 0.24240529537200928}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -444.5999999999997, "episode_return_mean": 111.82499999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000, "num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 228.40495196036028, "num_env_steps_trained_throughput_per_sec": 228.40495196036028, "timesteps_total": 616000, "num_env_steps_sampled_lifetime": 616000, "num_agent_steps_sampled_lifetime": 2464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2464000, "timers": {"training_iteration_time_ms": 117019.704, "restore_workers_time_ms": 0.016, "training_step_time_ms": 117019.638, "sample_time_ms": 2441.822, "learn_time_ms": 114535.827, "learn_throughput": 34.924, "synch_weights_time_ms": 36.943}, "counters": {"num_env_steps_sampled": 616000, "num_env_steps_trained": 616000, "num_agent_steps_sampled": 2464000, "num_agent_steps_trained": 2464000}, "done": false, "training_iteration": 154, "trial_id": "3a355_00000", "date": "2024-08-13_05-04-26", "timestamp": 1723539866, "time_this_iter_s": 17.57988405227661, "time_total_s": 14064.992846488953, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5f9b8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14064.992846488953, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 79.788, "ram_util_percent": 83.39200000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9403195165689029, "cur_kl_coeff": 3.009265538105056e-37, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.355220134800704, "policy_loss": -0.0005785273840138443, "vf_loss": 3.355798655338388, "vf_explained_var": 0.0003293331653352768, "kl": 0.0018391057253598123, "entropy": 0.1565776079104691, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 292005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 62.44343084964172, "cur_kl_coeff": 1.6880551369566472e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.516953071841487, "policy_loss": -0.0010445681646978728, "vf_loss": 5.5179976624786535, "vf_explained_var": 0.11041433152067598, "kl": 0.001027792796798924, "entropy": 0.716718744695502, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 292005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -600.0, "episode_reward_mean": 95.78799999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 12.463999999999952, "predator_policy": 35.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [223.60000000000002, 209.1999999999993, 400.0, -6.0, 53.20000000000005, 315.8999999999999, 218.89999999999927, -314.0000000000004, 396.0, -75.10000000000088, 45.100000000000264, 72.60000000000002, 245.19999999999942, 95.80000000000001, 148.99999999999963, 325.3, 219.99999999999926, -109.8000000000005, -102.59999999999988, 178.29999999999947, 400.0, -41.3999999999998, 305.6, 201.9999999999999, -319.9999999999999, -444.5999999999997, 42.00000000000033, 46.3000000000004, -57.89999999999991, -0.699999999999807, 103.69999999999877, -98.40000000000114, 219.99999999999926, 117.39999999999984, 212.2999999999993, 76.69999999999996, -13.500000000000004, 317.1999999999999, -143.6000000000006, 125.49999999999977, 336.29999999999995, 268.20000000000005, 203.99999999999935, 194.99999999999935, 68.80000000000015, 155.79999999999953, -197.0, 81.19999999999999, 35.600000000000236, 40.0000000000003, 324.3999999999999, 199.99999999999935, 182.09999999999945, -186.10000000000002, -74.40000000000066, 92.89999999999881, 262.29999999999967, -24.29999999999987, 338.90000000000003, 391.9000000000002, 219.99999999999926, 118.19999999999976, 197.99999999999937, 76.80000000000004, 228.39999999999944, 57.90000000000009, 202.49999999999935, -82.09999999999985, 206.69999999999996, 322.5999999999999, 176.70000000000002, 40.0000000000003, 400.0, 284.8000000000004, 154.29999999999956, 335.70000000000005, 168.99999999999952, 194.99999999999994, -545.0, 40.0000000000003, 40.0000000000003, 161.29999999999953, 358.2, 219.99999999999926, 214.3999999999994, -306.5, -111.80000000000027, 233.7999999999997, 87.99999999999972, -600.0, 40.0000000000003, -7.899999999999874, -7.299999999999734, 123.2999999999999, -360.0, -160.20000000000076, 165.79999999999953, 134.4999999999997, 254.19999999999996, 14.69999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [104.59999999999998, 118.99999999999999, 20.000000000000014, 189.2, 200.0, 200.0, 164.0, -370.0, -181.59999999999988, 129.8, 119.89999999999998, 194.0, 200.0, 17.899999999999988, -223.6000000000002, -303.40000000000026, 194.0, 200.0, 20.000000000000014, -213.1000000000004, -141.7000000000007, 93.79999999999998, -261.4, 200.0, 45.199999999999974, 200.0, 20.000000000000014, 75.79999999999997, -85.0, 176.0, 175.7, 149.6, 20.000000000000014, 200.0, -284.8, 20.000000000000014, -112.30000000000004, -112.30000000000004, 77.29999999999947, 32.0, 200.0, 200.0, 20.000000000000014, -135.40000000000035, 164.0, 122.6, 114.49999999999999, 87.49999999999986, -236.20000000000005, -395.79999999999995, -376.89999999999986, -309.6999999999998, -91.00000000000001, 29.000000000000206, 20.000000000000014, 26.300000000000114, -109.0, -82.90000000000049, 20.000000000000014, -57.70000000000042, -19.899999999999785, 104.5999999999994, -173.2000000000005, -89.20000000000066, 20.000000000000014, 200.0, 97.39999999999998, 20.000000000000014, 5.299999999999978, 200.0, 146.89999999999998, -152.20000000000002, 186.5, -400.0, 200.0, 117.19999999999999, -40.900000000000034, -246.70000000000027, 20.000000000000014, 105.49999999999997, 170.3, 149.0, 149.0, 102.19999999999999, 164.0, 20.000000000000014, 200.0, -85.00000000000082, 48.80000000000024, 20.000000000000014, 161.3, -47.499999999999865, -179.5, -347.50000000000006, 184.7, -332.5, 20.000000000000014, 11.59999999999997, 20.000000000000014, 20.000000000000014, 124.39999999999998, 200.0, 20.000000000000014, 170.0, 20.000000000000014, 157.1, -274.0, -192.10000000000002, -223.60000000000048, -35.80000000000018, 20.000000000000014, 71.8999999999996, 62.30000000000012, 200.0, -280.3, 20.000000000000014, 161.0, 164.9, 200.0, 191.89999999999995, 200.0, 20.000000000000014, 153.2, -85.00000000000009, 20.000000000000014, 167.0, -208.0, 138.79999999999998, 72.19999999999955, 153.2, 77.3, -144.40000000000055, 24.50000000000008, 167.0, -53.50000000000002, -76.60000000000004, -238.3, 200.0, 122.6, 200.0, -322.29999999999995, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 128.89999999999998, 155.89999999999972, 20.000000000000014, 134.29999999999998, 148.7, 167.0, 169.4, -30.399999999999764, 71.60000000000012, 106.39999999999998, -355.0, -385.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -162.70000000000064, 200.0, 173.0, 171.2, 20.000000000000014, 200.0, 200.0, -31.599999999999852, -347.5, -274.0, -269.8, 20.000000000000014, 149.6, 54.19999999999965, 20.000000000000014, 2.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, 13.699999999999967, -118.60000000000053, -70.30000000000078, 20.000000000000014, 90.7999999999999, -95.5, -400.0, -159.99999999999994, 15.799999999999992, -357.99999999999955, 20.000000000000014, 144.8, 20.000000000000014, 114.49999999999999, 154.1, 100.09999999999998, -28.299999999999812, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 200.0, 79.0, 26.0, 2.0, 0.0, 1.0, 0.0, 97.0, 116.0, 0.0, 2.0, 78.0, 40.0, 58.0, 35.0, 134.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 155.0, 63.0, 59.0, 13.0, 56.0, 0.0, 0.0, 74.0, 0.0, 7.0, 12.0, 0.0, 0.0, 198.0, 114.0, 50.0, 192.0, 56.0, 48.0, 0.0, 0.0, 0.0, 134.0, 0.0, 37.0, 0.0, 19.0, 87.0, 77.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 82.0, 0.0, 200.0, 0.0, 0.0, 144.0, 0.0, 0.0, 0.0, 0.0, 17.0, 17.0, 0.0, 10.0, 10.0, 44.0, 36.0, 0.0, 0.0, 42.0, 0.0, 155.0, 175.0, 176.0, 53.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 5.0, 0.0, 140.0, 140.0, 69.0, 116.0, 0.0, 1.0, 0.0, 0.0, 143.0, 93.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 11.0, 0.0, 136.0, 10.0, 0.0, 3.0, 86.0, 39.0, 0.0, 11.0, 46.0, 2.0, 122.0, 123.0, 0.0, 0.0, 160.0, 139.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 9.0, 21.0, 17.0, 0.0, 195.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 74.0, 5.0, 9.0, 0.0, 0.0, 46.0, 0.0, 140.0, 175.0, 136.0, 2.0, 0.0, 30.0, 0.0, 66.0, 200.0, 0.0, 0.0, 0.0, 47.0, 50.0, 43.0, 0.0, 31.0, 97.0, 200.0, 0.0, 172.0, 10.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2526191984908412, "mean_inference_ms": 8.50507897598835, "mean_action_processing_ms": 0.7309409584409318, "mean_env_wait_ms": 1.1004367599907423, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014823317527770996, "StateBufferConnector_ms": 0.003934621810913086, "ViewRequirementAgentConnector_ms": 0.24496173858642578}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -600.0, "episode_return_mean": 95.78799999999983, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000, "num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 224.49426650470247, "num_env_steps_trained_throughput_per_sec": 224.49426650470247, "timesteps_total": 620000, "num_env_steps_sampled_lifetime": 620000, "num_agent_steps_sampled_lifetime": 2480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2480000, "timers": {"training_iteration_time_ms": 117066.481, "restore_workers_time_ms": 0.017, "training_step_time_ms": 117066.425, "sample_time_ms": 2486.986, "learn_time_ms": 114538.058, "learn_throughput": 34.923, "synch_weights_time_ms": 36.31}, "counters": {"num_env_steps_sampled": 620000, "num_env_steps_trained": 620000, "num_agent_steps_sampled": 2480000, "num_agent_steps_trained": 2480000}, "done": false, "training_iteration": 155, "trial_id": "3a355_00000", "date": "2024-08-13_05-04-43", "timestamp": 1723539883, "time_this_iter_s": 17.87945532798767, "time_total_s": 14082.87230181694, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fd6700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14082.87230181694, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 79.42800000000001, "ram_util_percent": 83.29199999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1231624872596175, "cur_kl_coeff": 1.504632769052528e-37, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.209410723555025, "policy_loss": -0.0012231764684199657, "vf_loss": 3.2106338977182984, "vf_explained_var": 0.013789847635087513, "kl": 0.0011658714330792007, "entropy": 0.153805051921379, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 293895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 55.0552143875884, "cur_kl_coeff": 8.440275684783236e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.649592172027265, "policy_loss": -0.0014939546514864243, "vf_loss": 5.651086129839459, "vf_explained_var": 0.3781514544650991, "kl": 0.00212633030275976, "entropy": 0.7937082014071247, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 293895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -600.0, "episode_reward_mean": 75.23299999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -2.453500000000039, "predator_policy": 40.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [305.6, 201.9999999999999, -319.9999999999999, -444.5999999999997, 42.00000000000033, 46.3000000000004, -57.89999999999991, -0.699999999999807, 103.69999999999877, -98.40000000000114, 219.99999999999926, 117.39999999999984, 212.2999999999993, 76.69999999999996, -13.500000000000004, 317.1999999999999, -143.6000000000006, 125.49999999999977, 336.29999999999995, 268.20000000000005, 203.99999999999935, 194.99999999999935, 68.80000000000015, 155.79999999999953, -197.0, 81.19999999999999, 35.600000000000236, 40.0000000000003, 324.3999999999999, 199.99999999999935, 182.09999999999945, -186.10000000000002, -74.40000000000066, 92.89999999999881, 262.29999999999967, -24.29999999999987, 338.90000000000003, 391.9000000000002, 219.99999999999926, 118.19999999999976, 197.99999999999937, 76.80000000000004, 228.39999999999944, 57.90000000000009, 202.49999999999935, -82.09999999999985, 206.69999999999996, 322.5999999999999, 176.70000000000002, 40.0000000000003, 400.0, 284.8000000000004, 154.29999999999956, 335.70000000000005, 168.99999999999952, 194.99999999999994, -545.0, 40.0000000000003, 40.0000000000003, 161.29999999999953, 358.2, 219.99999999999926, 214.3999999999994, -306.5, -111.80000000000027, 233.7999999999997, 87.99999999999972, -600.0, 40.0000000000003, -7.899999999999874, -7.299999999999734, 123.2999999999999, -360.0, -160.20000000000076, 165.79999999999953, 134.4999999999997, 254.19999999999996, 14.69999999999992, 18.599999999999994, -365.19999999999993, -202.00000000000082, 326.19999999999993, -7.7000000000001165, 390.10000000000025, 169.1, -20.700000000000024, -51.79999999999997, 110.29999999999983, -391.7000000000003, 61.400000000000354, 107.99999999999983, 12.499999999999988, 148.89999999999958, -248.39999999999995, 67.00000000000017, 110.29999999999973, -16.399999999999565, 219.99999999999926, 189.19999999999942, 215.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [164.0, 122.6, 114.49999999999999, 87.49999999999986, -236.20000000000005, -395.79999999999995, -376.89999999999986, -309.6999999999998, -91.00000000000001, 29.000000000000206, 20.000000000000014, 26.300000000000114, -109.0, -82.90000000000049, 20.000000000000014, -57.70000000000042, -19.899999999999785, 104.5999999999994, -173.2000000000005, -89.20000000000066, 20.000000000000014, 200.0, 97.39999999999998, 20.000000000000014, 5.299999999999978, 200.0, 146.89999999999998, -152.20000000000002, 186.5, -400.0, 200.0, 117.19999999999999, -40.900000000000034, -246.70000000000027, 20.000000000000014, 105.49999999999997, 170.3, 149.0, 149.0, 102.19999999999999, 164.0, 20.000000000000014, 200.0, -85.00000000000082, 48.80000000000024, 20.000000000000014, 161.3, -47.499999999999865, -179.5, -347.50000000000006, 184.7, -332.5, 20.000000000000014, 11.59999999999997, 20.000000000000014, 20.000000000000014, 124.39999999999998, 200.0, 20.000000000000014, 170.0, 20.000000000000014, 157.1, -274.0, -192.10000000000002, -223.60000000000048, -35.80000000000018, 20.000000000000014, 71.8999999999996, 62.30000000000012, 200.0, -280.3, 20.000000000000014, 161.0, 164.9, 200.0, 191.89999999999995, 200.0, 20.000000000000014, 153.2, -85.00000000000009, 20.000000000000014, 167.0, -208.0, 138.79999999999998, 72.19999999999955, 153.2, 77.3, -144.40000000000055, 24.50000000000008, 167.0, -53.50000000000002, -76.60000000000004, -238.3, 200.0, 122.6, 200.0, -322.29999999999995, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 128.89999999999998, 155.89999999999972, 20.000000000000014, 134.29999999999998, 148.7, 167.0, 169.4, -30.399999999999764, 71.60000000000012, 106.39999999999998, -355.0, -385.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -162.70000000000064, 200.0, 173.0, 171.2, 20.000000000000014, 200.0, 200.0, -31.599999999999852, -347.5, -274.0, -269.8, 20.000000000000014, 149.6, 54.19999999999965, 20.000000000000014, 2.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, 13.699999999999967, -118.60000000000053, -70.30000000000078, 20.000000000000014, 90.7999999999999, -95.5, -400.0, -159.99999999999994, 15.799999999999992, -357.99999999999955, 20.000000000000014, 144.8, 20.000000000000014, 114.49999999999999, 154.1, 100.09999999999998, -28.299999999999812, 20.000000000000014, -2.20000000000001, -68.20000000000005, -341.2, -195.99999999999997, -21.999999999999744, -400.0, 126.19999999999999, 200.0, -73.0, -57.699999999999996, 190.09999999999994, 200.0, 183.8, -393.7, 119.89999999999998, -286.6, -347.5000000000001, 106.69999999999968, 115.4, -45.09999999999981, -238.29999999999995, -324.4000000000002, 42.50000000000017, 17.899999999999988, 199.1, -192.10000000000014, -32.49999999999977, 20.000000000000014, 20.000000000000014, 128.89999999999998, -219.4, -190.00000000000034, -46.0, 20.000000000000014, 141.4999999999997, -299.2, 26.300000000000075, -99.70000000000078, 20.000000000000014, 200.0, 167.0, 3.1999999999999615, 47.00000000000024, 149.0], "policy_predator_policy_reward": [7.0, 12.0, 0.0, 0.0, 198.0, 114.0, 50.0, 192.0, 56.0, 48.0, 0.0, 0.0, 0.0, 134.0, 0.0, 37.0, 0.0, 19.0, 87.0, 77.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 82.0, 0.0, 200.0, 0.0, 0.0, 144.0, 0.0, 0.0, 0.0, 0.0, 17.0, 17.0, 0.0, 10.0, 10.0, 44.0, 36.0, 0.0, 0.0, 42.0, 0.0, 155.0, 175.0, 176.0, 53.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 5.0, 0.0, 140.0, 140.0, 69.0, 116.0, 0.0, 1.0, 0.0, 0.0, 143.0, 93.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 11.0, 0.0, 136.0, 10.0, 0.0, 3.0, 86.0, 39.0, 0.0, 11.0, 46.0, 2.0, 122.0, 123.0, 0.0, 0.0, 160.0, 139.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 9.0, 21.0, 17.0, 0.0, 195.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 74.0, 5.0, 9.0, 0.0, 0.0, 46.0, 0.0, 140.0, 175.0, 136.0, 2.0, 0.0, 30.0, 0.0, 66.0, 200.0, 0.0, 0.0, 0.0, 47.0, 50.0, 43.0, 0.0, 31.0, 97.0, 200.0, 0.0, 172.0, 10.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 47.0, 42.0, 172.0, 0.0, 200.0, 20.0, 0.0, 0.0, 123.0, 0.0, 0.0, 0.0, 193.0, 186.0, 0.0, 146.0, 175.0, 14.0, 31.0, 9.0, 0.0, 171.0, 1.0, 0.0, 0.0, 101.0, 0.0, 25.0, 0.0, 0.0, 33.0, 128.0, 82.0, 11.0, 116.0, 152.0, 57.0, 0.0, 0.0, 0.0, 11.0, 8.0, 10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.292101720555674, "mean_inference_ms": 8.42553925218482, "mean_action_processing_ms": 0.7308975615840209, "mean_env_wait_ms": 1.0987439454623498, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015001893043518066, "StateBufferConnector_ms": 0.00422060489654541, "ViewRequirementAgentConnector_ms": 0.3094029426574707}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -600.0, "episode_return_mean": 75.23299999999983, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000, "num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.61957941203735, "num_env_steps_trained_throughput_per_sec": 210.61957941203735, "timesteps_total": 624000, "num_env_steps_sampled_lifetime": 624000, "num_agent_steps_sampled_lifetime": 2496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2496000, "timers": {"training_iteration_time_ms": 117162.724, "restore_workers_time_ms": 0.017, "training_step_time_ms": 117162.667, "sample_time_ms": 2675.275, "learn_time_ms": 114444.662, "learn_throughput": 34.951, "synch_weights_time_ms": 36.629}, "counters": {"num_env_steps_sampled": 624000, "num_env_steps_trained": 624000, "num_agent_steps_sampled": 2496000, "num_agent_steps_trained": 2496000}, "done": false, "training_iteration": 156, "trial_id": "3a355_00000", "date": "2024-08-13_05-05-03", "timestamp": 1723539903, "time_this_iter_s": 19.07541799545288, "time_total_s": 14101.947719812393, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5556550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14101.947719812393, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 78.64814814814815, "ram_util_percent": 83.34814814814816}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9522122179862683, "cur_kl_coeff": 7.52316384526264e-38, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.789054551704851, "policy_loss": -0.000546185409886733, "vf_loss": 3.789600731582238, "vf_explained_var": 0.003648699402178406, "kl": 0.000780883287454595, "entropy": 0.1431959178752054, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 295785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 53.361830251904394, "cur_kl_coeff": 4.220137842391618e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.631584565349357, "policy_loss": -0.001768802510939105, "vf_loss": 5.633353374874781, "vf_explained_var": 0.3449487667235117, "kl": 0.0020495170644569656, "entropy": 0.648966656333555, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 295785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -600.0, "episode_reward_mean": 78.70699999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -2.5165000000000375, "predator_policy": 41.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [336.29999999999995, 268.20000000000005, 203.99999999999935, 194.99999999999935, 68.80000000000015, 155.79999999999953, -197.0, 81.19999999999999, 35.600000000000236, 40.0000000000003, 324.3999999999999, 199.99999999999935, 182.09999999999945, -186.10000000000002, -74.40000000000066, 92.89999999999881, 262.29999999999967, -24.29999999999987, 338.90000000000003, 391.9000000000002, 219.99999999999926, 118.19999999999976, 197.99999999999937, 76.80000000000004, 228.39999999999944, 57.90000000000009, 202.49999999999935, -82.09999999999985, 206.69999999999996, 322.5999999999999, 176.70000000000002, 40.0000000000003, 400.0, 284.8000000000004, 154.29999999999956, 335.70000000000005, 168.99999999999952, 194.99999999999994, -545.0, 40.0000000000003, 40.0000000000003, 161.29999999999953, 358.2, 219.99999999999926, 214.3999999999994, -306.5, -111.80000000000027, 233.7999999999997, 87.99999999999972, -600.0, 40.0000000000003, -7.899999999999874, -7.299999999999734, 123.2999999999999, -360.0, -160.20000000000076, 165.79999999999953, 134.4999999999997, 254.19999999999996, 14.69999999999992, 18.599999999999994, -365.19999999999993, -202.00000000000082, 326.19999999999993, -7.7000000000001165, 390.10000000000025, 169.1, -20.700000000000024, -51.79999999999997, 110.29999999999983, -391.7000000000003, 61.400000000000354, 107.99999999999983, 12.499999999999988, 148.89999999999958, -248.39999999999995, 67.00000000000017, 110.29999999999973, -16.399999999999565, 219.99999999999926, 189.19999999999942, 215.99999999999926, 123.39999999999978, -253.40000000000003, -361.50000000000006, -459.30000000000007, 97.9999999999994, 219.99999999999926, -72.79999999999998, 56.20000000000027, 40.0000000000003, -146.00000000000057, 394.0, 400.0, 348.70000000000005, 12.500000000000016, 395.5000000000001, 50.60000000000023, 82.30000000000011, 109.19999999999897], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.3, 149.0, 149.0, 102.19999999999999, 164.0, 20.000000000000014, 200.0, -85.00000000000082, 48.80000000000024, 20.000000000000014, 161.3, -47.499999999999865, -179.5, -347.50000000000006, 184.7, -332.5, 20.000000000000014, 11.59999999999997, 20.000000000000014, 20.000000000000014, 124.39999999999998, 200.0, 20.000000000000014, 170.0, 20.000000000000014, 157.1, -274.0, -192.10000000000002, -223.60000000000048, -35.80000000000018, 20.000000000000014, 71.8999999999996, 62.30000000000012, 200.0, -280.3, 20.000000000000014, 161.0, 164.9, 200.0, 191.89999999999995, 200.0, 20.000000000000014, 153.2, -85.00000000000009, 20.000000000000014, 167.0, -208.0, 138.79999999999998, 72.19999999999955, 153.2, 77.3, -144.40000000000055, 24.50000000000008, 167.0, -53.50000000000002, -76.60000000000004, -238.3, 200.0, 122.6, 200.0, -322.29999999999995, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 128.89999999999998, 155.89999999999972, 20.000000000000014, 134.29999999999998, 148.7, 167.0, 169.4, -30.399999999999764, 71.60000000000012, 106.39999999999998, -355.0, -385.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -162.70000000000064, 200.0, 173.0, 171.2, 20.000000000000014, 200.0, 200.0, -31.599999999999852, -347.5, -274.0, -269.8, 20.000000000000014, 149.6, 54.19999999999965, 20.000000000000014, 2.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, 13.699999999999967, -118.60000000000053, -70.30000000000078, 20.000000000000014, 90.7999999999999, -95.5, -400.0, -159.99999999999994, 15.799999999999992, -357.99999999999955, 20.000000000000014, 144.8, 20.000000000000014, 114.49999999999999, 154.1, 100.09999999999998, -28.299999999999812, 20.000000000000014, -2.20000000000001, -68.20000000000005, -341.2, -195.99999999999997, -21.999999999999744, -400.0, 126.19999999999999, 200.0, -73.0, -57.699999999999996, 190.09999999999994, 200.0, 183.8, -393.7, 119.89999999999998, -286.6, -347.5000000000001, 106.69999999999968, 115.4, -45.09999999999981, -238.29999999999995, -324.4000000000002, 42.50000000000017, 17.899999999999988, 199.1, -192.10000000000014, -32.49999999999977, 20.000000000000014, 20.000000000000014, 128.89999999999998, -219.4, -190.00000000000034, -46.0, 20.000000000000014, 141.4999999999997, -299.2, 26.300000000000075, -99.70000000000078, 20.000000000000014, 200.0, 167.0, 3.1999999999999615, 47.00000000000024, 149.0, -10.599999999999914, 74.0, -232.3, -318.09999999999997, -347.5, -379.00000000000006, -282.4, -397.9, 20.000000000000014, -112.0, 200.0, 20.000000000000014, 91.99999999999947, -332.79999999999995, 36.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -364.0, 200.0, 191.0, 200.0, 200.0, 148.7, 200.0, -32.49999999999976, 20.000000000000014, 195.49999999999997, 200.0, 109.99999999999997, -156.40000000000066, 62.29999999999996, 20.000000000000014, -202.60000000000053, 111.7999999999995], "policy_predator_policy_reward": [0.0, 17.0, 17.0, 0.0, 10.0, 10.0, 44.0, 36.0, 0.0, 0.0, 42.0, 0.0, 155.0, 175.0, 176.0, 53.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 5.0, 0.0, 140.0, 140.0, 69.0, 116.0, 0.0, 1.0, 0.0, 0.0, 143.0, 93.0, 0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 11.0, 0.0, 136.0, 10.0, 0.0, 3.0, 86.0, 39.0, 0.0, 11.0, 46.0, 2.0, 122.0, 123.0, 0.0, 0.0, 160.0, 139.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 9.0, 21.0, 17.0, 0.0, 195.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 74.0, 5.0, 9.0, 0.0, 0.0, 46.0, 0.0, 140.0, 175.0, 136.0, 2.0, 0.0, 30.0, 0.0, 66.0, 200.0, 0.0, 0.0, 0.0, 47.0, 50.0, 43.0, 0.0, 31.0, 97.0, 200.0, 0.0, 172.0, 10.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 47.0, 42.0, 172.0, 0.0, 200.0, 20.0, 0.0, 0.0, 123.0, 0.0, 0.0, 0.0, 193.0, 186.0, 0.0, 146.0, 175.0, 14.0, 31.0, 9.0, 0.0, 171.0, 1.0, 0.0, 0.0, 101.0, 0.0, 25.0, 0.0, 0.0, 33.0, 128.0, 82.0, 11.0, 116.0, 152.0, 57.0, 0.0, 0.0, 0.0, 11.0, 8.0, 10.0, 10.0, 18.0, 42.0, 153.0, 144.0, 190.0, 175.0, 21.0, 200.0, 89.0, 101.0, 0.0, 0.0, 156.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 188.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 39.0, 58.0, 0.0, 0.0, 97.0, 103.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2422654474949413, "mean_inference_ms": 8.449644988928387, "mean_action_processing_ms": 0.7289644218847715, "mean_env_wait_ms": 1.0929676798139645, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015062093734741211, "StateBufferConnector_ms": 0.013973236083984375, "ViewRequirementAgentConnector_ms": 0.3392035961151123}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -600.0, "episode_return_mean": 78.70699999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000, "num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 218.98746314546008, "num_env_steps_trained_throughput_per_sec": 218.98746314546008, "timesteps_total": 628000, "num_env_steps_sampled_lifetime": 628000, "num_agent_steps_sampled_lifetime": 2512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2512000, "timers": {"training_iteration_time_ms": 117140.418, "restore_workers_time_ms": 0.023, "training_step_time_ms": 117140.345, "sample_time_ms": 2809.316, "learn_time_ms": 114286.151, "learn_throughput": 35.0, "synch_weights_time_ms": 39.417}, "counters": {"num_env_steps_sampled": 628000, "num_env_steps_trained": 628000, "num_agent_steps_sampled": 2512000, "num_agent_steps_trained": 2512000}, "done": false, "training_iteration": 157, "trial_id": "3a355_00000", "date": "2024-08-13_05-05-22", "timestamp": 1723539922, "time_this_iter_s": 18.352958917617798, "time_total_s": 14120.300678730011, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fd6ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14120.300678730011, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 77.31538461538462, "ram_util_percent": 83.33846153846154}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9345662238342421, "cur_kl_coeff": 3.76158192263132e-38, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.053499090734613, "policy_loss": -0.001794405303471697, "vf_loss": 3.0552934988465887, "vf_explained_var": 0.007358679317292713, "kl": 0.0010013554668929267, "entropy": 0.13056754671707355, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 297675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 37.18588173200214, "cur_kl_coeff": 2.110068921195809e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.996424995023737, "policy_loss": 0.0005525461757782275, "vf_loss": 4.995872439530792, "vf_explained_var": 0.4981878609253616, "kl": 0.000842598449660561, "entropy": 0.615570900821812, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 297675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -600.0, "episode_reward_mean": 72.86299999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -5.138500000000031, "predator_policy": 41.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [338.90000000000003, 391.9000000000002, 219.99999999999926, 118.19999999999976, 197.99999999999937, 76.80000000000004, 228.39999999999944, 57.90000000000009, 202.49999999999935, -82.09999999999985, 206.69999999999996, 322.5999999999999, 176.70000000000002, 40.0000000000003, 400.0, 284.8000000000004, 154.29999999999956, 335.70000000000005, 168.99999999999952, 194.99999999999994, -545.0, 40.0000000000003, 40.0000000000003, 161.29999999999953, 358.2, 219.99999999999926, 214.3999999999994, -306.5, -111.80000000000027, 233.7999999999997, 87.99999999999972, -600.0, 40.0000000000003, -7.899999999999874, -7.299999999999734, 123.2999999999999, -360.0, -160.20000000000076, 165.79999999999953, 134.4999999999997, 254.19999999999996, 14.69999999999992, 18.599999999999994, -365.19999999999993, -202.00000000000082, 326.19999999999993, -7.7000000000001165, 390.10000000000025, 169.1, -20.700000000000024, -51.79999999999997, 110.29999999999983, -391.7000000000003, 61.400000000000354, 107.99999999999983, 12.499999999999988, 148.89999999999958, -248.39999999999995, 67.00000000000017, 110.29999999999973, -16.399999999999565, 219.99999999999926, 189.19999999999942, 215.99999999999926, 123.39999999999978, -253.40000000000003, -361.50000000000006, -459.30000000000007, 97.9999999999994, 219.99999999999926, -72.79999999999998, 56.20000000000027, 40.0000000000003, -146.00000000000057, 394.0, 400.0, 348.70000000000005, 12.500000000000016, 395.5000000000001, 50.60000000000023, 82.30000000000011, 109.19999999999897, 27.0, 230.59999999999917, 166.09999999999954, -180.00000000000065, 288.79999999999984, 310.0, 193.5999999999994, -335.6000000000005, 168.0999999999995, 219.99999999999926, -287.2000000000002, 6.999999999999963, 219.99999999999926, 40.0000000000003, 62.10000000000016, 24.999999999999993, 283.5, -58.59999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [161.0, 164.9, 200.0, 191.89999999999995, 200.0, 20.000000000000014, 153.2, -85.00000000000009, 20.000000000000014, 167.0, -208.0, 138.79999999999998, 72.19999999999955, 153.2, 77.3, -144.40000000000055, 24.50000000000008, 167.0, -53.50000000000002, -76.60000000000004, -238.3, 200.0, 122.6, 200.0, -322.29999999999995, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 128.89999999999998, 155.89999999999972, 20.000000000000014, 134.29999999999998, 148.7, 167.0, 169.4, -30.399999999999764, 71.60000000000012, 106.39999999999998, -355.0, -385.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -162.70000000000064, 200.0, 173.0, 171.2, 20.000000000000014, 200.0, 200.0, -31.599999999999852, -347.5, -274.0, -269.8, 20.000000000000014, 149.6, 54.19999999999965, 20.000000000000014, 2.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, 13.699999999999967, -118.60000000000053, -70.30000000000078, 20.000000000000014, 90.7999999999999, -95.5, -400.0, -159.99999999999994, 15.799999999999992, -357.99999999999955, 20.000000000000014, 144.8, 20.000000000000014, 114.49999999999999, 154.1, 100.09999999999998, -28.299999999999812, 20.000000000000014, -2.20000000000001, -68.20000000000005, -341.2, -195.99999999999997, -21.999999999999744, -400.0, 126.19999999999999, 200.0, -73.0, -57.699999999999996, 190.09999999999994, 200.0, 183.8, -393.7, 119.89999999999998, -286.6, -347.5000000000001, 106.69999999999968, 115.4, -45.09999999999981, -238.29999999999995, -324.4000000000002, 42.50000000000017, 17.899999999999988, 199.1, -192.10000000000014, -32.49999999999977, 20.000000000000014, 20.000000000000014, 128.89999999999998, -219.4, -190.00000000000034, -46.0, 20.000000000000014, 141.4999999999997, -299.2, 26.300000000000075, -99.70000000000078, 20.000000000000014, 200.0, 167.0, 3.1999999999999615, 47.00000000000024, 149.0, -10.599999999999914, 74.0, -232.3, -318.09999999999997, -347.5, -379.00000000000006, -282.4, -397.9, 20.000000000000014, -112.0, 200.0, 20.000000000000014, 91.99999999999947, -332.79999999999995, 36.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -364.0, 200.0, 191.0, 200.0, 200.0, 148.7, 200.0, -32.49999999999976, 20.000000000000014, 195.49999999999997, 200.0, 109.99999999999997, -156.40000000000066, 62.29999999999996, 20.000000000000014, -202.60000000000053, 111.7999999999995, -346.0, 167.0, 32.60000000000023, 197.0, -82.90000000000012, 200.0, 20.000000000000014, -400.0, 179.0, 102.79999999999998, 156.8, 153.2, 200.0, -30.400000000000045, -358.0, -223.60000000000048, 110.0, 28.100000000000147, 200.0, 20.000000000000014, -320.20000000000005, -253.0000000000001, -250.9, 128.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 103.69999999999997, -106.5999999999999, 37.999999999999986, -42.999999999999815, 36.5, 200.0, -139.60000000000042, 5.0000000000000355], "policy_predator_policy_reward": [0.0, 13.0, 0.0, 0.0, 0.0, 0.0, 50.0, 0.0, 11.0, 0.0, 136.0, 10.0, 0.0, 3.0, 86.0, 39.0, 0.0, 11.0, 46.0, 2.0, 122.0, 123.0, 0.0, 0.0, 160.0, 139.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 9.0, 21.0, 17.0, 0.0, 195.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 74.0, 5.0, 9.0, 0.0, 0.0, 46.0, 0.0, 140.0, 175.0, 136.0, 2.0, 0.0, 30.0, 0.0, 66.0, 200.0, 0.0, 0.0, 0.0, 47.0, 50.0, 43.0, 0.0, 31.0, 97.0, 200.0, 0.0, 172.0, 10.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 47.0, 42.0, 172.0, 0.0, 200.0, 20.0, 0.0, 0.0, 123.0, 0.0, 0.0, 0.0, 193.0, 186.0, 0.0, 146.0, 175.0, 14.0, 31.0, 9.0, 0.0, 171.0, 1.0, 0.0, 0.0, 101.0, 0.0, 25.0, 0.0, 0.0, 33.0, 128.0, 82.0, 11.0, 116.0, 152.0, 57.0, 0.0, 0.0, 0.0, 11.0, 8.0, 10.0, 10.0, 18.0, 42.0, 153.0, 144.0, 190.0, 175.0, 21.0, 200.0, 89.0, 101.0, 0.0, 0.0, 156.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 188.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 39.0, 58.0, 0.0, 0.0, 97.0, 103.0, 50.0, 156.0, 0.0, 1.0, 0.0, 49.0, 200.0, 0.0, 0.0, 7.0, 0.0, 0.0, 24.0, 0.0, 180.0, 66.0, 0.0, 30.0, 0.0, 0.0, 148.0, 138.0, 0.0, 129.0, 0.0, 0.0, 0.0, 0.0, 65.0, 0.0, 30.0, 0.0, 0.0, 47.0, 76.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2382109529857757, "mean_inference_ms": 8.426087619218842, "mean_action_processing_ms": 0.7282500757384571, "mean_env_wait_ms": 1.0896528104965117, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0053817033767700195, "StateBufferConnector_ms": 0.014645576477050781, "ViewRequirementAgentConnector_ms": 0.3253822326660156}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -600.0, "episode_return_mean": 72.86299999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000, "num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 209.71419337187183, "num_env_steps_trained_throughput_per_sec": 209.71419337187183, "timesteps_total": 632000, "num_env_steps_sampled_lifetime": 632000, "num_agent_steps_sampled_lifetime": 2528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2528000, "timers": {"training_iteration_time_ms": 17997.665, "restore_workers_time_ms": 0.024, "training_step_time_ms": 17997.59, "sample_time_ms": 2967.033, "learn_time_ms": 14985.209, "learn_throughput": 266.93, "synch_weights_time_ms": 39.869}, "counters": {"num_env_steps_sampled": 632000, "num_env_steps_trained": 632000, "num_agent_steps_sampled": 2528000, "num_agent_steps_trained": 2528000}, "done": false, "training_iteration": 158, "trial_id": "3a355_00000", "date": "2024-08-13_05-05-41", "timestamp": 1723539941, "time_this_iter_s": 19.120203733444214, "time_total_s": 14139.420882463455, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5f9be50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14139.420882463455, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 80.14642857142857, "ram_util_percent": 83.17142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.126042464343959, "cur_kl_coeff": 1.88079096131566e-38, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7019654706672385, "policy_loss": -0.0031115880529223768, "vf_loss": 3.7050770553962264, "vf_explained_var": 0.007807697221715614, "kl": 0.009175808891140898, "entropy": 0.19408268494501946, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 299565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 35.60461274861659, "cur_kl_coeff": 1.0550344605979045e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.553818539210728, "policy_loss": 0.00032111943142597006, "vf_loss": 5.553497417641696, "vf_explained_var": 0.48057449762783355, "kl": 0.0012309435415557215, "entropy": 0.6135863346555246, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 299565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -600.0, "episode_reward_mean": 48.41999999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -22.915000000000035, "predator_policy": 47.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [168.99999999999952, 194.99999999999994, -545.0, 40.0000000000003, 40.0000000000003, 161.29999999999953, 358.2, 219.99999999999926, 214.3999999999994, -306.5, -111.80000000000027, 233.7999999999997, 87.99999999999972, -600.0, 40.0000000000003, -7.899999999999874, -7.299999999999734, 123.2999999999999, -360.0, -160.20000000000076, 165.79999999999953, 134.4999999999997, 254.19999999999996, 14.69999999999992, 18.599999999999994, -365.19999999999993, -202.00000000000082, 326.19999999999993, -7.7000000000001165, 390.10000000000025, 169.1, -20.700000000000024, -51.79999999999997, 110.29999999999983, -391.7000000000003, 61.400000000000354, 107.99999999999983, 12.499999999999988, 148.89999999999958, -248.39999999999995, 67.00000000000017, 110.29999999999973, -16.399999999999565, 219.99999999999926, 189.19999999999942, 215.99999999999926, 123.39999999999978, -253.40000000000003, -361.50000000000006, -459.30000000000007, 97.9999999999994, 219.99999999999926, -72.79999999999998, 56.20000000000027, 40.0000000000003, -146.00000000000057, 394.0, 400.0, 348.70000000000005, 12.500000000000016, 395.5000000000001, 50.60000000000023, 82.30000000000011, 109.19999999999897, 27.0, 230.59999999999917, 166.09999999999954, -180.00000000000065, 288.79999999999984, 310.0, 193.5999999999994, -335.6000000000005, 168.0999999999995, 219.99999999999926, -287.2000000000002, 6.999999999999963, 219.99999999999926, 40.0000000000003, 62.10000000000016, 24.999999999999993, 283.5, -58.59999999999976, 318.9999999999999, 53.500000000000405, 5.3999999999999995, -412.79999999999995, 219.99999999999926, 28.9, 321.70000000000005, 139.19999999999936, -20.40000000000004, 58.300000000000054, 203.99999999999935, 102.10000000000002, 356.0, 7.39999999999999, 64.89999999999941, 19.4, 88.70000000000002, -328.2999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [169.4, -30.399999999999764, 71.60000000000012, 106.39999999999998, -355.0, -385.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -162.70000000000064, 200.0, 173.0, 171.2, 20.000000000000014, 200.0, 200.0, -31.599999999999852, -347.5, -274.0, -269.8, 20.000000000000014, 149.6, 54.19999999999965, 20.000000000000014, 2.0, -400.0, -400.0, 20.000000000000014, 20.000000000000014, 13.699999999999967, -118.60000000000053, -70.30000000000078, 20.000000000000014, 90.7999999999999, -95.5, -400.0, -159.99999999999994, 15.799999999999992, -357.99999999999955, 20.000000000000014, 144.8, 20.000000000000014, 114.49999999999999, 154.1, 100.09999999999998, -28.299999999999812, 20.000000000000014, -2.20000000000001, -68.20000000000005, -341.2, -195.99999999999997, -21.999999999999744, -400.0, 126.19999999999999, 200.0, -73.0, -57.699999999999996, 190.09999999999994, 200.0, 183.8, -393.7, 119.89999999999998, -286.6, -347.5000000000001, 106.69999999999968, 115.4, -45.09999999999981, -238.29999999999995, -324.4000000000002, 42.50000000000017, 17.899999999999988, 199.1, -192.10000000000014, -32.49999999999977, 20.000000000000014, 20.000000000000014, 128.89999999999998, -219.4, -190.00000000000034, -46.0, 20.000000000000014, 141.4999999999997, -299.2, 26.300000000000075, -99.70000000000078, 20.000000000000014, 200.0, 167.0, 3.1999999999999615, 47.00000000000024, 149.0, -10.599999999999914, 74.0, -232.3, -318.09999999999997, -347.5, -379.00000000000006, -282.4, -397.9, 20.000000000000014, -112.0, 200.0, 20.000000000000014, 91.99999999999947, -332.79999999999995, 36.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -364.0, 200.0, 191.0, 200.0, 200.0, 148.7, 200.0, -32.49999999999976, 20.000000000000014, 195.49999999999997, 200.0, 109.99999999999997, -156.40000000000066, 62.29999999999996, 20.000000000000014, -202.60000000000053, 111.7999999999995, -346.0, 167.0, 32.60000000000023, 197.0, -82.90000000000012, 200.0, 20.000000000000014, -400.0, 179.0, 102.79999999999998, 156.8, 153.2, 200.0, -30.400000000000045, -358.0, -223.60000000000048, 110.0, 28.100000000000147, 200.0, 20.000000000000014, -320.20000000000005, -253.0000000000001, -250.9, 128.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 103.69999999999997, -106.5999999999999, 37.999999999999986, -42.999999999999815, 36.5, 200.0, -139.60000000000042, 5.0000000000000355, 118.99999999999999, 200.0, 33.500000000000206, 20.000000000000014, -362.20000000000005, 185.6, -244.59999999999994, -362.2, 20.000000000000014, 200.0, -204.70000000000002, 119.6, 186.5, 135.2, -72.40000000000089, 167.59999999999982, 64.09999999999997, -263.5, 200.0, -288.7000000000001, 20.000000000000014, 176.0, -370.89999999999975, 191.0, 182.0, 158.0, 142.39999999999998, -295.0000000000001, 81.19999999999942, -217.3, -244.60000000000002, 107.0, -259.3000000000002, 197.0, -395.8, -179.5], "policy_predator_policy_reward": [9.0, 21.0, 17.0, 0.0, 195.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 74.0, 5.0, 9.0, 0.0, 0.0, 46.0, 0.0, 140.0, 175.0, 136.0, 2.0, 0.0, 30.0, 0.0, 66.0, 200.0, 0.0, 0.0, 0.0, 47.0, 50.0, 43.0, 0.0, 31.0, 97.0, 200.0, 0.0, 172.0, 10.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 47.0, 42.0, 172.0, 0.0, 200.0, 20.0, 0.0, 0.0, 123.0, 0.0, 0.0, 0.0, 193.0, 186.0, 0.0, 146.0, 175.0, 14.0, 31.0, 9.0, 0.0, 171.0, 1.0, 0.0, 0.0, 101.0, 0.0, 25.0, 0.0, 0.0, 33.0, 128.0, 82.0, 11.0, 116.0, 152.0, 57.0, 0.0, 0.0, 0.0, 11.0, 8.0, 10.0, 10.0, 18.0, 42.0, 153.0, 144.0, 190.0, 175.0, 21.0, 200.0, 89.0, 101.0, 0.0, 0.0, 156.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 188.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 39.0, 58.0, 0.0, 0.0, 97.0, 103.0, 50.0, 156.0, 0.0, 1.0, 0.0, 49.0, 200.0, 0.0, 0.0, 7.0, 0.0, 0.0, 24.0, 0.0, 180.0, 66.0, 0.0, 30.0, 0.0, 0.0, 148.0, 138.0, 0.0, 129.0, 0.0, 0.0, 0.0, 0.0, 65.0, 0.0, 30.0, 0.0, 0.0, 47.0, 76.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 182.0, 4.0, 190.0, 0.0, 0.0, 0.0, 114.0, 0.0, 0.0, 44.0, 0.0, 55.0, 124.0, 0.0, 147.0, 8.0, 0.0, 97.0, 185.0, 10.0, 6.0, 10.0, 150.0, 99.0, 102.0, 31.0, 126.0, 118.0, 33.0, 100.0, 147.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.23465659139742, "mean_inference_ms": 8.403300995433902, "mean_action_processing_ms": 0.7276726350796195, "mean_env_wait_ms": 1.0864421156987796, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010448098182678223, "StateBufferConnector_ms": 0.020531773567199707, "ViewRequirementAgentConnector_ms": 0.3325667381286621}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -600.0, "episode_return_mean": 48.41999999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000, "num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 198.5361340756409, "num_env_steps_trained_throughput_per_sec": 198.5361340756409, "timesteps_total": 636000, "num_env_steps_sampled_lifetime": 636000, "num_agent_steps_sampled_lifetime": 2544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2544000, "timers": {"training_iteration_time_ms": 18246.211, "restore_workers_time_ms": 0.023, "training_step_time_ms": 18246.137, "sample_time_ms": 3091.513, "learn_time_ms": 15109.789, "learn_throughput": 264.729, "synch_weights_time_ms": 39.741}, "counters": {"num_env_steps_sampled": 636000, "num_env_steps_trained": 636000, "num_agent_steps_sampled": 2544000, "num_agent_steps_trained": 2544000}, "done": false, "training_iteration": 159, "trial_id": "3a355_00000", "date": "2024-08-13_05-06-01", "timestamp": 1723539961, "time_this_iter_s": 20.224417686462402, "time_total_s": 14159.645300149918, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73a6700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14159.645300149918, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 81.94285714285715, "ram_util_percent": 83.39642857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9131309176760691, "cur_kl_coeff": 1.88079096131566e-38, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.692660620982054, "policy_loss": -0.0020016748943518865, "vf_loss": 3.6946622970873717, "vf_explained_var": 0.005281944186599166, "kl": 0.001959480668113282, "entropy": 0.16635178750942622, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 301455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 55.02529231656796, "cur_kl_coeff": 5.275172302989523e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.308034878180771, "policy_loss": 0.0006500257436609852, "vf_loss": 6.307384851748351, "vf_explained_var": 0.34877425898950565, "kl": 0.002861030510996375, "entropy": 0.7053385445680568, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 301455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -459.30000000000007, "episode_reward_mean": 63.69599999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -14.66200000000003, "predator_policy": 46.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [326.19999999999993, -7.7000000000001165, 390.10000000000025, 169.1, -20.700000000000024, -51.79999999999997, 110.29999999999983, -391.7000000000003, 61.400000000000354, 107.99999999999983, 12.499999999999988, 148.89999999999958, -248.39999999999995, 67.00000000000017, 110.29999999999973, -16.399999999999565, 219.99999999999926, 189.19999999999942, 215.99999999999926, 123.39999999999978, -253.40000000000003, -361.50000000000006, -459.30000000000007, 97.9999999999994, 219.99999999999926, -72.79999999999998, 56.20000000000027, 40.0000000000003, -146.00000000000057, 394.0, 400.0, 348.70000000000005, 12.500000000000016, 395.5000000000001, 50.60000000000023, 82.30000000000011, 109.19999999999897, 27.0, 230.59999999999917, 166.09999999999954, -180.00000000000065, 288.79999999999984, 310.0, 193.5999999999994, -335.6000000000005, 168.0999999999995, 219.99999999999926, -287.2000000000002, 6.999999999999963, 219.99999999999926, 40.0000000000003, 62.10000000000016, 24.999999999999993, 283.5, -58.59999999999976, 318.9999999999999, 53.500000000000405, 5.3999999999999995, -412.79999999999995, 219.99999999999926, 28.9, 321.70000000000005, 139.19999999999936, -20.40000000000004, 58.300000000000054, 203.99999999999935, 102.10000000000002, 356.0, 7.39999999999999, 64.89999999999941, 19.4, 88.70000000000002, -328.2999999999999, 400.0, 91.89999999999993, 256.4999999999993, 181.2999999999995, 107.49999999999983, -133.69999999999993, -178.90000000000012, 349.2, 175.2999999999995, -106.50000000000006, 16.799999999999965, -317.4, 348.70000000000005, 113.59999999999951, -319.5, 40.0000000000003, 6.199999999999973, 120.5999999999998, 231.69999999999933, 213.09999999999928, -126.10000000000034, 51.30000000000001, -110.80000000000025, -154.7000000000005, 40.70000000000001, -32.199999999999534, 67.90000000000023], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [126.19999999999999, 200.0, -73.0, -57.699999999999996, 190.09999999999994, 200.0, 183.8, -393.7, 119.89999999999998, -286.6, -347.5000000000001, 106.69999999999968, 115.4, -45.09999999999981, -238.29999999999995, -324.4000000000002, 42.50000000000017, 17.899999999999988, 199.1, -192.10000000000014, -32.49999999999977, 20.000000000000014, 20.000000000000014, 128.89999999999998, -219.4, -190.00000000000034, -46.0, 20.000000000000014, 141.4999999999997, -299.2, 26.300000000000075, -99.70000000000078, 20.000000000000014, 200.0, 167.0, 3.1999999999999615, 47.00000000000024, 149.0, -10.599999999999914, 74.0, -232.3, -318.09999999999997, -347.5, -379.00000000000006, -282.4, -397.9, 20.000000000000014, -112.0, 200.0, 20.000000000000014, 91.99999999999947, -332.79999999999995, 36.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -364.0, 200.0, 191.0, 200.0, 200.0, 148.7, 200.0, -32.49999999999976, 20.000000000000014, 195.49999999999997, 200.0, 109.99999999999997, -156.40000000000066, 62.29999999999996, 20.000000000000014, -202.60000000000053, 111.7999999999995, -346.0, 167.0, 32.60000000000023, 197.0, -82.90000000000012, 200.0, 20.000000000000014, -400.0, 179.0, 102.79999999999998, 156.8, 153.2, 200.0, -30.400000000000045, -358.0, -223.60000000000048, 110.0, 28.100000000000147, 200.0, 20.000000000000014, -320.20000000000005, -253.0000000000001, -250.9, 128.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 103.69999999999997, -106.5999999999999, 37.999999999999986, -42.999999999999815, 36.5, 200.0, -139.60000000000042, 5.0000000000000355, 118.99999999999999, 200.0, 33.500000000000206, 20.000000000000014, -362.20000000000005, 185.6, -244.59999999999994, -362.2, 20.000000000000014, 200.0, -204.70000000000002, 119.6, 186.5, 135.2, -72.40000000000089, 167.59999999999982, 64.09999999999997, -263.5, 200.0, -288.7000000000001, 20.000000000000014, 176.0, -370.89999999999975, 191.0, 182.0, 158.0, 142.39999999999998, -295.0000000000001, 81.19999999999942, -217.3, -244.60000000000002, 107.0, -259.3000000000002, 197.0, -395.8, -179.5, 200.0, 200.0, -49.30000000000003, 108.19999999999999, 178.6999999999999, 75.79999999999933, 85.69999999999956, 95.59999999999997, 186.5, -168.99999999999994, -181.60000000000002, -48.09999999999988, -39.39999999999996, -284.5, 189.2, 140.0, -24.099999999999774, 178.4, -54.70000000000002, -122.79999999999995, 20.000000000000014, -257.1999999999989, -305.5, -166.90000000000003, 200.0, 148.7, 11.599999999999964, 47.0, -238.3, -236.2, 20.000000000000014, 20.000000000000014, -295.0, 126.19999999999999, -116.50000000000077, 172.1, 200.0, 31.700000000000117, 20.000000000000014, 190.1, 20.000000000000014, -297.1, -351.7, 200.0, -316.0, 45.199999999999974, -351.7, 20.000000000000014, -215.20000000000002, 137.89999999999998, -72.40000000000089, -17.79999999999974, 46.99999999999997, 20.90000000000003], "policy_predator_policy_reward": [0.0, 0.0, 123.0, 0.0, 0.0, 0.0, 193.0, 186.0, 0.0, 146.0, 175.0, 14.0, 31.0, 9.0, 0.0, 171.0, 1.0, 0.0, 0.0, 101.0, 0.0, 25.0, 0.0, 0.0, 33.0, 128.0, 82.0, 11.0, 116.0, 152.0, 57.0, 0.0, 0.0, 0.0, 11.0, 8.0, 10.0, 10.0, 18.0, 42.0, 153.0, 144.0, 190.0, 175.0, 21.0, 200.0, 89.0, 101.0, 0.0, 0.0, 156.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 188.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 39.0, 58.0, 0.0, 0.0, 97.0, 103.0, 50.0, 156.0, 0.0, 1.0, 0.0, 49.0, 200.0, 0.0, 0.0, 7.0, 0.0, 0.0, 24.0, 0.0, 180.0, 66.0, 0.0, 30.0, 0.0, 0.0, 148.0, 138.0, 0.0, 129.0, 0.0, 0.0, 0.0, 0.0, 65.0, 0.0, 30.0, 0.0, 0.0, 47.0, 76.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 182.0, 4.0, 190.0, 0.0, 0.0, 0.0, 114.0, 0.0, 0.0, 44.0, 0.0, 55.0, 124.0, 0.0, 147.0, 8.0, 0.0, 97.0, 185.0, 10.0, 6.0, 10.0, 150.0, 99.0, 102.0, 31.0, 126.0, 118.0, 33.0, 100.0, 147.0, 0.0, 0.0, 0.0, 33.0, 0.0, 2.0, 0.0, 0.0, 79.0, 11.0, 96.0, 0.0, 145.0, 0.0, 10.0, 10.0, 21.0, 0.0, 0.0, 71.0, 122.0, 132.0, 155.0, 0.0, 0.0, 0.0, 27.0, 28.0, 32.0, 123.0, 0.0, 0.0, 51.0, 124.0, 65.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 151.0, 177.0, 26.0, 146.0, 14.0, 17.0, 160.0, 6.0, 112.0, 39.0, 19.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2748815959829676, "mean_inference_ms": 8.324943714791818, "mean_action_processing_ms": 0.7281696419798852, "mean_env_wait_ms": 1.0841193093691013, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02462613582611084, "StateBufferConnector_ms": 0.03047025203704834, "ViewRequirementAgentConnector_ms": 0.3769712448120117}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": -459.30000000000007, "episode_return_mean": 63.69599999999984, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000, "num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 191.67091438233206, "num_env_steps_trained_throughput_per_sec": 191.67091438233206, "timesteps_total": 640000, "num_env_steps_sampled_lifetime": 640000, "num_agent_steps_sampled_lifetime": 2560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2560000, "timers": {"training_iteration_time_ms": 18339.305, "restore_workers_time_ms": 0.023, "training_step_time_ms": 18339.193, "sample_time_ms": 3255.639, "learn_time_ms": 15039.421, "learn_throughput": 265.968, "synch_weights_time_ms": 38.555}, "counters": {"num_env_steps_sampled": 640000, "num_env_steps_trained": 640000, "num_agent_steps_sampled": 2560000, "num_agent_steps_trained": 2560000}, "done": false, "training_iteration": 160, "trial_id": "3a355_00000", "date": "2024-08-13_05-06-22", "timestamp": 1723539982, "time_this_iter_s": 20.906877040863037, "time_total_s": 14180.55217719078, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5534700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14180.55217719078, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 83.39666666666669, "ram_util_percent": 83.48333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7228569158880168, "cur_kl_coeff": 9.4039548065783e-39, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8692206223805745, "policy_loss": -0.0008393001602223469, "vf_loss": 2.8700599221325427, "vf_explained_var": 0.005830153397151402, "kl": 0.0019397527452959186, "entropy": 0.1438466523414251, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 303345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 47.7886663487664, "cur_kl_coeff": 2.6375861514947613e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.997068296286164, "policy_loss": -0.0010330512747661305, "vf_loss": 4.998101331947972, "vf_explained_var": 0.4267862969920749, "kl": 0.0015506873909440046, "entropy": 0.6376846565298302, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 303345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -459.30000000000007, "episode_reward_mean": 65.64299999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -12.278500000000035, "predator_policy": 45.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [215.99999999999926, 123.39999999999978, -253.40000000000003, -361.50000000000006, -459.30000000000007, 97.9999999999994, 219.99999999999926, -72.79999999999998, 56.20000000000027, 40.0000000000003, -146.00000000000057, 394.0, 400.0, 348.70000000000005, 12.500000000000016, 395.5000000000001, 50.60000000000023, 82.30000000000011, 109.19999999999897, 27.0, 230.59999999999917, 166.09999999999954, -180.00000000000065, 288.79999999999984, 310.0, 193.5999999999994, -335.6000000000005, 168.0999999999995, 219.99999999999926, -287.2000000000002, 6.999999999999963, 219.99999999999926, 40.0000000000003, 62.10000000000016, 24.999999999999993, 283.5, -58.59999999999976, 318.9999999999999, 53.500000000000405, 5.3999999999999995, -412.79999999999995, 219.99999999999926, 28.9, 321.70000000000005, 139.19999999999936, -20.40000000000004, 58.300000000000054, 203.99999999999935, 102.10000000000002, 356.0, 7.39999999999999, 64.89999999999941, 19.4, 88.70000000000002, -328.2999999999999, 400.0, 91.89999999999993, 256.4999999999993, 181.2999999999995, 107.49999999999983, -133.69999999999993, -178.90000000000012, 349.2, 175.2999999999995, -106.50000000000006, 16.799999999999965, -317.4, 348.70000000000005, 113.59999999999951, -319.5, 40.0000000000003, 6.199999999999973, 120.5999999999998, 231.69999999999933, 213.09999999999928, -126.10000000000034, 51.30000000000001, -110.80000000000025, -154.7000000000005, 40.70000000000001, -32.199999999999534, 67.90000000000023, -87.90000000000009, -185.7000000000001, 373.90000000000003, -371.2, 45.700000000000365, 207.99999999999932, 13.199999999999998, 197.99999999999926, 308.2, 313.99999999999994, 50.50000000000036, 17.200000000000422, -10.6, 136.59999999999968, 32.80000000000002, 210.0999999999993, 203.7999999999997, -85.60000000000008], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [47.00000000000024, 149.0, -10.599999999999914, 74.0, -232.3, -318.09999999999997, -347.5, -379.00000000000006, -282.4, -397.9, 20.000000000000014, -112.0, 200.0, 20.000000000000014, 91.99999999999947, -332.79999999999995, 36.19999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -364.0, 200.0, 191.0, 200.0, 200.0, 148.7, 200.0, -32.49999999999976, 20.000000000000014, 195.49999999999997, 200.0, 109.99999999999997, -156.40000000000066, 62.29999999999996, 20.000000000000014, -202.60000000000053, 111.7999999999995, -346.0, 167.0, 32.60000000000023, 197.0, -82.90000000000012, 200.0, 20.000000000000014, -400.0, 179.0, 102.79999999999998, 156.8, 153.2, 200.0, -30.400000000000045, -358.0, -223.60000000000048, 110.0, 28.100000000000147, 200.0, 20.000000000000014, -320.20000000000005, -253.0000000000001, -250.9, 128.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 103.69999999999997, -106.5999999999999, 37.999999999999986, -42.999999999999815, 36.5, 200.0, -139.60000000000042, 5.0000000000000355, 118.99999999999999, 200.0, 33.500000000000206, 20.000000000000014, -362.20000000000005, 185.6, -244.59999999999994, -362.2, 20.000000000000014, 200.0, -204.70000000000002, 119.6, 186.5, 135.2, -72.40000000000089, 167.59999999999982, 64.09999999999997, -263.5, 200.0, -288.7000000000001, 20.000000000000014, 176.0, -370.89999999999975, 191.0, 182.0, 158.0, 142.39999999999998, -295.0000000000001, 81.19999999999942, -217.3, -244.60000000000002, 107.0, -259.3000000000002, 197.0, -395.8, -179.5, 200.0, 200.0, -49.30000000000003, 108.19999999999999, 178.6999999999999, 75.79999999999933, 85.69999999999956, 95.59999999999997, 186.5, -168.99999999999994, -181.60000000000002, -48.09999999999988, -39.39999999999996, -284.5, 189.2, 140.0, -24.099999999999774, 178.4, -54.70000000000002, -122.79999999999995, 20.000000000000014, -257.1999999999989, -305.5, -166.90000000000003, 200.0, 148.7, 11.599999999999964, 47.0, -238.3, -236.2, 20.000000000000014, 20.000000000000014, -295.0, 126.19999999999999, -116.50000000000077, 172.1, 200.0, 31.700000000000117, 20.000000000000014, 190.1, 20.000000000000014, -297.1, -351.7, 200.0, -316.0, 45.199999999999974, -351.7, 20.000000000000014, -215.20000000000002, 137.89999999999998, -72.40000000000089, -17.79999999999974, 46.99999999999997, 20.90000000000003, 36.20000000000016, -255.10000000000002, 14.299999999999613, -400.0, 200.0, 173.9, -189.70000000000002, -368.5, 68.59999999999985, -61.900000000000766, 20.000000000000014, 182.0, 200.0, -374.8, 20.000000000000014, 167.0, 154.1, 154.1, 200.0, 106.99999999999997, 38.00000000000023, -137.50000000000003, -35.79999999999981, 20.000000000000014, -76.60000000000001, 20.000000000000014, 124.39999999999998, -122.80000000000075, 170.0, -299.20000000000005, 1.0999999999999759, 200.0, 139.7, 64.10000000000005, -372.7, 100.09999999999998], "policy_predator_policy_reward": [10.0, 10.0, 18.0, 42.0, 153.0, 144.0, 190.0, 175.0, 21.0, 200.0, 89.0, 101.0, 0.0, 0.0, 156.0, 12.0, 0.0, 0.0, 0.0, 0.0, 10.0, 188.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 0.0, 0.0, 39.0, 58.0, 0.0, 0.0, 97.0, 103.0, 50.0, 156.0, 0.0, 1.0, 0.0, 49.0, 200.0, 0.0, 0.0, 7.0, 0.0, 0.0, 24.0, 0.0, 180.0, 66.0, 0.0, 30.0, 0.0, 0.0, 148.0, 138.0, 0.0, 129.0, 0.0, 0.0, 0.0, 0.0, 65.0, 0.0, 30.0, 0.0, 0.0, 47.0, 76.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 182.0, 4.0, 190.0, 0.0, 0.0, 0.0, 114.0, 0.0, 0.0, 44.0, 0.0, 55.0, 124.0, 0.0, 147.0, 8.0, 0.0, 97.0, 185.0, 10.0, 6.0, 10.0, 150.0, 99.0, 102.0, 31.0, 126.0, 118.0, 33.0, 100.0, 147.0, 0.0, 0.0, 0.0, 33.0, 0.0, 2.0, 0.0, 0.0, 79.0, 11.0, 96.0, 0.0, 145.0, 0.0, 10.0, 10.0, 21.0, 0.0, 0.0, 71.0, 122.0, 132.0, 155.0, 0.0, 0.0, 0.0, 27.0, 28.0, 32.0, 123.0, 0.0, 0.0, 51.0, 124.0, 65.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 151.0, 177.0, 26.0, 146.0, 14.0, 17.0, 160.0, 6.0, 112.0, 39.0, 19.0, 0.0, 0.0, 128.0, 3.0, 0.0, 200.0, 0.0, 0.0, 0.0, 187.0, 39.0, 0.0, 0.0, 6.0, 188.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 7.0, 75.0, 75.0, 33.0, 0.0, 46.0, 0.0, 67.0, 68.0, 147.0, 15.0, 9.0, 0.0, 0.0, 0.0, 184.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2263561644139096, "mean_inference_ms": 8.348694575001574, "mean_action_processing_ms": 0.7263406397412188, "mean_env_wait_ms": 1.0785136947557472, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02638399600982666, "StateBufferConnector_ms": 0.030997753143310547, "ViewRequirementAgentConnector_ms": 0.31997108459472656}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -459.30000000000007, "episode_return_mean": 65.64299999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000, "num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 192.14935070401268, "num_env_steps_trained_throughput_per_sec": 192.14935070401268, "timesteps_total": 644000, "num_env_steps_sampled_lifetime": 644000, "num_agent_steps_sampled_lifetime": 2576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2576000, "timers": {"training_iteration_time_ms": 18764.523, "restore_workers_time_ms": 0.022, "training_step_time_ms": 18764.412, "sample_time_ms": 3301.231, "learn_time_ms": 15421.772, "learn_throughput": 259.374, "synch_weights_time_ms": 36.249}, "counters": {"num_env_steps_sampled": 644000, "num_env_steps_trained": 644000, "num_agent_steps_sampled": 2576000, "num_agent_steps_trained": 2576000}, "done": false, "training_iteration": 161, "trial_id": "3a355_00000", "date": "2024-08-13_05-06-43", "timestamp": 1723540003, "time_this_iter_s": 20.861435890197754, "time_total_s": 14201.413613080978, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5534940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 14201.413613080978, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 82.39999999999998, "ram_util_percent": 83.26896551724138}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7905262929145936, "cur_kl_coeff": 4.70197740328915e-39, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7531206571866598, "policy_loss": -0.0011996944321605264, "vf_loss": 2.7543203468045228, "vf_explained_var": 0.0050336619533559, "kl": 0.001956958047030974, "entropy": 0.1915616365849341, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 305235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 42.2356325539647, "cur_kl_coeff": 1.3187930757473806e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.698609783283617, "policy_loss": -0.00012820218788292358, "vf_loss": 4.698737974141641, "vf_explained_var": 0.40430475404022864, "kl": 0.0011490496337696584, "entropy": 0.5268062466193759, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 305235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -463.49999999999994, "episode_reward_mean": 78.75799999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -2.3110000000000364, "predator_policy": 41.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [109.19999999999897, 27.0, 230.59999999999917, 166.09999999999954, -180.00000000000065, 288.79999999999984, 310.0, 193.5999999999994, -335.6000000000005, 168.0999999999995, 219.99999999999926, -287.2000000000002, 6.999999999999963, 219.99999999999926, 40.0000000000003, 62.10000000000016, 24.999999999999993, 283.5, -58.59999999999976, 318.9999999999999, 53.500000000000405, 5.3999999999999995, -412.79999999999995, 219.99999999999926, 28.9, 321.70000000000005, 139.19999999999936, -20.40000000000004, 58.300000000000054, 203.99999999999935, 102.10000000000002, 356.0, 7.39999999999999, 64.89999999999941, 19.4, 88.70000000000002, -328.2999999999999, 400.0, 91.89999999999993, 256.4999999999993, 181.2999999999995, 107.49999999999983, -133.69999999999993, -178.90000000000012, 349.2, 175.2999999999995, -106.50000000000006, 16.799999999999965, -317.4, 348.70000000000005, 113.59999999999951, -319.5, 40.0000000000003, 6.199999999999973, 120.5999999999998, 231.69999999999933, 213.09999999999928, -126.10000000000034, 51.30000000000001, -110.80000000000025, -154.7000000000005, 40.70000000000001, -32.199999999999534, 67.90000000000023, -87.90000000000009, -185.7000000000001, 373.90000000000003, -371.2, 45.700000000000365, 207.99999999999932, 13.199999999999998, 197.99999999999926, 308.2, 313.99999999999994, 50.50000000000036, 17.200000000000422, -10.6, 136.59999999999968, 32.80000000000002, 210.0999999999993, 203.7999999999997, -85.60000000000008, 243.69999999999968, 346.7, 65.29999999999973, 74.0, 370.30000000000075, 156.1999999999998, 213.9999999999993, -463.49999999999994, 165.89999999999984, 145.19999999999965, 219.99999999999926, 349.1, -20.499999999999545, 40.0000000000003, 40.0000000000003, 291.0999999999997, 40.0000000000003, 178.19999999999948], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-202.60000000000053, 111.7999999999995, -346.0, 167.0, 32.60000000000023, 197.0, -82.90000000000012, 200.0, 20.000000000000014, -400.0, 179.0, 102.79999999999998, 156.8, 153.2, 200.0, -30.400000000000045, -358.0, -223.60000000000048, 110.0, 28.100000000000147, 200.0, 20.000000000000014, -320.20000000000005, -253.0000000000001, -250.9, 128.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 103.69999999999997, -106.5999999999999, 37.999999999999986, -42.999999999999815, 36.5, 200.0, -139.60000000000042, 5.0000000000000355, 118.99999999999999, 200.0, 33.500000000000206, 20.000000000000014, -362.20000000000005, 185.6, -244.59999999999994, -362.2, 20.000000000000014, 200.0, -204.70000000000002, 119.6, 186.5, 135.2, -72.40000000000089, 167.59999999999982, 64.09999999999997, -263.5, 200.0, -288.7000000000001, 20.000000000000014, 176.0, -370.89999999999975, 191.0, 182.0, 158.0, 142.39999999999998, -295.0000000000001, 81.19999999999942, -217.3, -244.60000000000002, 107.0, -259.3000000000002, 197.0, -395.8, -179.5, 200.0, 200.0, -49.30000000000003, 108.19999999999999, 178.6999999999999, 75.79999999999933, 85.69999999999956, 95.59999999999997, 186.5, -168.99999999999994, -181.60000000000002, -48.09999999999988, -39.39999999999996, -284.5, 189.2, 140.0, -24.099999999999774, 178.4, -54.70000000000002, -122.79999999999995, 20.000000000000014, -257.1999999999989, -305.5, -166.90000000000003, 200.0, 148.7, 11.599999999999964, 47.0, -238.3, -236.2, 20.000000000000014, 20.000000000000014, -295.0, 126.19999999999999, -116.50000000000077, 172.1, 200.0, 31.700000000000117, 20.000000000000014, 190.1, 20.000000000000014, -297.1, -351.7, 200.0, -316.0, 45.199999999999974, -351.7, 20.000000000000014, -215.20000000000002, 137.89999999999998, -72.40000000000089, -17.79999999999974, 46.99999999999997, 20.90000000000003, 36.20000000000016, -255.10000000000002, 14.299999999999613, -400.0, 200.0, 173.9, -189.70000000000002, -368.5, 68.59999999999985, -61.900000000000766, 20.000000000000014, 182.0, 200.0, -374.8, 20.000000000000014, 167.0, 154.1, 154.1, 200.0, 106.99999999999997, 38.00000000000023, -137.50000000000003, -35.79999999999981, 20.000000000000014, -76.60000000000001, 20.000000000000014, 124.39999999999998, -122.80000000000075, 170.0, -299.20000000000005, 1.0999999999999759, 200.0, 139.7, 64.10000000000005, -372.7, 100.09999999999998, -130.29999999999993, 200.0, 166.7, 170.0, -22.300000000000004, 11.600000000000009, -184.89999999999995, 131.9, 200.0, 170.2999999999998, 157.7, -95.49999999999994, 191.0, 20.000000000000014, -400.0, -263.5, -126.09999999999997, 182.0, -122.80000000000004, 200.0, 200.0, 20.000000000000014, 163.1, 179.0, 20.000000000000014, -95.50000000000082, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 91.09999999999997, 20.000000000000014, 20.000000000000014, -59.80000000000004, 200.0], "policy_predator_policy_reward": [97.0, 103.0, 50.0, 156.0, 0.0, 1.0, 0.0, 49.0, 200.0, 0.0, 0.0, 7.0, 0.0, 0.0, 24.0, 0.0, 180.0, 66.0, 0.0, 30.0, 0.0, 0.0, 148.0, 138.0, 0.0, 129.0, 0.0, 0.0, 0.0, 0.0, 65.0, 0.0, 30.0, 0.0, 0.0, 47.0, 76.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 182.0, 4.0, 190.0, 0.0, 0.0, 0.0, 114.0, 0.0, 0.0, 44.0, 0.0, 55.0, 124.0, 0.0, 147.0, 8.0, 0.0, 97.0, 185.0, 10.0, 6.0, 10.0, 150.0, 99.0, 102.0, 31.0, 126.0, 118.0, 33.0, 100.0, 147.0, 0.0, 0.0, 0.0, 33.0, 0.0, 2.0, 0.0, 0.0, 79.0, 11.0, 96.0, 0.0, 145.0, 0.0, 10.0, 10.0, 21.0, 0.0, 0.0, 71.0, 122.0, 132.0, 155.0, 0.0, 0.0, 0.0, 27.0, 28.0, 32.0, 123.0, 0.0, 0.0, 51.0, 124.0, 65.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 151.0, 177.0, 26.0, 146.0, 14.0, 17.0, 160.0, 6.0, 112.0, 39.0, 19.0, 0.0, 0.0, 128.0, 3.0, 0.0, 200.0, 0.0, 0.0, 0.0, 187.0, 39.0, 0.0, 0.0, 6.0, 188.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 7.0, 75.0, 75.0, 33.0, 0.0, 46.0, 0.0, 67.0, 68.0, 147.0, 15.0, 9.0, 0.0, 0.0, 0.0, 184.0, 3.0, 87.0, 87.0, 10.0, 0.0, 65.0, 11.0, 110.0, 17.0, 0.0, 0.0, 79.0, 15.0, 3.0, 0.0, 200.0, 0.0, 12.0, 98.0, 0.0, 68.0, 0.0, 0.0, 0.0, 7.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 38.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.222142567259623, "mean_inference_ms": 8.324769244496355, "mean_action_processing_ms": 0.7255236143578361, "mean_env_wait_ms": 1.0751884142197483, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027922630310058594, "StateBufferConnector_ms": 0.021509766578674316, "ViewRequirementAgentConnector_ms": 0.29139840602874756}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -463.49999999999994, "episode_return_mean": 78.75799999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000, "num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.247812875782487, "num_env_steps_trained_throughput_per_sec": 4.247812875782487, "timesteps_total": 648000, "num_env_steps_sampled_lifetime": 648000, "num_agent_steps_sampled_lifetime": 2592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2592000, "timers": {"training_iteration_time_ms": 111355.758, "restore_workers_time_ms": 0.023, "training_step_time_ms": 111355.647, "sample_time_ms": 3367.668, "learn_time_ms": 107948.465, "learn_throughput": 37.055, "synch_weights_time_ms": 34.733}, "counters": {"num_env_steps_sampled": 648000, "num_env_steps_trained": 648000, "num_agent_steps_sampled": 2592000, "num_agent_steps_trained": 2592000}, "done": false, "training_iteration": 162, "trial_id": "3a355_00000", "date": "2024-08-13_05-22-25", "timestamp": 1723540945, "time_this_iter_s": 941.748941898346, "time_total_s": 15143.162554979324, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73a6dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15143.162554979324, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 94.02790697674419, "ram_util_percent": 83.48372093023255}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8474936725088844, "cur_kl_coeff": 2.350988701644575e-39, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0232119528074115, "policy_loss": -0.0010957477199130508, "vf_loss": 3.024307696403019, "vf_explained_var": 0.005136080582936605, "kl": 0.001988553089295375, "entropy": 0.1653009420704274, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 307125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 50.75121742953699, "cur_kl_coeff": 6.593965378736903e-20, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.044201260269004, "policy_loss": -0.0016697715297735558, "vf_loss": 5.045871017849635, "vf_explained_var": 0.5557553652417723, "kl": 0.002326862372826227, "entropy": 0.6087454036114708, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 307125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -522.0, "episode_reward_mean": 79.25199999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -3.4540000000000326, "predator_policy": 43.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-58.59999999999976, 318.9999999999999, 53.500000000000405, 5.3999999999999995, -412.79999999999995, 219.99999999999926, 28.9, 321.70000000000005, 139.19999999999936, -20.40000000000004, 58.300000000000054, 203.99999999999935, 102.10000000000002, 356.0, 7.39999999999999, 64.89999999999941, 19.4, 88.70000000000002, -328.2999999999999, 400.0, 91.89999999999993, 256.4999999999993, 181.2999999999995, 107.49999999999983, -133.69999999999993, -178.90000000000012, 349.2, 175.2999999999995, -106.50000000000006, 16.799999999999965, -317.4, 348.70000000000005, 113.59999999999951, -319.5, 40.0000000000003, 6.199999999999973, 120.5999999999998, 231.69999999999933, 213.09999999999928, -126.10000000000034, 51.30000000000001, -110.80000000000025, -154.7000000000005, 40.70000000000001, -32.199999999999534, 67.90000000000023, -87.90000000000009, -185.7000000000001, 373.90000000000003, -371.2, 45.700000000000365, 207.99999999999932, 13.199999999999998, 197.99999999999926, 308.2, 313.99999999999994, 50.50000000000036, 17.200000000000422, -10.6, 136.59999999999968, 32.80000000000002, 210.0999999999993, 203.7999999999997, -85.60000000000008, 243.69999999999968, 346.7, 65.29999999999973, 74.0, 370.30000000000075, 156.1999999999998, 213.9999999999993, -463.49999999999994, 165.89999999999984, 145.19999999999965, 219.99999999999926, 349.1, -20.499999999999545, 40.0000000000003, 40.0000000000003, 291.0999999999997, 40.0000000000003, 178.19999999999948, 209.19999999999928, 125.29999999999971, 0.9000000000000004, -30.999999999999893, 351.20000000000005, -522.0, -109.80000000000024, 86.89999999999995, 246.79999999999944, 151.7999999999996, -180.00000000000065, 217.2999999999995, 103.29999999999976, 188.3, 68.80000000000022, -23.399999999999828, 355.00000000000006, 359.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-139.60000000000042, 5.0000000000000355, 118.99999999999999, 200.0, 33.500000000000206, 20.000000000000014, -362.20000000000005, 185.6, -244.59999999999994, -362.2, 20.000000000000014, 200.0, -204.70000000000002, 119.6, 186.5, 135.2, -72.40000000000089, 167.59999999999982, 64.09999999999997, -263.5, 200.0, -288.7000000000001, 20.000000000000014, 176.0, -370.89999999999975, 191.0, 182.0, 158.0, 142.39999999999998, -295.0000000000001, 81.19999999999942, -217.3, -244.60000000000002, 107.0, -259.3000000000002, 197.0, -395.8, -179.5, 200.0, 200.0, -49.30000000000003, 108.19999999999999, 178.6999999999999, 75.79999999999933, 85.69999999999956, 95.59999999999997, 186.5, -168.99999999999994, -181.60000000000002, -48.09999999999988, -39.39999999999996, -284.5, 189.2, 140.0, -24.099999999999774, 178.4, -54.70000000000002, -122.79999999999995, 20.000000000000014, -257.1999999999989, -305.5, -166.90000000000003, 200.0, 148.7, 11.599999999999964, 47.0, -238.3, -236.2, 20.000000000000014, 20.000000000000014, -295.0, 126.19999999999999, -116.50000000000077, 172.1, 200.0, 31.700000000000117, 20.000000000000014, 190.1, 20.000000000000014, -297.1, -351.7, 200.0, -316.0, 45.199999999999974, -351.7, 20.000000000000014, -215.20000000000002, 137.89999999999998, -72.40000000000089, -17.79999999999974, 46.99999999999997, 20.90000000000003, 36.20000000000016, -255.10000000000002, 14.299999999999613, -400.0, 200.0, 173.9, -189.70000000000002, -368.5, 68.59999999999985, -61.900000000000766, 20.000000000000014, 182.0, 200.0, -374.8, 20.000000000000014, 167.0, 154.1, 154.1, 200.0, 106.99999999999997, 38.00000000000023, -137.50000000000003, -35.79999999999981, 20.000000000000014, -76.60000000000001, 20.000000000000014, 124.39999999999998, -122.80000000000075, 170.0, -299.20000000000005, 1.0999999999999759, 200.0, 139.7, 64.10000000000005, -372.7, 100.09999999999998, -130.29999999999993, 200.0, 166.7, 170.0, -22.300000000000004, 11.600000000000009, -184.89999999999995, 131.9, 200.0, 170.2999999999998, 157.7, -95.49999999999994, 191.0, 20.000000000000014, -400.0, -263.5, -126.09999999999997, 182.0, -122.80000000000004, 200.0, 200.0, 20.000000000000014, 163.1, 179.0, 20.000000000000014, -95.50000000000082, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 91.09999999999997, 20.000000000000014, 20.000000000000014, -59.80000000000004, 200.0, 54.200000000000195, 155.0, 164.0, -162.7000000000004, -381.1, 191.0, 101.89999999999975, -271.9000000000003, 153.2, 197.0, -362.2, -374.8, -400.0, 90.19999999999976, 200.0, -234.09999999999988, 45.80000000000008, 200.0, -110.20000000000003, 200.0, 20.000000000000014, -400.0, 176.6, 40.70000000000007, 170.0, -162.7000000000006, -393.7, 200.0, 20.000000000000014, 48.800000000000004, 11.600000000000009, -85.00000000000003, 200.0, 155.0, 170.0, 173.0], "policy_predator_policy_reward": [76.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 182.0, 4.0, 190.0, 0.0, 0.0, 0.0, 114.0, 0.0, 0.0, 44.0, 0.0, 55.0, 124.0, 0.0, 147.0, 8.0, 0.0, 97.0, 185.0, 10.0, 6.0, 10.0, 150.0, 99.0, 102.0, 31.0, 126.0, 118.0, 33.0, 100.0, 147.0, 0.0, 0.0, 0.0, 33.0, 0.0, 2.0, 0.0, 0.0, 79.0, 11.0, 96.0, 0.0, 145.0, 0.0, 10.0, 10.0, 21.0, 0.0, 0.0, 71.0, 122.0, 132.0, 155.0, 0.0, 0.0, 0.0, 27.0, 28.0, 32.0, 123.0, 0.0, 0.0, 51.0, 124.0, 65.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 151.0, 177.0, 26.0, 146.0, 14.0, 17.0, 160.0, 6.0, 112.0, 39.0, 19.0, 0.0, 0.0, 128.0, 3.0, 0.0, 200.0, 0.0, 0.0, 0.0, 187.0, 39.0, 0.0, 0.0, 6.0, 188.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 7.0, 75.0, 75.0, 33.0, 0.0, 46.0, 0.0, 67.0, 68.0, 147.0, 15.0, 9.0, 0.0, 0.0, 0.0, 184.0, 3.0, 87.0, 87.0, 10.0, 0.0, 65.0, 11.0, 110.0, 17.0, 0.0, 0.0, 79.0, 15.0, 3.0, 0.0, 200.0, 0.0, 12.0, 98.0, 0.0, 68.0, 0.0, 0.0, 0.0, 7.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 66.0, 58.0, 127.0, 64.0, 139.0, 0.0, 0.0, 1.0, 182.0, 33.0, 0.0, 200.0, 120.0, 1.0, 1.0, 0.0, 62.0, 0.0, 200.0, 0.0, 0.0, 0.0, 60.0, 36.0, 185.0, 197.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2173818181382505, "mean_inference_ms": 8.299837997581585, "mean_action_processing_ms": 0.7245216551562405, "mean_env_wait_ms": 1.071601441917934, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027751564979553223, "StateBufferConnector_ms": 0.02064955234527588, "ViewRequirementAgentConnector_ms": 0.2465531826019287}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -522.0, "episode_return_mean": 79.25199999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000, "num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 209.07824052675724, "num_env_steps_trained_throughput_per_sec": 209.07824052675724, "timesteps_total": 652000, "num_env_steps_sampled_lifetime": 652000, "num_agent_steps_sampled_lifetime": 2608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2608000, "timers": {"training_iteration_time_ms": 111428.818, "restore_workers_time_ms": 0.022, "training_step_time_ms": 111428.707, "sample_time_ms": 3291.115, "learn_time_ms": 108097.609, "learn_throughput": 37.004, "synch_weights_time_ms": 35.017}, "counters": {"num_env_steps_sampled": 652000, "num_env_steps_trained": 652000, "num_agent_steps_sampled": 2608000, "num_agent_steps_trained": 2608000}, "done": false, "training_iteration": 163, "trial_id": "3a355_00000", "date": "2024-08-13_05-22-44", "timestamp": 1723540964, "time_this_iter_s": 19.177019834518433, "time_total_s": 15162.339574813843, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b52f7c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 15162.339574813843, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 90.85925925925928, "ram_util_percent": 83.65185185185184}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9889635948040498, "cur_kl_coeff": 1.1754943508222876e-39, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6685345157744393, "policy_loss": -0.0017322620288247154, "vf_loss": 3.670266780146846, "vf_explained_var": 0.0038862674324600783, "kl": 0.0016664033022994313, "entropy": 0.2036054574150257, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 309015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 46.47914794368088, "cur_kl_coeff": 3.2969826893684516e-20, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.241091174801822, "policy_loss": 0.0002622544728515167, "vf_loss": 5.240828905660639, "vf_explained_var": 0.3576340609126621, "kl": 0.0009737105948962137, "entropy": 0.4402119252732191, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 309015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -522.0, "episode_reward_mean": 83.84299999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 0.006499999999965098, "predator_policy": 41.915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [107.49999999999983, -133.69999999999993, -178.90000000000012, 349.2, 175.2999999999995, -106.50000000000006, 16.799999999999965, -317.4, 348.70000000000005, 113.59999999999951, -319.5, 40.0000000000003, 6.199999999999973, 120.5999999999998, 231.69999999999933, 213.09999999999928, -126.10000000000034, 51.30000000000001, -110.80000000000025, -154.7000000000005, 40.70000000000001, -32.199999999999534, 67.90000000000023, -87.90000000000009, -185.7000000000001, 373.90000000000003, -371.2, 45.700000000000365, 207.99999999999932, 13.199999999999998, 197.99999999999926, 308.2, 313.99999999999994, 50.50000000000036, 17.200000000000422, -10.6, 136.59999999999968, 32.80000000000002, 210.0999999999993, 203.7999999999997, -85.60000000000008, 243.69999999999968, 346.7, 65.29999999999973, 74.0, 370.30000000000075, 156.1999999999998, 213.9999999999993, -463.49999999999994, 165.89999999999984, 145.19999999999965, 219.99999999999926, 349.1, -20.499999999999545, 40.0000000000003, 40.0000000000003, 291.0999999999997, 40.0000000000003, 178.19999999999948, 209.19999999999928, 125.29999999999971, 0.9000000000000004, -30.999999999999893, 351.20000000000005, -522.0, -109.80000000000024, 86.89999999999995, 246.79999999999944, 151.7999999999996, -180.00000000000065, 217.2999999999995, 103.29999999999976, 188.3, 68.80000000000022, -23.399999999999828, 355.00000000000006, 359.0, -25.999999999999545, 19.8, 137.19999999999874, 8.800000000000011, 167.7999999999995, 219.99999999999926, -75.19999999999999, 98.49999999999997, -50.30000000000016, 147.10000000000002, 319.8, 315.0, 343.30000000000007, -236.09999999999997, 400.0, 373.0, 219.99999999999926, 40.0000000000003, -164.00000000000057, 39.40000000000006, 40.0000000000003, 122.29999999999971, 96.80000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [186.5, -168.99999999999994, -181.60000000000002, -48.09999999999988, -39.39999999999996, -284.5, 189.2, 140.0, -24.099999999999774, 178.4, -54.70000000000002, -122.79999999999995, 20.000000000000014, -257.1999999999989, -305.5, -166.90000000000003, 200.0, 148.7, 11.599999999999964, 47.0, -238.3, -236.2, 20.000000000000014, 20.000000000000014, -295.0, 126.19999999999999, -116.50000000000077, 172.1, 200.0, 31.700000000000117, 20.000000000000014, 190.1, 20.000000000000014, -297.1, -351.7, 200.0, -316.0, 45.199999999999974, -351.7, 20.000000000000014, -215.20000000000002, 137.89999999999998, -72.40000000000089, -17.79999999999974, 46.99999999999997, 20.90000000000003, 36.20000000000016, -255.10000000000002, 14.299999999999613, -400.0, 200.0, 173.9, -189.70000000000002, -368.5, 68.59999999999985, -61.900000000000766, 20.000000000000014, 182.0, 200.0, -374.8, 20.000000000000014, 167.0, 154.1, 154.1, 200.0, 106.99999999999997, 38.00000000000023, -137.50000000000003, -35.79999999999981, 20.000000000000014, -76.60000000000001, 20.000000000000014, 124.39999999999998, -122.80000000000075, 170.0, -299.20000000000005, 1.0999999999999759, 200.0, 139.7, 64.10000000000005, -372.7, 100.09999999999998, -130.29999999999993, 200.0, 166.7, 170.0, -22.300000000000004, 11.600000000000009, -184.89999999999995, 131.9, 200.0, 170.2999999999998, 157.7, -95.49999999999994, 191.0, 20.000000000000014, -400.0, -263.5, -126.09999999999997, 182.0, -122.80000000000004, 200.0, 200.0, 20.000000000000014, 163.1, 179.0, 20.000000000000014, -95.50000000000082, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 91.09999999999997, 20.000000000000014, 20.000000000000014, -59.80000000000004, 200.0, 54.200000000000195, 155.0, 164.0, -162.7000000000004, -381.1, 191.0, 101.89999999999975, -271.9000000000003, 153.2, 197.0, -362.2, -374.8, -400.0, 90.19999999999976, 200.0, -234.09999999999988, 45.80000000000008, 200.0, -110.20000000000003, 200.0, 20.000000000000014, -400.0, 176.6, 40.70000000000007, 170.0, -162.7000000000006, -393.7, 200.0, 20.000000000000014, 48.800000000000004, 11.600000000000009, -85.00000000000003, 200.0, 155.0, 170.0, 173.0, 20.000000000000014, -106.0000000000008, -362.2, 200.0, 20.000000000000014, 117.19999999999948, -194.20000000000002, 100.99999999999997, 20.000000000000014, 147.8, 20.000000000000014, 200.0, -250.9, 46.69999999999956, 78.49999999999997, 20.000000000000014, 54.199999999999534, -221.5, 144.2, -192.10000000000002, 129.79999999999998, 185.0, 170.0, 113.0, 143.3, 200.0, -158.50000000000003, -328.6, 200.0, 200.0, 194.0, 164.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -376.0, 158.29999999999978, -334.9, 20.000000000000014, 20.000000000000014, 134.0, -225.7000000000004, 89.29999999999997, -242.5], "policy_predator_policy_reward": [79.0, 11.0, 96.0, 0.0, 145.0, 0.0, 10.0, 10.0, 21.0, 0.0, 0.0, 71.0, 122.0, 132.0, 155.0, 0.0, 0.0, 0.0, 27.0, 28.0, 32.0, 123.0, 0.0, 0.0, 51.0, 124.0, 65.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 151.0, 177.0, 26.0, 146.0, 14.0, 17.0, 160.0, 6.0, 112.0, 39.0, 19.0, 0.0, 0.0, 128.0, 3.0, 0.0, 200.0, 0.0, 0.0, 0.0, 187.0, 39.0, 0.0, 0.0, 6.0, 188.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 7.0, 75.0, 75.0, 33.0, 0.0, 46.0, 0.0, 67.0, 68.0, 147.0, 15.0, 9.0, 0.0, 0.0, 0.0, 184.0, 3.0, 87.0, 87.0, 10.0, 0.0, 65.0, 11.0, 110.0, 17.0, 0.0, 0.0, 79.0, 15.0, 3.0, 0.0, 200.0, 0.0, 12.0, 98.0, 0.0, 68.0, 0.0, 0.0, 0.0, 7.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 66.0, 58.0, 127.0, 64.0, 139.0, 0.0, 0.0, 1.0, 182.0, 33.0, 0.0, 200.0, 120.0, 1.0, 1.0, 0.0, 62.0, 0.0, 200.0, 0.0, 0.0, 0.0, 60.0, 36.0, 185.0, 197.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0.0, 16.0, 60.0, 0.0, 182.0, 0.0, 0.0, 0.0, 102.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 129.0, 0.0, 0.0, 0.0, 117.0, 99.0, 96.0, 5.0, 0.0, 0.0, 32.0, 0.0, 0.0, 85.0, 166.0, 0.0, 0.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 192.0, 169.0, 47.0, 0.0, 0.0, 127.0, 87.0, 125.0, 125.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.210925090357836, "mean_inference_ms": 8.218391013108764, "mean_action_processing_ms": 0.7240344047201489, "mean_env_wait_ms": 1.1085228988280924, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022282958030700684, "StateBufferConnector_ms": 0.0071266889572143555, "ViewRequirementAgentConnector_ms": 0.20885813236236572}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -522.0, "episode_return_mean": 83.84299999999986, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000, "num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 4.334290527255209, "num_env_steps_trained_throughput_per_sec": 4.334290527255209, "timesteps_total": 656000, "num_env_steps_sampled_lifetime": 656000, "num_agent_steps_sampled_lifetime": 2624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2624000, "timers": {"training_iteration_time_ms": 201964.849, "restore_workers_time_ms": 0.022, "training_step_time_ms": 201964.738, "sample_time_ms": 3183.388, "learn_time_ms": 198749.877, "learn_throughput": 20.126, "synch_weights_time_ms": 26.394}, "counters": {"num_env_steps_sampled": 656000, "num_env_steps_trained": 656000, "num_agent_steps_sampled": 2624000, "num_agent_steps_trained": 2624000}, "done": false, "training_iteration": 164, "trial_id": "3a355_00000", "date": "2024-08-13_05-38-07", "timestamp": 1723541887, "time_this_iter_s": 922.9692010879517, "time_total_s": 16085.308775901794, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5556ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16085.308775901794, "iterations_since_restore": 164, "perf": {"cpu_util_percent": 91.53947368421052, "ram_util_percent": 82.45}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0885527102404802, "cur_kl_coeff": 5.877471754111438e-40, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0959847176516497, "policy_loss": -0.0016746179723037928, "vf_loss": 2.097659329194871, "vf_explained_var": 0.004630191269375029, "kl": 0.0027346003575251508, "entropy": 0.21974919725347447, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 310905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 55.38109742286344, "cur_kl_coeff": 1.6484913446842258e-20, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.134894715162812, "policy_loss": -0.0004084877433284881, "vf_loss": 5.135303206544704, "vf_explained_var": 0.5648933152673106, "kl": 0.0013354150406926233, "entropy": 0.5663107590385215, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 310905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -522.0, "episode_reward_mean": 105.57999999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": 15.784999999999954, "predator_policy": 37.005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [67.90000000000023, -87.90000000000009, -185.7000000000001, 373.90000000000003, -371.2, 45.700000000000365, 207.99999999999932, 13.199999999999998, 197.99999999999926, 308.2, 313.99999999999994, 50.50000000000036, 17.200000000000422, -10.6, 136.59999999999968, 32.80000000000002, 210.0999999999993, 203.7999999999997, -85.60000000000008, 243.69999999999968, 346.7, 65.29999999999973, 74.0, 370.30000000000075, 156.1999999999998, 213.9999999999993, -463.49999999999994, 165.89999999999984, 145.19999999999965, 219.99999999999926, 349.1, -20.499999999999545, 40.0000000000003, 40.0000000000003, 291.0999999999997, 40.0000000000003, 178.19999999999948, 209.19999999999928, 125.29999999999971, 0.9000000000000004, -30.999999999999893, 351.20000000000005, -522.0, -109.80000000000024, 86.89999999999995, 246.79999999999944, 151.7999999999996, -180.00000000000065, 217.2999999999995, 103.29999999999976, 188.3, 68.80000000000022, -23.399999999999828, 355.00000000000006, 359.0, -25.999999999999545, 19.8, 137.19999999999874, 8.800000000000011, 167.7999999999995, 219.99999999999926, -75.19999999999999, 98.49999999999997, -50.30000000000016, 147.10000000000002, 319.8, 315.0, 343.30000000000007, -236.09999999999997, 400.0, 373.0, 219.99999999999926, 40.0000000000003, -164.00000000000057, 39.40000000000006, 40.0000000000003, 122.29999999999971, 96.80000000000001, -92.90000000000006, 75.59999999999954, 314.4999999999999, 254.59999999999957, 327.0999999999999, -186.89999999999998, 284.0, 158.79999999999953, 161.6, -25.099999999999575, 108.39999999999989, 123.29999999999976, 132.6999999999997, 40.0000000000003, 40.0000000000003, 197.99999999999937, -7.299999999999677, 209.89999999999964, -163.70000000000056, 18.20000000000005, 298.5999999999998, 239.19999999999987], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [46.99999999999997, 20.90000000000003, 36.20000000000016, -255.10000000000002, 14.299999999999613, -400.0, 200.0, 173.9, -189.70000000000002, -368.5, 68.59999999999985, -61.900000000000766, 20.000000000000014, 182.0, 200.0, -374.8, 20.000000000000014, 167.0, 154.1, 154.1, 200.0, 106.99999999999997, 38.00000000000023, -137.50000000000003, -35.79999999999981, 20.000000000000014, -76.60000000000001, 20.000000000000014, 124.39999999999998, -122.80000000000075, 170.0, -299.20000000000005, 1.0999999999999759, 200.0, 139.7, 64.10000000000005, -372.7, 100.09999999999998, -130.29999999999993, 200.0, 166.7, 170.0, -22.300000000000004, 11.600000000000009, -184.89999999999995, 131.9, 200.0, 170.2999999999998, 157.7, -95.49999999999994, 191.0, 20.000000000000014, -400.0, -263.5, -126.09999999999997, 182.0, -122.80000000000004, 200.0, 200.0, 20.000000000000014, 163.1, 179.0, 20.000000000000014, -95.50000000000082, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 91.09999999999997, 20.000000000000014, 20.000000000000014, -59.80000000000004, 200.0, 54.200000000000195, 155.0, 164.0, -162.7000000000004, -381.1, 191.0, 101.89999999999975, -271.9000000000003, 153.2, 197.0, -362.2, -374.8, -400.0, 90.19999999999976, 200.0, -234.09999999999988, 45.80000000000008, 200.0, -110.20000000000003, 200.0, 20.000000000000014, -400.0, 176.6, 40.70000000000007, 170.0, -162.7000000000006, -393.7, 200.0, 20.000000000000014, 48.800000000000004, 11.600000000000009, -85.00000000000003, 200.0, 155.0, 170.0, 173.0, 20.000000000000014, -106.0000000000008, -362.2, 200.0, 20.000000000000014, 117.19999999999948, -194.20000000000002, 100.99999999999997, 20.000000000000014, 147.8, 20.000000000000014, 200.0, -250.9, 46.69999999999956, 78.49999999999997, 20.000000000000014, 54.199999999999534, -221.5, 144.2, -192.10000000000002, 129.79999999999998, 185.0, 170.0, 113.0, 143.3, 200.0, -158.50000000000003, -328.6, 200.0, 200.0, 194.0, 164.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -376.0, 158.29999999999978, -334.9, 20.000000000000014, 20.000000000000014, 134.0, -225.7000000000004, 89.29999999999997, -242.5, -184.0000000000001, -61.90000000000054, -40.89999999999976, 87.50000000000006, 114.49999999999999, 200.0, 44.60000000000001, 200.0, 200.0, 127.1, -66.10000000000004, -248.8, 26.0, 200.0, 138.79999999999998, 20.000000000000014, -387.4, 200.0, -68.20000000000076, 1.0999999999999617, 88.39999999999998, 20.000000000000014, -22.000000000000043, 125.29999999999998, 112.69999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, -70.30000000000089, 47.89999999999997, 143.0, 20.000000000000014, -372.7, 38.00000000000015, -122.80000000000072, 95.6, 200.0, 170.0, 36.20000000000013], "policy_predator_policy_reward": [0.0, 0.0, 128.0, 3.0, 0.0, 200.0, 0.0, 0.0, 0.0, 187.0, 39.0, 0.0, 0.0, 6.0, 188.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 7.0, 75.0, 75.0, 33.0, 0.0, 46.0, 0.0, 67.0, 68.0, 147.0, 15.0, 9.0, 0.0, 0.0, 0.0, 184.0, 3.0, 87.0, 87.0, 10.0, 0.0, 65.0, 11.0, 110.0, 17.0, 0.0, 0.0, 79.0, 15.0, 3.0, 0.0, 200.0, 0.0, 12.0, 98.0, 0.0, 68.0, 0.0, 0.0, 0.0, 7.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 66.0, 58.0, 127.0, 64.0, 139.0, 0.0, 0.0, 1.0, 182.0, 33.0, 0.0, 200.0, 120.0, 1.0, 1.0, 0.0, 62.0, 0.0, 200.0, 0.0, 0.0, 0.0, 60.0, 36.0, 185.0, 197.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0.0, 16.0, 60.0, 0.0, 182.0, 0.0, 0.0, 0.0, 102.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 129.0, 0.0, 0.0, 0.0, 117.0, 99.0, 96.0, 5.0, 0.0, 0.0, 32.0, 0.0, 0.0, 85.0, 166.0, 0.0, 0.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 192.0, 169.0, 47.0, 0.0, 0.0, 127.0, 87.0, 125.0, 125.0, 37.0, 116.0, 29.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 128.0, 9.0, 49.0, 0.0, 0.0, 155.0, 194.0, 42.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 43.0, 0.0, 19.0, 142.0, 47.0, 47.0, 56.0, 0.0, 3.0, 0.0, 33.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2037209289720603, "mean_inference_ms": 8.235815865141662, "mean_action_processing_ms": 0.7213861777105661, "mean_env_wait_ms": 1.062559656199555, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012956619262695312, "StateBufferConnector_ms": 0.0252230167388916, "ViewRequirementAgentConnector_ms": 0.20333373546600342}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -522.0, "episode_return_mean": 105.57999999999991, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000, "num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 218.57075250138936, "num_env_steps_trained_throughput_per_sec": 218.57075250138936, "timesteps_total": 660000, "num_env_steps_sampled_lifetime": 660000, "num_agent_steps_sampled_lifetime": 2640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2640000, "timers": {"training_iteration_time_ms": 202013.138, "restore_workers_time_ms": 0.022, "training_step_time_ms": 202013.027, "sample_time_ms": 3266.825, "learn_time_ms": 198711.991, "learn_throughput": 20.13, "synch_weights_time_ms": 28.47}, "counters": {"num_env_steps_sampled": 660000, "num_env_steps_trained": 660000, "num_agent_steps_sampled": 2640000, "num_agent_steps_trained": 2640000}, "done": false, "training_iteration": 165, "trial_id": "3a355_00000", "date": "2024-08-13_05-38-26", "timestamp": 1723541906, "time_this_iter_s": 18.451161861419678, "time_total_s": 16103.759937763214, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73a6dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16103.759937763214, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 88.18846153846154, "ram_util_percent": 83.33076923076922}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2686730114871232, "cur_kl_coeff": 2.938735877055719e-40, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.751098518144517, "policy_loss": -0.0028302929033993413, "vf_loss": 3.7539288103265105, "vf_explained_var": 0.0032918370274639635, "kl": 0.004957323847077341, "entropy": 0.28350122170473535, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 312795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 57.18131548446953, "cur_kl_coeff": 8.242456723421129e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.303073113809818, "policy_loss": -0.004776456881383503, "vf_loss": 6.307849563871112, "vf_explained_var": 0.3872355555415784, "kl": 0.009140103390048273, "entropy": 0.6791958978251805, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 312795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -552.3, "episode_reward_mean": 74.96799999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -4.20100000000004, "predator_policy": 41.685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-85.60000000000008, 243.69999999999968, 346.7, 65.29999999999973, 74.0, 370.30000000000075, 156.1999999999998, 213.9999999999993, -463.49999999999994, 165.89999999999984, 145.19999999999965, 219.99999999999926, 349.1, -20.499999999999545, 40.0000000000003, 40.0000000000003, 291.0999999999997, 40.0000000000003, 178.19999999999948, 209.19999999999928, 125.29999999999971, 0.9000000000000004, -30.999999999999893, 351.20000000000005, -522.0, -109.80000000000024, 86.89999999999995, 246.79999999999944, 151.7999999999996, -180.00000000000065, 217.2999999999995, 103.29999999999976, 188.3, 68.80000000000022, -23.399999999999828, 355.00000000000006, 359.0, -25.999999999999545, 19.8, 137.19999999999874, 8.800000000000011, 167.7999999999995, 219.99999999999926, -75.19999999999999, 98.49999999999997, -50.30000000000016, 147.10000000000002, 319.8, 315.0, 343.30000000000007, -236.09999999999997, 400.0, 373.0, 219.99999999999926, 40.0000000000003, -164.00000000000057, 39.40000000000006, 40.0000000000003, 122.29999999999971, 96.80000000000001, -92.90000000000006, 75.59999999999954, 314.4999999999999, 254.59999999999957, 327.0999999999999, -186.89999999999998, 284.0, 158.79999999999953, 161.6, -25.099999999999575, 108.39999999999989, 123.29999999999976, 132.6999999999997, 40.0000000000003, 40.0000000000003, 197.99999999999937, -7.299999999999677, 209.89999999999964, -163.70000000000056, 18.20000000000005, 298.5999999999998, 239.19999999999987, -79.89999999999998, -164.4000000000002, 219.99999999999926, -133.60000000000048, -428.49999999999994, 25.500000000000007, -95.30000000000015, -551.7, 5.5, -552.3, -3.9999999999998024, -180.00000000000068, 63.80000000000015, 156.09999999999954, -34.80000000000004, 60.50000000000006, 116.39999999999979, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-372.7, 100.09999999999998, -130.29999999999993, 200.0, 166.7, 170.0, -22.300000000000004, 11.600000000000009, -184.89999999999995, 131.9, 200.0, 170.2999999999998, 157.7, -95.49999999999994, 191.0, 20.000000000000014, -400.0, -263.5, -126.09999999999997, 182.0, -122.80000000000004, 200.0, 200.0, 20.000000000000014, 163.1, 179.0, 20.000000000000014, -95.50000000000082, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 91.09999999999997, 20.000000000000014, 20.000000000000014, -59.80000000000004, 200.0, 54.200000000000195, 155.0, 164.0, -162.7000000000004, -381.1, 191.0, 101.89999999999975, -271.9000000000003, 153.2, 197.0, -362.2, -374.8, -400.0, 90.19999999999976, 200.0, -234.09999999999988, 45.80000000000008, 200.0, -110.20000000000003, 200.0, 20.000000000000014, -400.0, 176.6, 40.70000000000007, 170.0, -162.7000000000006, -393.7, 200.0, 20.000000000000014, 48.800000000000004, 11.600000000000009, -85.00000000000003, 200.0, 155.0, 170.0, 173.0, 20.000000000000014, -106.0000000000008, -362.2, 200.0, 20.000000000000014, 117.19999999999948, -194.20000000000002, 100.99999999999997, 20.000000000000014, 147.8, 20.000000000000014, 200.0, -250.9, 46.69999999999956, 78.49999999999997, 20.000000000000014, 54.199999999999534, -221.5, 144.2, -192.10000000000002, 129.79999999999998, 185.0, 170.0, 113.0, 143.3, 200.0, -158.50000000000003, -328.6, 200.0, 200.0, 194.0, 164.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -376.0, 158.29999999999978, -334.9, 20.000000000000014, 20.000000000000014, 134.0, -225.7000000000004, 89.29999999999997, -242.5, -184.0000000000001, -61.90000000000054, -40.89999999999976, 87.50000000000006, 114.49999999999999, 200.0, 44.60000000000001, 200.0, 200.0, 127.1, -66.10000000000004, -248.8, 26.0, 200.0, 138.79999999999998, 20.000000000000014, -387.4, 200.0, -68.20000000000076, 1.0999999999999617, 88.39999999999998, 20.000000000000014, -22.000000000000043, 125.29999999999998, 112.69999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, -70.30000000000089, 47.89999999999997, 143.0, 20.000000000000014, -372.7, 38.00000000000015, -122.80000000000072, 95.6, 200.0, 170.0, 36.20000000000013, 13.699999999999964, -202.59999999999985, -187.89999999999986, -152.50000000000037, 200.0, 20.000000000000014, 35.30000000000021, -376.9, -368.5, -253.00000000000003, -305.5, 164.0, 20.000000000000014, -238.3, -368.5, -383.2, -389.5, 200.0, -381.1, -362.2, -169.00000000000063, 20.000000000000014, -400.0, 20.000000000000014, -51.40000000000004, 81.19999999999996, 136.1, 20.000000000000014, -122.79999999999995, 20.000000000000014, 200.0, -284.5, -139.60000000000002, 170.0, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [184.0, 3.0, 87.0, 87.0, 10.0, 0.0, 65.0, 11.0, 110.0, 17.0, 0.0, 0.0, 79.0, 15.0, 3.0, 0.0, 200.0, 0.0, 12.0, 98.0, 0.0, 68.0, 0.0, 0.0, 0.0, 7.0, 0.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 66.0, 58.0, 127.0, 64.0, 139.0, 0.0, 0.0, 1.0, 182.0, 33.0, 0.0, 200.0, 120.0, 1.0, 1.0, 0.0, 62.0, 0.0, 200.0, 0.0, 0.0, 0.0, 60.0, 36.0, 185.0, 197.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0.0, 16.0, 60.0, 0.0, 182.0, 0.0, 0.0, 0.0, 102.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 129.0, 0.0, 0.0, 0.0, 117.0, 99.0, 96.0, 5.0, 0.0, 0.0, 32.0, 0.0, 0.0, 85.0, 166.0, 0.0, 0.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 192.0, 169.0, 47.0, 0.0, 0.0, 127.0, 87.0, 125.0, 125.0, 37.0, 116.0, 29.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 128.0, 9.0, 49.0, 0.0, 0.0, 155.0, 194.0, 42.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 43.0, 0.0, 19.0, 142.0, 47.0, 47.0, 56.0, 0.0, 3.0, 0.0, 33.0, 106.0, 3.0, 17.0, 159.0, 0.0, 0.0, 19.0, 189.0, 6.0, 187.0, 12.0, 155.0, 123.0, 0.0, 200.0, 0.0, 195.0, 0.0, 0.0, 191.0, 68.0, 77.0, 200.0, 0.0, 34.0, 0.0, 0.0, 0.0, 68.0, 0.0, 0.0, 145.0, 76.0, 10.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1988243400156646, "mean_inference_ms": 8.211023645652915, "mean_action_processing_ms": 0.7202905129002581, "mean_env_wait_ms": 1.0590333350744954, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010917305946350098, "StateBufferConnector_ms": 0.02446615695953369, "ViewRequirementAgentConnector_ms": 0.19656550884246826}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -552.3, "episode_return_mean": 74.96799999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000, "num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 233.77720704502934, "num_env_steps_trained_throughput_per_sec": 233.77720704502934, "timesteps_total": 664000, "num_env_steps_sampled_lifetime": 664000, "num_agent_steps_sampled_lifetime": 2656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2656000, "timers": {"training_iteration_time_ms": 201825.038, "restore_workers_time_ms": 0.039, "training_step_time_ms": 201824.87, "sample_time_ms": 3196.744, "learn_time_ms": 198594.79, "learn_throughput": 20.142, "synch_weights_time_ms": 28.446}, "counters": {"num_env_steps_sampled": 664000, "num_env_steps_trained": 664000, "num_agent_steps_sampled": 2656000, "num_agent_steps_trained": 2656000}, "done": false, "training_iteration": 166, "trial_id": "3a355_00000", "date": "2024-08-13_05-38-43", "timestamp": 1723541923, "time_this_iter_s": 17.15447211265564, "time_total_s": 16120.91440987587, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73edd30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16120.91440987587, "iterations_since_restore": 166, "perf": {"cpu_util_percent": 82.7625, "ram_util_percent": 80.78333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9466576441531144, "cur_kl_coeff": 1.4693679385278595e-40, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1585788686439473, "policy_loss": -5.659170746901837e-05, "vf_loss": 3.1586354578613602, "vf_explained_var": 0.00588497210431982, "kl": 0.0014775744533546574, "entropy": 0.1729435731060606, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 314685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 50.060152892728965, "cur_kl_coeff": 8.242456723421129e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.540385217767544, "policy_loss": -0.0020534122120046978, "vf_loss": 5.542438636507307, "vf_explained_var": 0.5357787069504854, "kl": 0.010947925287363764, "entropy": 0.4917663687278354, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 314685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -552.3, "episode_reward_mean": 75.64499999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -3.512500000000042, "predator_policy": 41.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [178.19999999999948, 209.19999999999928, 125.29999999999971, 0.9000000000000004, -30.999999999999893, 351.20000000000005, -522.0, -109.80000000000024, 86.89999999999995, 246.79999999999944, 151.7999999999996, -180.00000000000065, 217.2999999999995, 103.29999999999976, 188.3, 68.80000000000022, -23.399999999999828, 355.00000000000006, 359.0, -25.999999999999545, 19.8, 137.19999999999874, 8.800000000000011, 167.7999999999995, 219.99999999999926, -75.19999999999999, 98.49999999999997, -50.30000000000016, 147.10000000000002, 319.8, 315.0, 343.30000000000007, -236.09999999999997, 400.0, 373.0, 219.99999999999926, 40.0000000000003, -164.00000000000057, 39.40000000000006, 40.0000000000003, 122.29999999999971, 96.80000000000001, -92.90000000000006, 75.59999999999954, 314.4999999999999, 254.59999999999957, 327.0999999999999, -186.89999999999998, 284.0, 158.79999999999953, 161.6, -25.099999999999575, 108.39999999999989, 123.29999999999976, 132.6999999999997, 40.0000000000003, 40.0000000000003, 197.99999999999937, -7.299999999999677, 209.89999999999964, -163.70000000000056, 18.20000000000005, 298.5999999999998, 239.19999999999987, -79.89999999999998, -164.4000000000002, 219.99999999999926, -133.60000000000048, -428.49999999999994, 25.500000000000007, -95.30000000000015, -551.7, 5.5, -552.3, -3.9999999999998024, -180.00000000000068, 63.80000000000015, 156.09999999999954, -34.80000000000004, 60.50000000000006, 116.39999999999979, 40.0000000000003, 156.09999999999954, 115.89999999999976, 32.80000000000005, 199.99999999999935, 400.0, 115.5999999999998, 167.19999999999953, 38.50000000000002, -7.0, 40.0000000000003, 129.4999999999998, 40.0000000000003, 112.89999999999986, 219.99999999999926, 150.6999999999996, 79.19999999999999, 151.7999999999996, 116.39999999999979], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-59.80000000000004, 200.0, 54.200000000000195, 155.0, 164.0, -162.7000000000004, -381.1, 191.0, 101.89999999999975, -271.9000000000003, 153.2, 197.0, -362.2, -374.8, -400.0, 90.19999999999976, 200.0, -234.09999999999988, 45.80000000000008, 200.0, -110.20000000000003, 200.0, 20.000000000000014, -400.0, 176.6, 40.70000000000007, 170.0, -162.7000000000006, -393.7, 200.0, 20.000000000000014, 48.800000000000004, 11.600000000000009, -85.00000000000003, 200.0, 155.0, 170.0, 173.0, 20.000000000000014, -106.0000000000008, -362.2, 200.0, 20.000000000000014, 117.19999999999948, -194.20000000000002, 100.99999999999997, 20.000000000000014, 147.8, 20.000000000000014, 200.0, -250.9, 46.69999999999956, 78.49999999999997, 20.000000000000014, 54.199999999999534, -221.5, 144.2, -192.10000000000002, 129.79999999999998, 185.0, 170.0, 113.0, 143.3, 200.0, -158.50000000000003, -328.6, 200.0, 200.0, 194.0, 164.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -376.0, 158.29999999999978, -334.9, 20.000000000000014, 20.000000000000014, 134.0, -225.7000000000004, 89.29999999999997, -242.5, -184.0000000000001, -61.90000000000054, -40.89999999999976, 87.50000000000006, 114.49999999999999, 200.0, 44.60000000000001, 200.0, 200.0, 127.1, -66.10000000000004, -248.8, 26.0, 200.0, 138.79999999999998, 20.000000000000014, -387.4, 200.0, -68.20000000000076, 1.0999999999999617, 88.39999999999998, 20.000000000000014, -22.000000000000043, 125.29999999999998, 112.69999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, -70.30000000000089, 47.89999999999997, 143.0, 20.000000000000014, -372.7, 38.00000000000015, -122.80000000000072, 95.6, 200.0, 170.0, 36.20000000000013, 13.699999999999964, -202.59999999999985, -187.89999999999986, -152.50000000000037, 200.0, 20.000000000000014, 35.30000000000021, -376.9, -368.5, -253.00000000000003, -305.5, 164.0, 20.000000000000014, -238.3, -368.5, -383.2, -389.5, 200.0, -381.1, -362.2, -169.00000000000063, 20.000000000000014, -400.0, 20.000000000000014, -51.40000000000004, 81.19999999999996, 136.1, 20.000000000000014, -122.79999999999995, 20.000000000000014, 200.0, -284.5, -139.60000000000002, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 136.1, 148.7, -80.80000000000004, 170.0, -299.2, 170.0, 20.000000000000014, 200.0, 200.0, -156.40000000000003, 182.0, 200.0, -80.80000000000004, -326.5, 200.0, -358.0, 161.0, 20.000000000000014, 20.000000000000014, -70.30000000000064, 147.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, 130.7, 200.0, -248.8, 200.0, -110.20000000000002, -139.60000000000002, 170.0], "policy_predator_policy_reward": [0.0, 38.0, 0.0, 0.0, 66.0, 58.0, 127.0, 64.0, 139.0, 0.0, 0.0, 1.0, 182.0, 33.0, 0.0, 200.0, 120.0, 1.0, 1.0, 0.0, 62.0, 0.0, 200.0, 0.0, 0.0, 0.0, 60.0, 36.0, 185.0, 197.0, 0.0, 0.0, 0.0, 50.0, 0.0, 0.0, 0.0, 16.0, 60.0, 0.0, 182.0, 0.0, 0.0, 0.0, 102.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 129.0, 0.0, 0.0, 0.0, 117.0, 99.0, 96.0, 5.0, 0.0, 0.0, 32.0, 0.0, 0.0, 85.0, 166.0, 0.0, 0.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 192.0, 169.0, 47.0, 0.0, 0.0, 127.0, 87.0, 125.0, 125.0, 37.0, 116.0, 29.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 128.0, 9.0, 49.0, 0.0, 0.0, 155.0, 194.0, 42.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 43.0, 0.0, 19.0, 142.0, 47.0, 47.0, 56.0, 0.0, 3.0, 0.0, 33.0, 106.0, 3.0, 17.0, 159.0, 0.0, 0.0, 19.0, 189.0, 6.0, 187.0, 12.0, 155.0, 123.0, 0.0, 200.0, 0.0, 195.0, 0.0, 0.0, 191.0, 68.0, 77.0, 200.0, 0.0, 34.0, 0.0, 0.0, 0.0, 68.0, 0.0, 0.0, 145.0, 76.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 10.0, 152.0, 10.0, 0.0, 0.0, 0.0, 6.0, 84.0, 48.0, 0.0, 0.0, 165.0, 38.0, 152.0, 0.0, 0.0, 31.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 0.0, 0.0, 62.0, 10.0, 76.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1941076785714415, "mean_inference_ms": 8.186645891721849, "mean_action_processing_ms": 0.7191694649784148, "mean_env_wait_ms": 1.0555162342828743, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009152531623840332, "StateBufferConnector_ms": 0.05736064910888672, "ViewRequirementAgentConnector_ms": 0.1837707757949829}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -552.3, "episode_return_mean": 75.64499999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000, "num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 238.07803441036867, "num_env_steps_trained_throughput_per_sec": 238.07803441036867, "timesteps_total": 668000, "num_env_steps_sampled_lifetime": 668000, "num_agent_steps_sampled_lifetime": 2672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2672000, "timers": {"training_iteration_time_ms": 201678.564, "restore_workers_time_ms": 0.033, "training_step_time_ms": 201678.413, "sample_time_ms": 3140.385, "learn_time_ms": 198508.082, "learn_throughput": 20.15, "synch_weights_time_ms": 25.023}, "counters": {"num_env_steps_sampled": 668000, "num_env_steps_trained": 668000, "num_agent_steps_sampled": 2672000, "num_agent_steps_trained": 2672000}, "done": false, "training_iteration": 167, "trial_id": "3a355_00000", "date": "2024-08-13_05-39-00", "timestamp": 1723541940, "time_this_iter_s": 16.87167501449585, "time_total_s": 16137.786084890366, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5556700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16137.786084890366, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 82.19999999999999, "ram_util_percent": 80.97500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9838994858323267, "cur_kl_coeff": 7.346839692639297e-41, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2346582262604326, "policy_loss": -0.0005134510585949535, "vf_loss": 3.2351716761235836, "vf_explained_var": 0.002601692127803015, "kl": 0.002114315175629295, "entropy": 0.21878182634947793, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 316575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 38.64656661824574, "cur_kl_coeff": 8.242456723421129e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.253369571292211, "policy_loss": 0.0007653747406842374, "vf_loss": 5.252604193536062, "vf_explained_var": 0.4355230528526205, "kl": 0.00190434940883093, "entropy": 0.48751282704570303, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 316575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -552.3, "episode_reward_mean": 61.48399999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -11.443000000000033, "predator_policy": 42.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [359.0, -25.999999999999545, 19.8, 137.19999999999874, 8.800000000000011, 167.7999999999995, 219.99999999999926, -75.19999999999999, 98.49999999999997, -50.30000000000016, 147.10000000000002, 319.8, 315.0, 343.30000000000007, -236.09999999999997, 400.0, 373.0, 219.99999999999926, 40.0000000000003, -164.00000000000057, 39.40000000000006, 40.0000000000003, 122.29999999999971, 96.80000000000001, -92.90000000000006, 75.59999999999954, 314.4999999999999, 254.59999999999957, 327.0999999999999, -186.89999999999998, 284.0, 158.79999999999953, 161.6, -25.099999999999575, 108.39999999999989, 123.29999999999976, 132.6999999999997, 40.0000000000003, 40.0000000000003, 197.99999999999937, -7.299999999999677, 209.89999999999964, -163.70000000000056, 18.20000000000005, 298.5999999999998, 239.19999999999987, -79.89999999999998, -164.4000000000002, 219.99999999999926, -133.60000000000048, -428.49999999999994, 25.500000000000007, -95.30000000000015, -551.7, 5.5, -552.3, -3.9999999999998024, -180.00000000000068, 63.80000000000015, 156.09999999999954, -34.80000000000004, 60.50000000000006, 116.39999999999979, 40.0000000000003, 156.09999999999954, 115.89999999999976, 32.80000000000005, 199.99999999999935, 400.0, 115.5999999999998, 167.19999999999953, 38.50000000000002, -7.0, 40.0000000000003, 129.4999999999998, 40.0000000000003, 112.89999999999986, 219.99999999999926, 150.6999999999996, 79.19999999999999, 151.7999999999996, 116.39999999999979, -375.1000000000001, -145.40000000000057, -371.8, 159.69999999999953, 195.59999999999937, 183.09999999999943, -171.2000000000006, -254.79999999999995, -44.99999999999996, -29.099999999999966, 382.0, 350.0, 33.400000000000205, -175.50000000000017, -7.299999999999969, -130.7999999999999, 2.9000000000001123, 400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.0, 173.0, 20.000000000000014, -106.0000000000008, -362.2, 200.0, 20.000000000000014, 117.19999999999948, -194.20000000000002, 100.99999999999997, 20.000000000000014, 147.8, 20.000000000000014, 200.0, -250.9, 46.69999999999956, 78.49999999999997, 20.000000000000014, 54.199999999999534, -221.5, 144.2, -192.10000000000002, 129.79999999999998, 185.0, 170.0, 113.0, 143.3, 200.0, -158.50000000000003, -328.6, 200.0, 200.0, 194.0, 164.0, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -376.0, 158.29999999999978, -334.9, 20.000000000000014, 20.000000000000014, 134.0, -225.7000000000004, 89.29999999999997, -242.5, -184.0000000000001, -61.90000000000054, -40.89999999999976, 87.50000000000006, 114.49999999999999, 200.0, 44.60000000000001, 200.0, 200.0, 127.1, -66.10000000000004, -248.8, 26.0, 200.0, 138.79999999999998, 20.000000000000014, -387.4, 200.0, -68.20000000000076, 1.0999999999999617, 88.39999999999998, 20.000000000000014, -22.000000000000043, 125.29999999999998, 112.69999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, -70.30000000000089, 47.89999999999997, 143.0, 20.000000000000014, -372.7, 38.00000000000015, -122.80000000000072, 95.6, 200.0, 170.0, 36.20000000000013, 13.699999999999964, -202.59999999999985, -187.89999999999986, -152.50000000000037, 200.0, 20.000000000000014, 35.30000000000021, -376.9, -368.5, -253.00000000000003, -305.5, 164.0, 20.000000000000014, -238.3, -368.5, -383.2, -389.5, 200.0, -381.1, -362.2, -169.00000000000063, 20.000000000000014, -400.0, 20.000000000000014, -51.40000000000004, 81.19999999999996, 136.1, 20.000000000000014, -122.79999999999995, 20.000000000000014, 200.0, -284.5, -139.60000000000002, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 136.1, 148.7, -80.80000000000004, 170.0, -299.2, 170.0, 20.000000000000014, 200.0, 200.0, -156.40000000000003, 182.0, 200.0, -80.80000000000004, -326.5, 200.0, -358.0, 161.0, 20.000000000000014, 20.000000000000014, -70.30000000000064, 147.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, 130.7, 200.0, -248.8, 200.0, -110.20000000000002, -139.60000000000002, 170.0, -387.4, -183.70000000000002, 32.599999999999994, -400.0, -225.70000000000002, -297.1, 20.000000000000014, 139.7, -9.399999999999872, 191.0, 20.000000000000014, 163.1, 20.000000000000014, -383.2, -278.2, -118.60000000000002, -400.0, 154.99999999999977, 59.59999999999996, -267.7, 200.0, 173.0, 107.0, 200.0, 20.000000000000014, 7.399999999999965, -282.4, -171.1000000000002, -9.40000000000005, -40.89999999999978, -68.20000000000005, -139.60000000000008, -5.200000000000003, -229.9, 200.0, 200.0], "policy_predator_policy_reward": [0.0, 16.0, 60.0, 0.0, 182.0, 0.0, 0.0, 0.0, 102.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 129.0, 0.0, 0.0, 0.0, 117.0, 99.0, 96.0, 5.0, 0.0, 0.0, 32.0, 0.0, 0.0, 85.0, 166.0, 0.0, 0.0, 10.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 192.0, 169.0, 47.0, 0.0, 0.0, 127.0, 87.0, 125.0, 125.0, 37.0, 116.0, 29.0, 0.0, 0.0, 0.0, 8.0, 2.0, 0.0, 0.0, 0.0, 128.0, 9.0, 49.0, 0.0, 0.0, 155.0, 194.0, 42.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 43.0, 0.0, 19.0, 142.0, 47.0, 47.0, 56.0, 0.0, 3.0, 0.0, 33.0, 106.0, 3.0, 17.0, 159.0, 0.0, 0.0, 19.0, 189.0, 6.0, 187.0, 12.0, 155.0, 123.0, 0.0, 200.0, 0.0, 195.0, 0.0, 0.0, 191.0, 68.0, 77.0, 200.0, 0.0, 34.0, 0.0, 0.0, 0.0, 68.0, 0.0, 0.0, 145.0, 76.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 10.0, 152.0, 10.0, 0.0, 0.0, 0.0, 6.0, 84.0, 48.0, 0.0, 0.0, 165.0, 38.0, 152.0, 0.0, 0.0, 31.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 0.0, 0.0, 62.0, 10.0, 76.0, 6.0, 190.0, 200.0, 22.0, 0.0, 151.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 192.0, 0.0, 142.0, 0.0, 0.0, 200.0, 42.0, 137.0, 9.0, 0.0, 26.0, 17.0, 6.0, 0.0, 143.0, 135.0, 14.0, 29.0, 0.0, 77.0, 119.0, 119.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1890575306524194, "mean_inference_ms": 8.161177431562175, "mean_action_processing_ms": 0.7178076468772199, "mean_env_wait_ms": 1.051896738240616, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00893247127532959, "StateBufferConnector_ms": 0.05734705924987793, "ViewRequirementAgentConnector_ms": 0.18687236309051514}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -552.3, "episode_return_mean": 61.48399999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000, "num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 244.8530192241953, "num_env_steps_trained_throughput_per_sec": 244.8530192241953, "timesteps_total": 672000, "num_env_steps_sampled_lifetime": 672000, "num_agent_steps_sampled_lifetime": 2688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2688000, "timers": {"training_iteration_time_ms": 201404.839, "restore_workers_time_ms": 0.033, "training_step_time_ms": 201404.688, "sample_time_ms": 2935.948, "learn_time_ms": 198439.351, "learn_throughput": 20.157, "synch_weights_time_ms": 24.419}, "counters": {"num_env_steps_sampled": 672000, "num_env_steps_trained": 672000, "num_agent_steps_sampled": 2688000, "num_agent_steps_trained": 2688000}, "done": false, "training_iteration": 168, "trial_id": "3a355_00000", "date": "2024-08-13_05-39-16", "timestamp": 1723541956, "time_this_iter_s": 16.3871967792511, "time_total_s": 16154.173281669617, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73ede50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16154.173281669617, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 83.93478260869566, "ram_util_percent": 81.1304347826087}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0580258668572815, "cur_kl_coeff": 3.6734198463196487e-41, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.635068223085353, "policy_loss": -0.0010518290295891423, "vf_loss": 3.63612006089044, "vf_explained_var": 0.005391410608140249, "kl": 0.004210550106767976, "entropy": 0.2412277375027616, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 318465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 59.362705731612664, "cur_kl_coeff": 4.1212283617105645e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.323252335931889, "policy_loss": -0.0005656319756612734, "vf_loss": 4.32381795966436, "vf_explained_var": 0.4464270806501782, "kl": 0.001365512674982607, "entropy": 0.5179183120134646, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 318465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -552.3, "episode_reward_mean": 64.90299999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -10.313500000000028, "predator_policy": 42.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [254.59999999999957, 327.0999999999999, -186.89999999999998, 284.0, 158.79999999999953, 161.6, -25.099999999999575, 108.39999999999989, 123.29999999999976, 132.6999999999997, 40.0000000000003, 40.0000000000003, 197.99999999999937, -7.299999999999677, 209.89999999999964, -163.70000000000056, 18.20000000000005, 298.5999999999998, 239.19999999999987, -79.89999999999998, -164.4000000000002, 219.99999999999926, -133.60000000000048, -428.49999999999994, 25.500000000000007, -95.30000000000015, -551.7, 5.5, -552.3, -3.9999999999998024, -180.00000000000068, 63.80000000000015, 156.09999999999954, -34.80000000000004, 60.50000000000006, 116.39999999999979, 40.0000000000003, 156.09999999999954, 115.89999999999976, 32.80000000000005, 199.99999999999935, 400.0, 115.5999999999998, 167.19999999999953, 38.50000000000002, -7.0, 40.0000000000003, 129.4999999999998, 40.0000000000003, 112.89999999999986, 219.99999999999926, 150.6999999999996, 79.19999999999999, 151.7999999999996, 116.39999999999979, -375.1000000000001, -145.40000000000057, -371.8, 159.69999999999953, 195.59999999999937, 183.09999999999943, -171.2000000000006, -254.79999999999995, -44.99999999999996, -29.099999999999966, 382.0, 350.0, 33.400000000000205, -175.50000000000017, -7.299999999999969, -130.7999999999999, 2.9000000000001123, 400.0, 94.9, -161.30000000000055, 114.4999999999998, 36.70000000000025, -174.50000000000063, 78.29999999999998, 65.90000000000023, 72.0, 219.99999999999926, 219.99999999999926, 124.80000000000004, 207.29999999999993, 400.0, 215.99999999999926, 107.29999999999981, -8.099999999999968, 14.099999999999927, 145.19999999999965, 197.59999999999937, 400.0, 217.99999999999926, 44.90000000000001, 400.0, -8.39999999999966, 328.9, -36.79999999999997, 238.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [44.60000000000001, 200.0, 200.0, 127.1, -66.10000000000004, -248.8, 26.0, 200.0, 138.79999999999998, 20.000000000000014, -387.4, 200.0, -68.20000000000076, 1.0999999999999617, 88.39999999999998, 20.000000000000014, -22.000000000000043, 125.29999999999998, 112.69999999999999, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.0, 20.000000000000014, 20.000000000000014, -70.30000000000089, 47.89999999999997, 143.0, 20.000000000000014, -372.7, 38.00000000000015, -122.80000000000072, 95.6, 200.0, 170.0, 36.20000000000013, 13.699999999999964, -202.59999999999985, -187.89999999999986, -152.50000000000037, 200.0, 20.000000000000014, 35.30000000000021, -376.9, -368.5, -253.00000000000003, -305.5, 164.0, 20.000000000000014, -238.3, -368.5, -383.2, -389.5, 200.0, -381.1, -362.2, -169.00000000000063, 20.000000000000014, -400.0, 20.000000000000014, -51.40000000000004, 81.19999999999996, 136.1, 20.000000000000014, -122.79999999999995, 20.000000000000014, 200.0, -284.5, -139.60000000000002, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 136.1, 148.7, -80.80000000000004, 170.0, -299.2, 170.0, 20.000000000000014, 200.0, 200.0, -156.40000000000003, 182.0, 200.0, -80.80000000000004, -326.5, 200.0, -358.0, 161.0, 20.000000000000014, 20.000000000000014, -70.30000000000064, 147.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, 130.7, 200.0, -248.8, 200.0, -110.20000000000002, -139.60000000000002, 170.0, -387.4, -183.70000000000002, 32.599999999999994, -400.0, -225.70000000000002, -297.1, 20.000000000000014, 139.7, -9.399999999999872, 191.0, 20.000000000000014, 163.1, 20.000000000000014, -383.2, -278.2, -118.60000000000002, -400.0, 154.99999999999977, 59.59999999999996, -267.7, 200.0, 173.0, 107.0, 200.0, 20.000000000000014, 7.399999999999965, -282.4, -171.1000000000002, -9.40000000000005, -40.89999999999978, -68.20000000000005, -139.60000000000008, -5.200000000000003, -229.9, 200.0, 200.0, 74.89999999999996, 20.000000000000014, 9.499999999999964, -353.8, 182.0, -158.50000000000003, 13.699999999999966, 20.000000000000014, -389.5, 20.000000000000014, 158.6, -301.3, 34.39999999999969, -32.499999999999766, -379.0, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 148.7, -376.9, 200.0, -225.70000000000002, 200.0, 200.0, 194.0, 20.000000000000014, 20.000000000000014, 77.30000000000001, -324.4000000000001, 152.3, 20.000000000000014, -61.900000000000524, 200.0, -122.80000000000004, 11.599999999999966, 170.0, 200.0, 200.0, 20.000000000000014, 197.0, 151.4, -221.5, 200.0, 200.0, -72.40000000000089, 20.000000000000014, 128.89999999999998, 200.0, -400.0, 159.2, 117.19999999999999, 120.79999999999998], "policy_predator_policy_reward": [8.0, 2.0, 0.0, 0.0, 0.0, 128.0, 9.0, 49.0, 0.0, 0.0, 155.0, 194.0, 42.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 43.0, 0.0, 19.0, 142.0, 47.0, 47.0, 56.0, 0.0, 3.0, 0.0, 33.0, 106.0, 3.0, 17.0, 159.0, 0.0, 0.0, 19.0, 189.0, 6.0, 187.0, 12.0, 155.0, 123.0, 0.0, 200.0, 0.0, 195.0, 0.0, 0.0, 191.0, 68.0, 77.0, 200.0, 0.0, 34.0, 0.0, 0.0, 0.0, 68.0, 0.0, 0.0, 145.0, 76.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 10.0, 152.0, 10.0, 0.0, 0.0, 0.0, 6.0, 84.0, 48.0, 0.0, 0.0, 165.0, 38.0, 152.0, 0.0, 0.0, 31.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 0.0, 0.0, 62.0, 10.0, 76.0, 6.0, 190.0, 200.0, 22.0, 0.0, 151.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 192.0, 0.0, 142.0, 0.0, 0.0, 200.0, 42.0, 137.0, 9.0, 0.0, 26.0, 17.0, 6.0, 0.0, 143.0, 135.0, 14.0, 29.0, 0.0, 77.0, 119.0, 119.0, 0.0, 0.0, 0.0, 0.0, 0.0, 183.0, 85.0, 6.0, 3.0, 0.0, 195.0, 0.0, 153.0, 68.0, 39.0, 25.0, 190.0, 61.0, 0.0, 0.0, 0.0, 0.0, 164.0, 189.0, 117.0, 116.0, 0.0, 0.0, 2.0, 0.0, 10.0, 0.0, 127.0, 37.0, 34.0, 22.0, 0.0, 68.0, 10.0, 6.0, 0.0, 0.0, 1.0, 0.0, 115.0, 0.0, 0.0, 0.0, 22.0, 22.0, 0.0, 0.0, 200.0, 4.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.2241651114275314, "mean_inference_ms": 8.080551678049295, "mean_action_processing_ms": 0.7171165452255995, "mean_env_wait_ms": 1.048939443772735, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009131789207458496, "StateBufferConnector_ms": 0.03702652454376221, "ViewRequirementAgentConnector_ms": 0.17601144313812256}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": -552.3, "episode_return_mean": 64.90299999999984, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000, "num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 240.63898157306016, "num_env_steps_trained_throughput_per_sec": 240.63898157306016, "timesteps_total": 676000, "num_env_steps_sampled_lifetime": 676000, "num_agent_steps_sampled_lifetime": 2704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2704000, "timers": {"training_iteration_time_ms": 201052.335, "restore_workers_time_ms": 0.034, "training_step_time_ms": 201052.181, "sample_time_ms": 2770.493, "learn_time_ms": 198251.825, "learn_throughput": 20.176, "synch_weights_time_ms": 24.892}, "counters": {"num_env_steps_sampled": 676000, "num_env_steps_trained": 676000, "num_agent_steps_sampled": 2704000, "num_agent_steps_trained": 2704000}, "done": false, "training_iteration": 169, "trial_id": "3a355_00000", "date": "2024-08-13_05-39-33", "timestamp": 1723541973, "time_this_iter_s": 16.66413116455078, "time_total_s": 16170.837412834167, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73a6f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16170.837412834167, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 83.25652173913043, "ram_util_percent": 81.19565217391303}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9048645027454884, "cur_kl_coeff": 1.8367099231598243e-41, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.130707387949424, "policy_loss": -0.0006666375313042885, "vf_loss": 2.131374025092554, "vf_explained_var": 0.0024701985101851206, "kl": 0.003161803091688974, "entropy": 0.25273782718906956, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 320355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 56.274229335627226, "cur_kl_coeff": 2.0606141808552823e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.420853060767764, "policy_loss": 0.0005912407057448512, "vf_loss": 4.42026181574221, "vf_explained_var": 0.48868636854741937, "kl": 0.0017925660752100621, "entropy": 0.44904451737643547, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 320355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -552.3, "episode_reward_mean": 58.708999999999826, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -14.840500000000025, "predator_policy": 44.195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [239.19999999999987, -79.89999999999998, -164.4000000000002, 219.99999999999926, -133.60000000000048, -428.49999999999994, 25.500000000000007, -95.30000000000015, -551.7, 5.5, -552.3, -3.9999999999998024, -180.00000000000068, 63.80000000000015, 156.09999999999954, -34.80000000000004, 60.50000000000006, 116.39999999999979, 40.0000000000003, 156.09999999999954, 115.89999999999976, 32.80000000000005, 199.99999999999935, 400.0, 115.5999999999998, 167.19999999999953, 38.50000000000002, -7.0, 40.0000000000003, 129.4999999999998, 40.0000000000003, 112.89999999999986, 219.99999999999926, 150.6999999999996, 79.19999999999999, 151.7999999999996, 116.39999999999979, -375.1000000000001, -145.40000000000057, -371.8, 159.69999999999953, 195.59999999999937, 183.09999999999943, -171.2000000000006, -254.79999999999995, -44.99999999999996, -29.099999999999966, 382.0, 350.0, 33.400000000000205, -175.50000000000017, -7.299999999999969, -130.7999999999999, 2.9000000000001123, 400.0, 94.9, -161.30000000000055, 114.4999999999998, 36.70000000000025, -174.50000000000063, 78.29999999999998, 65.90000000000023, 72.0, 219.99999999999926, 219.99999999999926, 124.80000000000004, 207.29999999999993, 400.0, 215.99999999999926, 107.29999999999981, -8.099999999999968, 14.099999999999927, 145.19999999999965, 197.59999999999937, 400.0, 217.99999999999926, 44.90000000000001, 400.0, -8.39999999999966, 328.9, -36.79999999999997, 238.0, -527.7, 325.20000000000005, 204.69999999999933, 24.20000000000001, 40.0000000000003, 400.0, 137.19999999999968, 166.99999999999952, -102.60000000000022, 219.99999999999926, -96.30000000000013, 219.99999999999926, 178.99999999999943, 217.99999999999926, 79.0, 380.0, -335.30000000000007, -179.60000000000062], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.0, 36.20000000000013, 13.699999999999964, -202.59999999999985, -187.89999999999986, -152.50000000000037, 200.0, 20.000000000000014, 35.30000000000021, -376.9, -368.5, -253.00000000000003, -305.5, 164.0, 20.000000000000014, -238.3, -368.5, -383.2, -389.5, 200.0, -381.1, -362.2, -169.00000000000063, 20.000000000000014, -400.0, 20.000000000000014, -51.40000000000004, 81.19999999999996, 136.1, 20.000000000000014, -122.79999999999995, 20.000000000000014, 200.0, -284.5, -139.60000000000002, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 136.1, 148.7, -80.80000000000004, 170.0, -299.2, 170.0, 20.000000000000014, 200.0, 200.0, -156.40000000000003, 182.0, 200.0, -80.80000000000004, -326.5, 200.0, -358.0, 161.0, 20.000000000000014, 20.000000000000014, -70.30000000000064, 147.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, 130.7, 200.0, -248.8, 200.0, -110.20000000000002, -139.60000000000002, 170.0, -387.4, -183.70000000000002, 32.599999999999994, -400.0, -225.70000000000002, -297.1, 20.000000000000014, 139.7, -9.399999999999872, 191.0, 20.000000000000014, 163.1, 20.000000000000014, -383.2, -278.2, -118.60000000000002, -400.0, 154.99999999999977, 59.59999999999996, -267.7, 200.0, 173.0, 107.0, 200.0, 20.000000000000014, 7.399999999999965, -282.4, -171.1000000000002, -9.40000000000005, -40.89999999999978, -68.20000000000005, -139.60000000000008, -5.200000000000003, -229.9, 200.0, 200.0, 74.89999999999996, 20.000000000000014, 9.499999999999964, -353.8, 182.0, -158.50000000000003, 13.699999999999966, 20.000000000000014, -389.5, 20.000000000000014, 158.6, -301.3, 34.39999999999969, -32.499999999999766, -379.0, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 148.7, -376.9, 200.0, -225.70000000000002, 200.0, 200.0, 194.0, 20.000000000000014, 20.000000000000014, 77.30000000000001, -324.4000000000001, 152.3, 20.000000000000014, -61.900000000000524, 200.0, -122.80000000000004, 11.599999999999966, 170.0, 200.0, 200.0, 20.000000000000014, 197.0, 151.4, -221.5, 200.0, 200.0, -72.40000000000089, 20.000000000000014, 128.89999999999998, 200.0, -400.0, 159.2, 117.19999999999999, 120.79999999999998, -347.5, -362.2, 153.2, 158.0, 184.7, 20.000000000000014, 200.0, -353.8, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 117.19999999999999, 20.000000000000014, 11.599999999999964, 148.39999999999998, -267.7, 28.1, 20.000000000000014, 200.0, 103.69999999999997, -400.0, 200.0, 20.000000000000014, -80.8000000000006, 174.8, 20.000000000000014, 197.0, -211.0000000000004, 170.0, 170.0, 200.0, -263.5, -206.8, -68.20000000000063, -303.3999999999999], "policy_predator_policy_reward": [0.0, 33.0, 106.0, 3.0, 17.0, 159.0, 0.0, 0.0, 19.0, 189.0, 6.0, 187.0, 12.0, 155.0, 123.0, 0.0, 200.0, 0.0, 195.0, 0.0, 0.0, 191.0, 68.0, 77.0, 200.0, 0.0, 34.0, 0.0, 0.0, 0.0, 68.0, 0.0, 0.0, 145.0, 76.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 10.0, 152.0, 10.0, 0.0, 0.0, 0.0, 6.0, 84.0, 48.0, 0.0, 0.0, 165.0, 38.0, 152.0, 0.0, 0.0, 31.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 0.0, 0.0, 62.0, 10.0, 76.0, 6.0, 190.0, 200.0, 22.0, 0.0, 151.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 192.0, 0.0, 142.0, 0.0, 0.0, 200.0, 42.0, 137.0, 9.0, 0.0, 26.0, 17.0, 6.0, 0.0, 143.0, 135.0, 14.0, 29.0, 0.0, 77.0, 119.0, 119.0, 0.0, 0.0, 0.0, 0.0, 0.0, 183.0, 85.0, 6.0, 3.0, 0.0, 195.0, 0.0, 153.0, 68.0, 39.0, 25.0, 190.0, 61.0, 0.0, 0.0, 0.0, 0.0, 164.0, 189.0, 117.0, 116.0, 0.0, 0.0, 2.0, 0.0, 10.0, 0.0, 127.0, 37.0, 34.0, 22.0, 0.0, 68.0, 10.0, 6.0, 0.0, 0.0, 1.0, 0.0, 115.0, 0.0, 0.0, 0.0, 22.0, 22.0, 0.0, 0.0, 200.0, 4.0, 0.0, 0.0, 182.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 178.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 137.0, 0.0, 0.0, 0.0, 200.0, 0.0, 0.0, 0.0, 47.0, 38.0, 0.0, 1.0, 0.0, 120.0, 0.0, 10.0, 135.0, 0.0, 164.0, 28.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1759995772249066, "mean_inference_ms": 8.097101820002456, "mean_action_processing_ms": 0.7141643069111941, "mean_env_wait_ms": 1.0429612899619303, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0046149492263793945, "StateBufferConnector_ms": 0.036881446838378906, "ViewRequirementAgentConnector_ms": 0.14094555377960205}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -552.3, "episode_return_mean": 58.708999999999826, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000, "num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 236.2922872469355, "num_env_steps_trained_throughput_per_sec": 236.2922872469355, "timesteps_total": 680000, "num_env_steps_sampled_lifetime": 680000, "num_agent_steps_sampled_lifetime": 2720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2720000, "timers": {"training_iteration_time_ms": 200658.243, "restore_workers_time_ms": 0.034, "training_step_time_ms": 200658.128, "sample_time_ms": 2649.752, "learn_time_ms": 197978.826, "learn_throughput": 20.204, "synch_weights_time_ms": 24.777}, "counters": {"num_env_steps_sampled": 680000, "num_env_steps_trained": 680000, "num_agent_steps_sampled": 2720000, "num_agent_steps_trained": 2720000}, "done": false, "training_iteration": 170, "trial_id": "3a355_00000", "date": "2024-08-13_05-39-50", "timestamp": 1723541990, "time_this_iter_s": 16.993776082992554, "time_total_s": 16187.83118891716, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5f61940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16187.83118891716, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 85.49583333333332, "ram_util_percent": 81.33333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9871591079369109, "cur_kl_coeff": 9.183549615799122e-42, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.927703388405855, "policy_loss": -0.0017848401894625374, "vf_loss": 3.9294882325268294, "vf_explained_var": 0.00328084252498768, "kl": 0.0022666968858113382, "entropy": 0.2259218410051689, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 322245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 32.31279650180743, "cur_kl_coeff": 1.0303070904276411e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.180422838276656, "policy_loss": -0.0013286928229881499, "vf_loss": 5.181751528871122, "vf_explained_var": 0.5262363022282011, "kl": 0.007537253970578924, "entropy": 0.36882854346875793, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 322245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -527.7, "episode_reward_mean": 88.20999999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -0.05500000000002388, "predator_policy": 44.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 156.09999999999954, 115.89999999999976, 32.80000000000005, 199.99999999999935, 400.0, 115.5999999999998, 167.19999999999953, 38.50000000000002, -7.0, 40.0000000000003, 129.4999999999998, 40.0000000000003, 112.89999999999986, 219.99999999999926, 150.6999999999996, 79.19999999999999, 151.7999999999996, 116.39999999999979, -375.1000000000001, -145.40000000000057, -371.8, 159.69999999999953, 195.59999999999937, 183.09999999999943, -171.2000000000006, -254.79999999999995, -44.99999999999996, -29.099999999999966, 382.0, 350.0, 33.400000000000205, -175.50000000000017, -7.299999999999969, -130.7999999999999, 2.9000000000001123, 400.0, 94.9, -161.30000000000055, 114.4999999999998, 36.70000000000025, -174.50000000000063, 78.29999999999998, 65.90000000000023, 72.0, 219.99999999999926, 219.99999999999926, 124.80000000000004, 207.29999999999993, 400.0, 215.99999999999926, 107.29999999999981, -8.099999999999968, 14.099999999999927, 145.19999999999965, 197.59999999999937, 400.0, 217.99999999999926, 44.90000000000001, 400.0, -8.39999999999966, 328.9, -36.79999999999997, 238.0, -527.7, 325.20000000000005, 204.69999999999933, 24.20000000000001, 40.0000000000003, 400.0, 137.19999999999968, 166.99999999999952, -102.60000000000022, 219.99999999999926, -96.30000000000013, 219.99999999999926, 178.99999999999943, 217.99999999999926, 79.0, 380.0, -335.30000000000007, -179.60000000000062, 141.69999999999965, 360.0, 219.99999999999926, -76.1, -95.80000000000018, 5.299999999999994, -137.10000000000005, 2.9999999999999374, 5.700000000000183, 366.0, 51.0, 40.0000000000003, 366.9, 387.4, 3.0, -273.5000000000007, 138.09999999999965, 107.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 136.1, 148.7, -80.80000000000004, 170.0, -299.2, 170.0, 20.000000000000014, 200.0, 200.0, -156.40000000000003, 182.0, 200.0, -80.80000000000004, -326.5, 200.0, -358.0, 161.0, 20.000000000000014, 20.000000000000014, -70.30000000000064, 147.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999998, 200.0, 20.000000000000014, 20.000000000000014, 130.7, 200.0, -248.8, 200.0, -110.20000000000002, -139.60000000000002, 170.0, -387.4, -183.70000000000002, 32.599999999999994, -400.0, -225.70000000000002, -297.1, 20.000000000000014, 139.7, -9.399999999999872, 191.0, 20.000000000000014, 163.1, 20.000000000000014, -383.2, -278.2, -118.60000000000002, -400.0, 154.99999999999977, 59.59999999999996, -267.7, 200.0, 173.0, 107.0, 200.0, 20.000000000000014, 7.399999999999965, -282.4, -171.1000000000002, -9.40000000000005, -40.89999999999978, -68.20000000000005, -139.60000000000008, -5.200000000000003, -229.9, 200.0, 200.0, 74.89999999999996, 20.000000000000014, 9.499999999999964, -353.8, 182.0, -158.50000000000003, 13.699999999999966, 20.000000000000014, -389.5, 20.000000000000014, 158.6, -301.3, 34.39999999999969, -32.499999999999766, -379.0, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 148.7, -376.9, 200.0, -225.70000000000002, 200.0, 200.0, 194.0, 20.000000000000014, 20.000000000000014, 77.30000000000001, -324.4000000000001, 152.3, 20.000000000000014, -61.900000000000524, 200.0, -122.80000000000004, 11.599999999999966, 170.0, 200.0, 200.0, 20.000000000000014, 197.0, 151.4, -221.5, 200.0, 200.0, -72.40000000000089, 20.000000000000014, 128.89999999999998, 200.0, -400.0, 159.2, 117.19999999999999, 120.79999999999998, -347.5, -362.2, 153.2, 158.0, 184.7, 20.000000000000014, 200.0, -353.8, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 117.19999999999999, 20.000000000000014, 11.599999999999964, 148.39999999999998, -267.7, 28.1, 20.000000000000014, 200.0, 103.69999999999997, -400.0, 200.0, 20.000000000000014, -80.8000000000006, 174.8, 20.000000000000014, 197.0, -211.0000000000004, 170.0, 170.0, 200.0, -263.5, -206.8, -68.20000000000063, -303.3999999999999, 20.000000000000014, 121.69999999999999, 167.0, 182.0, 20.000000000000014, 200.0, 90.19999999999997, -343.3, -397.9, 82.10000000000008, -313.9, 150.2, -135.40000000000003, -288.7, -148.00000000000068, 20.000000000000014, -141.70000000000005, 52.39999999999996, 170.0, 179.0, 200.0, -400.0, 20.000000000000014, 20.000000000000014, 176.0, 182.9, 187.4, 200.0, 200.0, -400.0, -95.49999999999983, -400.0, 200.0, -229.90000000000043, 200.0, -400.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 48.0, 10.0, 152.0, 10.0, 0.0, 0.0, 0.0, 6.0, 84.0, 48.0, 0.0, 0.0, 165.0, 38.0, 152.0, 0.0, 0.0, 31.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 128.0, 0.0, 0.0, 62.0, 10.0, 76.0, 6.0, 190.0, 200.0, 22.0, 0.0, 151.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 192.0, 0.0, 142.0, 0.0, 0.0, 200.0, 42.0, 137.0, 9.0, 0.0, 26.0, 17.0, 6.0, 0.0, 143.0, 135.0, 14.0, 29.0, 0.0, 77.0, 119.0, 119.0, 0.0, 0.0, 0.0, 0.0, 0.0, 183.0, 85.0, 6.0, 3.0, 0.0, 195.0, 0.0, 153.0, 68.0, 39.0, 25.0, 190.0, 61.0, 0.0, 0.0, 0.0, 0.0, 164.0, 189.0, 117.0, 116.0, 0.0, 0.0, 2.0, 0.0, 10.0, 0.0, 127.0, 37.0, 34.0, 22.0, 0.0, 68.0, 10.0, 6.0, 0.0, 0.0, 1.0, 0.0, 115.0, 0.0, 0.0, 0.0, 22.0, 22.0, 0.0, 0.0, 200.0, 4.0, 0.0, 0.0, 182.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 178.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 137.0, 0.0, 0.0, 0.0, 200.0, 0.0, 0.0, 0.0, 47.0, 38.0, 0.0, 1.0, 0.0, 120.0, 0.0, 10.0, 135.0, 0.0, 164.0, 28.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 150.0, 27.0, 21.0, 199.0, 10.0, 159.0, 140.0, 147.0, 66.0, 65.0, 95.0, 0.0, 17.0, 0.0, 200.0, 51.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 3.0, 200.0, 22.0, 200.0, 52.0, 116.0, 142.0, 165.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1697021361108098, "mean_inference_ms": 8.0688870028994, "mean_action_processing_ms": 0.7122958496850285, "mean_env_wait_ms": 1.03910771125528, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0051146745681762695, "StateBufferConnector_ms": 0.038010239601135254, "ViewRequirementAgentConnector_ms": 0.13592755794525146}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -527.7, "episode_return_mean": 88.20999999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000, "num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 232.0505819218949, "num_env_steps_trained_throughput_per_sec": 232.0505819218949, "timesteps_total": 684000, "num_env_steps_sampled_lifetime": 684000, "num_agent_steps_sampled_lifetime": 2736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2736000, "timers": {"training_iteration_time_ms": 200300.291, "restore_workers_time_ms": 0.034, "training_step_time_ms": 200300.176, "sample_time_ms": 2602.539, "learn_time_ms": 197667.433, "learn_throughput": 20.236, "synch_weights_time_ms": 24.797}, "counters": {"num_env_steps_sampled": 684000, "num_env_steps_trained": 684000, "num_agent_steps_sampled": 2736000, "num_agent_steps_trained": 2736000}, "done": false, "training_iteration": 171, "trial_id": "3a355_00000", "date": "2024-08-13_05-40-07", "timestamp": 1723542007, "time_this_iter_s": 17.280771017074585, "time_total_s": 16205.111959934235, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73ede50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16205.111959934235, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 83.52, "ram_util_percent": 81.548}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2020750981080468, "cur_kl_coeff": 4.591774807899561e-42, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.870137574054577, "policy_loss": -0.0007309438347836177, "vf_loss": 3.870868515085291, "vf_explained_var": 0.004679460847188556, "kl": 0.0016362615589572576, "entropy": 0.2480930791724296, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 324135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 55.77391865617699, "cur_kl_coeff": 1.0303070904276411e-21, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.657948952503305, "policy_loss": 0.0011463755069093572, "vf_loss": 4.656802582236194, "vf_explained_var": 0.4950606715426874, "kl": 0.003853119025141119, "entropy": 0.472023271725922, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 324135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -547.3, "episode_reward_mean": 84.97899999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -4.325500000000028, "predator_policy": 46.815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [116.39999999999979, -375.1000000000001, -145.40000000000057, -371.8, 159.69999999999953, 195.59999999999937, 183.09999999999943, -171.2000000000006, -254.79999999999995, -44.99999999999996, -29.099999999999966, 382.0, 350.0, 33.400000000000205, -175.50000000000017, -7.299999999999969, -130.7999999999999, 2.9000000000001123, 400.0, 94.9, -161.30000000000055, 114.4999999999998, 36.70000000000025, -174.50000000000063, 78.29999999999998, 65.90000000000023, 72.0, 219.99999999999926, 219.99999999999926, 124.80000000000004, 207.29999999999993, 400.0, 215.99999999999926, 107.29999999999981, -8.099999999999968, 14.099999999999927, 145.19999999999965, 197.59999999999937, 400.0, 217.99999999999926, 44.90000000000001, 400.0, -8.39999999999966, 328.9, -36.79999999999997, 238.0, -527.7, 325.20000000000005, 204.69999999999933, 24.20000000000001, 40.0000000000003, 400.0, 137.19999999999968, 166.99999999999952, -102.60000000000022, 219.99999999999926, -96.30000000000013, 219.99999999999926, 178.99999999999943, 217.99999999999926, 79.0, 380.0, -335.30000000000007, -179.60000000000062, 141.69999999999965, 360.0, 219.99999999999926, -76.1, -95.80000000000018, 5.299999999999994, -137.10000000000005, 2.9999999999999374, 5.700000000000183, 366.0, 51.0, 40.0000000000003, 366.9, 387.4, 3.0, -273.5000000000007, 138.09999999999965, 107.0, 400.0, -20.799999999999756, 285.49999999999966, 171.3999999999995, -547.3, 109.89999999999989, -137.80000000000058, 18.799999999999983, 219.99999999999926, 67.40000000000002, 254.20000000000005, 46.70000000000003, 32.30000000000023, 400.0, 18.5, -11.800000000000004, 359.50000000000006, 193.5999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-139.60000000000002, 170.0, -387.4, -183.70000000000002, 32.599999999999994, -400.0, -225.70000000000002, -297.1, 20.000000000000014, 139.7, -9.399999999999872, 191.0, 20.000000000000014, 163.1, 20.000000000000014, -383.2, -278.2, -118.60000000000002, -400.0, 154.99999999999977, 59.59999999999996, -267.7, 200.0, 173.0, 107.0, 200.0, 20.000000000000014, 7.399999999999965, -282.4, -171.1000000000002, -9.40000000000005, -40.89999999999978, -68.20000000000005, -139.60000000000008, -5.200000000000003, -229.9, 200.0, 200.0, 74.89999999999996, 20.000000000000014, 9.499999999999964, -353.8, 182.0, -158.50000000000003, 13.699999999999966, 20.000000000000014, -389.5, 20.000000000000014, 158.6, -301.3, 34.39999999999969, -32.499999999999766, -379.0, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 148.7, -376.9, 200.0, -225.70000000000002, 200.0, 200.0, 194.0, 20.000000000000014, 20.000000000000014, 77.30000000000001, -324.4000000000001, 152.3, 20.000000000000014, -61.900000000000524, 200.0, -122.80000000000004, 11.599999999999966, 170.0, 200.0, 200.0, 20.000000000000014, 197.0, 151.4, -221.5, 200.0, 200.0, -72.40000000000089, 20.000000000000014, 128.89999999999998, 200.0, -400.0, 159.2, 117.19999999999999, 120.79999999999998, -347.5, -362.2, 153.2, 158.0, 184.7, 20.000000000000014, 200.0, -353.8, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 117.19999999999999, 20.000000000000014, 11.599999999999964, 148.39999999999998, -267.7, 28.1, 20.000000000000014, 200.0, 103.69999999999997, -400.0, 200.0, 20.000000000000014, -80.8000000000006, 174.8, 20.000000000000014, 197.0, -211.0000000000004, 170.0, 170.0, 200.0, -263.5, -206.8, -68.20000000000063, -303.3999999999999, 20.000000000000014, 121.69999999999999, 167.0, 182.0, 20.000000000000014, 200.0, 90.19999999999997, -343.3, -397.9, 82.10000000000008, -313.9, 150.2, -135.40000000000003, -288.7, -148.00000000000068, 20.000000000000014, -141.70000000000005, 52.39999999999996, 170.0, 179.0, 200.0, -400.0, 20.000000000000014, 20.000000000000014, 176.0, 182.9, 187.4, 200.0, 200.0, -400.0, -95.49999999999983, -400.0, 200.0, -229.90000000000043, 200.0, -400.0, 200.0, 200.0, -19.900000000000013, -19.900000000000013, 87.49999999999997, 197.0, 161.3, 1.099999999999958, -391.6, -351.7, -213.10000000000002, 200.0, -391.6, -5.200000000000003, 20.000000000000014, -131.20000000000064, 20.000000000000014, 200.0, -328.6000000000001, 200.0, 80.0, 120.20000000000003, 128.59999999999997, -187.90000000000003, 20.000000000000014, 5.299999999999967, 200.0, 200.0, -326.5, 170.0, 183.8, -391.6, 200.0, 159.5, 167.0, 11.600000000000009], "policy_predator_policy_reward": [10.0, 76.0, 6.0, 190.0, 200.0, 22.0, 0.0, 151.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 192.0, 0.0, 142.0, 0.0, 0.0, 200.0, 42.0, 137.0, 9.0, 0.0, 26.0, 17.0, 6.0, 0.0, 143.0, 135.0, 14.0, 29.0, 0.0, 77.0, 119.0, 119.0, 0.0, 0.0, 0.0, 0.0, 0.0, 183.0, 85.0, 6.0, 3.0, 0.0, 195.0, 0.0, 153.0, 68.0, 39.0, 25.0, 190.0, 61.0, 0.0, 0.0, 0.0, 0.0, 164.0, 189.0, 117.0, 116.0, 0.0, 0.0, 2.0, 0.0, 10.0, 0.0, 127.0, 37.0, 34.0, 22.0, 0.0, 68.0, 10.0, 6.0, 0.0, 0.0, 1.0, 0.0, 115.0, 0.0, 0.0, 0.0, 22.0, 22.0, 0.0, 0.0, 200.0, 4.0, 0.0, 0.0, 182.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 178.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 137.0, 0.0, 0.0, 0.0, 200.0, 0.0, 0.0, 0.0, 47.0, 38.0, 0.0, 1.0, 0.0, 120.0, 0.0, 10.0, 135.0, 0.0, 164.0, 28.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 150.0, 27.0, 21.0, 199.0, 10.0, 159.0, 140.0, 147.0, 66.0, 65.0, 95.0, 0.0, 17.0, 0.0, 200.0, 51.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 3.0, 200.0, 22.0, 200.0, 52.0, 116.0, 142.0, 165.0, 0.0, 0.0, 19.0, 0.0, 1.0, 0.0, 9.0, 0.0, 196.0, 0.0, 89.0, 34.0, 63.0, 196.0, 58.0, 72.0, 0.0, 0.0, 123.0, 73.0, 0.0, 54.0, 7.0, 99.0, 4.0, 3.0, 0.0, 0.0, 0.0, 175.0, 119.0, 77.0, 0.0, 0.0, 4.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1633599829246264, "mean_inference_ms": 8.040835234828236, "mean_action_processing_ms": 0.7104423737144733, "mean_env_wait_ms": 1.0352752743081377, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0052231550216674805, "StateBufferConnector_ms": 0.004925251007080078, "ViewRequirementAgentConnector_ms": 0.14205515384674072}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -547.3, "episode_return_mean": 84.97899999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000, "num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 217.14543358881969, "num_env_steps_trained_throughput_per_sec": 217.14543358881969, "timesteps_total": 688000, "num_env_steps_sampled_lifetime": 688000, "num_agent_steps_sampled_lifetime": 2752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2752000, "timers": {"training_iteration_time_ms": 107976.268, "restore_workers_time_ms": 0.034, "training_step_time_ms": 107976.152, "sample_time_ms": 2605.885, "learn_time_ms": 105339.104, "learn_throughput": 37.973, "synch_weights_time_ms": 25.535}, "counters": {"num_env_steps_sampled": 688000, "num_env_steps_trained": 688000, "num_agent_steps_sampled": 2752000, "num_agent_steps_trained": 2752000}, "done": false, "training_iteration": 172, "trial_id": "3a355_00000", "date": "2024-08-13_05-40-36", "timestamp": 1723542036, "time_this_iter_s": 28.326399087905884, "time_total_s": 16233.43835902214, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5293040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16233.43835902214, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 88.23589743589743, "ram_util_percent": 83.11794871794872}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1711986549711102, "cur_kl_coeff": 2.2958874039497804e-42, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.390344463832795, "policy_loss": -0.0021194546936799293, "vf_loss": 4.392463915057914, "vf_explained_var": 0.0047275795823051815, "kl": 0.002630322981202825, "entropy": 0.2653078124636695, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 326025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 78.79030758464147, "cur_kl_coeff": 5.151535452138206e-22, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.348522742084725, "policy_loss": -0.0008389782021314931, "vf_loss": 5.349361733027867, "vf_explained_var": 0.3265932686114437, "kl": 0.0022327278211639726, "entropy": 0.5147867533264967, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 326025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -547.3, "episode_reward_mean": 95.02199999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -2.614000000000024, "predator_policy": 50.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-174.50000000000063, 78.29999999999998, 65.90000000000023, 72.0, 219.99999999999926, 219.99999999999926, 124.80000000000004, 207.29999999999993, 400.0, 215.99999999999926, 107.29999999999981, -8.099999999999968, 14.099999999999927, 145.19999999999965, 197.59999999999937, 400.0, 217.99999999999926, 44.90000000000001, 400.0, -8.39999999999966, 328.9, -36.79999999999997, 238.0, -527.7, 325.20000000000005, 204.69999999999933, 24.20000000000001, 40.0000000000003, 400.0, 137.19999999999968, 166.99999999999952, -102.60000000000022, 219.99999999999926, -96.30000000000013, 219.99999999999926, 178.99999999999943, 217.99999999999926, 79.0, 380.0, -335.30000000000007, -179.60000000000062, 141.69999999999965, 360.0, 219.99999999999926, -76.1, -95.80000000000018, 5.299999999999994, -137.10000000000005, 2.9999999999999374, 5.700000000000183, 366.0, 51.0, 40.0000000000003, 366.9, 387.4, 3.0, -273.5000000000007, 138.09999999999965, 107.0, 400.0, -20.799999999999756, 285.49999999999966, 171.3999999999995, -547.3, 109.89999999999989, -137.80000000000058, 18.799999999999983, 219.99999999999926, 67.40000000000002, 254.20000000000005, 46.70000000000003, 32.30000000000023, 400.0, 18.5, -11.800000000000004, 359.50000000000006, 193.5999999999994, 40.0000000000003, -115.00000000000026, 70.40000000000003, -362.7000000000005, 285.1, 184.5, 400.0, 130.8999999999997, -42.99999999999996, 25.700000000000085, -286.9, 0.0, 0.0, 199.99999999999935, -370.4999999999993, 198.0, 167.99999999999952, 89.99999999999993, 14.09999999999999, 389.2, 374.0, -31.999999999999844, -153.60000000000053], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-389.5, 20.000000000000014, 158.6, -301.3, 34.39999999999969, -32.499999999999766, -379.0, 200.0, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 148.7, -376.9, 200.0, -225.70000000000002, 200.0, 200.0, 194.0, 20.000000000000014, 20.000000000000014, 77.30000000000001, -324.4000000000001, 152.3, 20.000000000000014, -61.900000000000524, 200.0, -122.80000000000004, 11.599999999999966, 170.0, 200.0, 200.0, 20.000000000000014, 197.0, 151.4, -221.5, 200.0, 200.0, -72.40000000000089, 20.000000000000014, 128.89999999999998, 200.0, -400.0, 159.2, 117.19999999999999, 120.79999999999998, -347.5, -362.2, 153.2, 158.0, 184.7, 20.000000000000014, 200.0, -353.8, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 117.19999999999999, 20.000000000000014, 11.599999999999964, 148.39999999999998, -267.7, 28.1, 20.000000000000014, 200.0, 103.69999999999997, -400.0, 200.0, 20.000000000000014, -80.8000000000006, 174.8, 20.000000000000014, 197.0, -211.0000000000004, 170.0, 170.0, 200.0, -263.5, -206.8, -68.20000000000063, -303.3999999999999, 20.000000000000014, 121.69999999999999, 167.0, 182.0, 20.000000000000014, 200.0, 90.19999999999997, -343.3, -397.9, 82.10000000000008, -313.9, 150.2, -135.40000000000003, -288.7, -148.00000000000068, 20.000000000000014, -141.70000000000005, 52.39999999999996, 170.0, 179.0, 200.0, -400.0, 20.000000000000014, 20.000000000000014, 176.0, 182.9, 187.4, 200.0, 200.0, -400.0, -95.49999999999983, -400.0, 200.0, -229.90000000000043, 200.0, -400.0, 200.0, 200.0, -19.900000000000013, -19.900000000000013, 87.49999999999997, 197.0, 161.3, 1.099999999999958, -391.6, -351.7, -213.10000000000002, 200.0, -391.6, -5.200000000000003, 20.000000000000014, -131.20000000000064, 20.000000000000014, 200.0, -328.6000000000001, 200.0, 80.0, 120.20000000000003, 128.59999999999997, -187.90000000000003, 20.000000000000014, 5.299999999999967, 200.0, 200.0, -326.5, 170.0, 183.8, -391.6, 200.0, 159.5, 167.0, 11.600000000000009, 20.000000000000014, 20.000000000000014, -341.2, 54.19999999999996, -265.6, 200.0, -206.80000000000052, -334.9, 157.7, 115.39999999999998, -368.5, 176.0, 200.0, 200.0, 20.000000000000014, 92.89999999999999, 90.80000000000003, -332.8, 20.000000000000014, -7.299999999999912, -347.5, -114.40000000000009, -400.0, 200.0, 200.0, -400.0, 170.0, 20.000000000000014, -286.5999999999991, -313.9, 200.0, -400.0, 20.000000000000014, 107.0, -40.90000000000005, 74.9000000000001, -124.9, 20.000000000000014, 200.0, 189.2, 200.0, 161.0, -324.4, 22.399999999999984, 17.900000000000013, -368.5], "policy_predator_policy_reward": [195.0, 0.0, 153.0, 68.0, 39.0, 25.0, 190.0, 61.0, 0.0, 0.0, 0.0, 0.0, 164.0, 189.0, 117.0, 116.0, 0.0, 0.0, 2.0, 0.0, 10.0, 0.0, 127.0, 37.0, 34.0, 22.0, 0.0, 68.0, 10.0, 6.0, 0.0, 0.0, 1.0, 0.0, 115.0, 0.0, 0.0, 0.0, 22.0, 22.0, 0.0, 0.0, 200.0, 4.0, 0.0, 0.0, 182.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 178.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 137.0, 0.0, 0.0, 0.0, 200.0, 0.0, 0.0, 0.0, 47.0, 38.0, 0.0, 1.0, 0.0, 120.0, 0.0, 10.0, 135.0, 0.0, 164.0, 28.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 150.0, 27.0, 21.0, 199.0, 10.0, 159.0, 140.0, 147.0, 66.0, 65.0, 95.0, 0.0, 17.0, 0.0, 200.0, 51.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 3.0, 200.0, 22.0, 200.0, 52.0, 116.0, 142.0, 165.0, 0.0, 0.0, 19.0, 0.0, 1.0, 0.0, 9.0, 0.0, 196.0, 0.0, 89.0, 34.0, 63.0, 196.0, 58.0, 72.0, 0.0, 0.0, 123.0, 73.0, 0.0, 54.0, 7.0, 99.0, 4.0, 3.0, 0.0, 0.0, 0.0, 175.0, 119.0, 77.0, 0.0, 0.0, 4.0, 11.0, 0.0, 0.0, 0.0, 172.0, 136.0, 0.0, 3.0, 176.0, 0.0, 12.0, 185.0, 192.0, 0.0, 0.0, 0.0, 18.0, 0.0, 199.0, 13.0, 0.0, 175.0, 0.0, 0.0, 200.0, 0.0, 200.0, 10.0, 0.0, 159.0, 71.0, 200.0, 198.0, 31.0, 10.0, 29.0, 27.0, 50.0, 69.0, 0.0, 0.0, 3.0, 10.0, 106.0, 164.0, 185.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1568003681841965, "mean_inference_ms": 7.961530554188949, "mean_action_processing_ms": 0.709454252068729, "mean_env_wait_ms": 1.0702567142834771, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00595247745513916, "StateBufferConnector_ms": 0.00541377067565918, "ViewRequirementAgentConnector_ms": 0.16510403156280518}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -547.3, "episode_return_mean": 95.02199999999986, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000, "num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 207.07873821712525, "num_env_steps_trained_throughput_per_sec": 207.07873821712525, "timesteps_total": 692000, "num_env_steps_sampled_lifetime": 692000, "num_agent_steps_sampled_lifetime": 2768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2768000, "timers": {"training_iteration_time_ms": 107994.754, "restore_workers_time_ms": 0.041, "training_step_time_ms": 107994.618, "sample_time_ms": 2582.748, "learn_time_ms": 105381.491, "learn_throughput": 37.957, "synch_weights_time_ms": 24.845}, "counters": {"num_env_steps_sampled": 692000, "num_env_steps_trained": 692000, "num_agent_steps_sampled": 2768000, "num_agent_steps_trained": 2768000}, "done": false, "training_iteration": 173, "trial_id": "3a355_00000", "date": "2024-08-13_05-40-55", "timestamp": 1723542055, "time_this_iter_s": 19.368032932281494, "time_total_s": 16252.806391954422, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73a6430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16252.806391954422, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 86.7535714285714, "ram_util_percent": 82.79285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2756968924253391, "cur_kl_coeff": 1.1479437019748902e-42, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.520891182763236, "policy_loss": -0.013985655996849929, "vf_loss": 4.534876821659229, "vf_explained_var": 0.007317187924864431, "kl": 0.10443957416522374, "entropy": 0.36774198150350934, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 327915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 66.19196842817402, "cur_kl_coeff": 2.575767726069103e-22, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.506124725795927, "policy_loss": -0.007353262314030891, "vf_loss": 5.513477989100905, "vf_explained_var": 0.33873133665670163, "kl": 0.07971370588789699, "entropy": 0.7134793673873578, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 327915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -547.3, "episode_reward_mean": 89.75299999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -5.7385000000000215, "predator_policy": 50.615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [238.0, -527.7, 325.20000000000005, 204.69999999999933, 24.20000000000001, 40.0000000000003, 400.0, 137.19999999999968, 166.99999999999952, -102.60000000000022, 219.99999999999926, -96.30000000000013, 219.99999999999926, 178.99999999999943, 217.99999999999926, 79.0, 380.0, -335.30000000000007, -179.60000000000062, 141.69999999999965, 360.0, 219.99999999999926, -76.1, -95.80000000000018, 5.299999999999994, -137.10000000000005, 2.9999999999999374, 5.700000000000183, 366.0, 51.0, 40.0000000000003, 366.9, 387.4, 3.0, -273.5000000000007, 138.09999999999965, 107.0, 400.0, -20.799999999999756, 285.49999999999966, 171.3999999999995, -547.3, 109.89999999999989, -137.80000000000058, 18.799999999999983, 219.99999999999926, 67.40000000000002, 254.20000000000005, 46.70000000000003, 32.30000000000023, 400.0, 18.5, -11.800000000000004, 359.50000000000006, 193.5999999999994, 40.0000000000003, -115.00000000000026, 70.40000000000003, -362.7000000000005, 285.1, 184.5, 400.0, 130.8999999999997, -42.99999999999996, 25.700000000000085, -286.9, 0.0, 0.0, 199.99999999999935, -370.4999999999993, 198.0, 167.99999999999952, 89.99999999999993, 14.09999999999999, 389.2, 374.0, -31.999999999999844, -153.60000000000053, -37.49999999999968, 400.0, 40.0000000000003, 178.39999999999947, 192.29999999999944, -0.9000000000000647, 132.99999999999966, -107.00000000000007, 377.5, 400.0, -7.699999999999839, 106.69999999999985, 9.400000000000261, 22.90000000000024, -155.80000000000052, -14.999999999999929, 400.0, 282.6, 190.5, 40.0000000000003, 75.80000000000018, 180.39999999999944], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [117.19999999999999, 120.79999999999998, -347.5, -362.2, 153.2, 158.0, 184.7, 20.000000000000014, 200.0, -353.8, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 117.19999999999999, 20.000000000000014, 11.599999999999964, 148.39999999999998, -267.7, 28.1, 20.000000000000014, 200.0, 103.69999999999997, -400.0, 200.0, 20.000000000000014, -80.8000000000006, 174.8, 20.000000000000014, 197.0, -211.0000000000004, 170.0, 170.0, 200.0, -263.5, -206.8, -68.20000000000063, -303.3999999999999, 20.000000000000014, 121.69999999999999, 167.0, 182.0, 20.000000000000014, 200.0, 90.19999999999997, -343.3, -397.9, 82.10000000000008, -313.9, 150.2, -135.40000000000003, -288.7, -148.00000000000068, 20.000000000000014, -141.70000000000005, 52.39999999999996, 170.0, 179.0, 200.0, -400.0, 20.000000000000014, 20.000000000000014, 176.0, 182.9, 187.4, 200.0, 200.0, -400.0, -95.49999999999983, -400.0, 200.0, -229.90000000000043, 200.0, -400.0, 200.0, 200.0, -19.900000000000013, -19.900000000000013, 87.49999999999997, 197.0, 161.3, 1.099999999999958, -391.6, -351.7, -213.10000000000002, 200.0, -391.6, -5.200000000000003, 20.000000000000014, -131.20000000000064, 20.000000000000014, 200.0, -328.6000000000001, 200.0, 80.0, 120.20000000000003, 128.59999999999997, -187.90000000000003, 20.000000000000014, 5.299999999999967, 200.0, 200.0, -326.5, 170.0, 183.8, -391.6, 200.0, 159.5, 167.0, 11.600000000000009, 20.000000000000014, 20.000000000000014, -341.2, 54.19999999999996, -265.6, 200.0, -206.80000000000052, -334.9, 157.7, 115.39999999999998, -368.5, 176.0, 200.0, 200.0, 20.000000000000014, 92.89999999999999, 90.80000000000003, -332.8, 20.000000000000014, -7.299999999999912, -347.5, -114.40000000000009, -400.0, 200.0, 200.0, -400.0, 170.0, 20.000000000000014, -286.5999999999991, -313.9, 200.0, -400.0, 20.000000000000014, 107.0, -40.90000000000005, 74.9000000000001, -124.9, 20.000000000000014, 200.0, 189.2, 200.0, 161.0, -324.4, 22.399999999999984, 17.900000000000013, -368.5, 5.299999999999965, -269.79999999999995, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 157.4, 20.000000000000014, -15.70000000000001, 170.0, -292.9, 20.000000000000014, 20.000000000000014, 110.0, -400.0, -106.00000000000009, 177.5, 200.0, 200.0, 200.0, -397.9, 3.1999999999999615, 200.0, -196.3000000000004, 15.800000000000011, -30.40000000000002, -19.900000000000013, 15.799999999999963, 20.000000000000014, -353.8, 5.299999999999967, -70.30000000000004, 200.0, 200.0, 128.89999999999998, 151.7, -368.5, 200.0, 20.000000000000014, 20.000000000000014, 60.199999999999974, -9.400000000000011, 20.000000000000014, 160.4], "policy_predator_policy_reward": [0.0, 0.0, 182.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 178.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 137.0, 0.0, 0.0, 0.0, 200.0, 0.0, 0.0, 0.0, 47.0, 38.0, 0.0, 1.0, 0.0, 120.0, 0.0, 10.0, 135.0, 0.0, 164.0, 28.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 150.0, 27.0, 21.0, 199.0, 10.0, 159.0, 140.0, 147.0, 66.0, 65.0, 95.0, 0.0, 17.0, 0.0, 200.0, 51.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 3.0, 200.0, 22.0, 200.0, 52.0, 116.0, 142.0, 165.0, 0.0, 0.0, 19.0, 0.0, 1.0, 0.0, 9.0, 0.0, 196.0, 0.0, 89.0, 34.0, 63.0, 196.0, 58.0, 72.0, 0.0, 0.0, 123.0, 73.0, 0.0, 54.0, 7.0, 99.0, 4.0, 3.0, 0.0, 0.0, 0.0, 175.0, 119.0, 77.0, 0.0, 0.0, 4.0, 11.0, 0.0, 0.0, 0.0, 172.0, 136.0, 0.0, 3.0, 176.0, 0.0, 12.0, 185.0, 192.0, 0.0, 0.0, 0.0, 18.0, 0.0, 199.0, 13.0, 0.0, 175.0, 0.0, 0.0, 200.0, 0.0, 200.0, 10.0, 0.0, 159.0, 71.0, 200.0, 198.0, 31.0, 10.0, 29.0, 27.0, 50.0, 69.0, 0.0, 0.0, 3.0, 10.0, 106.0, 164.0, 185.0, 12.0, 138.0, 89.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 27.0, 149.0, 123.0, 3.0, 0.0, 200.0, 199.0, 0.0, 0.0, 0.0, 0.0, 188.0, 199.0, 0.0, 103.0, 0.0, 24.0, 19.0, 8.0, 178.0, 0.0, 50.0, 0.0, 0.0, 0.0, 2.0, 0.0, 174.0, 185.0, 0.0, 0.0, 14.0, 11.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.149371326324368, "mean_inference_ms": 7.977317450773241, "mean_action_processing_ms": 0.7065445271446669, "mean_env_wait_ms": 1.0265948607245483, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008037805557250977, "StateBufferConnector_ms": 0.010128617286682129, "ViewRequirementAgentConnector_ms": 0.18419265747070312}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -547.3, "episode_return_mean": 89.75299999999987, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000, "num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.4389718651533, "num_env_steps_trained_throughput_per_sec": 195.4389718651533, "timesteps_total": 696000, "num_env_steps_sampled_lifetime": 696000, "num_agent_steps_sampled_lifetime": 2784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2784000, "timers": {"training_iteration_time_ms": 17754.122, "restore_workers_time_ms": 0.041, "training_step_time_ms": 17753.986, "sample_time_ms": 2628.66, "learn_time_ms": 15095.857, "learn_throughput": 264.973, "synch_weights_time_ms": 24.64}, "counters": {"num_env_steps_sampled": 696000, "num_env_steps_trained": 696000, "num_agent_steps_sampled": 2784000, "num_agent_steps_trained": 2784000}, "done": false, "training_iteration": 174, "trial_id": "3a355_00000", "date": "2024-08-13_05-41-16", "timestamp": 1723542076, "time_this_iter_s": 20.54225206375122, "time_total_s": 16273.348644018173, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5556820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16273.348644018173, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 85.47931034482761, "ram_util_percent": 83.5448275862069}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7235993603786464, "cur_kl_coeff": 1.7219155529623348e-42, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.973198691751591, "policy_loss": -0.003691561111229319, "vf_loss": 4.976890249479385, "vf_explained_var": 0.02112795458268867, "kl": 0.0068531170760517835, "entropy": 0.5352786103411327, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 329805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 82.27650207095046, "cur_kl_coeff": 3.8636515891036556e-22, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.413514284355931, "policy_loss": 0.0002179884430632074, "vf_loss": 6.413296297870616, "vf_explained_var": -0.09051095928464617, "kl": 0.004561463133392656, "entropy": 0.919105182722132, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 329805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -547.3, "episode_reward_mean": 82.02299999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -13.02850000000004, "predator_policy": 54.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-179.60000000000062, 141.69999999999965, 360.0, 219.99999999999926, -76.1, -95.80000000000018, 5.299999999999994, -137.10000000000005, 2.9999999999999374, 5.700000000000183, 366.0, 51.0, 40.0000000000003, 366.9, 387.4, 3.0, -273.5000000000007, 138.09999999999965, 107.0, 400.0, -20.799999999999756, 285.49999999999966, 171.3999999999995, -547.3, 109.89999999999989, -137.80000000000058, 18.799999999999983, 219.99999999999926, 67.40000000000002, 254.20000000000005, 46.70000000000003, 32.30000000000023, 400.0, 18.5, -11.800000000000004, 359.50000000000006, 193.5999999999994, 40.0000000000003, -115.00000000000026, 70.40000000000003, -362.7000000000005, 285.1, 184.5, 400.0, 130.8999999999997, -42.99999999999996, 25.700000000000085, -286.9, 0.0, 0.0, 199.99999999999935, -370.4999999999993, 198.0, 167.99999999999952, 89.99999999999993, 14.09999999999999, 389.2, 374.0, -31.999999999999844, -153.60000000000053, -37.49999999999968, 400.0, 40.0000000000003, 178.39999999999947, 192.29999999999944, -0.9000000000000647, 132.99999999999966, -107.00000000000007, 377.5, 400.0, -7.699999999999839, 106.69999999999985, 9.400000000000261, 22.90000000000024, -155.80000000000052, -14.999999999999929, 400.0, 282.6, 190.5, 40.0000000000003, 75.80000000000018, 180.39999999999944, 84.99999999999918, -9.09999999999982, 151.39999999999867, -19.399999999999757, 117.49999999999889, -36.999999999999964, 135.89999999999895, -45.79999999999983, 138.4999999999993, -51.49999999999984, 40.0000000000003, 9.199999999999944, 83.79999999999991, 4.199999999999548, 199.8999999999994, 129.09999999999872, -60.099999999999845, 125.79999999999916], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-68.20000000000063, -303.3999999999999, 20.000000000000014, 121.69999999999999, 167.0, 182.0, 20.000000000000014, 200.0, 90.19999999999997, -343.3, -397.9, 82.10000000000008, -313.9, 150.2, -135.40000000000003, -288.7, -148.00000000000068, 20.000000000000014, -141.70000000000005, 52.39999999999996, 170.0, 179.0, 200.0, -400.0, 20.000000000000014, 20.000000000000014, 176.0, 182.9, 187.4, 200.0, 200.0, -400.0, -95.49999999999983, -400.0, 200.0, -229.90000000000043, 200.0, -400.0, 200.0, 200.0, -19.900000000000013, -19.900000000000013, 87.49999999999997, 197.0, 161.3, 1.099999999999958, -391.6, -351.7, -213.10000000000002, 200.0, -391.6, -5.200000000000003, 20.000000000000014, -131.20000000000064, 20.000000000000014, 200.0, -328.6000000000001, 200.0, 80.0, 120.20000000000003, 128.59999999999997, -187.90000000000003, 20.000000000000014, 5.299999999999967, 200.0, 200.0, -326.5, 170.0, 183.8, -391.6, 200.0, 159.5, 167.0, 11.600000000000009, 20.000000000000014, 20.000000000000014, -341.2, 54.19999999999996, -265.6, 200.0, -206.80000000000052, -334.9, 157.7, 115.39999999999998, -368.5, 176.0, 200.0, 200.0, 20.000000000000014, 92.89999999999999, 90.80000000000003, -332.8, 20.000000000000014, -7.299999999999912, -347.5, -114.40000000000009, -400.0, 200.0, 200.0, -400.0, 170.0, 20.000000000000014, -286.5999999999991, -313.9, 200.0, -400.0, 20.000000000000014, 107.0, -40.90000000000005, 74.9000000000001, -124.9, 20.000000000000014, 200.0, 189.2, 200.0, 161.0, -324.4, 22.399999999999984, 17.900000000000013, -368.5, 5.299999999999965, -269.79999999999995, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 157.4, 20.000000000000014, -15.70000000000001, 170.0, -292.9, 20.000000000000014, 20.000000000000014, 110.0, -400.0, -106.00000000000009, 177.5, 200.0, 200.0, 200.0, -397.9, 3.1999999999999615, 200.0, -196.3000000000004, 15.800000000000011, -30.40000000000002, -19.900000000000013, 15.799999999999963, 20.000000000000014, -353.8, 5.299999999999967, -70.30000000000004, 200.0, 200.0, 128.89999999999998, 151.7, -368.5, 200.0, 20.000000000000014, 20.000000000000014, 60.199999999999974, -9.400000000000011, 20.000000000000014, 160.4, 20.000000000000014, 65.00000000000001, -215.20000000000047, -145.90000000000003, 47.90000000000022, 93.49999999999952, -15.70000000000005, -57.70000000000048, -24.099999999999916, 32.60000000000022, 3.1999999999999633, -110.20000000000003, 20.90000000000003, 34.999999999999716, 3.499999999999517, -283.3000000000003, -70.30000000000081, 165.79999999999978, -288.7, 90.1999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.79999999999981, -305.5000000000002, 116.2999999999999, -122.80000000000017, 20.000000000000014, 55.999999999999375, 101.90000000000006, 109.09999999999944, 20.000000000000014, -24.099999999999945, -166.0, 118.99999999999962, -68.20000000000005], "policy_predator_policy_reward": [164.0, 28.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 150.0, 27.0, 21.0, 199.0, 10.0, 159.0, 140.0, 147.0, 66.0, 65.0, 95.0, 0.0, 17.0, 0.0, 200.0, 51.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 3.0, 200.0, 22.0, 200.0, 52.0, 116.0, 142.0, 165.0, 0.0, 0.0, 19.0, 0.0, 1.0, 0.0, 9.0, 0.0, 196.0, 0.0, 89.0, 34.0, 63.0, 196.0, 58.0, 72.0, 0.0, 0.0, 123.0, 73.0, 0.0, 54.0, 7.0, 99.0, 4.0, 3.0, 0.0, 0.0, 0.0, 175.0, 119.0, 77.0, 0.0, 0.0, 4.0, 11.0, 0.0, 0.0, 0.0, 172.0, 136.0, 0.0, 3.0, 176.0, 0.0, 12.0, 185.0, 192.0, 0.0, 0.0, 0.0, 18.0, 0.0, 199.0, 13.0, 0.0, 175.0, 0.0, 0.0, 200.0, 0.0, 200.0, 10.0, 0.0, 159.0, 71.0, 200.0, 198.0, 31.0, 10.0, 29.0, 27.0, 50.0, 69.0, 0.0, 0.0, 3.0, 10.0, 106.0, 164.0, 185.0, 12.0, 138.0, 89.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 27.0, 149.0, 123.0, 3.0, 0.0, 200.0, 199.0, 0.0, 0.0, 0.0, 0.0, 188.0, 199.0, 0.0, 103.0, 0.0, 24.0, 19.0, 8.0, 178.0, 0.0, 50.0, 0.0, 0.0, 0.0, 2.0, 0.0, 174.0, 185.0, 0.0, 0.0, 14.0, 11.0, 0.0, 0.0, 0.0, 0.0, 181.0, 171.0, 0.0, 10.0, 17.0, 37.0, 55.0, 54.0, 70.0, 0.0, 40.0, 40.0, 112.0, 122.0, 43.0, 0.0, 147.0, 0.0, 0.0, 0.0, 28.0, 0.0, 128.0, 145.0, 95.0, 12.0, 14.0, 28.0, 0.0, 0.0, 96.0, 34.0, 42.0, 33.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.144101563707526, "mean_inference_ms": 7.9528512790018215, "mean_action_processing_ms": 0.7052046377754748, "mean_env_wait_ms": 1.0231735850547343, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008288025856018066, "StateBufferConnector_ms": 0.010353565216064453, "ViewRequirementAgentConnector_ms": 0.18673717975616455}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -547.3, "episode_return_mean": 82.02299999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000, "num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 188.9140254297277, "num_env_steps_trained_throughput_per_sec": 188.9140254297277, "timesteps_total": 700000, "num_env_steps_sampled_lifetime": 700000, "num_agent_steps_sampled_lifetime": 2800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2800000, "timers": {"training_iteration_time_ms": 18041.417, "restore_workers_time_ms": 0.043, "training_step_time_ms": 18041.276, "sample_time_ms": 2544.636, "learn_time_ms": 15468.981, "learn_throughput": 258.582, "synch_weights_time_ms": 23.102}, "counters": {"num_env_steps_sampled": 700000, "num_env_steps_trained": 700000, "num_agent_steps_sampled": 2800000, "num_agent_steps_trained": 2800000}, "done": false, "training_iteration": 175, "trial_id": "3a355_00000", "date": "2024-08-13_05-41-37", "timestamp": 1723542097, "time_this_iter_s": 21.218905925750732, "time_total_s": 16294.567549943924, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5534820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16294.567549943924, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 86.0, "ram_util_percent": 83.57999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5424734889987914, "cur_kl_coeff": 1.7219155529623348e-42, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.756437995446422, "policy_loss": -0.0012181497027447064, "vf_loss": 5.75765615695368, "vf_explained_var": 0.029785097938366038, "kl": 0.0064546556662983465, "entropy": 0.3720583927930978, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 331695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 66.16232972309072, "cur_kl_coeff": 1.9318257945518278e-22, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.575707926321282, "policy_loss": -0.00046264558867920957, "vf_loss": 7.576170576186407, "vf_explained_var": 0.11517969076595609, "kl": 0.004440455678628669, "entropy": 0.8245141393293148, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 331695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -547.3, "episode_reward_mean": 63.63499999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -25.907500000000045, "predator_policy": 57.725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [107.0, 400.0, -20.799999999999756, 285.49999999999966, 171.3999999999995, -547.3, 109.89999999999989, -137.80000000000058, 18.799999999999983, 219.99999999999926, 67.40000000000002, 254.20000000000005, 46.70000000000003, 32.30000000000023, 400.0, 18.5, -11.800000000000004, 359.50000000000006, 193.5999999999994, 40.0000000000003, -115.00000000000026, 70.40000000000003, -362.7000000000005, 285.1, 184.5, 400.0, 130.8999999999997, -42.99999999999996, 25.700000000000085, -286.9, 0.0, 0.0, 199.99999999999935, -370.4999999999993, 198.0, 167.99999999999952, 89.99999999999993, 14.09999999999999, 389.2, 374.0, -31.999999999999844, -153.60000000000053, -37.49999999999968, 400.0, 40.0000000000003, 178.39999999999947, 192.29999999999944, -0.9000000000000647, 132.99999999999966, -107.00000000000007, 377.5, 400.0, -7.699999999999839, 106.69999999999985, 9.400000000000261, 22.90000000000024, -155.80000000000052, -14.999999999999929, 400.0, 282.6, 190.5, 40.0000000000003, 75.80000000000018, 180.39999999999944, 84.99999999999918, -9.09999999999982, 151.39999999999867, -19.399999999999757, 117.49999999999889, -36.999999999999964, 135.89999999999895, -45.79999999999983, 138.4999999999993, -51.49999999999984, 40.0000000000003, 9.199999999999944, 83.79999999999991, 4.199999999999548, 199.8999999999994, 129.09999999999872, -60.099999999999845, 125.79999999999916, -58.39999999999992, 7.199999999999962, -157.2, 2.7000000000000313, -143.30000000000067, 122.89999999999935, 2.0000000000000764, -137.7000000000001, -174.59999999999994, -153.70000000000002, 58.90000000000051, 222.99999999999943, -84.3000000000001, -266.29999999999995, -57.90000000000037, 106.49999999999977, 150.19999999999902, 47.20000000000036], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, -400.0, 200.0, 200.0, -19.900000000000013, -19.900000000000013, 87.49999999999997, 197.0, 161.3, 1.099999999999958, -391.6, -351.7, -213.10000000000002, 200.0, -391.6, -5.200000000000003, 20.000000000000014, -131.20000000000064, 20.000000000000014, 200.0, -328.6000000000001, 200.0, 80.0, 120.20000000000003, 128.59999999999997, -187.90000000000003, 20.000000000000014, 5.299999999999967, 200.0, 200.0, -326.5, 170.0, 183.8, -391.6, 200.0, 159.5, 167.0, 11.600000000000009, 20.000000000000014, 20.000000000000014, -341.2, 54.19999999999996, -265.6, 200.0, -206.80000000000052, -334.9, 157.7, 115.39999999999998, -368.5, 176.0, 200.0, 200.0, 20.000000000000014, 92.89999999999999, 90.80000000000003, -332.8, 20.000000000000014, -7.299999999999912, -347.5, -114.40000000000009, -400.0, 200.0, 200.0, -400.0, 170.0, 20.000000000000014, -286.5999999999991, -313.9, 200.0, -400.0, 20.000000000000014, 107.0, -40.90000000000005, 74.9000000000001, -124.9, 20.000000000000014, 200.0, 189.2, 200.0, 161.0, -324.4, 22.399999999999984, 17.900000000000013, -368.5, 5.299999999999965, -269.79999999999995, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 157.4, 20.000000000000014, -15.70000000000001, 170.0, -292.9, 20.000000000000014, 20.000000000000014, 110.0, -400.0, -106.00000000000009, 177.5, 200.0, 200.0, 200.0, -397.9, 3.1999999999999615, 200.0, -196.3000000000004, 15.800000000000011, -30.40000000000002, -19.900000000000013, 15.799999999999963, 20.000000000000014, -353.8, 5.299999999999967, -70.30000000000004, 200.0, 200.0, 128.89999999999998, 151.7, -368.5, 200.0, 20.000000000000014, 20.000000000000014, 60.199999999999974, -9.400000000000011, 20.000000000000014, 160.4, 20.000000000000014, 65.00000000000001, -215.20000000000047, -145.90000000000003, 47.90000000000022, 93.49999999999952, -15.70000000000005, -57.70000000000048, -24.099999999999916, 32.60000000000022, 3.1999999999999633, -110.20000000000003, 20.90000000000003, 34.999999999999716, 3.499999999999517, -283.3000000000003, -70.30000000000081, 165.79999999999978, -288.7, 90.1999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.79999999999981, -305.5000000000002, 116.2999999999999, -122.80000000000017, 20.000000000000014, 55.999999999999375, 101.90000000000006, 109.09999999999944, 20.000000000000014, -24.099999999999945, -166.0, 118.99999999999962, -68.20000000000005, 12.199999999999992, -307.6, 20.000000000000014, -395.8, -43.00000000000003, -236.20000000000002, 32.900000000000006, -320.2, 11.599999999999996, -313.90000000000015, -51.400000000000034, 110.29999999999987, 128.30000000000004, -280.29999999999995, -374.8, 49.09999999999937, -129.10000000000002, -116.50000000000003, -107.80000000000001, -376.9, 20.000000000000014, 38.900000000000254, 122.59999999999977, 88.39999999999961, -217.3, 20.000000000000014, -339.1, -200.19999999999993, -397.9, 20.000000000000014, 168.5, -148.00000000000054, -75.39999999999986, 140.59999999999962, 23.60000000000005, 23.600000000000072], "policy_predator_policy_reward": [142.0, 165.0, 0.0, 0.0, 19.0, 0.0, 1.0, 0.0, 9.0, 0.0, 196.0, 0.0, 89.0, 34.0, 63.0, 196.0, 58.0, 72.0, 0.0, 0.0, 123.0, 73.0, 0.0, 54.0, 7.0, 99.0, 4.0, 3.0, 0.0, 0.0, 0.0, 175.0, 119.0, 77.0, 0.0, 0.0, 4.0, 11.0, 0.0, 0.0, 0.0, 172.0, 136.0, 0.0, 3.0, 176.0, 0.0, 12.0, 185.0, 192.0, 0.0, 0.0, 0.0, 18.0, 0.0, 199.0, 13.0, 0.0, 175.0, 0.0, 0.0, 200.0, 0.0, 200.0, 10.0, 0.0, 159.0, 71.0, 200.0, 198.0, 31.0, 10.0, 29.0, 27.0, 50.0, 69.0, 0.0, 0.0, 3.0, 10.0, 106.0, 164.0, 185.0, 12.0, 138.0, 89.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 27.0, 149.0, 123.0, 3.0, 0.0, 200.0, 199.0, 0.0, 0.0, 0.0, 0.0, 188.0, 199.0, 0.0, 103.0, 0.0, 24.0, 19.0, 8.0, 178.0, 0.0, 50.0, 0.0, 0.0, 0.0, 2.0, 0.0, 174.0, 185.0, 0.0, 0.0, 14.0, 11.0, 0.0, 0.0, 0.0, 0.0, 181.0, 171.0, 0.0, 10.0, 17.0, 37.0, 55.0, 54.0, 70.0, 0.0, 40.0, 40.0, 112.0, 122.0, 43.0, 0.0, 147.0, 0.0, 0.0, 0.0, 28.0, 0.0, 128.0, 145.0, 95.0, 12.0, 14.0, 28.0, 0.0, 0.0, 96.0, 34.0, 42.0, 33.0, 156.0, 81.0, 197.0, 186.0, 122.0, 0.0, 162.0, 128.0, 0.0, 159.0, 36.0, 28.0, 143.0, 11.0, 0.0, 188.0, 71.0, 0.0, 176.0, 155.0, 0.0, 0.0, 0.0, 12.0, 0.0, 113.0, 171.0, 102.0, 199.0, 121.0, 0.0, 86.0, 57.0, 28.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1391050533954745, "mean_inference_ms": 7.929366030071355, "mean_action_processing_ms": 0.7040286126982642, "mean_env_wait_ms": 1.0198811832522683, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007943153381347656, "StateBufferConnector_ms": 0.009483695030212402, "ViewRequirementAgentConnector_ms": 0.1997143030166626}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -547.3, "episode_return_mean": 63.63499999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000, "num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 181.96316519467877, "num_env_steps_trained_throughput_per_sec": 181.96316519467877, "timesteps_total": 704000, "num_env_steps_sampled_lifetime": 704000, "num_agent_steps_sampled_lifetime": 2816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2816000, "timers": {"training_iteration_time_ms": 18528.606, "restore_workers_time_ms": 0.026, "training_step_time_ms": 18528.519, "sample_time_ms": 2471.699, "learn_time_ms": 16028.445, "learn_throughput": 249.556, "synch_weights_time_ms": 23.744}, "counters": {"num_env_steps_sampled": 704000, "num_env_steps_trained": 704000, "num_agent_steps_sampled": 2816000, "num_agent_steps_trained": 2816000}, "done": false, "training_iteration": 176, "trial_id": "3a355_00000", "date": "2024-08-13_05-41-59", "timestamp": 1723542119, "time_this_iter_s": 22.053986072540283, "time_total_s": 16316.621536016464, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73ed1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16316.621536016464, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 86.61612903225804, "ram_util_percent": 83.53548387096775}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5999511390372558, "cur_kl_coeff": 1.7219155529623348e-42, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.226169536731861, "policy_loss": -0.0013678784878855502, "vf_loss": 4.227537415393446, "vf_explained_var": 0.01989317681423571, "kl": 0.0033227542656910996, "entropy": 0.3564274312800201, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 333585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 73.49431803112938, "cur_kl_coeff": 9.659128972759139e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.595099292987238, "policy_loss": -0.0017110441005714829, "vf_loss": 6.596810362830994, "vf_explained_var": 0.04431428893533333, "kl": 0.0034833456305002164, "entropy": 0.7662191516192501, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 333585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -370.4999999999993, "episode_reward_mean": 46.02299999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -35.24350000000005, "predator_policy": 58.255}, "custom_metrics": {}, "hist_stats": {"episode_reward": [193.5999999999994, 40.0000000000003, -115.00000000000026, 70.40000000000003, -362.7000000000005, 285.1, 184.5, 400.0, 130.8999999999997, -42.99999999999996, 25.700000000000085, -286.9, 0.0, 0.0, 199.99999999999935, -370.4999999999993, 198.0, 167.99999999999952, 89.99999999999993, 14.09999999999999, 389.2, 374.0, -31.999999999999844, -153.60000000000053, -37.49999999999968, 400.0, 40.0000000000003, 178.39999999999947, 192.29999999999944, -0.9000000000000647, 132.99999999999966, -107.00000000000007, 377.5, 400.0, -7.699999999999839, 106.69999999999985, 9.400000000000261, 22.90000000000024, -155.80000000000052, -14.999999999999929, 400.0, 282.6, 190.5, 40.0000000000003, 75.80000000000018, 180.39999999999944, 84.99999999999918, -9.09999999999982, 151.39999999999867, -19.399999999999757, 117.49999999999889, -36.999999999999964, 135.89999999999895, -45.79999999999983, 138.4999999999993, -51.49999999999984, 40.0000000000003, 9.199999999999944, 83.79999999999991, 4.199999999999548, 199.8999999999994, 129.09999999999872, -60.099999999999845, 125.79999999999916, -58.39999999999992, 7.199999999999962, -157.2, 2.7000000000000313, -143.30000000000067, 122.89999999999935, 2.0000000000000764, -137.7000000000001, -174.59999999999994, -153.70000000000002, 58.90000000000051, 222.99999999999943, -84.3000000000001, -266.29999999999995, -57.90000000000037, 106.49999999999977, 150.19999999999902, 47.20000000000036, 66.50000000000018, 120.69999999999882, -165.70000000000059, 8.500000000000124, -199.09999999999974, -5.40000000000015, -202.09999999999997, 124.19999999999982, 270.20000000000016, -92.3, 175.899999999999, 40.0000000000003, 21.5000000000001, 108.39999999999827, -248.50000000000003, -121.7000000000003, -138.20000000000041, 249.3999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [167.0, 11.600000000000009, 20.000000000000014, 20.000000000000014, -341.2, 54.19999999999996, -265.6, 200.0, -206.80000000000052, -334.9, 157.7, 115.39999999999998, -368.5, 176.0, 200.0, 200.0, 20.000000000000014, 92.89999999999999, 90.80000000000003, -332.8, 20.000000000000014, -7.299999999999912, -347.5, -114.40000000000009, -400.0, 200.0, 200.0, -400.0, 170.0, 20.000000000000014, -286.5999999999991, -313.9, 200.0, -400.0, 20.000000000000014, 107.0, -40.90000000000005, 74.9000000000001, -124.9, 20.000000000000014, 200.0, 189.2, 200.0, 161.0, -324.4, 22.399999999999984, 17.900000000000013, -368.5, 5.299999999999965, -269.79999999999995, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 157.4, 20.000000000000014, -15.70000000000001, 170.0, -292.9, 20.000000000000014, 20.000000000000014, 110.0, -400.0, -106.00000000000009, 177.5, 200.0, 200.0, 200.0, -397.9, 3.1999999999999615, 200.0, -196.3000000000004, 15.800000000000011, -30.40000000000002, -19.900000000000013, 15.799999999999963, 20.000000000000014, -353.8, 5.299999999999967, -70.30000000000004, 200.0, 200.0, 128.89999999999998, 151.7, -368.5, 200.0, 20.000000000000014, 20.000000000000014, 60.199999999999974, -9.400000000000011, 20.000000000000014, 160.4, 20.000000000000014, 65.00000000000001, -215.20000000000047, -145.90000000000003, 47.90000000000022, 93.49999999999952, -15.70000000000005, -57.70000000000048, -24.099999999999916, 32.60000000000022, 3.1999999999999633, -110.20000000000003, 20.90000000000003, 34.999999999999716, 3.499999999999517, -283.3000000000003, -70.30000000000081, 165.79999999999978, -288.7, 90.1999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.79999999999981, -305.5000000000002, 116.2999999999999, -122.80000000000017, 20.000000000000014, 55.999999999999375, 101.90000000000006, 109.09999999999944, 20.000000000000014, -24.099999999999945, -166.0, 118.99999999999962, -68.20000000000005, 12.199999999999992, -307.6, 20.000000000000014, -395.8, -43.00000000000003, -236.20000000000002, 32.900000000000006, -320.2, 11.599999999999996, -313.90000000000015, -51.400000000000034, 110.29999999999987, 128.30000000000004, -280.29999999999995, -374.8, 49.09999999999937, -129.10000000000002, -116.50000000000003, -107.80000000000001, -376.9, 20.000000000000014, 38.900000000000254, 122.59999999999977, 88.39999999999961, -217.3, 20.000000000000014, -339.1, -200.19999999999993, -397.9, 20.000000000000014, 168.5, -148.00000000000054, -75.39999999999986, 140.59999999999962, 23.60000000000005, 23.600000000000072, 5.299999999999965, 45.200000000000195, -11.499999999999819, 117.19999999999948, -372.7, 20.000000000000014, -17.79999999999974, 8.300000000000036, -187.90000000000046, -110.20000000000003, 105.4999999999994, -229.9, -85.6, -284.50000000000017, 182.9, -279.69999999999925, 92.59999999999947, 176.59999999999997, 92.29999999999976, -370.6, 155.89999999999975, 20.000000000000014, 20.000000000000014, 20.000000000000014, -314.19999999999993, 103.69999999999949, 67.69999999999995, 40.70000000000025, -362.2, -121.29999999999984, 20.000000000000014, -306.7, 20.000000000000014, -320.2, 154.7, 34.699999999999505], "policy_predator_policy_reward": [4.0, 11.0, 0.0, 0.0, 0.0, 172.0, 136.0, 0.0, 3.0, 176.0, 0.0, 12.0, 185.0, 192.0, 0.0, 0.0, 0.0, 18.0, 0.0, 199.0, 13.0, 0.0, 175.0, 0.0, 0.0, 200.0, 0.0, 200.0, 10.0, 0.0, 159.0, 71.0, 200.0, 198.0, 31.0, 10.0, 29.0, 27.0, 50.0, 69.0, 0.0, 0.0, 3.0, 10.0, 106.0, 164.0, 185.0, 12.0, 138.0, 89.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 11.0, 27.0, 149.0, 123.0, 3.0, 0.0, 200.0, 199.0, 0.0, 0.0, 0.0, 0.0, 188.0, 199.0, 0.0, 103.0, 0.0, 24.0, 19.0, 8.0, 178.0, 0.0, 50.0, 0.0, 0.0, 0.0, 2.0, 0.0, 174.0, 185.0, 0.0, 0.0, 14.0, 11.0, 0.0, 0.0, 0.0, 0.0, 181.0, 171.0, 0.0, 10.0, 17.0, 37.0, 55.0, 54.0, 70.0, 0.0, 40.0, 40.0, 112.0, 122.0, 43.0, 0.0, 147.0, 0.0, 0.0, 0.0, 28.0, 0.0, 128.0, 145.0, 95.0, 12.0, 14.0, 28.0, 0.0, 0.0, 96.0, 34.0, 42.0, 33.0, 156.0, 81.0, 197.0, 186.0, 122.0, 0.0, 162.0, 128.0, 0.0, 159.0, 36.0, 28.0, 143.0, 11.0, 0.0, 188.0, 71.0, 0.0, 176.0, 155.0, 0.0, 0.0, 0.0, 12.0, 0.0, 113.0, 171.0, 102.0, 199.0, 121.0, 0.0, 86.0, 57.0, 28.0, 0.0, 0.0, 9.0, 7.0, 0.0, 15.0, 187.0, 0.0, 18.0, 0.0, 0.0, 99.0, 0.0, 119.0, 0.0, 168.0, 139.0, 82.0, 0.0, 1.0, 0.0, 186.0, 0.0, 0.0, 0.0, 0.0, 72.0, 160.0, 0.0, 0.0, 180.0, 55.0, 0.0, 165.0, 162.0, 0.0, 28.0, 32.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1342153945320685, "mean_inference_ms": 7.906734358630797, "mean_action_processing_ms": 0.7029685328541859, "mean_env_wait_ms": 1.0166990051018305, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018212556838989258, "StateBufferConnector_ms": 0.009760737419128418, "ViewRequirementAgentConnector_ms": 0.2184540033340454}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -370.4999999999993, "episode_return_mean": 46.02299999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000, "num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 176.27334391345025, "num_env_steps_trained_throughput_per_sec": 176.27334391345025, "timesteps_total": 708000, "num_env_steps_sampled_lifetime": 708000, "num_agent_steps_sampled_lifetime": 2832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2832000, "timers": {"training_iteration_time_ms": 19117.688, "restore_workers_time_ms": 0.027, "training_step_time_ms": 19117.599, "sample_time_ms": 2474.862, "learn_time_ms": 16612.627, "learn_throughput": 240.781, "synch_weights_time_ms": 25.272}, "counters": {"num_env_steps_sampled": 708000, "num_env_steps_trained": 708000, "num_agent_steps_sampled": 2832000, "num_agent_steps_trained": 2832000}, "done": false, "training_iteration": 177, "trial_id": "3a355_00000", "date": "2024-08-13_05-42-22", "timestamp": 1723542142, "time_this_iter_s": 22.803135871887207, "time_total_s": 16339.424671888351, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b74301f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16339.424671888351, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 86.02812499999999, "ram_util_percent": 83.515625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5706162740708027, "cur_kl_coeff": 8.609577764811674e-43, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.011939053308396, "policy_loss": -0.003155485172534273, "vf_loss": 6.015094539097377, "vf_explained_var": 0.012217140197753907, "kl": 0.004140514387078093, "entropy": 0.3177539444868527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 335475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 48.54555771027608, "cur_kl_coeff": 4.8295644863795696e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.670101102445491, "policy_loss": -0.001841890711150078, "vf_loss": 6.671943007827436, "vf_explained_var": 0.30476115951462396, "kl": 0.004246569230899779, "entropy": 0.6459950418699355, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 335475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -505.7, "episode_reward_mean": 21.345999999999798, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -51.562000000000054, "predator_policy": 62.235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [178.39999999999947, 192.29999999999944, -0.9000000000000647, 132.99999999999966, -107.00000000000007, 377.5, 400.0, -7.699999999999839, 106.69999999999985, 9.400000000000261, 22.90000000000024, -155.80000000000052, -14.999999999999929, 400.0, 282.6, 190.5, 40.0000000000003, 75.80000000000018, 180.39999999999944, 84.99999999999918, -9.09999999999982, 151.39999999999867, -19.399999999999757, 117.49999999999889, -36.999999999999964, 135.89999999999895, -45.79999999999983, 138.4999999999993, -51.49999999999984, 40.0000000000003, 9.199999999999944, 83.79999999999991, 4.199999999999548, 199.8999999999994, 129.09999999999872, -60.099999999999845, 125.79999999999916, -58.39999999999992, 7.199999999999962, -157.2, 2.7000000000000313, -143.30000000000067, 122.89999999999935, 2.0000000000000764, -137.7000000000001, -174.59999999999994, -153.70000000000002, 58.90000000000051, 222.99999999999943, -84.3000000000001, -266.29999999999995, -57.90000000000037, 106.49999999999977, 150.19999999999902, 47.20000000000036, 66.50000000000018, 120.69999999999882, -165.70000000000059, 8.500000000000124, -199.09999999999974, -5.40000000000015, -202.09999999999997, 124.19999999999982, 270.20000000000016, -92.3, 175.899999999999, 40.0000000000003, 21.5000000000001, 108.39999999999827, -248.50000000000003, -121.7000000000003, -138.20000000000041, 249.3999999999995, -256.79999999999984, 219.99999999999926, 32.40000000000019, -250.8, 16.69999999999996, 40.0000000000003, -78.6999999999998, -339.60000000000036, -16.499999999999993, 150.69999999999882, 188.39999999999992, 78.2999999999999, -180.00000000000065, 39.90000000000011, 182.69999999999925, -505.7, -463.5, 2.2999999999999954, 40.0000000000003, 374.8000000000003, -425.1, 73.50000000000001, -387.99999999999983, 268.1999999999996, 229.1999999999991, 194.5, 107.69999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [157.4, 20.000000000000014, -15.70000000000001, 170.0, -292.9, 20.000000000000014, 20.000000000000014, 110.0, -400.0, -106.00000000000009, 177.5, 200.0, 200.0, 200.0, -397.9, 3.1999999999999615, 200.0, -196.3000000000004, 15.800000000000011, -30.40000000000002, -19.900000000000013, 15.799999999999963, 20.000000000000014, -353.8, 5.299999999999967, -70.30000000000004, 200.0, 200.0, 128.89999999999998, 151.7, -368.5, 200.0, 20.000000000000014, 20.000000000000014, 60.199999999999974, -9.400000000000011, 20.000000000000014, 160.4, 20.000000000000014, 65.00000000000001, -215.20000000000047, -145.90000000000003, 47.90000000000022, 93.49999999999952, -15.70000000000005, -57.70000000000048, -24.099999999999916, 32.60000000000022, 3.1999999999999633, -110.20000000000003, 20.90000000000003, 34.999999999999716, 3.499999999999517, -283.3000000000003, -70.30000000000081, 165.79999999999978, -288.7, 90.1999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.79999999999981, -305.5000000000002, 116.2999999999999, -122.80000000000017, 20.000000000000014, 55.999999999999375, 101.90000000000006, 109.09999999999944, 20.000000000000014, -24.099999999999945, -166.0, 118.99999999999962, -68.20000000000005, 12.199999999999992, -307.6, 20.000000000000014, -395.8, -43.00000000000003, -236.20000000000002, 32.900000000000006, -320.2, 11.599999999999996, -313.90000000000015, -51.400000000000034, 110.29999999999987, 128.30000000000004, -280.29999999999995, -374.8, 49.09999999999937, -129.10000000000002, -116.50000000000003, -107.80000000000001, -376.9, 20.000000000000014, 38.900000000000254, 122.59999999999977, 88.39999999999961, -217.3, 20.000000000000014, -339.1, -200.19999999999993, -397.9, 20.000000000000014, 168.5, -148.00000000000054, -75.39999999999986, 140.59999999999962, 23.60000000000005, 23.600000000000072, 5.299999999999965, 45.200000000000195, -11.499999999999819, 117.19999999999948, -372.7, 20.000000000000014, -17.79999999999974, 8.300000000000036, -187.90000000000046, -110.20000000000003, 105.4999999999994, -229.9, -85.6, -284.50000000000017, 182.9, -279.69999999999925, 92.59999999999947, 176.59999999999997, 92.29999999999976, -370.6, 155.89999999999975, 20.000000000000014, 20.000000000000014, 20.000000000000014, -314.19999999999993, 103.69999999999949, 67.69999999999995, 40.70000000000025, -362.2, -121.29999999999984, 20.000000000000014, -306.7, 20.000000000000014, -320.2, 154.7, 34.699999999999505, -132.69999999999985, -255.1000000000003, 200.0, 20.000000000000014, 20.000000000000014, -34.600000000000044, -339.1, -246.70000000000002, -322.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.200000000000003, -323.49999999999966, -332.8, -200.80000000000018, 167.0, -389.5, 130.69999999999956, 20.000000000000014, 197.0, -223.60000000000002, -187.90000000000003, 165.19999999999996, 20.000000000000014, -400.0, 47.90000000000011, -211.00000000000003, 17.899999999999988, 153.7999999999999, -324.4, -364.3, -347.5, -400.0, -355.9, 174.2, 20.000000000000014, 20.000000000000014, 198.2, 176.59999999999994, -395.8, -385.3, -242.5, 191.0, -255.10000000000005, -271.9, 182.0, -11.800000000000304, 25.700000000000237, 195.49999999999997, 200.0, -368.5, -1.0, 7.6999999999998465], "policy_predator_policy_reward": [1.0, 0.0, 11.0, 27.0, 149.0, 123.0, 3.0, 0.0, 200.0, 199.0, 0.0, 0.0, 0.0, 0.0, 188.0, 199.0, 0.0, 103.0, 0.0, 24.0, 19.0, 8.0, 178.0, 0.0, 50.0, 0.0, 0.0, 0.0, 2.0, 0.0, 174.0, 185.0, 0.0, 0.0, 14.0, 11.0, 0.0, 0.0, 0.0, 0.0, 181.0, 171.0, 0.0, 10.0, 17.0, 37.0, 55.0, 54.0, 70.0, 0.0, 40.0, 40.0, 112.0, 122.0, 43.0, 0.0, 147.0, 0.0, 0.0, 0.0, 28.0, 0.0, 128.0, 145.0, 95.0, 12.0, 14.0, 28.0, 0.0, 0.0, 96.0, 34.0, 42.0, 33.0, 156.0, 81.0, 197.0, 186.0, 122.0, 0.0, 162.0, 128.0, 0.0, 159.0, 36.0, 28.0, 143.0, 11.0, 0.0, 188.0, 71.0, 0.0, 176.0, 155.0, 0.0, 0.0, 0.0, 12.0, 0.0, 113.0, 171.0, 102.0, 199.0, 121.0, 0.0, 86.0, 57.0, 28.0, 0.0, 0.0, 9.0, 7.0, 0.0, 15.0, 187.0, 0.0, 18.0, 0.0, 0.0, 99.0, 0.0, 119.0, 0.0, 168.0, 139.0, 82.0, 0.0, 1.0, 0.0, 186.0, 0.0, 0.0, 0.0, 0.0, 72.0, 160.0, 0.0, 0.0, 180.0, 55.0, 0.0, 165.0, 162.0, 0.0, 28.0, 32.0, 0.0, 131.0, 0.0, 0.0, 21.0, 26.0, 171.0, 164.0, 156.0, 163.0, 0.0, 0.0, 155.0, 95.0, 194.0, 0.0, 11.0, 195.0, 0.0, 0.0, 99.0, 116.0, 99.0, 2.0, 200.0, 0.0, 102.0, 101.0, 11.0, 0.0, 0.0, 183.0, 84.0, 200.0, 5.0, 179.0, 0.0, 0.0, 0.0, 0.0, 168.0, 188.0, 0.0, 125.0, 0.0, 139.0, 52.0, 46.0, 8.0, 0.0, 178.0, 185.0, 46.0, 55.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.16863056208375, "mean_inference_ms": 7.836130900046202, "mean_action_processing_ms": 0.7031900806828826, "mean_env_wait_ms": 1.014674326334405, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01862466335296631, "StateBufferConnector_ms": 0.009925246238708496, "ViewRequirementAgentConnector_ms": 0.22795474529266357}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": -505.7, "episode_return_mean": 21.345999999999798, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000, "num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 184.70728983507888, "num_env_steps_trained_throughput_per_sec": 184.70728983507888, "timesteps_total": 712000, "num_env_steps_sampled_lifetime": 712000, "num_agent_steps_sampled_lifetime": 2848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2848000, "timers": {"training_iteration_time_ms": 19649.643, "restore_workers_time_ms": 0.026, "training_step_time_ms": 19649.554, "sample_time_ms": 2693.573, "learn_time_ms": 16926.34, "learn_throughput": 236.318, "synch_weights_time_ms": 24.911}, "counters": {"num_env_steps_sampled": 712000, "num_env_steps_trained": 712000, "num_agent_steps_sampled": 2848000, "num_agent_steps_trained": 2848000}, "done": false, "training_iteration": 178, "trial_id": "3a355_00000", "date": "2024-08-13_05-42-44", "timestamp": 1723542164, "time_this_iter_s": 21.708054065704346, "time_total_s": 16361.132725954056, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b74323a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16361.132725954056, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 83.87741935483874, "ram_util_percent": 83.56774193548385}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4344513865493278, "cur_kl_coeff": 4.304788882405837e-43, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.487144612887549, "policy_loss": -0.000972702289517555, "vf_loss": 4.488117318557053, "vf_explained_var": 0.00921020542503034, "kl": 0.0025291415620339575, "entropy": 0.32743172889979427, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 337365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 49.10929138158995, "cur_kl_coeff": 2.4147822431897848e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.747574736327722, "policy_loss": 0.0005104499499476146, "vf_loss": 5.7470642950169, "vf_explained_var": 0.23992279380086867, "kl": 0.0033955506342639007, "entropy": 0.5878055896866259, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 337365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000}, "env_runners": {"episode_reward_max": 374.8000000000003, "episode_reward_min": -505.7, "episode_reward_mean": 8.956999999999772, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -61.07650000000005, "predator_policy": 65.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.39999999999944, 84.99999999999918, -9.09999999999982, 151.39999999999867, -19.399999999999757, 117.49999999999889, -36.999999999999964, 135.89999999999895, -45.79999999999983, 138.4999999999993, -51.49999999999984, 40.0000000000003, 9.199999999999944, 83.79999999999991, 4.199999999999548, 199.8999999999994, 129.09999999999872, -60.099999999999845, 125.79999999999916, -58.39999999999992, 7.199999999999962, -157.2, 2.7000000000000313, -143.30000000000067, 122.89999999999935, 2.0000000000000764, -137.7000000000001, -174.59999999999994, -153.70000000000002, 58.90000000000051, 222.99999999999943, -84.3000000000001, -266.29999999999995, -57.90000000000037, 106.49999999999977, 150.19999999999902, 47.20000000000036, 66.50000000000018, 120.69999999999882, -165.70000000000059, 8.500000000000124, -199.09999999999974, -5.40000000000015, -202.09999999999997, 124.19999999999982, 270.20000000000016, -92.3, 175.899999999999, 40.0000000000003, 21.5000000000001, 108.39999999999827, -248.50000000000003, -121.7000000000003, -138.20000000000041, 249.3999999999995, -256.79999999999984, 219.99999999999926, 32.40000000000019, -250.8, 16.69999999999996, 40.0000000000003, -78.6999999999998, -339.60000000000036, -16.499999999999993, 150.69999999999882, 188.39999999999992, 78.2999999999999, -180.00000000000065, 39.90000000000011, 182.69999999999925, -505.7, -463.5, 2.2999999999999954, 40.0000000000003, 374.8000000000003, -425.1, 73.50000000000001, -387.99999999999983, 268.1999999999996, 229.1999999999991, 194.5, 107.69999999999926, 79.59999999999953, 73.99999999999972, 334.8000000000002, -150.70000000000047, 45.10000000000003, -3.1999999999999478, -468.20000000000005, 192.8, 62.60000000000034, 216.39999999999927, 126.7999999999988, 322.0, 176.30000000000004, -347.9, 58.90000000000005, 54.59999999999975, -3.0, 112.89999999999898], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 160.4, 20.000000000000014, 65.00000000000001, -215.20000000000047, -145.90000000000003, 47.90000000000022, 93.49999999999952, -15.70000000000005, -57.70000000000048, -24.099999999999916, 32.60000000000022, 3.1999999999999633, -110.20000000000003, 20.90000000000003, 34.999999999999716, 3.499999999999517, -283.3000000000003, -70.30000000000081, 165.79999999999978, -288.7, 90.1999999999993, 20.000000000000014, 20.000000000000014, 20.000000000000014, -38.79999999999981, -305.5000000000002, 116.2999999999999, -122.80000000000017, 20.000000000000014, 55.999999999999375, 101.90000000000006, 109.09999999999944, 20.000000000000014, -24.099999999999945, -166.0, 118.99999999999962, -68.20000000000005, 12.199999999999992, -307.6, 20.000000000000014, -395.8, -43.00000000000003, -236.20000000000002, 32.900000000000006, -320.2, 11.599999999999996, -313.90000000000015, -51.400000000000034, 110.29999999999987, 128.30000000000004, -280.29999999999995, -374.8, 49.09999999999937, -129.10000000000002, -116.50000000000003, -107.80000000000001, -376.9, 20.000000000000014, 38.900000000000254, 122.59999999999977, 88.39999999999961, -217.3, 20.000000000000014, -339.1, -200.19999999999993, -397.9, 20.000000000000014, 168.5, -148.00000000000054, -75.39999999999986, 140.59999999999962, 23.60000000000005, 23.600000000000072, 5.299999999999965, 45.200000000000195, -11.499999999999819, 117.19999999999948, -372.7, 20.000000000000014, -17.79999999999974, 8.300000000000036, -187.90000000000046, -110.20000000000003, 105.4999999999994, -229.9, -85.6, -284.50000000000017, 182.9, -279.69999999999925, 92.59999999999947, 176.59999999999997, 92.29999999999976, -370.6, 155.89999999999975, 20.000000000000014, 20.000000000000014, 20.000000000000014, -314.19999999999993, 103.69999999999949, 67.69999999999995, 40.70000000000025, -362.2, -121.29999999999984, 20.000000000000014, -306.7, 20.000000000000014, -320.2, 154.7, 34.699999999999505, -132.69999999999985, -255.1000000000003, 200.0, 20.000000000000014, 20.000000000000014, -34.600000000000044, -339.1, -246.70000000000002, -322.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.200000000000003, -323.49999999999966, -332.8, -200.80000000000018, 167.0, -389.5, 130.69999999999956, 20.000000000000014, 197.0, -223.60000000000002, -187.90000000000003, 165.19999999999996, 20.000000000000014, -400.0, 47.90000000000011, -211.00000000000003, 17.899999999999988, 153.7999999999999, -324.4, -364.3, -347.5, -400.0, -355.9, 174.2, 20.000000000000014, 20.000000000000014, 198.2, 176.59999999999994, -395.8, -385.3, -242.5, 191.0, -255.10000000000005, -271.9, 182.0, -11.800000000000304, 25.700000000000237, 195.49999999999997, 200.0, -368.5, -1.0, 7.6999999999998465, 20.000000000000014, 59.60000000000012, 53.0000000000002, 20.000000000000014, 200.0, 105.79999999999995, 41.600000000000115, -385.29999999999995, -313.9, 200.0, -383.2, 20.000000000000014, -303.4, -332.79999999999995, 200.0, -383.2, -21.39999999999982, 20.000000000000014, 182.9, 33.50000000000025, 78.1999999999993, 44.59999999999997, 101.0, 188.0, 194.0, -309.7, -330.7, -299.2, -263.5, 187.4, 86.5999999999997, -148.0, -400.0, 77.0, 92.89999999999955, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 181.0, 171.0, 0.0, 10.0, 17.0, 37.0, 55.0, 54.0, 70.0, 0.0, 40.0, 40.0, 112.0, 122.0, 43.0, 0.0, 147.0, 0.0, 0.0, 0.0, 28.0, 0.0, 128.0, 145.0, 95.0, 12.0, 14.0, 28.0, 0.0, 0.0, 96.0, 34.0, 42.0, 33.0, 156.0, 81.0, 197.0, 186.0, 122.0, 0.0, 162.0, 128.0, 0.0, 159.0, 36.0, 28.0, 143.0, 11.0, 0.0, 188.0, 71.0, 0.0, 176.0, 155.0, 0.0, 0.0, 0.0, 12.0, 0.0, 113.0, 171.0, 102.0, 199.0, 121.0, 0.0, 86.0, 57.0, 28.0, 0.0, 0.0, 9.0, 7.0, 0.0, 15.0, 187.0, 0.0, 18.0, 0.0, 0.0, 99.0, 0.0, 119.0, 0.0, 168.0, 139.0, 82.0, 0.0, 1.0, 0.0, 186.0, 0.0, 0.0, 0.0, 0.0, 72.0, 160.0, 0.0, 0.0, 180.0, 55.0, 0.0, 165.0, 162.0, 0.0, 28.0, 32.0, 0.0, 131.0, 0.0, 0.0, 21.0, 26.0, 171.0, 164.0, 156.0, 163.0, 0.0, 0.0, 155.0, 95.0, 194.0, 0.0, 11.0, 195.0, 0.0, 0.0, 99.0, 116.0, 99.0, 2.0, 200.0, 0.0, 102.0, 101.0, 11.0, 0.0, 0.0, 183.0, 84.0, 200.0, 5.0, 179.0, 0.0, 0.0, 0.0, 0.0, 168.0, 188.0, 0.0, 125.0, 0.0, 139.0, 52.0, 46.0, 8.0, 0.0, 178.0, 185.0, 46.0, 55.0, 0.0, 0.0, 0.0, 1.0, 3.0, 26.0, 0.0, 193.0, 159.0, 0.0, 168.0, 192.0, 168.0, 0.0, 192.0, 184.0, 36.0, 28.0, 0.0, 0.0, 4.0, 0.0, 33.0, 0.0, 159.0, 133.0, 115.0, 167.0, 135.0, 0.0, 0.0, 116.0, 120.0, 200.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1251386914561996, "mean_inference_ms": 7.85847676481782, "mean_action_processing_ms": 0.7014134391185378, "mean_env_wait_ms": 1.0098530788984394, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016599535942077637, "StateBufferConnector_ms": 0.008989810943603516, "ViewRequirementAgentConnector_ms": 0.28553950786590576}, "num_episodes": 18, "episode_return_max": 374.8000000000003, "episode_return_min": -505.7, "episode_return_mean": 8.956999999999772, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000, "num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 178.07726328755373, "num_env_steps_trained_throughput_per_sec": 178.07726328755373, "timesteps_total": 716000, "num_env_steps_sampled_lifetime": 716000, "num_agent_steps_sampled_lifetime": 2864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2864000, "timers": {"training_iteration_time_ms": 20233.616, "restore_workers_time_ms": 0.025, "training_step_time_ms": 20233.53, "sample_time_ms": 2952.899, "learn_time_ms": 17249.41, "learn_throughput": 231.892, "synch_weights_time_ms": 26.037}, "counters": {"num_env_steps_sampled": 716000, "num_env_steps_trained": 716000, "num_agent_steps_sampled": 2864000, "num_agent_steps_trained": 2864000}, "done": false, "training_iteration": 179, "trial_id": "3a355_00000", "date": "2024-08-13_05-43-06", "timestamp": 1723542186, "time_this_iter_s": 22.516721963882446, "time_total_s": 16383.649447917938, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b507e3a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16383.649447917938, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 85.25161290322582, "ram_util_percent": 83.4483870967742}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6963813988620011, "cur_kl_coeff": 2.1523944412029185e-43, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8730278534863993, "policy_loss": -0.001634877625478323, "vf_loss": 3.874662716931136, "vf_explained_var": 0.0009116534202817887, "kl": 0.002720207681866141, "entropy": 0.33621718733714373, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 339255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 37.67659887926919, "cur_kl_coeff": 1.2073911215948924e-23, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.091701306363262, "policy_loss": -0.0004405638350853844, "vf_loss": 5.0921418540692205, "vf_explained_var": 0.4451490829545985, "kl": 0.0033626964909298502, "entropy": 0.5964818008835353, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 339255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000}, "env_runners": {"episode_reward_max": 374.8000000000003, "episode_reward_min": -505.7, "episode_reward_mean": 8.711999999999803, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 229.0}, "policy_reward_mean": {"prey_policy": -64.67400000000004, "predator_policy": 69.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [125.79999999999916, -58.39999999999992, 7.199999999999962, -157.2, 2.7000000000000313, -143.30000000000067, 122.89999999999935, 2.0000000000000764, -137.7000000000001, -174.59999999999994, -153.70000000000002, 58.90000000000051, 222.99999999999943, -84.3000000000001, -266.29999999999995, -57.90000000000037, 106.49999999999977, 150.19999999999902, 47.20000000000036, 66.50000000000018, 120.69999999999882, -165.70000000000059, 8.500000000000124, -199.09999999999974, -5.40000000000015, -202.09999999999997, 124.19999999999982, 270.20000000000016, -92.3, 175.899999999999, 40.0000000000003, 21.5000000000001, 108.39999999999827, -248.50000000000003, -121.7000000000003, -138.20000000000041, 249.3999999999995, -256.79999999999984, 219.99999999999926, 32.40000000000019, -250.8, 16.69999999999996, 40.0000000000003, -78.6999999999998, -339.60000000000036, -16.499999999999993, 150.69999999999882, 188.39999999999992, 78.2999999999999, -180.00000000000065, 39.90000000000011, 182.69999999999925, -505.7, -463.5, 2.2999999999999954, 40.0000000000003, 374.8000000000003, -425.1, 73.50000000000001, -387.99999999999983, 268.1999999999996, 229.1999999999991, 194.5, 107.69999999999926, 79.59999999999953, 73.99999999999972, 334.8000000000002, -150.70000000000047, 45.10000000000003, -3.1999999999999478, -468.20000000000005, 192.8, 62.60000000000034, 216.39999999999927, 126.7999999999988, 322.0, 176.30000000000004, -347.9, 58.90000000000005, 54.59999999999975, -3.0, 112.89999999999898, 223.09999999999957, -173.40000000000052, 174.59999999999945, 108.29999999999983, -335.4000000000003, 357.70000000000005, 172.30000000000004, 352.3, 89.99999999999923, -285.80000000000007, -45.899999999999984, -120.5000000000008, 58.30000000000005, -259.20000000000005, 185.79999999999905, 14.199999999999964, 181.29999999999944, 329.8000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [118.99999999999962, -68.20000000000005, 12.199999999999992, -307.6, 20.000000000000014, -395.8, -43.00000000000003, -236.20000000000002, 32.900000000000006, -320.2, 11.599999999999996, -313.90000000000015, -51.400000000000034, 110.29999999999987, 128.30000000000004, -280.29999999999995, -374.8, 49.09999999999937, -129.10000000000002, -116.50000000000003, -107.80000000000001, -376.9, 20.000000000000014, 38.900000000000254, 122.59999999999977, 88.39999999999961, -217.3, 20.000000000000014, -339.1, -200.19999999999993, -397.9, 20.000000000000014, 168.5, -148.00000000000054, -75.39999999999986, 140.59999999999962, 23.60000000000005, 23.600000000000072, 5.299999999999965, 45.200000000000195, -11.499999999999819, 117.19999999999948, -372.7, 20.000000000000014, -17.79999999999974, 8.300000000000036, -187.90000000000046, -110.20000000000003, 105.4999999999994, -229.9, -85.6, -284.50000000000017, 182.9, -279.69999999999925, 92.59999999999947, 176.59999999999997, 92.29999999999976, -370.6, 155.89999999999975, 20.000000000000014, 20.000000000000014, 20.000000000000014, -314.19999999999993, 103.69999999999949, 67.69999999999995, 40.70000000000025, -362.2, -121.29999999999984, 20.000000000000014, -306.7, 20.000000000000014, -320.2, 154.7, 34.699999999999505, -132.69999999999985, -255.1000000000003, 200.0, 20.000000000000014, 20.000000000000014, -34.600000000000044, -339.1, -246.70000000000002, -322.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.200000000000003, -323.49999999999966, -332.8, -200.80000000000018, 167.0, -389.5, 130.69999999999956, 20.000000000000014, 197.0, -223.60000000000002, -187.90000000000003, 165.19999999999996, 20.000000000000014, -400.0, 47.90000000000011, -211.00000000000003, 17.899999999999988, 153.7999999999999, -324.4, -364.3, -347.5, -400.0, -355.9, 174.2, 20.000000000000014, 20.000000000000014, 198.2, 176.59999999999994, -395.8, -385.3, -242.5, 191.0, -255.10000000000005, -271.9, 182.0, -11.800000000000304, 25.700000000000237, 195.49999999999997, 200.0, -368.5, -1.0, 7.6999999999998465, 20.000000000000014, 59.60000000000012, 53.0000000000002, 20.000000000000014, 200.0, 105.79999999999995, 41.600000000000115, -385.29999999999995, -313.9, 200.0, -383.2, 20.000000000000014, -303.4, -332.79999999999995, 200.0, -383.2, -21.39999999999982, 20.000000000000014, 182.9, 33.50000000000025, 78.1999999999993, 44.59999999999997, 101.0, 188.0, 194.0, -309.7, -330.7, -299.2, -263.5, 187.4, 86.5999999999997, -148.0, -400.0, 77.0, 92.89999999999955, 20.000000000000014, 37.09999999999998, 179.0, -261.4, -106.00000000000074, 166.7, -3.099999999999958, 182.9, -160.60000000000016, -389.5, -145.90000000000003, 157.7, 200.0, 165.8, -221.5, 143.3, 200.0, 76.69999999999956, -36.700000000000024, -218.8, -400.0, -395.8, 140.9, -278.2000000000002, 7.699999999999967, -288.7, 200.0, -341.0, -299.2000000000001, 165.79999999999978, 20.000000000000014, -374.8, 20.000000000000014, 161.3, 20.000000000000014, 145.99999999999966, 183.8], "policy_predator_policy_reward": [42.0, 33.0, 156.0, 81.0, 197.0, 186.0, 122.0, 0.0, 162.0, 128.0, 0.0, 159.0, 36.0, 28.0, 143.0, 11.0, 0.0, 188.0, 71.0, 0.0, 176.0, 155.0, 0.0, 0.0, 0.0, 12.0, 0.0, 113.0, 171.0, 102.0, 199.0, 121.0, 0.0, 86.0, 57.0, 28.0, 0.0, 0.0, 9.0, 7.0, 0.0, 15.0, 187.0, 0.0, 18.0, 0.0, 0.0, 99.0, 0.0, 119.0, 0.0, 168.0, 139.0, 82.0, 0.0, 1.0, 0.0, 186.0, 0.0, 0.0, 0.0, 0.0, 72.0, 160.0, 0.0, 0.0, 180.0, 55.0, 0.0, 165.0, 162.0, 0.0, 28.0, 32.0, 0.0, 131.0, 0.0, 0.0, 21.0, 26.0, 171.0, 164.0, 156.0, 163.0, 0.0, 0.0, 155.0, 95.0, 194.0, 0.0, 11.0, 195.0, 0.0, 0.0, 99.0, 116.0, 99.0, 2.0, 200.0, 0.0, 102.0, 101.0, 11.0, 0.0, 0.0, 183.0, 84.0, 200.0, 5.0, 179.0, 0.0, 0.0, 0.0, 0.0, 168.0, 188.0, 0.0, 125.0, 0.0, 139.0, 52.0, 46.0, 8.0, 0.0, 178.0, 185.0, 46.0, 55.0, 0.0, 0.0, 0.0, 1.0, 3.0, 26.0, 0.0, 193.0, 159.0, 0.0, 168.0, 192.0, 168.0, 0.0, 192.0, 184.0, 36.0, 28.0, 0.0, 0.0, 4.0, 0.0, 33.0, 0.0, 159.0, 133.0, 115.0, 167.0, 135.0, 0.0, 0.0, 116.0, 120.0, 200.0, 0.0, 0.0, 0.0, 7.0, 60.0, 134.0, 11.0, 0.0, 0.0, 86.0, 200.0, 0.0, 0.0, 0.0, 113.0, 115.0, 0.0, 9.0, 23.0, 27.0, 200.0, 133.0, 198.0, 11.0, 0.0, 150.0, 147.0, 0.0, 229.0, 152.0, 0.0, 0.0, 188.0, 181.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1226172746296417, "mean_inference_ms": 7.841035482394911, "mean_action_processing_ms": 0.701078333999277, "mean_env_wait_ms": 1.007445140571532, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016605138778686523, "StateBufferConnector_ms": 0.009050846099853516, "ViewRequirementAgentConnector_ms": 0.2953147888183594}, "num_episodes": 18, "episode_return_max": 374.8000000000003, "episode_return_min": -505.7, "episode_return_mean": 8.711999999999803, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000, "num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 161.96473622156591, "num_env_steps_trained_throughput_per_sec": 161.96473622156591, "timesteps_total": 720000, "num_env_steps_sampled_lifetime": 720000, "num_agent_steps_sampled_lifetime": 2880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2880000, "timers": {"training_iteration_time_ms": 21010.471, "restore_workers_time_ms": 0.026, "training_step_time_ms": 21010.385, "sample_time_ms": 3104.488, "learn_time_ms": 17874.348, "learn_throughput": 223.784, "synch_weights_time_ms": 26.291}, "counters": {"num_env_steps_sampled": 720000, "num_env_steps_trained": 720000, "num_agent_steps_sampled": 2880000, "num_agent_steps_trained": 2880000}, "done": false, "training_iteration": 180, "trial_id": "3a355_00000", "date": "2024-08-13_05-43-31", "timestamp": 1723542211, "time_this_iter_s": 24.79212999343872, "time_total_s": 16408.441577911377, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b7430940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16408.441577911377, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 87.36944444444445, "ram_util_percent": 83.6111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.443750729250214, "cur_kl_coeff": 1.0761972206014593e-43, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.752962659275721, "policy_loss": -0.0009359254192551056, "vf_loss": 3.753898579229123, "vf_explained_var": 0.00335003967007632, "kl": 0.0019041600677345736, "entropy": 0.2797520149794836, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 341145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 45.801618439605626, "cur_kl_coeff": 6.036955607974462e-24, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.256279565922167, "policy_loss": 0.0004553237042966343, "vf_loss": 5.255824237399631, "vf_explained_var": 0.4704880088094681, "kl": 0.0016760218246334925, "entropy": 0.6472477051946852, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 341145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000}, "env_runners": {"episode_reward_max": 387.0, "episode_reward_min": -505.7, "episode_reward_mean": 34.81799999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 229.0}, "policy_reward_mean": {"prey_policy": -44.61600000000002, "predator_policy": 62.025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [47.20000000000036, 66.50000000000018, 120.69999999999882, -165.70000000000059, 8.500000000000124, -199.09999999999974, -5.40000000000015, -202.09999999999997, 124.19999999999982, 270.20000000000016, -92.3, 175.899999999999, 40.0000000000003, 21.5000000000001, 108.39999999999827, -248.50000000000003, -121.7000000000003, -138.20000000000041, 249.3999999999995, -256.79999999999984, 219.99999999999926, 32.40000000000019, -250.8, 16.69999999999996, 40.0000000000003, -78.6999999999998, -339.60000000000036, -16.499999999999993, 150.69999999999882, 188.39999999999992, 78.2999999999999, -180.00000000000065, 39.90000000000011, 182.69999999999925, -505.7, -463.5, 2.2999999999999954, 40.0000000000003, 374.8000000000003, -425.1, 73.50000000000001, -387.99999999999983, 268.1999999999996, 229.1999999999991, 194.5, 107.69999999999926, 79.59999999999953, 73.99999999999972, 334.8000000000002, -150.70000000000047, 45.10000000000003, -3.1999999999999478, -468.20000000000005, 192.8, 62.60000000000034, 216.39999999999927, 126.7999999999988, 322.0, 176.30000000000004, -347.9, 58.90000000000005, 54.59999999999975, -3.0, 112.89999999999898, 223.09999999999957, -173.40000000000052, 174.59999999999945, 108.29999999999983, -335.4000000000003, 357.70000000000005, 172.30000000000004, 352.3, 89.99999999999923, -285.80000000000007, -45.899999999999984, -120.5000000000008, 58.30000000000005, -259.20000000000005, 185.79999999999905, 14.199999999999964, 181.29999999999944, 329.8000000000014, 350.5, -133.10000000000036, 236.99999999999946, 109.39999999999955, 227.19999999999925, 366.8000000000002, 169.5999999999995, 58.0000000000003, 283.9000000000002, 387.0, 27.500000000000014, -43.6999999999997, 27.10000000000001, 60.80000000000004, -66.49999999999983, -24.19999999999998, 209.0999999999993, -70.00000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [23.60000000000005, 23.600000000000072, 5.299999999999965, 45.200000000000195, -11.499999999999819, 117.19999999999948, -372.7, 20.000000000000014, -17.79999999999974, 8.300000000000036, -187.90000000000046, -110.20000000000003, 105.4999999999994, -229.9, -85.6, -284.50000000000017, 182.9, -279.69999999999925, 92.59999999999947, 176.59999999999997, 92.29999999999976, -370.6, 155.89999999999975, 20.000000000000014, 20.000000000000014, 20.000000000000014, -314.19999999999993, 103.69999999999949, 67.69999999999995, 40.70000000000025, -362.2, -121.29999999999984, 20.000000000000014, -306.7, 20.000000000000014, -320.2, 154.7, 34.699999999999505, -132.69999999999985, -255.1000000000003, 200.0, 20.000000000000014, 20.000000000000014, -34.600000000000044, -339.1, -246.70000000000002, -322.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.200000000000003, -323.49999999999966, -332.8, -200.80000000000018, 167.0, -389.5, 130.69999999999956, 20.000000000000014, 197.0, -223.60000000000002, -187.90000000000003, 165.19999999999996, 20.000000000000014, -400.0, 47.90000000000011, -211.00000000000003, 17.899999999999988, 153.7999999999999, -324.4, -364.3, -347.5, -400.0, -355.9, 174.2, 20.000000000000014, 20.000000000000014, 198.2, 176.59999999999994, -395.8, -385.3, -242.5, 191.0, -255.10000000000005, -271.9, 182.0, -11.800000000000304, 25.700000000000237, 195.49999999999997, 200.0, -368.5, -1.0, 7.6999999999998465, 20.000000000000014, 59.60000000000012, 53.0000000000002, 20.000000000000014, 200.0, 105.79999999999995, 41.600000000000115, -385.29999999999995, -313.9, 200.0, -383.2, 20.000000000000014, -303.4, -332.79999999999995, 200.0, -383.2, -21.39999999999982, 20.000000000000014, 182.9, 33.50000000000025, 78.1999999999993, 44.59999999999997, 101.0, 188.0, 194.0, -309.7, -330.7, -299.2, -263.5, 187.4, 86.5999999999997, -148.0, -400.0, 77.0, 92.89999999999955, 20.000000000000014, 37.09999999999998, 179.0, -261.4, -106.00000000000074, 166.7, -3.099999999999958, 182.9, -160.60000000000016, -389.5, -145.90000000000003, 157.7, 200.0, 165.8, -221.5, 143.3, 200.0, 76.69999999999956, -36.700000000000024, -218.8, -400.0, -395.8, 140.9, -278.2000000000002, 7.699999999999967, -288.7, 200.0, -341.0, -299.2000000000001, 165.79999999999978, 20.000000000000014, -374.8, 20.000000000000014, 161.3, 20.000000000000014, 145.99999999999966, 183.8, 181.1, 169.4, 41.60000000000018, -351.7, 185.0, 47.00000000000007, -217.3, 97.69999999999956, 200.0, 27.200000000000145, 174.79999999999995, 188.0, -9.400000000000007, 143.0, 20.000000000000014, 38.00000000000014, 117.19999999999948, 166.7, 191.0, 194.0, 200.0, -347.5, -3.099999999999958, -349.60000000000014, -313.89999999999907, 182.0, -248.5, 179.3, -87.10000000000004, -30.40000000000002, -345.4, 141.2, 184.1, 20.000000000000014, -190.00000000000003, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 9.0, 7.0, 0.0, 15.0, 187.0, 0.0, 18.0, 0.0, 0.0, 99.0, 0.0, 119.0, 0.0, 168.0, 139.0, 82.0, 0.0, 1.0, 0.0, 186.0, 0.0, 0.0, 0.0, 0.0, 72.0, 160.0, 0.0, 0.0, 180.0, 55.0, 0.0, 165.0, 162.0, 0.0, 28.0, 32.0, 0.0, 131.0, 0.0, 0.0, 21.0, 26.0, 171.0, 164.0, 156.0, 163.0, 0.0, 0.0, 155.0, 95.0, 194.0, 0.0, 11.0, 195.0, 0.0, 0.0, 99.0, 116.0, 99.0, 2.0, 200.0, 0.0, 102.0, 101.0, 11.0, 0.0, 0.0, 183.0, 84.0, 200.0, 5.0, 179.0, 0.0, 0.0, 0.0, 0.0, 168.0, 188.0, 0.0, 125.0, 0.0, 139.0, 52.0, 46.0, 8.0, 0.0, 178.0, 185.0, 46.0, 55.0, 0.0, 0.0, 0.0, 1.0, 3.0, 26.0, 0.0, 193.0, 159.0, 0.0, 168.0, 192.0, 168.0, 0.0, 192.0, 184.0, 36.0, 28.0, 0.0, 0.0, 4.0, 0.0, 33.0, 0.0, 159.0, 133.0, 115.0, 167.0, 135.0, 0.0, 0.0, 116.0, 120.0, 200.0, 0.0, 0.0, 0.0, 7.0, 60.0, 134.0, 11.0, 0.0, 0.0, 86.0, 200.0, 0.0, 0.0, 0.0, 113.0, 115.0, 0.0, 9.0, 23.0, 27.0, 200.0, 133.0, 198.0, 11.0, 0.0, 150.0, 147.0, 0.0, 229.0, 152.0, 0.0, 0.0, 188.0, 181.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 177.0, 0.0, 5.0, 109.0, 120.0, 0.0, 0.0, 4.0, 0.0, 27.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 175.0, 0.0, 176.0, 133.0, 0.0, 159.0, 130.0, 0.0, 0.0, 51.0, 177.0, 3.0, 5.0, 0.0, 100.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.120294593609128, "mean_inference_ms": 7.824599000210457, "mean_action_processing_ms": 0.7008493126996282, "mean_env_wait_ms": 1.0051573139802799, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017445802688598633, "StateBufferConnector_ms": 0.011806488037109375, "ViewRequirementAgentConnector_ms": 0.29122281074523926}, "num_episodes": 18, "episode_return_max": 387.0, "episode_return_min": -505.7, "episode_return_mean": 34.81799999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000, "num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 185.64115726435136, "num_env_steps_trained_throughput_per_sec": 185.64115726435136, "timesteps_total": 724000, "num_env_steps_sampled_lifetime": 724000, "num_agent_steps_sampled_lifetime": 2896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2896000, "timers": {"training_iteration_time_ms": 21441.404, "restore_workers_time_ms": 0.026, "training_step_time_ms": 21441.315, "sample_time_ms": 3214.186, "learn_time_ms": 18191.449, "learn_throughput": 219.884, "synch_weights_time_ms": 31.004}, "counters": {"num_env_steps_sampled": 724000, "num_env_steps_trained": 724000, "num_agent_steps_sampled": 2896000, "num_agent_steps_trained": 2896000}, "done": false, "training_iteration": 181, "trial_id": "3a355_00000", "date": "2024-08-13_05-43-53", "timestamp": 1723542233, "time_this_iter_s": 21.653229236602783, "time_total_s": 16430.09480714798, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5f61ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16430.09480714798, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 84.26333333333334, "ram_util_percent": 83.47999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2697070561940709, "cur_kl_coeff": 5.380986103007296e-44, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7509895723332805, "policy_loss": -0.0020563229691808816, "vf_loss": 3.7530458900663586, "vf_explained_var": 0.002974609092429832, "kl": 0.004485125169686211, "entropy": 0.27494740585486094, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 343035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 61.45901387751733, "cur_kl_coeff": 3.018477803987231e-24, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.037662837745021, "policy_loss": 0.00012991664236381887, "vf_loss": 5.037532918163078, "vf_explained_var": 0.464765390864125, "kl": 0.002468149608820948, "entropy": 0.6638383480133834, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 343035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000}, "env_runners": {"episode_reward_max": 387.0, "episode_reward_min": -505.7, "episode_reward_mean": 50.44399999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 229.0}, "policy_reward_mean": {"prey_policy": -37.983000000000025, "predator_policy": 63.205}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.69999999999996, 40.0000000000003, -78.6999999999998, -339.60000000000036, -16.499999999999993, 150.69999999999882, 188.39999999999992, 78.2999999999999, -180.00000000000065, 39.90000000000011, 182.69999999999925, -505.7, -463.5, 2.2999999999999954, 40.0000000000003, 374.8000000000003, -425.1, 73.50000000000001, -387.99999999999983, 268.1999999999996, 229.1999999999991, 194.5, 107.69999999999926, 79.59999999999953, 73.99999999999972, 334.8000000000002, -150.70000000000047, 45.10000000000003, -3.1999999999999478, -468.20000000000005, 192.8, 62.60000000000034, 216.39999999999927, 126.7999999999988, 322.0, 176.30000000000004, -347.9, 58.90000000000005, 54.59999999999975, -3.0, 112.89999999999898, 223.09999999999957, -173.40000000000052, 174.59999999999945, 108.29999999999983, -335.4000000000003, 357.70000000000005, 172.30000000000004, 352.3, 89.99999999999923, -285.80000000000007, -45.899999999999984, -120.5000000000008, 58.30000000000005, -259.20000000000005, 185.79999999999905, 14.199999999999964, 181.29999999999944, 329.8000000000014, 350.5, -133.10000000000036, 236.99999999999946, 109.39999999999955, 227.19999999999925, 366.8000000000002, 169.5999999999995, 58.0000000000003, 283.9000000000002, 387.0, 27.500000000000014, -43.6999999999997, 27.10000000000001, 60.80000000000004, -66.49999999999983, -24.19999999999998, 209.0999999999993, -70.00000000000001, 183.39999999999944, 39.00000000000002, 219.99999999999926, 82.50000000000016, -376.6, 219.99999999999926, -87.60000000000005, 152.0, 293.7000000000004, -492.69999999999993, 38.9000000000003, -160.39999999999995, 160.39999999999995, 138.6, -22.79999999999994, 6.999999999999972, 348.0, -43.20000000000002, 219.99999999999926, 219.99999999999926, 136.3999999999997, 40.0000000000003, 50.30000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-322.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, -5.200000000000003, -323.49999999999966, -332.8, -200.80000000000018, 167.0, -389.5, 130.69999999999956, 20.000000000000014, 197.0, -223.60000000000002, -187.90000000000003, 165.19999999999996, 20.000000000000014, -400.0, 47.90000000000011, -211.00000000000003, 17.899999999999988, 153.7999999999999, -324.4, -364.3, -347.5, -400.0, -355.9, 174.2, 20.000000000000014, 20.000000000000014, 198.2, 176.59999999999994, -395.8, -385.3, -242.5, 191.0, -255.10000000000005, -271.9, 182.0, -11.800000000000304, 25.700000000000237, 195.49999999999997, 200.0, -368.5, -1.0, 7.6999999999998465, 20.000000000000014, 59.60000000000012, 53.0000000000002, 20.000000000000014, 200.0, 105.79999999999995, 41.600000000000115, -385.29999999999995, -313.9, 200.0, -383.2, 20.000000000000014, -303.4, -332.79999999999995, 200.0, -383.2, -21.39999999999982, 20.000000000000014, 182.9, 33.50000000000025, 78.1999999999993, 44.59999999999997, 101.0, 188.0, 194.0, -309.7, -330.7, -299.2, -263.5, 187.4, 86.5999999999997, -148.0, -400.0, 77.0, 92.89999999999955, 20.000000000000014, 37.09999999999998, 179.0, -261.4, -106.00000000000074, 166.7, -3.099999999999958, 182.9, -160.60000000000016, -389.5, -145.90000000000003, 157.7, 200.0, 165.8, -221.5, 143.3, 200.0, 76.69999999999956, -36.700000000000024, -218.8, -400.0, -395.8, 140.9, -278.2000000000002, 7.699999999999967, -288.7, 200.0, -341.0, -299.2000000000001, 165.79999999999978, 20.000000000000014, -374.8, 20.000000000000014, 161.3, 20.000000000000014, 145.99999999999966, 183.8, 181.1, 169.4, 41.60000000000018, -351.7, 185.0, 47.00000000000007, -217.3, 97.69999999999956, 200.0, 27.200000000000145, 174.79999999999995, 188.0, -9.400000000000007, 143.0, 20.000000000000014, 38.00000000000014, 117.19999999999948, 166.7, 191.0, 194.0, 200.0, -347.5, -3.099999999999958, -349.60000000000014, -313.89999999999907, 182.0, -248.5, 179.3, -87.10000000000004, -30.40000000000002, -345.4, 141.2, 184.1, 20.000000000000014, -190.00000000000003, 20.000000000000014, 20.000000000000014, 151.40000000000003, 176.0, -295.00000000000006, 20.000000000000014, 200.0, 31.70000000000022, 24.799999999999997, -370.6, -337.0, 20.000000000000014, 200.0, -223.60000000000008, 20.000000000000014, 181.1, -381.1, 185.0, 103.69999999999943, -297.1, -391.6, 20.000000000000014, 17.899999999999977, -326.5, 1.099999999999767, -139.60000000000002, 122.0, 173.0, -387.4, 79.39999999999998, -227.20000000000002, -316.0, 20.000000000000014, 200.0, 122.0, -18.399999999999764, -101.80000000000004, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 200.0, -139.60000000000034, 20.000000000000014, 20.000000000000014, 176.59999999999988, -259.3], "policy_predator_policy_reward": [156.0, 163.0, 0.0, 0.0, 155.0, 95.0, 194.0, 0.0, 11.0, 195.0, 0.0, 0.0, 99.0, 116.0, 99.0, 2.0, 200.0, 0.0, 102.0, 101.0, 11.0, 0.0, 0.0, 183.0, 84.0, 200.0, 5.0, 179.0, 0.0, 0.0, 0.0, 0.0, 168.0, 188.0, 0.0, 125.0, 0.0, 139.0, 52.0, 46.0, 8.0, 0.0, 178.0, 185.0, 46.0, 55.0, 0.0, 0.0, 0.0, 1.0, 3.0, 26.0, 0.0, 193.0, 159.0, 0.0, 168.0, 192.0, 168.0, 0.0, 192.0, 184.0, 36.0, 28.0, 0.0, 0.0, 4.0, 0.0, 33.0, 0.0, 159.0, 133.0, 115.0, 167.0, 135.0, 0.0, 0.0, 116.0, 120.0, 200.0, 0.0, 0.0, 0.0, 7.0, 60.0, 134.0, 11.0, 0.0, 0.0, 86.0, 200.0, 0.0, 0.0, 0.0, 113.0, 115.0, 0.0, 9.0, 23.0, 27.0, 200.0, 133.0, 198.0, 11.0, 0.0, 150.0, 147.0, 0.0, 229.0, 152.0, 0.0, 0.0, 188.0, 181.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 177.0, 0.0, 5.0, 109.0, 120.0, 0.0, 0.0, 4.0, 0.0, 27.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 175.0, 0.0, 176.0, 133.0, 0.0, 159.0, 130.0, 0.0, 0.0, 51.0, 177.0, 3.0, 5.0, 0.0, 100.0, 0.0, 12.0, 0.0, 158.0, 0.0, 0.0, 0.0, 0.0, 26.0, 186.0, 145.0, 0.0, 0.0, 116.0, 0.0, 191.0, 161.0, 5.0, 0.0, 196.0, 0.0, 0.0, 1.0, 165.0, 0.0, 102.0, 76.0, 200.0, 153.0, 0.0, 125.0, 160.0, 143.0, 26.0, 0.0, 58.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 0.0, 0.0, 0.0, 133.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.119082368269217, "mean_inference_ms": 7.761437735256648, "mean_action_processing_ms": 0.7018162719947035, "mean_env_wait_ms": 1.0399718223206178, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009087920188903809, "StateBufferConnector_ms": 0.012264847755432129, "ViewRequirementAgentConnector_ms": 0.3336818218231201}, "num_episodes": 23, "episode_return_max": 387.0, "episode_return_min": -505.7, "episode_return_mean": 50.44399999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000, "num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.8604023742967, "num_env_steps_trained_throughput_per_sec": 195.8604023742967, "timesteps_total": 728000, "num_env_steps_sampled_lifetime": 728000, "num_agent_steps_sampled_lifetime": 2912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2912000, "timers": {"training_iteration_time_ms": 21641.591, "restore_workers_time_ms": 0.026, "training_step_time_ms": 21641.502, "sample_time_ms": 3365.854, "learn_time_ms": 18240.08, "learn_throughput": 219.297, "synch_weights_time_ms": 30.882}, "counters": {"num_env_steps_sampled": 728000, "num_env_steps_trained": 728000, "num_agent_steps_sampled": 2912000, "num_agent_steps_trained": 2912000}, "done": false, "training_iteration": 182, "trial_id": "3a355_00000", "date": "2024-08-13_05-44-13", "timestamp": 1723542253, "time_this_iter_s": 20.522658824920654, "time_total_s": 16450.6174659729, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5556ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16450.6174659729, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 81.3103448275862, "ram_util_percent": 83.20344827586206}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3069502394350747, "cur_kl_coeff": 2.690493051503648e-44, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.686245520657333, "policy_loss": -0.0011003198272119912, "vf_loss": 4.687345856081241, "vf_explained_var": 0.011598202002742303, "kl": 0.00243105401837951, "entropy": 0.26950735951226856, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 344925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 63.68812967207697, "cur_kl_coeff": 1.5092389019936155e-24, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.7075351646968295, "policy_loss": 0.0014282755685536554, "vf_loss": 5.706106886283431, "vf_explained_var": 0.32451901451620474, "kl": 0.002687956478497192, "entropy": 0.7022021538681454, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 344925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000}, "env_runners": {"episode_reward_max": 387.0, "episode_reward_min": -492.69999999999993, "episode_reward_mean": 68.74399999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 229.0}, "policy_reward_mean": {"prey_policy": -24.45300000000002, "predator_policy": 58.825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [107.69999999999926, 79.59999999999953, 73.99999999999972, 334.8000000000002, -150.70000000000047, 45.10000000000003, -3.1999999999999478, -468.20000000000005, 192.8, 62.60000000000034, 216.39999999999927, 126.7999999999988, 322.0, 176.30000000000004, -347.9, 58.90000000000005, 54.59999999999975, -3.0, 112.89999999999898, 223.09999999999957, -173.40000000000052, 174.59999999999945, 108.29999999999983, -335.4000000000003, 357.70000000000005, 172.30000000000004, 352.3, 89.99999999999923, -285.80000000000007, -45.899999999999984, -120.5000000000008, 58.30000000000005, -259.20000000000005, 185.79999999999905, 14.199999999999964, 181.29999999999944, 329.8000000000014, 350.5, -133.10000000000036, 236.99999999999946, 109.39999999999955, 227.19999999999925, 366.8000000000002, 169.5999999999995, 58.0000000000003, 283.9000000000002, 387.0, 27.500000000000014, -43.6999999999997, 27.10000000000001, 60.80000000000004, -66.49999999999983, -24.19999999999998, 209.0999999999993, -70.00000000000001, 183.39999999999944, 39.00000000000002, 219.99999999999926, 82.50000000000016, -376.6, 219.99999999999926, -87.60000000000005, 152.0, 293.7000000000004, -492.69999999999993, 38.9000000000003, -160.39999999999995, 160.39999999999995, 138.6, -22.79999999999994, 6.999999999999972, 348.0, -43.20000000000002, 219.99999999999926, 219.99999999999926, 136.3999999999997, 40.0000000000003, 50.30000000000002, 185.19999999999945, 337.90000000000003, 40.0000000000003, 219.99999999999926, 171.39999999999947, 34.70000000000025, -293.30000000000024, 32.40000000000009, 183.20000000000005, 172.29999999999896, -122.1000000000003, 23.40000000000003, -26.299999999999663, 99.09999999999985, 91.40000000000005, -72.19999999999996, 32.599999999999994, 144.29999999999973, 272.20000000000033, -28.099999999999767, -174.50000000000063, -11.500000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-1.0, 7.6999999999998465, 20.000000000000014, 59.60000000000012, 53.0000000000002, 20.000000000000014, 200.0, 105.79999999999995, 41.600000000000115, -385.29999999999995, -313.9, 200.0, -383.2, 20.000000000000014, -303.4, -332.79999999999995, 200.0, -383.2, -21.39999999999982, 20.000000000000014, 182.9, 33.50000000000025, 78.1999999999993, 44.59999999999997, 101.0, 188.0, 194.0, -309.7, -330.7, -299.2, -263.5, 187.4, 86.5999999999997, -148.0, -400.0, 77.0, 92.89999999999955, 20.000000000000014, 37.09999999999998, 179.0, -261.4, -106.00000000000074, 166.7, -3.099999999999958, 182.9, -160.60000000000016, -389.5, -145.90000000000003, 157.7, 200.0, 165.8, -221.5, 143.3, 200.0, 76.69999999999956, -36.700000000000024, -218.8, -400.0, -395.8, 140.9, -278.2000000000002, 7.699999999999967, -288.7, 200.0, -341.0, -299.2000000000001, 165.79999999999978, 20.000000000000014, -374.8, 20.000000000000014, 161.3, 20.000000000000014, 145.99999999999966, 183.8, 181.1, 169.4, 41.60000000000018, -351.7, 185.0, 47.00000000000007, -217.3, 97.69999999999956, 200.0, 27.200000000000145, 174.79999999999995, 188.0, -9.400000000000007, 143.0, 20.000000000000014, 38.00000000000014, 117.19999999999948, 166.7, 191.0, 194.0, 200.0, -347.5, -3.099999999999958, -349.60000000000014, -313.89999999999907, 182.0, -248.5, 179.3, -87.10000000000004, -30.40000000000002, -345.4, 141.2, 184.1, 20.000000000000014, -190.00000000000003, 20.000000000000014, 20.000000000000014, 151.40000000000003, 176.0, -295.00000000000006, 20.000000000000014, 200.0, 31.70000000000022, 24.799999999999997, -370.6, -337.0, 20.000000000000014, 200.0, -223.60000000000008, 20.000000000000014, 181.1, -381.1, 185.0, 103.69999999999943, -297.1, -391.6, 20.000000000000014, 17.899999999999977, -326.5, 1.099999999999767, -139.60000000000002, 122.0, 173.0, -387.4, 79.39999999999998, -227.20000000000002, -316.0, 20.000000000000014, 200.0, 122.0, -18.399999999999764, -101.80000000000004, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 200.0, -139.60000000000034, 20.000000000000014, 20.000000000000014, 176.59999999999988, -259.3, 13.699999999999966, 168.5, 181.1, 156.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 151.4, 20.000000000000014, 20.000000000000014, -49.30000000000003, -400.0, -196.29999999999995, 64.10000000000002, -78.70000000000005, -311.79999999999995, 200.0, 20.000000000000014, 152.2999999999997, 21.800000000000047, -292.9, 20.000000000000014, -25.59999999999978, 20.000000000000014, -280.3000000000003, 145.1, -106.00000000000003, 145.1, -372.70000000000005, 20.000000000000014, -194.20000000000002, 32.599999999999994, -400.0, 9.500000000000007, 99.80000000000003, 161.3, 110.89999999999986, -242.49999999999991, 76.40000000000013, 20.000000000000014, -389.5, -379.0, 177.5], "policy_predator_policy_reward": [46.0, 55.0, 0.0, 0.0, 0.0, 1.0, 3.0, 26.0, 0.0, 193.0, 159.0, 0.0, 168.0, 192.0, 168.0, 0.0, 192.0, 184.0, 36.0, 28.0, 0.0, 0.0, 4.0, 0.0, 33.0, 0.0, 159.0, 133.0, 115.0, 167.0, 135.0, 0.0, 0.0, 116.0, 120.0, 200.0, 0.0, 0.0, 0.0, 7.0, 60.0, 134.0, 11.0, 0.0, 0.0, 86.0, 200.0, 0.0, 0.0, 0.0, 113.0, 115.0, 0.0, 9.0, 23.0, 27.0, 200.0, 133.0, 198.0, 11.0, 0.0, 150.0, 147.0, 0.0, 229.0, 152.0, 0.0, 0.0, 188.0, 181.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 177.0, 0.0, 5.0, 109.0, 120.0, 0.0, 0.0, 4.0, 0.0, 27.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 175.0, 0.0, 176.0, 133.0, 0.0, 159.0, 130.0, 0.0, 0.0, 51.0, 177.0, 3.0, 5.0, 0.0, 100.0, 0.0, 12.0, 0.0, 158.0, 0.0, 0.0, 0.0, 0.0, 26.0, 186.0, 145.0, 0.0, 0.0, 116.0, 0.0, 191.0, 161.0, 5.0, 0.0, 196.0, 0.0, 0.0, 1.0, 165.0, 0.0, 102.0, 76.0, 200.0, 153.0, 0.0, 125.0, 160.0, 143.0, 26.0, 0.0, 58.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 0.0, 0.0, 0.0, 133.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 31.0, 103.0, 200.0, 47.0, 0.0, 157.0, 138.0, 0.0, 0.0, 0.0, 149.0, 24.0, 5.0, 143.0, 91.0, 60.0, 0.0, 138.0, 181.0, 0.0, 102.0, 200.0, 200.0, 5.0, 30.0, 0.0, 0.0, 13.0, 125.0, 195.0, 0.0, 190.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.117092489696052, "mean_inference_ms": 7.790024165652212, "mean_action_processing_ms": 0.701241420895887, "mean_env_wait_ms": 1.0002988266991, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011845231056213379, "StateBufferConnector_ms": 0.013093709945678711, "ViewRequirementAgentConnector_ms": 0.37577831745147705}, "num_episodes": 22, "episode_return_max": 387.0, "episode_return_min": -492.69999999999993, "episode_return_mean": 68.74399999999986, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000, "num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 177.0505320850332, "num_env_steps_trained_throughput_per_sec": 177.0505320850332, "timesteps_total": 732000, "num_env_steps_sampled_lifetime": 732000, "num_agent_steps_sampled_lifetime": 2928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2928000, "timers": {"training_iteration_time_ms": 21969.187, "restore_workers_time_ms": 0.019, "training_step_time_ms": 21969.119, "sample_time_ms": 3612.173, "learn_time_ms": 18321.387, "learn_throughput": 218.324, "synch_weights_time_ms": 30.698}, "counters": {"num_env_steps_sampled": 732000, "num_env_steps_trained": 732000, "num_agent_steps_sampled": 2928000, "num_agent_steps_trained": 2928000}, "done": false, "training_iteration": 183, "trial_id": "3a355_00000", "date": "2024-08-13_05-44-36", "timestamp": 1723542276, "time_this_iter_s": 22.643574714660645, "time_total_s": 16473.26104068756, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b6011c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16473.26104068756, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 83.98750000000001, "ram_util_percent": 83.453125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2740201980585144, "cur_kl_coeff": 1.345246525751824e-44, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3121741643027653, "policy_loss": -0.002097067869238792, "vf_loss": 3.3142712362228877, "vf_explained_var": 0.006267610586509503, "kl": 0.002606887890291248, "entropy": 0.29127921629204323, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 346815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 31.744905680039572, "cur_kl_coeff": 7.546194509968077e-25, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.9898212291576245, "policy_loss": 0.0023396613771125437, "vf_loss": 4.98748157730809, "vf_explained_var": 0.36929752132879995, "kl": 0.004696125571558191, "entropy": 0.5035919250161559, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 346815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000}, "env_runners": {"episode_reward_max": 392.0, "episode_reward_min": -600.0, "episode_reward_mean": 65.39299999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 229.0}, "policy_reward_mean": {"prey_policy": -22.60350000000001, "predator_policy": 55.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [112.89999999999898, 223.09999999999957, -173.40000000000052, 174.59999999999945, 108.29999999999983, -335.4000000000003, 357.70000000000005, 172.30000000000004, 352.3, 89.99999999999923, -285.80000000000007, -45.899999999999984, -120.5000000000008, 58.30000000000005, -259.20000000000005, 185.79999999999905, 14.199999999999964, 181.29999999999944, 329.8000000000014, 350.5, -133.10000000000036, 236.99999999999946, 109.39999999999955, 227.19999999999925, 366.8000000000002, 169.5999999999995, 58.0000000000003, 283.9000000000002, 387.0, 27.500000000000014, -43.6999999999997, 27.10000000000001, 60.80000000000004, -66.49999999999983, -24.19999999999998, 209.0999999999993, -70.00000000000001, 183.39999999999944, 39.00000000000002, 219.99999999999926, 82.50000000000016, -376.6, 219.99999999999926, -87.60000000000005, 152.0, 293.7000000000004, -492.69999999999993, 38.9000000000003, -160.39999999999995, 160.39999999999995, 138.6, -22.79999999999994, 6.999999999999972, 348.0, -43.20000000000002, 219.99999999999926, 219.99999999999926, 136.3999999999997, 40.0000000000003, 50.30000000000002, 185.19999999999945, 337.90000000000003, 40.0000000000003, 219.99999999999926, 171.39999999999947, 34.70000000000025, -293.30000000000024, 32.40000000000009, 183.20000000000005, 172.29999999999896, -122.1000000000003, 23.40000000000003, -26.299999999999663, 99.09999999999985, 91.40000000000005, -72.19999999999996, 32.599999999999994, 144.29999999999973, 272.20000000000033, -28.099999999999767, -174.50000000000063, -11.500000000000004, 219.99999999999926, -33.499999999999986, 62.70000000000006, -177.30000000000064, -167.90000000000057, 372.6, 219.99999999999926, -176.70000000000064, 340.4, 23.000000000000092, 387.4, 11.2, 174.99999999999946, -423.2999999999999, -204.9000000000004, -600.0, 122.79999999999978, 392.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [92.89999999999955, 20.000000000000014, 37.09999999999998, 179.0, -261.4, -106.00000000000074, 166.7, -3.099999999999958, 182.9, -160.60000000000016, -389.5, -145.90000000000003, 157.7, 200.0, 165.8, -221.5, 143.3, 200.0, 76.69999999999956, -36.700000000000024, -218.8, -400.0, -395.8, 140.9, -278.2000000000002, 7.699999999999967, -288.7, 200.0, -341.0, -299.2000000000001, 165.79999999999978, 20.000000000000014, -374.8, 20.000000000000014, 161.3, 20.000000000000014, 145.99999999999966, 183.8, 181.1, 169.4, 41.60000000000018, -351.7, 185.0, 47.00000000000007, -217.3, 97.69999999999956, 200.0, 27.200000000000145, 174.79999999999995, 188.0, -9.400000000000007, 143.0, 20.000000000000014, 38.00000000000014, 117.19999999999948, 166.7, 191.0, 194.0, 200.0, -347.5, -3.099999999999958, -349.60000000000014, -313.89999999999907, 182.0, -248.5, 179.3, -87.10000000000004, -30.40000000000002, -345.4, 141.2, 184.1, 20.000000000000014, -190.00000000000003, 20.000000000000014, 20.000000000000014, 151.40000000000003, 176.0, -295.00000000000006, 20.000000000000014, 200.0, 31.70000000000022, 24.799999999999997, -370.6, -337.0, 20.000000000000014, 200.0, -223.60000000000008, 20.000000000000014, 181.1, -381.1, 185.0, 103.69999999999943, -297.1, -391.6, 20.000000000000014, 17.899999999999977, -326.5, 1.099999999999767, -139.60000000000002, 122.0, 173.0, -387.4, 79.39999999999998, -227.20000000000002, -316.0, 20.000000000000014, 200.0, 122.0, -18.399999999999764, -101.80000000000004, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 200.0, -139.60000000000034, 20.000000000000014, 20.000000000000014, 176.59999999999988, -259.3, 13.699999999999966, 168.5, 181.1, 156.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 151.4, 20.000000000000014, 20.000000000000014, -49.30000000000003, -400.0, -196.29999999999995, 64.10000000000002, -78.70000000000005, -311.79999999999995, 200.0, 20.000000000000014, 152.2999999999997, 21.800000000000047, -292.9, 20.000000000000014, -25.59999999999978, 20.000000000000014, -280.3000000000003, 145.1, -106.00000000000003, 145.1, -372.70000000000005, 20.000000000000014, -194.20000000000002, 32.599999999999994, -400.0, 9.500000000000007, 99.80000000000003, 161.3, 110.89999999999986, -242.49999999999991, 76.40000000000013, 20.000000000000014, -389.5, -379.0, 177.5, 20.000000000000014, 200.0, 125.89999999999999, -324.4, 200.0, -280.3, 22.700000000000063, -400.0, 20.000000000000014, -376.9, 194.0, 176.6, 200.0, 20.000000000000014, -393.7, 20.000000000000014, 160.4, 170.0, -135.40000000000003, 28.400000000000006, 187.4, 200.0, -358.0, 189.2, 155.0, 20.000000000000014, -343.29999999999995, -253.00000000000003, -190.30000000000038, -349.59999999999997, -400.0, -400.0, 20.000000000000014, 102.79999999999998, 188.0, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 7.0, 60.0, 134.0, 11.0, 0.0, 0.0, 86.0, 200.0, 0.0, 0.0, 0.0, 113.0, 115.0, 0.0, 9.0, 23.0, 27.0, 200.0, 133.0, 198.0, 11.0, 0.0, 150.0, 147.0, 0.0, 229.0, 152.0, 0.0, 0.0, 188.0, 181.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 177.0, 0.0, 5.0, 109.0, 120.0, 0.0, 0.0, 4.0, 0.0, 27.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 175.0, 0.0, 176.0, 133.0, 0.0, 159.0, 130.0, 0.0, 0.0, 51.0, 177.0, 3.0, 5.0, 0.0, 100.0, 0.0, 12.0, 0.0, 158.0, 0.0, 0.0, 0.0, 0.0, 26.0, 186.0, 145.0, 0.0, 0.0, 116.0, 0.0, 191.0, 161.0, 5.0, 0.0, 196.0, 0.0, 0.0, 1.0, 165.0, 0.0, 102.0, 76.0, 200.0, 153.0, 0.0, 125.0, 160.0, 143.0, 26.0, 0.0, 58.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 0.0, 0.0, 0.0, 133.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 31.0, 103.0, 200.0, 47.0, 0.0, 157.0, 138.0, 0.0, 0.0, 0.0, 149.0, 24.0, 5.0, 143.0, 91.0, 60.0, 0.0, 138.0, 181.0, 0.0, 102.0, 200.0, 200.0, 5.0, 30.0, 0.0, 0.0, 13.0, 125.0, 195.0, 0.0, 190.0, 0.0, 0.0, 0.0, 164.0, 1.0, 143.0, 0.0, 0.0, 200.0, 189.0, 0.0, 0.0, 2.0, 0.0, 0.0, 197.0, 0.0, 10.0, 0.0, 0.0, 130.0, 0.0, 0.0, 0.0, 180.0, 0.0, 0.0, 0.0, 173.0, 196.0, 139.0, 200.0, 0.0, 0.0, 0.0, 0.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1159051167856444, "mean_inference_ms": 7.77607295012675, "mean_action_processing_ms": 0.7014214140705957, "mean_env_wait_ms": 0.9982603936519413, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03325366973876953, "StateBufferConnector_ms": 0.009633302688598633, "ViewRequirementAgentConnector_ms": 0.35002779960632324}, "num_episodes": 18, "episode_return_max": 392.0, "episode_return_min": -600.0, "episode_return_mean": 65.39299999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000, "num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 171.34172384630736, "num_env_steps_trained_throughput_per_sec": 171.34172384630736, "timesteps_total": 736000, "num_env_steps_sampled_lifetime": 736000, "num_agent_steps_sampled_lifetime": 2944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2944000, "timers": {"training_iteration_time_ms": 22257.029, "restore_workers_time_ms": 0.02, "training_step_time_ms": 22256.948, "sample_time_ms": 3764.47, "learn_time_ms": 18457.66, "learn_throughput": 216.712, "synch_weights_time_ms": 30.197}, "counters": {"num_env_steps_sampled": 736000, "num_env_steps_trained": 736000, "num_agent_steps_sampled": 2944000, "num_agent_steps_trained": 2944000}, "done": false, "training_iteration": 184, "trial_id": "3a355_00000", "date": "2024-08-13_05-45-00", "timestamp": 1723542300, "time_this_iter_s": 23.405508041381836, "time_total_s": 16496.666548728943, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fe6940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16496.666548728943, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 85.82727272727271, "ram_util_percent": 83.51818181818183}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.534353181909001, "cur_kl_coeff": 6.72623262875912e-45, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.144789594064945, "policy_loss": -0.0031595406319610973, "vf_loss": 5.1479491296899385, "vf_explained_var": 0.0044303767264835415, "kl": 0.022481771572889348, "entropy": 0.3112089081021844, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 348705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 38.25107652537091, "cur_kl_coeff": 3.7730972549840387e-25, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.738721430995477, "policy_loss": -0.0001946292465266885, "vf_loss": 5.738916068859202, "vf_explained_var": 0.4902446830398822, "kl": 0.004208057652534084, "entropy": 0.48090016044006145, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 348705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000}, "env_runners": {"episode_reward_max": 392.0, "episode_reward_min": -600.0, "episode_reward_mean": 69.12499999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -20.897500000000008, "predator_policy": 55.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [329.8000000000014, 350.5, -133.10000000000036, 236.99999999999946, 109.39999999999955, 227.19999999999925, 366.8000000000002, 169.5999999999995, 58.0000000000003, 283.9000000000002, 387.0, 27.500000000000014, -43.6999999999997, 27.10000000000001, 60.80000000000004, -66.49999999999983, -24.19999999999998, 209.0999999999993, -70.00000000000001, 183.39999999999944, 39.00000000000002, 219.99999999999926, 82.50000000000016, -376.6, 219.99999999999926, -87.60000000000005, 152.0, 293.7000000000004, -492.69999999999993, 38.9000000000003, -160.39999999999995, 160.39999999999995, 138.6, -22.79999999999994, 6.999999999999972, 348.0, -43.20000000000002, 219.99999999999926, 219.99999999999926, 136.3999999999997, 40.0000000000003, 50.30000000000002, 185.19999999999945, 337.90000000000003, 40.0000000000003, 219.99999999999926, 171.39999999999947, 34.70000000000025, -293.30000000000024, 32.40000000000009, 183.20000000000005, 172.29999999999896, -122.1000000000003, 23.40000000000003, -26.299999999999663, 99.09999999999985, 91.40000000000005, -72.19999999999996, 32.599999999999994, 144.29999999999973, 272.20000000000033, -28.099999999999767, -174.50000000000063, -11.500000000000004, 219.99999999999926, -33.499999999999986, 62.70000000000006, -177.30000000000064, -167.90000000000057, 372.6, 219.99999999999926, -176.70000000000064, 340.4, 23.000000000000092, 387.4, 11.2, 174.99999999999946, -423.2999999999999, -204.9000000000004, -600.0, 122.79999999999978, 392.0, 307.1, 203.79999999999987, 25.19999999999969, 142.90000000000003, -471.0, 166.89999999999978, 27.50000000000001, -236.09999999999994, 309.1, 356.8000000000004, 219.99999999999926, -156.1000000000004, 133.9, 197.49999999999935, 351.3, -137.10000000000042, -369.0, 111.09999999999982], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [145.99999999999966, 183.8, 181.1, 169.4, 41.60000000000018, -351.7, 185.0, 47.00000000000007, -217.3, 97.69999999999956, 200.0, 27.200000000000145, 174.79999999999995, 188.0, -9.400000000000007, 143.0, 20.000000000000014, 38.00000000000014, 117.19999999999948, 166.7, 191.0, 194.0, 200.0, -347.5, -3.099999999999958, -349.60000000000014, -313.89999999999907, 182.0, -248.5, 179.3, -87.10000000000004, -30.40000000000002, -345.4, 141.2, 184.1, 20.000000000000014, -190.00000000000003, 20.000000000000014, 20.000000000000014, 151.40000000000003, 176.0, -295.00000000000006, 20.000000000000014, 200.0, 31.70000000000022, 24.799999999999997, -370.6, -337.0, 20.000000000000014, 200.0, -223.60000000000008, 20.000000000000014, 181.1, -381.1, 185.0, 103.69999999999943, -297.1, -391.6, 20.000000000000014, 17.899999999999977, -326.5, 1.099999999999767, -139.60000000000002, 122.0, 173.0, -387.4, 79.39999999999998, -227.20000000000002, -316.0, 20.000000000000014, 200.0, 122.0, -18.399999999999764, -101.80000000000004, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 200.0, -139.60000000000034, 20.000000000000014, 20.000000000000014, 176.59999999999988, -259.3, 13.699999999999966, 168.5, 181.1, 156.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 151.4, 20.000000000000014, 20.000000000000014, -49.30000000000003, -400.0, -196.29999999999995, 64.10000000000002, -78.70000000000005, -311.79999999999995, 200.0, 20.000000000000014, 152.2999999999997, 21.800000000000047, -292.9, 20.000000000000014, -25.59999999999978, 20.000000000000014, -280.3000000000003, 145.1, -106.00000000000003, 145.1, -372.70000000000005, 20.000000000000014, -194.20000000000002, 32.599999999999994, -400.0, 9.500000000000007, 99.80000000000003, 161.3, 110.89999999999986, -242.49999999999991, 76.40000000000013, 20.000000000000014, -389.5, -379.0, 177.5, 20.000000000000014, 200.0, 125.89999999999999, -324.4, 200.0, -280.3, 22.700000000000063, -400.0, 20.000000000000014, -376.9, 194.0, 176.6, 200.0, 20.000000000000014, -393.7, 20.000000000000014, 160.4, 170.0, -135.40000000000003, 28.400000000000006, 187.4, 200.0, -358.0, 189.2, 155.0, 20.000000000000014, -343.29999999999995, -253.00000000000003, -190.30000000000038, -349.59999999999997, -400.0, -400.0, 20.000000000000014, 102.79999999999998, 188.0, 200.0, 127.1, 170.0, -52.000000000000014, 165.8, 112.69999999999945, -200.49999999999994, -284.5, 178.4, -313.9, -318.1, -93.40000000000003, 152.3, -347.4999999999995, 200.0, -159.09999999999994, -337.0, 146.89999999999998, 162.2, 183.7999999999999, 173.0, 20.000000000000014, 200.0, -360.1, -34.00000000000007, 173.0, -381.1, -29.4999999999999, 200.0, 185.0, 161.3, -318.1, 20.000000000000014, -389.5, -347.5, 200.0, -187.9], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 177.0, 0.0, 5.0, 109.0, 120.0, 0.0, 0.0, 4.0, 0.0, 27.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 175.0, 0.0, 176.0, 133.0, 0.0, 159.0, 130.0, 0.0, 0.0, 51.0, 177.0, 3.0, 5.0, 0.0, 100.0, 0.0, 12.0, 0.0, 158.0, 0.0, 0.0, 0.0, 0.0, 26.0, 186.0, 145.0, 0.0, 0.0, 116.0, 0.0, 191.0, 161.0, 5.0, 0.0, 196.0, 0.0, 0.0, 1.0, 165.0, 0.0, 102.0, 76.0, 200.0, 153.0, 0.0, 125.0, 160.0, 143.0, 26.0, 0.0, 58.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 0.0, 0.0, 0.0, 133.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 31.0, 103.0, 200.0, 47.0, 0.0, 157.0, 138.0, 0.0, 0.0, 0.0, 149.0, 24.0, 5.0, 143.0, 91.0, 60.0, 0.0, 138.0, 181.0, 0.0, 102.0, 200.0, 200.0, 5.0, 30.0, 0.0, 0.0, 13.0, 125.0, 195.0, 0.0, 190.0, 0.0, 0.0, 0.0, 164.0, 1.0, 143.0, 0.0, 0.0, 200.0, 189.0, 0.0, 0.0, 2.0, 0.0, 0.0, 197.0, 0.0, 10.0, 0.0, 0.0, 130.0, 0.0, 0.0, 0.0, 180.0, 0.0, 0.0, 0.0, 173.0, 196.0, 139.0, 200.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 0.0, 75.0, 15.0, 105.0, 8.0, 145.0, 104.0, 0.0, 161.0, 54.0, 54.0, 0.0, 175.0, 170.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 181.0, 57.0, 195.0, 147.0, 27.0, 0.0, 0.0, 5.0, 0.0, 161.0, 175.0, 193.0, 0.0, 99.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.11444284592891, "mean_inference_ms": 7.761755475940492, "mean_action_processing_ms": 0.7015460538977767, "mean_env_wait_ms": 0.9961514584302585, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.033794403076171875, "StateBufferConnector_ms": 0.00965416431427002, "ViewRequirementAgentConnector_ms": 0.3581709861755371}, "num_episodes": 18, "episode_return_max": 392.0, "episode_return_min": -600.0, "episode_return_mean": 69.12499999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000, "num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 166.32187483193425, "num_env_steps_trained_throughput_per_sec": 166.32187483193425, "timesteps_total": 740000, "num_env_steps_sampled_lifetime": 740000, "num_agent_steps_sampled_lifetime": 2960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2960000, "timers": {"training_iteration_time_ms": 22544.639, "restore_workers_time_ms": 0.019, "training_step_time_ms": 22544.562, "sample_time_ms": 3783.743, "learn_time_ms": 18727.158, "learn_throughput": 213.594, "synch_weights_time_ms": 29.653}, "counters": {"num_env_steps_sampled": 740000, "num_env_steps_trained": 740000, "num_agent_steps_sampled": 2960000, "num_agent_steps_trained": 2960000}, "done": false, "training_iteration": 185, "trial_id": "3a355_00000", "date": "2024-08-13_05-45-24", "timestamp": 1723542324, "time_this_iter_s": 24.10134792327881, "time_total_s": 16520.76789665222, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b6011040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16520.76789665222, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 86.71470588235293, "ram_util_percent": 83.31764705882354}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4355761193251484, "cur_kl_coeff": 1.0089348943138686e-44, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.780093585120307, "policy_loss": -0.0011646087515468477, "vf_loss": 5.78125818519996, "vf_explained_var": 0.00426062266662638, "kl": 0.003960396527026877, "entropy": 0.3137065295031462, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 350595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 27.19848436020985, "cur_kl_coeff": 1.8865486274920194e-25, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.785389912191522, "policy_loss": -0.00047374711982984706, "vf_loss": 5.78586365508024, "vf_explained_var": 0.48996249326953184, "kl": 0.005435928490959486, "entropy": 0.5254642932660996, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 350595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000}, "env_runners": {"episode_reward_max": 392.0, "episode_reward_min": -600.0, "episode_reward_mean": 51.895999999999866, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -38.182000000000016, "predator_policy": 64.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-70.00000000000001, 183.39999999999944, 39.00000000000002, 219.99999999999926, 82.50000000000016, -376.6, 219.99999999999926, -87.60000000000005, 152.0, 293.7000000000004, -492.69999999999993, 38.9000000000003, -160.39999999999995, 160.39999999999995, 138.6, -22.79999999999994, 6.999999999999972, 348.0, -43.20000000000002, 219.99999999999926, 219.99999999999926, 136.3999999999997, 40.0000000000003, 50.30000000000002, 185.19999999999945, 337.90000000000003, 40.0000000000003, 219.99999999999926, 171.39999999999947, 34.70000000000025, -293.30000000000024, 32.40000000000009, 183.20000000000005, 172.29999999999896, -122.1000000000003, 23.40000000000003, -26.299999999999663, 99.09999999999985, 91.40000000000005, -72.19999999999996, 32.599999999999994, 144.29999999999973, 272.20000000000033, -28.099999999999767, -174.50000000000063, -11.500000000000004, 219.99999999999926, -33.499999999999986, 62.70000000000006, -177.30000000000064, -167.90000000000057, 372.6, 219.99999999999926, -176.70000000000064, 340.4, 23.000000000000092, 387.4, 11.2, 174.99999999999946, -423.2999999999999, -204.9000000000004, -600.0, 122.79999999999978, 392.0, 307.1, 203.79999999999987, 25.19999999999969, 142.90000000000003, -471.0, 166.89999999999978, 27.50000000000001, -236.09999999999994, 309.1, 356.8000000000004, 219.99999999999926, -156.1000000000004, 133.9, 197.49999999999935, 351.3, -137.10000000000042, -369.0, 111.09999999999982, -413.9, 348.0, 355.5, -285.6, 126.3, -370.4, 375.3, -295.99999999999994, 354.8, -254.80000000000064, 117.39999999999984, 206.79999999999967, 16.30000000000011, 137.1, 315.6, 182.1, -75.5, 14.299999999999953], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-190.00000000000003, 20.000000000000014, 20.000000000000014, 151.40000000000003, 176.0, -295.00000000000006, 20.000000000000014, 200.0, 31.70000000000022, 24.799999999999997, -370.6, -337.0, 20.000000000000014, 200.0, -223.60000000000008, 20.000000000000014, 181.1, -381.1, 185.0, 103.69999999999943, -297.1, -391.6, 20.000000000000014, 17.899999999999977, -326.5, 1.099999999999767, -139.60000000000002, 122.0, 173.0, -387.4, 79.39999999999998, -227.20000000000002, -316.0, 20.000000000000014, 200.0, 122.0, -18.399999999999764, -101.80000000000004, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 200.0, -139.60000000000034, 20.000000000000014, 20.000000000000014, 176.59999999999988, -259.3, 13.699999999999966, 168.5, 181.1, 156.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 151.4, 20.000000000000014, 20.000000000000014, -49.30000000000003, -400.0, -196.29999999999995, 64.10000000000002, -78.70000000000005, -311.79999999999995, 200.0, 20.000000000000014, 152.2999999999997, 21.800000000000047, -292.9, 20.000000000000014, -25.59999999999978, 20.000000000000014, -280.3000000000003, 145.1, -106.00000000000003, 145.1, -372.70000000000005, 20.000000000000014, -194.20000000000002, 32.599999999999994, -400.0, 9.500000000000007, 99.80000000000003, 161.3, 110.89999999999986, -242.49999999999991, 76.40000000000013, 20.000000000000014, -389.5, -379.0, 177.5, 20.000000000000014, 200.0, 125.89999999999999, -324.4, 200.0, -280.3, 22.700000000000063, -400.0, 20.000000000000014, -376.9, 194.0, 176.6, 200.0, 20.000000000000014, -393.7, 20.000000000000014, 160.4, 170.0, -135.40000000000003, 28.400000000000006, 187.4, 200.0, -358.0, 189.2, 155.0, 20.000000000000014, -343.29999999999995, -253.00000000000003, -190.30000000000038, -349.59999999999997, -400.0, -400.0, 20.000000000000014, 102.79999999999998, 188.0, 200.0, 127.1, 170.0, -52.000000000000014, 165.8, 112.69999999999945, -200.49999999999994, -284.5, 178.4, -313.9, -318.1, -93.40000000000003, 152.3, -347.4999999999995, 200.0, -159.09999999999994, -337.0, 146.89999999999998, 162.2, 183.7999999999999, 173.0, 20.000000000000014, 200.0, -360.1, -34.00000000000007, 173.0, -381.1, -29.4999999999999, 200.0, 185.0, 161.3, -318.1, 20.000000000000014, -389.5, -347.5, 200.0, -187.9, -276.1, -290.8, 131.0, 191.0, 162.5, 182.0, -274.0, -265.6, -376.9, 168.2, -374.8, -370.6, 187.7, 185.6, -391.6, -261.4, 200.0, 144.80000000000004, -343.30000000000007, -179.50000000000054, 97.39999999999998, 20.000000000000014, 197.0, -131.20000000000005, 7.399999999999947, -213.10000000000002, 188.0, -376.90000000000003, 112.99999999999997, 194.6, -397.9, 197.0, -200.5, 20.000000000000014, 20.000000000000014, -225.70000000000044], "policy_predator_policy_reward": [100.0, 0.0, 12.0, 0.0, 158.0, 0.0, 0.0, 0.0, 0.0, 26.0, 186.0, 145.0, 0.0, 0.0, 116.0, 0.0, 191.0, 161.0, 5.0, 0.0, 196.0, 0.0, 0.0, 1.0, 165.0, 0.0, 102.0, 76.0, 200.0, 153.0, 0.0, 125.0, 160.0, 143.0, 26.0, 0.0, 58.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.0, 0.0, 0.0, 0.0, 133.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 31.0, 103.0, 200.0, 47.0, 0.0, 157.0, 138.0, 0.0, 0.0, 0.0, 149.0, 24.0, 5.0, 143.0, 91.0, 60.0, 0.0, 138.0, 181.0, 0.0, 102.0, 200.0, 200.0, 5.0, 30.0, 0.0, 0.0, 13.0, 125.0, 195.0, 0.0, 190.0, 0.0, 0.0, 0.0, 164.0, 1.0, 143.0, 0.0, 0.0, 200.0, 189.0, 0.0, 0.0, 2.0, 0.0, 0.0, 197.0, 0.0, 10.0, 0.0, 0.0, 130.0, 0.0, 0.0, 0.0, 180.0, 0.0, 0.0, 0.0, 173.0, 196.0, 139.0, 200.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 0.0, 75.0, 15.0, 105.0, 8.0, 145.0, 104.0, 0.0, 161.0, 54.0, 54.0, 0.0, 175.0, 170.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 181.0, 57.0, 195.0, 147.0, 27.0, 0.0, 0.0, 5.0, 0.0, 161.0, 175.0, 193.0, 0.0, 99.0, 0.0, 153.0, 23.0, 3.0, 0.0, 11.0, 126.0, 128.0, 189.0, 146.0, 188.0, 187.0, 2.0, 0.0, 161.0, 196.0, 0.0, 10.0, 95.0, 173.0, 0.0, 0.0, 68.0, 73.0, 111.0, 111.0, 149.0, 177.0, 0.0, 8.0, 200.0, 183.0, 105.0, 0.0, 110.0, 110.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1129672942454225, "mean_inference_ms": 7.747273284980629, "mean_action_processing_ms": 0.7016081283404114, "mean_env_wait_ms": 0.9940203166770651, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0331493616104126, "StateBufferConnector_ms": 0.006901741027832031, "ViewRequirementAgentConnector_ms": 0.3710132837295532}, "num_episodes": 18, "episode_return_max": 392.0, "episode_return_min": -600.0, "episode_return_mean": 51.895999999999866, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000, "num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 174.01285795019683, "num_env_steps_trained_throughput_per_sec": 174.01285795019683, "timesteps_total": 744000, "num_env_steps_sampled_lifetime": 744000, "num_agent_steps_sampled_lifetime": 2976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2976000, "timers": {"training_iteration_time_ms": 22645.071, "restore_workers_time_ms": 0.018, "training_step_time_ms": 22644.992, "sample_time_ms": 3812.701, "learn_time_ms": 18798.826, "learn_throughput": 212.779, "synch_weights_time_ms": 29.444}, "counters": {"num_env_steps_sampled": 744000, "num_env_steps_trained": 744000, "num_agent_steps_sampled": 2976000, "num_agent_steps_trained": 2976000}, "done": false, "training_iteration": 186, "trial_id": "3a355_00000", "date": "2024-08-13_05-45-47", "timestamp": 1723542347, "time_this_iter_s": 23.0501708984375, "time_total_s": 16543.81806755066, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b7430790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16543.81806755066, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 84.4909090909091, "ram_util_percent": 83.1878787878788}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2634575829777137, "cur_kl_coeff": 5.044674471569343e-45, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.565192230794795, "policy_loss": -0.0012056251918212092, "vf_loss": 4.566397853881594, "vf_explained_var": 0.002141187209931631, "kl": 0.0023579702746891733, "entropy": 0.27882411577714183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 352485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 55.518590908075765, "cur_kl_coeff": 1.8865486274920194e-25, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.308747920409712, "policy_loss": 0.0008852768233587975, "vf_loss": 5.3078626380395635, "vf_explained_var": 0.5236279118628729, "kl": 0.0027312824626399097, "entropy": 0.4432577483158894, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 352485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -600.0, "episode_reward_mean": 56.454999999999856, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -36.857500000000016, "predator_policy": 65.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 171.39999999999947, 34.70000000000025, -293.30000000000024, 32.40000000000009, 183.20000000000005, 172.29999999999896, -122.1000000000003, 23.40000000000003, -26.299999999999663, 99.09999999999985, 91.40000000000005, -72.19999999999996, 32.599999999999994, 144.29999999999973, 272.20000000000033, -28.099999999999767, -174.50000000000063, -11.500000000000004, 219.99999999999926, -33.499999999999986, 62.70000000000006, -177.30000000000064, -167.90000000000057, 372.6, 219.99999999999926, -176.70000000000064, 340.4, 23.000000000000092, 387.4, 11.2, 174.99999999999946, -423.2999999999999, -204.9000000000004, -600.0, 122.79999999999978, 392.0, 307.1, 203.79999999999987, 25.19999999999969, 142.90000000000003, -471.0, 166.89999999999978, 27.50000000000001, -236.09999999999994, 309.1, 356.8000000000004, 219.99999999999926, -156.1000000000004, 133.9, 197.49999999999935, 351.3, -137.10000000000042, -369.0, 111.09999999999982, -413.9, 348.0, 355.5, -285.6, 126.3, -370.4, 375.3, -295.99999999999994, 354.8, -254.80000000000064, 117.39999999999984, 206.79999999999967, 16.30000000000011, 137.1, 315.6, 182.1, -75.5, 14.299999999999953, -14.100000000000003, 228.79999999999953, 200.00000000000006, 22.800000000000054, 183.5999999999995, 400.0, -78.89999999999995, -237.8, 212.2999999999997, 340.2, 342.70000000000005, -203.40000000000012, 219.99999999999926, 165.69999999999973, 5.7000000000000215, 212.7999999999993, 162.9, 277.3, -450.9, 98.20000000000013, -29.299999999999983, 0.0, -234.79999999999998, 217.79999999999927, 284.79999999999995, -249.3999999999999, 238.89999999999912], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 200.0, 151.4, 20.000000000000014, 20.000000000000014, -49.30000000000003, -400.0, -196.29999999999995, 64.10000000000002, -78.70000000000005, -311.79999999999995, 200.0, 20.000000000000014, 152.2999999999997, 21.800000000000047, -292.9, 20.000000000000014, -25.59999999999978, 20.000000000000014, -280.3000000000003, 145.1, -106.00000000000003, 145.1, -372.70000000000005, 20.000000000000014, -194.20000000000002, 32.599999999999994, -400.0, 9.500000000000007, 99.80000000000003, 161.3, 110.89999999999986, -242.49999999999991, 76.40000000000013, 20.000000000000014, -389.5, -379.0, 177.5, 20.000000000000014, 200.0, 125.89999999999999, -324.4, 200.0, -280.3, 22.700000000000063, -400.0, 20.000000000000014, -376.9, 194.0, 176.6, 200.0, 20.000000000000014, -393.7, 20.000000000000014, 160.4, 170.0, -135.40000000000003, 28.400000000000006, 187.4, 200.0, -358.0, 189.2, 155.0, 20.000000000000014, -343.29999999999995, -253.00000000000003, -190.30000000000038, -349.59999999999997, -400.0, -400.0, 20.000000000000014, 102.79999999999998, 188.0, 200.0, 127.1, 170.0, -52.000000000000014, 165.8, 112.69999999999945, -200.49999999999994, -284.5, 178.4, -313.9, -318.1, -93.40000000000003, 152.3, -347.4999999999995, 200.0, -159.09999999999994, -337.0, 146.89999999999998, 162.2, 183.7999999999999, 173.0, 20.000000000000014, 200.0, -360.1, -34.00000000000007, 173.0, -381.1, -29.4999999999999, 200.0, 185.0, 161.3, -318.1, 20.000000000000014, -389.5, -347.5, 200.0, -187.9, -276.1, -290.8, 131.0, 191.0, 162.5, 182.0, -274.0, -265.6, -376.9, 168.2, -374.8, -370.6, 187.7, 185.6, -391.6, -261.4, 200.0, 144.80000000000004, -343.30000000000007, -179.50000000000054, 97.39999999999998, 20.000000000000014, 197.0, -131.20000000000005, 7.399999999999947, -213.10000000000002, 188.0, -376.90000000000003, 112.99999999999997, 194.6, -397.9, 197.0, -200.5, 20.000000000000014, 20.000000000000014, -225.70000000000044, 169.4, -368.5, 170.0, 48.79999999999997, -274.0, 200.0, -227.8, 11.599999999999964, 161.0, -9.400000000000006, 200.0, 200.0, 65.0, -292.9, -305.5, -91.30000000000004, 200.0, -141.70000000000005, 148.10000000000002, 181.1, 130.70000000000005, 200.0, -137.5000000000005, -229.9, 20.000000000000014, 200.0, 200.0, -154.3, 80.29999999999997, -160.6, 192.8, 20.000000000000014, -25.599999999999973, 123.49999999999999, 200.0, 26.30000000000004, -400.0, -250.9, 38.60000000000019, 53.59999999999998, -339.1, 138.79999999999998, 200.0, -400.0, -372.7, -150.1000000000001, 200.0, 15.800000000000004, 137.89999999999998, 146.89999999999998, -208.9, -389.5, 38.900000000000254, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 33.0, 31.0, 103.0, 200.0, 47.0, 0.0, 157.0, 138.0, 0.0, 0.0, 0.0, 149.0, 24.0, 5.0, 143.0, 91.0, 60.0, 0.0, 138.0, 181.0, 0.0, 102.0, 200.0, 200.0, 5.0, 30.0, 0.0, 0.0, 13.0, 125.0, 195.0, 0.0, 190.0, 0.0, 0.0, 0.0, 164.0, 1.0, 143.0, 0.0, 0.0, 200.0, 189.0, 0.0, 0.0, 2.0, 0.0, 0.0, 197.0, 0.0, 10.0, 0.0, 0.0, 130.0, 0.0, 0.0, 0.0, 180.0, 0.0, 0.0, 0.0, 173.0, 196.0, 139.0, 200.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 0.0, 75.0, 15.0, 105.0, 8.0, 145.0, 104.0, 0.0, 161.0, 54.0, 54.0, 0.0, 175.0, 170.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 181.0, 57.0, 195.0, 147.0, 27.0, 0.0, 0.0, 5.0, 0.0, 161.0, 175.0, 193.0, 0.0, 99.0, 0.0, 153.0, 23.0, 3.0, 0.0, 11.0, 126.0, 128.0, 189.0, 146.0, 188.0, 187.0, 2.0, 0.0, 161.0, 196.0, 0.0, 10.0, 95.0, 173.0, 0.0, 0.0, 68.0, 73.0, 111.0, 111.0, 149.0, 177.0, 0.0, 8.0, 200.0, 183.0, 105.0, 0.0, 110.0, 110.0, 185.0, 0.0, 10.0, 0.0, 140.0, 134.0, 117.0, 122.0, 14.0, 18.0, 0.0, 0.0, 149.0, 0.0, 4.0, 155.0, 77.0, 77.0, 0.0, 11.0, 12.0, 0.0, 45.0, 119.0, 0.0, 0.0, 37.0, 83.0, 86.0, 0.0, 0.0, 0.0, 2.0, 63.0, 30.0, 21.0, 200.0, 0.0, 4.0, 2.0, 0.0, 171.0, 0.0, 200.0, 141.0, 147.0, 2.0, 0.0, 0.0, 0.0, 200.0, 149.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.148791860939775, "mean_inference_ms": 7.685740267478463, "mean_action_processing_ms": 0.7027532758539522, "mean_env_wait_ms": 0.9928943120844012, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03018498420715332, "StateBufferConnector_ms": 0.015173673629760742, "ViewRequirementAgentConnector_ms": 0.31706738471984863}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": -600.0, "episode_return_mean": 56.454999999999856, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000, "num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 163.37751081474693, "num_env_steps_trained_throughput_per_sec": 163.37751081474693, "timesteps_total": 748000, "num_env_steps_sampled_lifetime": 748000, "num_agent_steps_sampled_lifetime": 2992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 2992000, "timers": {"training_iteration_time_ms": 22824.186, "restore_workers_time_ms": 0.019, "training_step_time_ms": 22824.107, "sample_time_ms": 3810.107, "learn_time_ms": 18980.762, "learn_throughput": 210.74, "synch_weights_time_ms": 29.098}, "counters": {"num_env_steps_sampled": 748000, "num_env_steps_trained": 748000, "num_agent_steps_sampled": 2992000, "num_agent_steps_trained": 2992000}, "done": false, "training_iteration": 187, "trial_id": "3a355_00000", "date": "2024-08-13_05-46-11", "timestamp": 1723542371, "time_this_iter_s": 24.57313108444214, "time_total_s": 16568.3911986351, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b74325e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16568.3911986351, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 88.53529411764706, "ram_util_percent": 83.26764705882353}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4758735844067166, "cur_kl_coeff": 2.5223372357846714e-45, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.421010002131185, "policy_loss": -0.0012744845723900845, "vf_loss": 4.422284487063292, "vf_explained_var": 0.005011590038027082, "kl": 0.0038187463619155453, "entropy": 0.39639189020981863, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 354375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 51.56817339903148, "cur_kl_coeff": 9.432743137460097e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.448162497162188, "policy_loss": -0.001072735441158767, "vf_loss": 5.44923525071018, "vf_explained_var": 0.3985096353702444, "kl": 0.0029646255122765396, "entropy": 0.5021023970432382, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 354375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -600.0, "episode_reward_mean": 65.17499999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -32.1475, "predator_policy": 64.735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.500000000000004, 219.99999999999926, -33.499999999999986, 62.70000000000006, -177.30000000000064, -167.90000000000057, 372.6, 219.99999999999926, -176.70000000000064, 340.4, 23.000000000000092, 387.4, 11.2, 174.99999999999946, -423.2999999999999, -204.9000000000004, -600.0, 122.79999999999978, 392.0, 307.1, 203.79999999999987, 25.19999999999969, 142.90000000000003, -471.0, 166.89999999999978, 27.50000000000001, -236.09999999999994, 309.1, 356.8000000000004, 219.99999999999926, -156.1000000000004, 133.9, 197.49999999999935, 351.3, -137.10000000000042, -369.0, 111.09999999999982, -413.9, 348.0, 355.5, -285.6, 126.3, -370.4, 375.3, -295.99999999999994, 354.8, -254.80000000000064, 117.39999999999984, 206.79999999999967, 16.30000000000011, 137.1, 315.6, 182.1, -75.5, 14.299999999999953, -14.100000000000003, 228.79999999999953, 200.00000000000006, 22.800000000000054, 183.5999999999995, 400.0, -78.89999999999995, -237.8, 212.2999999999997, 340.2, 342.70000000000005, -203.40000000000012, 219.99999999999926, 165.69999999999973, 5.7000000000000215, 212.7999999999993, 162.9, 277.3, -450.9, 98.20000000000013, -29.299999999999983, 0.0, -234.79999999999998, 217.79999999999927, 284.79999999999995, -249.3999999999999, 238.89999999999912, 396.0, 108.99999999999983, 336.4, -423.09999999999974, -328.59999999999997, 194.0, 152.2, -121.7000000000009, 345.40000000000003, 28.200000000000202, 64.50000000000006, 171.3999999999995, 153.5999999999996, 183.89999999999944, 219.99999999999926, 175.9999999999995, 90.30000000000001, -115.00000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-379.0, 177.5, 20.000000000000014, 200.0, 125.89999999999999, -324.4, 200.0, -280.3, 22.700000000000063, -400.0, 20.000000000000014, -376.9, 194.0, 176.6, 200.0, 20.000000000000014, -393.7, 20.000000000000014, 160.4, 170.0, -135.40000000000003, 28.400000000000006, 187.4, 200.0, -358.0, 189.2, 155.0, 20.000000000000014, -343.29999999999995, -253.00000000000003, -190.30000000000038, -349.59999999999997, -400.0, -400.0, 20.000000000000014, 102.79999999999998, 188.0, 200.0, 127.1, 170.0, -52.000000000000014, 165.8, 112.69999999999945, -200.49999999999994, -284.5, 178.4, -313.9, -318.1, -93.40000000000003, 152.3, -347.4999999999995, 200.0, -159.09999999999994, -337.0, 146.89999999999998, 162.2, 183.7999999999999, 173.0, 20.000000000000014, 200.0, -360.1, -34.00000000000007, 173.0, -381.1, -29.4999999999999, 200.0, 185.0, 161.3, -318.1, 20.000000000000014, -389.5, -347.5, 200.0, -187.9, -276.1, -290.8, 131.0, 191.0, 162.5, 182.0, -274.0, -265.6, -376.9, 168.2, -374.8, -370.6, 187.7, 185.6, -391.6, -261.4, 200.0, 144.80000000000004, -343.30000000000007, -179.50000000000054, 97.39999999999998, 20.000000000000014, 197.0, -131.20000000000005, 7.399999999999947, -213.10000000000002, 188.0, -376.90000000000003, 112.99999999999997, 194.6, -397.9, 197.0, -200.5, 20.000000000000014, 20.000000000000014, -225.70000000000044, 169.4, -368.5, 170.0, 48.79999999999997, -274.0, 200.0, -227.8, 11.599999999999964, 161.0, -9.400000000000006, 200.0, 200.0, 65.0, -292.9, -305.5, -91.30000000000004, 200.0, -141.70000000000005, 148.10000000000002, 181.1, 130.70000000000005, 200.0, -137.5000000000005, -229.9, 20.000000000000014, 200.0, 200.0, -154.3, 80.29999999999997, -160.6, 192.8, 20.000000000000014, -25.599999999999973, 123.49999999999999, 200.0, 26.30000000000004, -400.0, -250.9, 38.60000000000019, 53.59999999999998, -339.1, 138.79999999999998, 200.0, -400.0, -372.7, -150.1000000000001, 200.0, 15.800000000000004, 137.89999999999998, 146.89999999999998, -208.9, -389.5, 38.900000000000254, 200.0, 200.0, 194.0, -143.8, 174.8, 173.0, 154.4, -257.1999999999997, -334.9, -162.70000000000002, -334.9, 200.0, -400.0, 147.8, -307.6, -271.89999999999884, 3.1999999999999864, 142.39999999999998, 200.0, 33.500000000000085, -385.3, 173.0, -242.49999999999994, 20.000000000000014, 151.4, -72.40000000000002, 176.0, 197.0, -45.10000000000002, 200.0, 20.000000000000014, 200.0, -64.00000000000004, -351.7, 200.0, -271.9, 17.900000000000013], "policy_predator_policy_reward": [190.0, 0.0, 0.0, 0.0, 164.0, 1.0, 143.0, 0.0, 0.0, 200.0, 189.0, 0.0, 0.0, 2.0, 0.0, 0.0, 197.0, 0.0, 10.0, 0.0, 0.0, 130.0, 0.0, 0.0, 0.0, 180.0, 0.0, 0.0, 0.0, 173.0, 196.0, 139.0, 200.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 0.0, 75.0, 15.0, 105.0, 8.0, 145.0, 104.0, 0.0, 161.0, 54.0, 54.0, 0.0, 175.0, 170.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 181.0, 57.0, 195.0, 147.0, 27.0, 0.0, 0.0, 5.0, 0.0, 161.0, 175.0, 193.0, 0.0, 99.0, 0.0, 153.0, 23.0, 3.0, 0.0, 11.0, 126.0, 128.0, 189.0, 146.0, 188.0, 187.0, 2.0, 0.0, 161.0, 196.0, 0.0, 10.0, 95.0, 173.0, 0.0, 0.0, 68.0, 73.0, 111.0, 111.0, 149.0, 177.0, 0.0, 8.0, 200.0, 183.0, 105.0, 0.0, 110.0, 110.0, 185.0, 0.0, 10.0, 0.0, 140.0, 134.0, 117.0, 122.0, 14.0, 18.0, 0.0, 0.0, 149.0, 0.0, 4.0, 155.0, 77.0, 77.0, 0.0, 11.0, 12.0, 0.0, 45.0, 119.0, 0.0, 0.0, 37.0, 83.0, 86.0, 0.0, 0.0, 0.0, 2.0, 63.0, 30.0, 21.0, 200.0, 0.0, 4.0, 2.0, 0.0, 171.0, 0.0, 200.0, 141.0, 147.0, 2.0, 0.0, 0.0, 0.0, 200.0, 149.0, 0.0, 0.0, 0.0, 2.0, 78.0, 0.0, 0.0, 9.0, 0.0, 169.0, 169.0, 0.0, 194.0, 200.0, 156.0, 156.0, 3.0, 144.0, 0.0, 3.0, 193.0, 187.0, 0.0, 134.0, 0.0, 0.0, 50.0, 0.0, 31.0, 1.0, 0.0, 0.0, 40.0, 0.0, 177.0, 65.0, 139.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1071494831493194, "mean_inference_ms": 7.706332978090063, "mean_action_processing_ms": 0.7007690661363665, "mean_env_wait_ms": 0.9880381680264486, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03285527229309082, "StateBufferConnector_ms": 0.014387011528015137, "ViewRequirementAgentConnector_ms": 0.2650165557861328}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -600.0, "episode_return_mean": 65.17499999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000, "num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 153.07652155460204, "num_env_steps_trained_throughput_per_sec": 153.07652155460204, "timesteps_total": 752000, "num_env_steps_sampled_lifetime": 752000, "num_agent_steps_sampled_lifetime": 3008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3008000, "timers": {"training_iteration_time_ms": 23271.67, "restore_workers_time_ms": 0.018, "training_step_time_ms": 23271.479, "sample_time_ms": 3726.112, "learn_time_ms": 19511.504, "learn_throughput": 205.007, "synch_weights_time_ms": 29.521}, "counters": {"num_env_steps_sampled": 752000, "num_env_steps_trained": 752000, "num_agent_steps_sampled": 3008000, "num_agent_steps_trained": 3008000}, "done": false, "training_iteration": 188, "trial_id": "3a355_00000", "date": "2024-08-13_05-46-38", "timestamp": 1723542398, "time_this_iter_s": 26.18497085571289, "time_total_s": 16594.576169490814, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fe33a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16594.576169490814, "iterations_since_restore": 188, "perf": {"cpu_util_percent": 89.24594594594595, "ram_util_percent": 83.41891891891892}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3362126271087658, "cur_kl_coeff": 1.2611686178923357e-45, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.547904975073678, "policy_loss": -0.002018139584029399, "vf_loss": 5.5499231144233985, "vf_explained_var": 0.004483463587584319, "kl": 0.005870375187693769, "entropy": 0.2718353968527582, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 356265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 38.87357553519585, "cur_kl_coeff": 4.7163715687300484e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.568676032212676, "policy_loss": -0.00103395732474469, "vf_loss": 5.569709994300964, "vf_explained_var": 0.4643893297387179, "kl": 0.0019982876887422473, "entropy": 0.5286848638108168, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 356265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -481.0999999999999, "episode_reward_mean": 73.67399999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -31.123, "predator_policy": 67.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [392.0, 307.1, 203.79999999999987, 25.19999999999969, 142.90000000000003, -471.0, 166.89999999999978, 27.50000000000001, -236.09999999999994, 309.1, 356.8000000000004, 219.99999999999926, -156.1000000000004, 133.9, 197.49999999999935, 351.3, -137.10000000000042, -369.0, 111.09999999999982, -413.9, 348.0, 355.5, -285.6, 126.3, -370.4, 375.3, -295.99999999999994, 354.8, -254.80000000000064, 117.39999999999984, 206.79999999999967, 16.30000000000011, 137.1, 315.6, 182.1, -75.5, 14.299999999999953, -14.100000000000003, 228.79999999999953, 200.00000000000006, 22.800000000000054, 183.5999999999995, 400.0, -78.89999999999995, -237.8, 212.2999999999997, 340.2, 342.70000000000005, -203.40000000000012, 219.99999999999926, 165.69999999999973, 5.7000000000000215, 212.7999999999993, 162.9, 277.3, -450.9, 98.20000000000013, -29.299999999999983, 0.0, -234.79999999999998, 217.79999999999927, 284.79999999999995, -249.3999999999999, 238.89999999999912, 396.0, 108.99999999999983, 336.4, -423.09999999999974, -328.59999999999997, 194.0, 152.2, -121.7000000000009, 345.40000000000003, 28.200000000000202, 64.50000000000006, 171.3999999999995, 153.5999999999996, 183.89999999999944, 219.99999999999926, 175.9999999999995, 90.30000000000001, -115.00000000000027, 40.0000000000003, 19.49999999999997, -118.4000000000003, 54.200000000000045, 95.09999999999997, 172.49999999999994, 178.90000000000003, 174.09999999999945, -10.599999999999815, 189.9999999999994, 102.4000000000001, -83.99999999999983, 61.40000000000005, -481.0999999999999, 302.79999999999995, 157.0, 100.90000000000003, 35.200000000000024], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [188.0, 200.0, 127.1, 170.0, -52.000000000000014, 165.8, 112.69999999999945, -200.49999999999994, -284.5, 178.4, -313.9, -318.1, -93.40000000000003, 152.3, -347.4999999999995, 200.0, -159.09999999999994, -337.0, 146.89999999999998, 162.2, 183.7999999999999, 173.0, 20.000000000000014, 200.0, -360.1, -34.00000000000007, 173.0, -381.1, -29.4999999999999, 200.0, 185.0, 161.3, -318.1, 20.000000000000014, -389.5, -347.5, 200.0, -187.9, -276.1, -290.8, 131.0, 191.0, 162.5, 182.0, -274.0, -265.6, -376.9, 168.2, -374.8, -370.6, 187.7, 185.6, -391.6, -261.4, 200.0, 144.80000000000004, -343.30000000000007, -179.50000000000054, 97.39999999999998, 20.000000000000014, 197.0, -131.20000000000005, 7.399999999999947, -213.10000000000002, 188.0, -376.90000000000003, 112.99999999999997, 194.6, -397.9, 197.0, -200.5, 20.000000000000014, 20.000000000000014, -225.70000000000044, 169.4, -368.5, 170.0, 48.79999999999997, -274.0, 200.0, -227.8, 11.599999999999964, 161.0, -9.400000000000006, 200.0, 200.0, 65.0, -292.9, -305.5, -91.30000000000004, 200.0, -141.70000000000005, 148.10000000000002, 181.1, 130.70000000000005, 200.0, -137.5000000000005, -229.9, 20.000000000000014, 200.0, 200.0, -154.3, 80.29999999999997, -160.6, 192.8, 20.000000000000014, -25.599999999999973, 123.49999999999999, 200.0, 26.30000000000004, -400.0, -250.9, 38.60000000000019, 53.59999999999998, -339.1, 138.79999999999998, 200.0, -400.0, -372.7, -150.1000000000001, 200.0, 15.800000000000004, 137.89999999999998, 146.89999999999998, -208.9, -389.5, 38.900000000000254, 200.0, 200.0, 194.0, -143.8, 174.8, 173.0, 154.4, -257.1999999999997, -334.9, -162.70000000000002, -334.9, 200.0, -400.0, 147.8, -307.6, -271.89999999999884, 3.1999999999999864, 142.39999999999998, 200.0, 33.500000000000085, -385.3, 173.0, -242.49999999999994, 20.000000000000014, 151.4, -72.40000000000002, 176.0, 197.0, -45.10000000000002, 200.0, 20.000000000000014, 200.0, -64.00000000000004, -351.7, 200.0, -271.9, 17.900000000000013, 20.000000000000014, 20.000000000000014, -250.9, 127.40000000000005, -282.4, 20.000000000000014, 179.0, -269.8, -309.7, 93.79999999999998, -221.49999999999991, 188.0, 170.0, -255.10000000000002, 154.1, 20.000000000000014, 20.000000000000014, -76.60000000000004, 20.000000000000014, 155.0, -160.60000000000002, 113.0, -389.5, -32.50000000000002, -244.60000000000002, 170.0, -379.0, -297.1, 150.5, 152.3, 143.0, -337.0, -211.0, 164.9, 200.0, -332.8], "policy_predator_policy_reward": [0.0, 4.0, 10.0, 0.0, 75.0, 15.0, 105.0, 8.0, 145.0, 104.0, 0.0, 161.0, 54.0, 54.0, 0.0, 175.0, 170.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 181.0, 57.0, 195.0, 147.0, 27.0, 0.0, 0.0, 5.0, 0.0, 161.0, 175.0, 193.0, 0.0, 99.0, 0.0, 153.0, 23.0, 3.0, 0.0, 11.0, 126.0, 128.0, 189.0, 146.0, 188.0, 187.0, 2.0, 0.0, 161.0, 196.0, 0.0, 10.0, 95.0, 173.0, 0.0, 0.0, 68.0, 73.0, 111.0, 111.0, 149.0, 177.0, 0.0, 8.0, 200.0, 183.0, 105.0, 0.0, 110.0, 110.0, 185.0, 0.0, 10.0, 0.0, 140.0, 134.0, 117.0, 122.0, 14.0, 18.0, 0.0, 0.0, 149.0, 0.0, 4.0, 155.0, 77.0, 77.0, 0.0, 11.0, 12.0, 0.0, 45.0, 119.0, 0.0, 0.0, 37.0, 83.0, 86.0, 0.0, 0.0, 0.0, 2.0, 63.0, 30.0, 21.0, 200.0, 0.0, 4.0, 2.0, 0.0, 171.0, 0.0, 200.0, 141.0, 147.0, 2.0, 0.0, 0.0, 0.0, 200.0, 149.0, 0.0, 0.0, 0.0, 2.0, 78.0, 0.0, 0.0, 9.0, 0.0, 169.0, 169.0, 0.0, 194.0, 200.0, 156.0, 156.0, 3.0, 144.0, 0.0, 3.0, 193.0, 187.0, 0.0, 134.0, 0.0, 0.0, 50.0, 0.0, 31.0, 1.0, 0.0, 0.0, 40.0, 0.0, 177.0, 65.0, 139.0, 0.0, 0.0, 0.0, 7.0, 136.0, 0.0, 144.0, 0.0, 145.0, 157.0, 154.0, 114.0, 92.0, 131.0, 133.0, 0.0, 0.0, 46.0, 0.0, 0.0, 15.0, 35.0, 115.0, 143.0, 195.0, 0.0, 136.0, 195.0, 0.0, 0.0, 0.0, 182.0, 169.0, 27.0, 120.0, 168.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1037272667452105, "mean_inference_ms": 7.688163953508621, "mean_action_processing_ms": 0.7001333335887101, "mean_env_wait_ms": 0.9854794191775589, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013266801834106445, "StateBufferConnector_ms": 0.014487147331237793, "ViewRequirementAgentConnector_ms": 0.23398399353027344}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -481.0999999999999, "episode_return_mean": 73.67399999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000, "num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 164.46375609855704, "num_env_steps_trained_throughput_per_sec": 164.46375609855704, "timesteps_total": 756000, "num_env_steps_sampled_lifetime": 756000, "num_agent_steps_sampled_lifetime": 3024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3024000, "timers": {"training_iteration_time_ms": 23457.601, "restore_workers_time_ms": 0.019, "training_step_time_ms": 23457.407, "sample_time_ms": 3581.048, "learn_time_ms": 19844.408, "learn_throughput": 201.568, "synch_weights_time_ms": 27.522}, "counters": {"num_env_steps_sampled": 756000, "num_env_steps_trained": 756000, "num_agent_steps_sampled": 3024000, "num_agent_steps_trained": 3024000}, "done": false, "training_iteration": 189, "trial_id": "3a355_00000", "date": "2024-08-13_05-47-02", "timestamp": 1723542422, "time_this_iter_s": 24.381414890289307, "time_total_s": 16618.957584381104, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b7432820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16618.957584381104, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 87.7657142857143, "ram_util_percent": 82.88285714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1434964378359456, "cur_kl_coeff": 1.2611686178923357e-45, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7700950632650385, "policy_loss": -0.0017828619004123742, "vf_loss": 2.7718779186723093, "vf_explained_var": 0.0008128690656530794, "kl": 0.004310558247199503, "entropy": 0.24869744579785716, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 358155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 45.13011804382322, "cur_kl_coeff": 2.3581857843650242e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.634288605558809, "policy_loss": -9.607915155510738e-05, "vf_loss": 4.634384702374695, "vf_explained_var": 0.49462400198613526, "kl": 0.002364719520293158, "entropy": 0.47583923265732153, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 358155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -481.0999999999999, "episode_reward_mean": 72.8539999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -31.55800000000001, "predator_policy": 67.985}, "custom_metrics": {}, "hist_stats": {"episode_reward": [111.09999999999982, -413.9, 348.0, 355.5, -285.6, 126.3, -370.4, 375.3, -295.99999999999994, 354.8, -254.80000000000064, 117.39999999999984, 206.79999999999967, 16.30000000000011, 137.1, 315.6, 182.1, -75.5, 14.299999999999953, -14.100000000000003, 228.79999999999953, 200.00000000000006, 22.800000000000054, 183.5999999999995, 400.0, -78.89999999999995, -237.8, 212.2999999999997, 340.2, 342.70000000000005, -203.40000000000012, 219.99999999999926, 165.69999999999973, 5.7000000000000215, 212.7999999999993, 162.9, 277.3, -450.9, 98.20000000000013, -29.299999999999983, 0.0, -234.79999999999998, 217.79999999999927, 284.79999999999995, -249.3999999999999, 238.89999999999912, 396.0, 108.99999999999983, 336.4, -423.09999999999974, -328.59999999999997, 194.0, 152.2, -121.7000000000009, 345.40000000000003, 28.200000000000202, 64.50000000000006, 171.3999999999995, 153.5999999999996, 183.89999999999944, 219.99999999999926, 175.9999999999995, 90.30000000000001, -115.00000000000027, 40.0000000000003, 19.49999999999997, -118.4000000000003, 54.200000000000045, 95.09999999999997, 172.49999999999994, 178.90000000000003, 174.09999999999945, -10.599999999999815, 189.9999999999994, 102.4000000000001, -83.99999999999983, 61.40000000000005, -481.0999999999999, 302.79999999999995, 157.0, 100.90000000000003, 35.200000000000024, 275.7999999999997, 219.99999999999926, -278.9999999999999, -450.8999999999997, 361.30000000000007, -358.6, -107.40000000000023, 52.59999999999953, 219.99999999999926, 400.0, -91.00000000000006, 301.9000000000009, 178.2, 154.2000000000001, 100.69999999999996, 38.700000000000266, 46.30000000000041, 319.90000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, -187.9, -276.1, -290.8, 131.0, 191.0, 162.5, 182.0, -274.0, -265.6, -376.9, 168.2, -374.8, -370.6, 187.7, 185.6, -391.6, -261.4, 200.0, 144.80000000000004, -343.30000000000007, -179.50000000000054, 97.39999999999998, 20.000000000000014, 197.0, -131.20000000000005, 7.399999999999947, -213.10000000000002, 188.0, -376.90000000000003, 112.99999999999997, 194.6, -397.9, 197.0, -200.5, 20.000000000000014, 20.000000000000014, -225.70000000000044, 169.4, -368.5, 170.0, 48.79999999999997, -274.0, 200.0, -227.8, 11.599999999999964, 161.0, -9.400000000000006, 200.0, 200.0, 65.0, -292.9, -305.5, -91.30000000000004, 200.0, -141.70000000000005, 148.10000000000002, 181.1, 130.70000000000005, 200.0, -137.5000000000005, -229.9, 20.000000000000014, 200.0, 200.0, -154.3, 80.29999999999997, -160.6, 192.8, 20.000000000000014, -25.599999999999973, 123.49999999999999, 200.0, 26.30000000000004, -400.0, -250.9, 38.60000000000019, 53.59999999999998, -339.1, 138.79999999999998, 200.0, -400.0, -372.7, -150.1000000000001, 200.0, 15.800000000000004, 137.89999999999998, 146.89999999999998, -208.9, -389.5, 38.900000000000254, 200.0, 200.0, 194.0, -143.8, 174.8, 173.0, 154.4, -257.1999999999997, -334.9, -162.70000000000002, -334.9, 200.0, -400.0, 147.8, -307.6, -271.89999999999884, 3.1999999999999864, 142.39999999999998, 200.0, 33.500000000000085, -385.3, 173.0, -242.49999999999994, 20.000000000000014, 151.4, -72.40000000000002, 176.0, 197.0, -45.10000000000002, 200.0, 20.000000000000014, 200.0, -64.00000000000004, -351.7, 200.0, -271.9, 17.900000000000013, 20.000000000000014, 20.000000000000014, -250.9, 127.40000000000005, -282.4, 20.000000000000014, 179.0, -269.8, -309.7, 93.79999999999998, -221.49999999999991, 188.0, 170.0, -255.10000000000002, 154.1, 20.000000000000014, 20.000000000000014, -76.60000000000004, 20.000000000000014, 155.0, -160.60000000000002, 113.0, -389.5, -32.50000000000002, -244.60000000000002, 170.0, -379.0, -297.1, 150.5, 152.3, 143.0, -337.0, -211.0, 164.9, 200.0, -332.8, 75.79999999999934, 200.0, 20.000000000000014, 200.0, -349.5999999999997, -219.4, -400.0, -250.90000000000006, 161.3, 200.0, -358.0, -370.6, -261.4, 20.000000000000014, -74.50000000000088, 82.10000000000008, 200.0, 20.000000000000014, 200.0, 200.0, -68.20000000000002, -353.7999999999998, 156.8, 145.09999999999968, -353.8, 200.0, 125.0, -227.8, 116.29999999999998, -370.59999999999997, 20.000000000000014, 16.699999999999964, 26.30000000000012, 20.000000000000014, 179.3, 140.6], "policy_predator_policy_reward": [0.0, 99.0, 0.0, 153.0, 23.0, 3.0, 0.0, 11.0, 126.0, 128.0, 189.0, 146.0, 188.0, 187.0, 2.0, 0.0, 161.0, 196.0, 0.0, 10.0, 95.0, 173.0, 0.0, 0.0, 68.0, 73.0, 111.0, 111.0, 149.0, 177.0, 0.0, 8.0, 200.0, 183.0, 105.0, 0.0, 110.0, 110.0, 185.0, 0.0, 10.0, 0.0, 140.0, 134.0, 117.0, 122.0, 14.0, 18.0, 0.0, 0.0, 149.0, 0.0, 4.0, 155.0, 77.0, 77.0, 0.0, 11.0, 12.0, 0.0, 45.0, 119.0, 0.0, 0.0, 37.0, 83.0, 86.0, 0.0, 0.0, 0.0, 2.0, 63.0, 30.0, 21.0, 200.0, 0.0, 4.0, 2.0, 0.0, 171.0, 0.0, 200.0, 141.0, 147.0, 2.0, 0.0, 0.0, 0.0, 200.0, 149.0, 0.0, 0.0, 0.0, 2.0, 78.0, 0.0, 0.0, 9.0, 0.0, 169.0, 169.0, 0.0, 194.0, 200.0, 156.0, 156.0, 3.0, 144.0, 0.0, 3.0, 193.0, 187.0, 0.0, 134.0, 0.0, 0.0, 50.0, 0.0, 31.0, 1.0, 0.0, 0.0, 40.0, 0.0, 177.0, 65.0, 139.0, 0.0, 0.0, 0.0, 7.0, 136.0, 0.0, 144.0, 0.0, 145.0, 157.0, 154.0, 114.0, 92.0, 131.0, 133.0, 0.0, 0.0, 46.0, 0.0, 0.0, 15.0, 35.0, 115.0, 143.0, 195.0, 0.0, 136.0, 195.0, 0.0, 0.0, 0.0, 182.0, 169.0, 27.0, 120.0, 168.0, 0.0, 0.0, 0.0, 0.0, 0.0, 176.0, 114.0, 200.0, 0.0, 0.0, 0.0, 190.0, 180.0, 0.0, 134.0, 45.0, 0.0, 0.0, 0.0, 0.0, 0.0, 162.0, 169.0, 0.0, 0.0, 178.0, 154.0, 118.0, 139.0, 174.0, 181.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1003091661814355, "mean_inference_ms": 7.670503368629178, "mean_action_processing_ms": 0.6995464947588012, "mean_env_wait_ms": 0.9829895047110914, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012960553169250488, "StateBufferConnector_ms": 0.014550924301147461, "ViewRequirementAgentConnector_ms": 0.2358551025390625}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -481.0999999999999, "episode_return_mean": 72.8539999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000, "num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 158.36999173384797, "num_env_steps_trained_throughput_per_sec": 158.36999173384797, "timesteps_total": 760000, "num_env_steps_sampled_lifetime": 760000, "num_agent_steps_sampled_lifetime": 3040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3040000, "timers": {"training_iteration_time_ms": 23513.658, "restore_workers_time_ms": 0.018, "training_step_time_ms": 23513.462, "sample_time_ms": 3521.862, "learn_time_ms": 19958.592, "learn_throughput": 200.415, "synch_weights_time_ms": 28.329}, "counters": {"num_env_steps_sampled": 760000, "num_env_steps_trained": 760000, "num_agent_steps_sampled": 3040000, "num_agent_steps_trained": 3040000}, "done": false, "training_iteration": 190, "trial_id": "3a355_00000", "date": "2024-08-13_05-47-28", "timestamp": 1723542448, "time_this_iter_s": 25.33254623413086, "time_total_s": 16644.290130615234, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5556310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16644.290130615234, "iterations_since_restore": 190, "perf": {"cpu_util_percent": 89.71666666666667, "ram_util_percent": 83.39999999999998}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.333916929458815, "cur_kl_coeff": 6.3058430894616785e-46, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.0888677368719115, "policy_loss": -0.0027763901798241826, "vf_loss": 5.091644131695783, "vf_explained_var": 0.0010015784748016842, "kl": 0.005939214260060073, "entropy": 0.2790905146765961, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 360045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 48.3423849228671, "cur_kl_coeff": 1.1790928921825121e-26, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.425701993987674, "policy_loss": -0.0004135428798488445, "vf_loss": 5.426115541357212, "vf_explained_var": 0.4715901602512945, "kl": 0.0015403544041805858, "entropy": 0.5226603861523684, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 360045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -481.0999999999999, "episode_reward_mean": 79.05699999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -21.086500000000004, "predator_policy": 60.615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [183.5999999999995, 400.0, -78.89999999999995, -237.8, 212.2999999999997, 340.2, 342.70000000000005, -203.40000000000012, 219.99999999999926, 165.69999999999973, 5.7000000000000215, 212.7999999999993, 162.9, 277.3, -450.9, 98.20000000000013, -29.299999999999983, 0.0, -234.79999999999998, 217.79999999999927, 284.79999999999995, -249.3999999999999, 238.89999999999912, 396.0, 108.99999999999983, 336.4, -423.09999999999974, -328.59999999999997, 194.0, 152.2, -121.7000000000009, 345.40000000000003, 28.200000000000202, 64.50000000000006, 171.3999999999995, 153.5999999999996, 183.89999999999944, 219.99999999999926, 175.9999999999995, 90.30000000000001, -115.00000000000027, 40.0000000000003, 19.49999999999997, -118.4000000000003, 54.200000000000045, 95.09999999999997, 172.49999999999994, 178.90000000000003, 174.09999999999945, -10.599999999999815, 189.9999999999994, 102.4000000000001, -83.99999999999983, 61.40000000000005, -481.0999999999999, 302.79999999999995, 157.0, 100.90000000000003, 35.200000000000024, 275.7999999999997, 219.99999999999926, -278.9999999999999, -450.8999999999997, 361.30000000000007, -358.6, -107.40000000000023, 52.59999999999953, 219.99999999999926, 400.0, -91.00000000000006, 301.9000000000009, 178.2, 154.2000000000001, 100.69999999999996, 38.700000000000266, 46.30000000000041, 319.90000000000003, 144.3999999999996, -316.4000000000003, 219.99999999999926, -81.90000000000033, 189.9999999999994, 348.0, 217.99999999999926, -22.399999999999736, 219.99999999999926, -60.09999999999995, -123.90000000000032, 114.59999999999991, 172.60000000000002, 348.5, -281.3000000000003, 37.50000000000026, 214.29999999999995, 360.0, -50.19999999999985, 123.60000000000001, 219.99999999999926, 20.1, 6.8000000000001215], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [161.0, -9.400000000000006, 200.0, 200.0, 65.0, -292.9, -305.5, -91.30000000000004, 200.0, -141.70000000000005, 148.10000000000002, 181.1, 130.70000000000005, 200.0, -137.5000000000005, -229.9, 20.000000000000014, 200.0, 200.0, -154.3, 80.29999999999997, -160.6, 192.8, 20.000000000000014, -25.599999999999973, 123.49999999999999, 200.0, 26.30000000000004, -400.0, -250.9, 38.60000000000019, 53.59999999999998, -339.1, 138.79999999999998, 200.0, -400.0, -372.7, -150.1000000000001, 200.0, 15.800000000000004, 137.89999999999998, 146.89999999999998, -208.9, -389.5, 38.900000000000254, 200.0, 200.0, 194.0, -143.8, 174.8, 173.0, 154.4, -257.1999999999997, -334.9, -162.70000000000002, -334.9, 200.0, -400.0, 147.8, -307.6, -271.89999999999884, 3.1999999999999864, 142.39999999999998, 200.0, 33.500000000000085, -385.3, 173.0, -242.49999999999994, 20.000000000000014, 151.4, -72.40000000000002, 176.0, 197.0, -45.10000000000002, 200.0, 20.000000000000014, 200.0, -64.00000000000004, -351.7, 200.0, -271.9, 17.900000000000013, 20.000000000000014, 20.000000000000014, -250.9, 127.40000000000005, -282.4, 20.000000000000014, 179.0, -269.8, -309.7, 93.79999999999998, -221.49999999999991, 188.0, 170.0, -255.10000000000002, 154.1, 20.000000000000014, 20.000000000000014, -76.60000000000004, 20.000000000000014, 155.0, -160.60000000000002, 113.0, -389.5, -32.50000000000002, -244.60000000000002, 170.0, -379.0, -297.1, 150.5, 152.3, 143.0, -337.0, -211.0, 164.9, 200.0, -332.8, 75.79999999999934, 200.0, 20.000000000000014, 200.0, -349.5999999999997, -219.4, -400.0, -250.90000000000006, 161.3, 200.0, -358.0, -370.6, -261.4, 20.000000000000014, -74.50000000000088, 82.10000000000008, 200.0, 20.000000000000014, 200.0, 200.0, -68.20000000000002, -353.7999999999998, 156.8, 145.09999999999968, -353.8, 200.0, 125.0, -227.8, 116.29999999999998, -370.59999999999997, 20.000000000000014, 16.699999999999964, 26.30000000000012, 20.000000000000014, 179.3, 140.6, 20.000000000000014, 124.39999999999998, -246.70000000000002, -393.7, 200.0, 20.000000000000014, -292.9, 20.000000000000014, 155.0, 20.000000000000014, 140.0, 188.0, 20.000000000000014, 197.0, 20.000000000000014, -345.4000000000001, 20.000000000000014, 200.0, -171.10000000000002, 20.000000000000014, 20.000000000000014, -292.9, 200.0, -219.4, 170.0, -303.4, 138.50000000000006, 200.0, -160.59999999999994, -330.7, -32.50000000000003, 20.000000000000014, 79.39999999999998, 119.9, 200.0, 140.0, -152.2000000000002, 20.000000000000014, 190.1, -326.5000000000002, 20.000000000000014, 200.0, 20.000000000000014, -313.9, -47.19999999999976, 20.000000000000014], "policy_predator_policy_reward": [14.0, 18.0, 0.0, 0.0, 149.0, 0.0, 4.0, 155.0, 77.0, 77.0, 0.0, 11.0, 12.0, 0.0, 45.0, 119.0, 0.0, 0.0, 37.0, 83.0, 86.0, 0.0, 0.0, 0.0, 2.0, 63.0, 30.0, 21.0, 200.0, 0.0, 4.0, 2.0, 0.0, 171.0, 0.0, 200.0, 141.0, 147.0, 2.0, 0.0, 0.0, 0.0, 200.0, 149.0, 0.0, 0.0, 0.0, 2.0, 78.0, 0.0, 0.0, 9.0, 0.0, 169.0, 169.0, 0.0, 194.0, 200.0, 156.0, 156.0, 3.0, 144.0, 0.0, 3.0, 193.0, 187.0, 0.0, 134.0, 0.0, 0.0, 50.0, 0.0, 31.0, 1.0, 0.0, 0.0, 40.0, 0.0, 177.0, 65.0, 139.0, 0.0, 0.0, 0.0, 7.0, 136.0, 0.0, 144.0, 0.0, 145.0, 157.0, 154.0, 114.0, 92.0, 131.0, 133.0, 0.0, 0.0, 46.0, 0.0, 0.0, 15.0, 35.0, 115.0, 143.0, 195.0, 0.0, 136.0, 195.0, 0.0, 0.0, 0.0, 182.0, 169.0, 27.0, 120.0, 168.0, 0.0, 0.0, 0.0, 0.0, 0.0, 176.0, 114.0, 200.0, 0.0, 0.0, 0.0, 190.0, 180.0, 0.0, 134.0, 45.0, 0.0, 0.0, 0.0, 0.0, 0.0, 162.0, 169.0, 0.0, 0.0, 178.0, 154.0, 118.0, 139.0, 174.0, 181.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.0, 197.0, 0.0, 0.0, 42.0, 149.0, 0.0, 15.0, 20.0, 0.0, 0.0, 1.0, 160.0, 143.0, 0.0, 0.0, 0.0, 91.0, 0.0, 149.0, 114.0, 20.0, 164.0, 142.0, 0.0, 10.0, 43.0, 167.0, 25.0, 25.0, 15.0, 0.0, 20.0, 0.0, 82.0, 0.0, 129.0, 131.0, 0.0, 0.0, 159.0, 155.0, 29.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.0969216781235214, "mean_inference_ms": 7.606157981177798, "mean_action_processing_ms": 0.6999469895688014, "mean_env_wait_ms": 1.015759560642899, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013079047203063965, "StateBufferConnector_ms": 0.015158414840698242, "ViewRequirementAgentConnector_ms": 0.228607177734375}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -481.0999999999999, "episode_return_mean": 79.05699999999987, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000, "num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 163.30926561935868, "num_env_steps_trained_throughput_per_sec": 163.30926561935868, "timesteps_total": 764000, "num_env_steps_sampled_lifetime": 764000, "num_agent_steps_sampled_lifetime": 3056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3056000, "timers": {"training_iteration_time_ms": 23808.304, "restore_workers_time_ms": 0.018, "training_step_time_ms": 23808.109, "sample_time_ms": 3515.117, "learn_time_ms": 20263.628, "learn_throughput": 197.398, "synch_weights_time_ms": 24.68}, "counters": {"num_env_steps_sampled": 764000, "num_env_steps_trained": 764000, "num_agent_steps_sampled": 3056000, "num_agent_steps_trained": 3056000}, "done": false, "training_iteration": 191, "trial_id": "3a355_00000", "date": "2024-08-13_05-47-52", "timestamp": 1723542472, "time_this_iter_s": 24.56871199607849, "time_total_s": 16668.858842611313, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fe3550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16668.858842611313, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 87.13529411764705, "ram_util_percent": 83.39411764705882}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3429361053244777, "cur_kl_coeff": 6.3058430894616785e-46, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.415398129332003, "policy_loss": -0.0009997344127407781, "vf_loss": 5.416397851232499, "vf_explained_var": 0.0010253062323918418, "kl": 0.001629785381319873, "entropy": 0.24136300247813028, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 361935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 36.110773708549125, "cur_kl_coeff": 5.8954644609125605e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.112391603056085, "policy_loss": -0.00010585021042811966, "vf_loss": 6.112497457373079, "vf_explained_var": 0.3403665763045114, "kl": 0.003363614081299582, "entropy": 0.5132401940526155, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 361935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -504.5999999999999, "episode_reward_mean": 68.65899999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -31.800499999999996, "predator_policy": 66.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [238.89999999999912, 396.0, 108.99999999999983, 336.4, -423.09999999999974, -328.59999999999997, 194.0, 152.2, -121.7000000000009, 345.40000000000003, 28.200000000000202, 64.50000000000006, 171.3999999999995, 153.5999999999996, 183.89999999999944, 219.99999999999926, 175.9999999999995, 90.30000000000001, -115.00000000000027, 40.0000000000003, 19.49999999999997, -118.4000000000003, 54.200000000000045, 95.09999999999997, 172.49999999999994, 178.90000000000003, 174.09999999999945, -10.599999999999815, 189.9999999999994, 102.4000000000001, -83.99999999999983, 61.40000000000005, -481.0999999999999, 302.79999999999995, 157.0, 100.90000000000003, 35.200000000000024, 275.7999999999997, 219.99999999999926, -278.9999999999999, -450.8999999999997, 361.30000000000007, -358.6, -107.40000000000023, 52.59999999999953, 219.99999999999926, 400.0, -91.00000000000006, 301.9000000000009, 178.2, 154.2000000000001, 100.69999999999996, 38.700000000000266, 46.30000000000041, 319.90000000000003, 144.3999999999996, -316.4000000000003, 219.99999999999926, -81.90000000000033, 189.9999999999994, 348.0, 217.99999999999926, -22.399999999999736, 219.99999999999926, -60.09999999999995, -123.90000000000032, 114.59999999999991, 172.60000000000002, 348.5, -281.3000000000003, 37.50000000000026, 214.29999999999995, 360.0, -50.19999999999985, 123.60000000000001, 219.99999999999926, 20.1, 6.8000000000001215, 61.7000000000002, -253.50000000000006, 0.0, 372.0, 160.79999999999956, 205.99999999999932, 138.09999999999965, 376.0, -140.40000000000043, -106.50000000000057, 71.90000000000009, -51.299999999999955, 239.89999999999944, -504.5999999999999, 40.60000000000005, 63.89999999999999, 10.099999999999941, 23.800000000000068, 72.39999999999995, -257.0, 73.60000000000002, 2.2], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [38.900000000000254, 200.0, 200.0, 194.0, -143.8, 174.8, 173.0, 154.4, -257.1999999999997, -334.9, -162.70000000000002, -334.9, 200.0, -400.0, 147.8, -307.6, -271.89999999999884, 3.1999999999999864, 142.39999999999998, 200.0, 33.500000000000085, -385.3, 173.0, -242.49999999999994, 20.000000000000014, 151.4, -72.40000000000002, 176.0, 197.0, -45.10000000000002, 200.0, 20.000000000000014, 200.0, -64.00000000000004, -351.7, 200.0, -271.9, 17.900000000000013, 20.000000000000014, 20.000000000000014, -250.9, 127.40000000000005, -282.4, 20.000000000000014, 179.0, -269.8, -309.7, 93.79999999999998, -221.49999999999991, 188.0, 170.0, -255.10000000000002, 154.1, 20.000000000000014, 20.000000000000014, -76.60000000000004, 20.000000000000014, 155.0, -160.60000000000002, 113.0, -389.5, -32.50000000000002, -244.60000000000002, 170.0, -379.0, -297.1, 150.5, 152.3, 143.0, -337.0, -211.0, 164.9, 200.0, -332.8, 75.79999999999934, 200.0, 20.000000000000014, 200.0, -349.5999999999997, -219.4, -400.0, -250.90000000000006, 161.3, 200.0, -358.0, -370.6, -261.4, 20.000000000000014, -74.50000000000088, 82.10000000000008, 200.0, 20.000000000000014, 200.0, 200.0, -68.20000000000002, -353.7999999999998, 156.8, 145.09999999999968, -353.8, 200.0, 125.0, -227.8, 116.29999999999998, -370.59999999999997, 20.000000000000014, 16.699999999999964, 26.30000000000012, 20.000000000000014, 179.3, 140.6, 20.000000000000014, 124.39999999999998, -246.70000000000002, -393.7, 200.0, 20.000000000000014, -292.9, 20.000000000000014, 155.0, 20.000000000000014, 140.0, 188.0, 20.000000000000014, 197.0, 20.000000000000014, -345.4000000000001, 20.000000000000014, 200.0, -171.10000000000002, 20.000000000000014, 20.000000000000014, -292.9, 200.0, -219.4, 170.0, -303.4, 138.50000000000006, 200.0, -160.59999999999994, -330.7, -32.50000000000003, 20.000000000000014, 79.39999999999998, 119.9, 200.0, 140.0, -152.2000000000002, 20.000000000000014, 190.1, -326.5000000000002, 20.000000000000014, 200.0, 20.000000000000014, -313.9, -47.19999999999976, 20.000000000000014, 37.70000000000003, 20.000000000000014, -292.9, -286.60000000000014, -400.0, 200.0, 158.0, 200.0, -47.200000000000024, 164.0, 179.0, 20.000000000000014, 20.000000000000014, 118.09999999999998, 200.0, 164.0, -324.4, 20.000000000000014, -368.5, 20.000000000000014, 113.89999999999998, -358.0000000000001, 118.99999999999999, -343.3, 35.90000000000012, 200.0, -324.4, -362.19999999999993, -238.30000000000032, 155.9, 185.6, -393.70000000000005, 20.000000000000014, -208.9, -320.2, 20.000000000000014, 52.39999999999999, 20.000000000000014, -250.9, -381.1, -269.4, 200.0, -395.8, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 2.0, 78.0, 0.0, 0.0, 9.0, 0.0, 169.0, 169.0, 0.0, 194.0, 200.0, 156.0, 156.0, 3.0, 144.0, 0.0, 3.0, 193.0, 187.0, 0.0, 134.0, 0.0, 0.0, 50.0, 0.0, 31.0, 1.0, 0.0, 0.0, 40.0, 0.0, 177.0, 65.0, 139.0, 0.0, 0.0, 0.0, 7.0, 136.0, 0.0, 144.0, 0.0, 145.0, 157.0, 154.0, 114.0, 92.0, 131.0, 133.0, 0.0, 0.0, 46.0, 0.0, 0.0, 15.0, 35.0, 115.0, 143.0, 195.0, 0.0, 136.0, 195.0, 0.0, 0.0, 0.0, 182.0, 169.0, 27.0, 120.0, 168.0, 0.0, 0.0, 0.0, 0.0, 0.0, 176.0, 114.0, 200.0, 0.0, 0.0, 0.0, 190.0, 180.0, 0.0, 134.0, 45.0, 0.0, 0.0, 0.0, 0.0, 0.0, 162.0, 169.0, 0.0, 0.0, 178.0, 154.0, 118.0, 139.0, 174.0, 181.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.0, 197.0, 0.0, 0.0, 42.0, 149.0, 0.0, 15.0, 20.0, 0.0, 0.0, 1.0, 160.0, 143.0, 0.0, 0.0, 0.0, 91.0, 0.0, 149.0, 114.0, 20.0, 164.0, 142.0, 0.0, 10.0, 43.0, 167.0, 25.0, 25.0, 15.0, 0.0, 20.0, 0.0, 82.0, 0.0, 129.0, 131.0, 0.0, 0.0, 159.0, 155.0, 29.0, 5.0, 4.0, 0.0, 163.0, 163.0, 0.0, 200.0, 14.0, 0.0, 0.0, 44.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 164.0, 0.0, 185.0, 57.0, 177.0, 139.0, 0.0, 173.0, 4.0, 0.0, 182.0, 0.0, 0.0, 123.0, 75.0, 197.0, 106.0, 93.0, 162.0, 162.0, 0.0, 0.0, 191.0, 184.0, 143.0, 0.0, 198.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.0926598142173827, "mean_inference_ms": 7.629898101813332, "mean_action_processing_ms": 0.6985912606806872, "mean_env_wait_ms": 0.9774011772468356, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014494657516479492, "StateBufferConnector_ms": 0.006438851356506348, "ViewRequirementAgentConnector_ms": 0.2865018844604492}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -504.5999999999999, "episode_return_mean": 68.65899999999986, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000, "num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 159.23022284920958, "num_env_steps_trained_throughput_per_sec": 159.23022284920958, "timesteps_total": 768000, "num_env_steps_sampled_lifetime": 768000, "num_agent_steps_sampled_lifetime": 3072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3072000, "timers": {"training_iteration_time_ms": 24278.119, "restore_workers_time_ms": 0.018, "training_step_time_ms": 24277.924, "sample_time_ms": 3474.274, "learn_time_ms": 20772.332, "learn_throughput": 192.564, "synch_weights_time_ms": 25.924}, "counters": {"num_env_steps_sampled": 768000, "num_env_steps_trained": 768000, "num_agent_steps_sampled": 3072000, "num_agent_steps_trained": 3072000}, "done": false, "training_iteration": 192, "trial_id": "3a355_00000", "date": "2024-08-13_05-48-18", "timestamp": 1723542498, "time_this_iter_s": 25.23264503479004, "time_total_s": 16694.091487646103, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fe3f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16694.091487646103, "iterations_since_restore": 192, "perf": {"cpu_util_percent": 85.46666666666667, "ram_util_percent": 83.46111111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2118154710799298, "cur_kl_coeff": 3.1529215447308393e-46, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.22628463462547, "policy_loss": -0.0017251571164855724, "vf_loss": 4.228009796268726, "vf_explained_var": 0.0029378197495899504, "kl": 0.005222865738081305, "entropy": 0.25909995070052527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 363825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 73.33038138264702, "cur_kl_coeff": 2.9477322304562802e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.945985278124532, "policy_loss": 0.0012453874511516125, "vf_loss": 4.944739894892173, "vf_explained_var": 0.40704779505098937, "kl": 0.0021560034557586076, "entropy": 0.5131283652530145, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 363825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -504.5999999999999, "episode_reward_mean": 58.98799999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -40.69100000000001, "predator_policy": 70.185}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-115.00000000000027, 40.0000000000003, 19.49999999999997, -118.4000000000003, 54.200000000000045, 95.09999999999997, 172.49999999999994, 178.90000000000003, 174.09999999999945, -10.599999999999815, 189.9999999999994, 102.4000000000001, -83.99999999999983, 61.40000000000005, -481.0999999999999, 302.79999999999995, 157.0, 100.90000000000003, 35.200000000000024, 275.7999999999997, 219.99999999999926, -278.9999999999999, -450.8999999999997, 361.30000000000007, -358.6, -107.40000000000023, 52.59999999999953, 219.99999999999926, 400.0, -91.00000000000006, 301.9000000000009, 178.2, 154.2000000000001, 100.69999999999996, 38.700000000000266, 46.30000000000041, 319.90000000000003, 144.3999999999996, -316.4000000000003, 219.99999999999926, -81.90000000000033, 189.9999999999994, 348.0, 217.99999999999926, -22.399999999999736, 219.99999999999926, -60.09999999999995, -123.90000000000032, 114.59999999999991, 172.60000000000002, 348.5, -281.3000000000003, 37.50000000000026, 214.29999999999995, 360.0, -50.19999999999985, 123.60000000000001, 219.99999999999926, 20.1, 6.8000000000001215, 61.7000000000002, -253.50000000000006, 0.0, 372.0, 160.79999999999956, 205.99999999999932, 138.09999999999965, 376.0, -140.40000000000043, -106.50000000000057, 71.90000000000009, -51.299999999999955, 239.89999999999944, -504.5999999999999, 40.60000000000005, 63.89999999999999, 10.099999999999941, 23.800000000000068, 72.39999999999995, -257.0, 73.60000000000002, 2.2, 133.00000000000003, 217.99999999999926, 31.500000000000092, -36.0000000000005, -198.9000000000007, -132.7000000000004, 63.60000000000008, -50.39999999999998, 32.30000000000018, 400.0, 178.9, 219.99999999999926, 168.10000000000005, 151.39999999999958, 74.60000000000004, -240.30000000000067, 107.8, -101.6000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-271.9, 17.900000000000013, 20.000000000000014, 20.000000000000014, -250.9, 127.40000000000005, -282.4, 20.000000000000014, 179.0, -269.8, -309.7, 93.79999999999998, -221.49999999999991, 188.0, 170.0, -255.10000000000002, 154.1, 20.000000000000014, 20.000000000000014, -76.60000000000004, 20.000000000000014, 155.0, -160.60000000000002, 113.0, -389.5, -32.50000000000002, -244.60000000000002, 170.0, -379.0, -297.1, 150.5, 152.3, 143.0, -337.0, -211.0, 164.9, 200.0, -332.8, 75.79999999999934, 200.0, 20.000000000000014, 200.0, -349.5999999999997, -219.4, -400.0, -250.90000000000006, 161.3, 200.0, -358.0, -370.6, -261.4, 20.000000000000014, -74.50000000000088, 82.10000000000008, 200.0, 20.000000000000014, 200.0, 200.0, -68.20000000000002, -353.7999999999998, 156.8, 145.09999999999968, -353.8, 200.0, 125.0, -227.8, 116.29999999999998, -370.59999999999997, 20.000000000000014, 16.699999999999964, 26.30000000000012, 20.000000000000014, 179.3, 140.6, 20.000000000000014, 124.39999999999998, -246.70000000000002, -393.7, 200.0, 20.000000000000014, -292.9, 20.000000000000014, 155.0, 20.000000000000014, 140.0, 188.0, 20.000000000000014, 197.0, 20.000000000000014, -345.4000000000001, 20.000000000000014, 200.0, -171.10000000000002, 20.000000000000014, 20.000000000000014, -292.9, 200.0, -219.4, 170.0, -303.4, 138.50000000000006, 200.0, -160.59999999999994, -330.7, -32.50000000000003, 20.000000000000014, 79.39999999999998, 119.9, 200.0, 140.0, -152.2000000000002, 20.000000000000014, 190.1, -326.5000000000002, 20.000000000000014, 200.0, 20.000000000000014, -313.9, -47.19999999999976, 20.000000000000014, 37.70000000000003, 20.000000000000014, -292.9, -286.60000000000014, -400.0, 200.0, 158.0, 200.0, -47.200000000000024, 164.0, 179.0, 20.000000000000014, 20.000000000000014, 118.09999999999998, 200.0, 164.0, -324.4, 20.000000000000014, -368.5, 20.000000000000014, 113.89999999999998, -358.0000000000001, 118.99999999999999, -343.3, 35.90000000000012, 200.0, -324.4, -362.19999999999993, -238.30000000000032, 155.9, 185.6, -393.70000000000005, 20.000000000000014, -208.9, -320.2, 20.000000000000014, 52.39999999999999, 20.000000000000014, -250.9, -381.1, -269.4, 200.0, -395.8, 200.0, -395.8, 156.8, 20.000000000000014, 197.0, -343.3, 93.79999999999998, -184.0, 20.000000000000014, -192.1000000000002, -122.80000000000047, -309.69999999999993, 20.000000000000014, -240.4, 170.0, -395.8, 127.40000000000002, 20.000000000000014, 5.299999999999965, 200.0, 200.0, 200.0, -360.1, 20.000000000000014, 200.0, 194.0, -271.9, 130.39999999999998, 20.000000000000014, 118.99999999999999, -324.4, -53.49999999999983, -374.8, -362.2, 116.0, -295.0, 43.40000000000005], "policy_predator_policy_reward": [139.0, 0.0, 0.0, 0.0, 7.0, 136.0, 0.0, 144.0, 0.0, 145.0, 157.0, 154.0, 114.0, 92.0, 131.0, 133.0, 0.0, 0.0, 46.0, 0.0, 0.0, 15.0, 35.0, 115.0, 143.0, 195.0, 0.0, 136.0, 195.0, 0.0, 0.0, 0.0, 182.0, 169.0, 27.0, 120.0, 168.0, 0.0, 0.0, 0.0, 0.0, 0.0, 176.0, 114.0, 200.0, 0.0, 0.0, 0.0, 190.0, 180.0, 0.0, 134.0, 45.0, 0.0, 0.0, 0.0, 0.0, 0.0, 162.0, 169.0, 0.0, 0.0, 178.0, 154.0, 118.0, 139.0, 174.0, 181.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.0, 197.0, 0.0, 0.0, 42.0, 149.0, 0.0, 15.0, 20.0, 0.0, 0.0, 1.0, 160.0, 143.0, 0.0, 0.0, 0.0, 91.0, 0.0, 149.0, 114.0, 20.0, 164.0, 142.0, 0.0, 10.0, 43.0, 167.0, 25.0, 25.0, 15.0, 0.0, 20.0, 0.0, 82.0, 0.0, 129.0, 131.0, 0.0, 0.0, 159.0, 155.0, 29.0, 5.0, 4.0, 0.0, 163.0, 163.0, 0.0, 200.0, 14.0, 0.0, 0.0, 44.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 164.0, 0.0, 185.0, 57.0, 177.0, 139.0, 0.0, 173.0, 4.0, 0.0, 182.0, 0.0, 0.0, 123.0, 75.0, 197.0, 106.0, 93.0, 162.0, 162.0, 0.0, 0.0, 191.0, 184.0, 143.0, 0.0, 198.0, 0.0, 198.0, 174.0, 0.0, 1.0, 173.0, 108.0, 128.0, 0.0, 0.0, 116.0, 157.0, 0.0, 0.0, 134.0, 20.0, 198.0, 7.0, 0.0, 0.0, 0.0, 158.0, 181.0, 0.0, 0.0, 116.0, 130.0, 0.0, 1.0, 125.0, 155.0, 188.0, 0.0, 194.0, 160.0, 0.0, 150.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.0902054608418257, "mean_inference_ms": 7.6152045473803085, "mean_action_processing_ms": 0.6984752875107124, "mean_env_wait_ms": 0.9752533599960563, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009943127632141113, "StateBufferConnector_ms": 0.0064544677734375, "ViewRequirementAgentConnector_ms": 0.3014622926712036}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -504.5999999999999, "episode_return_mean": 58.98799999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000, "num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 170.48133515580145, "num_env_steps_trained_throughput_per_sec": 170.48133515580145, "timesteps_total": 772000, "num_env_steps_sampled_lifetime": 772000, "num_agent_steps_sampled_lifetime": 3088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3088000, "timers": {"training_iteration_time_ms": 24365.176, "restore_workers_time_ms": 0.02, "training_step_time_ms": 24364.978, "sample_time_ms": 3387.642, "learn_time_ms": 20944.874, "learn_throughput": 190.978, "synch_weights_time_ms": 26.645}, "counters": {"num_env_steps_sampled": 772000, "num_env_steps_trained": 772000, "num_agent_steps_sampled": 3088000, "num_agent_steps_trained": 3088000}, "done": false, "training_iteration": 193, "trial_id": "3a355_00000", "date": "2024-08-13_05-48-41", "timestamp": 1723542521, "time_this_iter_s": 23.55643320083618, "time_total_s": 16717.64792084694, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5fe3940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16717.64792084694, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 83.47878787878788, "ram_util_percent": 83.19090909090909}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2567702913213343, "cur_kl_coeff": 3.1529215447308393e-46, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.4133541589060785, "policy_loss": -0.0010552186890943813, "vf_loss": 4.4144093821288415, "vf_explained_var": 0.0026594111212977656, "kl": 0.002434772155439148, "entropy": 0.26769176206733813, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 365715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 41.42931769342019, "cur_kl_coeff": 1.4738661152281401e-27, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.261576966507725, "policy_loss": -0.0001844718953762105, "vf_loss": 5.261761439414252, "vf_explained_var": 0.4614367436479639, "kl": 0.004543529771935347, "entropy": 0.42750105764815416, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 365715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -504.5999999999999, "episode_reward_mean": 69.98199999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -30.68900000000001, "predator_policy": 65.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [35.200000000000024, 275.7999999999997, 219.99999999999926, -278.9999999999999, -450.8999999999997, 361.30000000000007, -358.6, -107.40000000000023, 52.59999999999953, 219.99999999999926, 400.0, -91.00000000000006, 301.9000000000009, 178.2, 154.2000000000001, 100.69999999999996, 38.700000000000266, 46.30000000000041, 319.90000000000003, 144.3999999999996, -316.4000000000003, 219.99999999999926, -81.90000000000033, 189.9999999999994, 348.0, 217.99999999999926, -22.399999999999736, 219.99999999999926, -60.09999999999995, -123.90000000000032, 114.59999999999991, 172.60000000000002, 348.5, -281.3000000000003, 37.50000000000026, 214.29999999999995, 360.0, -50.19999999999985, 123.60000000000001, 219.99999999999926, 20.1, 6.8000000000001215, 61.7000000000002, -253.50000000000006, 0.0, 372.0, 160.79999999999956, 205.99999999999932, 138.09999999999965, 376.0, -140.40000000000043, -106.50000000000057, 71.90000000000009, -51.299999999999955, 239.89999999999944, -504.5999999999999, 40.60000000000005, 63.89999999999999, 10.099999999999941, 23.800000000000068, 72.39999999999995, -257.0, 73.60000000000002, 2.2, 133.00000000000003, 217.99999999999926, 31.500000000000092, -36.0000000000005, -198.9000000000007, -132.7000000000004, 63.60000000000008, -50.39999999999998, 32.30000000000018, 400.0, 178.9, 219.99999999999926, 168.10000000000005, 151.39999999999958, 74.60000000000004, -240.30000000000067, 107.8, -101.6000000000002, 40.0000000000003, 181.09999999999945, 249.09999999999968, 372.2, -269.6999999999996, 124.69999999999962, 296.4999999999998, 23.100000000000083, 114.79999999999978, -446.9000000000002, 219.99999999999926, 10.899999999999947, 371.2, 385.0000000000002, 353.2, 156.3, -376.6, 134.1999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, -332.8, 75.79999999999934, 200.0, 20.000000000000014, 200.0, -349.5999999999997, -219.4, -400.0, -250.90000000000006, 161.3, 200.0, -358.0, -370.6, -261.4, 20.000000000000014, -74.50000000000088, 82.10000000000008, 200.0, 20.000000000000014, 200.0, 200.0, -68.20000000000002, -353.7999999999998, 156.8, 145.09999999999968, -353.8, 200.0, 125.0, -227.8, 116.29999999999998, -370.59999999999997, 20.000000000000014, 16.699999999999964, 26.30000000000012, 20.000000000000014, 179.3, 140.6, 20.000000000000014, 124.39999999999998, -246.70000000000002, -393.7, 200.0, 20.000000000000014, -292.9, 20.000000000000014, 155.0, 20.000000000000014, 140.0, 188.0, 20.000000000000014, 197.0, 20.000000000000014, -345.4000000000001, 20.000000000000014, 200.0, -171.10000000000002, 20.000000000000014, 20.000000000000014, -292.9, 200.0, -219.4, 170.0, -303.4, 138.50000000000006, 200.0, -160.59999999999994, -330.7, -32.50000000000003, 20.000000000000014, 79.39999999999998, 119.9, 200.0, 140.0, -152.2000000000002, 20.000000000000014, 190.1, -326.5000000000002, 20.000000000000014, 200.0, 20.000000000000014, -313.9, -47.19999999999976, 20.000000000000014, 37.70000000000003, 20.000000000000014, -292.9, -286.60000000000014, -400.0, 200.0, 158.0, 200.0, -47.200000000000024, 164.0, 179.0, 20.000000000000014, 20.000000000000014, 118.09999999999998, 200.0, 164.0, -324.4, 20.000000000000014, -368.5, 20.000000000000014, 113.89999999999998, -358.0000000000001, 118.99999999999999, -343.3, 35.90000000000012, 200.0, -324.4, -362.19999999999993, -238.30000000000032, 155.9, 185.6, -393.70000000000005, 20.000000000000014, -208.9, -320.2, 20.000000000000014, 52.39999999999999, 20.000000000000014, -250.9, -381.1, -269.4, 200.0, -395.8, 200.0, -395.8, 156.8, 20.000000000000014, 197.0, -343.3, 93.79999999999998, -184.0, 20.000000000000014, -192.1000000000002, -122.80000000000047, -309.69999999999993, 20.000000000000014, -240.4, 170.0, -395.8, 127.40000000000002, 20.000000000000014, 5.299999999999965, 200.0, 200.0, 200.0, -360.1, 20.000000000000014, 200.0, 194.0, -271.9, 130.39999999999998, 20.000000000000014, 118.99999999999999, -324.4, -53.49999999999983, -374.8, -362.2, 116.0, -295.0, 43.40000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 151.10000000000002, 173.0, 67.09999999999998, 168.2, 200.0, -330.7, -106.00000000000013, 139.69999999999962, -400.0, 96.49999999999997, 200.0, -61.90000000000004, 20.000000000000014, 194.0, -173.20000000000002, -341.2, -288.70000000000016, 200.0, 20.000000000000014, -192.10000000000002, 20.000000000000014, 191.9, 179.3, 190.99999999999994, 191.0, 173.0, 180.2, -288.69999999999993, 170.0, -374.8, -374.8, 200.0, -143.8], "policy_predator_policy_reward": [168.0, 0.0, 0.0, 0.0, 0.0, 0.0, 176.0, 114.0, 200.0, 0.0, 0.0, 0.0, 190.0, 180.0, 0.0, 134.0, 45.0, 0.0, 0.0, 0.0, 0.0, 0.0, 162.0, 169.0, 0.0, 0.0, 178.0, 154.0, 118.0, 139.0, 174.0, 181.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 127.0, 197.0, 0.0, 0.0, 42.0, 149.0, 0.0, 15.0, 20.0, 0.0, 0.0, 1.0, 160.0, 143.0, 0.0, 0.0, 0.0, 91.0, 0.0, 149.0, 114.0, 20.0, 164.0, 142.0, 0.0, 10.0, 43.0, 167.0, 25.0, 25.0, 15.0, 0.0, 20.0, 0.0, 82.0, 0.0, 129.0, 131.0, 0.0, 0.0, 159.0, 155.0, 29.0, 5.0, 4.0, 0.0, 163.0, 163.0, 0.0, 200.0, 14.0, 0.0, 0.0, 44.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 164.0, 0.0, 185.0, 57.0, 177.0, 139.0, 0.0, 173.0, 4.0, 0.0, 182.0, 0.0, 0.0, 123.0, 75.0, 197.0, 106.0, 93.0, 162.0, 162.0, 0.0, 0.0, 191.0, 184.0, 143.0, 0.0, 198.0, 0.0, 198.0, 174.0, 0.0, 1.0, 173.0, 108.0, 128.0, 0.0, 0.0, 116.0, 157.0, 0.0, 0.0, 134.0, 20.0, 198.0, 7.0, 0.0, 0.0, 0.0, 158.0, 181.0, 0.0, 0.0, 116.0, 130.0, 0.0, 1.0, 125.0, 155.0, 188.0, 0.0, 194.0, 160.0, 0.0, 150.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 4.0, 0.0, 167.0, 0.0, 200.0, 185.0, 0.0, 0.0, 32.0, 33.0, 0.0, 94.0, 0.0, 183.0, 0.0, 0.0, 82.0, 101.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 121.0, 154.0, 185.0, 188.0, 78.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.0886242587016928, "mean_inference_ms": 7.603061915629876, "mean_action_processing_ms": 0.6986788445018774, "mean_env_wait_ms": 0.9734012875030976, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.023176193237304688, "StateBufferConnector_ms": 0.006473064422607422, "ViewRequirementAgentConnector_ms": 0.32150983810424805}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -504.5999999999999, "episode_return_mean": 69.98199999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000, "num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 159.74396961900578, "num_env_steps_trained_throughput_per_sec": 159.74396961900578, "timesteps_total": 776000, "num_env_steps_sampled_lifetime": 776000, "num_agent_steps_sampled_lifetime": 3104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3104000, "timers": {"training_iteration_time_ms": 24534.667, "restore_workers_time_ms": 0.019, "training_step_time_ms": 24534.481, "sample_time_ms": 3516.328, "learn_time_ms": 20984.755, "learn_throughput": 190.615, "synch_weights_time_ms": 27.01}, "counters": {"num_env_steps_sampled": 776000, "num_env_steps_trained": 776000, "num_agent_steps_sampled": 3104000, "num_agent_steps_trained": 3104000}, "done": false, "training_iteration": 194, "trial_id": "3a355_00000", "date": "2024-08-13_05-49-06", "timestamp": 1723542546, "time_this_iter_s": 25.096585988998413, "time_total_s": 16742.744506835938, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b6011040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16742.744506835938, "iterations_since_restore": 194, "perf": {"cpu_util_percent": 84.46666666666665, "ram_util_percent": 82.98888888888888}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0890376254955612, "cur_kl_coeff": 1.5764607723654196e-46, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.821497006517239, "policy_loss": -0.002061962411325011, "vf_loss": 4.823558986250055, "vf_explained_var": 0.0007356192699815861, "kl": 0.003349066625323424, "entropy": 0.1932610546391477, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 367605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 40.64432074154811, "cur_kl_coeff": 7.369330576140701e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.369436857813881, "policy_loss": -0.0004378717979071317, "vf_loss": 5.369874735988637, "vf_explained_var": 0.3696411229945995, "kl": 0.0026289004376615897, "entropy": 0.47541892564801314, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 367605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -504.5999999999999, "episode_reward_mean": 63.66399999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -36.93800000000001, "predator_policy": 68.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [319.90000000000003, 144.3999999999996, -316.4000000000003, 219.99999999999926, -81.90000000000033, 189.9999999999994, 348.0, 217.99999999999926, -22.399999999999736, 219.99999999999926, -60.09999999999995, -123.90000000000032, 114.59999999999991, 172.60000000000002, 348.5, -281.3000000000003, 37.50000000000026, 214.29999999999995, 360.0, -50.19999999999985, 123.60000000000001, 219.99999999999926, 20.1, 6.8000000000001215, 61.7000000000002, -253.50000000000006, 0.0, 372.0, 160.79999999999956, 205.99999999999932, 138.09999999999965, 376.0, -140.40000000000043, -106.50000000000057, 71.90000000000009, -51.299999999999955, 239.89999999999944, -504.5999999999999, 40.60000000000005, 63.89999999999999, 10.099999999999941, 23.800000000000068, 72.39999999999995, -257.0, 73.60000000000002, 2.2, 133.00000000000003, 217.99999999999926, 31.500000000000092, -36.0000000000005, -198.9000000000007, -132.7000000000004, 63.60000000000008, -50.39999999999998, 32.30000000000018, 400.0, 178.9, 219.99999999999926, 168.10000000000005, 151.39999999999958, 74.60000000000004, -240.30000000000067, 107.8, -101.6000000000002, 40.0000000000003, 181.09999999999945, 249.09999999999968, 372.2, -269.6999999999996, 124.69999999999962, 296.4999999999998, 23.100000000000083, 114.79999999999978, -446.9000000000002, 219.99999999999926, 10.899999999999947, 371.2, 385.0000000000002, 353.2, 156.3, -376.6, 134.1999999999997, 271.6000000000003, 26.40000000000002, -363.0, -83.00000000000003, 199.99999999999935, 166.1, 10.30000000000025, 40.0000000000003, 352.8, -414.19999999999993, 14.799999999999999, 196.8, -6.899999999999878, 18.399999999999785, 6.6, 256.8999999999995, -322.79999999999995, 95.40000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [179.3, 140.6, 20.000000000000014, 124.39999999999998, -246.70000000000002, -393.7, 200.0, 20.000000000000014, -292.9, 20.000000000000014, 155.0, 20.000000000000014, 140.0, 188.0, 20.000000000000014, 197.0, 20.000000000000014, -345.4000000000001, 20.000000000000014, 200.0, -171.10000000000002, 20.000000000000014, 20.000000000000014, -292.9, 200.0, -219.4, 170.0, -303.4, 138.50000000000006, 200.0, -160.59999999999994, -330.7, -32.50000000000003, 20.000000000000014, 79.39999999999998, 119.9, 200.0, 140.0, -152.2000000000002, 20.000000000000014, 190.1, -326.5000000000002, 20.000000000000014, 200.0, 20.000000000000014, -313.9, -47.19999999999976, 20.000000000000014, 37.70000000000003, 20.000000000000014, -292.9, -286.60000000000014, -400.0, 200.0, 158.0, 200.0, -47.200000000000024, 164.0, 179.0, 20.000000000000014, 20.000000000000014, 118.09999999999998, 200.0, 164.0, -324.4, 20.000000000000014, -368.5, 20.000000000000014, 113.89999999999998, -358.0000000000001, 118.99999999999999, -343.3, 35.90000000000012, 200.0, -324.4, -362.19999999999993, -238.30000000000032, 155.9, 185.6, -393.70000000000005, 20.000000000000014, -208.9, -320.2, 20.000000000000014, 52.39999999999999, 20.000000000000014, -250.9, -381.1, -269.4, 200.0, -395.8, 200.0, -395.8, 156.8, 20.000000000000014, 197.0, -343.3, 93.79999999999998, -184.0, 20.000000000000014, -192.1000000000002, -122.80000000000047, -309.69999999999993, 20.000000000000014, -240.4, 170.0, -395.8, 127.40000000000002, 20.000000000000014, 5.299999999999965, 200.0, 200.0, 200.0, -360.1, 20.000000000000014, 200.0, 194.0, -271.9, 130.39999999999998, 20.000000000000014, 118.99999999999999, -324.4, -53.49999999999983, -374.8, -362.2, 116.0, -295.0, 43.40000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 151.10000000000002, 173.0, 67.09999999999998, 168.2, 200.0, -330.7, -106.00000000000013, 139.69999999999962, -400.0, 96.49999999999997, 200.0, -61.90000000000004, 20.000000000000014, 194.0, -173.20000000000002, -341.2, -288.70000000000016, 200.0, 20.000000000000014, -192.10000000000002, 20.000000000000014, 191.9, 179.3, 190.99999999999994, 191.0, 173.0, 180.2, -288.69999999999993, 170.0, -374.8, -374.8, 200.0, -143.8, 155.0, 113.59999999999985, -397.9, 146.29999999999993, -358.0, -358.0, -309.7, 61.70000000000018, 20.000000000000014, 170.0, 143.0, -292.9, 20.000000000000014, -36.700000000000024, 20.000000000000014, 20.000000000000014, 144.8, 188.0, -236.20000000000002, -358.0, -339.1, 182.9, 200.0, -362.2, 20.000000000000014, -397.9, -169.0000000000001, 97.39999999999935, 200.0, -387.4, 56.89999999999996, 200.0, -290.8, -358.00000000000006, 164.0, -307.6], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 127.0, 197.0, 0.0, 0.0, 42.0, 149.0, 0.0, 15.0, 20.0, 0.0, 0.0, 1.0, 160.0, 143.0, 0.0, 0.0, 0.0, 91.0, 0.0, 149.0, 114.0, 20.0, 164.0, 142.0, 0.0, 10.0, 43.0, 167.0, 25.0, 25.0, 15.0, 0.0, 20.0, 0.0, 82.0, 0.0, 129.0, 131.0, 0.0, 0.0, 159.0, 155.0, 29.0, 5.0, 4.0, 0.0, 163.0, 163.0, 0.0, 200.0, 14.0, 0.0, 0.0, 44.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 164.0, 0.0, 185.0, 57.0, 177.0, 139.0, 0.0, 173.0, 4.0, 0.0, 182.0, 0.0, 0.0, 123.0, 75.0, 197.0, 106.0, 93.0, 162.0, 162.0, 0.0, 0.0, 191.0, 184.0, 143.0, 0.0, 198.0, 0.0, 198.0, 174.0, 0.0, 1.0, 173.0, 108.0, 128.0, 0.0, 0.0, 116.0, 157.0, 0.0, 0.0, 134.0, 20.0, 198.0, 7.0, 0.0, 0.0, 0.0, 158.0, 181.0, 0.0, 0.0, 116.0, 130.0, 0.0, 1.0, 125.0, 155.0, 188.0, 0.0, 194.0, 160.0, 0.0, 150.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 4.0, 0.0, 167.0, 0.0, 200.0, 185.0, 0.0, 0.0, 32.0, 33.0, 0.0, 94.0, 0.0, 183.0, 0.0, 0.0, 82.0, 101.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 121.0, 154.0, 185.0, 188.0, 78.0, 0.0, 3.0, 0.0, 200.0, 78.0, 166.0, 187.0, 157.0, 8.0, 0.0, 10.0, 151.0, 165.0, 27.0, 0.0, 0.0, 0.0, 20.0, 0.0, 180.0, 0.0, 0.0, 171.0, 178.0, 181.0, 199.0, 172.0, 90.0, 0.0, 194.0, 0.0, 0.0, 0.0, 184.0, 142.0, 73.0, 166.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.0884376770325073, "mean_inference_ms": 7.593728612075811, "mean_action_processing_ms": 0.6994874222947888, "mean_env_wait_ms": 0.9719707706406321, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.023174643516540527, "StateBufferConnector_ms": 0.007913827896118164, "ViewRequirementAgentConnector_ms": 0.3291904926300049}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -504.5999999999999, "episode_return_mean": 63.66399999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000, "num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 156.77634091291753, "num_env_steps_trained_throughput_per_sec": 156.77634091291753, "timesteps_total": 780000, "num_env_steps_sampled_lifetime": 780000, "num_agent_steps_sampled_lifetime": 3120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3120000, "timers": {"training_iteration_time_ms": 24681.097, "restore_workers_time_ms": 0.019, "training_step_time_ms": 24680.911, "sample_time_ms": 3812.72, "learn_time_ms": 20833.804, "learn_throughput": 191.996, "synch_weights_time_ms": 27.523}, "counters": {"num_env_steps_sampled": 780000, "num_env_steps_trained": 780000, "num_agent_steps_sampled": 3120000, "num_agent_steps_trained": 3120000}, "done": false, "training_iteration": 195, "trial_id": "3a355_00000", "date": "2024-08-13_05-49-32", "timestamp": 1723542572, "time_this_iter_s": 25.56208300590515, "time_total_s": 16768.306589841843, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5f61af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16768.306589841843, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 83.55555555555557, "ram_util_percent": 83.26666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.150420823003407, "cur_kl_coeff": 7.882303861827098e-47, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.708354810179857, "policy_loss": -0.0008125985414528895, "vf_loss": 3.709167407933997, "vf_explained_var": 0.001080783586653452, "kl": 0.0015415831166734333, "entropy": 0.17741179489505984, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 369495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 34.450432117780046, "cur_kl_coeff": 3.6846652880703503e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5087395440964473, "policy_loss": -0.0009484875607230361, "vf_loss": 3.5096880303488835, "vf_explained_var": 0.43318788081249865, "kl": 0.0009694050348260303, "entropy": 0.3183299710747426, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 369495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -504.5999999999999, "episode_reward_mean": 85.06199999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -24.704000000000015, "predator_policy": 67.235}, "custom_metrics": {}, "hist_stats": {"episode_reward": [372.0, 160.79999999999956, 205.99999999999932, 138.09999999999965, 376.0, -140.40000000000043, -106.50000000000057, 71.90000000000009, -51.299999999999955, 239.89999999999944, -504.5999999999999, 40.60000000000005, 63.89999999999999, 10.099999999999941, 23.800000000000068, 72.39999999999995, -257.0, 73.60000000000002, 2.2, 133.00000000000003, 217.99999999999926, 31.500000000000092, -36.0000000000005, -198.9000000000007, -132.7000000000004, 63.60000000000008, -50.39999999999998, 32.30000000000018, 400.0, 178.9, 219.99999999999926, 168.10000000000005, 151.39999999999958, 74.60000000000004, -240.30000000000067, 107.8, -101.6000000000002, 40.0000000000003, 181.09999999999945, 249.09999999999968, 372.2, -269.6999999999996, 124.69999999999962, 296.4999999999998, 23.100000000000083, 114.79999999999978, -446.9000000000002, 219.99999999999926, 10.899999999999947, 371.2, 385.0000000000002, 353.2, 156.3, -376.6, 134.1999999999997, 271.6000000000003, 26.40000000000002, -363.0, -83.00000000000003, 199.99999999999935, 166.1, 10.30000000000025, 40.0000000000003, 352.8, -414.19999999999993, 14.799999999999999, 196.8, -6.899999999999878, 18.399999999999785, 6.6, 256.8999999999995, -322.79999999999995, 95.40000000000002, 293.7999999999997, 9.299999999999963, 38.50000000000002, -15.599999999999937, 115.69999999999985, 378.0, 346.00000000000006, 199.90000000000003, 360.0, 89.19999999999943, 213.9999999999993, 365.5, 13.299999999999956, 357.70000000000005, -379.0, -156.90000000000052, 336.5, 3.500000000000063, 185.29999999999941, 124.29999999999976, 198.79999999999936, 199.99999999999935, 26.000000000000203, 213.1999999999993, 195.6999999999994, 185.49999999999943, 391.9], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [158.0, 200.0, -47.200000000000024, 164.0, 179.0, 20.000000000000014, 20.000000000000014, 118.09999999999998, 200.0, 164.0, -324.4, 20.000000000000014, -368.5, 20.000000000000014, 113.89999999999998, -358.0000000000001, 118.99999999999999, -343.3, 35.90000000000012, 200.0, -324.4, -362.19999999999993, -238.30000000000032, 155.9, 185.6, -393.70000000000005, 20.000000000000014, -208.9, -320.2, 20.000000000000014, 52.39999999999999, 20.000000000000014, -250.9, -381.1, -269.4, 200.0, -395.8, 200.0, -395.8, 156.8, 20.000000000000014, 197.0, -343.3, 93.79999999999998, -184.0, 20.000000000000014, -192.1000000000002, -122.80000000000047, -309.69999999999993, 20.000000000000014, -240.4, 170.0, -395.8, 127.40000000000002, 20.000000000000014, 5.299999999999965, 200.0, 200.0, 200.0, -360.1, 20.000000000000014, 200.0, 194.0, -271.9, 130.39999999999998, 20.000000000000014, 118.99999999999999, -324.4, -53.49999999999983, -374.8, -362.2, 116.0, -295.0, 43.40000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 151.10000000000002, 173.0, 67.09999999999998, 168.2, 200.0, -330.7, -106.00000000000013, 139.69999999999962, -400.0, 96.49999999999997, 200.0, -61.90000000000004, 20.000000000000014, 194.0, -173.20000000000002, -341.2, -288.70000000000016, 200.0, 20.000000000000014, -192.10000000000002, 20.000000000000014, 191.9, 179.3, 190.99999999999994, 191.0, 173.0, 180.2, -288.69999999999993, 170.0, -374.8, -374.8, 200.0, -143.8, 155.0, 113.59999999999985, -397.9, 146.29999999999993, -358.0, -358.0, -309.7, 61.70000000000018, 20.000000000000014, 170.0, 143.0, -292.9, 20.000000000000014, -36.700000000000024, 20.000000000000014, 20.000000000000014, 144.8, 188.0, -236.20000000000002, -358.0, -339.1, 182.9, 200.0, -362.2, 20.000000000000014, -397.9, -169.0000000000001, 97.39999999999935, 200.0, -387.4, 56.89999999999996, 200.0, -290.8, -358.00000000000006, 164.0, -307.6, 93.79999999999998, 200.0, 15.799999999999963, -368.5, -326.5, 200.0, 131.6, -299.20000000000016, -177.40000000000003, 190.1, 167.0, 200.0, 193.7, 152.3, 200.0, -297.1, 170.0, 170.0, 109.99999999999943, -395.8, 20.000000000000014, 185.0, 155.0, 186.5, 20.000000000000014, -309.7, 157.7, 200.0, -373.0, -379.0, 20.000000000000014, -355.9, 158.0, 153.50000000000003, 155.3, -311.79999999999995, 173.0, 5.299999999999967, -162.70000000000002, 200.0, 188.0, -5.199999999999951, 170.0, 20.000000000000014, -34.60000000000002, 11.599999999999964, 200.0, 3.199999999999969, 20.000000000000014, 175.7, 15.799999999999963, 154.70000000000002, 200.0, 191.9], "policy_predator_policy_reward": [14.0, 0.0, 0.0, 44.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 164.0, 0.0, 185.0, 57.0, 177.0, 139.0, 0.0, 173.0, 4.0, 0.0, 182.0, 0.0, 0.0, 123.0, 75.0, 197.0, 106.0, 93.0, 162.0, 162.0, 0.0, 0.0, 191.0, 184.0, 143.0, 0.0, 198.0, 0.0, 198.0, 174.0, 0.0, 1.0, 173.0, 108.0, 128.0, 0.0, 0.0, 116.0, 157.0, 0.0, 0.0, 134.0, 20.0, 198.0, 7.0, 0.0, 0.0, 0.0, 158.0, 181.0, 0.0, 0.0, 116.0, 130.0, 0.0, 1.0, 125.0, 155.0, 188.0, 0.0, 194.0, 160.0, 0.0, 150.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 4.0, 0.0, 167.0, 0.0, 200.0, 185.0, 0.0, 0.0, 32.0, 33.0, 0.0, 94.0, 0.0, 183.0, 0.0, 0.0, 82.0, 101.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 121.0, 154.0, 185.0, 188.0, 78.0, 0.0, 3.0, 0.0, 200.0, 78.0, 166.0, 187.0, 157.0, 8.0, 0.0, 10.0, 151.0, 165.0, 27.0, 0.0, 0.0, 0.0, 20.0, 0.0, 180.0, 0.0, 0.0, 171.0, 178.0, 181.0, 199.0, 172.0, 90.0, 0.0, 194.0, 0.0, 0.0, 0.0, 184.0, 142.0, 73.0, 166.0, 0.0, 0.0, 175.0, 187.0, 0.0, 165.0, 152.0, 0.0, 14.0, 89.0, 11.0, 0.0, 0.0, 0.0, 146.0, 151.0, 10.0, 10.0, 187.0, 188.0, 4.0, 5.0, 13.0, 11.0, 157.0, 146.0, 0.0, 0.0, 182.0, 191.0, 0.0, 179.0, 4.0, 21.0, 127.0, 33.0, 0.0, 7.0, 0.0, 87.0, 0.0, 16.0, 10.0, 0.0, 30.0, 19.0, 2.0, 8.0, 0.0, 0.0, 13.0, 2.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1268225864839474, "mean_inference_ms": 7.546286258535909, "mean_action_processing_ms": 0.7025734951992331, "mean_env_wait_ms": 0.9723453690980435, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.024077534675598145, "StateBufferConnector_ms": 0.007391810417175293, "ViewRequirementAgentConnector_ms": 0.3799409866333008}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": -504.5999999999999, "episode_return_mean": 85.06199999999984, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000, "num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 157.75042237444436, "num_env_steps_trained_throughput_per_sec": 157.75042237444436, "timesteps_total": 784000, "num_env_steps_sampled_lifetime": 784000, "num_agent_steps_sampled_lifetime": 3136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3136000, "timers": {"training_iteration_time_ms": 24918.067, "restore_workers_time_ms": 0.019, "training_step_time_ms": 24917.886, "sample_time_ms": 3987.425, "learn_time_ms": 20894.775, "learn_throughput": 191.435, "synch_weights_time_ms": 27.716}, "counters": {"num_env_steps_sampled": 784000, "num_env_steps_trained": 784000, "num_agent_steps_sampled": 3136000, "num_agent_steps_trained": 3136000}, "done": false, "training_iteration": 196, "trial_id": "3a355_00000", "date": "2024-08-13_05-49-57", "timestamp": 1723542597, "time_this_iter_s": 25.409348726272583, "time_total_s": 16793.715938568115, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b73f91f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16793.715938568115, "iterations_since_restore": 196, "perf": {"cpu_util_percent": 84.93333333333334, "ram_util_percent": 83.0111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2274357446681254, "cur_kl_coeff": 3.941151930913549e-47, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.221638982510441, "policy_loss": -0.0013626560189381794, "vf_loss": 5.2230016361468685, "vf_explained_var": 0.00019119883340502542, "kl": 0.0031244842667960625, "entropy": 0.24047360447033372, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 371385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 41.78374469207708, "cur_kl_coeff": 1.8423326440351752e-28, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.888778420857021, "policy_loss": -0.0003771091954260276, "vf_loss": 5.889155508979918, "vf_explained_var": 0.3873490740382482, "kl": 0.0035043643191854904, "entropy": 0.4783906030749518, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 371385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -462.3, "episode_reward_mean": 80.89599999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -27.877000000000017, "predator_policy": 68.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.2, 133.00000000000003, 217.99999999999926, 31.500000000000092, -36.0000000000005, -198.9000000000007, -132.7000000000004, 63.60000000000008, -50.39999999999998, 32.30000000000018, 400.0, 178.9, 219.99999999999926, 168.10000000000005, 151.39999999999958, 74.60000000000004, -240.30000000000067, 107.8, -101.6000000000002, 40.0000000000003, 181.09999999999945, 249.09999999999968, 372.2, -269.6999999999996, 124.69999999999962, 296.4999999999998, 23.100000000000083, 114.79999999999978, -446.9000000000002, 219.99999999999926, 10.899999999999947, 371.2, 385.0000000000002, 353.2, 156.3, -376.6, 134.1999999999997, 271.6000000000003, 26.40000000000002, -363.0, -83.00000000000003, 199.99999999999935, 166.1, 10.30000000000025, 40.0000000000003, 352.8, -414.19999999999993, 14.799999999999999, 196.8, -6.899999999999878, 18.399999999999785, 6.6, 256.8999999999995, -322.79999999999995, 95.40000000000002, 293.7999999999997, 9.299999999999963, 38.50000000000002, -15.599999999999937, 115.69999999999985, 378.0, 346.00000000000006, 199.90000000000003, 360.0, 89.19999999999943, 213.9999999999993, 365.5, 13.299999999999956, 357.70000000000005, -379.0, -156.90000000000052, 336.5, 3.500000000000063, 185.29999999999941, 124.29999999999976, 198.79999999999936, 199.99999999999935, 26.000000000000203, 213.1999999999993, 195.6999999999994, 185.49999999999943, 391.9, -121.5000000000005, 381.8, 15.300000000000104, -104.90000000000055, 242.90000000000003, 6.0, -162.90000000000057, -337.6, 334.29999999999995, 74.90000000000013, -462.3, -7.600000000000003, 38.50000000000002, 146.0, 177.4, 288.2000000000007, -184.20000000000002, 48.40000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-395.8, 200.0, -395.8, 156.8, 20.000000000000014, 197.0, -343.3, 93.79999999999998, -184.0, 20.000000000000014, -192.1000000000002, -122.80000000000047, -309.69999999999993, 20.000000000000014, -240.4, 170.0, -395.8, 127.40000000000002, 20.000000000000014, 5.299999999999965, 200.0, 200.0, 200.0, -360.1, 20.000000000000014, 200.0, 194.0, -271.9, 130.39999999999998, 20.000000000000014, 118.99999999999999, -324.4, -53.49999999999983, -374.8, -362.2, 116.0, -295.0, 43.40000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 151.10000000000002, 173.0, 67.09999999999998, 168.2, 200.0, -330.7, -106.00000000000013, 139.69999999999962, -400.0, 96.49999999999997, 200.0, -61.90000000000004, 20.000000000000014, 194.0, -173.20000000000002, -341.2, -288.70000000000016, 200.0, 20.000000000000014, -192.10000000000002, 20.000000000000014, 191.9, 179.3, 190.99999999999994, 191.0, 173.0, 180.2, -288.69999999999993, 170.0, -374.8, -374.8, 200.0, -143.8, 155.0, 113.59999999999985, -397.9, 146.29999999999993, -358.0, -358.0, -309.7, 61.70000000000018, 20.000000000000014, 170.0, 143.0, -292.9, 20.000000000000014, -36.700000000000024, 20.000000000000014, 20.000000000000014, 144.8, 188.0, -236.20000000000002, -358.0, -339.1, 182.9, 200.0, -362.2, 20.000000000000014, -397.9, -169.0000000000001, 97.39999999999935, 200.0, -387.4, 56.89999999999996, 200.0, -290.8, -358.00000000000006, 164.0, -307.6, 93.79999999999998, 200.0, 15.799999999999963, -368.5, -326.5, 200.0, 131.6, -299.20000000000016, -177.40000000000003, 190.1, 167.0, 200.0, 193.7, 152.3, 200.0, -297.1, 170.0, 170.0, 109.99999999999943, -395.8, 20.000000000000014, 185.0, 155.0, 186.5, 20.000000000000014, -309.7, 157.7, 200.0, -373.0, -379.0, 20.000000000000014, -355.9, 158.0, 153.50000000000003, 155.3, -311.79999999999995, 173.0, 5.299999999999967, -162.70000000000002, 200.0, 188.0, -5.199999999999951, 170.0, 20.000000000000014, -34.60000000000002, 11.599999999999964, 200.0, 3.199999999999969, 20.000000000000014, 175.7, 15.799999999999963, 154.70000000000002, 200.0, 191.9, -347.5, 20.000000000000014, 200.0, 180.8, -120.70000000000003, 20.000000000000014, 20.000000000000014, -271.89999999999947, 128.90000000000003, 92.0, 191.0, -400.0, -376.9, 20.000000000000014, -227.8, -227.8, 200.0, 134.29999999999998, 84.50000000000003, -349.6, -288.7, -349.59999999999997, 170.0, -370.6, -326.5, 200.0, -360.1, 166.1, -4.900000000000006, 137.3, 170.0, 108.19999999999982, -370.6, -181.60000000000002, 200.0, -307.6], "policy_predator_policy_reward": [198.0, 0.0, 198.0, 174.0, 0.0, 1.0, 173.0, 108.0, 128.0, 0.0, 0.0, 116.0, 157.0, 0.0, 0.0, 134.0, 20.0, 198.0, 7.0, 0.0, 0.0, 0.0, 158.0, 181.0, 0.0, 0.0, 116.0, 130.0, 0.0, 1.0, 125.0, 155.0, 188.0, 0.0, 194.0, 160.0, 0.0, 150.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 4.0, 0.0, 167.0, 0.0, 200.0, 185.0, 0.0, 0.0, 32.0, 33.0, 0.0, 94.0, 0.0, 183.0, 0.0, 0.0, 82.0, 101.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 121.0, 154.0, 185.0, 188.0, 78.0, 0.0, 3.0, 0.0, 200.0, 78.0, 166.0, 187.0, 157.0, 8.0, 0.0, 10.0, 151.0, 165.0, 27.0, 0.0, 0.0, 0.0, 20.0, 0.0, 180.0, 0.0, 0.0, 171.0, 178.0, 181.0, 199.0, 172.0, 90.0, 0.0, 194.0, 0.0, 0.0, 0.0, 184.0, 142.0, 73.0, 166.0, 0.0, 0.0, 175.0, 187.0, 0.0, 165.0, 152.0, 0.0, 14.0, 89.0, 11.0, 0.0, 0.0, 0.0, 146.0, 151.0, 10.0, 10.0, 187.0, 188.0, 4.0, 5.0, 13.0, 11.0, 157.0, 146.0, 0.0, 0.0, 182.0, 191.0, 0.0, 179.0, 4.0, 21.0, 127.0, 33.0, 0.0, 7.0, 0.0, 87.0, 0.0, 16.0, 10.0, 0.0, 30.0, 19.0, 2.0, 8.0, 0.0, 0.0, 13.0, 2.0, 0.0, 0.0, 175.0, 31.0, 1.0, 0.0, 49.0, 67.0, 139.0, 8.0, 13.0, 9.0, 15.0, 200.0, 7.0, 187.0, 118.0, 0.0, 0.0, 0.0, 182.0, 158.0, 176.0, 0.0, 0.0, 193.0, 0.0, 165.0, 159.0, 181.0, 45.0, 0.0, 10.0, 0.0, 182.0, 186.0, 0.0, 156.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.090172125298801, "mean_inference_ms": 7.574641481070098, "mean_action_processing_ms": 0.7021641794513781, "mean_env_wait_ms": 0.9688741470726353, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.024232029914855957, "StateBufferConnector_ms": 0.007437944412231445, "ViewRequirementAgentConnector_ms": 0.332442045211792}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -462.3, "episode_return_mean": 80.89599999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000, "num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 154.4526599439949, "num_env_steps_trained_throughput_per_sec": 154.4526599439949, "timesteps_total": 788000, "num_env_steps_sampled_lifetime": 788000, "num_agent_steps_sampled_lifetime": 3152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3152000, "timers": {"training_iteration_time_ms": 25059.54, "restore_workers_time_ms": 0.019, "training_step_time_ms": 25059.359, "sample_time_ms": 4084.266, "learn_time_ms": 20932.375, "learn_throughput": 191.092, "synch_weights_time_ms": 35.04}, "counters": {"num_env_steps_sampled": 788000, "num_env_steps_trained": 788000, "num_agent_steps_sampled": 3152000, "num_agent_steps_trained": 3152000}, "done": false, "training_iteration": 197, "trial_id": "3a355_00000", "date": "2024-08-13_05-50-24", "timestamp": 1723542624, "time_this_iter_s": 26.010172128677368, "time_total_s": 16819.726110696793, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b74a5550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16819.726110696793, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 84.91666666666669, "ram_util_percent": 83.11666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0547481717847327, "cur_kl_coeff": 1.9705759654567745e-47, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.641459983492655, "policy_loss": -0.00028747602060397783, "vf_loss": 5.641747474418115, "vf_explained_var": 0.001394516008871573, "kl": 0.0015141083912348773, "entropy": 0.1945784969619973, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 373275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 41.20318116222425, "cur_kl_coeff": 9.211663220175876e-29, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.511183534349714, "policy_loss": -0.000429775799555635, "vf_loss": 5.51161330540975, "vf_explained_var": 0.3899453676566876, "kl": 0.002951559094703329, "entropy": 0.46986422731132105, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 373275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000}, "env_runners": {"episode_reward_max": 391.9, "episode_reward_min": -462.3, "episode_reward_mean": 76.0609999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -29.504500000000018, "predator_policy": 67.535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-101.6000000000002, 40.0000000000003, 181.09999999999945, 249.09999999999968, 372.2, -269.6999999999996, 124.69999999999962, 296.4999999999998, 23.100000000000083, 114.79999999999978, -446.9000000000002, 219.99999999999926, 10.899999999999947, 371.2, 385.0000000000002, 353.2, 156.3, -376.6, 134.1999999999997, 271.6000000000003, 26.40000000000002, -363.0, -83.00000000000003, 199.99999999999935, 166.1, 10.30000000000025, 40.0000000000003, 352.8, -414.19999999999993, 14.799999999999999, 196.8, -6.899999999999878, 18.399999999999785, 6.6, 256.8999999999995, -322.79999999999995, 95.40000000000002, 293.7999999999997, 9.299999999999963, 38.50000000000002, -15.599999999999937, 115.69999999999985, 378.0, 346.00000000000006, 199.90000000000003, 360.0, 89.19999999999943, 213.9999999999993, 365.5, 13.299999999999956, 357.70000000000005, -379.0, -156.90000000000052, 336.5, 3.500000000000063, 185.29999999999941, 124.29999999999976, 198.79999999999936, 199.99999999999935, 26.000000000000203, 213.1999999999993, 195.6999999999994, 185.49999999999943, 391.9, -121.5000000000005, 381.8, 15.300000000000104, -104.90000000000055, 242.90000000000003, 6.0, -162.90000000000057, -337.6, 334.29999999999995, 74.90000000000013, -462.3, -7.600000000000003, 38.50000000000002, 146.0, 177.4, 288.2000000000007, -184.20000000000002, 48.40000000000004, -64.49999999999974, 204.6, -266.4999999999999, -359.3, -141.50000000000043, 168.5999999999998, -17.39999999999995, 5.699999999999955, 67.00000000000024, 219.99999999999926, 144.19999999999985, 160.79999999999998, -427.1000000000002, 164.4, 210.9999999999993, 236.2999999999994, 8.599999999999966, 324.69999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-295.0, 43.40000000000005, 20.000000000000014, 20.000000000000014, 20.000000000000014, 151.10000000000002, 173.0, 67.09999999999998, 168.2, 200.0, -330.7, -106.00000000000013, 139.69999999999962, -400.0, 96.49999999999997, 200.0, -61.90000000000004, 20.000000000000014, 194.0, -173.20000000000002, -341.2, -288.70000000000016, 200.0, 20.000000000000014, -192.10000000000002, 20.000000000000014, 191.9, 179.3, 190.99999999999994, 191.0, 173.0, 180.2, -288.69999999999993, 170.0, -374.8, -374.8, 200.0, -143.8, 155.0, 113.59999999999985, -397.9, 146.29999999999993, -358.0, -358.0, -309.7, 61.70000000000018, 20.000000000000014, 170.0, 143.0, -292.9, 20.000000000000014, -36.700000000000024, 20.000000000000014, 20.000000000000014, 144.8, 188.0, -236.20000000000002, -358.0, -339.1, 182.9, 200.0, -362.2, 20.000000000000014, -397.9, -169.0000000000001, 97.39999999999935, 200.0, -387.4, 56.89999999999996, 200.0, -290.8, -358.00000000000006, 164.0, -307.6, 93.79999999999998, 200.0, 15.799999999999963, -368.5, -326.5, 200.0, 131.6, -299.20000000000016, -177.40000000000003, 190.1, 167.0, 200.0, 193.7, 152.3, 200.0, -297.1, 170.0, 170.0, 109.99999999999943, -395.8, 20.000000000000014, 185.0, 155.0, 186.5, 20.000000000000014, -309.7, 157.7, 200.0, -373.0, -379.0, 20.000000000000014, -355.9, 158.0, 153.50000000000003, 155.3, -311.79999999999995, 173.0, 5.299999999999967, -162.70000000000002, 200.0, 188.0, -5.199999999999951, 170.0, 20.000000000000014, -34.60000000000002, 11.599999999999964, 200.0, 3.199999999999969, 20.000000000000014, 175.7, 15.799999999999963, 154.70000000000002, 200.0, 191.9, -347.5, 20.000000000000014, 200.0, 180.8, -120.70000000000003, 20.000000000000014, 20.000000000000014, -271.89999999999947, 128.90000000000003, 92.0, 191.0, -400.0, -376.9, 20.000000000000014, -227.8, -227.8, 200.0, 134.29999999999998, 84.50000000000003, -349.6, -288.7, -349.59999999999997, 170.0, -370.6, -326.5, 200.0, -360.1, 166.1, -4.900000000000006, 137.3, 170.0, 108.19999999999982, -370.6, -181.60000000000002, 200.0, -307.6, -103.89999999999985, -55.60000000000005, 182.6, -94.0, -284.5000000000002, -169.0, -374.8, -284.5, -324.4, 17.899999999999988, 173.9, -259.3000000000004, 139.7, -318.10000000000014, 13.699999999999964, -210.9999999999999, 20.000000000000014, 46.99999999999997, 20.000000000000014, 200.0, 39.79999999999998, 94.40000000000003, -353.79999999999995, 176.6, -366.4, -246.70000000000016, -370.6, 167.0, 176.0, 20.000000000000014, 186.5, -56.19999999999985, 20.000000000000014, -366.4, 200.0, 121.69999999999999], "policy_predator_policy_reward": [0.0, 150.0, 0.0, 0.0, 0.0, 10.0, 0.0, 9.0, 4.0, 0.0, 167.0, 0.0, 200.0, 185.0, 0.0, 0.0, 32.0, 33.0, 0.0, 94.0, 0.0, 183.0, 0.0, 0.0, 82.0, 101.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 121.0, 154.0, 185.0, 188.0, 78.0, 0.0, 3.0, 0.0, 200.0, 78.0, 166.0, 187.0, 157.0, 8.0, 0.0, 10.0, 151.0, 165.0, 27.0, 0.0, 0.0, 0.0, 20.0, 0.0, 180.0, 0.0, 0.0, 171.0, 178.0, 181.0, 199.0, 172.0, 90.0, 0.0, 194.0, 0.0, 0.0, 0.0, 184.0, 142.0, 73.0, 166.0, 0.0, 0.0, 175.0, 187.0, 0.0, 165.0, 152.0, 0.0, 14.0, 89.0, 11.0, 0.0, 0.0, 0.0, 146.0, 151.0, 10.0, 10.0, 187.0, 188.0, 4.0, 5.0, 13.0, 11.0, 157.0, 146.0, 0.0, 0.0, 182.0, 191.0, 0.0, 179.0, 4.0, 21.0, 127.0, 33.0, 0.0, 7.0, 0.0, 87.0, 0.0, 16.0, 10.0, 0.0, 30.0, 19.0, 2.0, 8.0, 0.0, 0.0, 13.0, 2.0, 0.0, 0.0, 175.0, 31.0, 1.0, 0.0, 49.0, 67.0, 139.0, 8.0, 13.0, 9.0, 15.0, 200.0, 7.0, 187.0, 118.0, 0.0, 0.0, 0.0, 182.0, 158.0, 176.0, 0.0, 0.0, 193.0, 0.0, 165.0, 159.0, 181.0, 45.0, 0.0, 10.0, 0.0, 182.0, 186.0, 0.0, 156.0, 95.0, 0.0, 23.0, 93.0, 146.0, 41.0, 112.0, 188.0, 1.0, 164.0, 123.0, 131.0, 161.0, 0.0, 108.0, 95.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 169.0, 169.0, 0.0, 186.0, 188.0, 180.0, 7.0, 8.0, 53.0, 53.0, 171.0, 184.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.090773543216693, "mean_inference_ms": 7.567027363120605, "mean_action_processing_ms": 0.7032124024398052, "mean_env_wait_ms": 0.9677408308981703, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02439749240875244, "StateBufferConnector_ms": 0.007863283157348633, "ViewRequirementAgentConnector_ms": 0.33350181579589844}, "num_episodes": 18, "episode_return_max": 391.9, "episode_return_min": -462.3, "episode_return_mean": 76.0609999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000, "num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 168.46985431586958, "num_env_steps_trained_throughput_per_sec": 168.46985431586958, "timesteps_total": 792000, "num_env_steps_sampled_lifetime": 792000, "num_agent_steps_sampled_lifetime": 3168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3168000, "timers": {"training_iteration_time_ms": 24820.779, "restore_workers_time_ms": 0.019, "training_step_time_ms": 24820.711, "sample_time_ms": 4197.485, "learn_time_ms": 20569.056, "learn_throughput": 194.467, "synch_weights_time_ms": 45.518}, "counters": {"num_env_steps_sampled": 792000, "num_env_steps_trained": 792000, "num_agent_steps_sampled": 3168000, "num_agent_steps_trained": 3168000}, "done": false, "training_iteration": 198, "trial_id": "3a355_00000", "date": "2024-08-13_05-50-47", "timestamp": 1723542647, "time_this_iter_s": 23.858930110931396, "time_total_s": 16843.585040807724, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b7432820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16843.585040807724, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 81.51515151515152, "ram_util_percent": 83.20606060606062}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2071094049111246, "cur_kl_coeff": 9.852879827283873e-48, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.771996040571303, "policy_loss": -0.0014595482670874506, "vf_loss": 4.773455583986151, "vf_explained_var": 0.0027274124836795545, "kl": 0.0028383126824467453, "entropy": 0.20447422256545414, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 375165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 65.24638415202892, "cur_kl_coeff": 4.605831610087938e-29, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.726859798885527, "policy_loss": 0.0005796916038783455, "vf_loss": 5.726280110727543, "vf_explained_var": 0.37252095669665664, "kl": 0.0021815370682156873, "entropy": 0.4598900891485668, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 375165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -558.6, "episode_reward_mean": 64.71199999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -35.80900000000001, "predator_policy": 68.165}, "custom_metrics": {}, "hist_stats": {"episode_reward": [134.1999999999997, 271.6000000000003, 26.40000000000002, -363.0, -83.00000000000003, 199.99999999999935, 166.1, 10.30000000000025, 40.0000000000003, 352.8, -414.19999999999993, 14.799999999999999, 196.8, -6.899999999999878, 18.399999999999785, 6.6, 256.8999999999995, -322.79999999999995, 95.40000000000002, 293.7999999999997, 9.299999999999963, 38.50000000000002, -15.599999999999937, 115.69999999999985, 378.0, 346.00000000000006, 199.90000000000003, 360.0, 89.19999999999943, 213.9999999999993, 365.5, 13.299999999999956, 357.70000000000005, -379.0, -156.90000000000052, 336.5, 3.500000000000063, 185.29999999999941, 124.29999999999976, 198.79999999999936, 199.99999999999935, 26.000000000000203, 213.1999999999993, 195.6999999999994, 185.49999999999943, 391.9, -121.5000000000005, 381.8, 15.300000000000104, -104.90000000000055, 242.90000000000003, 6.0, -162.90000000000057, -337.6, 334.29999999999995, 74.90000000000013, -462.3, -7.600000000000003, 38.50000000000002, 146.0, 177.4, 288.2000000000007, -184.20000000000002, 48.40000000000004, -64.49999999999974, 204.6, -266.4999999999999, -359.3, -141.50000000000043, 168.5999999999998, -17.39999999999995, 5.699999999999955, 67.00000000000024, 219.99999999999926, 144.19999999999985, 160.79999999999998, -427.1000000000002, 164.4, 210.9999999999993, 236.2999999999994, 8.599999999999966, 324.69999999999993, -346.4, -19.799999999999834, 135.09999999999968, 35.10000000000041, -139.3000000000004, 61.59999999999995, -113.10000000000025, 189.29999999999941, 218.49999999999926, -1.800000000000051, -558.6, 400.0, 343.2, -128.30000000000035, 15.399999999999999, 137.9999999999997, 40.0000000000003, 299.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, -143.8, 155.0, 113.59999999999985, -397.9, 146.29999999999993, -358.0, -358.0, -309.7, 61.70000000000018, 20.000000000000014, 170.0, 143.0, -292.9, 20.000000000000014, -36.700000000000024, 20.000000000000014, 20.000000000000014, 144.8, 188.0, -236.20000000000002, -358.0, -339.1, 182.9, 200.0, -362.2, 20.000000000000014, -397.9, -169.0000000000001, 97.39999999999935, 200.0, -387.4, 56.89999999999996, 200.0, -290.8, -358.00000000000006, 164.0, -307.6, 93.79999999999998, 200.0, 15.799999999999963, -368.5, -326.5, 200.0, 131.6, -299.20000000000016, -177.40000000000003, 190.1, 167.0, 200.0, 193.7, 152.3, 200.0, -297.1, 170.0, 170.0, 109.99999999999943, -395.8, 20.000000000000014, 185.0, 155.0, 186.5, 20.000000000000014, -309.7, 157.7, 200.0, -373.0, -379.0, 20.000000000000014, -355.9, 158.0, 153.50000000000003, 155.3, -311.79999999999995, 173.0, 5.299999999999967, -162.70000000000002, 200.0, 188.0, -5.199999999999951, 170.0, 20.000000000000014, -34.60000000000002, 11.599999999999964, 200.0, 3.199999999999969, 20.000000000000014, 175.7, 15.799999999999963, 154.70000000000002, 200.0, 191.9, -347.5, 20.000000000000014, 200.0, 180.8, -120.70000000000003, 20.000000000000014, 20.000000000000014, -271.89999999999947, 128.90000000000003, 92.0, 191.0, -400.0, -376.9, 20.000000000000014, -227.8, -227.8, 200.0, 134.29999999999998, 84.50000000000003, -349.6, -288.7, -349.59999999999997, 170.0, -370.6, -326.5, 200.0, -360.1, 166.1, -4.900000000000006, 137.3, 170.0, 108.19999999999982, -370.6, -181.60000000000002, 200.0, -307.6, -103.89999999999985, -55.60000000000005, 182.6, -94.0, -284.5000000000002, -169.0, -374.8, -284.5, -324.4, 17.899999999999988, 173.9, -259.3000000000004, 139.7, -318.10000000000014, 13.699999999999964, -210.9999999999999, 20.000000000000014, 46.99999999999997, 20.000000000000014, 200.0, 39.79999999999998, 94.40000000000003, -353.79999999999995, 176.6, -366.4, -246.70000000000016, -370.6, 167.0, 176.0, 20.000000000000014, 186.5, -56.19999999999985, 20.000000000000014, -366.4, 200.0, 121.69999999999999, -341.2, -341.2, 20.000000000000014, -311.79999999999995, 170.0, -103.90000000000074, 20.000000000000014, -49.89999999999997, -322.3, 20.000000000000014, -313.9, 60.49999999999996, -330.7, 50.60000000000001, 164.0, 5.299999999999965, 200.0, 15.500000000000025, -59.799999999999926, 20.000000000000014, -374.8, -374.8, 200.0, 200.0, 164.0, 165.2, 20.000000000000014, -301.3, 180.2, -332.8, 77.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 117.5, 170.0], "policy_predator_policy_reward": [78.0, 0.0, 3.0, 0.0, 200.0, 78.0, 166.0, 187.0, 157.0, 8.0, 0.0, 10.0, 151.0, 165.0, 27.0, 0.0, 0.0, 0.0, 20.0, 0.0, 180.0, 0.0, 0.0, 171.0, 178.0, 181.0, 199.0, 172.0, 90.0, 0.0, 194.0, 0.0, 0.0, 0.0, 184.0, 142.0, 73.0, 166.0, 0.0, 0.0, 175.0, 187.0, 0.0, 165.0, 152.0, 0.0, 14.0, 89.0, 11.0, 0.0, 0.0, 0.0, 146.0, 151.0, 10.0, 10.0, 187.0, 188.0, 4.0, 5.0, 13.0, 11.0, 157.0, 146.0, 0.0, 0.0, 182.0, 191.0, 0.0, 179.0, 4.0, 21.0, 127.0, 33.0, 0.0, 7.0, 0.0, 87.0, 0.0, 16.0, 10.0, 0.0, 30.0, 19.0, 2.0, 8.0, 0.0, 0.0, 13.0, 2.0, 0.0, 0.0, 175.0, 31.0, 1.0, 0.0, 49.0, 67.0, 139.0, 8.0, 13.0, 9.0, 15.0, 200.0, 7.0, 187.0, 118.0, 0.0, 0.0, 0.0, 182.0, 158.0, 176.0, 0.0, 0.0, 193.0, 0.0, 165.0, 159.0, 181.0, 45.0, 0.0, 10.0, 0.0, 182.0, 186.0, 0.0, 156.0, 95.0, 0.0, 23.0, 93.0, 146.0, 41.0, 112.0, 188.0, 1.0, 164.0, 123.0, 131.0, 161.0, 0.0, 108.0, 95.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 169.0, 169.0, 0.0, 186.0, 188.0, 180.0, 7.0, 8.0, 53.0, 53.0, 171.0, 184.0, 3.0, 0.0, 164.0, 172.0, 120.0, 152.0, 59.0, 10.0, 45.0, 20.0, 0.0, 163.0, 158.0, 157.0, 167.0, 0.0, 17.0, 3.0, 3.0, 0.0, 0.0, 38.0, 191.0, 0.0, 0.0, 0.0, 12.0, 2.0, 153.0, 0.0, 168.0, 0.0, 41.0, 0.0, 0.0, 0.0, 10.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.0918242394188153, "mean_inference_ms": 7.561277828742987, "mean_action_processing_ms": 0.7044692338329007, "mean_env_wait_ms": 0.9667603054845809, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009538888931274414, "StateBufferConnector_ms": 0.013245820999145508, "ViewRequirementAgentConnector_ms": 0.36711227893829346}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -558.6, "episode_return_mean": 64.71199999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000, "num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 161.70810914136115, "num_env_steps_trained_throughput_per_sec": 161.70810914136115, "timesteps_total": 796000, "num_env_steps_sampled_lifetime": 796000, "num_agent_steps_sampled_lifetime": 3184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3184000, "timers": {"training_iteration_time_ms": 24862.226, "restore_workers_time_ms": 0.021, "training_step_time_ms": 24862.153, "sample_time_ms": 4551.362, "learn_time_ms": 20255.872, "learn_throughput": 197.474, "synch_weights_time_ms": 46.069}, "counters": {"num_env_steps_sampled": 796000, "num_env_steps_trained": 796000, "num_agent_steps_sampled": 3184000, "num_agent_steps_trained": 3184000}, "done": false, "training_iteration": 199, "trial_id": "3a355_00000", "date": "2024-08-13_05-51-12", "timestamp": 1723542672, "time_this_iter_s": 24.810592651367188, "time_total_s": 16868.39563345909, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b6011820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16868.39563345909, "iterations_since_restore": 199, "perf": {"cpu_util_percent": 82.72285714285715, "ram_util_percent": 83.21142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2535223729829623, "cur_kl_coeff": 4.9264399136419364e-48, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.451391202684433, "policy_loss": -0.0034034350909115303, "vf_loss": 5.454794635217657, "vf_explained_var": 0.001510394502569128, "kl": 0.007317475091347887, "entropy": 0.21690569442731364, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 377055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 56.30204389688199, "cur_kl_coeff": 2.302915805043969e-29, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.399205594214182, "policy_loss": 0.0009266864141281793, "vf_loss": 5.398278895257011, "vf_explained_var": 0.33779603652853185, "kl": 0.004208955294637827, "entropy": 0.41801741947888066, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 377055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -558.6, "episode_reward_mean": 58.005999999999865, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -41.73700000000001, "predator_policy": 70.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [360.0, 89.19999999999943, 213.9999999999993, 365.5, 13.299999999999956, 357.70000000000005, -379.0, -156.90000000000052, 336.5, 3.500000000000063, 185.29999999999941, 124.29999999999976, 198.79999999999936, 199.99999999999935, 26.000000000000203, 213.1999999999993, 195.6999999999994, 185.49999999999943, 391.9, -121.5000000000005, 381.8, 15.300000000000104, -104.90000000000055, 242.90000000000003, 6.0, -162.90000000000057, -337.6, 334.29999999999995, 74.90000000000013, -462.3, -7.600000000000003, 38.50000000000002, 146.0, 177.4, 288.2000000000007, -184.20000000000002, 48.40000000000004, -64.49999999999974, 204.6, -266.4999999999999, -359.3, -141.50000000000043, 168.5999999999998, -17.39999999999995, 5.699999999999955, 67.00000000000024, 219.99999999999926, 144.19999999999985, 160.79999999999998, -427.1000000000002, 164.4, 210.9999999999993, 236.2999999999994, 8.599999999999966, 324.69999999999993, -346.4, -19.799999999999834, 135.09999999999968, 35.10000000000041, -139.3000000000004, 61.59999999999995, -113.10000000000025, 189.29999999999941, 218.49999999999926, -1.800000000000051, -558.6, 400.0, 343.2, -128.30000000000035, 15.399999999999999, 137.9999999999997, 40.0000000000003, 299.5, -48.49999999999994, -27.49999999999995, 179.1, -6.6999999999998785, 29.200000000000017, 179.49999999999943, 135.3, -6.299999999999887, 153.39999999999955, -152.5000000000005, 15.799999999999914, 210.9999999999993, 40.0000000000003, 190.5, 291.9999999999999, -128.30000000000035, 382.8, 20.09999999999999, -64.70000000000044, -373.2999999999987, -143.70000000000044, 361.5, 4.900000000000002, -273.3, 27.50000000000001, 178.8, 118.79999999999978], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.0, 170.0, 109.99999999999943, -395.8, 20.000000000000014, 185.0, 155.0, 186.5, 20.000000000000014, -309.7, 157.7, 200.0, -373.0, -379.0, 20.000000000000014, -355.9, 158.0, 153.50000000000003, 155.3, -311.79999999999995, 173.0, 5.299999999999967, -162.70000000000002, 200.0, 188.0, -5.199999999999951, 170.0, 20.000000000000014, -34.60000000000002, 11.599999999999964, 200.0, 3.199999999999969, 20.000000000000014, 175.7, 15.799999999999963, 154.70000000000002, 200.0, 191.9, -347.5, 20.000000000000014, 200.0, 180.8, -120.70000000000003, 20.000000000000014, 20.000000000000014, -271.89999999999947, 128.90000000000003, 92.0, 191.0, -400.0, -376.9, 20.000000000000014, -227.8, -227.8, 200.0, 134.29999999999998, 84.50000000000003, -349.6, -288.7, -349.59999999999997, 170.0, -370.6, -326.5, 200.0, -360.1, 166.1, -4.900000000000006, 137.3, 170.0, 108.19999999999982, -370.6, -181.60000000000002, 200.0, -307.6, -103.89999999999985, -55.60000000000005, 182.6, -94.0, -284.5000000000002, -169.0, -374.8, -284.5, -324.4, 17.899999999999988, 173.9, -259.3000000000004, 139.7, -318.10000000000014, 13.699999999999964, -210.9999999999999, 20.000000000000014, 46.99999999999997, 20.000000000000014, 200.0, 39.79999999999998, 94.40000000000003, -353.79999999999995, 176.6, -366.4, -246.70000000000016, -370.6, 167.0, 176.0, 20.000000000000014, 186.5, -56.19999999999985, 20.000000000000014, -366.4, 200.0, 121.69999999999999, -341.2, -341.2, 20.000000000000014, -311.79999999999995, 170.0, -103.90000000000074, 20.000000000000014, -49.89999999999997, -322.3, 20.000000000000014, -313.9, 60.49999999999996, -330.7, 50.60000000000001, 164.0, 5.299999999999965, 200.0, 15.500000000000025, -59.799999999999926, 20.000000000000014, -374.8, -374.8, 200.0, 200.0, 164.0, 165.2, 20.000000000000014, -301.3, 180.2, -332.8, 77.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 117.5, 170.0, -295.0, 96.49999999999997, -13.599999999999985, -397.9, -358.0, 181.1, -393.7, 20.000000000000014, 125.0, -248.79999999999995, 20.000000000000014, 159.5, 140.0, -372.7, 13.699999999999964, -400.0, 133.39999999999998, 20.000000000000014, 20.000000000000014, -347.5, 20.000000000000014, -26.199999999999754, 20.000000000000014, 191.0, 20.000000000000014, 20.000000000000014, 200.0, -389.5, 107.29999999999998, 184.7, -301.3, 20.000000000000014, 192.8, 185.0, 20.000000000000014, -229.9, -284.5, -5.200000000000051, -360.1, -194.2000000000004, 11.599999999999968, -322.3, 176.0, 177.5, 182.9, -358.0, -274.0, -280.3, -347.5, 200.0, 167.0, -341.2, 200.0, -173.20000000000002], "policy_predator_policy_reward": [10.0, 10.0, 187.0, 188.0, 4.0, 5.0, 13.0, 11.0, 157.0, 146.0, 0.0, 0.0, 182.0, 191.0, 0.0, 179.0, 4.0, 21.0, 127.0, 33.0, 0.0, 7.0, 0.0, 87.0, 0.0, 16.0, 10.0, 0.0, 30.0, 19.0, 2.0, 8.0, 0.0, 0.0, 13.0, 2.0, 0.0, 0.0, 175.0, 31.0, 1.0, 0.0, 49.0, 67.0, 139.0, 8.0, 13.0, 9.0, 15.0, 200.0, 7.0, 187.0, 118.0, 0.0, 0.0, 0.0, 182.0, 158.0, 176.0, 0.0, 0.0, 193.0, 0.0, 165.0, 159.0, 181.0, 45.0, 0.0, 10.0, 0.0, 182.0, 186.0, 0.0, 156.0, 95.0, 0.0, 23.0, 93.0, 146.0, 41.0, 112.0, 188.0, 1.0, 164.0, 123.0, 131.0, 161.0, 0.0, 108.0, 95.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 169.0, 169.0, 0.0, 186.0, 188.0, 180.0, 7.0, 8.0, 53.0, 53.0, 171.0, 184.0, 3.0, 0.0, 164.0, 172.0, 120.0, 152.0, 59.0, 10.0, 45.0, 20.0, 0.0, 163.0, 158.0, 157.0, 167.0, 0.0, 17.0, 3.0, 3.0, 0.0, 0.0, 38.0, 191.0, 0.0, 0.0, 0.0, 12.0, 2.0, 153.0, 0.0, 168.0, 0.0, 41.0, 0.0, 0.0, 0.0, 10.0, 2.0, 0.0, 150.0, 199.0, 185.0, 176.0, 180.0, 197.0, 170.0, 128.0, 25.0, 0.0, 0.0, 181.0, 187.0, 188.0, 192.0, 0.0, 0.0, 175.0, 0.0, 12.0, 10.0, 0.0, 0.0, 0.0, 0.0, 195.0, 185.0, 0.0, 0.0, 153.0, 0.0, 0.0, 5.0, 111.0, 119.0, 80.0, 145.0, 0.0, 181.0, 4.0, 163.0, 0.0, 8.0, 180.0, 0.0, 138.0, 143.0, 0.0, 175.0, 181.0, 172.0, 92.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 2.1283594082414736, "mean_inference_ms": 7.48276894993491, "mean_action_processing_ms": 0.7072670277790932, "mean_env_wait_ms": 0.9984554733574388, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0170290470123291, "StateBufferConnector_ms": 0.01613008975982666, "ViewRequirementAgentConnector_ms": 0.46459484100341797}, "num_episodes": 27, "episode_return_max": 400.0, "episode_return_min": -558.6, "episode_return_mean": 58.005999999999865, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000, "num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 150.96846277291345, "num_env_steps_trained_throughput_per_sec": 150.96846277291345, "timesteps_total": 800000, "num_env_steps_sampled_lifetime": 800000, "num_agent_steps_sampled_lifetime": 3200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 3200000, "timers": {"training_iteration_time_ms": 24986.056, "restore_workers_time_ms": 0.022, "training_step_time_ms": 24985.982, "sample_time_ms": 5036.794, "learn_time_ms": 19895.408, "learn_throughput": 201.051, "synch_weights_time_ms": 45.354}, "counters": {"num_env_steps_sampled": 800000, "num_env_steps_trained": 800000, "num_agent_steps_sampled": 3200000, "num_agent_steps_trained": 3200000}, "done": true, "training_iteration": 200, "trial_id": "3a355_00000", "date": "2024-08-13_05-51-39", "timestamp": 1723542699, "time_this_iter_s": 26.541760206222534, "time_total_s": 16894.937393665314, "pid": 21342, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b5534820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16894.937393665314, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 83.90526315789474, "ram_util_percent": 83.47894736842105}}
