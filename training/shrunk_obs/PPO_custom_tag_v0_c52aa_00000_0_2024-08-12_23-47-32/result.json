{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9754333800266659, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.322771071378517, "policy_loss": -0.0011341325692319996, "vf_loss": 8.323161292202258, "vf_explained_var": 0.0011018332350190986, "kl": 0.0037195568084106845, "entropy": 1.6057659678988987, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.1923810056100289, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.936807135047105, "policy_loss": -0.002264576559768073, "vf_loss": 4.9382657989623056, "vf_explained_var": 0.0004617894768084168, "kl": 0.004029466461839633, "entropy": 1.605333844694511, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 212.00000000000006, "episode_reward_min": -181.20000000000053, "episode_reward_mean": 8.683333333333287, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -280.30000000000024, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 146.0, "predator_policy": 119.0}, "policy_reward_mean": {"prey_policy": -40.49166666666672, "predator_policy": 44.833333333333336}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.20000000000053, 43.80000000000025, 109.69999999999989, 104.39999999999918, -26.299999999999876, -17.399999999999793, 42.00000000000002, -75.89999999999998, 7.900000000000068, 212.00000000000006, -51.1000000000003, -70.4000000000001, 159.6999999999992, -28.199999999999676, -8.500000000000039, 40.0000000000003, -65.39999999999975, -38.799999999999734], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.3000000000001, -229.90000000000038, 44.299999999999976, -71.49999999999993, 117.20000000000005, -32.49999999999989, 20.000000000000014, 46.400000000000034, 20.000000000000014, -148.30000000000007, -235.9000000000001, 42.500000000000234, -124.90000000000035, 77.9, 30.800000000000132, -225.7000000000001, -73.00000000000054, -0.10000000000000281, 43.999999999999986, 146.0, 20.000000000000014, -180.10000000000014, -152.80000000000024, -13.599999999999929, 25.400000000000023, 107.29999999999993, -106.00000000000057, 15.800000000000011, -62.50000000000001, -18.999999999999936, 20.000000000000014, 20.000000000000014, 20.90000000000003, -280.30000000000024, -47.199999999999875, -97.60000000000012], "policy_predator_policy_reward": [105.0, 119.0, 34.0, 37.0, 0.0, 25.0, 37.0, 1.0, 102.0, 0.0, 103.0, 73.0, 0.0, 89.0, 114.0, 5.0, 62.0, 19.0, 22.0, 0.0, 109.0, 0.0, 0.0, 96.0, 0.0, 27.0, 2.0, 60.0, 66.0, 7.0, 0.0, 0.0, 99.0, 95.0, 106.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2726951370087203, "mean_inference_ms": 3.4960011235751574, "mean_action_processing_ms": 0.511278416096654, "mean_env_wait_ms": 0.8062239287151475, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01017451286315918, "StateBufferConnector_ms": 0.004425976011488173, "ViewRequirementAgentConnector_ms": 0.21708872583177355}, "num_episodes": 18, "episode_return_max": 212.00000000000006, "episode_return_min": -181.20000000000053, "episode_return_mean": 8.683333333333287, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 291.71951337770696, "num_env_steps_trained_throughput_per_sec": 291.71951337770696, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 13711.903, "restore_workers_time_ms": 0.023, "training_step_time_ms": 13711.501, "sample_time_ms": 2868.942, "learn_time_ms": 10823.214, "learn_throughput": 369.576, "synch_weights_time_ms": 14.678}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "c52aa_00000", "date": "2024-08-12_23-48-00", "timestamp": 1723520880, "time_this_iter_s": 13.764770746231079, "time_total_s": 13.764770746231079, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x329e9a940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 13.764770746231079, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 66.33500000000001, "ram_util_percent": 83.59}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.01835330881612, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.9723015308380125, "policy_loss": -0.00035443076372353567, "vf_loss": 6.972340392561817, "vf_explained_var": 0.0008738648954522673, "kl": 0.003155770886078375, "entropy": 1.6005018431673605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.24884065567027955, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.070569634059119, "policy_loss": -0.0009434448727579028, "vf_loss": 3.071230347635885, "vf_explained_var": 0.006315625439245234, "kl": 0.002827430692251085, "entropy": 1.602841581175567, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 225.8999999999995, "episode_reward_min": -181.20000000000053, "episode_reward_mean": 30.333333333333215, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -280.30000000000024, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.6, "predator_policy": 145.0}, "policy_reward_mean": {"prey_policy": -22.70833333333341, "predator_policy": 37.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.20000000000053, 43.80000000000025, 109.69999999999989, 104.39999999999918, -26.299999999999876, -17.399999999999793, 42.00000000000002, -75.89999999999998, 7.900000000000068, 212.00000000000006, -51.1000000000003, -70.4000000000001, 159.6999999999992, -28.199999999999676, -8.500000000000039, 40.0000000000003, -65.39999999999975, -38.799999999999734, 65.8000000000001, 40.9000000000003, 105.19999999999862, -121.90000000000046, 44.200000000000315, 52.40000000000046, -118.30000000000078, 195.59999999999997, -28.699999999999783, 225.8999999999995, 36.50000000000014, -61.10000000000053, 65.20000000000002, 165.09999999999857, 63.40000000000015, 160.39999999999944, 6.800000000000191, 38.30000000000033], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.3000000000001, -229.90000000000038, 44.299999999999976, -71.49999999999993, 117.20000000000005, -32.49999999999989, 20.000000000000014, 46.400000000000034, 20.000000000000014, -148.30000000000007, -235.9000000000001, 42.500000000000234, -124.90000000000035, 77.9, 30.800000000000132, -225.7000000000001, -73.00000000000054, -0.10000000000000281, 43.999999999999986, 146.0, 20.000000000000014, -180.10000000000014, -152.80000000000024, -13.599999999999929, 25.400000000000023, 107.29999999999993, -106.00000000000057, 15.800000000000011, -62.50000000000001, -18.999999999999936, 20.000000000000014, 20.000000000000014, 20.90000000000003, -280.30000000000024, -47.199999999999875, -97.60000000000012, 20.000000000000014, 12.800000000000104, 20.90000000000003, 20.000000000000014, 92.89999999999932, 5.299999999999981, -174.70000000000024, -137.20000000000022, 18.19999999999999, 20.000000000000014, 31.40000000000019, 20.000000000000014, -202.29999999999998, -85.00000000000063, 11.599999999999994, 112.99999999999997, -25.59999999999991, -81.10000000000036, 38.30000000000013, 185.6, -53.19999999999998, -4.299999999999811, 20.000000000000014, -204.10000000000028, 137.0, -230.8000000000004, 73.99999999999949, 91.09999999999951, 46.69999999999996, -37.30000000000013, 139.39999999999995, 20.000000000000014, 30.80000000000003, -109.0000000000001, -21.69999999999984, 20.000000000000014], "policy_predator_policy_reward": [105.0, 119.0, 34.0, 37.0, 0.0, 25.0, 37.0, 1.0, 102.0, 0.0, 103.0, 73.0, 0.0, 89.0, 114.0, 5.0, 62.0, 19.0, 22.0, 0.0, 109.0, 0.0, 0.0, 96.0, 0.0, 27.0, 2.0, 60.0, 66.0, 7.0, 0.0, 0.0, 99.0, 95.0, 106.0, 0.0, 32.0, 1.0, 0.0, 0.0, 0.0, 7.0, 145.0, 45.0, 6.0, 0.0, 0.0, 1.0, 53.0, 116.0, 51.0, 20.0, 55.0, 23.0, 0.0, 2.0, 89.0, 5.0, 90.0, 33.0, 121.0, 38.0, 0.0, 0.0, 54.0, 0.0, 0.0, 1.0, 0.0, 85.0, 0.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.292762278389827, "mean_inference_ms": 3.6151257371066845, "mean_action_processing_ms": 0.5163488762280399, "mean_env_wait_ms": 0.7966842830453597, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009749001926845975, "StateBufferConnector_ms": 0.003848473230997721, "ViewRequirementAgentConnector_ms": 0.22714369826846653}, "num_episodes": 18, "episode_return_max": 225.8999999999995, "episode_return_min": -181.20000000000053, "episode_return_mean": 30.333333333333215, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 231.87685025206557, "num_env_steps_trained_throughput_per_sec": 231.87685025206557, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 15481.227, "restore_workers_time_ms": 0.038, "training_step_time_ms": 15480.923, "sample_time_ms": 3124.401, "learn_time_ms": 12337.364, "learn_throughput": 324.218, "synch_weights_time_ms": 15.855}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "c52aa_00000", "date": "2024-08-12_23-48-21", "timestamp": 1723520901, "time_this_iter_s": 17.34367299079895, "time_total_s": 31.10844373703003, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x329e8c160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 31.10844373703003, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 78.44137931034484, "ram_util_percent": 83.60689655172413}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.820730807667687, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.217157073878737, "policy_loss": -0.003413176498617287, "vf_loss": 5.219739789306802, "vf_explained_var": 0.006424905635692455, "kl": 0.016609512232295457, "entropy": 1.5654190144841633, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2551283666834472, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2696405039893257, "policy_loss": -0.00031037387997404764, "vf_loss": 3.2698409938938404, "vf_explained_var": -0.000904154588305761, "kl": 0.002197708652933173, "entropy": 1.5985646708932504, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 225.8999999999995, "episode_reward_min": -181.20000000000053, "episode_reward_mean": 29.49074074074061, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -280.30000000000024, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.6, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -19.291666666666746, "predator_policy": 34.03703703703704}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.20000000000053, 43.80000000000025, 109.69999999999989, 104.39999999999918, -26.299999999999876, -17.399999999999793, 42.00000000000002, -75.89999999999998, 7.900000000000068, 212.00000000000006, -51.1000000000003, -70.4000000000001, 159.6999999999992, -28.199999999999676, -8.500000000000039, 40.0000000000003, -65.39999999999975, -38.799999999999734, 65.8000000000001, 40.9000000000003, 105.19999999999862, -121.90000000000046, 44.200000000000315, 52.40000000000046, -118.30000000000078, 195.59999999999997, -28.699999999999783, 225.8999999999995, 36.50000000000014, -61.10000000000053, 65.20000000000002, 165.09999999999857, 63.40000000000015, 160.39999999999944, 6.800000000000191, 38.30000000000033, 9.800000000000104, 71.29999999999973, 61.00000000000027, 98.19999999999942, 1.400000000000272, -55.800000000000026, 20.700000000000003, -65.10000000000005, 111.9999999999985, -50.60000000000076, 151.39999999999938, 118.69999999999996, 11.400000000000166, 39.000000000000256, 4.800000000000124, 40.0000000000003, -127.50000000000065, 59.80000000000043], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.3000000000001, -229.90000000000038, 44.299999999999976, -71.49999999999993, 117.20000000000005, -32.49999999999989, 20.000000000000014, 46.400000000000034, 20.000000000000014, -148.30000000000007, -235.9000000000001, 42.500000000000234, -124.90000000000035, 77.9, 30.800000000000132, -225.7000000000001, -73.00000000000054, -0.10000000000000281, 43.999999999999986, 146.0, 20.000000000000014, -180.10000000000014, -152.80000000000024, -13.599999999999929, 25.400000000000023, 107.29999999999993, -106.00000000000057, 15.800000000000011, -62.50000000000001, -18.999999999999936, 20.000000000000014, 20.000000000000014, 20.90000000000003, -280.30000000000024, -47.199999999999875, -97.60000000000012, 20.000000000000014, 12.800000000000104, 20.90000000000003, 20.000000000000014, 92.89999999999932, 5.299999999999981, -174.70000000000024, -137.20000000000022, 18.19999999999999, 20.000000000000014, 31.40000000000019, 20.000000000000014, -202.29999999999998, -85.00000000000063, 11.599999999999994, 112.99999999999997, -25.59999999999991, -81.10000000000036, 38.30000000000013, 185.6, -53.19999999999998, -4.299999999999811, 20.000000000000014, -204.10000000000028, 137.0, -230.8000000000004, 73.99999999999949, 91.09999999999951, 46.69999999999996, -37.30000000000013, 139.39999999999995, 20.000000000000014, 30.80000000000003, -109.0000000000001, -21.69999999999984, 20.000000000000014, 27.200000000000024, -51.39999999999992, 46.70000000000012, 23.60000000000008, 1.0999999999999819, 47.90000000000012, 20.000000000000014, 54.20000000000007, -21.099999999999895, -11.500000000000021, -6.100000000000016, -141.7, -21.999999999999744, 22.700000000000063, 21.80000000000004, -247.90000000000032, 79.39999999999927, 32.60000000000019, -76.90000000000066, -126.70000000000039, 1.6999999999999689, 121.69999999999996, -51.3999999999999, 136.1000000000001, -61.900000000000766, 2.3000000000000913, 4.999999999999956, 20.000000000000014, -179.50000000000057, 89.29999999999981, 20.000000000000014, 20.000000000000014, -76.60000000000053, -226.90000000000023, 20.000000000000014, 39.800000000000196], "policy_predator_policy_reward": [105.0, 119.0, 34.0, 37.0, 0.0, 25.0, 37.0, 1.0, 102.0, 0.0, 103.0, 73.0, 0.0, 89.0, 114.0, 5.0, 62.0, 19.0, 22.0, 0.0, 109.0, 0.0, 0.0, 96.0, 0.0, 27.0, 2.0, 60.0, 66.0, 7.0, 0.0, 0.0, 99.0, 95.0, 106.0, 0.0, 32.0, 1.0, 0.0, 0.0, 0.0, 7.0, 145.0, 45.0, 6.0, 0.0, 0.0, 1.0, 53.0, 116.0, 51.0, 20.0, 55.0, 23.0, 0.0, 2.0, 89.0, 5.0, 90.0, 33.0, 121.0, 38.0, 0.0, 0.0, 54.0, 0.0, 0.0, 1.0, 0.0, 85.0, 0.0, 40.0, 0.0, 34.0, 0.0, 1.0, 4.0, 8.0, 24.0, 0.0, 34.0, 0.0, 77.0, 15.0, 20.0, 0.0, 0.0, 161.0, 0.0, 0.0, 71.0, 82.0, 18.0, 10.0, 34.0, 0.0, 47.0, 24.0, 14.0, 0.0, 0.0, 95.0, 0.0, 0.0, 46.0, 130.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2619909967546334, "mean_inference_ms": 3.5510240047865347, "mean_action_processing_ms": 0.500674092824107, "mean_env_wait_ms": 0.7738771358288278, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009061892827351889, "StateBufferConnector_ms": 0.004007860466285988, "ViewRequirementAgentConnector_ms": 0.20486955289487485}, "num_episodes": 18, "episode_return_max": 225.8999999999995, "episode_return_min": -181.20000000000053, "episode_return_mean": 29.49074074074061, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.0043794483781, "num_env_steps_trained_throughput_per_sec": 334.0043794483781, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 14312.788, "restore_workers_time_ms": 0.036, "training_step_time_ms": 14312.547, "sample_time_ms": 2819.148, "learn_time_ms": 11474.057, "learn_throughput": 348.613, "synch_weights_time_ms": 14.497}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "c52aa_00000", "date": "2024-08-12_23-48-33", "timestamp": 1723520913, "time_this_iter_s": 12.016723155975342, "time_total_s": 43.12516689300537, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x329e9aee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 43.12516689300537, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 62.84117647058823, "ram_util_percent": 83.58235294117648}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4697635083050324, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.5018239472908945, "policy_loss": -0.0024220447618977497, "vf_loss": 5.503322423198235, "vf_explained_var": 0.009395080016403603, "kl": 0.018471475719752044, "entropy": 1.551901041452216, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2457746089864818, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4951030386188044, "policy_loss": -0.0024875041225521023, "vf_loss": 2.497412983387236, "vf_explained_var": -0.000329599935541708, "kl": 0.007102534548523408, "entropy": 1.5850179230094588, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 225.8999999999995, "episode_reward_min": -182.0000000000012, "episode_reward_mean": 30.60416666666653, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -288.6999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.6, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -15.40625000000007, "predator_policy": 30.708333333333332}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.20000000000053, 43.80000000000025, 109.69999999999989, 104.39999999999918, -26.299999999999876, -17.399999999999793, 42.00000000000002, -75.89999999999998, 7.900000000000068, 212.00000000000006, -51.1000000000003, -70.4000000000001, 159.6999999999992, -28.199999999999676, -8.500000000000039, 40.0000000000003, -65.39999999999975, -38.799999999999734, 65.8000000000001, 40.9000000000003, 105.19999999999862, -121.90000000000046, 44.200000000000315, 52.40000000000046, -118.30000000000078, 195.59999999999997, -28.699999999999783, 225.8999999999995, 36.50000000000014, -61.10000000000053, 65.20000000000002, 165.09999999999857, 63.40000000000015, 160.39999999999944, 6.800000000000191, 38.30000000000033, 9.800000000000104, 71.29999999999973, 61.00000000000027, 98.19999999999942, 1.400000000000272, -55.800000000000026, 20.700000000000003, -65.10000000000005, 111.9999999999985, -50.60000000000076, 151.39999999999938, 118.69999999999996, 11.400000000000166, 39.000000000000256, 4.800000000000124, 40.0000000000003, -127.50000000000065, 59.80000000000043, -137.5000000000009, 67.90000000000023, -102.80000000000035, -32.199999999999775, 223.09999999999937, 182.1999999999993, -20.49999999999961, 170.49999999999895, 40.0000000000003, 169.69999999999953, -9.499999999999806, 25.20000000000018, 19.199999999999964, 15.800000000000267, 68.80000000000038, -182.0000000000012, 38.90000000000028, 74.20000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.3000000000001, -229.90000000000038, 44.299999999999976, -71.49999999999993, 117.20000000000005, -32.49999999999989, 20.000000000000014, 46.400000000000034, 20.000000000000014, -148.30000000000007, -235.9000000000001, 42.500000000000234, -124.90000000000035, 77.9, 30.800000000000132, -225.7000000000001, -73.00000000000054, -0.10000000000000281, 43.999999999999986, 146.0, 20.000000000000014, -180.10000000000014, -152.80000000000024, -13.599999999999929, 25.400000000000023, 107.29999999999993, -106.00000000000057, 15.800000000000011, -62.50000000000001, -18.999999999999936, 20.000000000000014, 20.000000000000014, 20.90000000000003, -280.30000000000024, -47.199999999999875, -97.60000000000012, 20.000000000000014, 12.800000000000104, 20.90000000000003, 20.000000000000014, 92.89999999999932, 5.299999999999981, -174.70000000000024, -137.20000000000022, 18.19999999999999, 20.000000000000014, 31.40000000000019, 20.000000000000014, -202.29999999999998, -85.00000000000063, 11.599999999999994, 112.99999999999997, -25.59999999999991, -81.10000000000036, 38.30000000000013, 185.6, -53.19999999999998, -4.299999999999811, 20.000000000000014, -204.10000000000028, 137.0, -230.8000000000004, 73.99999999999949, 91.09999999999951, 46.69999999999996, -37.30000000000013, 139.39999999999995, 20.000000000000014, 30.80000000000003, -109.0000000000001, -21.69999999999984, 20.000000000000014, 27.200000000000024, -51.39999999999992, 46.70000000000012, 23.60000000000008, 1.0999999999999819, 47.90000000000012, 20.000000000000014, 54.20000000000007, -21.099999999999895, -11.500000000000021, -6.100000000000016, -141.7, -21.999999999999744, 22.700000000000063, 21.80000000000004, -247.90000000000032, 79.39999999999927, 32.60000000000019, -76.90000000000066, -126.70000000000039, 1.6999999999999689, 121.69999999999996, -51.3999999999999, 136.1000000000001, -61.900000000000766, 2.3000000000000913, 4.999999999999956, 20.000000000000014, -179.50000000000057, 89.29999999999981, 20.000000000000014, 20.000000000000014, -76.60000000000053, -226.90000000000023, 20.000000000000014, 39.800000000000196, -288.6999999999996, 3.1999999999999615, 20.90000000000003, 46.99999999999998, -72.10000000000002, -204.7000000000005, 15.799999999999963, -136.0000000000002, 168.19999999999993, 47.89999999999997, 159.49999999999994, 13.699999999999987, -13.599999999999868, -61.90000000000064, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.70000000000005, -112.30000000000015, 39.80000000000025, 20.000000000000014, -23.79999999999984, 20.000000000000014, -23.799999999999756, 20.000000000000014, -26.200000000000024, 22.700000000000063, 46.10000000000011, -142.90000000000066, -162.10000000000053, 20.000000000000014, 17.899999999999988, 28.100000000000037, 46.09999999999997], "policy_predator_policy_reward": [105.0, 119.0, 34.0, 37.0, 0.0, 25.0, 37.0, 1.0, 102.0, 0.0, 103.0, 73.0, 0.0, 89.0, 114.0, 5.0, 62.0, 19.0, 22.0, 0.0, 109.0, 0.0, 0.0, 96.0, 0.0, 27.0, 2.0, 60.0, 66.0, 7.0, 0.0, 0.0, 99.0, 95.0, 106.0, 0.0, 32.0, 1.0, 0.0, 0.0, 0.0, 7.0, 145.0, 45.0, 6.0, 0.0, 0.0, 1.0, 53.0, 116.0, 51.0, 20.0, 55.0, 23.0, 0.0, 2.0, 89.0, 5.0, 90.0, 33.0, 121.0, 38.0, 0.0, 0.0, 54.0, 0.0, 0.0, 1.0, 0.0, 85.0, 0.0, 40.0, 0.0, 34.0, 0.0, 1.0, 4.0, 8.0, 24.0, 0.0, 34.0, 0.0, 77.0, 15.0, 20.0, 0.0, 0.0, 161.0, 0.0, 0.0, 71.0, 82.0, 18.0, 10.0, 34.0, 0.0, 47.0, 24.0, 14.0, 0.0, 0.0, 95.0, 0.0, 0.0, 46.0, 130.0, 0.0, 0.0, 146.0, 2.0, 0.0, 0.0, 33.0, 141.0, 88.0, 0.0, 0.0, 7.0, 9.0, 0.0, 39.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 63.0, 0.0, 0.0, 29.0, 23.0, 0.0, 22.0, 0.0, 0.0, 0.0, 47.0, 76.0, 1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2340618323417065, "mean_inference_ms": 3.489181551899381, "mean_action_processing_ms": 0.49106778929741474, "mean_env_wait_ms": 0.7599571640200846, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010557472705841064, "StateBufferConnector_ms": 0.0038295984268188477, "ViewRequirementAgentConnector_ms": 0.1816994614071316}, "num_episodes": 18, "episode_return_max": 225.8999999999995, "episode_return_min": -182.0000000000012, "episode_return_mean": 30.60416666666653, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 305.892200688007, "num_env_steps_trained_throughput_per_sec": 305.892200688007, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 14003.718, "restore_workers_time_ms": 0.031, "training_step_time_ms": 14003.527, "sample_time_ms": 2695.766, "learn_time_ms": 11287.156, "learn_throughput": 354.385, "synch_weights_time_ms": 16.719}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "c52aa_00000", "date": "2024-08-12_23-48-46", "timestamp": 1723520926, "time_this_iter_s": 13.145484924316406, "time_total_s": 56.27065181732178, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9bce50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 56.27065181732178, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 67.42105263157895, "ram_util_percent": 82.07894736842105}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3278914643816215, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7392617841246265, "policy_loss": -0.0015304019014355998, "vf_loss": 3.740190351450885, "vf_explained_var": -0.0009882239122239371, "kl": 0.012036633807776125, "entropy": 1.5050477952553483, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.21064882967719642, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5285553020144267, "policy_loss": -0.00470479402676343, "vf_loss": 2.5329155002952253, "vf_explained_var": -0.0001330958156989365, "kl": 0.013783433803470581, "entropy": 1.5732053479189596, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 225.8999999999995, "episode_reward_min": -201.50000000000026, "episode_reward_mean": 28.77070707070694, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -288.6999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.6, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -14.543939393939448, "predator_policy": 28.92929292929293}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.20000000000053, 43.80000000000025, 109.69999999999989, 104.39999999999918, -26.299999999999876, -17.399999999999793, 42.00000000000002, -75.89999999999998, 7.900000000000068, 212.00000000000006, -51.1000000000003, -70.4000000000001, 159.6999999999992, -28.199999999999676, -8.500000000000039, 40.0000000000003, -65.39999999999975, -38.799999999999734, 65.8000000000001, 40.9000000000003, 105.19999999999862, -121.90000000000046, 44.200000000000315, 52.40000000000046, -118.30000000000078, 195.59999999999997, -28.699999999999783, 225.8999999999995, 36.50000000000014, -61.10000000000053, 65.20000000000002, 165.09999999999857, 63.40000000000015, 160.39999999999944, 6.800000000000191, 38.30000000000033, 9.800000000000104, 71.29999999999973, 61.00000000000027, 98.19999999999942, 1.400000000000272, -55.800000000000026, 20.700000000000003, -65.10000000000005, 111.9999999999985, -50.60000000000076, 151.39999999999938, 118.69999999999996, 11.400000000000166, 39.000000000000256, 4.800000000000124, 40.0000000000003, -127.50000000000065, 59.80000000000043, -137.5000000000009, 67.90000000000023, -102.80000000000035, -32.199999999999775, 223.09999999999937, 182.1999999999993, -20.49999999999961, 170.49999999999895, 40.0000000000003, 169.69999999999953, -9.499999999999806, 25.20000000000018, 19.199999999999964, 15.800000000000267, 68.80000000000038, -182.0000000000012, 38.90000000000028, 74.20000000000016, 77.7999999999999, 9.099999999999989, 40.0000000000003, 46.30000000000034, 84.99999999999898, 23.500000000000096, 89.89999999999995, -56.89999999999991, 11.499999999999929, 40.0000000000003, -105.7000000000005, 17.400000000000077, 153.39999999999966, -201.50000000000026, -29.299999999999564, -122.10000000000039, 72.20000000000002, 1.3000000000001606, 76.59999999999951, 108.0999999999989, 66.50000000000023, 111.89999999999947, 84.99999999999898, -31.099999999999675, 33.50000000000005, 12.499999999999988, 29.900000000000123], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.3000000000001, -229.90000000000038, 44.299999999999976, -71.49999999999993, 117.20000000000005, -32.49999999999989, 20.000000000000014, 46.400000000000034, 20.000000000000014, -148.30000000000007, -235.9000000000001, 42.500000000000234, -124.90000000000035, 77.9, 30.800000000000132, -225.7000000000001, -73.00000000000054, -0.10000000000000281, 43.999999999999986, 146.0, 20.000000000000014, -180.10000000000014, -152.80000000000024, -13.599999999999929, 25.400000000000023, 107.29999999999993, -106.00000000000057, 15.800000000000011, -62.50000000000001, -18.999999999999936, 20.000000000000014, 20.000000000000014, 20.90000000000003, -280.30000000000024, -47.199999999999875, -97.60000000000012, 20.000000000000014, 12.800000000000104, 20.90000000000003, 20.000000000000014, 92.89999999999932, 5.299999999999981, -174.70000000000024, -137.20000000000022, 18.19999999999999, 20.000000000000014, 31.40000000000019, 20.000000000000014, -202.29999999999998, -85.00000000000063, 11.599999999999994, 112.99999999999997, -25.59999999999991, -81.10000000000036, 38.30000000000013, 185.6, -53.19999999999998, -4.299999999999811, 20.000000000000014, -204.10000000000028, 137.0, -230.8000000000004, 73.99999999999949, 91.09999999999951, 46.69999999999996, -37.30000000000013, 139.39999999999995, 20.000000000000014, 30.80000000000003, -109.0000000000001, -21.69999999999984, 20.000000000000014, 27.200000000000024, -51.39999999999992, 46.70000000000012, 23.60000000000008, 1.0999999999999819, 47.90000000000012, 20.000000000000014, 54.20000000000007, -21.099999999999895, -11.500000000000021, -6.100000000000016, -141.7, -21.999999999999744, 22.700000000000063, 21.80000000000004, -247.90000000000032, 79.39999999999927, 32.60000000000019, -76.90000000000066, -126.70000000000039, 1.6999999999999689, 121.69999999999996, -51.3999999999999, 136.1000000000001, -61.900000000000766, 2.3000000000000913, 4.999999999999956, 20.000000000000014, -179.50000000000057, 89.29999999999981, 20.000000000000014, 20.000000000000014, -76.60000000000053, -226.90000000000023, 20.000000000000014, 39.800000000000196, -288.6999999999996, 3.1999999999999615, 20.90000000000003, 46.99999999999998, -72.10000000000002, -204.7000000000005, 15.799999999999963, -136.0000000000002, 168.19999999999993, 47.89999999999997, 159.49999999999994, 13.699999999999987, -13.599999999999868, -61.90000000000064, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.70000000000005, -112.30000000000015, 39.80000000000025, 20.000000000000014, -23.79999999999984, 20.000000000000014, -23.799999999999756, 20.000000000000014, -26.200000000000024, 22.700000000000063, 46.10000000000011, -142.90000000000066, -162.10000000000053, 20.000000000000014, 17.899999999999988, 28.100000000000037, 46.09999999999997, 57.80000000000021, 20.000000000000014, -5.1999999999999265, -27.69999999999984, 20.000000000000014, 20.000000000000014, 26.30000000000013, 20.000000000000014, 20.000000000000014, 65.00000000000014, -50.49999999999985, 20.000000000000014, -26.500000000000007, 73.39999999999995, -125.2000000000001, -69.70000000000007, 20.000000000000014, -47.499999999999794, 20.000000000000014, 20.000000000000014, -55.89999999999993, -155.80000000000013, 20.000000000000014, -52.59999999999985, 48.80000000000015, 104.59999999999997, -178.6000000000001, -166.90000000000032, 20.000000000000014, -112.30000000000051, -93.40000000000076, -237.7000000000001, 49.40000000000021, 21.80000000000001, -136.30000000000018, 8.600000000000001, 50.000000000000185, -6.399999999999951, 64.10000000000021, 20.000000000000053, 20.000000000000014, 30.500000000000192, 64.40000000000003, 33.500000000000085, 20.000000000000014, 65.00000000000014, -100.30000000000052, -2.799999999999972, -144.70000000000002, 84.19999999999969, 20.000000000000014, -32.49999999999976, -0.10000000000003478, 20.000000000000014], "policy_predator_policy_reward": [105.0, 119.0, 34.0, 37.0, 0.0, 25.0, 37.0, 1.0, 102.0, 0.0, 103.0, 73.0, 0.0, 89.0, 114.0, 5.0, 62.0, 19.0, 22.0, 0.0, 109.0, 0.0, 0.0, 96.0, 0.0, 27.0, 2.0, 60.0, 66.0, 7.0, 0.0, 0.0, 99.0, 95.0, 106.0, 0.0, 32.0, 1.0, 0.0, 0.0, 0.0, 7.0, 145.0, 45.0, 6.0, 0.0, 0.0, 1.0, 53.0, 116.0, 51.0, 20.0, 55.0, 23.0, 0.0, 2.0, 89.0, 5.0, 90.0, 33.0, 121.0, 38.0, 0.0, 0.0, 54.0, 0.0, 0.0, 1.0, 0.0, 85.0, 0.0, 40.0, 0.0, 34.0, 0.0, 1.0, 4.0, 8.0, 24.0, 0.0, 34.0, 0.0, 77.0, 15.0, 20.0, 0.0, 0.0, 161.0, 0.0, 0.0, 71.0, 82.0, 18.0, 10.0, 34.0, 0.0, 47.0, 24.0, 14.0, 0.0, 0.0, 95.0, 0.0, 0.0, 46.0, 130.0, 0.0, 0.0, 146.0, 2.0, 0.0, 0.0, 33.0, 141.0, 88.0, 0.0, 0.0, 7.0, 9.0, 0.0, 39.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 63.0, 0.0, 0.0, 29.0, 23.0, 0.0, 22.0, 0.0, 0.0, 0.0, 47.0, 76.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 29.0, 11.0, 32.0, 78.0, 60.0, 39.0, 0.0, 0.0, 0.0, 1.0, 105.0, 0.0, 50.0, 0.0, 0.0, 144.0, 0.0, 0.0, 63.0, 130.0, 79.0, 1.0, 0.0, 30.0, 99.0, 14.0, 19.0, 24.0, 0.0, 3.0, 13.0, 0.0, 14.0, 0.0, 0.0, 15.0, 57.0, 0.0, 94.0, 25.0, 0.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2096045978537273, "mean_inference_ms": 3.419188908718823, "mean_action_processing_ms": 0.4832160205267986, "mean_env_wait_ms": 0.7464373500270982, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010259344120218295, "StateBufferConnector_ms": 0.005290604601002702, "ViewRequirementAgentConnector_ms": 0.19227266311645508}, "num_episodes": 27, "episode_return_max": 225.8999999999995, "episode_return_min": -201.50000000000026, "episode_return_mean": 28.77070707070694, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.0247272523899, "num_env_steps_trained_throughput_per_sec": 320.0247272523899, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 13702.783, "restore_workers_time_ms": 0.028, "training_step_time_ms": 13702.621, "sample_time_ms": 2647.859, "learn_time_ms": 11035.488, "learn_throughput": 362.467, "synch_weights_time_ms": 15.942}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "c52aa_00000", "date": "2024-08-12_23-48-58", "timestamp": 1723520938, "time_this_iter_s": 12.540761232376099, "time_total_s": 68.81141304969788, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 68.81141304969788, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 64.53333333333335, "ram_util_percent": 83.00555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.305926874390355, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.1476781760574015, "policy_loss": -0.0014158958073941961, "vf_loss": 5.148538864352716, "vf_explained_var": -0.0019447982311248779, "kl": 0.0111039856169673, "entropy": 1.4956527590751647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2633786102963818, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.383273282883659, "policy_loss": -0.00393929787894228, "vf_loss": 3.3868978875023976, "vf_explained_var": -5.189293906802223e-05, "kl": 0.012587686711848905, "entropy": 1.5633633688013389, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 225.8999999999995, "episode_reward_min": -349.59999999999997, "episode_reward_mean": 18.727999999999863, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -288.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.6, "predator_policy": 202.0}, "policy_reward_mean": {"prey_policy": -19.041000000000043, "predator_policy": 28.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-38.799999999999734, 65.8000000000001, 40.9000000000003, 105.19999999999862, -121.90000000000046, 44.200000000000315, 52.40000000000046, -118.30000000000078, 195.59999999999997, -28.699999999999783, 225.8999999999995, 36.50000000000014, -61.10000000000053, 65.20000000000002, 165.09999999999857, 63.40000000000015, 160.39999999999944, 6.800000000000191, 38.30000000000033, 9.800000000000104, 71.29999999999973, 61.00000000000027, 98.19999999999942, 1.400000000000272, -55.800000000000026, 20.700000000000003, -65.10000000000005, 111.9999999999985, -50.60000000000076, 151.39999999999938, 118.69999999999996, 11.400000000000166, 39.000000000000256, 4.800000000000124, 40.0000000000003, -127.50000000000065, 59.80000000000043, -137.5000000000009, 67.90000000000023, -102.80000000000035, -32.199999999999775, 223.09999999999937, 182.1999999999993, -20.49999999999961, 170.49999999999895, 40.0000000000003, 169.69999999999953, -9.499999999999806, 25.20000000000018, 19.199999999999964, 15.800000000000267, 68.80000000000038, -182.0000000000012, 38.90000000000028, 74.20000000000016, 77.7999999999999, 9.099999999999989, 40.0000000000003, 46.30000000000034, 84.99999999999898, 23.500000000000096, 89.89999999999995, -56.89999999999991, 11.499999999999929, 40.0000000000003, -105.7000000000005, 17.400000000000077, 153.39999999999966, -201.50000000000026, -29.299999999999564, -122.10000000000039, 72.20000000000002, 1.3000000000001606, 76.59999999999951, 108.0999999999989, 66.50000000000023, 111.89999999999947, 84.99999999999898, -31.099999999999675, 33.50000000000005, 12.499999999999988, 29.900000000000123, 61.29999999999933, -42.000000000000284, -349.59999999999997, 16.89999999999992, 30.100000000000147, -105.0000000000004, -172.2999999999999, 7.999999999999979, 40.90000000000031, -171.60000000000045, -76.90000000000012, -46.39999999999968, 36.700000000000294, -69.90000000000055, 91.29999999999855, -127.79999999999993, 49.60000000000037, 46.300000000000395], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-47.199999999999875, -97.60000000000012, 20.000000000000014, 12.800000000000104, 20.90000000000003, 20.000000000000014, 92.89999999999932, 5.299999999999981, -174.70000000000024, -137.20000000000022, 18.19999999999999, 20.000000000000014, 31.40000000000019, 20.000000000000014, -202.29999999999998, -85.00000000000063, 11.599999999999994, 112.99999999999997, -25.59999999999991, -81.10000000000036, 38.30000000000013, 185.6, -53.19999999999998, -4.299999999999811, 20.000000000000014, -204.10000000000028, 137.0, -230.8000000000004, 73.99999999999949, 91.09999999999951, 46.69999999999996, -37.30000000000013, 139.39999999999995, 20.000000000000014, 30.80000000000003, -109.0000000000001, -21.69999999999984, 20.000000000000014, 27.200000000000024, -51.39999999999992, 46.70000000000012, 23.60000000000008, 1.0999999999999819, 47.90000000000012, 20.000000000000014, 54.20000000000007, -21.099999999999895, -11.500000000000021, -6.100000000000016, -141.7, -21.999999999999744, 22.700000000000063, 21.80000000000004, -247.90000000000032, 79.39999999999927, 32.60000000000019, -76.90000000000066, -126.70000000000039, 1.6999999999999689, 121.69999999999996, -51.3999999999999, 136.1000000000001, -61.900000000000766, 2.3000000000000913, 4.999999999999956, 20.000000000000014, -179.50000000000057, 89.29999999999981, 20.000000000000014, 20.000000000000014, -76.60000000000053, -226.90000000000023, 20.000000000000014, 39.800000000000196, -288.6999999999996, 3.1999999999999615, 20.90000000000003, 46.99999999999998, -72.10000000000002, -204.7000000000005, 15.799999999999963, -136.0000000000002, 168.19999999999993, 47.89999999999997, 159.49999999999994, 13.699999999999987, -13.599999999999868, -61.90000000000064, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.70000000000005, -112.30000000000015, 39.80000000000025, 20.000000000000014, -23.79999999999984, 20.000000000000014, -23.799999999999756, 20.000000000000014, -26.200000000000024, 22.700000000000063, 46.10000000000011, -142.90000000000066, -162.10000000000053, 20.000000000000014, 17.899999999999988, 28.100000000000037, 46.09999999999997, 57.80000000000021, 20.000000000000014, -5.1999999999999265, -27.69999999999984, 20.000000000000014, 20.000000000000014, 26.30000000000013, 20.000000000000014, 20.000000000000014, 65.00000000000014, -50.49999999999985, 20.000000000000014, -26.500000000000007, 73.39999999999995, -125.2000000000001, -69.70000000000007, 20.000000000000014, -47.499999999999794, 20.000000000000014, 20.000000000000014, -55.89999999999993, -155.80000000000013, 20.000000000000014, -52.59999999999985, 48.80000000000015, 104.59999999999997, -178.6000000000001, -166.90000000000032, 20.000000000000014, -112.30000000000051, -93.40000000000076, -237.7000000000001, 49.40000000000021, 21.80000000000001, -136.30000000000018, 8.600000000000001, 50.000000000000185, -6.399999999999951, 64.10000000000021, 20.000000000000053, 20.000000000000014, 30.500000000000192, 64.40000000000003, 33.500000000000085, 20.000000000000014, 65.00000000000014, -100.30000000000052, -2.799999999999972, -144.70000000000002, 84.19999999999969, 20.000000000000014, -32.49999999999976, -0.10000000000003478, 20.000000000000014, -5.799999999999928, 7.0999999999999766, -13.900000000000004, -144.09999999999997, -229.90000000000012, -288.7000000000003, 20.000000000000014, -24.099999999999746, 20.000000000000014, 1.0999999999999759, -135.4000000000002, -97.6000000000003, -85.0, -238.30000000000007, 18.80000000000003, -38.799999999999756, 20.000000000000014, 20.90000000000003, -69.3999999999999, -278.19999999999965, -17.5, -162.40000000000023, -61.89999999999992, -74.50000000000078, 20.000000000000014, 13.699999999999946, -60.10000000000051, -137.8000000000003, 41.60000000000025, 49.70000000000024, -95.50000000000009, -284.30000000000024, 20.000000000000014, 2.5999999999999805, 26.300000000000114, 20.000000000000014], "policy_predator_policy_reward": [106.0, 0.0, 32.0, 1.0, 0.0, 0.0, 0.0, 7.0, 145.0, 45.0, 6.0, 0.0, 0.0, 1.0, 53.0, 116.0, 51.0, 20.0, 55.0, 23.0, 0.0, 2.0, 89.0, 5.0, 90.0, 33.0, 121.0, 38.0, 0.0, 0.0, 54.0, 0.0, 0.0, 1.0, 0.0, 85.0, 0.0, 40.0, 0.0, 34.0, 0.0, 1.0, 4.0, 8.0, 24.0, 0.0, 34.0, 0.0, 77.0, 15.0, 20.0, 0.0, 0.0, 161.0, 0.0, 0.0, 71.0, 82.0, 18.0, 10.0, 34.0, 0.0, 47.0, 24.0, 14.0, 0.0, 0.0, 95.0, 0.0, 0.0, 46.0, 130.0, 0.0, 0.0, 146.0, 2.0, 0.0, 0.0, 33.0, 141.0, 88.0, 0.0, 0.0, 7.0, 9.0, 0.0, 39.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 63.0, 0.0, 0.0, 29.0, 23.0, 0.0, 22.0, 0.0, 0.0, 0.0, 47.0, 76.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 29.0, 11.0, 32.0, 78.0, 60.0, 39.0, 0.0, 0.0, 0.0, 1.0, 105.0, 0.0, 50.0, 0.0, 0.0, 144.0, 0.0, 0.0, 63.0, 130.0, 79.0, 1.0, 0.0, 30.0, 99.0, 14.0, 19.0, 24.0, 0.0, 3.0, 13.0, 0.0, 14.0, 0.0, 0.0, 15.0, 57.0, 0.0, 94.0, 25.0, 0.0, 0.0, 10.0, 1.0, 59.0, 102.0, 14.0, 0.0, 169.0, 21.0, 0.0, 9.0, 0.0, 6.0, 122.0, 0.0, 151.0, 0.0, 28.0, 0.0, 0.0, 151.0, 25.0, 101.0, 2.0, 0.0, 90.0, 3.0, 0.0, 37.0, 91.0, 0.0, 0.0, 202.0, 50.0, 15.0, 12.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1900882729843592, "mean_inference_ms": 3.3624919367628343, "mean_action_processing_ms": 0.472732338103751, "mean_env_wait_ms": 0.7284892984501903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009708166122436523, "StateBufferConnector_ms": 0.005039095878601074, "ViewRequirementAgentConnector_ms": 0.17380273342132568}, "num_episodes": 18, "episode_return_max": 225.8999999999995, "episode_return_min": -349.59999999999997, "episode_return_mean": 18.727999999999863, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 270.2623298935429, "num_env_steps_trained_throughput_per_sec": 270.2623298935429, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 13885.727, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13885.582, "sample_time_ms": 2601.176, "learn_time_ms": 11264.234, "learn_throughput": 355.106, "synch_weights_time_ms": 16.298}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "c52aa_00000", "date": "2024-08-12_23-49-13", "timestamp": 1723520953, "time_this_iter_s": 14.861377954483032, "time_total_s": 83.67279100418091, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 83.67279100418091, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 72.96190476190475, "ram_util_percent": 83.64761904761906}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0312615291703315, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.915556816070799, "policy_loss": -0.002774247530079077, "vf_loss": 5.9177454691084606, "vf_explained_var": 0.0019606838150629923, "kl": 0.011711826177000229, "entropy": 1.5009058536675872, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.26859441240510296, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.744944500040125, "policy_loss": -0.004256204834759787, "vf_loss": 4.748826532136826, "vf_explained_var": 0.0002301057495137371, "kl": 0.014967720276049297, "entropy": 1.5416156152568796, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 223.09999999999937, "episode_reward_min": -349.59999999999997, "episode_reward_mean": 6.0819999999998995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -288.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.19999999999993, "predator_policy": 202.0}, "policy_reward_mean": {"prey_policy": -26.934000000000037, "predator_policy": 29.975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.30000000000033, 9.800000000000104, 71.29999999999973, 61.00000000000027, 98.19999999999942, 1.400000000000272, -55.800000000000026, 20.700000000000003, -65.10000000000005, 111.9999999999985, -50.60000000000076, 151.39999999999938, 118.69999999999996, 11.400000000000166, 39.000000000000256, 4.800000000000124, 40.0000000000003, -127.50000000000065, 59.80000000000043, -137.5000000000009, 67.90000000000023, -102.80000000000035, -32.199999999999775, 223.09999999999937, 182.1999999999993, -20.49999999999961, 170.49999999999895, 40.0000000000003, 169.69999999999953, -9.499999999999806, 25.20000000000018, 19.199999999999964, 15.800000000000267, 68.80000000000038, -182.0000000000012, 38.90000000000028, 74.20000000000016, 77.7999999999999, 9.099999999999989, 40.0000000000003, 46.30000000000034, 84.99999999999898, 23.500000000000096, 89.89999999999995, -56.89999999999991, 11.499999999999929, 40.0000000000003, -105.7000000000005, 17.400000000000077, 153.39999999999966, -201.50000000000026, -29.299999999999564, -122.10000000000039, 72.20000000000002, 1.3000000000001606, 76.59999999999951, 108.0999999999989, 66.50000000000023, 111.89999999999947, 84.99999999999898, -31.099999999999675, 33.50000000000005, 12.499999999999988, 29.900000000000123, 61.29999999999933, -42.000000000000284, -349.59999999999997, 16.89999999999992, 30.100000000000147, -105.0000000000004, -172.2999999999999, 7.999999999999979, 40.90000000000031, -171.60000000000045, -76.90000000000012, -46.39999999999968, 36.700000000000294, -69.90000000000055, 91.29999999999855, -127.79999999999993, 49.60000000000037, 46.300000000000395, 35.10000000000041, 19.999999999999975, 33.40000000000029, 86.79999999999882, 17.400000000000304, -13.899999999999633, 21.099999999998943, 40.0000000000003, -45.99999999999968, -44.499999999999886, -123.40000000000006, -103.59999999999981, -1.0999999999998127, 46.99999999999968, -183.10000000000014, -24.699999999999793, -3.4999999999997815, -163.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-21.69999999999984, 20.000000000000014, 27.200000000000024, -51.39999999999992, 46.70000000000012, 23.60000000000008, 1.0999999999999819, 47.90000000000012, 20.000000000000014, 54.20000000000007, -21.099999999999895, -11.500000000000021, -6.100000000000016, -141.7, -21.999999999999744, 22.700000000000063, 21.80000000000004, -247.90000000000032, 79.39999999999927, 32.60000000000019, -76.90000000000066, -126.70000000000039, 1.6999999999999689, 121.69999999999996, -51.3999999999999, 136.1000000000001, -61.900000000000766, 2.3000000000000913, 4.999999999999956, 20.000000000000014, -179.50000000000057, 89.29999999999981, 20.000000000000014, 20.000000000000014, -76.60000000000053, -226.90000000000023, 20.000000000000014, 39.800000000000196, -288.6999999999996, 3.1999999999999615, 20.90000000000003, 46.99999999999998, -72.10000000000002, -204.7000000000005, 15.799999999999963, -136.0000000000002, 168.19999999999993, 47.89999999999997, 159.49999999999994, 13.699999999999987, -13.599999999999868, -61.90000000000064, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.70000000000005, -112.30000000000015, 39.80000000000025, 20.000000000000014, -23.79999999999984, 20.000000000000014, -23.799999999999756, 20.000000000000014, -26.200000000000024, 22.700000000000063, 46.10000000000011, -142.90000000000066, -162.10000000000053, 20.000000000000014, 17.899999999999988, 28.100000000000037, 46.09999999999997, 57.80000000000021, 20.000000000000014, -5.1999999999999265, -27.69999999999984, 20.000000000000014, 20.000000000000014, 26.30000000000013, 20.000000000000014, 20.000000000000014, 65.00000000000014, -50.49999999999985, 20.000000000000014, -26.500000000000007, 73.39999999999995, -125.2000000000001, -69.70000000000007, 20.000000000000014, -47.499999999999794, 20.000000000000014, 20.000000000000014, -55.89999999999993, -155.80000000000013, 20.000000000000014, -52.59999999999985, 48.80000000000015, 104.59999999999997, -178.6000000000001, -166.90000000000032, 20.000000000000014, -112.30000000000051, -93.40000000000076, -237.7000000000001, 49.40000000000021, 21.80000000000001, -136.30000000000018, 8.600000000000001, 50.000000000000185, -6.399999999999951, 64.10000000000021, 20.000000000000053, 20.000000000000014, 30.500000000000192, 64.40000000000003, 33.500000000000085, 20.000000000000014, 65.00000000000014, -100.30000000000052, -2.799999999999972, -144.70000000000002, 84.19999999999969, 20.000000000000014, -32.49999999999976, -0.10000000000003478, 20.000000000000014, -5.799999999999928, 7.0999999999999766, -13.900000000000004, -144.09999999999997, -229.90000000000012, -288.7000000000003, 20.000000000000014, -24.099999999999746, 20.000000000000014, 1.0999999999999759, -135.4000000000002, -97.6000000000003, -85.0, -238.30000000000007, 18.80000000000003, -38.799999999999756, 20.000000000000014, 20.90000000000003, -69.3999999999999, -278.19999999999965, -17.5, -162.40000000000023, -61.89999999999992, -74.50000000000078, 20.000000000000014, 13.699999999999946, -60.10000000000051, -137.8000000000003, 41.60000000000025, 49.70000000000024, -95.50000000000009, -284.30000000000024, 20.000000000000014, 2.5999999999999805, 26.300000000000114, 20.000000000000014, 30.8000000000002, -24.700000000000017, -19.899999999999743, 20.90000000000003, 20.000000000000014, 7.400000000000006, 72.19999999999955, -3.3999999999999866, 20.000000000000014, -25.59999999999998, -82.90000000000073, 20.000000000000014, 7.999999999999709, -34.9, 20.000000000000014, 20.000000000000014, -21.099999999999845, -98.9, 33.20000000000012, -199.70000000000002, -51.099999999999916, -259.3, -75.39999999999998, -134.20000000000059, 6.500000000000041, -55.60000000000004, -19.00000000000007, 20.000000000000014, -195.50000000000003, -150.60000000000014, -17.19999999999976, -74.49999999999994, 41.60000000000018, -238.10000000000002, -194.19999999999993, -263.8], "policy_predator_policy_reward": [0.0, 40.0, 0.0, 34.0, 0.0, 1.0, 4.0, 8.0, 24.0, 0.0, 34.0, 0.0, 77.0, 15.0, 20.0, 0.0, 0.0, 161.0, 0.0, 0.0, 71.0, 82.0, 18.0, 10.0, 34.0, 0.0, 47.0, 24.0, 14.0, 0.0, 0.0, 95.0, 0.0, 0.0, 46.0, 130.0, 0.0, 0.0, 146.0, 2.0, 0.0, 0.0, 33.0, 141.0, 88.0, 0.0, 0.0, 7.0, 9.0, 0.0, 39.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 63.0, 0.0, 0.0, 29.0, 23.0, 0.0, 22.0, 0.0, 0.0, 0.0, 47.0, 76.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 29.0, 11.0, 32.0, 78.0, 60.0, 39.0, 0.0, 0.0, 0.0, 1.0, 105.0, 0.0, 50.0, 0.0, 0.0, 144.0, 0.0, 0.0, 63.0, 130.0, 79.0, 1.0, 0.0, 30.0, 99.0, 14.0, 19.0, 24.0, 0.0, 3.0, 13.0, 0.0, 14.0, 0.0, 0.0, 15.0, 57.0, 0.0, 94.0, 25.0, 0.0, 0.0, 10.0, 1.0, 59.0, 102.0, 14.0, 0.0, 169.0, 21.0, 0.0, 9.0, 0.0, 6.0, 122.0, 0.0, 151.0, 0.0, 28.0, 0.0, 0.0, 151.0, 25.0, 101.0, 2.0, 0.0, 90.0, 3.0, 0.0, 37.0, 91.0, 0.0, 0.0, 202.0, 50.0, 15.0, 12.0, 0.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 6.0, 0.0, 18.0, 23.0, 0.0, 0.0, 49.0, 18.0, 30.0, 0.0, 0.0, 67.0, 7.0, 7.0, 115.0, 40.0, 147.0, 0.0, 106.0, 36.0, 12.0, 0.0, 46.0, 17.0, 146.0, 30.0, 37.0, 180.0, 13.0, 148.0, 147.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.170989771699751, "mean_inference_ms": 3.2942876345661802, "mean_action_processing_ms": 0.4660134291721382, "mean_env_wait_ms": 0.722973911182205, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008923530578613281, "StateBufferConnector_ms": 0.005050539970397949, "ViewRequirementAgentConnector_ms": 0.19138622283935547}, "num_episodes": 18, "episode_return_max": 223.09999999999937, "episode_return_min": -349.59999999999997, "episode_return_mean": 6.0819999999998995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 276.71086407590434, "num_env_steps_trained_throughput_per_sec": 276.71086407590434, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 13967.128, "restore_workers_time_ms": 0.027, "training_step_time_ms": 13966.992, "sample_time_ms": 2733.998, "learn_time_ms": 11213.256, "learn_throughput": 356.721, "synch_weights_time_ms": 16.234}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "c52aa_00000", "date": "2024-08-12_23-49-28", "timestamp": 1723520968, "time_this_iter_s": 14.500437021255493, "time_total_s": 98.1732280254364, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c7e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 98.1732280254364, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 70.34, "ram_util_percent": 83.035}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1256473730559702, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.361602605083001, "policy_loss": -0.0044194549157052605, "vf_loss": 5.364987858010347, "vf_explained_var": 0.0003654064009429286, "kl": 0.02068410803399744, "entropy": 1.4241988248295254, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2597807902951168, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.835645460451722, "policy_loss": -0.0021454209726668463, "vf_loss": 5.837528202773402, "vf_explained_var": 0.00017462022720821321, "kl": 0.010507472714014752, "entropy": 1.510946931220867, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 223.09999999999937, "episode_reward_min": -349.59999999999997, "episode_reward_mean": -10.7730000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -392.80000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.19999999999993, "predator_policy": 287.0}, "policy_reward_mean": {"prey_policy": -43.566500000000026, "predator_policy": 38.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [59.80000000000043, -137.5000000000009, 67.90000000000023, -102.80000000000035, -32.199999999999775, 223.09999999999937, 182.1999999999993, -20.49999999999961, 170.49999999999895, 40.0000000000003, 169.69999999999953, -9.499999999999806, 25.20000000000018, 19.199999999999964, 15.800000000000267, 68.80000000000038, -182.0000000000012, 38.90000000000028, 74.20000000000016, 77.7999999999999, 9.099999999999989, 40.0000000000003, 46.30000000000034, 84.99999999999898, 23.500000000000096, 89.89999999999995, -56.89999999999991, 11.499999999999929, 40.0000000000003, -105.7000000000005, 17.400000000000077, 153.39999999999966, -201.50000000000026, -29.299999999999564, -122.10000000000039, 72.20000000000002, 1.3000000000001606, 76.59999999999951, 108.0999999999989, 66.50000000000023, 111.89999999999947, 84.99999999999898, -31.099999999999675, 33.50000000000005, 12.499999999999988, 29.900000000000123, 61.29999999999933, -42.000000000000284, -349.59999999999997, 16.89999999999992, 30.100000000000147, -105.0000000000004, -172.2999999999999, 7.999999999999979, 40.90000000000031, -171.60000000000045, -76.90000000000012, -46.39999999999968, 36.700000000000294, -69.90000000000055, 91.29999999999855, -127.79999999999993, 49.60000000000037, 46.300000000000395, 35.10000000000041, 19.999999999999975, 33.40000000000029, 86.79999999999882, 17.400000000000304, -13.899999999999633, 21.099999999998943, 40.0000000000003, -45.99999999999968, -44.499999999999886, -123.40000000000006, -103.59999999999981, -1.0999999999998127, 46.99999999999968, -183.10000000000014, -24.699999999999793, -3.4999999999997815, -163.0, -105.99999999999994, 33.400000000000205, 80.99999999999899, -102.10000000000008, -65.29999999999993, -72.80000000000018, 6.900000000000189, 30.80000000000029, -21.799999999999947, -177.7999999999999, -278.8000000000005, -112.70000000000067, -35.89999999999986, 54.90000000000017, -138.1, 83.19999999999908, -262.0000000000001, -123.40000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 39.800000000000196, -288.6999999999996, 3.1999999999999615, 20.90000000000003, 46.99999999999998, -72.10000000000002, -204.7000000000005, 15.799999999999963, -136.0000000000002, 168.19999999999993, 47.89999999999997, 159.49999999999994, 13.699999999999987, -13.599999999999868, -61.90000000000064, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.70000000000005, -112.30000000000015, 39.80000000000025, 20.000000000000014, -23.79999999999984, 20.000000000000014, -23.799999999999756, 20.000000000000014, -26.200000000000024, 22.700000000000063, 46.10000000000011, -142.90000000000066, -162.10000000000053, 20.000000000000014, 17.899999999999988, 28.100000000000037, 46.09999999999997, 57.80000000000021, 20.000000000000014, -5.1999999999999265, -27.69999999999984, 20.000000000000014, 20.000000000000014, 26.30000000000013, 20.000000000000014, 20.000000000000014, 65.00000000000014, -50.49999999999985, 20.000000000000014, -26.500000000000007, 73.39999999999995, -125.2000000000001, -69.70000000000007, 20.000000000000014, -47.499999999999794, 20.000000000000014, 20.000000000000014, -55.89999999999993, -155.80000000000013, 20.000000000000014, -52.59999999999985, 48.80000000000015, 104.59999999999997, -178.6000000000001, -166.90000000000032, 20.000000000000014, -112.30000000000051, -93.40000000000076, -237.7000000000001, 49.40000000000021, 21.80000000000001, -136.30000000000018, 8.600000000000001, 50.000000000000185, -6.399999999999951, 64.10000000000021, 20.000000000000053, 20.000000000000014, 30.500000000000192, 64.40000000000003, 33.500000000000085, 20.000000000000014, 65.00000000000014, -100.30000000000052, -2.799999999999972, -144.70000000000002, 84.19999999999969, 20.000000000000014, -32.49999999999976, -0.10000000000003478, 20.000000000000014, -5.799999999999928, 7.0999999999999766, -13.900000000000004, -144.09999999999997, -229.90000000000012, -288.7000000000003, 20.000000000000014, -24.099999999999746, 20.000000000000014, 1.0999999999999759, -135.4000000000002, -97.6000000000003, -85.0, -238.30000000000007, 18.80000000000003, -38.799999999999756, 20.000000000000014, 20.90000000000003, -69.3999999999999, -278.19999999999965, -17.5, -162.40000000000023, -61.89999999999992, -74.50000000000078, 20.000000000000014, 13.699999999999946, -60.10000000000051, -137.8000000000003, 41.60000000000025, 49.70000000000024, -95.50000000000009, -284.30000000000024, 20.000000000000014, 2.5999999999999805, 26.300000000000114, 20.000000000000014, 30.8000000000002, -24.700000000000017, -19.899999999999743, 20.90000000000003, 20.000000000000014, 7.400000000000006, 72.19999999999955, -3.3999999999999866, 20.000000000000014, -25.59999999999998, -82.90000000000073, 20.000000000000014, 7.999999999999709, -34.9, 20.000000000000014, 20.000000000000014, -21.099999999999845, -98.9, 33.20000000000012, -199.70000000000002, -51.099999999999916, -259.3, -75.39999999999998, -134.20000000000059, 6.500000000000041, -55.60000000000004, -19.00000000000007, 20.000000000000014, -195.50000000000003, -150.60000000000014, -17.19999999999976, -74.49999999999994, 41.60000000000018, -238.10000000000002, -194.19999999999993, -263.8, -122.80000000000005, -65.2, 7.399999999999965, 20.000000000000014, 17.900000000000013, 61.10000000000015, -172.30000000000013, -59.80000000000004, -310.1999999999998, -24.10000000000005, -215.50000000000028, 19.700000000000017, 29.00000000000024, -66.10000000000014, -24.699999999999825, -92.49999999999991, 27.200000000000134, -240.0000000000003, -111.99999999999991, -392.80000000000007, -229.90000000000046, -229.90000000000038, -88.30000000000027, -198.40000000000038, 17.900000000000013, -122.8000000000001, -167.00000000000009, 41.90000000000019, -115.00000000000001, -246.0999999999999, 63.200000000000195, 20.000000000000014, -310.70000000000016, -290.29999999999995, -126.7000000000001, -138.70000000000005], "policy_predator_policy_reward": [0.0, 0.0, 146.0, 2.0, 0.0, 0.0, 33.0, 141.0, 88.0, 0.0, 0.0, 7.0, 9.0, 0.0, 39.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 63.0, 0.0, 0.0, 29.0, 23.0, 0.0, 22.0, 0.0, 0.0, 0.0, 47.0, 76.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 29.0, 11.0, 32.0, 78.0, 60.0, 39.0, 0.0, 0.0, 0.0, 1.0, 105.0, 0.0, 50.0, 0.0, 0.0, 144.0, 0.0, 0.0, 63.0, 130.0, 79.0, 1.0, 0.0, 30.0, 99.0, 14.0, 19.0, 24.0, 0.0, 3.0, 13.0, 0.0, 14.0, 0.0, 0.0, 15.0, 57.0, 0.0, 94.0, 25.0, 0.0, 0.0, 10.0, 1.0, 59.0, 102.0, 14.0, 0.0, 169.0, 21.0, 0.0, 9.0, 0.0, 6.0, 122.0, 0.0, 151.0, 0.0, 28.0, 0.0, 0.0, 151.0, 25.0, 101.0, 2.0, 0.0, 90.0, 3.0, 0.0, 37.0, 91.0, 0.0, 0.0, 202.0, 50.0, 15.0, 12.0, 0.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 6.0, 0.0, 18.0, 23.0, 0.0, 0.0, 49.0, 18.0, 30.0, 0.0, 0.0, 67.0, 7.0, 7.0, 115.0, 40.0, 147.0, 0.0, 106.0, 36.0, 12.0, 0.0, 46.0, 17.0, 146.0, 30.0, 37.0, 180.0, 13.0, 148.0, 147.0, 22.0, 60.0, 6.0, 0.0, 0.0, 2.0, 92.0, 38.0, 96.0, 173.0, 63.0, 60.0, 0.0, 44.0, 75.0, 73.0, 90.0, 101.0, 287.0, 40.0, 6.0, 175.0, 116.0, 58.0, 68.0, 1.0, 63.0, 117.0, 148.0, 75.0, 0.0, 0.0, 242.0, 97.0, 97.0, 45.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1655401381476085, "mean_inference_ms": 3.254780228149213, "mean_action_processing_ms": 0.46512924721765375, "mean_env_wait_ms": 0.7220805511065126, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00918424129486084, "StateBufferConnector_ms": 0.005532383918762207, "ViewRequirementAgentConnector_ms": 0.19068551063537598}, "num_episodes": 18, "episode_return_max": 223.09999999999937, "episode_return_min": -349.59999999999997, "episode_return_mean": -10.7730000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.5311282405818, "num_env_steps_trained_throughput_per_sec": 329.5311282405818, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 13738.546, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13738.421, "sample_time_ms": 2640.151, "learn_time_ms": 11078.009, "learn_throughput": 361.076, "synch_weights_time_ms": 16.343}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "c52aa_00000", "date": "2024-08-12_23-49-40", "timestamp": 1723520980, "time_this_iter_s": 12.192026138305664, "time_total_s": 110.36525416374207, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 110.36525416374207, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 60.21111111111112, "ram_util_percent": 83.27222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0455286415520484, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.069522832814979, "policy_loss": -0.002882786373060847, "vf_loss": 5.071629565985745, "vf_explained_var": -0.0030346702646326137, "kl": 0.010347119633343269, "entropy": 1.3889928798826914, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27977974319229365, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.674156392819036, "policy_loss": -0.0018909276704545375, "vf_loss": 4.675690575756093, "vf_explained_var": 0.0027548960592380907, "kl": 0.014269416411906016, "entropy": 1.5298635046948832, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 153.39999999999966, "episode_reward_min": -349.59999999999997, "episode_reward_mean": -23.15200000000008, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -392.80000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 104.59999999999997, "predator_policy": 287.0}, "policy_reward_mean": {"prey_policy": -58.38600000000003, "predator_policy": 46.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [46.30000000000034, 84.99999999999898, 23.500000000000096, 89.89999999999995, -56.89999999999991, 11.499999999999929, 40.0000000000003, -105.7000000000005, 17.400000000000077, 153.39999999999966, -201.50000000000026, -29.299999999999564, -122.10000000000039, 72.20000000000002, 1.3000000000001606, 76.59999999999951, 108.0999999999989, 66.50000000000023, 111.89999999999947, 84.99999999999898, -31.099999999999675, 33.50000000000005, 12.499999999999988, 29.900000000000123, 61.29999999999933, -42.000000000000284, -349.59999999999997, 16.89999999999992, 30.100000000000147, -105.0000000000004, -172.2999999999999, 7.999999999999979, 40.90000000000031, -171.60000000000045, -76.90000000000012, -46.39999999999968, 36.700000000000294, -69.90000000000055, 91.29999999999855, -127.79999999999993, 49.60000000000037, 46.300000000000395, 35.10000000000041, 19.999999999999975, 33.40000000000029, 86.79999999999882, 17.400000000000304, -13.899999999999633, 21.099999999998943, 40.0000000000003, -45.99999999999968, -44.499999999999886, -123.40000000000006, -103.59999999999981, -1.0999999999998127, 46.99999999999968, -183.10000000000014, -24.699999999999793, -3.4999999999997815, -163.0, -105.99999999999994, 33.400000000000205, 80.99999999999899, -102.10000000000008, -65.29999999999993, -72.80000000000018, 6.900000000000189, 30.80000000000029, -21.799999999999947, -177.7999999999999, -278.8000000000005, -112.70000000000067, -35.89999999999986, 54.90000000000017, -138.1, 83.19999999999908, -262.0000000000001, -123.40000000000018, 40.0000000000003, -77.00000000000071, -17.59999999999964, 127.59999999999846, 32.200000000000415, -187.1000000000005, -15.19999999999967, -124.10000000000065, -38.599999999999774, 52.90000000000009, 40.50000000000039, 34.80000000000024, -0.699999999999743, -135.000000000001, -111.1000000000007, -85.40000000000005, 40.0000000000003, -35.79999999999973, -7.899999999999821, -77.79999999999981, 42.70000000000034, 62.40000000000047], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [26.30000000000013, 20.000000000000014, 20.000000000000014, 65.00000000000014, -50.49999999999985, 20.000000000000014, -26.500000000000007, 73.39999999999995, -125.2000000000001, -69.70000000000007, 20.000000000000014, -47.499999999999794, 20.000000000000014, 20.000000000000014, -55.89999999999993, -155.80000000000013, 20.000000000000014, -52.59999999999985, 48.80000000000015, 104.59999999999997, -178.6000000000001, -166.90000000000032, 20.000000000000014, -112.30000000000051, -93.40000000000076, -237.7000000000001, 49.40000000000021, 21.80000000000001, -136.30000000000018, 8.600000000000001, 50.000000000000185, -6.399999999999951, 64.10000000000021, 20.000000000000053, 20.000000000000014, 30.500000000000192, 64.40000000000003, 33.500000000000085, 20.000000000000014, 65.00000000000014, -100.30000000000052, -2.799999999999972, -144.70000000000002, 84.19999999999969, 20.000000000000014, -32.49999999999976, -0.10000000000003478, 20.000000000000014, -5.799999999999928, 7.0999999999999766, -13.900000000000004, -144.09999999999997, -229.90000000000012, -288.7000000000003, 20.000000000000014, -24.099999999999746, 20.000000000000014, 1.0999999999999759, -135.4000000000002, -97.6000000000003, -85.0, -238.30000000000007, 18.80000000000003, -38.799999999999756, 20.000000000000014, 20.90000000000003, -69.3999999999999, -278.19999999999965, -17.5, -162.40000000000023, -61.89999999999992, -74.50000000000078, 20.000000000000014, 13.699999999999946, -60.10000000000051, -137.8000000000003, 41.60000000000025, 49.70000000000024, -95.50000000000009, -284.30000000000024, 20.000000000000014, 2.5999999999999805, 26.300000000000114, 20.000000000000014, 30.8000000000002, -24.700000000000017, -19.899999999999743, 20.90000000000003, 20.000000000000014, 7.400000000000006, 72.19999999999955, -3.3999999999999866, 20.000000000000014, -25.59999999999998, -82.90000000000073, 20.000000000000014, 7.999999999999709, -34.9, 20.000000000000014, 20.000000000000014, -21.099999999999845, -98.9, 33.20000000000012, -199.70000000000002, -51.099999999999916, -259.3, -75.39999999999998, -134.20000000000059, 6.500000000000041, -55.60000000000004, -19.00000000000007, 20.000000000000014, -195.50000000000003, -150.60000000000014, -17.19999999999976, -74.49999999999994, 41.60000000000018, -238.10000000000002, -194.19999999999993, -263.8, -122.80000000000005, -65.2, 7.399999999999965, 20.000000000000014, 17.900000000000013, 61.10000000000015, -172.30000000000013, -59.80000000000004, -310.1999999999998, -24.10000000000005, -215.50000000000028, 19.700000000000017, 29.00000000000024, -66.10000000000014, -24.699999999999825, -92.49999999999991, 27.200000000000134, -240.0000000000003, -111.99999999999991, -392.80000000000007, -229.90000000000046, -229.90000000000038, -88.30000000000027, -198.40000000000038, 17.900000000000013, -122.8000000000001, -167.00000000000009, 41.90000000000019, -115.00000000000001, -246.0999999999999, 63.200000000000195, 20.000000000000014, -310.70000000000016, -290.29999999999995, -126.7000000000001, -138.70000000000005, 20.000000000000014, 20.000000000000014, -383.1999999999998, -38.799999999999756, -66.10000000000079, -38.4999999999999, 56.900000000000226, 67.6999999999999, 28.100000000000147, -43.900000000000006, -65.20000000000039, -268.90000000000003, 21.80000000000004, -208.0000000000005, -66.10000000000059, -316.0, 20.000000000000014, -208.60000000000034, 20.000000000000014, -378.1, -17.49999999999986, 20.000000000000014, -12.099999999999874, 20.900000000000027, -0.9999999999999846, -21.699999999999754, -124.90000000000043, -96.10000000000053, -130.80000000000075, -349.2999999999997, -198.1, -28.299999999999834, 20.000000000000014, 20.000000000000014, -15.099999999999842, -69.70000000000041, 20.000000000000014, -130.90000000000015, -79.2999999999999, -53.50000000000001, 22.700000000000053, 20.000000000000014, 32.90000000000023, 24.500000000000092], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 25.0, 29.0, 11.0, 32.0, 78.0, 60.0, 39.0, 0.0, 0.0, 0.0, 1.0, 105.0, 0.0, 50.0, 0.0, 0.0, 144.0, 0.0, 0.0, 63.0, 130.0, 79.0, 1.0, 0.0, 30.0, 99.0, 14.0, 19.0, 24.0, 0.0, 3.0, 13.0, 0.0, 14.0, 0.0, 0.0, 15.0, 57.0, 0.0, 94.0, 25.0, 0.0, 0.0, 10.0, 1.0, 59.0, 102.0, 14.0, 0.0, 169.0, 21.0, 0.0, 9.0, 0.0, 6.0, 122.0, 0.0, 151.0, 0.0, 28.0, 0.0, 0.0, 151.0, 25.0, 101.0, 2.0, 0.0, 90.0, 3.0, 0.0, 37.0, 91.0, 0.0, 0.0, 202.0, 50.0, 15.0, 12.0, 0.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 6.0, 0.0, 18.0, 23.0, 0.0, 0.0, 49.0, 18.0, 30.0, 0.0, 0.0, 67.0, 7.0, 7.0, 115.0, 40.0, 147.0, 0.0, 106.0, 36.0, 12.0, 0.0, 46.0, 17.0, 146.0, 30.0, 37.0, 180.0, 13.0, 148.0, 147.0, 22.0, 60.0, 6.0, 0.0, 0.0, 2.0, 92.0, 38.0, 96.0, 173.0, 63.0, 60.0, 0.0, 44.0, 75.0, 73.0, 90.0, 101.0, 287.0, 40.0, 6.0, 175.0, 116.0, 58.0, 68.0, 1.0, 63.0, 117.0, 148.0, 75.0, 0.0, 0.0, 242.0, 97.0, 97.0, 45.0, 0.0, 0.0, 162.0, 183.0, 57.0, 30.0, 1.0, 2.0, 0.0, 48.0, 0.0, 147.0, 86.0, 85.0, 125.0, 133.0, 121.0, 29.0, 228.0, 183.0, 38.0, 0.0, 26.0, 0.0, 22.0, 0.0, 20.0, 66.0, 185.0, 184.0, 25.0, 116.0, 0.0, 0.0, 49.0, 0.0, 10.0, 93.0, 55.0, 0.0, 0.0, 0.0, 3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1598732514812902, "mean_inference_ms": 3.214931233198962, "mean_action_processing_ms": 0.46065361916182224, "mean_env_wait_ms": 0.7170080744861588, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007471203804016113, "StateBufferConnector_ms": 0.0059081315994262695, "ViewRequirementAgentConnector_ms": 0.1800597906112671}, "num_episodes": 22, "episode_return_max": 153.39999999999966, "episode_return_min": -349.59999999999997, "episode_return_mean": -23.15200000000008, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.1415137313923, "num_env_steps_trained_throughput_per_sec": 334.1415137313923, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 13542.15, "restore_workers_time_ms": 0.025, "training_step_time_ms": 13542.033, "sample_time_ms": 2540.881, "learn_time_ms": 10981.757, "learn_throughput": 364.24, "synch_weights_time_ms": 15.794}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "c52aa_00000", "date": "2024-08-12_23-49-52", "timestamp": 1723520992, "time_this_iter_s": 12.008384943008423, "time_total_s": 122.37363910675049, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 122.37363910675049, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 61.98235294117647, "ram_util_percent": 83.77058823529413}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9772520573799888, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.222989404264581, "policy_loss": -6.776436714938393e-05, "vf_loss": 8.222804074312643, "vf_explained_var": 0.0009378233283915848, "kl": 0.0033747331011881234, "entropy": 1.4145922132900783, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2992436814816698, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.26892168912938, "policy_loss": -0.001849375586345713, "vf_loss": 7.270263438502317, "vf_explained_var": 0.0007962147394816081, "kl": 0.02030530708541728, "entropy": 1.4856098144773453, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 127.59999999999846, "episode_reward_min": -358.5999999999998, "episode_reward_mean": -59.91300000000008, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -421.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 72.19999999999955, "predator_policy": 299.0}, "policy_reward_mean": {"prey_policy": -89.42150000000005, "predator_policy": 59.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.900000000000123, 61.29999999999933, -42.000000000000284, -349.59999999999997, 16.89999999999992, 30.100000000000147, -105.0000000000004, -172.2999999999999, 7.999999999999979, 40.90000000000031, -171.60000000000045, -76.90000000000012, -46.39999999999968, 36.700000000000294, -69.90000000000055, 91.29999999999855, -127.79999999999993, 49.60000000000037, 46.300000000000395, 35.10000000000041, 19.999999999999975, 33.40000000000029, 86.79999999999882, 17.400000000000304, -13.899999999999633, 21.099999999998943, 40.0000000000003, -45.99999999999968, -44.499999999999886, -123.40000000000006, -103.59999999999981, -1.0999999999998127, 46.99999999999968, -183.10000000000014, -24.699999999999793, -3.4999999999997815, -163.0, -105.99999999999994, 33.400000000000205, 80.99999999999899, -102.10000000000008, -65.29999999999993, -72.80000000000018, 6.900000000000189, 30.80000000000029, -21.799999999999947, -177.7999999999999, -278.8000000000005, -112.70000000000067, -35.89999999999986, 54.90000000000017, -138.1, 83.19999999999908, -262.0000000000001, -123.40000000000018, 40.0000000000003, -77.00000000000071, -17.59999999999964, 127.59999999999846, 32.200000000000415, -187.1000000000005, -15.19999999999967, -124.10000000000065, -38.599999999999774, 52.90000000000009, 40.50000000000039, 34.80000000000024, -0.699999999999743, -135.000000000001, -111.1000000000007, -85.40000000000005, 40.0000000000003, -35.79999999999973, -7.899999999999821, -77.79999999999981, 42.70000000000034, 62.40000000000047, -358.5999999999998, -186.70000000000033, -147.8000000000009, -333.09999999999997, -60.30000000000059, -226.40000000000043, -225.20000000000036, -239.70000000000005, -10.699999999999871, -59.299999999999855, -86.70000000000007, -81.59999999999965, -34.19999999999985, -237.6999999999998, -72.3000000000005, -116.60000000000039, -218.90000000000055, -57.19999999999987, -189.80000000000064, -6.200000000000047, 57.900000000000524, -166.90000000000003, -130.10000000000053], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.10000000000003478, 20.000000000000014, -5.799999999999928, 7.0999999999999766, -13.900000000000004, -144.09999999999997, -229.90000000000012, -288.7000000000003, 20.000000000000014, -24.099999999999746, 20.000000000000014, 1.0999999999999759, -135.4000000000002, -97.6000000000003, -85.0, -238.30000000000007, 18.80000000000003, -38.799999999999756, 20.000000000000014, 20.90000000000003, -69.3999999999999, -278.19999999999965, -17.5, -162.40000000000023, -61.89999999999992, -74.50000000000078, 20.000000000000014, 13.699999999999946, -60.10000000000051, -137.8000000000003, 41.60000000000025, 49.70000000000024, -95.50000000000009, -284.30000000000024, 20.000000000000014, 2.5999999999999805, 26.300000000000114, 20.000000000000014, 30.8000000000002, -24.700000000000017, -19.899999999999743, 20.90000000000003, 20.000000000000014, 7.400000000000006, 72.19999999999955, -3.3999999999999866, 20.000000000000014, -25.59999999999998, -82.90000000000073, 20.000000000000014, 7.999999999999709, -34.9, 20.000000000000014, 20.000000000000014, -21.099999999999845, -98.9, 33.20000000000012, -199.70000000000002, -51.099999999999916, -259.3, -75.39999999999998, -134.20000000000059, 6.500000000000041, -55.60000000000004, -19.00000000000007, 20.000000000000014, -195.50000000000003, -150.60000000000014, -17.19999999999976, -74.49999999999994, 41.60000000000018, -238.10000000000002, -194.19999999999993, -263.8, -122.80000000000005, -65.2, 7.399999999999965, 20.000000000000014, 17.900000000000013, 61.10000000000015, -172.30000000000013, -59.80000000000004, -310.1999999999998, -24.10000000000005, -215.50000000000028, 19.700000000000017, 29.00000000000024, -66.10000000000014, -24.699999999999825, -92.49999999999991, 27.200000000000134, -240.0000000000003, -111.99999999999991, -392.80000000000007, -229.90000000000046, -229.90000000000038, -88.30000000000027, -198.40000000000038, 17.900000000000013, -122.8000000000001, -167.00000000000009, 41.90000000000019, -115.00000000000001, -246.0999999999999, 63.200000000000195, 20.000000000000014, -310.70000000000016, -290.29999999999995, -126.7000000000001, -138.70000000000005, 20.000000000000014, 20.000000000000014, -383.1999999999998, -38.799999999999756, -66.10000000000079, -38.4999999999999, 56.900000000000226, 67.6999999999999, 28.100000000000147, -43.900000000000006, -65.20000000000039, -268.90000000000003, 21.80000000000004, -208.0000000000005, -66.10000000000059, -316.0, 20.000000000000014, -208.60000000000034, 20.000000000000014, -378.1, -17.49999999999986, 20.000000000000014, -12.099999999999874, 20.900000000000027, -0.9999999999999846, -21.699999999999754, -124.90000000000043, -96.10000000000053, -130.80000000000075, -349.2999999999997, -198.1, -28.299999999999834, 20.000000000000014, 20.000000000000014, -15.099999999999842, -69.70000000000041, 20.000000000000014, -130.90000000000015, -79.2999999999999, -53.50000000000001, 22.700000000000053, 20.000000000000014, 32.90000000000023, 24.500000000000092, -307.6000000000001, -388.0, -310.60000000000014, -87.10000000000002, -119.20000000000007, -150.60000000000053, -366.2, -421.9, -196.30000000000038, 20.000000000000014, -368.50000000000006, -103.90000000000028, -288.79999999999995, -198.40000000000038, -186.7, -269.0, -114.70000000000027, 20.000000000000014, -153.9000000000003, -21.399999999999977, -93.39999999999995, -49.30000000000001, -143.80000000000007, -20.799999999999898, -5.199999999999969, -103.0000000000003, -169.0, -208.69999999999993, -179.8000000000002, -53.50000000000019, -70.60000000000048, -189.99999999999991, -187.90000000000038, -211.00000000000014, -100.30000000000052, -70.90000000000015, -162.70000000000033, -135.10000000000036, -68.20000000000002, 20.000000000000014, 23.000000000000224, 29.90000000000018, -189.99999999999994, -219.89999999999995, -138.7000000000003, -261.40000000000015], "policy_predator_policy_reward": [0.0, 10.0, 1.0, 59.0, 102.0, 14.0, 0.0, 169.0, 21.0, 0.0, 9.0, 0.0, 6.0, 122.0, 0.0, 151.0, 0.0, 28.0, 0.0, 0.0, 151.0, 25.0, 101.0, 2.0, 0.0, 90.0, 3.0, 0.0, 37.0, 91.0, 0.0, 0.0, 202.0, 50.0, 15.0, 12.0, 0.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 6.0, 0.0, 18.0, 23.0, 0.0, 0.0, 49.0, 18.0, 30.0, 0.0, 0.0, 67.0, 7.0, 7.0, 115.0, 40.0, 147.0, 0.0, 106.0, 36.0, 12.0, 0.0, 46.0, 17.0, 146.0, 30.0, 37.0, 180.0, 13.0, 148.0, 147.0, 22.0, 60.0, 6.0, 0.0, 0.0, 2.0, 92.0, 38.0, 96.0, 173.0, 63.0, 60.0, 0.0, 44.0, 75.0, 73.0, 90.0, 101.0, 287.0, 40.0, 6.0, 175.0, 116.0, 58.0, 68.0, 1.0, 63.0, 117.0, 148.0, 75.0, 0.0, 0.0, 242.0, 97.0, 97.0, 45.0, 0.0, 0.0, 162.0, 183.0, 57.0, 30.0, 1.0, 2.0, 0.0, 48.0, 0.0, 147.0, 86.0, 85.0, 125.0, 133.0, 121.0, 29.0, 228.0, 183.0, 38.0, 0.0, 26.0, 0.0, 22.0, 0.0, 20.0, 66.0, 185.0, 184.0, 25.0, 116.0, 0.0, 0.0, 49.0, 0.0, 10.0, 93.0, 55.0, 0.0, 0.0, 0.0, 3.0, 2.0, 152.0, 185.0, 51.0, 160.0, 83.0, 39.0, 156.0, 299.0, 13.0, 103.0, 96.0, 150.0, 173.0, 89.0, 120.0, 96.0, 2.0, 82.0, 13.0, 103.0, 56.0, 0.0, 0.0, 83.0, 0.0, 74.0, 0.0, 140.0, 120.0, 41.0, 24.0, 120.0, 57.0, 123.0, 113.0, 1.0, 29.0, 79.0, 0.0, 42.0, 5.0, 0.0, 135.0, 108.0, 133.0, 137.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1603308294506665, "mean_inference_ms": 3.1675678664785005, "mean_action_processing_ms": 0.45900771062952933, "mean_env_wait_ms": 0.71561943719475, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007357358932495117, "StateBufferConnector_ms": 0.00465083122253418, "ViewRequirementAgentConnector_ms": 0.19831526279449463}, "num_episodes": 23, "episode_return_max": 127.59999999999846, "episode_return_min": -358.5999999999998, "episode_return_mean": -59.91300000000008, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.66014701030593, "num_env_steps_trained_throughput_per_sec": 324.66014701030593, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 13419.994, "restore_workers_time_ms": 0.024, "training_step_time_ms": 13419.883, "sample_time_ms": 2506.406, "learn_time_ms": 10894.715, "learn_throughput": 367.151, "synch_weights_time_ms": 15.427}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "c52aa_00000", "date": "2024-08-12_23-50-05", "timestamp": 1723521005, "time_this_iter_s": 12.361280679702759, "time_total_s": 134.73491978645325, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c5670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 134.73491978645325, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 61.711764705882345, "ram_util_percent": 82.98823529411764}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9369794995144561, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.177523980569587, "policy_loss": -0.005525939814283182, "vf_loss": 8.182373104145919, "vf_explained_var": 0.001027643775183057, "kl": 0.018048706043879797, "entropy": 1.4582971540077654, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5139575953166636, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.570276992535465, "policy_loss": -0.005378355791117188, "vf_loss": 8.574823530641183, "vf_explained_var": 0.0003640556461596615, "kl": 0.02218102840900431, "entropy": 1.3857644770511244, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 227.29999999999953, "episode_reward_min": -467.0, "episode_reward_mean": -66.02500000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -876.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 72.19999999999955, "predator_policy": 582.0}, "policy_reward_mean": {"prey_policy": -126.53250000000004, "predator_policy": 93.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [46.300000000000395, 35.10000000000041, 19.999999999999975, 33.40000000000029, 86.79999999999882, 17.400000000000304, -13.899999999999633, 21.099999999998943, 40.0000000000003, -45.99999999999968, -44.499999999999886, -123.40000000000006, -103.59999999999981, -1.0999999999998127, 46.99999999999968, -183.10000000000014, -24.699999999999793, -3.4999999999997815, -163.0, -105.99999999999994, 33.400000000000205, 80.99999999999899, -102.10000000000008, -65.29999999999993, -72.80000000000018, 6.900000000000189, 30.80000000000029, -21.799999999999947, -177.7999999999999, -278.8000000000005, -112.70000000000067, -35.89999999999986, 54.90000000000017, -138.1, 83.19999999999908, -262.0000000000001, -123.40000000000018, 40.0000000000003, -77.00000000000071, -17.59999999999964, 127.59999999999846, 32.200000000000415, -187.1000000000005, -15.19999999999967, -124.10000000000065, -38.599999999999774, 52.90000000000009, 40.50000000000039, 34.80000000000024, -0.699999999999743, -135.000000000001, -111.1000000000007, -85.40000000000005, 40.0000000000003, -35.79999999999973, -7.899999999999821, -77.79999999999981, 42.70000000000034, 62.40000000000047, -358.5999999999998, -186.70000000000033, -147.8000000000009, -333.09999999999997, -60.30000000000059, -226.40000000000043, -225.20000000000036, -239.70000000000005, -10.699999999999871, -59.299999999999855, -86.70000000000007, -81.59999999999965, -34.19999999999985, -237.6999999999998, -72.3000000000005, -116.60000000000039, -218.90000000000055, -57.19999999999987, -189.80000000000064, -6.200000000000047, 57.900000000000524, -166.90000000000003, -130.10000000000053, -12.699999999999736, 71.80000000000027, -136.09999999999997, 227.29999999999953, -467.0, 44.60000000000017, -226.20000000000005, 84.79999999999978, 126.30000000000015, 12.40000000000025, -203.3999999999998, -247.50000000000028, -42.799999999999855, 26.00000000000012, -205.00000000000045, -176.39999999999992, -300.9999999999999, 16.899999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [26.300000000000114, 20.000000000000014, 30.8000000000002, -24.700000000000017, -19.899999999999743, 20.90000000000003, 20.000000000000014, 7.400000000000006, 72.19999999999955, -3.3999999999999866, 20.000000000000014, -25.59999999999998, -82.90000000000073, 20.000000000000014, 7.999999999999709, -34.9, 20.000000000000014, 20.000000000000014, -21.099999999999845, -98.9, 33.20000000000012, -199.70000000000002, -51.099999999999916, -259.3, -75.39999999999998, -134.20000000000059, 6.500000000000041, -55.60000000000004, -19.00000000000007, 20.000000000000014, -195.50000000000003, -150.60000000000014, -17.19999999999976, -74.49999999999994, 41.60000000000018, -238.10000000000002, -194.19999999999993, -263.8, -122.80000000000005, -65.2, 7.399999999999965, 20.000000000000014, 17.900000000000013, 61.10000000000015, -172.30000000000013, -59.80000000000004, -310.1999999999998, -24.10000000000005, -215.50000000000028, 19.700000000000017, 29.00000000000024, -66.10000000000014, -24.699999999999825, -92.49999999999991, 27.200000000000134, -240.0000000000003, -111.99999999999991, -392.80000000000007, -229.90000000000046, -229.90000000000038, -88.30000000000027, -198.40000000000038, 17.900000000000013, -122.8000000000001, -167.00000000000009, 41.90000000000019, -115.00000000000001, -246.0999999999999, 63.200000000000195, 20.000000000000014, -310.70000000000016, -290.29999999999995, -126.7000000000001, -138.70000000000005, 20.000000000000014, 20.000000000000014, -383.1999999999998, -38.799999999999756, -66.10000000000079, -38.4999999999999, 56.900000000000226, 67.6999999999999, 28.100000000000147, -43.900000000000006, -65.20000000000039, -268.90000000000003, 21.80000000000004, -208.0000000000005, -66.10000000000059, -316.0, 20.000000000000014, -208.60000000000034, 20.000000000000014, -378.1, -17.49999999999986, 20.000000000000014, -12.099999999999874, 20.900000000000027, -0.9999999999999846, -21.699999999999754, -124.90000000000043, -96.10000000000053, -130.80000000000075, -349.2999999999997, -198.1, -28.299999999999834, 20.000000000000014, 20.000000000000014, -15.099999999999842, -69.70000000000041, 20.000000000000014, -130.90000000000015, -79.2999999999999, -53.50000000000001, 22.700000000000053, 20.000000000000014, 32.90000000000023, 24.500000000000092, -307.6000000000001, -388.0, -310.60000000000014, -87.10000000000002, -119.20000000000007, -150.60000000000053, -366.2, -421.9, -196.30000000000038, 20.000000000000014, -368.50000000000006, -103.90000000000028, -288.79999999999995, -198.40000000000038, -186.7, -269.0, -114.70000000000027, 20.000000000000014, -153.9000000000003, -21.399999999999977, -93.39999999999995, -49.30000000000001, -143.80000000000007, -20.799999999999898, -5.199999999999969, -103.0000000000003, -169.0, -208.69999999999993, -179.8000000000002, -53.50000000000019, -70.60000000000048, -189.99999999999991, -187.90000000000038, -211.00000000000014, -100.30000000000052, -70.90000000000015, -162.70000000000033, -135.10000000000036, -68.20000000000002, 20.000000000000014, 23.000000000000224, 29.90000000000018, -189.99999999999994, -219.89999999999995, -138.7000000000003, -261.40000000000015, -228.5, -44.20000000000004, 20.000000000000014, -240.19999999999993, -127.50000000000003, -145.60000000000002, 1.0999999999999712, -876.8, -490.4, -426.6, 1.099999999999953, -739.5, -312.70000000000005, -269.5, -38.80000000000005, -822.4, -528.7, 29.000000000000163, 1.0999999999999723, -42.69999999999997, -374.69999999999993, -225.70000000000002, -312.1, -341.399999999999, -91.29999999999998, -781.5, -113.9999999999998, 20.000000000000014, -180.70000000000027, -205.30000000000018, -665.1, -271.3000000000002, -294.3, -566.7, -24.099999999999746, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 6.0, 0.0, 18.0, 23.0, 0.0, 0.0, 49.0, 18.0, 30.0, 0.0, 0.0, 67.0, 7.0, 7.0, 115.0, 40.0, 147.0, 0.0, 106.0, 36.0, 12.0, 0.0, 46.0, 17.0, 146.0, 30.0, 37.0, 180.0, 13.0, 148.0, 147.0, 22.0, 60.0, 6.0, 0.0, 0.0, 2.0, 92.0, 38.0, 96.0, 173.0, 63.0, 60.0, 0.0, 44.0, 75.0, 73.0, 90.0, 101.0, 287.0, 40.0, 6.0, 175.0, 116.0, 58.0, 68.0, 1.0, 63.0, 117.0, 148.0, 75.0, 0.0, 0.0, 242.0, 97.0, 97.0, 45.0, 0.0, 0.0, 162.0, 183.0, 57.0, 30.0, 1.0, 2.0, 0.0, 48.0, 0.0, 147.0, 86.0, 85.0, 125.0, 133.0, 121.0, 29.0, 228.0, 183.0, 38.0, 0.0, 26.0, 0.0, 22.0, 0.0, 20.0, 66.0, 185.0, 184.0, 25.0, 116.0, 0.0, 0.0, 49.0, 0.0, 10.0, 93.0, 55.0, 0.0, 0.0, 0.0, 3.0, 2.0, 152.0, 185.0, 51.0, 160.0, 83.0, 39.0, 156.0, 299.0, 13.0, 103.0, 96.0, 150.0, 173.0, 89.0, 120.0, 96.0, 2.0, 82.0, 13.0, 103.0, 56.0, 0.0, 0.0, 83.0, 0.0, 74.0, 0.0, 140.0, 120.0, 41.0, 24.0, 120.0, 57.0, 123.0, 113.0, 1.0, 29.0, 79.0, 0.0, 42.0, 5.0, 0.0, 135.0, 108.0, 133.0, 137.0, 185.0, 75.0, 91.0, 201.0, 9.0, 128.0, 582.0, 521.0, 0.0, 450.0, 526.0, 257.0, 148.0, 208.0, 438.0, 508.0, 185.0, 441.0, 50.0, 4.0, 99.0, 298.0, 159.0, 247.0, 528.0, 302.0, 66.0, 54.0, 127.0, 54.0, 484.0, 276.0, 505.0, 55.0, 21.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1580805153423308, "mean_inference_ms": 3.149098092011108, "mean_action_processing_ms": 0.4607001480557602, "mean_env_wait_ms": 0.7149434275781457, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006706357002258301, "StateBufferConnector_ms": 0.00466001033782959, "ViewRequirementAgentConnector_ms": 0.20851421356201172}, "num_episodes": 18, "episode_return_max": 227.29999999999953, "episode_return_min": -467.0, "episode_return_mean": -66.02500000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 274.44001470706036, "num_env_steps_trained_throughput_per_sec": 274.44001470706036, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 13506.318, "restore_workers_time_ms": 0.023, "training_step_time_ms": 13506.242, "sample_time_ms": 2489.646, "learn_time_ms": 10998.462, "learn_throughput": 363.687, "synch_weights_time_ms": 15.083}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "c52aa_00000", "date": "2024-08-12_23-50-19", "timestamp": 1723521019, "time_this_iter_s": 14.622756958007812, "time_total_s": 149.35767674446106, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c58b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 149.35767674446106, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 74.42857142857144, "ram_util_percent": 83.24761904761905}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2216024547421112, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.15304631783218, "policy_loss": -0.006795808069023585, "vf_loss": 5.159066065404781, "vf_explained_var": 0.002771580313879346, "kl": 0.020694846175365926, "entropy": 1.4270503144415598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37199818367759385, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.747206431091147, "policy_loss": -0.0012377756175944808, "vf_loss": 6.747960481189546, "vf_explained_var": 0.0005484600231130287, "kl": 0.008599563540318305, "entropy": 1.4662906285946962, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 228.69999999999987, "episode_reward_min": -467.0, "episode_reward_mean": -60.191000000000095, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -876.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 74.89999999999941, "predator_policy": 582.0}, "policy_reward_mean": {"prey_policy": -151.25050000000005, "predator_policy": 121.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-163.0, -105.99999999999994, 33.400000000000205, 80.99999999999899, -102.10000000000008, -65.29999999999993, -72.80000000000018, 6.900000000000189, 30.80000000000029, -21.799999999999947, -177.7999999999999, -278.8000000000005, -112.70000000000067, -35.89999999999986, 54.90000000000017, -138.1, 83.19999999999908, -262.0000000000001, -123.40000000000018, 40.0000000000003, -77.00000000000071, -17.59999999999964, 127.59999999999846, 32.200000000000415, -187.1000000000005, -15.19999999999967, -124.10000000000065, -38.599999999999774, 52.90000000000009, 40.50000000000039, 34.80000000000024, -0.699999999999743, -135.000000000001, -111.1000000000007, -85.40000000000005, 40.0000000000003, -35.79999999999973, -7.899999999999821, -77.79999999999981, 42.70000000000034, 62.40000000000047, -358.5999999999998, -186.70000000000033, -147.8000000000009, -333.09999999999997, -60.30000000000059, -226.40000000000043, -225.20000000000036, -239.70000000000005, -10.699999999999871, -59.299999999999855, -86.70000000000007, -81.59999999999965, -34.19999999999985, -237.6999999999998, -72.3000000000005, -116.60000000000039, -218.90000000000055, -57.19999999999987, -189.80000000000064, -6.200000000000047, 57.900000000000524, -166.90000000000003, -130.10000000000053, -12.699999999999736, 71.80000000000027, -136.09999999999997, 227.29999999999953, -467.0, 44.60000000000017, -226.20000000000005, 84.79999999999978, 126.30000000000015, 12.40000000000025, -203.3999999999998, -247.50000000000028, -42.799999999999855, 26.00000000000012, -205.00000000000045, -176.39999999999992, -300.9999999999999, 16.899999999999974, -151.10000000000073, 137.69999999999916, 30.400000000000333, 85.50000000000006, 66.8999999999994, 57.10000000000046, 117.59999999999968, 25.700000000000358, 19.500000000000114, -10.499999999999831, -18.999999999999737, 228.69999999999987, -75.40000000000094, 86.6999999999988, 44.59999999999994, -45.99999999999974, -6.699999999999816, -205.00000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-194.19999999999993, -263.8, -122.80000000000005, -65.2, 7.399999999999965, 20.000000000000014, 17.900000000000013, 61.10000000000015, -172.30000000000013, -59.80000000000004, -310.1999999999998, -24.10000000000005, -215.50000000000028, 19.700000000000017, 29.00000000000024, -66.10000000000014, -24.699999999999825, -92.49999999999991, 27.200000000000134, -240.0000000000003, -111.99999999999991, -392.80000000000007, -229.90000000000046, -229.90000000000038, -88.30000000000027, -198.40000000000038, 17.900000000000013, -122.8000000000001, -167.00000000000009, 41.90000000000019, -115.00000000000001, -246.0999999999999, 63.200000000000195, 20.000000000000014, -310.70000000000016, -290.29999999999995, -126.7000000000001, -138.70000000000005, 20.000000000000014, 20.000000000000014, -383.1999999999998, -38.799999999999756, -66.10000000000079, -38.4999999999999, 56.900000000000226, 67.6999999999999, 28.100000000000147, -43.900000000000006, -65.20000000000039, -268.90000000000003, 21.80000000000004, -208.0000000000005, -66.10000000000059, -316.0, 20.000000000000014, -208.60000000000034, 20.000000000000014, -378.1, -17.49999999999986, 20.000000000000014, -12.099999999999874, 20.900000000000027, -0.9999999999999846, -21.699999999999754, -124.90000000000043, -96.10000000000053, -130.80000000000075, -349.2999999999997, -198.1, -28.299999999999834, 20.000000000000014, 20.000000000000014, -15.099999999999842, -69.70000000000041, 20.000000000000014, -130.90000000000015, -79.2999999999999, -53.50000000000001, 22.700000000000053, 20.000000000000014, 32.90000000000023, 24.500000000000092, -307.6000000000001, -388.0, -310.60000000000014, -87.10000000000002, -119.20000000000007, -150.60000000000053, -366.2, -421.9, -196.30000000000038, 20.000000000000014, -368.50000000000006, -103.90000000000028, -288.79999999999995, -198.40000000000038, -186.7, -269.0, -114.70000000000027, 20.000000000000014, -153.9000000000003, -21.399999999999977, -93.39999999999995, -49.30000000000001, -143.80000000000007, -20.799999999999898, -5.199999999999969, -103.0000000000003, -169.0, -208.69999999999993, -179.8000000000002, -53.50000000000019, -70.60000000000048, -189.99999999999991, -187.90000000000038, -211.00000000000014, -100.30000000000052, -70.90000000000015, -162.70000000000033, -135.10000000000036, -68.20000000000002, 20.000000000000014, 23.000000000000224, 29.90000000000018, -189.99999999999994, -219.89999999999995, -138.7000000000003, -261.40000000000015, -228.5, -44.20000000000004, 20.000000000000014, -240.19999999999993, -127.50000000000003, -145.60000000000002, 1.0999999999999712, -876.8, -490.4, -426.6, 1.099999999999953, -739.5, -312.70000000000005, -269.5, -38.80000000000005, -822.4, -528.7, 29.000000000000163, 1.0999999999999723, -42.69999999999997, -374.69999999999993, -225.70000000000002, -312.1, -341.399999999999, -91.29999999999998, -781.5, -113.9999999999998, 20.000000000000014, -180.70000000000027, -205.30000000000018, -665.1, -271.3000000000002, -294.3, -566.7, -24.099999999999746, 20.000000000000014, -202.60000000000053, -137.50000000000028, -511.20000000000005, 74.89999999999941, -25.6, 20.000000000000014, -651.4, 20.900000000000027, 58.4000000000001, -200.5000000000001, 20.000000000000014, 28.100000000000158, -702.3999999999999, 20.000000000000014, -74.49999999999997, 27.20000000000014, 20.000000000000014, -415.4999999999998, 20.000000000000014, -354.5, -49.59999999999983, -200.40000000000003, -30.39999999999977, -493.9, -60.70000000000031, -162.70000000000041, 43.400000000000205, 29.300000000000193, -362.1, -598.3, -139.6000000000007, -222.40000000000003, -95.50000000000057, -298.20000000000005, -386.69999999999936, -344.29999999999995], "policy_predator_policy_reward": [148.0, 147.0, 22.0, 60.0, 6.0, 0.0, 0.0, 2.0, 92.0, 38.0, 96.0, 173.0, 63.0, 60.0, 0.0, 44.0, 75.0, 73.0, 90.0, 101.0, 287.0, 40.0, 6.0, 175.0, 116.0, 58.0, 68.0, 1.0, 63.0, 117.0, 148.0, 75.0, 0.0, 0.0, 242.0, 97.0, 97.0, 45.0, 0.0, 0.0, 162.0, 183.0, 57.0, 30.0, 1.0, 2.0, 0.0, 48.0, 0.0, 147.0, 86.0, 85.0, 125.0, 133.0, 121.0, 29.0, 228.0, 183.0, 38.0, 0.0, 26.0, 0.0, 22.0, 0.0, 20.0, 66.0, 185.0, 184.0, 25.0, 116.0, 0.0, 0.0, 49.0, 0.0, 10.0, 93.0, 55.0, 0.0, 0.0, 0.0, 3.0, 2.0, 152.0, 185.0, 51.0, 160.0, 83.0, 39.0, 156.0, 299.0, 13.0, 103.0, 96.0, 150.0, 173.0, 89.0, 120.0, 96.0, 2.0, 82.0, 13.0, 103.0, 56.0, 0.0, 0.0, 83.0, 0.0, 74.0, 0.0, 140.0, 120.0, 41.0, 24.0, 120.0, 57.0, 123.0, 113.0, 1.0, 29.0, 79.0, 0.0, 42.0, 5.0, 0.0, 135.0, 108.0, 133.0, 137.0, 185.0, 75.0, 91.0, 201.0, 9.0, 128.0, 582.0, 521.0, 0.0, 450.0, 526.0, 257.0, 148.0, 208.0, 438.0, 508.0, 185.0, 441.0, 50.0, 4.0, 99.0, 298.0, 159.0, 247.0, 528.0, 302.0, 66.0, 54.0, 127.0, 54.0, 484.0, 276.0, 505.0, 55.0, 21.0, 0.0, 128.0, 61.0, 319.0, 255.0, 9.0, 27.0, 401.0, 315.0, 105.0, 104.0, 8.0, 1.0, 453.0, 347.0, 42.0, 31.0, 291.0, 124.0, 96.0, 228.0, 101.0, 130.0, 391.0, 362.0, 75.0, 73.0, 14.0, 0.0, 546.0, 459.0, 195.0, 121.0, 232.0, 155.0, 256.0, 270.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1381776705374103, "mean_inference_ms": 3.0841325071242203, "mean_action_processing_ms": 0.4555488725683719, "mean_env_wait_ms": 0.7015927065875616, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006567716598510742, "StateBufferConnector_ms": 0.0046422481536865234, "ViewRequirementAgentConnector_ms": 0.193037748336792}, "num_episodes": 18, "episode_return_max": 228.69999999999987, "episode_return_min": -467.0, "episode_return_mean": -60.191000000000095, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.8204651991397, "num_env_steps_trained_throughput_per_sec": 349.8204651991397, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 12924.707, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12924.646, "sample_time_ms": 2306.93, "learn_time_ms": 10600.044, "learn_throughput": 377.357, "synch_weights_time_ms": 14.676}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "c52aa_00000", "date": "2024-08-12_23-50-31", "timestamp": 1723521031, "time_this_iter_s": 11.500720024108887, "time_total_s": 160.85839676856995, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc093a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 160.85839676856995, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 57.46470588235294, "ram_util_percent": 83.12352941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0543433888327507, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0665000084216003, "policy_loss": -0.006143915175248391, "vf_loss": 3.0713718630649427, "vf_explained_var": -0.00021677711022593987, "kl": 0.02261432116271638, "entropy": 1.473744063781052, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3754588549828561, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7362354635561585, "policy_loss": -0.001574416626638994, "vf_loss": 3.737450291492321, "vf_explained_var": -0.00013680741900489444, "kl": 0.006392762330282295, "entropy": 1.4622559769443735, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 228.69999999999987, "episode_reward_min": -467.0, "episode_reward_mean": -43.8980000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -876.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 74.89999999999941, "predator_policy": 582.0}, "policy_reward_mean": {"prey_policy": -140.25900000000004, "predator_policy": 118.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-123.40000000000018, 40.0000000000003, -77.00000000000071, -17.59999999999964, 127.59999999999846, 32.200000000000415, -187.1000000000005, -15.19999999999967, -124.10000000000065, -38.599999999999774, 52.90000000000009, 40.50000000000039, 34.80000000000024, -0.699999999999743, -135.000000000001, -111.1000000000007, -85.40000000000005, 40.0000000000003, -35.79999999999973, -7.899999999999821, -77.79999999999981, 42.70000000000034, 62.40000000000047, -358.5999999999998, -186.70000000000033, -147.8000000000009, -333.09999999999997, -60.30000000000059, -226.40000000000043, -225.20000000000036, -239.70000000000005, -10.699999999999871, -59.299999999999855, -86.70000000000007, -81.59999999999965, -34.19999999999985, -237.6999999999998, -72.3000000000005, -116.60000000000039, -218.90000000000055, -57.19999999999987, -189.80000000000064, -6.200000000000047, 57.900000000000524, -166.90000000000003, -130.10000000000053, -12.699999999999736, 71.80000000000027, -136.09999999999997, 227.29999999999953, -467.0, 44.60000000000017, -226.20000000000005, 84.79999999999978, 126.30000000000015, 12.40000000000025, -203.3999999999998, -247.50000000000028, -42.799999999999855, 26.00000000000012, -205.00000000000045, -176.39999999999992, -300.9999999999999, 16.899999999999974, -151.10000000000073, 137.69999999999916, 30.400000000000333, 85.50000000000006, 66.8999999999994, 57.10000000000046, 117.59999999999968, 25.700000000000358, 19.500000000000114, -10.499999999999831, -18.999999999999737, 228.69999999999987, -75.40000000000094, 86.6999999999988, 44.59999999999994, -45.99999999999974, -6.699999999999816, -205.00000000000014, 5.199999999999916, 27.900000000000126, 65.29999999999876, 10.999999999999934, -22.399999999999572, 40.0000000000003, 43.60000000000036, 116.49999999999842, -8.299999999999631, 47.400000000000425, 12.000000000000172, 4.000000000000107, -11.399999999999592, -63.39999999999991, -128.900000000001, 179.7999999999997, 80.49999999999929, -15.599999999999719], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-126.7000000000001, -138.70000000000005, 20.000000000000014, 20.000000000000014, -383.1999999999998, -38.799999999999756, -66.10000000000079, -38.4999999999999, 56.900000000000226, 67.6999999999999, 28.100000000000147, -43.900000000000006, -65.20000000000039, -268.90000000000003, 21.80000000000004, -208.0000000000005, -66.10000000000059, -316.0, 20.000000000000014, -208.60000000000034, 20.000000000000014, -378.1, -17.49999999999986, 20.000000000000014, -12.099999999999874, 20.900000000000027, -0.9999999999999846, -21.699999999999754, -124.90000000000043, -96.10000000000053, -130.80000000000075, -349.2999999999997, -198.1, -28.299999999999834, 20.000000000000014, 20.000000000000014, -15.099999999999842, -69.70000000000041, 20.000000000000014, -130.90000000000015, -79.2999999999999, -53.50000000000001, 22.700000000000053, 20.000000000000014, 32.90000000000023, 24.500000000000092, -307.6000000000001, -388.0, -310.60000000000014, -87.10000000000002, -119.20000000000007, -150.60000000000053, -366.2, -421.9, -196.30000000000038, 20.000000000000014, -368.50000000000006, -103.90000000000028, -288.79999999999995, -198.40000000000038, -186.7, -269.0, -114.70000000000027, 20.000000000000014, -153.9000000000003, -21.399999999999977, -93.39999999999995, -49.30000000000001, -143.80000000000007, -20.799999999999898, -5.199999999999969, -103.0000000000003, -169.0, -208.69999999999993, -179.8000000000002, -53.50000000000019, -70.60000000000048, -189.99999999999991, -187.90000000000038, -211.00000000000014, -100.30000000000052, -70.90000000000015, -162.70000000000033, -135.10000000000036, -68.20000000000002, 20.000000000000014, 23.000000000000224, 29.90000000000018, -189.99999999999994, -219.89999999999995, -138.7000000000003, -261.40000000000015, -228.5, -44.20000000000004, 20.000000000000014, -240.19999999999993, -127.50000000000003, -145.60000000000002, 1.0999999999999712, -876.8, -490.4, -426.6, 1.099999999999953, -739.5, -312.70000000000005, -269.5, -38.80000000000005, -822.4, -528.7, 29.000000000000163, 1.0999999999999723, -42.69999999999997, -374.69999999999993, -225.70000000000002, -312.1, -341.399999999999, -91.29999999999998, -781.5, -113.9999999999998, 20.000000000000014, -180.70000000000027, -205.30000000000018, -665.1, -271.3000000000002, -294.3, -566.7, -24.099999999999746, 20.000000000000014, -202.60000000000053, -137.50000000000028, -511.20000000000005, 74.89999999999941, -25.6, 20.000000000000014, -651.4, 20.900000000000027, 58.4000000000001, -200.5000000000001, 20.000000000000014, 28.100000000000158, -702.3999999999999, 20.000000000000014, -74.49999999999997, 27.20000000000014, 20.000000000000014, -415.4999999999998, 20.000000000000014, -354.5, -49.59999999999983, -200.40000000000003, -30.39999999999977, -493.9, -60.70000000000031, -162.70000000000041, 43.400000000000205, 29.300000000000193, -362.1, -598.3, -139.6000000000007, -222.40000000000003, -95.50000000000057, -298.20000000000005, -386.69999999999936, -344.29999999999995, -230.49999999999991, 22.70000000000006, 35.3000000000002, -54.400000000000176, 25.400000000000098, 8.89999999999966, -5.200000000000037, -20.799999999999848, -78.40000000000076, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 51.500000000000234, 65.00000000000011, -15.699999999999761, -22.599999999999753, 20.000000000000014, 19.400000000000006, -632.0, 20.000000000000014, 14.299999999999976, -46.29999999999976, -11.499999999999819, -34.899999999999764, -177.40000000000043, 20.000000000000014, -135.10000000000045, -134.80000000000064, 20.000000000000014, -606.2, 58.70000000000021, 21.800000000000043, -130.6000000000005, 20.000000000000014], "policy_predator_policy_reward": [97.0, 45.0, 0.0, 0.0, 162.0, 183.0, 57.0, 30.0, 1.0, 2.0, 0.0, 48.0, 0.0, 147.0, 86.0, 85.0, 125.0, 133.0, 121.0, 29.0, 228.0, 183.0, 38.0, 0.0, 26.0, 0.0, 22.0, 0.0, 20.0, 66.0, 185.0, 184.0, 25.0, 116.0, 0.0, 0.0, 49.0, 0.0, 10.0, 93.0, 55.0, 0.0, 0.0, 0.0, 3.0, 2.0, 152.0, 185.0, 51.0, 160.0, 83.0, 39.0, 156.0, 299.0, 13.0, 103.0, 96.0, 150.0, 173.0, 89.0, 120.0, 96.0, 2.0, 82.0, 13.0, 103.0, 56.0, 0.0, 0.0, 83.0, 0.0, 74.0, 0.0, 140.0, 120.0, 41.0, 24.0, 120.0, 57.0, 123.0, 113.0, 1.0, 29.0, 79.0, 0.0, 42.0, 5.0, 0.0, 135.0, 108.0, 133.0, 137.0, 185.0, 75.0, 91.0, 201.0, 9.0, 128.0, 582.0, 521.0, 0.0, 450.0, 526.0, 257.0, 148.0, 208.0, 438.0, 508.0, 185.0, 441.0, 50.0, 4.0, 99.0, 298.0, 159.0, 247.0, 528.0, 302.0, 66.0, 54.0, 127.0, 54.0, 484.0, 276.0, 505.0, 55.0, 21.0, 0.0, 128.0, 61.0, 319.0, 255.0, 9.0, 27.0, 401.0, 315.0, 105.0, 104.0, 8.0, 1.0, 453.0, 347.0, 42.0, 31.0, 291.0, 124.0, 96.0, 228.0, 101.0, 130.0, 391.0, 362.0, 75.0, 73.0, 14.0, 0.0, 546.0, 459.0, 195.0, 121.0, 232.0, 155.0, 256.0, 270.0, 102.0, 111.0, 31.0, 16.0, 31.0, 0.0, 27.0, 10.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 8.0, 296.0, 328.0, 36.0, 0.0, 11.0, 24.0, 32.0, 62.0, 100.0, 41.0, 421.0, 345.0, 0.0, 0.0, 68.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1186261315692647, "mean_inference_ms": 3.0244227402362083, "mean_action_processing_ms": 0.4506326689711475, "mean_env_wait_ms": 0.6899554072717075, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007778286933898926, "StateBufferConnector_ms": 0.003930807113647461, "ViewRequirementAgentConnector_ms": 0.1673431396484375}, "num_episodes": 18, "episode_return_max": 228.69999999999987, "episode_return_min": -467.0, "episode_return_mean": -43.8980000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.3318184344731, "num_env_steps_trained_throughput_per_sec": 316.3318184344731, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 12991.612, "restore_workers_time_ms": 0.018, "training_step_time_ms": 12991.557, "sample_time_ms": 2248.215, "learn_time_ms": 10726.137, "learn_throughput": 372.921, "synch_weights_time_ms": 14.737}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "c52aa_00000", "date": "2024-08-12_23-50-44", "timestamp": 1723521044, "time_this_iter_s": 12.71767807006836, "time_total_s": 173.5760748386383, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc09d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 173.5760748386383, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 63.45000000000001, "ram_util_percent": 83.56666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3897373122276453, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.72523779824928, "policy_loss": -0.0024902861695933753, "vf_loss": 2.7268972994789245, "vf_explained_var": 0.018611206800218612, "kl": 0.009846332022614814, "entropy": 1.4693799790251192, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3270920560591751, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4951057544145634, "policy_loss": -0.005093977304185352, "vf_loss": 1.4993188337989585, "vf_explained_var": 0.0043437082931478185, "kl": 0.015660446067732304, "entropy": 1.4857560664257676, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 228.69999999999987, "episode_reward_min": -467.0, "episode_reward_mean": -18.953000000000085, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -876.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 115.39999999999952, "predator_policy": 582.0}, "policy_reward_mean": {"prey_policy": -113.69150000000005, "predator_policy": 104.215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-60.30000000000059, -226.40000000000043, -225.20000000000036, -239.70000000000005, -10.699999999999871, -59.299999999999855, -86.70000000000007, -81.59999999999965, -34.19999999999985, -237.6999999999998, -72.3000000000005, -116.60000000000039, -218.90000000000055, -57.19999999999987, -189.80000000000064, -6.200000000000047, 57.900000000000524, -166.90000000000003, -130.10000000000053, -12.699999999999736, 71.80000000000027, -136.09999999999997, 227.29999999999953, -467.0, 44.60000000000017, -226.20000000000005, 84.79999999999978, 126.30000000000015, 12.40000000000025, -203.3999999999998, -247.50000000000028, -42.799999999999855, 26.00000000000012, -205.00000000000045, -176.39999999999992, -300.9999999999999, 16.899999999999974, -151.10000000000073, 137.69999999999916, 30.400000000000333, 85.50000000000006, 66.8999999999994, 57.10000000000046, 117.59999999999968, 25.700000000000358, 19.500000000000114, -10.499999999999831, -18.999999999999737, 228.69999999999987, -75.40000000000094, 86.6999999999988, 44.59999999999994, -45.99999999999974, -6.699999999999816, -205.00000000000014, 5.199999999999916, 27.900000000000126, 65.29999999999876, 10.999999999999934, -22.399999999999572, 40.0000000000003, 43.60000000000036, 116.49999999999842, -8.299999999999631, 47.400000000000425, 12.000000000000172, 4.000000000000107, -11.399999999999592, -63.39999999999991, -128.900000000001, 179.7999999999997, 80.49999999999929, -15.599999999999719, 86.79999999999887, 32.6000000000004, 43.60000000000035, -32.899999999999665, 22.800000000000033, 39.200000000000294, -7.299999999999741, 108.69999999999854, 10.300000000000066, 53.000000000000355, 24.000000000000053, 75.59999999999964, -61.40000000000032, -20.499999999999773, 126.49999999999892, -7.899999999999704, 37.40000000000032, 39.40000000000029, 75.99999999999959, 83.29999999999937, 54.20000000000048, 42.90000000000042, -62.20000000000131, 62.50000000000028, 37.600000000000236, -2.199999999999975, 42.700000000000344], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-196.30000000000038, 20.000000000000014, -368.50000000000006, -103.90000000000028, -288.79999999999995, -198.40000000000038, -186.7, -269.0, -114.70000000000027, 20.000000000000014, -153.9000000000003, -21.399999999999977, -93.39999999999995, -49.30000000000001, -143.80000000000007, -20.799999999999898, -5.199999999999969, -103.0000000000003, -169.0, -208.69999999999993, -179.8000000000002, -53.50000000000019, -70.60000000000048, -189.99999999999991, -187.90000000000038, -211.00000000000014, -100.30000000000052, -70.90000000000015, -162.70000000000033, -135.10000000000036, -68.20000000000002, 20.000000000000014, 23.000000000000224, 29.90000000000018, -189.99999999999994, -219.89999999999995, -138.7000000000003, -261.40000000000015, -228.5, -44.20000000000004, 20.000000000000014, -240.19999999999993, -127.50000000000003, -145.60000000000002, 1.0999999999999712, -876.8, -490.4, -426.6, 1.099999999999953, -739.5, -312.70000000000005, -269.5, -38.80000000000005, -822.4, -528.7, 29.000000000000163, 1.0999999999999723, -42.69999999999997, -374.69999999999993, -225.70000000000002, -312.1, -341.399999999999, -91.29999999999998, -781.5, -113.9999999999998, 20.000000000000014, -180.70000000000027, -205.30000000000018, -665.1, -271.3000000000002, -294.3, -566.7, -24.099999999999746, 20.000000000000014, -202.60000000000053, -137.50000000000028, -511.20000000000005, 74.89999999999941, -25.6, 20.000000000000014, -651.4, 20.900000000000027, 58.4000000000001, -200.5000000000001, 20.000000000000014, 28.100000000000158, -702.3999999999999, 20.000000000000014, -74.49999999999997, 27.20000000000014, 20.000000000000014, -415.4999999999998, 20.000000000000014, -354.5, -49.59999999999983, -200.40000000000003, -30.39999999999977, -493.9, -60.70000000000031, -162.70000000000041, 43.400000000000205, 29.300000000000193, -362.1, -598.3, -139.6000000000007, -222.40000000000003, -95.50000000000057, -298.20000000000005, -386.69999999999936, -344.29999999999995, -230.49999999999991, 22.70000000000006, 35.3000000000002, -54.400000000000176, 25.400000000000098, 8.89999999999966, -5.200000000000037, -20.799999999999848, -78.40000000000076, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 51.500000000000234, 65.00000000000011, -15.699999999999761, -22.599999999999753, 20.000000000000014, 19.400000000000006, -632.0, 20.000000000000014, 14.299999999999976, -46.29999999999976, -11.499999999999819, -34.899999999999764, -177.40000000000043, 20.000000000000014, -135.10000000000045, -134.80000000000064, 20.000000000000014, -606.2, 58.70000000000021, 21.800000000000043, -130.6000000000005, 20.000000000000014, 38.000000000000256, 48.80000000000024, 53.30000000000023, -57.70000000000005, 23.600000000000065, 20.000000000000014, -202.3000000000003, -13.599999999999783, -2.500000000000004, 5.299999999999974, 20.000000000000014, -2.799999999999977, 20.000000000000014, -70.30000000000075, 70.39999999999972, 17.299999999999976, 20.000000000000014, -36.699999999999754, 21.200000000000152, 15.799999999999963, -21.999999999999773, 20.000000000000014, 20.000000000000014, 53.60000000000022, -144.70000000000024, -30.69999999999981, -53.49999999999999, -21.999999999999986, -1.899999999999932, 115.39999999999952, 20.000000000000014, -82.9000000000008, -26.19999999999979, 41.60000000000025, 20.900000000000027, -14.49999999999978, 56.000000000000206, 20.000000000000014, 1.3999999999999744, 47.90000000000013, 24.200000000000088, 20.000000000000014, -97.60000000000022, 42.50000000000021, -68.2000000000007, -42.99999999999979, 24.500000000000043, 20.000000000000014, 11.299999999999969, 14.299999999999955, -76.60000000000034, 22.400000000000105, 20.000000000000014, 22.700000000000063], "policy_predator_policy_reward": [13.0, 103.0, 96.0, 150.0, 173.0, 89.0, 120.0, 96.0, 2.0, 82.0, 13.0, 103.0, 56.0, 0.0, 0.0, 83.0, 0.0, 74.0, 0.0, 140.0, 120.0, 41.0, 24.0, 120.0, 57.0, 123.0, 113.0, 1.0, 29.0, 79.0, 0.0, 42.0, 5.0, 0.0, 135.0, 108.0, 133.0, 137.0, 185.0, 75.0, 91.0, 201.0, 9.0, 128.0, 582.0, 521.0, 0.0, 450.0, 526.0, 257.0, 148.0, 208.0, 438.0, 508.0, 185.0, 441.0, 50.0, 4.0, 99.0, 298.0, 159.0, 247.0, 528.0, 302.0, 66.0, 54.0, 127.0, 54.0, 484.0, 276.0, 505.0, 55.0, 21.0, 0.0, 128.0, 61.0, 319.0, 255.0, 9.0, 27.0, 401.0, 315.0, 105.0, 104.0, 8.0, 1.0, 453.0, 347.0, 42.0, 31.0, 291.0, 124.0, 96.0, 228.0, 101.0, 130.0, 391.0, 362.0, 75.0, 73.0, 14.0, 0.0, 546.0, 459.0, 195.0, 121.0, 232.0, 155.0, 256.0, 270.0, 102.0, 111.0, 31.0, 16.0, 31.0, 0.0, 27.0, 10.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 8.0, 296.0, 328.0, 36.0, 0.0, 11.0, 24.0, 32.0, 62.0, 100.0, 41.0, 421.0, 345.0, 0.0, 0.0, 68.0, 27.0, 0.0, 0.0, 24.0, 13.0, 0.0, 0.0, 73.0, 110.0, 20.0, 0.0, 3.0, 19.0, 6.0, 37.0, 0.0, 21.0, 27.0, 0.0, 6.0, 10.0, 23.0, 3.0, 0.0, 2.0, 114.0, 0.0, 55.0, 0.0, 0.0, 13.0, 24.0, 31.0, 0.0, 22.0, 14.0, 19.0, 0.0, 0.0, 17.0, 17.0, 10.0, 0.0, 55.0, 43.0, 20.0, 29.0, 18.0, 0.0, 0.0, 12.0, 51.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0975457206994284, "mean_inference_ms": 2.9656800428480716, "mean_action_processing_ms": 0.4475295279799113, "mean_env_wait_ms": 0.6785909113824001, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008842825889587402, "StateBufferConnector_ms": 0.00430452823638916, "ViewRequirementAgentConnector_ms": 0.186775803565979}, "num_episodes": 27, "episode_return_max": 228.69999999999987, "episode_return_min": -467.0, "episode_return_mean": -18.953000000000085, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.15826852295925, "num_env_steps_trained_throughput_per_sec": 319.15826852295925, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 12937.259, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12937.201, "sample_time_ms": 2222.223, "learn_time_ms": 10698.415, "learn_throughput": 373.887, "synch_weights_time_ms": 13.759}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "c52aa_00000", "date": "2024-08-12_23-50-56", "timestamp": 1723521056, "time_this_iter_s": 12.594578266143799, "time_total_s": 186.1706531047821, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c5c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 186.1706531047821, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 64.41666666666666, "ram_util_percent": 83.50555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.308545809014449, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.742012433778672, "policy_loss": -0.003973680209471948, "vf_loss": 3.7449628148760112, "vf_explained_var": 0.008670548755655844, "kl": 0.012127930922186433, "entropy": 1.4425984146103026, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29102065078914163, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.383835952748697, "policy_loss": -0.004458947924197351, "vf_loss": 2.3875770790236337, "vf_explained_var": 0.007267601023275385, "kl": 0.012761124528385572, "entropy": 1.5199843344865023, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 228.69999999999987, "episode_reward_min": -467.0, "episode_reward_mean": 12.54399999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -876.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.3999999999999, "predator_policy": 582.0}, "policy_reward_mean": {"prey_policy": -89.25299999999999, "predator_policy": 95.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-130.10000000000053, -12.699999999999736, 71.80000000000027, -136.09999999999997, 227.29999999999953, -467.0, 44.60000000000017, -226.20000000000005, 84.79999999999978, 126.30000000000015, 12.40000000000025, -203.3999999999998, -247.50000000000028, -42.799999999999855, 26.00000000000012, -205.00000000000045, -176.39999999999992, -300.9999999999999, 16.899999999999974, -151.10000000000073, 137.69999999999916, 30.400000000000333, 85.50000000000006, 66.8999999999994, 57.10000000000046, 117.59999999999968, 25.700000000000358, 19.500000000000114, -10.499999999999831, -18.999999999999737, 228.69999999999987, -75.40000000000094, 86.6999999999988, 44.59999999999994, -45.99999999999974, -6.699999999999816, -205.00000000000014, 5.199999999999916, 27.900000000000126, 65.29999999999876, 10.999999999999934, -22.399999999999572, 40.0000000000003, 43.60000000000036, 116.49999999999842, -8.299999999999631, 47.400000000000425, 12.000000000000172, 4.000000000000107, -11.399999999999592, -63.39999999999991, -128.900000000001, 179.7999999999997, 80.49999999999929, -15.599999999999719, 86.79999999999887, 32.6000000000004, 43.60000000000035, -32.899999999999665, 22.800000000000033, 39.200000000000294, -7.299999999999741, 108.69999999999854, 10.300000000000066, 53.000000000000355, 24.000000000000053, 75.59999999999964, -61.40000000000032, -20.499999999999773, 126.49999999999892, -7.899999999999704, 37.40000000000032, 39.40000000000029, 75.99999999999959, 83.29999999999937, 54.20000000000048, 42.90000000000042, -62.20000000000131, 62.50000000000028, 37.600000000000236, -2.199999999999975, 42.700000000000344, 45.60000000000037, -46.9000000000001, 119.19999999999824, 96.69999999999858, -23.19999999999996, -18.79999999999974, -16.199999999999598, 79.99999999999937, 17.500000000000014, 79.59999999999935, 195.6999999999991, 35.200000000000315, 61.6000000000005, 53.50000000000052, 179.8999999999993, 35.600000000000236, 121.3999999999995, 101.49999999999858], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-138.7000000000003, -261.40000000000015, -228.5, -44.20000000000004, 20.000000000000014, -240.19999999999993, -127.50000000000003, -145.60000000000002, 1.0999999999999712, -876.8, -490.4, -426.6, 1.099999999999953, -739.5, -312.70000000000005, -269.5, -38.80000000000005, -822.4, -528.7, 29.000000000000163, 1.0999999999999723, -42.69999999999997, -374.69999999999993, -225.70000000000002, -312.1, -341.399999999999, -91.29999999999998, -781.5, -113.9999999999998, 20.000000000000014, -180.70000000000027, -205.30000000000018, -665.1, -271.3000000000002, -294.3, -566.7, -24.099999999999746, 20.000000000000014, -202.60000000000053, -137.50000000000028, -511.20000000000005, 74.89999999999941, -25.6, 20.000000000000014, -651.4, 20.900000000000027, 58.4000000000001, -200.5000000000001, 20.000000000000014, 28.100000000000158, -702.3999999999999, 20.000000000000014, -74.49999999999997, 27.20000000000014, 20.000000000000014, -415.4999999999998, 20.000000000000014, -354.5, -49.59999999999983, -200.40000000000003, -30.39999999999977, -493.9, -60.70000000000031, -162.70000000000041, 43.400000000000205, 29.300000000000193, -362.1, -598.3, -139.6000000000007, -222.40000000000003, -95.50000000000057, -298.20000000000005, -386.69999999999936, -344.29999999999995, -230.49999999999991, 22.70000000000006, 35.3000000000002, -54.400000000000176, 25.400000000000098, 8.89999999999966, -5.200000000000037, -20.799999999999848, -78.40000000000076, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 51.500000000000234, 65.00000000000011, -15.699999999999761, -22.599999999999753, 20.000000000000014, 19.400000000000006, -632.0, 20.000000000000014, 14.299999999999976, -46.29999999999976, -11.499999999999819, -34.899999999999764, -177.40000000000043, 20.000000000000014, -135.10000000000045, -134.80000000000064, 20.000000000000014, -606.2, 58.70000000000021, 21.800000000000043, -130.6000000000005, 20.000000000000014, 38.000000000000256, 48.80000000000024, 53.30000000000023, -57.70000000000005, 23.600000000000065, 20.000000000000014, -202.3000000000003, -13.599999999999783, -2.500000000000004, 5.299999999999974, 20.000000000000014, -2.799999999999977, 20.000000000000014, -70.30000000000075, 70.39999999999972, 17.299999999999976, 20.000000000000014, -36.699999999999754, 21.200000000000152, 15.799999999999963, -21.999999999999773, 20.000000000000014, 20.000000000000014, 53.60000000000022, -144.70000000000024, -30.69999999999981, -53.49999999999999, -21.999999999999986, -1.899999999999932, 115.39999999999952, 20.000000000000014, -82.9000000000008, -26.19999999999979, 41.60000000000025, 20.900000000000027, -14.49999999999978, 56.000000000000206, 20.000000000000014, 1.3999999999999744, 47.90000000000013, 24.200000000000088, 20.000000000000014, -97.60000000000022, 42.50000000000021, -68.2000000000007, -42.99999999999979, 24.500000000000043, 20.000000000000014, 11.299999999999969, 14.299999999999955, -76.60000000000034, 22.400000000000105, 20.000000000000014, 22.700000000000063, 33.50000000000024, 4.099999999999966, -40.89999999999981, -58.000000000000156, 53.30000000000023, 65.90000000000008, 17.299999999999976, 61.400000000000176, -13.599999999999858, -118.60000000000001, -0.09999999999999937, -105.70000000000039, -92.2000000000007, 20.000000000000014, -63.70000000000049, 61.70000000000008, -28.299999999999862, -11.199999999999934, 10.099999999999968, 60.50000000000022, 82.09999999999926, 113.59999999999988, 19.40000000000001, -119.20000000000027, 24.500000000000078, 37.10000000000025, 20.000000000000014, 33.50000000000024, 30.500000000000178, 133.3999999999999, 20.000000000000014, 11.599999999999971, 118.99999999999986, -13.599999999999904, 78.49999999999935, 20.000000000000014], "policy_predator_policy_reward": [133.0, 137.0, 185.0, 75.0, 91.0, 201.0, 9.0, 128.0, 582.0, 521.0, 0.0, 450.0, 526.0, 257.0, 148.0, 208.0, 438.0, 508.0, 185.0, 441.0, 50.0, 4.0, 99.0, 298.0, 159.0, 247.0, 528.0, 302.0, 66.0, 54.0, 127.0, 54.0, 484.0, 276.0, 505.0, 55.0, 21.0, 0.0, 128.0, 61.0, 319.0, 255.0, 9.0, 27.0, 401.0, 315.0, 105.0, 104.0, 8.0, 1.0, 453.0, 347.0, 42.0, 31.0, 291.0, 124.0, 96.0, 228.0, 101.0, 130.0, 391.0, 362.0, 75.0, 73.0, 14.0, 0.0, 546.0, 459.0, 195.0, 121.0, 232.0, 155.0, 256.0, 270.0, 102.0, 111.0, 31.0, 16.0, 31.0, 0.0, 27.0, 10.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 8.0, 296.0, 328.0, 36.0, 0.0, 11.0, 24.0, 32.0, 62.0, 100.0, 41.0, 421.0, 345.0, 0.0, 0.0, 68.0, 27.0, 0.0, 0.0, 24.0, 13.0, 0.0, 0.0, 73.0, 110.0, 20.0, 0.0, 3.0, 19.0, 6.0, 37.0, 0.0, 21.0, 27.0, 0.0, 6.0, 10.0, 23.0, 3.0, 0.0, 2.0, 114.0, 0.0, 55.0, 0.0, 0.0, 13.0, 24.0, 31.0, 0.0, 22.0, 14.0, 19.0, 0.0, 0.0, 17.0, 17.0, 10.0, 0.0, 55.0, 43.0, 20.0, 29.0, 18.0, 0.0, 0.0, 12.0, 51.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 52.0, 0.0, 0.0, 3.0, 15.0, 52.0, 57.0, 63.0, 24.0, 0.0, 56.0, 56.0, 26.0, 9.0, 48.0, 9.0, 0.0, 0.0, 0.0, 78.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 4.0, 0.0, 9.0, 7.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0903179094086275, "mean_inference_ms": 2.941361408800592, "mean_action_processing_ms": 0.44554164763547294, "mean_env_wait_ms": 0.6755280495027073, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009439587593078613, "StateBufferConnector_ms": 0.004352450370788574, "ViewRequirementAgentConnector_ms": 0.17189979553222656}, "num_episodes": 18, "episode_return_max": 228.69999999999987, "episode_return_min": -467.0, "episode_return_mean": 12.54399999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 295.052941949657, "num_env_steps_trained_throughput_per_sec": 295.052941949657, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 13043.044, "restore_workers_time_ms": 0.018, "training_step_time_ms": 13042.985, "sample_time_ms": 2287.617, "learn_time_ms": 10737.125, "learn_throughput": 372.539, "synch_weights_time_ms": 14.992}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "c52aa_00000", "date": "2024-08-12_23-51-10", "timestamp": 1723521070, "time_this_iter_s": 13.625486135482788, "time_total_s": 199.7961392402649, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c59d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 199.7961392402649, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 66.99473684210527, "ram_util_percent": 83.47368421052632}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2035441559458535, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3712644493769086, "policy_loss": -0.004992337249313043, "vf_loss": 3.3748701453839662, "vf_explained_var": 0.03060488678790905, "kl": 0.016434089503542013, "entropy": 1.408699963332484, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27291429221984886, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6574297785128236, "policy_loss": -0.004287463054060936, "vf_loss": 1.6611539518391645, "vf_explained_var": 0.001278404331711865, "kl": 0.010014104193067388, "entropy": 1.5322852438719814, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 228.69999999999987, "episode_reward_min": -205.00000000000014, "episode_reward_mean": 35.86199999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -702.3999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.3999999999999, "predator_policy": 546.0}, "policy_reward_mean": {"prey_policy": -38.154000000000025, "predator_policy": 56.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.899999999999974, -151.10000000000073, 137.69999999999916, 30.400000000000333, 85.50000000000006, 66.8999999999994, 57.10000000000046, 117.59999999999968, 25.700000000000358, 19.500000000000114, -10.499999999999831, -18.999999999999737, 228.69999999999987, -75.40000000000094, 86.6999999999988, 44.59999999999994, -45.99999999999974, -6.699999999999816, -205.00000000000014, 5.199999999999916, 27.900000000000126, 65.29999999999876, 10.999999999999934, -22.399999999999572, 40.0000000000003, 43.60000000000036, 116.49999999999842, -8.299999999999631, 47.400000000000425, 12.000000000000172, 4.000000000000107, -11.399999999999592, -63.39999999999991, -128.900000000001, 179.7999999999997, 80.49999999999929, -15.599999999999719, 86.79999999999887, 32.6000000000004, 43.60000000000035, -32.899999999999665, 22.800000000000033, 39.200000000000294, -7.299999999999741, 108.69999999999854, 10.300000000000066, 53.000000000000355, 24.000000000000053, 75.59999999999964, -61.40000000000032, -20.499999999999773, 126.49999999999892, -7.899999999999704, 37.40000000000032, 39.40000000000029, 75.99999999999959, 83.29999999999937, 54.20000000000048, 42.90000000000042, -62.20000000000131, 62.50000000000028, 37.600000000000236, -2.199999999999975, 42.700000000000344, 45.60000000000037, -46.9000000000001, 119.19999999999824, 96.69999999999858, -23.19999999999996, -18.79999999999974, -16.199999999999598, 79.99999999999937, 17.500000000000014, 79.59999999999935, 195.6999999999991, 35.200000000000315, 61.6000000000005, 53.50000000000052, 179.8999999999993, 35.600000000000236, 121.3999999999995, 101.49999999999858, 83.4999999999991, -34.399999999999594, 35.60000000000031, 34.40000000000022, -6.399999999999666, 130.89999999999898, 66.4000000000002, 117.3999999999994, 94.09999999999854, -38.099999999999554, -14.999999999999636, 138.9999999999989, -17.199999999999598, 57.60000000000024, 17.699999999999953, -21.799999999999812, 116.19999999999982, 16.899999999999917], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.099999999999746, 20.000000000000014, -202.60000000000053, -137.50000000000028, -511.20000000000005, 74.89999999999941, -25.6, 20.000000000000014, -651.4, 20.900000000000027, 58.4000000000001, -200.5000000000001, 20.000000000000014, 28.100000000000158, -702.3999999999999, 20.000000000000014, -74.49999999999997, 27.20000000000014, 20.000000000000014, -415.4999999999998, 20.000000000000014, -354.5, -49.59999999999983, -200.40000000000003, -30.39999999999977, -493.9, -60.70000000000031, -162.70000000000041, 43.400000000000205, 29.300000000000193, -362.1, -598.3, -139.6000000000007, -222.40000000000003, -95.50000000000057, -298.20000000000005, -386.69999999999936, -344.29999999999995, -230.49999999999991, 22.70000000000006, 35.3000000000002, -54.400000000000176, 25.400000000000098, 8.89999999999966, -5.200000000000037, -20.799999999999848, -78.40000000000076, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 51.500000000000234, 65.00000000000011, -15.699999999999761, -22.599999999999753, 20.000000000000014, 19.400000000000006, -632.0, 20.000000000000014, 14.299999999999976, -46.29999999999976, -11.499999999999819, -34.899999999999764, -177.40000000000043, 20.000000000000014, -135.10000000000045, -134.80000000000064, 20.000000000000014, -606.2, 58.70000000000021, 21.800000000000043, -130.6000000000005, 20.000000000000014, 38.000000000000256, 48.80000000000024, 53.30000000000023, -57.70000000000005, 23.600000000000065, 20.000000000000014, -202.3000000000003, -13.599999999999783, -2.500000000000004, 5.299999999999974, 20.000000000000014, -2.799999999999977, 20.000000000000014, -70.30000000000075, 70.39999999999972, 17.299999999999976, 20.000000000000014, -36.699999999999754, 21.200000000000152, 15.799999999999963, -21.999999999999773, 20.000000000000014, 20.000000000000014, 53.60000000000022, -144.70000000000024, -30.69999999999981, -53.49999999999999, -21.999999999999986, -1.899999999999932, 115.39999999999952, 20.000000000000014, -82.9000000000008, -26.19999999999979, 41.60000000000025, 20.900000000000027, -14.49999999999978, 56.000000000000206, 20.000000000000014, 1.3999999999999744, 47.90000000000013, 24.200000000000088, 20.000000000000014, -97.60000000000022, 42.50000000000021, -68.2000000000007, -42.99999999999979, 24.500000000000043, 20.000000000000014, 11.299999999999969, 14.299999999999955, -76.60000000000034, 22.400000000000105, 20.000000000000014, 22.700000000000063, 33.50000000000024, 4.099999999999966, -40.89999999999981, -58.000000000000156, 53.30000000000023, 65.90000000000008, 17.299999999999976, 61.400000000000176, -13.599999999999858, -118.60000000000001, -0.09999999999999937, -105.70000000000039, -92.2000000000007, 20.000000000000014, -63.70000000000049, 61.70000000000008, -28.299999999999862, -11.199999999999934, 10.099999999999968, 60.50000000000022, 82.09999999999926, 113.59999999999988, 19.40000000000001, -119.20000000000027, 24.500000000000078, 37.10000000000025, 20.000000000000014, 33.50000000000024, 30.500000000000178, 133.3999999999999, 20.000000000000014, 11.599999999999971, 118.99999999999986, -13.599999999999904, 78.49999999999935, 20.000000000000014, -16.899999999999807, 61.40000000000016, -51.39999999999996, -42.99999999999982, 28.100000000000158, -5.500000000000018, -19.899999999999743, 35.30000000000025, -3.0999999999999757, -28.299999999999756, 100.09999999999957, 30.800000000000203, 35.300000000000175, 1.099999999999967, 20.000000000000014, 97.39999999999979, 11.599999999999968, 78.49999999999926, -34.59999999999977, -74.50000000000077, 20.000000000000014, -85.00000000000065, 42.50000000000025, 96.49999999999956, -139.6000000000007, 34.400000000000134, -78.70000000000071, 89.29999999999976, -24.099999999999746, -17.199999999999882, -93.70000000000041, -3.099999999999972, 36.20000000000008, 38.00000000000007, 11.599999999999973, -15.699999999999747], "policy_predator_policy_reward": [21.0, 0.0, 128.0, 61.0, 319.0, 255.0, 9.0, 27.0, 401.0, 315.0, 105.0, 104.0, 8.0, 1.0, 453.0, 347.0, 42.0, 31.0, 291.0, 124.0, 96.0, 228.0, 101.0, 130.0, 391.0, 362.0, 75.0, 73.0, 14.0, 0.0, 546.0, 459.0, 195.0, 121.0, 232.0, 155.0, 256.0, 270.0, 102.0, 111.0, 31.0, 16.0, 31.0, 0.0, 27.0, 10.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 8.0, 296.0, 328.0, 36.0, 0.0, 11.0, 24.0, 32.0, 62.0, 100.0, 41.0, 421.0, 345.0, 0.0, 0.0, 68.0, 27.0, 0.0, 0.0, 24.0, 13.0, 0.0, 0.0, 73.0, 110.0, 20.0, 0.0, 3.0, 19.0, 6.0, 37.0, 0.0, 21.0, 27.0, 0.0, 6.0, 10.0, 23.0, 3.0, 0.0, 2.0, 114.0, 0.0, 55.0, 0.0, 0.0, 13.0, 24.0, 31.0, 0.0, 22.0, 14.0, 19.0, 0.0, 0.0, 17.0, 17.0, 10.0, 0.0, 55.0, 43.0, 20.0, 29.0, 18.0, 0.0, 0.0, 12.0, 51.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 52.0, 0.0, 0.0, 3.0, 15.0, 52.0, 57.0, 63.0, 24.0, 0.0, 56.0, 56.0, 26.0, 9.0, 48.0, 9.0, 0.0, 0.0, 0.0, 78.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 4.0, 0.0, 9.0, 7.0, 3.0, 0.0, 27.0, 12.0, 0.0, 60.0, 0.0, 13.0, 19.0, 0.0, 2.0, 23.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 4.0, 50.0, 21.0, 29.0, 21.0, 0.0, 0.0, 53.0, 35.0, 30.0, 17.0, 37.0, 22.0, 64.0, 11.0, 27.0, 15.0, 0.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0815443164026568, "mean_inference_ms": 2.9084572200681724, "mean_action_processing_ms": 0.4405911301889276, "mean_env_wait_ms": 0.6695224348383002, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00971519947052002, "StateBufferConnector_ms": 0.004495501518249512, "ViewRequirementAgentConnector_ms": 0.19070923328399658}, "num_episodes": 18, "episode_return_max": 228.69999999999987, "episode_return_min": -205.00000000000014, "episode_return_mean": 35.86199999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.0888911450742, "num_env_steps_trained_throughput_per_sec": 294.0888911450742, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 12923.134, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12923.077, "sample_time_ms": 2252.911, "learn_time_ms": 10652.665, "learn_throughput": 375.493, "synch_weights_time_ms": 14.787}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "c52aa_00000", "date": "2024-08-12_23-51-24", "timestamp": 1723521084, "time_this_iter_s": 13.64987301826477, "time_total_s": 213.44601225852966, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9bcc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 213.44601225852966, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 72.81000000000002, "ram_util_percent": 83.405}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.087485268388791, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.80324432149766, "policy_loss": -0.004466456592590523, "vf_loss": 2.8062048183547126, "vf_explained_var": 0.06343153424994655, "kl": 0.017848395839707994, "entropy": 1.4195677905486375, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.34345996842261345, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.162908121990779, "policy_loss": -0.0019748573193927766, "vf_loss": 1.164547628258902, "vf_explained_var": 0.007660285821036687, "kl": 0.005961767757796674, "entropy": 1.5543336990649108, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 195.6999999999991, "episode_reward_min": -205.00000000000014, "episode_reward_mean": 38.03099999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -632.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.3999999999999, "predator_policy": 421.0}, "policy_reward_mean": {"prey_policy": -8.904500000000027, "predator_policy": 27.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-205.00000000000014, 5.199999999999916, 27.900000000000126, 65.29999999999876, 10.999999999999934, -22.399999999999572, 40.0000000000003, 43.60000000000036, 116.49999999999842, -8.299999999999631, 47.400000000000425, 12.000000000000172, 4.000000000000107, -11.399999999999592, -63.39999999999991, -128.900000000001, 179.7999999999997, 80.49999999999929, -15.599999999999719, 86.79999999999887, 32.6000000000004, 43.60000000000035, -32.899999999999665, 22.800000000000033, 39.200000000000294, -7.299999999999741, 108.69999999999854, 10.300000000000066, 53.000000000000355, 24.000000000000053, 75.59999999999964, -61.40000000000032, -20.499999999999773, 126.49999999999892, -7.899999999999704, 37.40000000000032, 39.40000000000029, 75.99999999999959, 83.29999999999937, 54.20000000000048, 42.90000000000042, -62.20000000000131, 62.50000000000028, 37.600000000000236, -2.199999999999975, 42.700000000000344, 45.60000000000037, -46.9000000000001, 119.19999999999824, 96.69999999999858, -23.19999999999996, -18.79999999999974, -16.199999999999598, 79.99999999999937, 17.500000000000014, 79.59999999999935, 195.6999999999991, 35.200000000000315, 61.6000000000005, 53.50000000000052, 179.8999999999993, 35.600000000000236, 121.3999999999995, 101.49999999999858, 83.4999999999991, -34.399999999999594, 35.60000000000031, 34.40000000000022, -6.399999999999666, 130.89999999999898, 66.4000000000002, 117.3999999999994, 94.09999999999854, -38.099999999999554, -14.999999999999636, 138.9999999999989, -17.199999999999598, 57.60000000000024, 17.699999999999953, -21.799999999999812, 116.19999999999982, 16.899999999999917, 137.79999999999893, 102.89999999999881, 89.49999999999885, 89.49999999999943, -63.399999999999935, 49.50000000000047, 16.899999999999935, 143.4999999999993, -36.50000000000002, 79.5999999999994, -107.70000000000036, 69.70000000000009, 9.200000000000063, 16.899999999999935, -62.00000000000087, 121.89999999999935, 86.49999999999883, 81.69999999999911], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-386.69999999999936, -344.29999999999995, -230.49999999999991, 22.70000000000006, 35.3000000000002, -54.400000000000176, 25.400000000000098, 8.89999999999966, -5.200000000000037, -20.799999999999848, -78.40000000000076, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 51.500000000000234, 65.00000000000011, -15.699999999999761, -22.599999999999753, 20.000000000000014, 19.400000000000006, -632.0, 20.000000000000014, 14.299999999999976, -46.29999999999976, -11.499999999999819, -34.899999999999764, -177.40000000000043, 20.000000000000014, -135.10000000000045, -134.80000000000064, 20.000000000000014, -606.2, 58.70000000000021, 21.800000000000043, -130.6000000000005, 20.000000000000014, 38.000000000000256, 48.80000000000024, 53.30000000000023, -57.70000000000005, 23.600000000000065, 20.000000000000014, -202.3000000000003, -13.599999999999783, -2.500000000000004, 5.299999999999974, 20.000000000000014, -2.799999999999977, 20.000000000000014, -70.30000000000075, 70.39999999999972, 17.299999999999976, 20.000000000000014, -36.699999999999754, 21.200000000000152, 15.799999999999963, -21.999999999999773, 20.000000000000014, 20.000000000000014, 53.60000000000022, -144.70000000000024, -30.69999999999981, -53.49999999999999, -21.999999999999986, -1.899999999999932, 115.39999999999952, 20.000000000000014, -82.9000000000008, -26.19999999999979, 41.60000000000025, 20.900000000000027, -14.49999999999978, 56.000000000000206, 20.000000000000014, 1.3999999999999744, 47.90000000000013, 24.200000000000088, 20.000000000000014, -97.60000000000022, 42.50000000000021, -68.2000000000007, -42.99999999999979, 24.500000000000043, 20.000000000000014, 11.299999999999969, 14.299999999999955, -76.60000000000034, 22.400000000000105, 20.000000000000014, 22.700000000000063, 33.50000000000024, 4.099999999999966, -40.89999999999981, -58.000000000000156, 53.30000000000023, 65.90000000000008, 17.299999999999976, 61.400000000000176, -13.599999999999858, -118.60000000000001, -0.09999999999999937, -105.70000000000039, -92.2000000000007, 20.000000000000014, -63.70000000000049, 61.70000000000008, -28.299999999999862, -11.199999999999934, 10.099999999999968, 60.50000000000022, 82.09999999999926, 113.59999999999988, 19.40000000000001, -119.20000000000027, 24.500000000000078, 37.10000000000025, 20.000000000000014, 33.50000000000024, 30.500000000000178, 133.3999999999999, 20.000000000000014, 11.599999999999971, 118.99999999999986, -13.599999999999904, 78.49999999999935, 20.000000000000014, -16.899999999999807, 61.40000000000016, -51.39999999999996, -42.99999999999982, 28.100000000000158, -5.500000000000018, -19.899999999999743, 35.30000000000025, -3.0999999999999757, -28.299999999999756, 100.09999999999957, 30.800000000000203, 35.300000000000175, 1.099999999999967, 20.000000000000014, 97.39999999999979, 11.599999999999968, 78.49999999999926, -34.59999999999977, -74.50000000000077, 20.000000000000014, -85.00000000000065, 42.50000000000025, 96.49999999999956, -139.6000000000007, 34.400000000000134, -78.70000000000071, 89.29999999999976, -24.099999999999746, -17.199999999999882, -93.70000000000041, -3.099999999999972, 36.20000000000008, 38.00000000000007, 11.599999999999973, -15.699999999999747, 14.599999999999966, 90.19999999999948, -28.29999999999975, 108.19999999999942, 69.4999999999998, 20.000000000000014, 20.000000000000014, 54.49999999999997, -154.3000000000005, -3.099999999999958, 15.799999999999963, 31.700000000000216, 15.799999999999946, -19.899999999999842, 104.59999999999977, 38.90000000000024, -112.29999999999998, 3.7999999999999816, 42.50000000000025, 37.10000000000026, 20.000000000000014, -291.70000000000005, 49.70000000000024, 20.000000000000014, 20.000000000000014, -38.79999999999976, 20.000000000000014, -24.099999999999838, -101.8000000000005, -47.19999999999976, 101.89999999999978, 20.000000000000014, 54.500000000000156, 16.999999999999964, 74.89999999999945, -5.199999999999937], "policy_predator_policy_reward": [256.0, 270.0, 102.0, 111.0, 31.0, 16.0, 31.0, 0.0, 27.0, 10.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 8.0, 296.0, 328.0, 36.0, 0.0, 11.0, 24.0, 32.0, 62.0, 100.0, 41.0, 421.0, 345.0, 0.0, 0.0, 68.0, 27.0, 0.0, 0.0, 24.0, 13.0, 0.0, 0.0, 73.0, 110.0, 20.0, 0.0, 3.0, 19.0, 6.0, 37.0, 0.0, 21.0, 27.0, 0.0, 6.0, 10.0, 23.0, 3.0, 0.0, 2.0, 114.0, 0.0, 55.0, 0.0, 0.0, 13.0, 24.0, 31.0, 0.0, 22.0, 14.0, 19.0, 0.0, 0.0, 17.0, 17.0, 10.0, 0.0, 55.0, 43.0, 20.0, 29.0, 18.0, 0.0, 0.0, 12.0, 51.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 52.0, 0.0, 0.0, 3.0, 15.0, 52.0, 57.0, 63.0, 24.0, 0.0, 56.0, 56.0, 26.0, 9.0, 48.0, 9.0, 0.0, 0.0, 0.0, 78.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 4.0, 0.0, 9.0, 7.0, 3.0, 0.0, 27.0, 12.0, 0.0, 60.0, 0.0, 13.0, 19.0, 0.0, 2.0, 23.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 4.0, 50.0, 21.0, 29.0, 21.0, 0.0, 0.0, 53.0, 35.0, 30.0, 17.0, 37.0, 22.0, 64.0, 11.0, 27.0, 15.0, 0.0, 21.0, 8.0, 25.0, 0.0, 23.0, 0.0, 0.0, 7.0, 8.0, 93.0, 1.0, 2.0, 0.0, 0.0, 21.0, 0.0, 0.0, 4.0, 68.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 0.0, 1.0, 86.0, 0.0, 0.0, 14.0, 1.0, 12.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0763801310489292, "mean_inference_ms": 2.8885279564238626, "mean_action_processing_ms": 0.43778911415476784, "mean_env_wait_ms": 0.6661890678017655, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010414838790893555, "StateBufferConnector_ms": 0.004613280296325684, "ViewRequirementAgentConnector_ms": 0.18803763389587402}, "num_episodes": 18, "episode_return_max": 195.6999999999991, "episode_return_min": -205.00000000000014, "episode_return_mean": 38.03099999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.06946108532105, "num_env_steps_trained_throughput_per_sec": 340.06946108532105, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 12653.811, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12653.757, "sample_time_ms": 2105.709, "learn_time_ms": 10530.169, "learn_throughput": 379.861, "synch_weights_time_ms": 14.542}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "c52aa_00000", "date": "2024-08-12_23-51-36", "timestamp": 1723521096, "time_this_iter_s": 11.828124046325684, "time_total_s": 225.27413630485535, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x329e23ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 225.27413630485535, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 60.9375, "ram_util_percent": 83.44999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1917190400775148, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.899321209185969, "policy_loss": -0.011939847504808788, "vf_loss": 6.909211505405486, "vf_explained_var": 0.006077464610811264, "kl": 0.024291150325902882, "entropy": 1.4274380475755721, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29643373397923023, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.305193211792638, "policy_loss": -0.004682223107074461, "vf_loss": 7.309038846202628, "vf_explained_var": 0.00030366239093598867, "kl": 0.014872668700430577, "entropy": 1.4675557158611439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 195.6999999999991, "episode_reward_min": -115.50000000000003, "episode_reward_mean": 40.5139999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -647.1999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.3999999999999, "predator_policy": 390.0}, "policy_reward_mean": {"prey_policy": -14.483000000000043, "predator_policy": 34.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.899999999999665, 22.800000000000033, 39.200000000000294, -7.299999999999741, 108.69999999999854, 10.300000000000066, 53.000000000000355, 24.000000000000053, 75.59999999999964, -61.40000000000032, -20.499999999999773, 126.49999999999892, -7.899999999999704, 37.40000000000032, 39.40000000000029, 75.99999999999959, 83.29999999999937, 54.20000000000048, 42.90000000000042, -62.20000000000131, 62.50000000000028, 37.600000000000236, -2.199999999999975, 42.700000000000344, 45.60000000000037, -46.9000000000001, 119.19999999999824, 96.69999999999858, -23.19999999999996, -18.79999999999974, -16.199999999999598, 79.99999999999937, 17.500000000000014, 79.59999999999935, 195.6999999999991, 35.200000000000315, 61.6000000000005, 53.50000000000052, 179.8999999999993, 35.600000000000236, 121.3999999999995, 101.49999999999858, 83.4999999999991, -34.399999999999594, 35.60000000000031, 34.40000000000022, -6.399999999999666, 130.89999999999898, 66.4000000000002, 117.3999999999994, 94.09999999999854, -38.099999999999554, -14.999999999999636, 138.9999999999989, -17.199999999999598, 57.60000000000024, 17.699999999999953, -21.799999999999812, 116.19999999999982, 16.899999999999917, 137.79999999999893, 102.89999999999881, 89.49999999999885, 89.49999999999943, -63.399999999999935, 49.50000000000047, 16.899999999999935, 143.4999999999993, -36.50000000000002, 79.5999999999994, -107.70000000000036, 69.70000000000009, 9.200000000000063, 16.899999999999935, -62.00000000000087, 121.89999999999935, 86.49999999999883, 81.69999999999911, 44.90000000000038, 157.09999999999974, -85.4000000000001, 63.10000000000024, 67.89999999999935, -69.00000000000018, 32.30000000000018, 28.10000000000018, 40.60000000000018, 129.3999999999991, -74.20000000000012, -34.999999999999964, 98.69999999999904, 52.00000000000023, 38.30000000000027, -114.70000000000027, 79.5999999999999, -115.50000000000003, 100.29999999999896, -13.299999999999798, 111.39999999999914, 52.90000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-202.3000000000003, -13.599999999999783, -2.500000000000004, 5.299999999999974, 20.000000000000014, -2.799999999999977, 20.000000000000014, -70.30000000000075, 70.39999999999972, 17.299999999999976, 20.000000000000014, -36.699999999999754, 21.200000000000152, 15.799999999999963, -21.999999999999773, 20.000000000000014, 20.000000000000014, 53.60000000000022, -144.70000000000024, -30.69999999999981, -53.49999999999999, -21.999999999999986, -1.899999999999932, 115.39999999999952, 20.000000000000014, -82.9000000000008, -26.19999999999979, 41.60000000000025, 20.900000000000027, -14.49999999999978, 56.000000000000206, 20.000000000000014, 1.3999999999999744, 47.90000000000013, 24.200000000000088, 20.000000000000014, -97.60000000000022, 42.50000000000021, -68.2000000000007, -42.99999999999979, 24.500000000000043, 20.000000000000014, 11.299999999999969, 14.299999999999955, -76.60000000000034, 22.400000000000105, 20.000000000000014, 22.700000000000063, 33.50000000000024, 4.099999999999966, -40.89999999999981, -58.000000000000156, 53.30000000000023, 65.90000000000008, 17.299999999999976, 61.400000000000176, -13.599999999999858, -118.60000000000001, -0.09999999999999937, -105.70000000000039, -92.2000000000007, 20.000000000000014, -63.70000000000049, 61.70000000000008, -28.299999999999862, -11.199999999999934, 10.099999999999968, 60.50000000000022, 82.09999999999926, 113.59999999999988, 19.40000000000001, -119.20000000000027, 24.500000000000078, 37.10000000000025, 20.000000000000014, 33.50000000000024, 30.500000000000178, 133.3999999999999, 20.000000000000014, 11.599999999999971, 118.99999999999986, -13.599999999999904, 78.49999999999935, 20.000000000000014, -16.899999999999807, 61.40000000000016, -51.39999999999996, -42.99999999999982, 28.100000000000158, -5.500000000000018, -19.899999999999743, 35.30000000000025, -3.0999999999999757, -28.299999999999756, 100.09999999999957, 30.800000000000203, 35.300000000000175, 1.099999999999967, 20.000000000000014, 97.39999999999979, 11.599999999999968, 78.49999999999926, -34.59999999999977, -74.50000000000077, 20.000000000000014, -85.00000000000065, 42.50000000000025, 96.49999999999956, -139.6000000000007, 34.400000000000134, -78.70000000000071, 89.29999999999976, -24.099999999999746, -17.199999999999882, -93.70000000000041, -3.099999999999972, 36.20000000000008, 38.00000000000007, 11.599999999999973, -15.699999999999747, 14.599999999999966, 90.19999999999948, -28.29999999999975, 108.19999999999942, 69.4999999999998, 20.000000000000014, 20.000000000000014, 54.49999999999997, -154.3000000000005, -3.099999999999958, 15.799999999999963, 31.700000000000216, 15.799999999999946, -19.899999999999842, 104.59999999999977, 38.90000000000024, -112.29999999999998, 3.7999999999999816, 42.50000000000025, 37.10000000000026, 20.000000000000014, -291.70000000000005, 49.70000000000024, 20.000000000000014, 20.000000000000014, -38.79999999999976, 20.000000000000014, -24.099999999999838, -101.8000000000005, -47.19999999999976, 101.89999999999978, 20.000000000000014, 54.500000000000156, 16.999999999999964, 74.89999999999945, -5.199999999999937, 22.700000000000053, 15.199999999999964, -647.1999999999999, 107.29999999999976, -73.30000000000032, -390.1, -59.80000000000048, 80.89999999999999, -309.29999999999995, 12.20000000000023, -291.0000000000002, -1.0000000000000382, 5.299999999999965, 20.000000000000014, -549.6, 13.69999999999997, -383.70000000000005, -66.70000000000078, 82.99999999999966, 25.400000000000105, -238.30000000000027, -188.9, 5.299999999999965, -128.30000000000004, 61.70000000000012, 20.000000000000014, -60.99999999999991, 65.00000000000003, 20.000000000000014, 5.299999999999972, -213.6000000000003, -444.1, 59.600000000000165, 20.000000000000014, -71.49999999999994, -196.00000000000026, 20.000000000000014, 80.2999999999995, 23.900000000000148, -136.2, 17.299999999999983, 73.09999999999978, -5.1999999999999265, 46.10000000000024], "policy_predator_policy_reward": [73.0, 110.0, 20.0, 0.0, 3.0, 19.0, 6.0, 37.0, 0.0, 21.0, 27.0, 0.0, 6.0, 10.0, 23.0, 3.0, 0.0, 2.0, 114.0, 0.0, 55.0, 0.0, 0.0, 13.0, 24.0, 31.0, 0.0, 22.0, 14.0, 19.0, 0.0, 0.0, 17.0, 17.0, 10.0, 0.0, 55.0, 43.0, 20.0, 29.0, 18.0, 0.0, 0.0, 12.0, 51.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 52.0, 0.0, 0.0, 3.0, 15.0, 52.0, 57.0, 63.0, 24.0, 0.0, 56.0, 56.0, 26.0, 9.0, 48.0, 9.0, 0.0, 0.0, 0.0, 78.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 4.0, 0.0, 9.0, 7.0, 3.0, 0.0, 27.0, 12.0, 0.0, 60.0, 0.0, 13.0, 19.0, 0.0, 2.0, 23.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 4.0, 50.0, 21.0, 29.0, 21.0, 0.0, 0.0, 53.0, 35.0, 30.0, 17.0, 37.0, 22.0, 64.0, 11.0, 27.0, 15.0, 0.0, 21.0, 8.0, 25.0, 0.0, 23.0, 0.0, 0.0, 7.0, 8.0, 93.0, 1.0, 2.0, 0.0, 0.0, 21.0, 0.0, 0.0, 4.0, 68.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 0.0, 1.0, 86.0, 0.0, 0.0, 14.0, 1.0, 12.0, 0.0, 7.0, 0.0, 390.0, 307.0, 145.0, 233.0, 38.0, 4.0, 108.0, 257.0, 116.0, 107.0, 7.0, 0.0, 197.0, 367.0, 332.0, 159.0, 21.0, 0.0, 172.0, 181.0, 0.0, 88.0, 17.0, 0.0, 28.0, 20.0, 13.0, 0.0, 321.0, 222.0, 0.0, 0.0, 89.0, 63.0, 0.0, 0.0, 19.0, 80.0, 21.0, 0.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0846096787319943, "mean_inference_ms": 2.9117092993140203, "mean_action_processing_ms": 0.4393553329300755, "mean_env_wait_ms": 0.6716542771105566, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00876760482788086, "StateBufferConnector_ms": 0.00478971004486084, "ViewRequirementAgentConnector_ms": 0.20772361755371094}, "num_episodes": 22, "episode_return_max": 195.6999999999991, "episode_return_min": -115.50000000000003, "episode_return_mean": 40.5139999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 174.38112077441224, "num_env_steps_trained_throughput_per_sec": 174.38112077441224, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 13733.791, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13733.737, "sample_time_ms": 2339.07, "learn_time_ms": 11375.221, "learn_throughput": 351.642, "synch_weights_time_ms": 16.623}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "c52aa_00000", "date": "2024-08-12_23-51-59", "timestamp": 1723521119, "time_this_iter_s": 23.166186094284058, "time_total_s": 248.4403223991394, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab849b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 248.4403223991394, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 89.6909090909091, "ram_util_percent": 83.69393939393939}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2743173431151757, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.775795467820748, "policy_loss": -0.0044687186828543425, "vf_loss": 3.778928467710182, "vf_explained_var": 0.047839830476770956, "kl": 0.010553859611960684, "entropy": 1.4330946333824641, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31361039008491887, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.064435407913551, "policy_loss": -0.0018284591360796223, "vf_loss": 2.065797741987087, "vf_explained_var": 0.004779145200416525, "kl": 0.008286667921820593, "entropy": 1.4911793317113604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 195.6999999999991, "episode_reward_min": -115.50000000000003, "episode_reward_mean": 47.61699999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -647.1999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.5, "predator_policy": 390.0}, "policy_reward_mean": {"prey_policy": -15.761500000000042, "predator_policy": 39.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [42.700000000000344, 45.60000000000037, -46.9000000000001, 119.19999999999824, 96.69999999999858, -23.19999999999996, -18.79999999999974, -16.199999999999598, 79.99999999999937, 17.500000000000014, 79.59999999999935, 195.6999999999991, 35.200000000000315, 61.6000000000005, 53.50000000000052, 179.8999999999993, 35.600000000000236, 121.3999999999995, 101.49999999999858, 83.4999999999991, -34.399999999999594, 35.60000000000031, 34.40000000000022, -6.399999999999666, 130.89999999999898, 66.4000000000002, 117.3999999999994, 94.09999999999854, -38.099999999999554, -14.999999999999636, 138.9999999999989, -17.199999999999598, 57.60000000000024, 17.699999999999953, -21.799999999999812, 116.19999999999982, 16.899999999999917, 137.79999999999893, 102.89999999999881, 89.49999999999885, 89.49999999999943, -63.399999999999935, 49.50000000000047, 16.899999999999935, 143.4999999999993, -36.50000000000002, 79.5999999999994, -107.70000000000036, 69.70000000000009, 9.200000000000063, 16.899999999999935, -62.00000000000087, 121.89999999999935, 86.49999999999883, 81.69999999999911, 44.90000000000038, 157.09999999999974, -85.4000000000001, 63.10000000000024, 67.89999999999935, -69.00000000000018, 32.30000000000018, 28.10000000000018, 40.60000000000018, 129.3999999999991, -74.20000000000012, -34.999999999999964, 98.69999999999904, 52.00000000000023, 38.30000000000027, -114.70000000000027, 79.5999999999999, -115.50000000000003, 100.29999999999896, -13.299999999999798, 111.39999999999914, 52.90000000000048, 59.10000000000009, 75.89999999999957, 19.600000000000104, -5.999999999999995, 179.39999999999944, 40.0000000000003, -42.79999999999971, 67.49999999999999, 66.10000000000029, 90.89999999999904, 40.0000000000003, 88.89999999999978, 105.8999999999987, 118.79999999999944, 7.299999999999928, 76.49999999999999, 122.79999999999869, 50.69999999999985, 90.39999999999858, 24.800000000000143, -107.89999999999984, 101.89999999999898, 139.49999999999966], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 22.700000000000063, 33.50000000000024, 4.099999999999966, -40.89999999999981, -58.000000000000156, 53.30000000000023, 65.90000000000008, 17.299999999999976, 61.400000000000176, -13.599999999999858, -118.60000000000001, -0.09999999999999937, -105.70000000000039, -92.2000000000007, 20.000000000000014, -63.70000000000049, 61.70000000000008, -28.299999999999862, -11.199999999999934, 10.099999999999968, 60.50000000000022, 82.09999999999926, 113.59999999999988, 19.40000000000001, -119.20000000000027, 24.500000000000078, 37.10000000000025, 20.000000000000014, 33.50000000000024, 30.500000000000178, 133.3999999999999, 20.000000000000014, 11.599999999999971, 118.99999999999986, -13.599999999999904, 78.49999999999935, 20.000000000000014, -16.899999999999807, 61.40000000000016, -51.39999999999996, -42.99999999999982, 28.100000000000158, -5.500000000000018, -19.899999999999743, 35.30000000000025, -3.0999999999999757, -28.299999999999756, 100.09999999999957, 30.800000000000203, 35.300000000000175, 1.099999999999967, 20.000000000000014, 97.39999999999979, 11.599999999999968, 78.49999999999926, -34.59999999999977, -74.50000000000077, 20.000000000000014, -85.00000000000065, 42.50000000000025, 96.49999999999956, -139.6000000000007, 34.400000000000134, -78.70000000000071, 89.29999999999976, -24.099999999999746, -17.199999999999882, -93.70000000000041, -3.099999999999972, 36.20000000000008, 38.00000000000007, 11.599999999999973, -15.699999999999747, 14.599999999999966, 90.19999999999948, -28.29999999999975, 108.19999999999942, 69.4999999999998, 20.000000000000014, 20.000000000000014, 54.49999999999997, -154.3000000000005, -3.099999999999958, 15.799999999999963, 31.700000000000216, 15.799999999999946, -19.899999999999842, 104.59999999999977, 38.90000000000024, -112.29999999999998, 3.7999999999999816, 42.50000000000025, 37.10000000000026, 20.000000000000014, -291.70000000000005, 49.70000000000024, 20.000000000000014, 20.000000000000014, -38.79999999999976, 20.000000000000014, -24.099999999999838, -101.8000000000005, -47.19999999999976, 101.89999999999978, 20.000000000000014, 54.500000000000156, 16.999999999999964, 74.89999999999945, -5.199999999999937, 22.700000000000053, 15.199999999999964, -647.1999999999999, 107.29999999999976, -73.30000000000032, -390.1, -59.80000000000048, 80.89999999999999, -309.29999999999995, 12.20000000000023, -291.0000000000002, -1.0000000000000382, 5.299999999999965, 20.000000000000014, -549.6, 13.69999999999997, -383.70000000000005, -66.70000000000078, 82.99999999999966, 25.400000000000105, -238.30000000000027, -188.9, 5.299999999999965, -128.30000000000004, 61.70000000000012, 20.000000000000014, -60.99999999999991, 65.00000000000003, 20.000000000000014, 5.299999999999972, -213.6000000000003, -444.1, 59.600000000000165, 20.000000000000014, -71.49999999999994, -196.00000000000026, 20.000000000000014, 80.2999999999995, 23.900000000000148, -136.2, 17.299999999999983, 73.09999999999978, -5.1999999999999265, 46.10000000000024, 68.59999999999997, -44.49999999999978, 25.700000000000127, 18.19999999999999, 20.000000000000014, -57.40000000000023, -104.50000000000028, -11.499999999999819, 189.5, -54.10000000000006, 20.000000000000014, 20.000000000000014, -118.60000000000025, -5.1999999999999265, -32.49999999999989, 62.00000000000015, 63.80000000000021, -15.699999999999875, 59.90000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.6999999999999, -185.8000000000005, -1.3000000000000118, 72.19999999999959, 78.80000000000001, 20.000000000000014, -8.199999999999902, -241.5, -45.39999999999983, 83.89999999999988, 102.79999999999941, 20.000000000000014, 114.49999999999974, -460.8, 20.000000000000014, 70.39999999999975, 20.000000000000014, -59.200000000000145, -309.1999999999999, -257.69999999999993, 25.4000000000001, 66.49999999999996, 20.000000000000014, 99.50000000000003], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 8.0, 0.0, 52.0, 0.0, 0.0, 3.0, 15.0, 52.0, 57.0, 63.0, 24.0, 0.0, 56.0, 56.0, 26.0, 9.0, 48.0, 9.0, 0.0, 0.0, 0.0, 78.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 4.0, 0.0, 9.0, 7.0, 3.0, 0.0, 27.0, 12.0, 0.0, 60.0, 0.0, 13.0, 19.0, 0.0, 2.0, 23.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 4.0, 50.0, 21.0, 29.0, 21.0, 0.0, 0.0, 53.0, 35.0, 30.0, 17.0, 37.0, 22.0, 64.0, 11.0, 27.0, 15.0, 0.0, 21.0, 8.0, 25.0, 0.0, 23.0, 0.0, 0.0, 7.0, 8.0, 93.0, 1.0, 2.0, 0.0, 0.0, 21.0, 0.0, 0.0, 4.0, 68.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 0.0, 1.0, 86.0, 0.0, 0.0, 14.0, 1.0, 12.0, 0.0, 7.0, 0.0, 390.0, 307.0, 145.0, 233.0, 38.0, 4.0, 108.0, 257.0, 116.0, 107.0, 7.0, 0.0, 197.0, 367.0, 332.0, 159.0, 21.0, 0.0, 172.0, 181.0, 0.0, 88.0, 17.0, 0.0, 28.0, 20.0, 13.0, 0.0, 321.0, 222.0, 0.0, 0.0, 89.0, 63.0, 0.0, 0.0, 19.0, 80.0, 21.0, 0.0, 0.0, 12.0, 35.0, 0.0, 12.0, 20.0, 19.0, 38.0, 60.0, 50.0, 0.0, 44.0, 0.0, 0.0, 81.0, 0.0, 23.0, 15.0, 18.0, 0.0, 0.0, 11.0, 0.0, 0.0, 96.0, 69.0, 14.0, 21.0, 0.0, 20.0, 58.0, 199.0, 36.0, 2.0, 0.0, 0.0, 199.0, 198.0, 0.0, 0.0, 17.0, 47.0, 219.0, 240.0, 10.0, 0.0, 20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.097635785066647, "mean_inference_ms": 2.9448646006120778, "mean_action_processing_ms": 0.44308129121504863, "mean_env_wait_ms": 0.6810591572664794, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014683008193969727, "StateBufferConnector_ms": 0.01026618480682373, "ViewRequirementAgentConnector_ms": 0.24875807762145996}, "num_episodes": 23, "episode_return_max": 195.6999999999991, "episode_return_min": -115.50000000000003, "episode_return_mean": 47.61699999999974, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 248.8143504457771, "num_env_steps_trained_throughput_per_sec": 248.8143504457771, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 14144.328, "restore_workers_time_ms": 0.03, "training_step_time_ms": 14144.245, "sample_time_ms": 2462.867, "learn_time_ms": 11661.053, "learn_throughput": 343.022, "synch_weights_time_ms": 17.165}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "c52aa_00000", "date": "2024-08-12_23-52-15", "timestamp": 1723521135, "time_this_iter_s": 16.201317071914673, "time_total_s": 264.6416394710541, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x329e23ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 264.6416394710541, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 86.175, "ram_util_percent": 83.84166666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1242752537367835, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.935413896659064, "policy_loss": -0.003918898417417295, "vf_loss": 2.93810056315528, "vf_explained_var": 0.042985039255606435, "kl": 0.009736130684260885, "entropy": 1.430749531145449, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.26635304453078085, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4795644765493101, "policy_loss": -0.0023466518435814473, "vf_loss": 1.4817075313241392, "vf_explained_var": 0.004168825143228763, "kl": 0.003619509501038805, "entropy": 1.5175946774936857, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 179.39999999999944, "episode_reward_min": -115.50000000000003, "episode_reward_mean": 44.216999999999786, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -647.1999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.5, "predator_policy": 390.0}, "policy_reward_mean": {"prey_policy": -16.811500000000034, "predator_policy": 38.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [101.49999999999858, 83.4999999999991, -34.399999999999594, 35.60000000000031, 34.40000000000022, -6.399999999999666, 130.89999999999898, 66.4000000000002, 117.3999999999994, 94.09999999999854, -38.099999999999554, -14.999999999999636, 138.9999999999989, -17.199999999999598, 57.60000000000024, 17.699999999999953, -21.799999999999812, 116.19999999999982, 16.899999999999917, 137.79999999999893, 102.89999999999881, 89.49999999999885, 89.49999999999943, -63.399999999999935, 49.50000000000047, 16.899999999999935, 143.4999999999993, -36.50000000000002, 79.5999999999994, -107.70000000000036, 69.70000000000009, 9.200000000000063, 16.899999999999935, -62.00000000000087, 121.89999999999935, 86.49999999999883, 81.69999999999911, 44.90000000000038, 157.09999999999974, -85.4000000000001, 63.10000000000024, 67.89999999999935, -69.00000000000018, 32.30000000000018, 28.10000000000018, 40.60000000000018, 129.3999999999991, -74.20000000000012, -34.999999999999964, 98.69999999999904, 52.00000000000023, 38.30000000000027, -114.70000000000027, 79.5999999999999, -115.50000000000003, 100.29999999999896, -13.299999999999798, 111.39999999999914, 52.90000000000048, 59.10000000000009, 75.89999999999957, 19.600000000000104, -5.999999999999995, 179.39999999999944, 40.0000000000003, -42.79999999999971, 67.49999999999999, 66.10000000000029, 90.89999999999904, 40.0000000000003, 88.89999999999978, 105.8999999999987, 118.79999999999944, 7.299999999999928, 76.49999999999999, 122.79999999999869, 50.69999999999985, 90.39999999999858, 24.800000000000143, -107.89999999999984, 101.89999999999898, 139.49999999999966, 70.79999999999995, 75.3999999999996, 82.19999999999908, 30.300000000000214, 40.0000000000003, 40.0000000000003, 52.30000000000042, 36.60000000000024, 80.69999999999966, -30.399999999999707, 80.69999999999912, 10.400000000000073, 142.6999999999992, 1.0000000000002356, 52.20000000000043, -70.10000000000062, -3.099999999999741, 27.40000000000009], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [78.49999999999935, 20.000000000000014, -16.899999999999807, 61.40000000000016, -51.39999999999996, -42.99999999999982, 28.100000000000158, -5.500000000000018, -19.899999999999743, 35.30000000000025, -3.0999999999999757, -28.299999999999756, 100.09999999999957, 30.800000000000203, 35.300000000000175, 1.099999999999967, 20.000000000000014, 97.39999999999979, 11.599999999999968, 78.49999999999926, -34.59999999999977, -74.50000000000077, 20.000000000000014, -85.00000000000065, 42.50000000000025, 96.49999999999956, -139.6000000000007, 34.400000000000134, -78.70000000000071, 89.29999999999976, -24.099999999999746, -17.199999999999882, -93.70000000000041, -3.099999999999972, 36.20000000000008, 38.00000000000007, 11.599999999999973, -15.699999999999747, 14.599999999999966, 90.19999999999948, -28.29999999999975, 108.19999999999942, 69.4999999999998, 20.000000000000014, 20.000000000000014, 54.49999999999997, -154.3000000000005, -3.099999999999958, 15.799999999999963, 31.700000000000216, 15.799999999999946, -19.899999999999842, 104.59999999999977, 38.90000000000024, -112.29999999999998, 3.7999999999999816, 42.50000000000025, 37.10000000000026, 20.000000000000014, -291.70000000000005, 49.70000000000024, 20.000000000000014, 20.000000000000014, -38.79999999999976, 20.000000000000014, -24.099999999999838, -101.8000000000005, -47.19999999999976, 101.89999999999978, 20.000000000000014, 54.500000000000156, 16.999999999999964, 74.89999999999945, -5.199999999999937, 22.700000000000053, 15.199999999999964, -647.1999999999999, 107.29999999999976, -73.30000000000032, -390.1, -59.80000000000048, 80.89999999999999, -309.29999999999995, 12.20000000000023, -291.0000000000002, -1.0000000000000382, 5.299999999999965, 20.000000000000014, -549.6, 13.69999999999997, -383.70000000000005, -66.70000000000078, 82.99999999999966, 25.400000000000105, -238.30000000000027, -188.9, 5.299999999999965, -128.30000000000004, 61.70000000000012, 20.000000000000014, -60.99999999999991, 65.00000000000003, 20.000000000000014, 5.299999999999972, -213.6000000000003, -444.1, 59.600000000000165, 20.000000000000014, -71.49999999999994, -196.00000000000026, 20.000000000000014, 80.2999999999995, 23.900000000000148, -136.2, 17.299999999999983, 73.09999999999978, -5.1999999999999265, 46.10000000000024, 68.59999999999997, -44.49999999999978, 25.700000000000127, 18.19999999999999, 20.000000000000014, -57.40000000000023, -104.50000000000028, -11.499999999999819, 189.5, -54.10000000000006, 20.000000000000014, 20.000000000000014, -118.60000000000025, -5.1999999999999265, -32.49999999999989, 62.00000000000015, 63.80000000000021, -15.699999999999875, 59.90000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.6999999999999, -185.8000000000005, -1.3000000000000118, 72.19999999999959, 78.80000000000001, 20.000000000000014, -8.199999999999902, -241.5, -45.39999999999983, 83.89999999999988, 102.79999999999941, 20.000000000000014, 114.49999999999974, -460.8, 20.000000000000014, 70.39999999999975, 20.000000000000014, -59.200000000000145, -309.1999999999999, -257.69999999999993, 25.4000000000001, 66.49999999999996, 20.000000000000014, 99.50000000000003, 33.80000000000018, 20.000000000000014, 16.399999999999967, 47.000000000000185, 26.60000000000014, 29.600000000000126, -7.3000000000000345, -6.400000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 66.80000000000001, -47.499999999999915, -6.399999999999958, 20.000000000000014, 20.000000000000014, 43.700000000000124, 20.000000000000014, -114.4000000000005, 43.700000000000124, 20.000000000000014, -30.39999999999975, 15.799999999999963, 44.30000000000013, 85.39999999999989, -7.299999999999891, -15.699999999999754, 20.60000000000003, 11.599999999999968, -32.49999999999991, -163.60000000000036, -64.00000000000065, 20.900000000000013, 26.30000000000013, -16.899999999999743], "policy_predator_policy_reward": [3.0, 0.0, 27.0, 12.0, 0.0, 60.0, 0.0, 13.0, 19.0, 0.0, 2.0, 23.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 4.0, 50.0, 21.0, 29.0, 21.0, 0.0, 0.0, 53.0, 35.0, 30.0, 17.0, 37.0, 22.0, 64.0, 11.0, 27.0, 15.0, 0.0, 21.0, 8.0, 25.0, 0.0, 23.0, 0.0, 0.0, 7.0, 8.0, 93.0, 1.0, 2.0, 0.0, 0.0, 21.0, 0.0, 0.0, 4.0, 68.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 0.0, 1.0, 86.0, 0.0, 0.0, 14.0, 1.0, 12.0, 0.0, 7.0, 0.0, 390.0, 307.0, 145.0, 233.0, 38.0, 4.0, 108.0, 257.0, 116.0, 107.0, 7.0, 0.0, 197.0, 367.0, 332.0, 159.0, 21.0, 0.0, 172.0, 181.0, 0.0, 88.0, 17.0, 0.0, 28.0, 20.0, 13.0, 0.0, 321.0, 222.0, 0.0, 0.0, 89.0, 63.0, 0.0, 0.0, 19.0, 80.0, 21.0, 0.0, 0.0, 12.0, 35.0, 0.0, 12.0, 20.0, 19.0, 38.0, 60.0, 50.0, 0.0, 44.0, 0.0, 0.0, 81.0, 0.0, 23.0, 15.0, 18.0, 0.0, 0.0, 11.0, 0.0, 0.0, 96.0, 69.0, 14.0, 21.0, 0.0, 20.0, 58.0, 199.0, 36.0, 2.0, 0.0, 0.0, 199.0, 198.0, 0.0, 0.0, 17.0, 47.0, 219.0, 240.0, 10.0, 0.0, 20.0, 0.0, 2.0, 15.0, 12.0, 0.0, 26.0, 0.0, 13.0, 31.0, 0.0, 0.0, 0.0, 0.0, 10.0, 23.0, 1.0, 22.0, 17.0, 0.0, 0.0, 64.0, 8.0, 9.0, 0.0, 25.0, 0.0, 13.0, 24.0, 0.0, 20.0, 0.0, 79.0, 47.0, 8.0, 32.0, 0.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1043550107950686, "mean_inference_ms": 2.9651206235170093, "mean_action_processing_ms": 0.44519012355971177, "mean_env_wait_ms": 0.6853138700045548, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012734770774841309, "StateBufferConnector_ms": 0.009874343872070312, "ViewRequirementAgentConnector_ms": 0.23603510856628418}, "num_episodes": 18, "episode_return_max": 179.39999999999944, "episode_return_min": -115.50000000000003, "episode_return_mean": 44.216999999999786, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 184.80247500167567, "num_env_steps_trained_throughput_per_sec": 184.80247500167567, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 15076.744, "restore_workers_time_ms": 0.032, "training_step_time_ms": 15076.658, "sample_time_ms": 2535.436, "learn_time_ms": 12519.115, "learn_throughput": 319.511, "synch_weights_time_ms": 18.462}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "c52aa_00000", "date": "2024-08-12_23-52-37", "timestamp": 1723521157, "time_this_iter_s": 21.71880793571472, "time_total_s": 286.3604474067688, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 286.3604474067688, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 91.69032258064516, "ram_util_percent": 83.75806451612905}}
