{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9754333800266659, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.322771071378517, "policy_loss": -0.0011341325692319996, "vf_loss": 8.323161292202258, "vf_explained_var": 0.0011018332350190986, "kl": 0.0037195568084106845, "entropy": 1.6057659678988987, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.1923810056100289, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.936807135047105, "policy_loss": -0.002264576559768073, "vf_loss": 4.9382657989623056, "vf_explained_var": 0.0004617894768084168, "kl": 0.004029466461839633, "entropy": 1.605333844694511, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 212.00000000000006, "episode_reward_min": -181.20000000000053, "episode_reward_mean": 8.683333333333287, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -280.30000000000024, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 146.0, "predator_policy": 119.0}, "policy_reward_mean": {"prey_policy": -40.49166666666672, "predator_policy": 44.833333333333336}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.20000000000053, 43.80000000000025, 109.69999999999989, 104.39999999999918, -26.299999999999876, -17.399999999999793, 42.00000000000002, -75.89999999999998, 7.900000000000068, 212.00000000000006, -51.1000000000003, -70.4000000000001, 159.6999999999992, -28.199999999999676, -8.500000000000039, 40.0000000000003, -65.39999999999975, -38.799999999999734], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.3000000000001, -229.90000000000038, 44.299999999999976, -71.49999999999993, 117.20000000000005, -32.49999999999989, 20.000000000000014, 46.400000000000034, 20.000000000000014, -148.30000000000007, -235.9000000000001, 42.500000000000234, -124.90000000000035, 77.9, 30.800000000000132, -225.7000000000001, -73.00000000000054, -0.10000000000000281, 43.999999999999986, 146.0, 20.000000000000014, -180.10000000000014, -152.80000000000024, -13.599999999999929, 25.400000000000023, 107.29999999999993, -106.00000000000057, 15.800000000000011, -62.50000000000001, -18.999999999999936, 20.000000000000014, 20.000000000000014, 20.90000000000003, -280.30000000000024, -47.199999999999875, -97.60000000000012], "policy_predator_policy_reward": [105.0, 119.0, 34.0, 37.0, 0.0, 25.0, 37.0, 1.0, 102.0, 0.0, 103.0, 73.0, 0.0, 89.0, 114.0, 5.0, 62.0, 19.0, 22.0, 0.0, 109.0, 0.0, 0.0, 96.0, 0.0, 27.0, 2.0, 60.0, 66.0, 7.0, 0.0, 0.0, 99.0, 95.0, 106.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2726951370087203, "mean_inference_ms": 3.4960011235751574, "mean_action_processing_ms": 0.511278416096654, "mean_env_wait_ms": 0.8062239287151475, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01017451286315918, "StateBufferConnector_ms": 0.004425976011488173, "ViewRequirementAgentConnector_ms": 0.21708872583177355}, "num_episodes": 18, "episode_return_max": 212.00000000000006, "episode_return_min": -181.20000000000053, "episode_return_mean": 8.683333333333287, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 291.71951337770696, "num_env_steps_trained_throughput_per_sec": 291.71951337770696, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 13711.903, "restore_workers_time_ms": 0.023, "training_step_time_ms": 13711.501, "sample_time_ms": 2868.942, "learn_time_ms": 10823.214, "learn_throughput": 369.576, "synch_weights_time_ms": 14.678}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "c52aa_00000", "date": "2024-08-12_23-48-00", "timestamp": 1723520880, "time_this_iter_s": 13.764770746231079, "time_total_s": 13.764770746231079, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x329e9a940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 13.764770746231079, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 66.33500000000001, "ram_util_percent": 83.59}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.01835330881612, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.9723015308380125, "policy_loss": -0.00035443076372353567, "vf_loss": 6.972340392561817, "vf_explained_var": 0.0008738648954522673, "kl": 0.003155770886078375, "entropy": 1.6005018431673605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.24884065567027955, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.070569634059119, "policy_loss": -0.0009434448727579028, "vf_loss": 3.071230347635885, "vf_explained_var": 0.006315625439245234, "kl": 0.002827430692251085, "entropy": 1.602841581175567, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 225.8999999999995, "episode_reward_min": -181.20000000000053, "episode_reward_mean": 30.333333333333215, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -280.30000000000024, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.6, "predator_policy": 145.0}, "policy_reward_mean": {"prey_policy": -22.70833333333341, "predator_policy": 37.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.20000000000053, 43.80000000000025, 109.69999999999989, 104.39999999999918, -26.299999999999876, -17.399999999999793, 42.00000000000002, -75.89999999999998, 7.900000000000068, 212.00000000000006, -51.1000000000003, -70.4000000000001, 159.6999999999992, -28.199999999999676, -8.500000000000039, 40.0000000000003, -65.39999999999975, -38.799999999999734, 65.8000000000001, 40.9000000000003, 105.19999999999862, -121.90000000000046, 44.200000000000315, 52.40000000000046, -118.30000000000078, 195.59999999999997, -28.699999999999783, 225.8999999999995, 36.50000000000014, -61.10000000000053, 65.20000000000002, 165.09999999999857, 63.40000000000015, 160.39999999999944, 6.800000000000191, 38.30000000000033], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.3000000000001, -229.90000000000038, 44.299999999999976, -71.49999999999993, 117.20000000000005, -32.49999999999989, 20.000000000000014, 46.400000000000034, 20.000000000000014, -148.30000000000007, -235.9000000000001, 42.500000000000234, -124.90000000000035, 77.9, 30.800000000000132, -225.7000000000001, -73.00000000000054, -0.10000000000000281, 43.999999999999986, 146.0, 20.000000000000014, -180.10000000000014, -152.80000000000024, -13.599999999999929, 25.400000000000023, 107.29999999999993, -106.00000000000057, 15.800000000000011, -62.50000000000001, -18.999999999999936, 20.000000000000014, 20.000000000000014, 20.90000000000003, -280.30000000000024, -47.199999999999875, -97.60000000000012, 20.000000000000014, 12.800000000000104, 20.90000000000003, 20.000000000000014, 92.89999999999932, 5.299999999999981, -174.70000000000024, -137.20000000000022, 18.19999999999999, 20.000000000000014, 31.40000000000019, 20.000000000000014, -202.29999999999998, -85.00000000000063, 11.599999999999994, 112.99999999999997, -25.59999999999991, -81.10000000000036, 38.30000000000013, 185.6, -53.19999999999998, -4.299999999999811, 20.000000000000014, -204.10000000000028, 137.0, -230.8000000000004, 73.99999999999949, 91.09999999999951, 46.69999999999996, -37.30000000000013, 139.39999999999995, 20.000000000000014, 30.80000000000003, -109.0000000000001, -21.69999999999984, 20.000000000000014], "policy_predator_policy_reward": [105.0, 119.0, 34.0, 37.0, 0.0, 25.0, 37.0, 1.0, 102.0, 0.0, 103.0, 73.0, 0.0, 89.0, 114.0, 5.0, 62.0, 19.0, 22.0, 0.0, 109.0, 0.0, 0.0, 96.0, 0.0, 27.0, 2.0, 60.0, 66.0, 7.0, 0.0, 0.0, 99.0, 95.0, 106.0, 0.0, 32.0, 1.0, 0.0, 0.0, 0.0, 7.0, 145.0, 45.0, 6.0, 0.0, 0.0, 1.0, 53.0, 116.0, 51.0, 20.0, 55.0, 23.0, 0.0, 2.0, 89.0, 5.0, 90.0, 33.0, 121.0, 38.0, 0.0, 0.0, 54.0, 0.0, 0.0, 1.0, 0.0, 85.0, 0.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.292762278389827, "mean_inference_ms": 3.6151257371066845, "mean_action_processing_ms": 0.5163488762280399, "mean_env_wait_ms": 0.7966842830453597, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009749001926845975, "StateBufferConnector_ms": 0.003848473230997721, "ViewRequirementAgentConnector_ms": 0.22714369826846653}, "num_episodes": 18, "episode_return_max": 225.8999999999995, "episode_return_min": -181.20000000000053, "episode_return_mean": 30.333333333333215, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 231.87685025206557, "num_env_steps_trained_throughput_per_sec": 231.87685025206557, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 15481.227, "restore_workers_time_ms": 0.038, "training_step_time_ms": 15480.923, "sample_time_ms": 3124.401, "learn_time_ms": 12337.364, "learn_throughput": 324.218, "synch_weights_time_ms": 15.855}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "c52aa_00000", "date": "2024-08-12_23-48-21", "timestamp": 1723520901, "time_this_iter_s": 17.34367299079895, "time_total_s": 31.10844373703003, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x329e8c160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 31.10844373703003, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 78.44137931034484, "ram_util_percent": 83.60689655172413}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.820730807667687, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.217157073878737, "policy_loss": -0.003413176498617287, "vf_loss": 5.219739789306802, "vf_explained_var": 0.006424905635692455, "kl": 0.016609512232295457, "entropy": 1.5654190144841633, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2551283666834472, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2696405039893257, "policy_loss": -0.00031037387997404764, "vf_loss": 3.2698409938938404, "vf_explained_var": -0.000904154588305761, "kl": 0.002197708652933173, "entropy": 1.5985646708932504, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 225.8999999999995, "episode_reward_min": -181.20000000000053, "episode_reward_mean": 29.49074074074061, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -280.30000000000024, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.6, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -19.291666666666746, "predator_policy": 34.03703703703704}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.20000000000053, 43.80000000000025, 109.69999999999989, 104.39999999999918, -26.299999999999876, -17.399999999999793, 42.00000000000002, -75.89999999999998, 7.900000000000068, 212.00000000000006, -51.1000000000003, -70.4000000000001, 159.6999999999992, -28.199999999999676, -8.500000000000039, 40.0000000000003, -65.39999999999975, -38.799999999999734, 65.8000000000001, 40.9000000000003, 105.19999999999862, -121.90000000000046, 44.200000000000315, 52.40000000000046, -118.30000000000078, 195.59999999999997, -28.699999999999783, 225.8999999999995, 36.50000000000014, -61.10000000000053, 65.20000000000002, 165.09999999999857, 63.40000000000015, 160.39999999999944, 6.800000000000191, 38.30000000000033, 9.800000000000104, 71.29999999999973, 61.00000000000027, 98.19999999999942, 1.400000000000272, -55.800000000000026, 20.700000000000003, -65.10000000000005, 111.9999999999985, -50.60000000000076, 151.39999999999938, 118.69999999999996, 11.400000000000166, 39.000000000000256, 4.800000000000124, 40.0000000000003, -127.50000000000065, 59.80000000000043], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.3000000000001, -229.90000000000038, 44.299999999999976, -71.49999999999993, 117.20000000000005, -32.49999999999989, 20.000000000000014, 46.400000000000034, 20.000000000000014, -148.30000000000007, -235.9000000000001, 42.500000000000234, -124.90000000000035, 77.9, 30.800000000000132, -225.7000000000001, -73.00000000000054, -0.10000000000000281, 43.999999999999986, 146.0, 20.000000000000014, -180.10000000000014, -152.80000000000024, -13.599999999999929, 25.400000000000023, 107.29999999999993, -106.00000000000057, 15.800000000000011, -62.50000000000001, -18.999999999999936, 20.000000000000014, 20.000000000000014, 20.90000000000003, -280.30000000000024, -47.199999999999875, -97.60000000000012, 20.000000000000014, 12.800000000000104, 20.90000000000003, 20.000000000000014, 92.89999999999932, 5.299999999999981, -174.70000000000024, -137.20000000000022, 18.19999999999999, 20.000000000000014, 31.40000000000019, 20.000000000000014, -202.29999999999998, -85.00000000000063, 11.599999999999994, 112.99999999999997, -25.59999999999991, -81.10000000000036, 38.30000000000013, 185.6, -53.19999999999998, -4.299999999999811, 20.000000000000014, -204.10000000000028, 137.0, -230.8000000000004, 73.99999999999949, 91.09999999999951, 46.69999999999996, -37.30000000000013, 139.39999999999995, 20.000000000000014, 30.80000000000003, -109.0000000000001, -21.69999999999984, 20.000000000000014, 27.200000000000024, -51.39999999999992, 46.70000000000012, 23.60000000000008, 1.0999999999999819, 47.90000000000012, 20.000000000000014, 54.20000000000007, -21.099999999999895, -11.500000000000021, -6.100000000000016, -141.7, -21.999999999999744, 22.700000000000063, 21.80000000000004, -247.90000000000032, 79.39999999999927, 32.60000000000019, -76.90000000000066, -126.70000000000039, 1.6999999999999689, 121.69999999999996, -51.3999999999999, 136.1000000000001, -61.900000000000766, 2.3000000000000913, 4.999999999999956, 20.000000000000014, -179.50000000000057, 89.29999999999981, 20.000000000000014, 20.000000000000014, -76.60000000000053, -226.90000000000023, 20.000000000000014, 39.800000000000196], "policy_predator_policy_reward": [105.0, 119.0, 34.0, 37.0, 0.0, 25.0, 37.0, 1.0, 102.0, 0.0, 103.0, 73.0, 0.0, 89.0, 114.0, 5.0, 62.0, 19.0, 22.0, 0.0, 109.0, 0.0, 0.0, 96.0, 0.0, 27.0, 2.0, 60.0, 66.0, 7.0, 0.0, 0.0, 99.0, 95.0, 106.0, 0.0, 32.0, 1.0, 0.0, 0.0, 0.0, 7.0, 145.0, 45.0, 6.0, 0.0, 0.0, 1.0, 53.0, 116.0, 51.0, 20.0, 55.0, 23.0, 0.0, 2.0, 89.0, 5.0, 90.0, 33.0, 121.0, 38.0, 0.0, 0.0, 54.0, 0.0, 0.0, 1.0, 0.0, 85.0, 0.0, 40.0, 0.0, 34.0, 0.0, 1.0, 4.0, 8.0, 24.0, 0.0, 34.0, 0.0, 77.0, 15.0, 20.0, 0.0, 0.0, 161.0, 0.0, 0.0, 71.0, 82.0, 18.0, 10.0, 34.0, 0.0, 47.0, 24.0, 14.0, 0.0, 0.0, 95.0, 0.0, 0.0, 46.0, 130.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2619909967546334, "mean_inference_ms": 3.5510240047865347, "mean_action_processing_ms": 0.500674092824107, "mean_env_wait_ms": 0.7738771358288278, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009061892827351889, "StateBufferConnector_ms": 0.004007860466285988, "ViewRequirementAgentConnector_ms": 0.20486955289487485}, "num_episodes": 18, "episode_return_max": 225.8999999999995, "episode_return_min": -181.20000000000053, "episode_return_mean": 29.49074074074061, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.0043794483781, "num_env_steps_trained_throughput_per_sec": 334.0043794483781, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 14312.788, "restore_workers_time_ms": 0.036, "training_step_time_ms": 14312.547, "sample_time_ms": 2819.148, "learn_time_ms": 11474.057, "learn_throughput": 348.613, "synch_weights_time_ms": 14.497}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "c52aa_00000", "date": "2024-08-12_23-48-33", "timestamp": 1723520913, "time_this_iter_s": 12.016723155975342, "time_total_s": 43.12516689300537, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x329e9aee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 43.12516689300537, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 62.84117647058823, "ram_util_percent": 83.58235294117648}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4697635083050324, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.5018239472908945, "policy_loss": -0.0024220447618977497, "vf_loss": 5.503322423198235, "vf_explained_var": 0.009395080016403603, "kl": 0.018471475719752044, "entropy": 1.551901041452216, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2457746089864818, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4951030386188044, "policy_loss": -0.0024875041225521023, "vf_loss": 2.497412983387236, "vf_explained_var": -0.000329599935541708, "kl": 0.007102534548523408, "entropy": 1.5850179230094588, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 225.8999999999995, "episode_reward_min": -182.0000000000012, "episode_reward_mean": 30.60416666666653, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -288.6999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.6, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -15.40625000000007, "predator_policy": 30.708333333333332}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.20000000000053, 43.80000000000025, 109.69999999999989, 104.39999999999918, -26.299999999999876, -17.399999999999793, 42.00000000000002, -75.89999999999998, 7.900000000000068, 212.00000000000006, -51.1000000000003, -70.4000000000001, 159.6999999999992, -28.199999999999676, -8.500000000000039, 40.0000000000003, -65.39999999999975, -38.799999999999734, 65.8000000000001, 40.9000000000003, 105.19999999999862, -121.90000000000046, 44.200000000000315, 52.40000000000046, -118.30000000000078, 195.59999999999997, -28.699999999999783, 225.8999999999995, 36.50000000000014, -61.10000000000053, 65.20000000000002, 165.09999999999857, 63.40000000000015, 160.39999999999944, 6.800000000000191, 38.30000000000033, 9.800000000000104, 71.29999999999973, 61.00000000000027, 98.19999999999942, 1.400000000000272, -55.800000000000026, 20.700000000000003, -65.10000000000005, 111.9999999999985, -50.60000000000076, 151.39999999999938, 118.69999999999996, 11.400000000000166, 39.000000000000256, 4.800000000000124, 40.0000000000003, -127.50000000000065, 59.80000000000043, -137.5000000000009, 67.90000000000023, -102.80000000000035, -32.199999999999775, 223.09999999999937, 182.1999999999993, -20.49999999999961, 170.49999999999895, 40.0000000000003, 169.69999999999953, -9.499999999999806, 25.20000000000018, 19.199999999999964, 15.800000000000267, 68.80000000000038, -182.0000000000012, 38.90000000000028, 74.20000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.3000000000001, -229.90000000000038, 44.299999999999976, -71.49999999999993, 117.20000000000005, -32.49999999999989, 20.000000000000014, 46.400000000000034, 20.000000000000014, -148.30000000000007, -235.9000000000001, 42.500000000000234, -124.90000000000035, 77.9, 30.800000000000132, -225.7000000000001, -73.00000000000054, -0.10000000000000281, 43.999999999999986, 146.0, 20.000000000000014, -180.10000000000014, -152.80000000000024, -13.599999999999929, 25.400000000000023, 107.29999999999993, -106.00000000000057, 15.800000000000011, -62.50000000000001, -18.999999999999936, 20.000000000000014, 20.000000000000014, 20.90000000000003, -280.30000000000024, -47.199999999999875, -97.60000000000012, 20.000000000000014, 12.800000000000104, 20.90000000000003, 20.000000000000014, 92.89999999999932, 5.299999999999981, -174.70000000000024, -137.20000000000022, 18.19999999999999, 20.000000000000014, 31.40000000000019, 20.000000000000014, -202.29999999999998, -85.00000000000063, 11.599999999999994, 112.99999999999997, -25.59999999999991, -81.10000000000036, 38.30000000000013, 185.6, -53.19999999999998, -4.299999999999811, 20.000000000000014, -204.10000000000028, 137.0, -230.8000000000004, 73.99999999999949, 91.09999999999951, 46.69999999999996, -37.30000000000013, 139.39999999999995, 20.000000000000014, 30.80000000000003, -109.0000000000001, -21.69999999999984, 20.000000000000014, 27.200000000000024, -51.39999999999992, 46.70000000000012, 23.60000000000008, 1.0999999999999819, 47.90000000000012, 20.000000000000014, 54.20000000000007, -21.099999999999895, -11.500000000000021, -6.100000000000016, -141.7, -21.999999999999744, 22.700000000000063, 21.80000000000004, -247.90000000000032, 79.39999999999927, 32.60000000000019, -76.90000000000066, -126.70000000000039, 1.6999999999999689, 121.69999999999996, -51.3999999999999, 136.1000000000001, -61.900000000000766, 2.3000000000000913, 4.999999999999956, 20.000000000000014, -179.50000000000057, 89.29999999999981, 20.000000000000014, 20.000000000000014, -76.60000000000053, -226.90000000000023, 20.000000000000014, 39.800000000000196, -288.6999999999996, 3.1999999999999615, 20.90000000000003, 46.99999999999998, -72.10000000000002, -204.7000000000005, 15.799999999999963, -136.0000000000002, 168.19999999999993, 47.89999999999997, 159.49999999999994, 13.699999999999987, -13.599999999999868, -61.90000000000064, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.70000000000005, -112.30000000000015, 39.80000000000025, 20.000000000000014, -23.79999999999984, 20.000000000000014, -23.799999999999756, 20.000000000000014, -26.200000000000024, 22.700000000000063, 46.10000000000011, -142.90000000000066, -162.10000000000053, 20.000000000000014, 17.899999999999988, 28.100000000000037, 46.09999999999997], "policy_predator_policy_reward": [105.0, 119.0, 34.0, 37.0, 0.0, 25.0, 37.0, 1.0, 102.0, 0.0, 103.0, 73.0, 0.0, 89.0, 114.0, 5.0, 62.0, 19.0, 22.0, 0.0, 109.0, 0.0, 0.0, 96.0, 0.0, 27.0, 2.0, 60.0, 66.0, 7.0, 0.0, 0.0, 99.0, 95.0, 106.0, 0.0, 32.0, 1.0, 0.0, 0.0, 0.0, 7.0, 145.0, 45.0, 6.0, 0.0, 0.0, 1.0, 53.0, 116.0, 51.0, 20.0, 55.0, 23.0, 0.0, 2.0, 89.0, 5.0, 90.0, 33.0, 121.0, 38.0, 0.0, 0.0, 54.0, 0.0, 0.0, 1.0, 0.0, 85.0, 0.0, 40.0, 0.0, 34.0, 0.0, 1.0, 4.0, 8.0, 24.0, 0.0, 34.0, 0.0, 77.0, 15.0, 20.0, 0.0, 0.0, 161.0, 0.0, 0.0, 71.0, 82.0, 18.0, 10.0, 34.0, 0.0, 47.0, 24.0, 14.0, 0.0, 0.0, 95.0, 0.0, 0.0, 46.0, 130.0, 0.0, 0.0, 146.0, 2.0, 0.0, 0.0, 33.0, 141.0, 88.0, 0.0, 0.0, 7.0, 9.0, 0.0, 39.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 63.0, 0.0, 0.0, 29.0, 23.0, 0.0, 22.0, 0.0, 0.0, 0.0, 47.0, 76.0, 1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2340618323417065, "mean_inference_ms": 3.489181551899381, "mean_action_processing_ms": 0.49106778929741474, "mean_env_wait_ms": 0.7599571640200846, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010557472705841064, "StateBufferConnector_ms": 0.0038295984268188477, "ViewRequirementAgentConnector_ms": 0.1816994614071316}, "num_episodes": 18, "episode_return_max": 225.8999999999995, "episode_return_min": -182.0000000000012, "episode_return_mean": 30.60416666666653, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 305.892200688007, "num_env_steps_trained_throughput_per_sec": 305.892200688007, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 14003.718, "restore_workers_time_ms": 0.031, "training_step_time_ms": 14003.527, "sample_time_ms": 2695.766, "learn_time_ms": 11287.156, "learn_throughput": 354.385, "synch_weights_time_ms": 16.719}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "c52aa_00000", "date": "2024-08-12_23-48-46", "timestamp": 1723520926, "time_this_iter_s": 13.145484924316406, "time_total_s": 56.27065181732178, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9bce50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 56.27065181732178, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 67.42105263157895, "ram_util_percent": 82.07894736842105}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3278914643816215, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7392617841246265, "policy_loss": -0.0015304019014355998, "vf_loss": 3.740190351450885, "vf_explained_var": -0.0009882239122239371, "kl": 0.012036633807776125, "entropy": 1.5050477952553483, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.21064882967719642, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5285553020144267, "policy_loss": -0.00470479402676343, "vf_loss": 2.5329155002952253, "vf_explained_var": -0.0001330958156989365, "kl": 0.013783433803470581, "entropy": 1.5732053479189596, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 225.8999999999995, "episode_reward_min": -201.50000000000026, "episode_reward_mean": 28.77070707070694, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -288.6999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.6, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -14.543939393939448, "predator_policy": 28.92929292929293}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.20000000000053, 43.80000000000025, 109.69999999999989, 104.39999999999918, -26.299999999999876, -17.399999999999793, 42.00000000000002, -75.89999999999998, 7.900000000000068, 212.00000000000006, -51.1000000000003, -70.4000000000001, 159.6999999999992, -28.199999999999676, -8.500000000000039, 40.0000000000003, -65.39999999999975, -38.799999999999734, 65.8000000000001, 40.9000000000003, 105.19999999999862, -121.90000000000046, 44.200000000000315, 52.40000000000046, -118.30000000000078, 195.59999999999997, -28.699999999999783, 225.8999999999995, 36.50000000000014, -61.10000000000053, 65.20000000000002, 165.09999999999857, 63.40000000000015, 160.39999999999944, 6.800000000000191, 38.30000000000033, 9.800000000000104, 71.29999999999973, 61.00000000000027, 98.19999999999942, 1.400000000000272, -55.800000000000026, 20.700000000000003, -65.10000000000005, 111.9999999999985, -50.60000000000076, 151.39999999999938, 118.69999999999996, 11.400000000000166, 39.000000000000256, 4.800000000000124, 40.0000000000003, -127.50000000000065, 59.80000000000043, -137.5000000000009, 67.90000000000023, -102.80000000000035, -32.199999999999775, 223.09999999999937, 182.1999999999993, -20.49999999999961, 170.49999999999895, 40.0000000000003, 169.69999999999953, -9.499999999999806, 25.20000000000018, 19.199999999999964, 15.800000000000267, 68.80000000000038, -182.0000000000012, 38.90000000000028, 74.20000000000016, 77.7999999999999, 9.099999999999989, 40.0000000000003, 46.30000000000034, 84.99999999999898, 23.500000000000096, 89.89999999999995, -56.89999999999991, 11.499999999999929, 40.0000000000003, -105.7000000000005, 17.400000000000077, 153.39999999999966, -201.50000000000026, -29.299999999999564, -122.10000000000039, 72.20000000000002, 1.3000000000001606, 76.59999999999951, 108.0999999999989, 66.50000000000023, 111.89999999999947, 84.99999999999898, -31.099999999999675, 33.50000000000005, 12.499999999999988, 29.900000000000123], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-175.3000000000001, -229.90000000000038, 44.299999999999976, -71.49999999999993, 117.20000000000005, -32.49999999999989, 20.000000000000014, 46.400000000000034, 20.000000000000014, -148.30000000000007, -235.9000000000001, 42.500000000000234, -124.90000000000035, 77.9, 30.800000000000132, -225.7000000000001, -73.00000000000054, -0.10000000000000281, 43.999999999999986, 146.0, 20.000000000000014, -180.10000000000014, -152.80000000000024, -13.599999999999929, 25.400000000000023, 107.29999999999993, -106.00000000000057, 15.800000000000011, -62.50000000000001, -18.999999999999936, 20.000000000000014, 20.000000000000014, 20.90000000000003, -280.30000000000024, -47.199999999999875, -97.60000000000012, 20.000000000000014, 12.800000000000104, 20.90000000000003, 20.000000000000014, 92.89999999999932, 5.299999999999981, -174.70000000000024, -137.20000000000022, 18.19999999999999, 20.000000000000014, 31.40000000000019, 20.000000000000014, -202.29999999999998, -85.00000000000063, 11.599999999999994, 112.99999999999997, -25.59999999999991, -81.10000000000036, 38.30000000000013, 185.6, -53.19999999999998, -4.299999999999811, 20.000000000000014, -204.10000000000028, 137.0, -230.8000000000004, 73.99999999999949, 91.09999999999951, 46.69999999999996, -37.30000000000013, 139.39999999999995, 20.000000000000014, 30.80000000000003, -109.0000000000001, -21.69999999999984, 20.000000000000014, 27.200000000000024, -51.39999999999992, 46.70000000000012, 23.60000000000008, 1.0999999999999819, 47.90000000000012, 20.000000000000014, 54.20000000000007, -21.099999999999895, -11.500000000000021, -6.100000000000016, -141.7, -21.999999999999744, 22.700000000000063, 21.80000000000004, -247.90000000000032, 79.39999999999927, 32.60000000000019, -76.90000000000066, -126.70000000000039, 1.6999999999999689, 121.69999999999996, -51.3999999999999, 136.1000000000001, -61.900000000000766, 2.3000000000000913, 4.999999999999956, 20.000000000000014, -179.50000000000057, 89.29999999999981, 20.000000000000014, 20.000000000000014, -76.60000000000053, -226.90000000000023, 20.000000000000014, 39.800000000000196, -288.6999999999996, 3.1999999999999615, 20.90000000000003, 46.99999999999998, -72.10000000000002, -204.7000000000005, 15.799999999999963, -136.0000000000002, 168.19999999999993, 47.89999999999997, 159.49999999999994, 13.699999999999987, -13.599999999999868, -61.90000000000064, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.70000000000005, -112.30000000000015, 39.80000000000025, 20.000000000000014, -23.79999999999984, 20.000000000000014, -23.799999999999756, 20.000000000000014, -26.200000000000024, 22.700000000000063, 46.10000000000011, -142.90000000000066, -162.10000000000053, 20.000000000000014, 17.899999999999988, 28.100000000000037, 46.09999999999997, 57.80000000000021, 20.000000000000014, -5.1999999999999265, -27.69999999999984, 20.000000000000014, 20.000000000000014, 26.30000000000013, 20.000000000000014, 20.000000000000014, 65.00000000000014, -50.49999999999985, 20.000000000000014, -26.500000000000007, 73.39999999999995, -125.2000000000001, -69.70000000000007, 20.000000000000014, -47.499999999999794, 20.000000000000014, 20.000000000000014, -55.89999999999993, -155.80000000000013, 20.000000000000014, -52.59999999999985, 48.80000000000015, 104.59999999999997, -178.6000000000001, -166.90000000000032, 20.000000000000014, -112.30000000000051, -93.40000000000076, -237.7000000000001, 49.40000000000021, 21.80000000000001, -136.30000000000018, 8.600000000000001, 50.000000000000185, -6.399999999999951, 64.10000000000021, 20.000000000000053, 20.000000000000014, 30.500000000000192, 64.40000000000003, 33.500000000000085, 20.000000000000014, 65.00000000000014, -100.30000000000052, -2.799999999999972, -144.70000000000002, 84.19999999999969, 20.000000000000014, -32.49999999999976, -0.10000000000003478, 20.000000000000014], "policy_predator_policy_reward": [105.0, 119.0, 34.0, 37.0, 0.0, 25.0, 37.0, 1.0, 102.0, 0.0, 103.0, 73.0, 0.0, 89.0, 114.0, 5.0, 62.0, 19.0, 22.0, 0.0, 109.0, 0.0, 0.0, 96.0, 0.0, 27.0, 2.0, 60.0, 66.0, 7.0, 0.0, 0.0, 99.0, 95.0, 106.0, 0.0, 32.0, 1.0, 0.0, 0.0, 0.0, 7.0, 145.0, 45.0, 6.0, 0.0, 0.0, 1.0, 53.0, 116.0, 51.0, 20.0, 55.0, 23.0, 0.0, 2.0, 89.0, 5.0, 90.0, 33.0, 121.0, 38.0, 0.0, 0.0, 54.0, 0.0, 0.0, 1.0, 0.0, 85.0, 0.0, 40.0, 0.0, 34.0, 0.0, 1.0, 4.0, 8.0, 24.0, 0.0, 34.0, 0.0, 77.0, 15.0, 20.0, 0.0, 0.0, 161.0, 0.0, 0.0, 71.0, 82.0, 18.0, 10.0, 34.0, 0.0, 47.0, 24.0, 14.0, 0.0, 0.0, 95.0, 0.0, 0.0, 46.0, 130.0, 0.0, 0.0, 146.0, 2.0, 0.0, 0.0, 33.0, 141.0, 88.0, 0.0, 0.0, 7.0, 9.0, 0.0, 39.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 63.0, 0.0, 0.0, 29.0, 23.0, 0.0, 22.0, 0.0, 0.0, 0.0, 47.0, 76.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 29.0, 11.0, 32.0, 78.0, 60.0, 39.0, 0.0, 0.0, 0.0, 1.0, 105.0, 0.0, 50.0, 0.0, 0.0, 144.0, 0.0, 0.0, 63.0, 130.0, 79.0, 1.0, 0.0, 30.0, 99.0, 14.0, 19.0, 24.0, 0.0, 3.0, 13.0, 0.0, 14.0, 0.0, 0.0, 15.0, 57.0, 0.0, 94.0, 25.0, 0.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2096045978537273, "mean_inference_ms": 3.419188908718823, "mean_action_processing_ms": 0.4832160205267986, "mean_env_wait_ms": 0.7464373500270982, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010259344120218295, "StateBufferConnector_ms": 0.005290604601002702, "ViewRequirementAgentConnector_ms": 0.19227266311645508}, "num_episodes": 27, "episode_return_max": 225.8999999999995, "episode_return_min": -201.50000000000026, "episode_return_mean": 28.77070707070694, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 320.0247272523899, "num_env_steps_trained_throughput_per_sec": 320.0247272523899, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 13702.783, "restore_workers_time_ms": 0.028, "training_step_time_ms": 13702.621, "sample_time_ms": 2647.859, "learn_time_ms": 11035.488, "learn_throughput": 362.467, "synch_weights_time_ms": 15.942}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "c52aa_00000", "date": "2024-08-12_23-48-58", "timestamp": 1723520938, "time_this_iter_s": 12.540761232376099, "time_total_s": 68.81141304969788, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 68.81141304969788, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 64.53333333333335, "ram_util_percent": 83.00555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.305926874390355, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.1476781760574015, "policy_loss": -0.0014158958073941961, "vf_loss": 5.148538864352716, "vf_explained_var": -0.0019447982311248779, "kl": 0.0111039856169673, "entropy": 1.4956527590751647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2633786102963818, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.383273282883659, "policy_loss": -0.00393929787894228, "vf_loss": 3.3868978875023976, "vf_explained_var": -5.189293906802223e-05, "kl": 0.012587686711848905, "entropy": 1.5633633688013389, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 225.8999999999995, "episode_reward_min": -349.59999999999997, "episode_reward_mean": 18.727999999999863, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -288.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.6, "predator_policy": 202.0}, "policy_reward_mean": {"prey_policy": -19.041000000000043, "predator_policy": 28.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-38.799999999999734, 65.8000000000001, 40.9000000000003, 105.19999999999862, -121.90000000000046, 44.200000000000315, 52.40000000000046, -118.30000000000078, 195.59999999999997, -28.699999999999783, 225.8999999999995, 36.50000000000014, -61.10000000000053, 65.20000000000002, 165.09999999999857, 63.40000000000015, 160.39999999999944, 6.800000000000191, 38.30000000000033, 9.800000000000104, 71.29999999999973, 61.00000000000027, 98.19999999999942, 1.400000000000272, -55.800000000000026, 20.700000000000003, -65.10000000000005, 111.9999999999985, -50.60000000000076, 151.39999999999938, 118.69999999999996, 11.400000000000166, 39.000000000000256, 4.800000000000124, 40.0000000000003, -127.50000000000065, 59.80000000000043, -137.5000000000009, 67.90000000000023, -102.80000000000035, -32.199999999999775, 223.09999999999937, 182.1999999999993, -20.49999999999961, 170.49999999999895, 40.0000000000003, 169.69999999999953, -9.499999999999806, 25.20000000000018, 19.199999999999964, 15.800000000000267, 68.80000000000038, -182.0000000000012, 38.90000000000028, 74.20000000000016, 77.7999999999999, 9.099999999999989, 40.0000000000003, 46.30000000000034, 84.99999999999898, 23.500000000000096, 89.89999999999995, -56.89999999999991, 11.499999999999929, 40.0000000000003, -105.7000000000005, 17.400000000000077, 153.39999999999966, -201.50000000000026, -29.299999999999564, -122.10000000000039, 72.20000000000002, 1.3000000000001606, 76.59999999999951, 108.0999999999989, 66.50000000000023, 111.89999999999947, 84.99999999999898, -31.099999999999675, 33.50000000000005, 12.499999999999988, 29.900000000000123, 61.29999999999933, -42.000000000000284, -349.59999999999997, 16.89999999999992, 30.100000000000147, -105.0000000000004, -172.2999999999999, 7.999999999999979, 40.90000000000031, -171.60000000000045, -76.90000000000012, -46.39999999999968, 36.700000000000294, -69.90000000000055, 91.29999999999855, -127.79999999999993, 49.60000000000037, 46.300000000000395], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-47.199999999999875, -97.60000000000012, 20.000000000000014, 12.800000000000104, 20.90000000000003, 20.000000000000014, 92.89999999999932, 5.299999999999981, -174.70000000000024, -137.20000000000022, 18.19999999999999, 20.000000000000014, 31.40000000000019, 20.000000000000014, -202.29999999999998, -85.00000000000063, 11.599999999999994, 112.99999999999997, -25.59999999999991, -81.10000000000036, 38.30000000000013, 185.6, -53.19999999999998, -4.299999999999811, 20.000000000000014, -204.10000000000028, 137.0, -230.8000000000004, 73.99999999999949, 91.09999999999951, 46.69999999999996, -37.30000000000013, 139.39999999999995, 20.000000000000014, 30.80000000000003, -109.0000000000001, -21.69999999999984, 20.000000000000014, 27.200000000000024, -51.39999999999992, 46.70000000000012, 23.60000000000008, 1.0999999999999819, 47.90000000000012, 20.000000000000014, 54.20000000000007, -21.099999999999895, -11.500000000000021, -6.100000000000016, -141.7, -21.999999999999744, 22.700000000000063, 21.80000000000004, -247.90000000000032, 79.39999999999927, 32.60000000000019, -76.90000000000066, -126.70000000000039, 1.6999999999999689, 121.69999999999996, -51.3999999999999, 136.1000000000001, -61.900000000000766, 2.3000000000000913, 4.999999999999956, 20.000000000000014, -179.50000000000057, 89.29999999999981, 20.000000000000014, 20.000000000000014, -76.60000000000053, -226.90000000000023, 20.000000000000014, 39.800000000000196, -288.6999999999996, 3.1999999999999615, 20.90000000000003, 46.99999999999998, -72.10000000000002, -204.7000000000005, 15.799999999999963, -136.0000000000002, 168.19999999999993, 47.89999999999997, 159.49999999999994, 13.699999999999987, -13.599999999999868, -61.90000000000064, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.70000000000005, -112.30000000000015, 39.80000000000025, 20.000000000000014, -23.79999999999984, 20.000000000000014, -23.799999999999756, 20.000000000000014, -26.200000000000024, 22.700000000000063, 46.10000000000011, -142.90000000000066, -162.10000000000053, 20.000000000000014, 17.899999999999988, 28.100000000000037, 46.09999999999997, 57.80000000000021, 20.000000000000014, -5.1999999999999265, -27.69999999999984, 20.000000000000014, 20.000000000000014, 26.30000000000013, 20.000000000000014, 20.000000000000014, 65.00000000000014, -50.49999999999985, 20.000000000000014, -26.500000000000007, 73.39999999999995, -125.2000000000001, -69.70000000000007, 20.000000000000014, -47.499999999999794, 20.000000000000014, 20.000000000000014, -55.89999999999993, -155.80000000000013, 20.000000000000014, -52.59999999999985, 48.80000000000015, 104.59999999999997, -178.6000000000001, -166.90000000000032, 20.000000000000014, -112.30000000000051, -93.40000000000076, -237.7000000000001, 49.40000000000021, 21.80000000000001, -136.30000000000018, 8.600000000000001, 50.000000000000185, -6.399999999999951, 64.10000000000021, 20.000000000000053, 20.000000000000014, 30.500000000000192, 64.40000000000003, 33.500000000000085, 20.000000000000014, 65.00000000000014, -100.30000000000052, -2.799999999999972, -144.70000000000002, 84.19999999999969, 20.000000000000014, -32.49999999999976, -0.10000000000003478, 20.000000000000014, -5.799999999999928, 7.0999999999999766, -13.900000000000004, -144.09999999999997, -229.90000000000012, -288.7000000000003, 20.000000000000014, -24.099999999999746, 20.000000000000014, 1.0999999999999759, -135.4000000000002, -97.6000000000003, -85.0, -238.30000000000007, 18.80000000000003, -38.799999999999756, 20.000000000000014, 20.90000000000003, -69.3999999999999, -278.19999999999965, -17.5, -162.40000000000023, -61.89999999999992, -74.50000000000078, 20.000000000000014, 13.699999999999946, -60.10000000000051, -137.8000000000003, 41.60000000000025, 49.70000000000024, -95.50000000000009, -284.30000000000024, 20.000000000000014, 2.5999999999999805, 26.300000000000114, 20.000000000000014], "policy_predator_policy_reward": [106.0, 0.0, 32.0, 1.0, 0.0, 0.0, 0.0, 7.0, 145.0, 45.0, 6.0, 0.0, 0.0, 1.0, 53.0, 116.0, 51.0, 20.0, 55.0, 23.0, 0.0, 2.0, 89.0, 5.0, 90.0, 33.0, 121.0, 38.0, 0.0, 0.0, 54.0, 0.0, 0.0, 1.0, 0.0, 85.0, 0.0, 40.0, 0.0, 34.0, 0.0, 1.0, 4.0, 8.0, 24.0, 0.0, 34.0, 0.0, 77.0, 15.0, 20.0, 0.0, 0.0, 161.0, 0.0, 0.0, 71.0, 82.0, 18.0, 10.0, 34.0, 0.0, 47.0, 24.0, 14.0, 0.0, 0.0, 95.0, 0.0, 0.0, 46.0, 130.0, 0.0, 0.0, 146.0, 2.0, 0.0, 0.0, 33.0, 141.0, 88.0, 0.0, 0.0, 7.0, 9.0, 0.0, 39.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 63.0, 0.0, 0.0, 29.0, 23.0, 0.0, 22.0, 0.0, 0.0, 0.0, 47.0, 76.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 29.0, 11.0, 32.0, 78.0, 60.0, 39.0, 0.0, 0.0, 0.0, 1.0, 105.0, 0.0, 50.0, 0.0, 0.0, 144.0, 0.0, 0.0, 63.0, 130.0, 79.0, 1.0, 0.0, 30.0, 99.0, 14.0, 19.0, 24.0, 0.0, 3.0, 13.0, 0.0, 14.0, 0.0, 0.0, 15.0, 57.0, 0.0, 94.0, 25.0, 0.0, 0.0, 10.0, 1.0, 59.0, 102.0, 14.0, 0.0, 169.0, 21.0, 0.0, 9.0, 0.0, 6.0, 122.0, 0.0, 151.0, 0.0, 28.0, 0.0, 0.0, 151.0, 25.0, 101.0, 2.0, 0.0, 90.0, 3.0, 0.0, 37.0, 91.0, 0.0, 0.0, 202.0, 50.0, 15.0, 12.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1900882729843592, "mean_inference_ms": 3.3624919367628343, "mean_action_processing_ms": 0.472732338103751, "mean_env_wait_ms": 0.7284892984501903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009708166122436523, "StateBufferConnector_ms": 0.005039095878601074, "ViewRequirementAgentConnector_ms": 0.17380273342132568}, "num_episodes": 18, "episode_return_max": 225.8999999999995, "episode_return_min": -349.59999999999997, "episode_return_mean": 18.727999999999863, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 270.2623298935429, "num_env_steps_trained_throughput_per_sec": 270.2623298935429, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 13885.727, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13885.582, "sample_time_ms": 2601.176, "learn_time_ms": 11264.234, "learn_throughput": 355.106, "synch_weights_time_ms": 16.298}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "c52aa_00000", "date": "2024-08-12_23-49-13", "timestamp": 1723520953, "time_this_iter_s": 14.861377954483032, "time_total_s": 83.67279100418091, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 83.67279100418091, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 72.96190476190475, "ram_util_percent": 83.64761904761906}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0312615291703315, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.915556816070799, "policy_loss": -0.002774247530079077, "vf_loss": 5.9177454691084606, "vf_explained_var": 0.0019606838150629923, "kl": 0.011711826177000229, "entropy": 1.5009058536675872, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.26859441240510296, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.744944500040125, "policy_loss": -0.004256204834759787, "vf_loss": 4.748826532136826, "vf_explained_var": 0.0002301057495137371, "kl": 0.014967720276049297, "entropy": 1.5416156152568796, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 223.09999999999937, "episode_reward_min": -349.59999999999997, "episode_reward_mean": 6.0819999999998995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -288.7000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.19999999999993, "predator_policy": 202.0}, "policy_reward_mean": {"prey_policy": -26.934000000000037, "predator_policy": 29.975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [38.30000000000033, 9.800000000000104, 71.29999999999973, 61.00000000000027, 98.19999999999942, 1.400000000000272, -55.800000000000026, 20.700000000000003, -65.10000000000005, 111.9999999999985, -50.60000000000076, 151.39999999999938, 118.69999999999996, 11.400000000000166, 39.000000000000256, 4.800000000000124, 40.0000000000003, -127.50000000000065, 59.80000000000043, -137.5000000000009, 67.90000000000023, -102.80000000000035, -32.199999999999775, 223.09999999999937, 182.1999999999993, -20.49999999999961, 170.49999999999895, 40.0000000000003, 169.69999999999953, -9.499999999999806, 25.20000000000018, 19.199999999999964, 15.800000000000267, 68.80000000000038, -182.0000000000012, 38.90000000000028, 74.20000000000016, 77.7999999999999, 9.099999999999989, 40.0000000000003, 46.30000000000034, 84.99999999999898, 23.500000000000096, 89.89999999999995, -56.89999999999991, 11.499999999999929, 40.0000000000003, -105.7000000000005, 17.400000000000077, 153.39999999999966, -201.50000000000026, -29.299999999999564, -122.10000000000039, 72.20000000000002, 1.3000000000001606, 76.59999999999951, 108.0999999999989, 66.50000000000023, 111.89999999999947, 84.99999999999898, -31.099999999999675, 33.50000000000005, 12.499999999999988, 29.900000000000123, 61.29999999999933, -42.000000000000284, -349.59999999999997, 16.89999999999992, 30.100000000000147, -105.0000000000004, -172.2999999999999, 7.999999999999979, 40.90000000000031, -171.60000000000045, -76.90000000000012, -46.39999999999968, 36.700000000000294, -69.90000000000055, 91.29999999999855, -127.79999999999993, 49.60000000000037, 46.300000000000395, 35.10000000000041, 19.999999999999975, 33.40000000000029, 86.79999999999882, 17.400000000000304, -13.899999999999633, 21.099999999998943, 40.0000000000003, -45.99999999999968, -44.499999999999886, -123.40000000000006, -103.59999999999981, -1.0999999999998127, 46.99999999999968, -183.10000000000014, -24.699999999999793, -3.4999999999997815, -163.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-21.69999999999984, 20.000000000000014, 27.200000000000024, -51.39999999999992, 46.70000000000012, 23.60000000000008, 1.0999999999999819, 47.90000000000012, 20.000000000000014, 54.20000000000007, -21.099999999999895, -11.500000000000021, -6.100000000000016, -141.7, -21.999999999999744, 22.700000000000063, 21.80000000000004, -247.90000000000032, 79.39999999999927, 32.60000000000019, -76.90000000000066, -126.70000000000039, 1.6999999999999689, 121.69999999999996, -51.3999999999999, 136.1000000000001, -61.900000000000766, 2.3000000000000913, 4.999999999999956, 20.000000000000014, -179.50000000000057, 89.29999999999981, 20.000000000000014, 20.000000000000014, -76.60000000000053, -226.90000000000023, 20.000000000000014, 39.800000000000196, -288.6999999999996, 3.1999999999999615, 20.90000000000003, 46.99999999999998, -72.10000000000002, -204.7000000000005, 15.799999999999963, -136.0000000000002, 168.19999999999993, 47.89999999999997, 159.49999999999994, 13.699999999999987, -13.599999999999868, -61.90000000000064, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.70000000000005, -112.30000000000015, 39.80000000000025, 20.000000000000014, -23.79999999999984, 20.000000000000014, -23.799999999999756, 20.000000000000014, -26.200000000000024, 22.700000000000063, 46.10000000000011, -142.90000000000066, -162.10000000000053, 20.000000000000014, 17.899999999999988, 28.100000000000037, 46.09999999999997, 57.80000000000021, 20.000000000000014, -5.1999999999999265, -27.69999999999984, 20.000000000000014, 20.000000000000014, 26.30000000000013, 20.000000000000014, 20.000000000000014, 65.00000000000014, -50.49999999999985, 20.000000000000014, -26.500000000000007, 73.39999999999995, -125.2000000000001, -69.70000000000007, 20.000000000000014, -47.499999999999794, 20.000000000000014, 20.000000000000014, -55.89999999999993, -155.80000000000013, 20.000000000000014, -52.59999999999985, 48.80000000000015, 104.59999999999997, -178.6000000000001, -166.90000000000032, 20.000000000000014, -112.30000000000051, -93.40000000000076, -237.7000000000001, 49.40000000000021, 21.80000000000001, -136.30000000000018, 8.600000000000001, 50.000000000000185, -6.399999999999951, 64.10000000000021, 20.000000000000053, 20.000000000000014, 30.500000000000192, 64.40000000000003, 33.500000000000085, 20.000000000000014, 65.00000000000014, -100.30000000000052, -2.799999999999972, -144.70000000000002, 84.19999999999969, 20.000000000000014, -32.49999999999976, -0.10000000000003478, 20.000000000000014, -5.799999999999928, 7.0999999999999766, -13.900000000000004, -144.09999999999997, -229.90000000000012, -288.7000000000003, 20.000000000000014, -24.099999999999746, 20.000000000000014, 1.0999999999999759, -135.4000000000002, -97.6000000000003, -85.0, -238.30000000000007, 18.80000000000003, -38.799999999999756, 20.000000000000014, 20.90000000000003, -69.3999999999999, -278.19999999999965, -17.5, -162.40000000000023, -61.89999999999992, -74.50000000000078, 20.000000000000014, 13.699999999999946, -60.10000000000051, -137.8000000000003, 41.60000000000025, 49.70000000000024, -95.50000000000009, -284.30000000000024, 20.000000000000014, 2.5999999999999805, 26.300000000000114, 20.000000000000014, 30.8000000000002, -24.700000000000017, -19.899999999999743, 20.90000000000003, 20.000000000000014, 7.400000000000006, 72.19999999999955, -3.3999999999999866, 20.000000000000014, -25.59999999999998, -82.90000000000073, 20.000000000000014, 7.999999999999709, -34.9, 20.000000000000014, 20.000000000000014, -21.099999999999845, -98.9, 33.20000000000012, -199.70000000000002, -51.099999999999916, -259.3, -75.39999999999998, -134.20000000000059, 6.500000000000041, -55.60000000000004, -19.00000000000007, 20.000000000000014, -195.50000000000003, -150.60000000000014, -17.19999999999976, -74.49999999999994, 41.60000000000018, -238.10000000000002, -194.19999999999993, -263.8], "policy_predator_policy_reward": [0.0, 40.0, 0.0, 34.0, 0.0, 1.0, 4.0, 8.0, 24.0, 0.0, 34.0, 0.0, 77.0, 15.0, 20.0, 0.0, 0.0, 161.0, 0.0, 0.0, 71.0, 82.0, 18.0, 10.0, 34.0, 0.0, 47.0, 24.0, 14.0, 0.0, 0.0, 95.0, 0.0, 0.0, 46.0, 130.0, 0.0, 0.0, 146.0, 2.0, 0.0, 0.0, 33.0, 141.0, 88.0, 0.0, 0.0, 7.0, 9.0, 0.0, 39.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 63.0, 0.0, 0.0, 29.0, 23.0, 0.0, 22.0, 0.0, 0.0, 0.0, 47.0, 76.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 29.0, 11.0, 32.0, 78.0, 60.0, 39.0, 0.0, 0.0, 0.0, 1.0, 105.0, 0.0, 50.0, 0.0, 0.0, 144.0, 0.0, 0.0, 63.0, 130.0, 79.0, 1.0, 0.0, 30.0, 99.0, 14.0, 19.0, 24.0, 0.0, 3.0, 13.0, 0.0, 14.0, 0.0, 0.0, 15.0, 57.0, 0.0, 94.0, 25.0, 0.0, 0.0, 10.0, 1.0, 59.0, 102.0, 14.0, 0.0, 169.0, 21.0, 0.0, 9.0, 0.0, 6.0, 122.0, 0.0, 151.0, 0.0, 28.0, 0.0, 0.0, 151.0, 25.0, 101.0, 2.0, 0.0, 90.0, 3.0, 0.0, 37.0, 91.0, 0.0, 0.0, 202.0, 50.0, 15.0, 12.0, 0.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 6.0, 0.0, 18.0, 23.0, 0.0, 0.0, 49.0, 18.0, 30.0, 0.0, 0.0, 67.0, 7.0, 7.0, 115.0, 40.0, 147.0, 0.0, 106.0, 36.0, 12.0, 0.0, 46.0, 17.0, 146.0, 30.0, 37.0, 180.0, 13.0, 148.0, 147.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.170989771699751, "mean_inference_ms": 3.2942876345661802, "mean_action_processing_ms": 0.4660134291721382, "mean_env_wait_ms": 0.722973911182205, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008923530578613281, "StateBufferConnector_ms": 0.005050539970397949, "ViewRequirementAgentConnector_ms": 0.19138622283935547}, "num_episodes": 18, "episode_return_max": 223.09999999999937, "episode_return_min": -349.59999999999997, "episode_return_mean": 6.0819999999998995, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 276.71086407590434, "num_env_steps_trained_throughput_per_sec": 276.71086407590434, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 13967.128, "restore_workers_time_ms": 0.027, "training_step_time_ms": 13966.992, "sample_time_ms": 2733.998, "learn_time_ms": 11213.256, "learn_throughput": 356.721, "synch_weights_time_ms": 16.234}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "c52aa_00000", "date": "2024-08-12_23-49-28", "timestamp": 1723520968, "time_this_iter_s": 14.500437021255493, "time_total_s": 98.1732280254364, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c7e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 98.1732280254364, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 70.34, "ram_util_percent": 83.035}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1256473730559702, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.361602605083001, "policy_loss": -0.0044194549157052605, "vf_loss": 5.364987858010347, "vf_explained_var": 0.0003654064009429286, "kl": 0.02068410803399744, "entropy": 1.4241988248295254, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2597807902951168, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.835645460451722, "policy_loss": -0.0021454209726668463, "vf_loss": 5.837528202773402, "vf_explained_var": 0.00017462022720821321, "kl": 0.010507472714014752, "entropy": 1.510946931220867, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 223.09999999999937, "episode_reward_min": -349.59999999999997, "episode_reward_mean": -10.7730000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -392.80000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.19999999999993, "predator_policy": 287.0}, "policy_reward_mean": {"prey_policy": -43.566500000000026, "predator_policy": 38.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [59.80000000000043, -137.5000000000009, 67.90000000000023, -102.80000000000035, -32.199999999999775, 223.09999999999937, 182.1999999999993, -20.49999999999961, 170.49999999999895, 40.0000000000003, 169.69999999999953, -9.499999999999806, 25.20000000000018, 19.199999999999964, 15.800000000000267, 68.80000000000038, -182.0000000000012, 38.90000000000028, 74.20000000000016, 77.7999999999999, 9.099999999999989, 40.0000000000003, 46.30000000000034, 84.99999999999898, 23.500000000000096, 89.89999999999995, -56.89999999999991, 11.499999999999929, 40.0000000000003, -105.7000000000005, 17.400000000000077, 153.39999999999966, -201.50000000000026, -29.299999999999564, -122.10000000000039, 72.20000000000002, 1.3000000000001606, 76.59999999999951, 108.0999999999989, 66.50000000000023, 111.89999999999947, 84.99999999999898, -31.099999999999675, 33.50000000000005, 12.499999999999988, 29.900000000000123, 61.29999999999933, -42.000000000000284, -349.59999999999997, 16.89999999999992, 30.100000000000147, -105.0000000000004, -172.2999999999999, 7.999999999999979, 40.90000000000031, -171.60000000000045, -76.90000000000012, -46.39999999999968, 36.700000000000294, -69.90000000000055, 91.29999999999855, -127.79999999999993, 49.60000000000037, 46.300000000000395, 35.10000000000041, 19.999999999999975, 33.40000000000029, 86.79999999999882, 17.400000000000304, -13.899999999999633, 21.099999999998943, 40.0000000000003, -45.99999999999968, -44.499999999999886, -123.40000000000006, -103.59999999999981, -1.0999999999998127, 46.99999999999968, -183.10000000000014, -24.699999999999793, -3.4999999999997815, -163.0, -105.99999999999994, 33.400000000000205, 80.99999999999899, -102.10000000000008, -65.29999999999993, -72.80000000000018, 6.900000000000189, 30.80000000000029, -21.799999999999947, -177.7999999999999, -278.8000000000005, -112.70000000000067, -35.89999999999986, 54.90000000000017, -138.1, 83.19999999999908, -262.0000000000001, -123.40000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 39.800000000000196, -288.6999999999996, 3.1999999999999615, 20.90000000000003, 46.99999999999998, -72.10000000000002, -204.7000000000005, 15.799999999999963, -136.0000000000002, 168.19999999999993, 47.89999999999997, 159.49999999999994, 13.699999999999987, -13.599999999999868, -61.90000000000064, 150.4999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 145.70000000000005, -112.30000000000015, 39.80000000000025, 20.000000000000014, -23.79999999999984, 20.000000000000014, -23.799999999999756, 20.000000000000014, -26.200000000000024, 22.700000000000063, 46.10000000000011, -142.90000000000066, -162.10000000000053, 20.000000000000014, 17.899999999999988, 28.100000000000037, 46.09999999999997, 57.80000000000021, 20.000000000000014, -5.1999999999999265, -27.69999999999984, 20.000000000000014, 20.000000000000014, 26.30000000000013, 20.000000000000014, 20.000000000000014, 65.00000000000014, -50.49999999999985, 20.000000000000014, -26.500000000000007, 73.39999999999995, -125.2000000000001, -69.70000000000007, 20.000000000000014, -47.499999999999794, 20.000000000000014, 20.000000000000014, -55.89999999999993, -155.80000000000013, 20.000000000000014, -52.59999999999985, 48.80000000000015, 104.59999999999997, -178.6000000000001, -166.90000000000032, 20.000000000000014, -112.30000000000051, -93.40000000000076, -237.7000000000001, 49.40000000000021, 21.80000000000001, -136.30000000000018, 8.600000000000001, 50.000000000000185, -6.399999999999951, 64.10000000000021, 20.000000000000053, 20.000000000000014, 30.500000000000192, 64.40000000000003, 33.500000000000085, 20.000000000000014, 65.00000000000014, -100.30000000000052, -2.799999999999972, -144.70000000000002, 84.19999999999969, 20.000000000000014, -32.49999999999976, -0.10000000000003478, 20.000000000000014, -5.799999999999928, 7.0999999999999766, -13.900000000000004, -144.09999999999997, -229.90000000000012, -288.7000000000003, 20.000000000000014, -24.099999999999746, 20.000000000000014, 1.0999999999999759, -135.4000000000002, -97.6000000000003, -85.0, -238.30000000000007, 18.80000000000003, -38.799999999999756, 20.000000000000014, 20.90000000000003, -69.3999999999999, -278.19999999999965, -17.5, -162.40000000000023, -61.89999999999992, -74.50000000000078, 20.000000000000014, 13.699999999999946, -60.10000000000051, -137.8000000000003, 41.60000000000025, 49.70000000000024, -95.50000000000009, -284.30000000000024, 20.000000000000014, 2.5999999999999805, 26.300000000000114, 20.000000000000014, 30.8000000000002, -24.700000000000017, -19.899999999999743, 20.90000000000003, 20.000000000000014, 7.400000000000006, 72.19999999999955, -3.3999999999999866, 20.000000000000014, -25.59999999999998, -82.90000000000073, 20.000000000000014, 7.999999999999709, -34.9, 20.000000000000014, 20.000000000000014, -21.099999999999845, -98.9, 33.20000000000012, -199.70000000000002, -51.099999999999916, -259.3, -75.39999999999998, -134.20000000000059, 6.500000000000041, -55.60000000000004, -19.00000000000007, 20.000000000000014, -195.50000000000003, -150.60000000000014, -17.19999999999976, -74.49999999999994, 41.60000000000018, -238.10000000000002, -194.19999999999993, -263.8, -122.80000000000005, -65.2, 7.399999999999965, 20.000000000000014, 17.900000000000013, 61.10000000000015, -172.30000000000013, -59.80000000000004, -310.1999999999998, -24.10000000000005, -215.50000000000028, 19.700000000000017, 29.00000000000024, -66.10000000000014, -24.699999999999825, -92.49999999999991, 27.200000000000134, -240.0000000000003, -111.99999999999991, -392.80000000000007, -229.90000000000046, -229.90000000000038, -88.30000000000027, -198.40000000000038, 17.900000000000013, -122.8000000000001, -167.00000000000009, 41.90000000000019, -115.00000000000001, -246.0999999999999, 63.200000000000195, 20.000000000000014, -310.70000000000016, -290.29999999999995, -126.7000000000001, -138.70000000000005], "policy_predator_policy_reward": [0.0, 0.0, 146.0, 2.0, 0.0, 0.0, 33.0, 141.0, 88.0, 0.0, 0.0, 7.0, 9.0, 0.0, 39.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 63.0, 0.0, 0.0, 29.0, 23.0, 0.0, 22.0, 0.0, 0.0, 0.0, 47.0, 76.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0, 29.0, 11.0, 32.0, 78.0, 60.0, 39.0, 0.0, 0.0, 0.0, 1.0, 105.0, 0.0, 50.0, 0.0, 0.0, 144.0, 0.0, 0.0, 63.0, 130.0, 79.0, 1.0, 0.0, 30.0, 99.0, 14.0, 19.0, 24.0, 0.0, 3.0, 13.0, 0.0, 14.0, 0.0, 0.0, 15.0, 57.0, 0.0, 94.0, 25.0, 0.0, 0.0, 10.0, 1.0, 59.0, 102.0, 14.0, 0.0, 169.0, 21.0, 0.0, 9.0, 0.0, 6.0, 122.0, 0.0, 151.0, 0.0, 28.0, 0.0, 0.0, 151.0, 25.0, 101.0, 2.0, 0.0, 90.0, 3.0, 0.0, 37.0, 91.0, 0.0, 0.0, 202.0, 50.0, 15.0, 12.0, 0.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 6.0, 0.0, 18.0, 23.0, 0.0, 0.0, 49.0, 18.0, 30.0, 0.0, 0.0, 67.0, 7.0, 7.0, 115.0, 40.0, 147.0, 0.0, 106.0, 36.0, 12.0, 0.0, 46.0, 17.0, 146.0, 30.0, 37.0, 180.0, 13.0, 148.0, 147.0, 22.0, 60.0, 6.0, 0.0, 0.0, 2.0, 92.0, 38.0, 96.0, 173.0, 63.0, 60.0, 0.0, 44.0, 75.0, 73.0, 90.0, 101.0, 287.0, 40.0, 6.0, 175.0, 116.0, 58.0, 68.0, 1.0, 63.0, 117.0, 148.0, 75.0, 0.0, 0.0, 242.0, 97.0, 97.0, 45.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1655401381476085, "mean_inference_ms": 3.254780228149213, "mean_action_processing_ms": 0.46512924721765375, "mean_env_wait_ms": 0.7220805511065126, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00918424129486084, "StateBufferConnector_ms": 0.005532383918762207, "ViewRequirementAgentConnector_ms": 0.19068551063537598}, "num_episodes": 18, "episode_return_max": 223.09999999999937, "episode_return_min": -349.59999999999997, "episode_return_mean": -10.7730000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 329.5311282405818, "num_env_steps_trained_throughput_per_sec": 329.5311282405818, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 13738.546, "restore_workers_time_ms": 0.026, "training_step_time_ms": 13738.421, "sample_time_ms": 2640.151, "learn_time_ms": 11078.009, "learn_throughput": 361.076, "synch_weights_time_ms": 16.343}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "c52aa_00000", "date": "2024-08-12_23-49-40", "timestamp": 1723520980, "time_this_iter_s": 12.192026138305664, "time_total_s": 110.36525416374207, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 110.36525416374207, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 60.21111111111112, "ram_util_percent": 83.27222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0455286415520484, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.069522832814979, "policy_loss": -0.002882786373060847, "vf_loss": 5.071629565985745, "vf_explained_var": -0.0030346702646326137, "kl": 0.010347119633343269, "entropy": 1.3889928798826914, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27977974319229365, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.674156392819036, "policy_loss": -0.0018909276704545375, "vf_loss": 4.675690575756093, "vf_explained_var": 0.0027548960592380907, "kl": 0.014269416411906016, "entropy": 1.5298635046948832, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 153.39999999999966, "episode_reward_min": -349.59999999999997, "episode_reward_mean": -23.15200000000008, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -392.80000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 104.59999999999997, "predator_policy": 287.0}, "policy_reward_mean": {"prey_policy": -58.38600000000003, "predator_policy": 46.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [46.30000000000034, 84.99999999999898, 23.500000000000096, 89.89999999999995, -56.89999999999991, 11.499999999999929, 40.0000000000003, -105.7000000000005, 17.400000000000077, 153.39999999999966, -201.50000000000026, -29.299999999999564, -122.10000000000039, 72.20000000000002, 1.3000000000001606, 76.59999999999951, 108.0999999999989, 66.50000000000023, 111.89999999999947, 84.99999999999898, -31.099999999999675, 33.50000000000005, 12.499999999999988, 29.900000000000123, 61.29999999999933, -42.000000000000284, -349.59999999999997, 16.89999999999992, 30.100000000000147, -105.0000000000004, -172.2999999999999, 7.999999999999979, 40.90000000000031, -171.60000000000045, -76.90000000000012, -46.39999999999968, 36.700000000000294, -69.90000000000055, 91.29999999999855, -127.79999999999993, 49.60000000000037, 46.300000000000395, 35.10000000000041, 19.999999999999975, 33.40000000000029, 86.79999999999882, 17.400000000000304, -13.899999999999633, 21.099999999998943, 40.0000000000003, -45.99999999999968, -44.499999999999886, -123.40000000000006, -103.59999999999981, -1.0999999999998127, 46.99999999999968, -183.10000000000014, -24.699999999999793, -3.4999999999997815, -163.0, -105.99999999999994, 33.400000000000205, 80.99999999999899, -102.10000000000008, -65.29999999999993, -72.80000000000018, 6.900000000000189, 30.80000000000029, -21.799999999999947, -177.7999999999999, -278.8000000000005, -112.70000000000067, -35.89999999999986, 54.90000000000017, -138.1, 83.19999999999908, -262.0000000000001, -123.40000000000018, 40.0000000000003, -77.00000000000071, -17.59999999999964, 127.59999999999846, 32.200000000000415, -187.1000000000005, -15.19999999999967, -124.10000000000065, -38.599999999999774, 52.90000000000009, 40.50000000000039, 34.80000000000024, -0.699999999999743, -135.000000000001, -111.1000000000007, -85.40000000000005, 40.0000000000003, -35.79999999999973, -7.899999999999821, -77.79999999999981, 42.70000000000034, 62.40000000000047], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [26.30000000000013, 20.000000000000014, 20.000000000000014, 65.00000000000014, -50.49999999999985, 20.000000000000014, -26.500000000000007, 73.39999999999995, -125.2000000000001, -69.70000000000007, 20.000000000000014, -47.499999999999794, 20.000000000000014, 20.000000000000014, -55.89999999999993, -155.80000000000013, 20.000000000000014, -52.59999999999985, 48.80000000000015, 104.59999999999997, -178.6000000000001, -166.90000000000032, 20.000000000000014, -112.30000000000051, -93.40000000000076, -237.7000000000001, 49.40000000000021, 21.80000000000001, -136.30000000000018, 8.600000000000001, 50.000000000000185, -6.399999999999951, 64.10000000000021, 20.000000000000053, 20.000000000000014, 30.500000000000192, 64.40000000000003, 33.500000000000085, 20.000000000000014, 65.00000000000014, -100.30000000000052, -2.799999999999972, -144.70000000000002, 84.19999999999969, 20.000000000000014, -32.49999999999976, -0.10000000000003478, 20.000000000000014, -5.799999999999928, 7.0999999999999766, -13.900000000000004, -144.09999999999997, -229.90000000000012, -288.7000000000003, 20.000000000000014, -24.099999999999746, 20.000000000000014, 1.0999999999999759, -135.4000000000002, -97.6000000000003, -85.0, -238.30000000000007, 18.80000000000003, -38.799999999999756, 20.000000000000014, 20.90000000000003, -69.3999999999999, -278.19999999999965, -17.5, -162.40000000000023, -61.89999999999992, -74.50000000000078, 20.000000000000014, 13.699999999999946, -60.10000000000051, -137.8000000000003, 41.60000000000025, 49.70000000000024, -95.50000000000009, -284.30000000000024, 20.000000000000014, 2.5999999999999805, 26.300000000000114, 20.000000000000014, 30.8000000000002, -24.700000000000017, -19.899999999999743, 20.90000000000003, 20.000000000000014, 7.400000000000006, 72.19999999999955, -3.3999999999999866, 20.000000000000014, -25.59999999999998, -82.90000000000073, 20.000000000000014, 7.999999999999709, -34.9, 20.000000000000014, 20.000000000000014, -21.099999999999845, -98.9, 33.20000000000012, -199.70000000000002, -51.099999999999916, -259.3, -75.39999999999998, -134.20000000000059, 6.500000000000041, -55.60000000000004, -19.00000000000007, 20.000000000000014, -195.50000000000003, -150.60000000000014, -17.19999999999976, -74.49999999999994, 41.60000000000018, -238.10000000000002, -194.19999999999993, -263.8, -122.80000000000005, -65.2, 7.399999999999965, 20.000000000000014, 17.900000000000013, 61.10000000000015, -172.30000000000013, -59.80000000000004, -310.1999999999998, -24.10000000000005, -215.50000000000028, 19.700000000000017, 29.00000000000024, -66.10000000000014, -24.699999999999825, -92.49999999999991, 27.200000000000134, -240.0000000000003, -111.99999999999991, -392.80000000000007, -229.90000000000046, -229.90000000000038, -88.30000000000027, -198.40000000000038, 17.900000000000013, -122.8000000000001, -167.00000000000009, 41.90000000000019, -115.00000000000001, -246.0999999999999, 63.200000000000195, 20.000000000000014, -310.70000000000016, -290.29999999999995, -126.7000000000001, -138.70000000000005, 20.000000000000014, 20.000000000000014, -383.1999999999998, -38.799999999999756, -66.10000000000079, -38.4999999999999, 56.900000000000226, 67.6999999999999, 28.100000000000147, -43.900000000000006, -65.20000000000039, -268.90000000000003, 21.80000000000004, -208.0000000000005, -66.10000000000059, -316.0, 20.000000000000014, -208.60000000000034, 20.000000000000014, -378.1, -17.49999999999986, 20.000000000000014, -12.099999999999874, 20.900000000000027, -0.9999999999999846, -21.699999999999754, -124.90000000000043, -96.10000000000053, -130.80000000000075, -349.2999999999997, -198.1, -28.299999999999834, 20.000000000000014, 20.000000000000014, -15.099999999999842, -69.70000000000041, 20.000000000000014, -130.90000000000015, -79.2999999999999, -53.50000000000001, 22.700000000000053, 20.000000000000014, 32.90000000000023, 24.500000000000092], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 25.0, 29.0, 11.0, 32.0, 78.0, 60.0, 39.0, 0.0, 0.0, 0.0, 1.0, 105.0, 0.0, 50.0, 0.0, 0.0, 144.0, 0.0, 0.0, 63.0, 130.0, 79.0, 1.0, 0.0, 30.0, 99.0, 14.0, 19.0, 24.0, 0.0, 3.0, 13.0, 0.0, 14.0, 0.0, 0.0, 15.0, 57.0, 0.0, 94.0, 25.0, 0.0, 0.0, 10.0, 1.0, 59.0, 102.0, 14.0, 0.0, 169.0, 21.0, 0.0, 9.0, 0.0, 6.0, 122.0, 0.0, 151.0, 0.0, 28.0, 0.0, 0.0, 151.0, 25.0, 101.0, 2.0, 0.0, 90.0, 3.0, 0.0, 37.0, 91.0, 0.0, 0.0, 202.0, 50.0, 15.0, 12.0, 0.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 6.0, 0.0, 18.0, 23.0, 0.0, 0.0, 49.0, 18.0, 30.0, 0.0, 0.0, 67.0, 7.0, 7.0, 115.0, 40.0, 147.0, 0.0, 106.0, 36.0, 12.0, 0.0, 46.0, 17.0, 146.0, 30.0, 37.0, 180.0, 13.0, 148.0, 147.0, 22.0, 60.0, 6.0, 0.0, 0.0, 2.0, 92.0, 38.0, 96.0, 173.0, 63.0, 60.0, 0.0, 44.0, 75.0, 73.0, 90.0, 101.0, 287.0, 40.0, 6.0, 175.0, 116.0, 58.0, 68.0, 1.0, 63.0, 117.0, 148.0, 75.0, 0.0, 0.0, 242.0, 97.0, 97.0, 45.0, 0.0, 0.0, 162.0, 183.0, 57.0, 30.0, 1.0, 2.0, 0.0, 48.0, 0.0, 147.0, 86.0, 85.0, 125.0, 133.0, 121.0, 29.0, 228.0, 183.0, 38.0, 0.0, 26.0, 0.0, 22.0, 0.0, 20.0, 66.0, 185.0, 184.0, 25.0, 116.0, 0.0, 0.0, 49.0, 0.0, 10.0, 93.0, 55.0, 0.0, 0.0, 0.0, 3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1598732514812902, "mean_inference_ms": 3.214931233198962, "mean_action_processing_ms": 0.46065361916182224, "mean_env_wait_ms": 0.7170080744861588, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007471203804016113, "StateBufferConnector_ms": 0.0059081315994262695, "ViewRequirementAgentConnector_ms": 0.1800597906112671}, "num_episodes": 22, "episode_return_max": 153.39999999999966, "episode_return_min": -349.59999999999997, "episode_return_mean": -23.15200000000008, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 334.1415137313923, "num_env_steps_trained_throughput_per_sec": 334.1415137313923, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 13542.15, "restore_workers_time_ms": 0.025, "training_step_time_ms": 13542.033, "sample_time_ms": 2540.881, "learn_time_ms": 10981.757, "learn_throughput": 364.24, "synch_weights_time_ms": 15.794}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "c52aa_00000", "date": "2024-08-12_23-49-52", "timestamp": 1723520992, "time_this_iter_s": 12.008384943008423, "time_total_s": 122.37363910675049, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 122.37363910675049, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 61.98235294117647, "ram_util_percent": 83.77058823529413}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9772520573799888, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.222989404264581, "policy_loss": -6.776436714938393e-05, "vf_loss": 8.222804074312643, "vf_explained_var": 0.0009378233283915848, "kl": 0.0033747331011881234, "entropy": 1.4145922132900783, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2992436814816698, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.26892168912938, "policy_loss": -0.001849375586345713, "vf_loss": 7.270263438502317, "vf_explained_var": 0.0007962147394816081, "kl": 0.02030530708541728, "entropy": 1.4856098144773453, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 127.59999999999846, "episode_reward_min": -358.5999999999998, "episode_reward_mean": -59.91300000000008, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -421.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 72.19999999999955, "predator_policy": 299.0}, "policy_reward_mean": {"prey_policy": -89.42150000000005, "predator_policy": 59.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [29.900000000000123, 61.29999999999933, -42.000000000000284, -349.59999999999997, 16.89999999999992, 30.100000000000147, -105.0000000000004, -172.2999999999999, 7.999999999999979, 40.90000000000031, -171.60000000000045, -76.90000000000012, -46.39999999999968, 36.700000000000294, -69.90000000000055, 91.29999999999855, -127.79999999999993, 49.60000000000037, 46.300000000000395, 35.10000000000041, 19.999999999999975, 33.40000000000029, 86.79999999999882, 17.400000000000304, -13.899999999999633, 21.099999999998943, 40.0000000000003, -45.99999999999968, -44.499999999999886, -123.40000000000006, -103.59999999999981, -1.0999999999998127, 46.99999999999968, -183.10000000000014, -24.699999999999793, -3.4999999999997815, -163.0, -105.99999999999994, 33.400000000000205, 80.99999999999899, -102.10000000000008, -65.29999999999993, -72.80000000000018, 6.900000000000189, 30.80000000000029, -21.799999999999947, -177.7999999999999, -278.8000000000005, -112.70000000000067, -35.89999999999986, 54.90000000000017, -138.1, 83.19999999999908, -262.0000000000001, -123.40000000000018, 40.0000000000003, -77.00000000000071, -17.59999999999964, 127.59999999999846, 32.200000000000415, -187.1000000000005, -15.19999999999967, -124.10000000000065, -38.599999999999774, 52.90000000000009, 40.50000000000039, 34.80000000000024, -0.699999999999743, -135.000000000001, -111.1000000000007, -85.40000000000005, 40.0000000000003, -35.79999999999973, -7.899999999999821, -77.79999999999981, 42.70000000000034, 62.40000000000047, -358.5999999999998, -186.70000000000033, -147.8000000000009, -333.09999999999997, -60.30000000000059, -226.40000000000043, -225.20000000000036, -239.70000000000005, -10.699999999999871, -59.299999999999855, -86.70000000000007, -81.59999999999965, -34.19999999999985, -237.6999999999998, -72.3000000000005, -116.60000000000039, -218.90000000000055, -57.19999999999987, -189.80000000000064, -6.200000000000047, 57.900000000000524, -166.90000000000003, -130.10000000000053], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-0.10000000000003478, 20.000000000000014, -5.799999999999928, 7.0999999999999766, -13.900000000000004, -144.09999999999997, -229.90000000000012, -288.7000000000003, 20.000000000000014, -24.099999999999746, 20.000000000000014, 1.0999999999999759, -135.4000000000002, -97.6000000000003, -85.0, -238.30000000000007, 18.80000000000003, -38.799999999999756, 20.000000000000014, 20.90000000000003, -69.3999999999999, -278.19999999999965, -17.5, -162.40000000000023, -61.89999999999992, -74.50000000000078, 20.000000000000014, 13.699999999999946, -60.10000000000051, -137.8000000000003, 41.60000000000025, 49.70000000000024, -95.50000000000009, -284.30000000000024, 20.000000000000014, 2.5999999999999805, 26.300000000000114, 20.000000000000014, 30.8000000000002, -24.700000000000017, -19.899999999999743, 20.90000000000003, 20.000000000000014, 7.400000000000006, 72.19999999999955, -3.3999999999999866, 20.000000000000014, -25.59999999999998, -82.90000000000073, 20.000000000000014, 7.999999999999709, -34.9, 20.000000000000014, 20.000000000000014, -21.099999999999845, -98.9, 33.20000000000012, -199.70000000000002, -51.099999999999916, -259.3, -75.39999999999998, -134.20000000000059, 6.500000000000041, -55.60000000000004, -19.00000000000007, 20.000000000000014, -195.50000000000003, -150.60000000000014, -17.19999999999976, -74.49999999999994, 41.60000000000018, -238.10000000000002, -194.19999999999993, -263.8, -122.80000000000005, -65.2, 7.399999999999965, 20.000000000000014, 17.900000000000013, 61.10000000000015, -172.30000000000013, -59.80000000000004, -310.1999999999998, -24.10000000000005, -215.50000000000028, 19.700000000000017, 29.00000000000024, -66.10000000000014, -24.699999999999825, -92.49999999999991, 27.200000000000134, -240.0000000000003, -111.99999999999991, -392.80000000000007, -229.90000000000046, -229.90000000000038, -88.30000000000027, -198.40000000000038, 17.900000000000013, -122.8000000000001, -167.00000000000009, 41.90000000000019, -115.00000000000001, -246.0999999999999, 63.200000000000195, 20.000000000000014, -310.70000000000016, -290.29999999999995, -126.7000000000001, -138.70000000000005, 20.000000000000014, 20.000000000000014, -383.1999999999998, -38.799999999999756, -66.10000000000079, -38.4999999999999, 56.900000000000226, 67.6999999999999, 28.100000000000147, -43.900000000000006, -65.20000000000039, -268.90000000000003, 21.80000000000004, -208.0000000000005, -66.10000000000059, -316.0, 20.000000000000014, -208.60000000000034, 20.000000000000014, -378.1, -17.49999999999986, 20.000000000000014, -12.099999999999874, 20.900000000000027, -0.9999999999999846, -21.699999999999754, -124.90000000000043, -96.10000000000053, -130.80000000000075, -349.2999999999997, -198.1, -28.299999999999834, 20.000000000000014, 20.000000000000014, -15.099999999999842, -69.70000000000041, 20.000000000000014, -130.90000000000015, -79.2999999999999, -53.50000000000001, 22.700000000000053, 20.000000000000014, 32.90000000000023, 24.500000000000092, -307.6000000000001, -388.0, -310.60000000000014, -87.10000000000002, -119.20000000000007, -150.60000000000053, -366.2, -421.9, -196.30000000000038, 20.000000000000014, -368.50000000000006, -103.90000000000028, -288.79999999999995, -198.40000000000038, -186.7, -269.0, -114.70000000000027, 20.000000000000014, -153.9000000000003, -21.399999999999977, -93.39999999999995, -49.30000000000001, -143.80000000000007, -20.799999999999898, -5.199999999999969, -103.0000000000003, -169.0, -208.69999999999993, -179.8000000000002, -53.50000000000019, -70.60000000000048, -189.99999999999991, -187.90000000000038, -211.00000000000014, -100.30000000000052, -70.90000000000015, -162.70000000000033, -135.10000000000036, -68.20000000000002, 20.000000000000014, 23.000000000000224, 29.90000000000018, -189.99999999999994, -219.89999999999995, -138.7000000000003, -261.40000000000015], "policy_predator_policy_reward": [0.0, 10.0, 1.0, 59.0, 102.0, 14.0, 0.0, 169.0, 21.0, 0.0, 9.0, 0.0, 6.0, 122.0, 0.0, 151.0, 0.0, 28.0, 0.0, 0.0, 151.0, 25.0, 101.0, 2.0, 0.0, 90.0, 3.0, 0.0, 37.0, 91.0, 0.0, 0.0, 202.0, 50.0, 15.0, 12.0, 0.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 6.0, 0.0, 18.0, 23.0, 0.0, 0.0, 49.0, 18.0, 30.0, 0.0, 0.0, 67.0, 7.0, 7.0, 115.0, 40.0, 147.0, 0.0, 106.0, 36.0, 12.0, 0.0, 46.0, 17.0, 146.0, 30.0, 37.0, 180.0, 13.0, 148.0, 147.0, 22.0, 60.0, 6.0, 0.0, 0.0, 2.0, 92.0, 38.0, 96.0, 173.0, 63.0, 60.0, 0.0, 44.0, 75.0, 73.0, 90.0, 101.0, 287.0, 40.0, 6.0, 175.0, 116.0, 58.0, 68.0, 1.0, 63.0, 117.0, 148.0, 75.0, 0.0, 0.0, 242.0, 97.0, 97.0, 45.0, 0.0, 0.0, 162.0, 183.0, 57.0, 30.0, 1.0, 2.0, 0.0, 48.0, 0.0, 147.0, 86.0, 85.0, 125.0, 133.0, 121.0, 29.0, 228.0, 183.0, 38.0, 0.0, 26.0, 0.0, 22.0, 0.0, 20.0, 66.0, 185.0, 184.0, 25.0, 116.0, 0.0, 0.0, 49.0, 0.0, 10.0, 93.0, 55.0, 0.0, 0.0, 0.0, 3.0, 2.0, 152.0, 185.0, 51.0, 160.0, 83.0, 39.0, 156.0, 299.0, 13.0, 103.0, 96.0, 150.0, 173.0, 89.0, 120.0, 96.0, 2.0, 82.0, 13.0, 103.0, 56.0, 0.0, 0.0, 83.0, 0.0, 74.0, 0.0, 140.0, 120.0, 41.0, 24.0, 120.0, 57.0, 123.0, 113.0, 1.0, 29.0, 79.0, 0.0, 42.0, 5.0, 0.0, 135.0, 108.0, 133.0, 137.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1603308294506665, "mean_inference_ms": 3.1675678664785005, "mean_action_processing_ms": 0.45900771062952933, "mean_env_wait_ms": 0.71561943719475, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007357358932495117, "StateBufferConnector_ms": 0.00465083122253418, "ViewRequirementAgentConnector_ms": 0.19831526279449463}, "num_episodes": 23, "episode_return_max": 127.59999999999846, "episode_return_min": -358.5999999999998, "episode_return_mean": -59.91300000000008, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 324.66014701030593, "num_env_steps_trained_throughput_per_sec": 324.66014701030593, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 13419.994, "restore_workers_time_ms": 0.024, "training_step_time_ms": 13419.883, "sample_time_ms": 2506.406, "learn_time_ms": 10894.715, "learn_throughput": 367.151, "synch_weights_time_ms": 15.427}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "c52aa_00000", "date": "2024-08-12_23-50-05", "timestamp": 1723521005, "time_this_iter_s": 12.361280679702759, "time_total_s": 134.73491978645325, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c5670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 134.73491978645325, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 61.711764705882345, "ram_util_percent": 82.98823529411764}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9369794995144561, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.177523980569587, "policy_loss": -0.005525939814283182, "vf_loss": 8.182373104145919, "vf_explained_var": 0.001027643775183057, "kl": 0.018048706043879797, "entropy": 1.4582971540077654, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5139575953166636, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.570276992535465, "policy_loss": -0.005378355791117188, "vf_loss": 8.574823530641183, "vf_explained_var": 0.0003640556461596615, "kl": 0.02218102840900431, "entropy": 1.3857644770511244, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 227.29999999999953, "episode_reward_min": -467.0, "episode_reward_mean": -66.02500000000005, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -876.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 72.19999999999955, "predator_policy": 582.0}, "policy_reward_mean": {"prey_policy": -126.53250000000004, "predator_policy": 93.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [46.300000000000395, 35.10000000000041, 19.999999999999975, 33.40000000000029, 86.79999999999882, 17.400000000000304, -13.899999999999633, 21.099999999998943, 40.0000000000003, -45.99999999999968, -44.499999999999886, -123.40000000000006, -103.59999999999981, -1.0999999999998127, 46.99999999999968, -183.10000000000014, -24.699999999999793, -3.4999999999997815, -163.0, -105.99999999999994, 33.400000000000205, 80.99999999999899, -102.10000000000008, -65.29999999999993, -72.80000000000018, 6.900000000000189, 30.80000000000029, -21.799999999999947, -177.7999999999999, -278.8000000000005, -112.70000000000067, -35.89999999999986, 54.90000000000017, -138.1, 83.19999999999908, -262.0000000000001, -123.40000000000018, 40.0000000000003, -77.00000000000071, -17.59999999999964, 127.59999999999846, 32.200000000000415, -187.1000000000005, -15.19999999999967, -124.10000000000065, -38.599999999999774, 52.90000000000009, 40.50000000000039, 34.80000000000024, -0.699999999999743, -135.000000000001, -111.1000000000007, -85.40000000000005, 40.0000000000003, -35.79999999999973, -7.899999999999821, -77.79999999999981, 42.70000000000034, 62.40000000000047, -358.5999999999998, -186.70000000000033, -147.8000000000009, -333.09999999999997, -60.30000000000059, -226.40000000000043, -225.20000000000036, -239.70000000000005, -10.699999999999871, -59.299999999999855, -86.70000000000007, -81.59999999999965, -34.19999999999985, -237.6999999999998, -72.3000000000005, -116.60000000000039, -218.90000000000055, -57.19999999999987, -189.80000000000064, -6.200000000000047, 57.900000000000524, -166.90000000000003, -130.10000000000053, -12.699999999999736, 71.80000000000027, -136.09999999999997, 227.29999999999953, -467.0, 44.60000000000017, -226.20000000000005, 84.79999999999978, 126.30000000000015, 12.40000000000025, -203.3999999999998, -247.50000000000028, -42.799999999999855, 26.00000000000012, -205.00000000000045, -176.39999999999992, -300.9999999999999, 16.899999999999974], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [26.300000000000114, 20.000000000000014, 30.8000000000002, -24.700000000000017, -19.899999999999743, 20.90000000000003, 20.000000000000014, 7.400000000000006, 72.19999999999955, -3.3999999999999866, 20.000000000000014, -25.59999999999998, -82.90000000000073, 20.000000000000014, 7.999999999999709, -34.9, 20.000000000000014, 20.000000000000014, -21.099999999999845, -98.9, 33.20000000000012, -199.70000000000002, -51.099999999999916, -259.3, -75.39999999999998, -134.20000000000059, 6.500000000000041, -55.60000000000004, -19.00000000000007, 20.000000000000014, -195.50000000000003, -150.60000000000014, -17.19999999999976, -74.49999999999994, 41.60000000000018, -238.10000000000002, -194.19999999999993, -263.8, -122.80000000000005, -65.2, 7.399999999999965, 20.000000000000014, 17.900000000000013, 61.10000000000015, -172.30000000000013, -59.80000000000004, -310.1999999999998, -24.10000000000005, -215.50000000000028, 19.700000000000017, 29.00000000000024, -66.10000000000014, -24.699999999999825, -92.49999999999991, 27.200000000000134, -240.0000000000003, -111.99999999999991, -392.80000000000007, -229.90000000000046, -229.90000000000038, -88.30000000000027, -198.40000000000038, 17.900000000000013, -122.8000000000001, -167.00000000000009, 41.90000000000019, -115.00000000000001, -246.0999999999999, 63.200000000000195, 20.000000000000014, -310.70000000000016, -290.29999999999995, -126.7000000000001, -138.70000000000005, 20.000000000000014, 20.000000000000014, -383.1999999999998, -38.799999999999756, -66.10000000000079, -38.4999999999999, 56.900000000000226, 67.6999999999999, 28.100000000000147, -43.900000000000006, -65.20000000000039, -268.90000000000003, 21.80000000000004, -208.0000000000005, -66.10000000000059, -316.0, 20.000000000000014, -208.60000000000034, 20.000000000000014, -378.1, -17.49999999999986, 20.000000000000014, -12.099999999999874, 20.900000000000027, -0.9999999999999846, -21.699999999999754, -124.90000000000043, -96.10000000000053, -130.80000000000075, -349.2999999999997, -198.1, -28.299999999999834, 20.000000000000014, 20.000000000000014, -15.099999999999842, -69.70000000000041, 20.000000000000014, -130.90000000000015, -79.2999999999999, -53.50000000000001, 22.700000000000053, 20.000000000000014, 32.90000000000023, 24.500000000000092, -307.6000000000001, -388.0, -310.60000000000014, -87.10000000000002, -119.20000000000007, -150.60000000000053, -366.2, -421.9, -196.30000000000038, 20.000000000000014, -368.50000000000006, -103.90000000000028, -288.79999999999995, -198.40000000000038, -186.7, -269.0, -114.70000000000027, 20.000000000000014, -153.9000000000003, -21.399999999999977, -93.39999999999995, -49.30000000000001, -143.80000000000007, -20.799999999999898, -5.199999999999969, -103.0000000000003, -169.0, -208.69999999999993, -179.8000000000002, -53.50000000000019, -70.60000000000048, -189.99999999999991, -187.90000000000038, -211.00000000000014, -100.30000000000052, -70.90000000000015, -162.70000000000033, -135.10000000000036, -68.20000000000002, 20.000000000000014, 23.000000000000224, 29.90000000000018, -189.99999999999994, -219.89999999999995, -138.7000000000003, -261.40000000000015, -228.5, -44.20000000000004, 20.000000000000014, -240.19999999999993, -127.50000000000003, -145.60000000000002, 1.0999999999999712, -876.8, -490.4, -426.6, 1.099999999999953, -739.5, -312.70000000000005, -269.5, -38.80000000000005, -822.4, -528.7, 29.000000000000163, 1.0999999999999723, -42.69999999999997, -374.69999999999993, -225.70000000000002, -312.1, -341.399999999999, -91.29999999999998, -781.5, -113.9999999999998, 20.000000000000014, -180.70000000000027, -205.30000000000018, -665.1, -271.3000000000002, -294.3, -566.7, -24.099999999999746, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 29.0, 0.0, 19.0, 0.0, 6.0, 0.0, 18.0, 23.0, 0.0, 0.0, 49.0, 18.0, 30.0, 0.0, 0.0, 67.0, 7.0, 7.0, 115.0, 40.0, 147.0, 0.0, 106.0, 36.0, 12.0, 0.0, 46.0, 17.0, 146.0, 30.0, 37.0, 180.0, 13.0, 148.0, 147.0, 22.0, 60.0, 6.0, 0.0, 0.0, 2.0, 92.0, 38.0, 96.0, 173.0, 63.0, 60.0, 0.0, 44.0, 75.0, 73.0, 90.0, 101.0, 287.0, 40.0, 6.0, 175.0, 116.0, 58.0, 68.0, 1.0, 63.0, 117.0, 148.0, 75.0, 0.0, 0.0, 242.0, 97.0, 97.0, 45.0, 0.0, 0.0, 162.0, 183.0, 57.0, 30.0, 1.0, 2.0, 0.0, 48.0, 0.0, 147.0, 86.0, 85.0, 125.0, 133.0, 121.0, 29.0, 228.0, 183.0, 38.0, 0.0, 26.0, 0.0, 22.0, 0.0, 20.0, 66.0, 185.0, 184.0, 25.0, 116.0, 0.0, 0.0, 49.0, 0.0, 10.0, 93.0, 55.0, 0.0, 0.0, 0.0, 3.0, 2.0, 152.0, 185.0, 51.0, 160.0, 83.0, 39.0, 156.0, 299.0, 13.0, 103.0, 96.0, 150.0, 173.0, 89.0, 120.0, 96.0, 2.0, 82.0, 13.0, 103.0, 56.0, 0.0, 0.0, 83.0, 0.0, 74.0, 0.0, 140.0, 120.0, 41.0, 24.0, 120.0, 57.0, 123.0, 113.0, 1.0, 29.0, 79.0, 0.0, 42.0, 5.0, 0.0, 135.0, 108.0, 133.0, 137.0, 185.0, 75.0, 91.0, 201.0, 9.0, 128.0, 582.0, 521.0, 0.0, 450.0, 526.0, 257.0, 148.0, 208.0, 438.0, 508.0, 185.0, 441.0, 50.0, 4.0, 99.0, 298.0, 159.0, 247.0, 528.0, 302.0, 66.0, 54.0, 127.0, 54.0, 484.0, 276.0, 505.0, 55.0, 21.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1580805153423308, "mean_inference_ms": 3.149098092011108, "mean_action_processing_ms": 0.4607001480557602, "mean_env_wait_ms": 0.7149434275781457, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006706357002258301, "StateBufferConnector_ms": 0.00466001033782959, "ViewRequirementAgentConnector_ms": 0.20851421356201172}, "num_episodes": 18, "episode_return_max": 227.29999999999953, "episode_return_min": -467.0, "episode_return_mean": -66.02500000000005, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 274.44001470706036, "num_env_steps_trained_throughput_per_sec": 274.44001470706036, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 13506.318, "restore_workers_time_ms": 0.023, "training_step_time_ms": 13506.242, "sample_time_ms": 2489.646, "learn_time_ms": 10998.462, "learn_throughput": 363.687, "synch_weights_time_ms": 15.083}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "c52aa_00000", "date": "2024-08-12_23-50-19", "timestamp": 1723521019, "time_this_iter_s": 14.622756958007812, "time_total_s": 149.35767674446106, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c58b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 149.35767674446106, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 74.42857142857144, "ram_util_percent": 83.24761904761905}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2216024547421112, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.15304631783218, "policy_loss": -0.006795808069023585, "vf_loss": 5.159066065404781, "vf_explained_var": 0.002771580313879346, "kl": 0.020694846175365926, "entropy": 1.4270503144415598, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37199818367759385, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.747206431091147, "policy_loss": -0.0012377756175944808, "vf_loss": 6.747960481189546, "vf_explained_var": 0.0005484600231130287, "kl": 0.008599563540318305, "entropy": 1.4662906285946962, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 228.69999999999987, "episode_reward_min": -467.0, "episode_reward_mean": -60.191000000000095, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -876.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 74.89999999999941, "predator_policy": 582.0}, "policy_reward_mean": {"prey_policy": -151.25050000000005, "predator_policy": 121.155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-163.0, -105.99999999999994, 33.400000000000205, 80.99999999999899, -102.10000000000008, -65.29999999999993, -72.80000000000018, 6.900000000000189, 30.80000000000029, -21.799999999999947, -177.7999999999999, -278.8000000000005, -112.70000000000067, -35.89999999999986, 54.90000000000017, -138.1, 83.19999999999908, -262.0000000000001, -123.40000000000018, 40.0000000000003, -77.00000000000071, -17.59999999999964, 127.59999999999846, 32.200000000000415, -187.1000000000005, -15.19999999999967, -124.10000000000065, -38.599999999999774, 52.90000000000009, 40.50000000000039, 34.80000000000024, -0.699999999999743, -135.000000000001, -111.1000000000007, -85.40000000000005, 40.0000000000003, -35.79999999999973, -7.899999999999821, -77.79999999999981, 42.70000000000034, 62.40000000000047, -358.5999999999998, -186.70000000000033, -147.8000000000009, -333.09999999999997, -60.30000000000059, -226.40000000000043, -225.20000000000036, -239.70000000000005, -10.699999999999871, -59.299999999999855, -86.70000000000007, -81.59999999999965, -34.19999999999985, -237.6999999999998, -72.3000000000005, -116.60000000000039, -218.90000000000055, -57.19999999999987, -189.80000000000064, -6.200000000000047, 57.900000000000524, -166.90000000000003, -130.10000000000053, -12.699999999999736, 71.80000000000027, -136.09999999999997, 227.29999999999953, -467.0, 44.60000000000017, -226.20000000000005, 84.79999999999978, 126.30000000000015, 12.40000000000025, -203.3999999999998, -247.50000000000028, -42.799999999999855, 26.00000000000012, -205.00000000000045, -176.39999999999992, -300.9999999999999, 16.899999999999974, -151.10000000000073, 137.69999999999916, 30.400000000000333, 85.50000000000006, 66.8999999999994, 57.10000000000046, 117.59999999999968, 25.700000000000358, 19.500000000000114, -10.499999999999831, -18.999999999999737, 228.69999999999987, -75.40000000000094, 86.6999999999988, 44.59999999999994, -45.99999999999974, -6.699999999999816, -205.00000000000014], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-194.19999999999993, -263.8, -122.80000000000005, -65.2, 7.399999999999965, 20.000000000000014, 17.900000000000013, 61.10000000000015, -172.30000000000013, -59.80000000000004, -310.1999999999998, -24.10000000000005, -215.50000000000028, 19.700000000000017, 29.00000000000024, -66.10000000000014, -24.699999999999825, -92.49999999999991, 27.200000000000134, -240.0000000000003, -111.99999999999991, -392.80000000000007, -229.90000000000046, -229.90000000000038, -88.30000000000027, -198.40000000000038, 17.900000000000013, -122.8000000000001, -167.00000000000009, 41.90000000000019, -115.00000000000001, -246.0999999999999, 63.200000000000195, 20.000000000000014, -310.70000000000016, -290.29999999999995, -126.7000000000001, -138.70000000000005, 20.000000000000014, 20.000000000000014, -383.1999999999998, -38.799999999999756, -66.10000000000079, -38.4999999999999, 56.900000000000226, 67.6999999999999, 28.100000000000147, -43.900000000000006, -65.20000000000039, -268.90000000000003, 21.80000000000004, -208.0000000000005, -66.10000000000059, -316.0, 20.000000000000014, -208.60000000000034, 20.000000000000014, -378.1, -17.49999999999986, 20.000000000000014, -12.099999999999874, 20.900000000000027, -0.9999999999999846, -21.699999999999754, -124.90000000000043, -96.10000000000053, -130.80000000000075, -349.2999999999997, -198.1, -28.299999999999834, 20.000000000000014, 20.000000000000014, -15.099999999999842, -69.70000000000041, 20.000000000000014, -130.90000000000015, -79.2999999999999, -53.50000000000001, 22.700000000000053, 20.000000000000014, 32.90000000000023, 24.500000000000092, -307.6000000000001, -388.0, -310.60000000000014, -87.10000000000002, -119.20000000000007, -150.60000000000053, -366.2, -421.9, -196.30000000000038, 20.000000000000014, -368.50000000000006, -103.90000000000028, -288.79999999999995, -198.40000000000038, -186.7, -269.0, -114.70000000000027, 20.000000000000014, -153.9000000000003, -21.399999999999977, -93.39999999999995, -49.30000000000001, -143.80000000000007, -20.799999999999898, -5.199999999999969, -103.0000000000003, -169.0, -208.69999999999993, -179.8000000000002, -53.50000000000019, -70.60000000000048, -189.99999999999991, -187.90000000000038, -211.00000000000014, -100.30000000000052, -70.90000000000015, -162.70000000000033, -135.10000000000036, -68.20000000000002, 20.000000000000014, 23.000000000000224, 29.90000000000018, -189.99999999999994, -219.89999999999995, -138.7000000000003, -261.40000000000015, -228.5, -44.20000000000004, 20.000000000000014, -240.19999999999993, -127.50000000000003, -145.60000000000002, 1.0999999999999712, -876.8, -490.4, -426.6, 1.099999999999953, -739.5, -312.70000000000005, -269.5, -38.80000000000005, -822.4, -528.7, 29.000000000000163, 1.0999999999999723, -42.69999999999997, -374.69999999999993, -225.70000000000002, -312.1, -341.399999999999, -91.29999999999998, -781.5, -113.9999999999998, 20.000000000000014, -180.70000000000027, -205.30000000000018, -665.1, -271.3000000000002, -294.3, -566.7, -24.099999999999746, 20.000000000000014, -202.60000000000053, -137.50000000000028, -511.20000000000005, 74.89999999999941, -25.6, 20.000000000000014, -651.4, 20.900000000000027, 58.4000000000001, -200.5000000000001, 20.000000000000014, 28.100000000000158, -702.3999999999999, 20.000000000000014, -74.49999999999997, 27.20000000000014, 20.000000000000014, -415.4999999999998, 20.000000000000014, -354.5, -49.59999999999983, -200.40000000000003, -30.39999999999977, -493.9, -60.70000000000031, -162.70000000000041, 43.400000000000205, 29.300000000000193, -362.1, -598.3, -139.6000000000007, -222.40000000000003, -95.50000000000057, -298.20000000000005, -386.69999999999936, -344.29999999999995], "policy_predator_policy_reward": [148.0, 147.0, 22.0, 60.0, 6.0, 0.0, 0.0, 2.0, 92.0, 38.0, 96.0, 173.0, 63.0, 60.0, 0.0, 44.0, 75.0, 73.0, 90.0, 101.0, 287.0, 40.0, 6.0, 175.0, 116.0, 58.0, 68.0, 1.0, 63.0, 117.0, 148.0, 75.0, 0.0, 0.0, 242.0, 97.0, 97.0, 45.0, 0.0, 0.0, 162.0, 183.0, 57.0, 30.0, 1.0, 2.0, 0.0, 48.0, 0.0, 147.0, 86.0, 85.0, 125.0, 133.0, 121.0, 29.0, 228.0, 183.0, 38.0, 0.0, 26.0, 0.0, 22.0, 0.0, 20.0, 66.0, 185.0, 184.0, 25.0, 116.0, 0.0, 0.0, 49.0, 0.0, 10.0, 93.0, 55.0, 0.0, 0.0, 0.0, 3.0, 2.0, 152.0, 185.0, 51.0, 160.0, 83.0, 39.0, 156.0, 299.0, 13.0, 103.0, 96.0, 150.0, 173.0, 89.0, 120.0, 96.0, 2.0, 82.0, 13.0, 103.0, 56.0, 0.0, 0.0, 83.0, 0.0, 74.0, 0.0, 140.0, 120.0, 41.0, 24.0, 120.0, 57.0, 123.0, 113.0, 1.0, 29.0, 79.0, 0.0, 42.0, 5.0, 0.0, 135.0, 108.0, 133.0, 137.0, 185.0, 75.0, 91.0, 201.0, 9.0, 128.0, 582.0, 521.0, 0.0, 450.0, 526.0, 257.0, 148.0, 208.0, 438.0, 508.0, 185.0, 441.0, 50.0, 4.0, 99.0, 298.0, 159.0, 247.0, 528.0, 302.0, 66.0, 54.0, 127.0, 54.0, 484.0, 276.0, 505.0, 55.0, 21.0, 0.0, 128.0, 61.0, 319.0, 255.0, 9.0, 27.0, 401.0, 315.0, 105.0, 104.0, 8.0, 1.0, 453.0, 347.0, 42.0, 31.0, 291.0, 124.0, 96.0, 228.0, 101.0, 130.0, 391.0, 362.0, 75.0, 73.0, 14.0, 0.0, 546.0, 459.0, 195.0, 121.0, 232.0, 155.0, 256.0, 270.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1381776705374103, "mean_inference_ms": 3.0841325071242203, "mean_action_processing_ms": 0.4555488725683719, "mean_env_wait_ms": 0.7015927065875616, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006567716598510742, "StateBufferConnector_ms": 0.0046422481536865234, "ViewRequirementAgentConnector_ms": 0.193037748336792}, "num_episodes": 18, "episode_return_max": 228.69999999999987, "episode_return_min": -467.0, "episode_return_mean": -60.191000000000095, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 349.8204651991397, "num_env_steps_trained_throughput_per_sec": 349.8204651991397, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 12924.707, "restore_workers_time_ms": 0.02, "training_step_time_ms": 12924.646, "sample_time_ms": 2306.93, "learn_time_ms": 10600.044, "learn_throughput": 377.357, "synch_weights_time_ms": 14.676}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "c52aa_00000", "date": "2024-08-12_23-50-31", "timestamp": 1723521031, "time_this_iter_s": 11.500720024108887, "time_total_s": 160.85839676856995, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc093a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 160.85839676856995, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 57.46470588235294, "ram_util_percent": 83.12352941176471}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0543433888327507, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0665000084216003, "policy_loss": -0.006143915175248391, "vf_loss": 3.0713718630649427, "vf_explained_var": -0.00021677711022593987, "kl": 0.02261432116271638, "entropy": 1.473744063781052, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3754588549828561, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7362354635561585, "policy_loss": -0.001574416626638994, "vf_loss": 3.737450291492321, "vf_explained_var": -0.00013680741900489444, "kl": 0.006392762330282295, "entropy": 1.4622559769443735, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 228.69999999999987, "episode_reward_min": -467.0, "episode_reward_mean": -43.8980000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -876.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 74.89999999999941, "predator_policy": 582.0}, "policy_reward_mean": {"prey_policy": -140.25900000000004, "predator_policy": 118.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-123.40000000000018, 40.0000000000003, -77.00000000000071, -17.59999999999964, 127.59999999999846, 32.200000000000415, -187.1000000000005, -15.19999999999967, -124.10000000000065, -38.599999999999774, 52.90000000000009, 40.50000000000039, 34.80000000000024, -0.699999999999743, -135.000000000001, -111.1000000000007, -85.40000000000005, 40.0000000000003, -35.79999999999973, -7.899999999999821, -77.79999999999981, 42.70000000000034, 62.40000000000047, -358.5999999999998, -186.70000000000033, -147.8000000000009, -333.09999999999997, -60.30000000000059, -226.40000000000043, -225.20000000000036, -239.70000000000005, -10.699999999999871, -59.299999999999855, -86.70000000000007, -81.59999999999965, -34.19999999999985, -237.6999999999998, -72.3000000000005, -116.60000000000039, -218.90000000000055, -57.19999999999987, -189.80000000000064, -6.200000000000047, 57.900000000000524, -166.90000000000003, -130.10000000000053, -12.699999999999736, 71.80000000000027, -136.09999999999997, 227.29999999999953, -467.0, 44.60000000000017, -226.20000000000005, 84.79999999999978, 126.30000000000015, 12.40000000000025, -203.3999999999998, -247.50000000000028, -42.799999999999855, 26.00000000000012, -205.00000000000045, -176.39999999999992, -300.9999999999999, 16.899999999999974, -151.10000000000073, 137.69999999999916, 30.400000000000333, 85.50000000000006, 66.8999999999994, 57.10000000000046, 117.59999999999968, 25.700000000000358, 19.500000000000114, -10.499999999999831, -18.999999999999737, 228.69999999999987, -75.40000000000094, 86.6999999999988, 44.59999999999994, -45.99999999999974, -6.699999999999816, -205.00000000000014, 5.199999999999916, 27.900000000000126, 65.29999999999876, 10.999999999999934, -22.399999999999572, 40.0000000000003, 43.60000000000036, 116.49999999999842, -8.299999999999631, 47.400000000000425, 12.000000000000172, 4.000000000000107, -11.399999999999592, -63.39999999999991, -128.900000000001, 179.7999999999997, 80.49999999999929, -15.599999999999719], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-126.7000000000001, -138.70000000000005, 20.000000000000014, 20.000000000000014, -383.1999999999998, -38.799999999999756, -66.10000000000079, -38.4999999999999, 56.900000000000226, 67.6999999999999, 28.100000000000147, -43.900000000000006, -65.20000000000039, -268.90000000000003, 21.80000000000004, -208.0000000000005, -66.10000000000059, -316.0, 20.000000000000014, -208.60000000000034, 20.000000000000014, -378.1, -17.49999999999986, 20.000000000000014, -12.099999999999874, 20.900000000000027, -0.9999999999999846, -21.699999999999754, -124.90000000000043, -96.10000000000053, -130.80000000000075, -349.2999999999997, -198.1, -28.299999999999834, 20.000000000000014, 20.000000000000014, -15.099999999999842, -69.70000000000041, 20.000000000000014, -130.90000000000015, -79.2999999999999, -53.50000000000001, 22.700000000000053, 20.000000000000014, 32.90000000000023, 24.500000000000092, -307.6000000000001, -388.0, -310.60000000000014, -87.10000000000002, -119.20000000000007, -150.60000000000053, -366.2, -421.9, -196.30000000000038, 20.000000000000014, -368.50000000000006, -103.90000000000028, -288.79999999999995, -198.40000000000038, -186.7, -269.0, -114.70000000000027, 20.000000000000014, -153.9000000000003, -21.399999999999977, -93.39999999999995, -49.30000000000001, -143.80000000000007, -20.799999999999898, -5.199999999999969, -103.0000000000003, -169.0, -208.69999999999993, -179.8000000000002, -53.50000000000019, -70.60000000000048, -189.99999999999991, -187.90000000000038, -211.00000000000014, -100.30000000000052, -70.90000000000015, -162.70000000000033, -135.10000000000036, -68.20000000000002, 20.000000000000014, 23.000000000000224, 29.90000000000018, -189.99999999999994, -219.89999999999995, -138.7000000000003, -261.40000000000015, -228.5, -44.20000000000004, 20.000000000000014, -240.19999999999993, -127.50000000000003, -145.60000000000002, 1.0999999999999712, -876.8, -490.4, -426.6, 1.099999999999953, -739.5, -312.70000000000005, -269.5, -38.80000000000005, -822.4, -528.7, 29.000000000000163, 1.0999999999999723, -42.69999999999997, -374.69999999999993, -225.70000000000002, -312.1, -341.399999999999, -91.29999999999998, -781.5, -113.9999999999998, 20.000000000000014, -180.70000000000027, -205.30000000000018, -665.1, -271.3000000000002, -294.3, -566.7, -24.099999999999746, 20.000000000000014, -202.60000000000053, -137.50000000000028, -511.20000000000005, 74.89999999999941, -25.6, 20.000000000000014, -651.4, 20.900000000000027, 58.4000000000001, -200.5000000000001, 20.000000000000014, 28.100000000000158, -702.3999999999999, 20.000000000000014, -74.49999999999997, 27.20000000000014, 20.000000000000014, -415.4999999999998, 20.000000000000014, -354.5, -49.59999999999983, -200.40000000000003, -30.39999999999977, -493.9, -60.70000000000031, -162.70000000000041, 43.400000000000205, 29.300000000000193, -362.1, -598.3, -139.6000000000007, -222.40000000000003, -95.50000000000057, -298.20000000000005, -386.69999999999936, -344.29999999999995, -230.49999999999991, 22.70000000000006, 35.3000000000002, -54.400000000000176, 25.400000000000098, 8.89999999999966, -5.200000000000037, -20.799999999999848, -78.40000000000076, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 51.500000000000234, 65.00000000000011, -15.699999999999761, -22.599999999999753, 20.000000000000014, 19.400000000000006, -632.0, 20.000000000000014, 14.299999999999976, -46.29999999999976, -11.499999999999819, -34.899999999999764, -177.40000000000043, 20.000000000000014, -135.10000000000045, -134.80000000000064, 20.000000000000014, -606.2, 58.70000000000021, 21.800000000000043, -130.6000000000005, 20.000000000000014], "policy_predator_policy_reward": [97.0, 45.0, 0.0, 0.0, 162.0, 183.0, 57.0, 30.0, 1.0, 2.0, 0.0, 48.0, 0.0, 147.0, 86.0, 85.0, 125.0, 133.0, 121.0, 29.0, 228.0, 183.0, 38.0, 0.0, 26.0, 0.0, 22.0, 0.0, 20.0, 66.0, 185.0, 184.0, 25.0, 116.0, 0.0, 0.0, 49.0, 0.0, 10.0, 93.0, 55.0, 0.0, 0.0, 0.0, 3.0, 2.0, 152.0, 185.0, 51.0, 160.0, 83.0, 39.0, 156.0, 299.0, 13.0, 103.0, 96.0, 150.0, 173.0, 89.0, 120.0, 96.0, 2.0, 82.0, 13.0, 103.0, 56.0, 0.0, 0.0, 83.0, 0.0, 74.0, 0.0, 140.0, 120.0, 41.0, 24.0, 120.0, 57.0, 123.0, 113.0, 1.0, 29.0, 79.0, 0.0, 42.0, 5.0, 0.0, 135.0, 108.0, 133.0, 137.0, 185.0, 75.0, 91.0, 201.0, 9.0, 128.0, 582.0, 521.0, 0.0, 450.0, 526.0, 257.0, 148.0, 208.0, 438.0, 508.0, 185.0, 441.0, 50.0, 4.0, 99.0, 298.0, 159.0, 247.0, 528.0, 302.0, 66.0, 54.0, 127.0, 54.0, 484.0, 276.0, 505.0, 55.0, 21.0, 0.0, 128.0, 61.0, 319.0, 255.0, 9.0, 27.0, 401.0, 315.0, 105.0, 104.0, 8.0, 1.0, 453.0, 347.0, 42.0, 31.0, 291.0, 124.0, 96.0, 228.0, 101.0, 130.0, 391.0, 362.0, 75.0, 73.0, 14.0, 0.0, 546.0, 459.0, 195.0, 121.0, 232.0, 155.0, 256.0, 270.0, 102.0, 111.0, 31.0, 16.0, 31.0, 0.0, 27.0, 10.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 8.0, 296.0, 328.0, 36.0, 0.0, 11.0, 24.0, 32.0, 62.0, 100.0, 41.0, 421.0, 345.0, 0.0, 0.0, 68.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1186261315692647, "mean_inference_ms": 3.0244227402362083, "mean_action_processing_ms": 0.4506326689711475, "mean_env_wait_ms": 0.6899554072717075, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007778286933898926, "StateBufferConnector_ms": 0.003930807113647461, "ViewRequirementAgentConnector_ms": 0.1673431396484375}, "num_episodes": 18, "episode_return_max": 228.69999999999987, "episode_return_min": -467.0, "episode_return_mean": -43.8980000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 316.3318184344731, "num_env_steps_trained_throughput_per_sec": 316.3318184344731, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 12991.612, "restore_workers_time_ms": 0.018, "training_step_time_ms": 12991.557, "sample_time_ms": 2248.215, "learn_time_ms": 10726.137, "learn_throughput": 372.921, "synch_weights_time_ms": 14.737}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "c52aa_00000", "date": "2024-08-12_23-50-44", "timestamp": 1723521044, "time_this_iter_s": 12.71767807006836, "time_total_s": 173.5760748386383, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc09d30>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 173.5760748386383, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 63.45000000000001, "ram_util_percent": 83.56666666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3897373122276453, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.72523779824928, "policy_loss": -0.0024902861695933753, "vf_loss": 2.7268972994789245, "vf_explained_var": 0.018611206800218612, "kl": 0.009846332022614814, "entropy": 1.4693799790251192, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3270920560591751, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4951057544145634, "policy_loss": -0.005093977304185352, "vf_loss": 1.4993188337989585, "vf_explained_var": 0.0043437082931478185, "kl": 0.015660446067732304, "entropy": 1.4857560664257676, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 228.69999999999987, "episode_reward_min": -467.0, "episode_reward_mean": -18.953000000000085, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -876.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 115.39999999999952, "predator_policy": 582.0}, "policy_reward_mean": {"prey_policy": -113.69150000000005, "predator_policy": 104.215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-60.30000000000059, -226.40000000000043, -225.20000000000036, -239.70000000000005, -10.699999999999871, -59.299999999999855, -86.70000000000007, -81.59999999999965, -34.19999999999985, -237.6999999999998, -72.3000000000005, -116.60000000000039, -218.90000000000055, -57.19999999999987, -189.80000000000064, -6.200000000000047, 57.900000000000524, -166.90000000000003, -130.10000000000053, -12.699999999999736, 71.80000000000027, -136.09999999999997, 227.29999999999953, -467.0, 44.60000000000017, -226.20000000000005, 84.79999999999978, 126.30000000000015, 12.40000000000025, -203.3999999999998, -247.50000000000028, -42.799999999999855, 26.00000000000012, -205.00000000000045, -176.39999999999992, -300.9999999999999, 16.899999999999974, -151.10000000000073, 137.69999999999916, 30.400000000000333, 85.50000000000006, 66.8999999999994, 57.10000000000046, 117.59999999999968, 25.700000000000358, 19.500000000000114, -10.499999999999831, -18.999999999999737, 228.69999999999987, -75.40000000000094, 86.6999999999988, 44.59999999999994, -45.99999999999974, -6.699999999999816, -205.00000000000014, 5.199999999999916, 27.900000000000126, 65.29999999999876, 10.999999999999934, -22.399999999999572, 40.0000000000003, 43.60000000000036, 116.49999999999842, -8.299999999999631, 47.400000000000425, 12.000000000000172, 4.000000000000107, -11.399999999999592, -63.39999999999991, -128.900000000001, 179.7999999999997, 80.49999999999929, -15.599999999999719, 86.79999999999887, 32.6000000000004, 43.60000000000035, -32.899999999999665, 22.800000000000033, 39.200000000000294, -7.299999999999741, 108.69999999999854, 10.300000000000066, 53.000000000000355, 24.000000000000053, 75.59999999999964, -61.40000000000032, -20.499999999999773, 126.49999999999892, -7.899999999999704, 37.40000000000032, 39.40000000000029, 75.99999999999959, 83.29999999999937, 54.20000000000048, 42.90000000000042, -62.20000000000131, 62.50000000000028, 37.600000000000236, -2.199999999999975, 42.700000000000344], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-196.30000000000038, 20.000000000000014, -368.50000000000006, -103.90000000000028, -288.79999999999995, -198.40000000000038, -186.7, -269.0, -114.70000000000027, 20.000000000000014, -153.9000000000003, -21.399999999999977, -93.39999999999995, -49.30000000000001, -143.80000000000007, -20.799999999999898, -5.199999999999969, -103.0000000000003, -169.0, -208.69999999999993, -179.8000000000002, -53.50000000000019, -70.60000000000048, -189.99999999999991, -187.90000000000038, -211.00000000000014, -100.30000000000052, -70.90000000000015, -162.70000000000033, -135.10000000000036, -68.20000000000002, 20.000000000000014, 23.000000000000224, 29.90000000000018, -189.99999999999994, -219.89999999999995, -138.7000000000003, -261.40000000000015, -228.5, -44.20000000000004, 20.000000000000014, -240.19999999999993, -127.50000000000003, -145.60000000000002, 1.0999999999999712, -876.8, -490.4, -426.6, 1.099999999999953, -739.5, -312.70000000000005, -269.5, -38.80000000000005, -822.4, -528.7, 29.000000000000163, 1.0999999999999723, -42.69999999999997, -374.69999999999993, -225.70000000000002, -312.1, -341.399999999999, -91.29999999999998, -781.5, -113.9999999999998, 20.000000000000014, -180.70000000000027, -205.30000000000018, -665.1, -271.3000000000002, -294.3, -566.7, -24.099999999999746, 20.000000000000014, -202.60000000000053, -137.50000000000028, -511.20000000000005, 74.89999999999941, -25.6, 20.000000000000014, -651.4, 20.900000000000027, 58.4000000000001, -200.5000000000001, 20.000000000000014, 28.100000000000158, -702.3999999999999, 20.000000000000014, -74.49999999999997, 27.20000000000014, 20.000000000000014, -415.4999999999998, 20.000000000000014, -354.5, -49.59999999999983, -200.40000000000003, -30.39999999999977, -493.9, -60.70000000000031, -162.70000000000041, 43.400000000000205, 29.300000000000193, -362.1, -598.3, -139.6000000000007, -222.40000000000003, -95.50000000000057, -298.20000000000005, -386.69999999999936, -344.29999999999995, -230.49999999999991, 22.70000000000006, 35.3000000000002, -54.400000000000176, 25.400000000000098, 8.89999999999966, -5.200000000000037, -20.799999999999848, -78.40000000000076, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 51.500000000000234, 65.00000000000011, -15.699999999999761, -22.599999999999753, 20.000000000000014, 19.400000000000006, -632.0, 20.000000000000014, 14.299999999999976, -46.29999999999976, -11.499999999999819, -34.899999999999764, -177.40000000000043, 20.000000000000014, -135.10000000000045, -134.80000000000064, 20.000000000000014, -606.2, 58.70000000000021, 21.800000000000043, -130.6000000000005, 20.000000000000014, 38.000000000000256, 48.80000000000024, 53.30000000000023, -57.70000000000005, 23.600000000000065, 20.000000000000014, -202.3000000000003, -13.599999999999783, -2.500000000000004, 5.299999999999974, 20.000000000000014, -2.799999999999977, 20.000000000000014, -70.30000000000075, 70.39999999999972, 17.299999999999976, 20.000000000000014, -36.699999999999754, 21.200000000000152, 15.799999999999963, -21.999999999999773, 20.000000000000014, 20.000000000000014, 53.60000000000022, -144.70000000000024, -30.69999999999981, -53.49999999999999, -21.999999999999986, -1.899999999999932, 115.39999999999952, 20.000000000000014, -82.9000000000008, -26.19999999999979, 41.60000000000025, 20.900000000000027, -14.49999999999978, 56.000000000000206, 20.000000000000014, 1.3999999999999744, 47.90000000000013, 24.200000000000088, 20.000000000000014, -97.60000000000022, 42.50000000000021, -68.2000000000007, -42.99999999999979, 24.500000000000043, 20.000000000000014, 11.299999999999969, 14.299999999999955, -76.60000000000034, 22.400000000000105, 20.000000000000014, 22.700000000000063], "policy_predator_policy_reward": [13.0, 103.0, 96.0, 150.0, 173.0, 89.0, 120.0, 96.0, 2.0, 82.0, 13.0, 103.0, 56.0, 0.0, 0.0, 83.0, 0.0, 74.0, 0.0, 140.0, 120.0, 41.0, 24.0, 120.0, 57.0, 123.0, 113.0, 1.0, 29.0, 79.0, 0.0, 42.0, 5.0, 0.0, 135.0, 108.0, 133.0, 137.0, 185.0, 75.0, 91.0, 201.0, 9.0, 128.0, 582.0, 521.0, 0.0, 450.0, 526.0, 257.0, 148.0, 208.0, 438.0, 508.0, 185.0, 441.0, 50.0, 4.0, 99.0, 298.0, 159.0, 247.0, 528.0, 302.0, 66.0, 54.0, 127.0, 54.0, 484.0, 276.0, 505.0, 55.0, 21.0, 0.0, 128.0, 61.0, 319.0, 255.0, 9.0, 27.0, 401.0, 315.0, 105.0, 104.0, 8.0, 1.0, 453.0, 347.0, 42.0, 31.0, 291.0, 124.0, 96.0, 228.0, 101.0, 130.0, 391.0, 362.0, 75.0, 73.0, 14.0, 0.0, 546.0, 459.0, 195.0, 121.0, 232.0, 155.0, 256.0, 270.0, 102.0, 111.0, 31.0, 16.0, 31.0, 0.0, 27.0, 10.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 8.0, 296.0, 328.0, 36.0, 0.0, 11.0, 24.0, 32.0, 62.0, 100.0, 41.0, 421.0, 345.0, 0.0, 0.0, 68.0, 27.0, 0.0, 0.0, 24.0, 13.0, 0.0, 0.0, 73.0, 110.0, 20.0, 0.0, 3.0, 19.0, 6.0, 37.0, 0.0, 21.0, 27.0, 0.0, 6.0, 10.0, 23.0, 3.0, 0.0, 2.0, 114.0, 0.0, 55.0, 0.0, 0.0, 13.0, 24.0, 31.0, 0.0, 22.0, 14.0, 19.0, 0.0, 0.0, 17.0, 17.0, 10.0, 0.0, 55.0, 43.0, 20.0, 29.0, 18.0, 0.0, 0.0, 12.0, 51.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0975457206994284, "mean_inference_ms": 2.9656800428480716, "mean_action_processing_ms": 0.4475295279799113, "mean_env_wait_ms": 0.6785909113824001, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008842825889587402, "StateBufferConnector_ms": 0.00430452823638916, "ViewRequirementAgentConnector_ms": 0.186775803565979}, "num_episodes": 27, "episode_return_max": 228.69999999999987, "episode_return_min": -467.0, "episode_return_mean": -18.953000000000085, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 319.15826852295925, "num_env_steps_trained_throughput_per_sec": 319.15826852295925, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 12937.259, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12937.201, "sample_time_ms": 2222.223, "learn_time_ms": 10698.415, "learn_throughput": 373.887, "synch_weights_time_ms": 13.759}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "c52aa_00000", "date": "2024-08-12_23-50-56", "timestamp": 1723521056, "time_this_iter_s": 12.594578266143799, "time_total_s": 186.1706531047821, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c5c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 186.1706531047821, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 64.41666666666666, "ram_util_percent": 83.50555555555555}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.308545809014449, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.742012433778672, "policy_loss": -0.003973680209471948, "vf_loss": 3.7449628148760112, "vf_explained_var": 0.008670548755655844, "kl": 0.012127930922186433, "entropy": 1.4425984146103026, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29102065078914163, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.383835952748697, "policy_loss": -0.004458947924197351, "vf_loss": 2.3875770790236337, "vf_explained_var": 0.007267601023275385, "kl": 0.012761124528385572, "entropy": 1.5199843344865023, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 228.69999999999987, "episode_reward_min": -467.0, "episode_reward_mean": 12.54399999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -876.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.3999999999999, "predator_policy": 582.0}, "policy_reward_mean": {"prey_policy": -89.25299999999999, "predator_policy": 95.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-130.10000000000053, -12.699999999999736, 71.80000000000027, -136.09999999999997, 227.29999999999953, -467.0, 44.60000000000017, -226.20000000000005, 84.79999999999978, 126.30000000000015, 12.40000000000025, -203.3999999999998, -247.50000000000028, -42.799999999999855, 26.00000000000012, -205.00000000000045, -176.39999999999992, -300.9999999999999, 16.899999999999974, -151.10000000000073, 137.69999999999916, 30.400000000000333, 85.50000000000006, 66.8999999999994, 57.10000000000046, 117.59999999999968, 25.700000000000358, 19.500000000000114, -10.499999999999831, -18.999999999999737, 228.69999999999987, -75.40000000000094, 86.6999999999988, 44.59999999999994, -45.99999999999974, -6.699999999999816, -205.00000000000014, 5.199999999999916, 27.900000000000126, 65.29999999999876, 10.999999999999934, -22.399999999999572, 40.0000000000003, 43.60000000000036, 116.49999999999842, -8.299999999999631, 47.400000000000425, 12.000000000000172, 4.000000000000107, -11.399999999999592, -63.39999999999991, -128.900000000001, 179.7999999999997, 80.49999999999929, -15.599999999999719, 86.79999999999887, 32.6000000000004, 43.60000000000035, -32.899999999999665, 22.800000000000033, 39.200000000000294, -7.299999999999741, 108.69999999999854, 10.300000000000066, 53.000000000000355, 24.000000000000053, 75.59999999999964, -61.40000000000032, -20.499999999999773, 126.49999999999892, -7.899999999999704, 37.40000000000032, 39.40000000000029, 75.99999999999959, 83.29999999999937, 54.20000000000048, 42.90000000000042, -62.20000000000131, 62.50000000000028, 37.600000000000236, -2.199999999999975, 42.700000000000344, 45.60000000000037, -46.9000000000001, 119.19999999999824, 96.69999999999858, -23.19999999999996, -18.79999999999974, -16.199999999999598, 79.99999999999937, 17.500000000000014, 79.59999999999935, 195.6999999999991, 35.200000000000315, 61.6000000000005, 53.50000000000052, 179.8999999999993, 35.600000000000236, 121.3999999999995, 101.49999999999858], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-138.7000000000003, -261.40000000000015, -228.5, -44.20000000000004, 20.000000000000014, -240.19999999999993, -127.50000000000003, -145.60000000000002, 1.0999999999999712, -876.8, -490.4, -426.6, 1.099999999999953, -739.5, -312.70000000000005, -269.5, -38.80000000000005, -822.4, -528.7, 29.000000000000163, 1.0999999999999723, -42.69999999999997, -374.69999999999993, -225.70000000000002, -312.1, -341.399999999999, -91.29999999999998, -781.5, -113.9999999999998, 20.000000000000014, -180.70000000000027, -205.30000000000018, -665.1, -271.3000000000002, -294.3, -566.7, -24.099999999999746, 20.000000000000014, -202.60000000000053, -137.50000000000028, -511.20000000000005, 74.89999999999941, -25.6, 20.000000000000014, -651.4, 20.900000000000027, 58.4000000000001, -200.5000000000001, 20.000000000000014, 28.100000000000158, -702.3999999999999, 20.000000000000014, -74.49999999999997, 27.20000000000014, 20.000000000000014, -415.4999999999998, 20.000000000000014, -354.5, -49.59999999999983, -200.40000000000003, -30.39999999999977, -493.9, -60.70000000000031, -162.70000000000041, 43.400000000000205, 29.300000000000193, -362.1, -598.3, -139.6000000000007, -222.40000000000003, -95.50000000000057, -298.20000000000005, -386.69999999999936, -344.29999999999995, -230.49999999999991, 22.70000000000006, 35.3000000000002, -54.400000000000176, 25.400000000000098, 8.89999999999966, -5.200000000000037, -20.799999999999848, -78.40000000000076, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 51.500000000000234, 65.00000000000011, -15.699999999999761, -22.599999999999753, 20.000000000000014, 19.400000000000006, -632.0, 20.000000000000014, 14.299999999999976, -46.29999999999976, -11.499999999999819, -34.899999999999764, -177.40000000000043, 20.000000000000014, -135.10000000000045, -134.80000000000064, 20.000000000000014, -606.2, 58.70000000000021, 21.800000000000043, -130.6000000000005, 20.000000000000014, 38.000000000000256, 48.80000000000024, 53.30000000000023, -57.70000000000005, 23.600000000000065, 20.000000000000014, -202.3000000000003, -13.599999999999783, -2.500000000000004, 5.299999999999974, 20.000000000000014, -2.799999999999977, 20.000000000000014, -70.30000000000075, 70.39999999999972, 17.299999999999976, 20.000000000000014, -36.699999999999754, 21.200000000000152, 15.799999999999963, -21.999999999999773, 20.000000000000014, 20.000000000000014, 53.60000000000022, -144.70000000000024, -30.69999999999981, -53.49999999999999, -21.999999999999986, -1.899999999999932, 115.39999999999952, 20.000000000000014, -82.9000000000008, -26.19999999999979, 41.60000000000025, 20.900000000000027, -14.49999999999978, 56.000000000000206, 20.000000000000014, 1.3999999999999744, 47.90000000000013, 24.200000000000088, 20.000000000000014, -97.60000000000022, 42.50000000000021, -68.2000000000007, -42.99999999999979, 24.500000000000043, 20.000000000000014, 11.299999999999969, 14.299999999999955, -76.60000000000034, 22.400000000000105, 20.000000000000014, 22.700000000000063, 33.50000000000024, 4.099999999999966, -40.89999999999981, -58.000000000000156, 53.30000000000023, 65.90000000000008, 17.299999999999976, 61.400000000000176, -13.599999999999858, -118.60000000000001, -0.09999999999999937, -105.70000000000039, -92.2000000000007, 20.000000000000014, -63.70000000000049, 61.70000000000008, -28.299999999999862, -11.199999999999934, 10.099999999999968, 60.50000000000022, 82.09999999999926, 113.59999999999988, 19.40000000000001, -119.20000000000027, 24.500000000000078, 37.10000000000025, 20.000000000000014, 33.50000000000024, 30.500000000000178, 133.3999999999999, 20.000000000000014, 11.599999999999971, 118.99999999999986, -13.599999999999904, 78.49999999999935, 20.000000000000014], "policy_predator_policy_reward": [133.0, 137.0, 185.0, 75.0, 91.0, 201.0, 9.0, 128.0, 582.0, 521.0, 0.0, 450.0, 526.0, 257.0, 148.0, 208.0, 438.0, 508.0, 185.0, 441.0, 50.0, 4.0, 99.0, 298.0, 159.0, 247.0, 528.0, 302.0, 66.0, 54.0, 127.0, 54.0, 484.0, 276.0, 505.0, 55.0, 21.0, 0.0, 128.0, 61.0, 319.0, 255.0, 9.0, 27.0, 401.0, 315.0, 105.0, 104.0, 8.0, 1.0, 453.0, 347.0, 42.0, 31.0, 291.0, 124.0, 96.0, 228.0, 101.0, 130.0, 391.0, 362.0, 75.0, 73.0, 14.0, 0.0, 546.0, 459.0, 195.0, 121.0, 232.0, 155.0, 256.0, 270.0, 102.0, 111.0, 31.0, 16.0, 31.0, 0.0, 27.0, 10.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 8.0, 296.0, 328.0, 36.0, 0.0, 11.0, 24.0, 32.0, 62.0, 100.0, 41.0, 421.0, 345.0, 0.0, 0.0, 68.0, 27.0, 0.0, 0.0, 24.0, 13.0, 0.0, 0.0, 73.0, 110.0, 20.0, 0.0, 3.0, 19.0, 6.0, 37.0, 0.0, 21.0, 27.0, 0.0, 6.0, 10.0, 23.0, 3.0, 0.0, 2.0, 114.0, 0.0, 55.0, 0.0, 0.0, 13.0, 24.0, 31.0, 0.0, 22.0, 14.0, 19.0, 0.0, 0.0, 17.0, 17.0, 10.0, 0.0, 55.0, 43.0, 20.0, 29.0, 18.0, 0.0, 0.0, 12.0, 51.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 52.0, 0.0, 0.0, 3.0, 15.0, 52.0, 57.0, 63.0, 24.0, 0.0, 56.0, 56.0, 26.0, 9.0, 48.0, 9.0, 0.0, 0.0, 0.0, 78.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 4.0, 0.0, 9.0, 7.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0903179094086275, "mean_inference_ms": 2.941361408800592, "mean_action_processing_ms": 0.44554164763547294, "mean_env_wait_ms": 0.6755280495027073, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009439587593078613, "StateBufferConnector_ms": 0.004352450370788574, "ViewRequirementAgentConnector_ms": 0.17189979553222656}, "num_episodes": 18, "episode_return_max": 228.69999999999987, "episode_return_min": -467.0, "episode_return_mean": 12.54399999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 295.052941949657, "num_env_steps_trained_throughput_per_sec": 295.052941949657, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 13043.044, "restore_workers_time_ms": 0.018, "training_step_time_ms": 13042.985, "sample_time_ms": 2287.617, "learn_time_ms": 10737.125, "learn_throughput": 372.539, "synch_weights_time_ms": 14.992}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "c52aa_00000", "date": "2024-08-12_23-51-10", "timestamp": 1723521070, "time_this_iter_s": 13.625486135482788, "time_total_s": 199.7961392402649, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c59d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 199.7961392402649, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 66.99473684210527, "ram_util_percent": 83.47368421052632}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2035441559458535, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3712644493769086, "policy_loss": -0.004992337249313043, "vf_loss": 3.3748701453839662, "vf_explained_var": 0.03060488678790905, "kl": 0.016434089503542013, "entropy": 1.408699963332484, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27291429221984886, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6574297785128236, "policy_loss": -0.004287463054060936, "vf_loss": 1.6611539518391645, "vf_explained_var": 0.001278404331711865, "kl": 0.010014104193067388, "entropy": 1.5322852438719814, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 228.69999999999987, "episode_reward_min": -205.00000000000014, "episode_reward_mean": 35.86199999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -702.3999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.3999999999999, "predator_policy": 546.0}, "policy_reward_mean": {"prey_policy": -38.154000000000025, "predator_policy": 56.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.899999999999974, -151.10000000000073, 137.69999999999916, 30.400000000000333, 85.50000000000006, 66.8999999999994, 57.10000000000046, 117.59999999999968, 25.700000000000358, 19.500000000000114, -10.499999999999831, -18.999999999999737, 228.69999999999987, -75.40000000000094, 86.6999999999988, 44.59999999999994, -45.99999999999974, -6.699999999999816, -205.00000000000014, 5.199999999999916, 27.900000000000126, 65.29999999999876, 10.999999999999934, -22.399999999999572, 40.0000000000003, 43.60000000000036, 116.49999999999842, -8.299999999999631, 47.400000000000425, 12.000000000000172, 4.000000000000107, -11.399999999999592, -63.39999999999991, -128.900000000001, 179.7999999999997, 80.49999999999929, -15.599999999999719, 86.79999999999887, 32.6000000000004, 43.60000000000035, -32.899999999999665, 22.800000000000033, 39.200000000000294, -7.299999999999741, 108.69999999999854, 10.300000000000066, 53.000000000000355, 24.000000000000053, 75.59999999999964, -61.40000000000032, -20.499999999999773, 126.49999999999892, -7.899999999999704, 37.40000000000032, 39.40000000000029, 75.99999999999959, 83.29999999999937, 54.20000000000048, 42.90000000000042, -62.20000000000131, 62.50000000000028, 37.600000000000236, -2.199999999999975, 42.700000000000344, 45.60000000000037, -46.9000000000001, 119.19999999999824, 96.69999999999858, -23.19999999999996, -18.79999999999974, -16.199999999999598, 79.99999999999937, 17.500000000000014, 79.59999999999935, 195.6999999999991, 35.200000000000315, 61.6000000000005, 53.50000000000052, 179.8999999999993, 35.600000000000236, 121.3999999999995, 101.49999999999858, 83.4999999999991, -34.399999999999594, 35.60000000000031, 34.40000000000022, -6.399999999999666, 130.89999999999898, 66.4000000000002, 117.3999999999994, 94.09999999999854, -38.099999999999554, -14.999999999999636, 138.9999999999989, -17.199999999999598, 57.60000000000024, 17.699999999999953, -21.799999999999812, 116.19999999999982, 16.899999999999917], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-24.099999999999746, 20.000000000000014, -202.60000000000053, -137.50000000000028, -511.20000000000005, 74.89999999999941, -25.6, 20.000000000000014, -651.4, 20.900000000000027, 58.4000000000001, -200.5000000000001, 20.000000000000014, 28.100000000000158, -702.3999999999999, 20.000000000000014, -74.49999999999997, 27.20000000000014, 20.000000000000014, -415.4999999999998, 20.000000000000014, -354.5, -49.59999999999983, -200.40000000000003, -30.39999999999977, -493.9, -60.70000000000031, -162.70000000000041, 43.400000000000205, 29.300000000000193, -362.1, -598.3, -139.6000000000007, -222.40000000000003, -95.50000000000057, -298.20000000000005, -386.69999999999936, -344.29999999999995, -230.49999999999991, 22.70000000000006, 35.3000000000002, -54.400000000000176, 25.400000000000098, 8.89999999999966, -5.200000000000037, -20.799999999999848, -78.40000000000076, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 51.500000000000234, 65.00000000000011, -15.699999999999761, -22.599999999999753, 20.000000000000014, 19.400000000000006, -632.0, 20.000000000000014, 14.299999999999976, -46.29999999999976, -11.499999999999819, -34.899999999999764, -177.40000000000043, 20.000000000000014, -135.10000000000045, -134.80000000000064, 20.000000000000014, -606.2, 58.70000000000021, 21.800000000000043, -130.6000000000005, 20.000000000000014, 38.000000000000256, 48.80000000000024, 53.30000000000023, -57.70000000000005, 23.600000000000065, 20.000000000000014, -202.3000000000003, -13.599999999999783, -2.500000000000004, 5.299999999999974, 20.000000000000014, -2.799999999999977, 20.000000000000014, -70.30000000000075, 70.39999999999972, 17.299999999999976, 20.000000000000014, -36.699999999999754, 21.200000000000152, 15.799999999999963, -21.999999999999773, 20.000000000000014, 20.000000000000014, 53.60000000000022, -144.70000000000024, -30.69999999999981, -53.49999999999999, -21.999999999999986, -1.899999999999932, 115.39999999999952, 20.000000000000014, -82.9000000000008, -26.19999999999979, 41.60000000000025, 20.900000000000027, -14.49999999999978, 56.000000000000206, 20.000000000000014, 1.3999999999999744, 47.90000000000013, 24.200000000000088, 20.000000000000014, -97.60000000000022, 42.50000000000021, -68.2000000000007, -42.99999999999979, 24.500000000000043, 20.000000000000014, 11.299999999999969, 14.299999999999955, -76.60000000000034, 22.400000000000105, 20.000000000000014, 22.700000000000063, 33.50000000000024, 4.099999999999966, -40.89999999999981, -58.000000000000156, 53.30000000000023, 65.90000000000008, 17.299999999999976, 61.400000000000176, -13.599999999999858, -118.60000000000001, -0.09999999999999937, -105.70000000000039, -92.2000000000007, 20.000000000000014, -63.70000000000049, 61.70000000000008, -28.299999999999862, -11.199999999999934, 10.099999999999968, 60.50000000000022, 82.09999999999926, 113.59999999999988, 19.40000000000001, -119.20000000000027, 24.500000000000078, 37.10000000000025, 20.000000000000014, 33.50000000000024, 30.500000000000178, 133.3999999999999, 20.000000000000014, 11.599999999999971, 118.99999999999986, -13.599999999999904, 78.49999999999935, 20.000000000000014, -16.899999999999807, 61.40000000000016, -51.39999999999996, -42.99999999999982, 28.100000000000158, -5.500000000000018, -19.899999999999743, 35.30000000000025, -3.0999999999999757, -28.299999999999756, 100.09999999999957, 30.800000000000203, 35.300000000000175, 1.099999999999967, 20.000000000000014, 97.39999999999979, 11.599999999999968, 78.49999999999926, -34.59999999999977, -74.50000000000077, 20.000000000000014, -85.00000000000065, 42.50000000000025, 96.49999999999956, -139.6000000000007, 34.400000000000134, -78.70000000000071, 89.29999999999976, -24.099999999999746, -17.199999999999882, -93.70000000000041, -3.099999999999972, 36.20000000000008, 38.00000000000007, 11.599999999999973, -15.699999999999747], "policy_predator_policy_reward": [21.0, 0.0, 128.0, 61.0, 319.0, 255.0, 9.0, 27.0, 401.0, 315.0, 105.0, 104.0, 8.0, 1.0, 453.0, 347.0, 42.0, 31.0, 291.0, 124.0, 96.0, 228.0, 101.0, 130.0, 391.0, 362.0, 75.0, 73.0, 14.0, 0.0, 546.0, 459.0, 195.0, 121.0, 232.0, 155.0, 256.0, 270.0, 102.0, 111.0, 31.0, 16.0, 31.0, 0.0, 27.0, 10.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 8.0, 296.0, 328.0, 36.0, 0.0, 11.0, 24.0, 32.0, 62.0, 100.0, 41.0, 421.0, 345.0, 0.0, 0.0, 68.0, 27.0, 0.0, 0.0, 24.0, 13.0, 0.0, 0.0, 73.0, 110.0, 20.0, 0.0, 3.0, 19.0, 6.0, 37.0, 0.0, 21.0, 27.0, 0.0, 6.0, 10.0, 23.0, 3.0, 0.0, 2.0, 114.0, 0.0, 55.0, 0.0, 0.0, 13.0, 24.0, 31.0, 0.0, 22.0, 14.0, 19.0, 0.0, 0.0, 17.0, 17.0, 10.0, 0.0, 55.0, 43.0, 20.0, 29.0, 18.0, 0.0, 0.0, 12.0, 51.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 52.0, 0.0, 0.0, 3.0, 15.0, 52.0, 57.0, 63.0, 24.0, 0.0, 56.0, 56.0, 26.0, 9.0, 48.0, 9.0, 0.0, 0.0, 0.0, 78.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 4.0, 0.0, 9.0, 7.0, 3.0, 0.0, 27.0, 12.0, 0.0, 60.0, 0.0, 13.0, 19.0, 0.0, 2.0, 23.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 4.0, 50.0, 21.0, 29.0, 21.0, 0.0, 0.0, 53.0, 35.0, 30.0, 17.0, 37.0, 22.0, 64.0, 11.0, 27.0, 15.0, 0.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0815443164026568, "mean_inference_ms": 2.9084572200681724, "mean_action_processing_ms": 0.4405911301889276, "mean_env_wait_ms": 0.6695224348383002, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00971519947052002, "StateBufferConnector_ms": 0.004495501518249512, "ViewRequirementAgentConnector_ms": 0.19070923328399658}, "num_episodes": 18, "episode_return_max": 228.69999999999987, "episode_return_min": -205.00000000000014, "episode_return_mean": 35.86199999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 294.0888911450742, "num_env_steps_trained_throughput_per_sec": 294.0888911450742, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 12923.134, "restore_workers_time_ms": 0.017, "training_step_time_ms": 12923.077, "sample_time_ms": 2252.911, "learn_time_ms": 10652.665, "learn_throughput": 375.493, "synch_weights_time_ms": 14.787}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "c52aa_00000", "date": "2024-08-12_23-51-24", "timestamp": 1723521084, "time_this_iter_s": 13.64987301826477, "time_total_s": 213.44601225852966, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9bcc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 213.44601225852966, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 72.81000000000002, "ram_util_percent": 83.405}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.087485268388791, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.80324432149766, "policy_loss": -0.004466456592590523, "vf_loss": 2.8062048183547126, "vf_explained_var": 0.06343153424994655, "kl": 0.017848395839707994, "entropy": 1.4195677905486375, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.34345996842261345, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.162908121990779, "policy_loss": -0.0019748573193927766, "vf_loss": 1.164547628258902, "vf_explained_var": 0.007660285821036687, "kl": 0.005961767757796674, "entropy": 1.5543336990649108, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 195.6999999999991, "episode_reward_min": -205.00000000000014, "episode_reward_mean": 38.03099999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -632.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.3999999999999, "predator_policy": 421.0}, "policy_reward_mean": {"prey_policy": -8.904500000000027, "predator_policy": 27.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-205.00000000000014, 5.199999999999916, 27.900000000000126, 65.29999999999876, 10.999999999999934, -22.399999999999572, 40.0000000000003, 43.60000000000036, 116.49999999999842, -8.299999999999631, 47.400000000000425, 12.000000000000172, 4.000000000000107, -11.399999999999592, -63.39999999999991, -128.900000000001, 179.7999999999997, 80.49999999999929, -15.599999999999719, 86.79999999999887, 32.6000000000004, 43.60000000000035, -32.899999999999665, 22.800000000000033, 39.200000000000294, -7.299999999999741, 108.69999999999854, 10.300000000000066, 53.000000000000355, 24.000000000000053, 75.59999999999964, -61.40000000000032, -20.499999999999773, 126.49999999999892, -7.899999999999704, 37.40000000000032, 39.40000000000029, 75.99999999999959, 83.29999999999937, 54.20000000000048, 42.90000000000042, -62.20000000000131, 62.50000000000028, 37.600000000000236, -2.199999999999975, 42.700000000000344, 45.60000000000037, -46.9000000000001, 119.19999999999824, 96.69999999999858, -23.19999999999996, -18.79999999999974, -16.199999999999598, 79.99999999999937, 17.500000000000014, 79.59999999999935, 195.6999999999991, 35.200000000000315, 61.6000000000005, 53.50000000000052, 179.8999999999993, 35.600000000000236, 121.3999999999995, 101.49999999999858, 83.4999999999991, -34.399999999999594, 35.60000000000031, 34.40000000000022, -6.399999999999666, 130.89999999999898, 66.4000000000002, 117.3999999999994, 94.09999999999854, -38.099999999999554, -14.999999999999636, 138.9999999999989, -17.199999999999598, 57.60000000000024, 17.699999999999953, -21.799999999999812, 116.19999999999982, 16.899999999999917, 137.79999999999893, 102.89999999999881, 89.49999999999885, 89.49999999999943, -63.399999999999935, 49.50000000000047, 16.899999999999935, 143.4999999999993, -36.50000000000002, 79.5999999999994, -107.70000000000036, 69.70000000000009, 9.200000000000063, 16.899999999999935, -62.00000000000087, 121.89999999999935, 86.49999999999883, 81.69999999999911], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-386.69999999999936, -344.29999999999995, -230.49999999999991, 22.70000000000006, 35.3000000000002, -54.400000000000176, 25.400000000000098, 8.89999999999966, -5.200000000000037, -20.799999999999848, -78.40000000000076, -1.0000000000000062, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.60000000000007, 51.500000000000234, 65.00000000000011, -15.699999999999761, -22.599999999999753, 20.000000000000014, 19.400000000000006, -632.0, 20.000000000000014, 14.299999999999976, -46.29999999999976, -11.499999999999819, -34.899999999999764, -177.40000000000043, 20.000000000000014, -135.10000000000045, -134.80000000000064, 20.000000000000014, -606.2, 58.70000000000021, 21.800000000000043, -130.6000000000005, 20.000000000000014, 38.000000000000256, 48.80000000000024, 53.30000000000023, -57.70000000000005, 23.600000000000065, 20.000000000000014, -202.3000000000003, -13.599999999999783, -2.500000000000004, 5.299999999999974, 20.000000000000014, -2.799999999999977, 20.000000000000014, -70.30000000000075, 70.39999999999972, 17.299999999999976, 20.000000000000014, -36.699999999999754, 21.200000000000152, 15.799999999999963, -21.999999999999773, 20.000000000000014, 20.000000000000014, 53.60000000000022, -144.70000000000024, -30.69999999999981, -53.49999999999999, -21.999999999999986, -1.899999999999932, 115.39999999999952, 20.000000000000014, -82.9000000000008, -26.19999999999979, 41.60000000000025, 20.900000000000027, -14.49999999999978, 56.000000000000206, 20.000000000000014, 1.3999999999999744, 47.90000000000013, 24.200000000000088, 20.000000000000014, -97.60000000000022, 42.50000000000021, -68.2000000000007, -42.99999999999979, 24.500000000000043, 20.000000000000014, 11.299999999999969, 14.299999999999955, -76.60000000000034, 22.400000000000105, 20.000000000000014, 22.700000000000063, 33.50000000000024, 4.099999999999966, -40.89999999999981, -58.000000000000156, 53.30000000000023, 65.90000000000008, 17.299999999999976, 61.400000000000176, -13.599999999999858, -118.60000000000001, -0.09999999999999937, -105.70000000000039, -92.2000000000007, 20.000000000000014, -63.70000000000049, 61.70000000000008, -28.299999999999862, -11.199999999999934, 10.099999999999968, 60.50000000000022, 82.09999999999926, 113.59999999999988, 19.40000000000001, -119.20000000000027, 24.500000000000078, 37.10000000000025, 20.000000000000014, 33.50000000000024, 30.500000000000178, 133.3999999999999, 20.000000000000014, 11.599999999999971, 118.99999999999986, -13.599999999999904, 78.49999999999935, 20.000000000000014, -16.899999999999807, 61.40000000000016, -51.39999999999996, -42.99999999999982, 28.100000000000158, -5.500000000000018, -19.899999999999743, 35.30000000000025, -3.0999999999999757, -28.299999999999756, 100.09999999999957, 30.800000000000203, 35.300000000000175, 1.099999999999967, 20.000000000000014, 97.39999999999979, 11.599999999999968, 78.49999999999926, -34.59999999999977, -74.50000000000077, 20.000000000000014, -85.00000000000065, 42.50000000000025, 96.49999999999956, -139.6000000000007, 34.400000000000134, -78.70000000000071, 89.29999999999976, -24.099999999999746, -17.199999999999882, -93.70000000000041, -3.099999999999972, 36.20000000000008, 38.00000000000007, 11.599999999999973, -15.699999999999747, 14.599999999999966, 90.19999999999948, -28.29999999999975, 108.19999999999942, 69.4999999999998, 20.000000000000014, 20.000000000000014, 54.49999999999997, -154.3000000000005, -3.099999999999958, 15.799999999999963, 31.700000000000216, 15.799999999999946, -19.899999999999842, 104.59999999999977, 38.90000000000024, -112.29999999999998, 3.7999999999999816, 42.50000000000025, 37.10000000000026, 20.000000000000014, -291.70000000000005, 49.70000000000024, 20.000000000000014, 20.000000000000014, -38.79999999999976, 20.000000000000014, -24.099999999999838, -101.8000000000005, -47.19999999999976, 101.89999999999978, 20.000000000000014, 54.500000000000156, 16.999999999999964, 74.89999999999945, -5.199999999999937], "policy_predator_policy_reward": [256.0, 270.0, 102.0, 111.0, 31.0, 16.0, 31.0, 0.0, 27.0, 10.0, 0.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 8.0, 296.0, 328.0, 36.0, 0.0, 11.0, 24.0, 32.0, 62.0, 100.0, 41.0, 421.0, 345.0, 0.0, 0.0, 68.0, 27.0, 0.0, 0.0, 24.0, 13.0, 0.0, 0.0, 73.0, 110.0, 20.0, 0.0, 3.0, 19.0, 6.0, 37.0, 0.0, 21.0, 27.0, 0.0, 6.0, 10.0, 23.0, 3.0, 0.0, 2.0, 114.0, 0.0, 55.0, 0.0, 0.0, 13.0, 24.0, 31.0, 0.0, 22.0, 14.0, 19.0, 0.0, 0.0, 17.0, 17.0, 10.0, 0.0, 55.0, 43.0, 20.0, 29.0, 18.0, 0.0, 0.0, 12.0, 51.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 52.0, 0.0, 0.0, 3.0, 15.0, 52.0, 57.0, 63.0, 24.0, 0.0, 56.0, 56.0, 26.0, 9.0, 48.0, 9.0, 0.0, 0.0, 0.0, 78.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 4.0, 0.0, 9.0, 7.0, 3.0, 0.0, 27.0, 12.0, 0.0, 60.0, 0.0, 13.0, 19.0, 0.0, 2.0, 23.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 4.0, 50.0, 21.0, 29.0, 21.0, 0.0, 0.0, 53.0, 35.0, 30.0, 17.0, 37.0, 22.0, 64.0, 11.0, 27.0, 15.0, 0.0, 21.0, 8.0, 25.0, 0.0, 23.0, 0.0, 0.0, 7.0, 8.0, 93.0, 1.0, 2.0, 0.0, 0.0, 21.0, 0.0, 0.0, 4.0, 68.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 0.0, 1.0, 86.0, 0.0, 0.0, 14.0, 1.0, 12.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0763801310489292, "mean_inference_ms": 2.8885279564238626, "mean_action_processing_ms": 0.43778911415476784, "mean_env_wait_ms": 0.6661890678017655, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010414838790893555, "StateBufferConnector_ms": 0.004613280296325684, "ViewRequirementAgentConnector_ms": 0.18803763389587402}, "num_episodes": 18, "episode_return_max": 195.6999999999991, "episode_return_min": -205.00000000000014, "episode_return_mean": 38.03099999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 340.06946108532105, "num_env_steps_trained_throughput_per_sec": 340.06946108532105, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 12653.811, "restore_workers_time_ms": 0.016, "training_step_time_ms": 12653.757, "sample_time_ms": 2105.709, "learn_time_ms": 10530.169, "learn_throughput": 379.861, "synch_weights_time_ms": 14.542}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "c52aa_00000", "date": "2024-08-12_23-51-36", "timestamp": 1723521096, "time_this_iter_s": 11.828124046325684, "time_total_s": 225.27413630485535, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x329e23ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 225.27413630485535, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 60.9375, "ram_util_percent": 83.44999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1917190400775148, "cur_kl_coeff": 0.084375, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.899321209185969, "policy_loss": -0.011939847504808788, "vf_loss": 6.909211505405486, "vf_explained_var": 0.006077464610811264, "kl": 0.024291150325902882, "entropy": 1.4274380475755721, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29643373397923023, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.305193211792638, "policy_loss": -0.004682223107074461, "vf_loss": 7.309038846202628, "vf_explained_var": 0.00030366239093598867, "kl": 0.014872668700430577, "entropy": 1.4675557158611439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 195.6999999999991, "episode_reward_min": -115.50000000000003, "episode_reward_mean": 40.5139999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -647.1999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.3999999999999, "predator_policy": 390.0}, "policy_reward_mean": {"prey_policy": -14.483000000000043, "predator_policy": 34.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.899999999999665, 22.800000000000033, 39.200000000000294, -7.299999999999741, 108.69999999999854, 10.300000000000066, 53.000000000000355, 24.000000000000053, 75.59999999999964, -61.40000000000032, -20.499999999999773, 126.49999999999892, -7.899999999999704, 37.40000000000032, 39.40000000000029, 75.99999999999959, 83.29999999999937, 54.20000000000048, 42.90000000000042, -62.20000000000131, 62.50000000000028, 37.600000000000236, -2.199999999999975, 42.700000000000344, 45.60000000000037, -46.9000000000001, 119.19999999999824, 96.69999999999858, -23.19999999999996, -18.79999999999974, -16.199999999999598, 79.99999999999937, 17.500000000000014, 79.59999999999935, 195.6999999999991, 35.200000000000315, 61.6000000000005, 53.50000000000052, 179.8999999999993, 35.600000000000236, 121.3999999999995, 101.49999999999858, 83.4999999999991, -34.399999999999594, 35.60000000000031, 34.40000000000022, -6.399999999999666, 130.89999999999898, 66.4000000000002, 117.3999999999994, 94.09999999999854, -38.099999999999554, -14.999999999999636, 138.9999999999989, -17.199999999999598, 57.60000000000024, 17.699999999999953, -21.799999999999812, 116.19999999999982, 16.899999999999917, 137.79999999999893, 102.89999999999881, 89.49999999999885, 89.49999999999943, -63.399999999999935, 49.50000000000047, 16.899999999999935, 143.4999999999993, -36.50000000000002, 79.5999999999994, -107.70000000000036, 69.70000000000009, 9.200000000000063, 16.899999999999935, -62.00000000000087, 121.89999999999935, 86.49999999999883, 81.69999999999911, 44.90000000000038, 157.09999999999974, -85.4000000000001, 63.10000000000024, 67.89999999999935, -69.00000000000018, 32.30000000000018, 28.10000000000018, 40.60000000000018, 129.3999999999991, -74.20000000000012, -34.999999999999964, 98.69999999999904, 52.00000000000023, 38.30000000000027, -114.70000000000027, 79.5999999999999, -115.50000000000003, 100.29999999999896, -13.299999999999798, 111.39999999999914, 52.90000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-202.3000000000003, -13.599999999999783, -2.500000000000004, 5.299999999999974, 20.000000000000014, -2.799999999999977, 20.000000000000014, -70.30000000000075, 70.39999999999972, 17.299999999999976, 20.000000000000014, -36.699999999999754, 21.200000000000152, 15.799999999999963, -21.999999999999773, 20.000000000000014, 20.000000000000014, 53.60000000000022, -144.70000000000024, -30.69999999999981, -53.49999999999999, -21.999999999999986, -1.899999999999932, 115.39999999999952, 20.000000000000014, -82.9000000000008, -26.19999999999979, 41.60000000000025, 20.900000000000027, -14.49999999999978, 56.000000000000206, 20.000000000000014, 1.3999999999999744, 47.90000000000013, 24.200000000000088, 20.000000000000014, -97.60000000000022, 42.50000000000021, -68.2000000000007, -42.99999999999979, 24.500000000000043, 20.000000000000014, 11.299999999999969, 14.299999999999955, -76.60000000000034, 22.400000000000105, 20.000000000000014, 22.700000000000063, 33.50000000000024, 4.099999999999966, -40.89999999999981, -58.000000000000156, 53.30000000000023, 65.90000000000008, 17.299999999999976, 61.400000000000176, -13.599999999999858, -118.60000000000001, -0.09999999999999937, -105.70000000000039, -92.2000000000007, 20.000000000000014, -63.70000000000049, 61.70000000000008, -28.299999999999862, -11.199999999999934, 10.099999999999968, 60.50000000000022, 82.09999999999926, 113.59999999999988, 19.40000000000001, -119.20000000000027, 24.500000000000078, 37.10000000000025, 20.000000000000014, 33.50000000000024, 30.500000000000178, 133.3999999999999, 20.000000000000014, 11.599999999999971, 118.99999999999986, -13.599999999999904, 78.49999999999935, 20.000000000000014, -16.899999999999807, 61.40000000000016, -51.39999999999996, -42.99999999999982, 28.100000000000158, -5.500000000000018, -19.899999999999743, 35.30000000000025, -3.0999999999999757, -28.299999999999756, 100.09999999999957, 30.800000000000203, 35.300000000000175, 1.099999999999967, 20.000000000000014, 97.39999999999979, 11.599999999999968, 78.49999999999926, -34.59999999999977, -74.50000000000077, 20.000000000000014, -85.00000000000065, 42.50000000000025, 96.49999999999956, -139.6000000000007, 34.400000000000134, -78.70000000000071, 89.29999999999976, -24.099999999999746, -17.199999999999882, -93.70000000000041, -3.099999999999972, 36.20000000000008, 38.00000000000007, 11.599999999999973, -15.699999999999747, 14.599999999999966, 90.19999999999948, -28.29999999999975, 108.19999999999942, 69.4999999999998, 20.000000000000014, 20.000000000000014, 54.49999999999997, -154.3000000000005, -3.099999999999958, 15.799999999999963, 31.700000000000216, 15.799999999999946, -19.899999999999842, 104.59999999999977, 38.90000000000024, -112.29999999999998, 3.7999999999999816, 42.50000000000025, 37.10000000000026, 20.000000000000014, -291.70000000000005, 49.70000000000024, 20.000000000000014, 20.000000000000014, -38.79999999999976, 20.000000000000014, -24.099999999999838, -101.8000000000005, -47.19999999999976, 101.89999999999978, 20.000000000000014, 54.500000000000156, 16.999999999999964, 74.89999999999945, -5.199999999999937, 22.700000000000053, 15.199999999999964, -647.1999999999999, 107.29999999999976, -73.30000000000032, -390.1, -59.80000000000048, 80.89999999999999, -309.29999999999995, 12.20000000000023, -291.0000000000002, -1.0000000000000382, 5.299999999999965, 20.000000000000014, -549.6, 13.69999999999997, -383.70000000000005, -66.70000000000078, 82.99999999999966, 25.400000000000105, -238.30000000000027, -188.9, 5.299999999999965, -128.30000000000004, 61.70000000000012, 20.000000000000014, -60.99999999999991, 65.00000000000003, 20.000000000000014, 5.299999999999972, -213.6000000000003, -444.1, 59.600000000000165, 20.000000000000014, -71.49999999999994, -196.00000000000026, 20.000000000000014, 80.2999999999995, 23.900000000000148, -136.2, 17.299999999999983, 73.09999999999978, -5.1999999999999265, 46.10000000000024], "policy_predator_policy_reward": [73.0, 110.0, 20.0, 0.0, 3.0, 19.0, 6.0, 37.0, 0.0, 21.0, 27.0, 0.0, 6.0, 10.0, 23.0, 3.0, 0.0, 2.0, 114.0, 0.0, 55.0, 0.0, 0.0, 13.0, 24.0, 31.0, 0.0, 22.0, 14.0, 19.0, 0.0, 0.0, 17.0, 17.0, 10.0, 0.0, 55.0, 43.0, 20.0, 29.0, 18.0, 0.0, 0.0, 12.0, 51.0, 1.0, 0.0, 0.0, 0.0, 8.0, 0.0, 52.0, 0.0, 0.0, 3.0, 15.0, 52.0, 57.0, 63.0, 24.0, 0.0, 56.0, 56.0, 26.0, 9.0, 48.0, 9.0, 0.0, 0.0, 0.0, 78.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 4.0, 0.0, 9.0, 7.0, 3.0, 0.0, 27.0, 12.0, 0.0, 60.0, 0.0, 13.0, 19.0, 0.0, 2.0, 23.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 4.0, 50.0, 21.0, 29.0, 21.0, 0.0, 0.0, 53.0, 35.0, 30.0, 17.0, 37.0, 22.0, 64.0, 11.0, 27.0, 15.0, 0.0, 21.0, 8.0, 25.0, 0.0, 23.0, 0.0, 0.0, 7.0, 8.0, 93.0, 1.0, 2.0, 0.0, 0.0, 21.0, 0.0, 0.0, 4.0, 68.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 0.0, 1.0, 86.0, 0.0, 0.0, 14.0, 1.0, 12.0, 0.0, 7.0, 0.0, 390.0, 307.0, 145.0, 233.0, 38.0, 4.0, 108.0, 257.0, 116.0, 107.0, 7.0, 0.0, 197.0, 367.0, 332.0, 159.0, 21.0, 0.0, 172.0, 181.0, 0.0, 88.0, 17.0, 0.0, 28.0, 20.0, 13.0, 0.0, 321.0, 222.0, 0.0, 0.0, 89.0, 63.0, 0.0, 0.0, 19.0, 80.0, 21.0, 0.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0846096787319943, "mean_inference_ms": 2.9117092993140203, "mean_action_processing_ms": 0.4393553329300755, "mean_env_wait_ms": 0.6716542771105566, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00876760482788086, "StateBufferConnector_ms": 0.00478971004486084, "ViewRequirementAgentConnector_ms": 0.20772361755371094}, "num_episodes": 22, "episode_return_max": 195.6999999999991, "episode_return_min": -115.50000000000003, "episode_return_mean": 40.5139999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 174.38112077441224, "num_env_steps_trained_throughput_per_sec": 174.38112077441224, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 13733.791, "restore_workers_time_ms": 0.015, "training_step_time_ms": 13733.737, "sample_time_ms": 2339.07, "learn_time_ms": 11375.221, "learn_throughput": 351.642, "synch_weights_time_ms": 16.623}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "c52aa_00000", "date": "2024-08-12_23-51-59", "timestamp": 1723521119, "time_this_iter_s": 23.166186094284058, "time_total_s": 248.4403223991394, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab849b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 248.4403223991394, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 89.6909090909091, "ram_util_percent": 83.69393939393939}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2743173431151757, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.775795467820748, "policy_loss": -0.0044687186828543425, "vf_loss": 3.778928467710182, "vf_explained_var": 0.047839830476770956, "kl": 0.010553859611960684, "entropy": 1.4330946333824641, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31361039008491887, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.064435407913551, "policy_loss": -0.0018284591360796223, "vf_loss": 2.065797741987087, "vf_explained_var": 0.004779145200416525, "kl": 0.008286667921820593, "entropy": 1.4911793317113604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 195.6999999999991, "episode_reward_min": -115.50000000000003, "episode_reward_mean": 47.61699999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -647.1999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.5, "predator_policy": 390.0}, "policy_reward_mean": {"prey_policy": -15.761500000000042, "predator_policy": 39.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [42.700000000000344, 45.60000000000037, -46.9000000000001, 119.19999999999824, 96.69999999999858, -23.19999999999996, -18.79999999999974, -16.199999999999598, 79.99999999999937, 17.500000000000014, 79.59999999999935, 195.6999999999991, 35.200000000000315, 61.6000000000005, 53.50000000000052, 179.8999999999993, 35.600000000000236, 121.3999999999995, 101.49999999999858, 83.4999999999991, -34.399999999999594, 35.60000000000031, 34.40000000000022, -6.399999999999666, 130.89999999999898, 66.4000000000002, 117.3999999999994, 94.09999999999854, -38.099999999999554, -14.999999999999636, 138.9999999999989, -17.199999999999598, 57.60000000000024, 17.699999999999953, -21.799999999999812, 116.19999999999982, 16.899999999999917, 137.79999999999893, 102.89999999999881, 89.49999999999885, 89.49999999999943, -63.399999999999935, 49.50000000000047, 16.899999999999935, 143.4999999999993, -36.50000000000002, 79.5999999999994, -107.70000000000036, 69.70000000000009, 9.200000000000063, 16.899999999999935, -62.00000000000087, 121.89999999999935, 86.49999999999883, 81.69999999999911, 44.90000000000038, 157.09999999999974, -85.4000000000001, 63.10000000000024, 67.89999999999935, -69.00000000000018, 32.30000000000018, 28.10000000000018, 40.60000000000018, 129.3999999999991, -74.20000000000012, -34.999999999999964, 98.69999999999904, 52.00000000000023, 38.30000000000027, -114.70000000000027, 79.5999999999999, -115.50000000000003, 100.29999999999896, -13.299999999999798, 111.39999999999914, 52.90000000000048, 59.10000000000009, 75.89999999999957, 19.600000000000104, -5.999999999999995, 179.39999999999944, 40.0000000000003, -42.79999999999971, 67.49999999999999, 66.10000000000029, 90.89999999999904, 40.0000000000003, 88.89999999999978, 105.8999999999987, 118.79999999999944, 7.299999999999928, 76.49999999999999, 122.79999999999869, 50.69999999999985, 90.39999999999858, 24.800000000000143, -107.89999999999984, 101.89999999999898, 139.49999999999966], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 22.700000000000063, 33.50000000000024, 4.099999999999966, -40.89999999999981, -58.000000000000156, 53.30000000000023, 65.90000000000008, 17.299999999999976, 61.400000000000176, -13.599999999999858, -118.60000000000001, -0.09999999999999937, -105.70000000000039, -92.2000000000007, 20.000000000000014, -63.70000000000049, 61.70000000000008, -28.299999999999862, -11.199999999999934, 10.099999999999968, 60.50000000000022, 82.09999999999926, 113.59999999999988, 19.40000000000001, -119.20000000000027, 24.500000000000078, 37.10000000000025, 20.000000000000014, 33.50000000000024, 30.500000000000178, 133.3999999999999, 20.000000000000014, 11.599999999999971, 118.99999999999986, -13.599999999999904, 78.49999999999935, 20.000000000000014, -16.899999999999807, 61.40000000000016, -51.39999999999996, -42.99999999999982, 28.100000000000158, -5.500000000000018, -19.899999999999743, 35.30000000000025, -3.0999999999999757, -28.299999999999756, 100.09999999999957, 30.800000000000203, 35.300000000000175, 1.099999999999967, 20.000000000000014, 97.39999999999979, 11.599999999999968, 78.49999999999926, -34.59999999999977, -74.50000000000077, 20.000000000000014, -85.00000000000065, 42.50000000000025, 96.49999999999956, -139.6000000000007, 34.400000000000134, -78.70000000000071, 89.29999999999976, -24.099999999999746, -17.199999999999882, -93.70000000000041, -3.099999999999972, 36.20000000000008, 38.00000000000007, 11.599999999999973, -15.699999999999747, 14.599999999999966, 90.19999999999948, -28.29999999999975, 108.19999999999942, 69.4999999999998, 20.000000000000014, 20.000000000000014, 54.49999999999997, -154.3000000000005, -3.099999999999958, 15.799999999999963, 31.700000000000216, 15.799999999999946, -19.899999999999842, 104.59999999999977, 38.90000000000024, -112.29999999999998, 3.7999999999999816, 42.50000000000025, 37.10000000000026, 20.000000000000014, -291.70000000000005, 49.70000000000024, 20.000000000000014, 20.000000000000014, -38.79999999999976, 20.000000000000014, -24.099999999999838, -101.8000000000005, -47.19999999999976, 101.89999999999978, 20.000000000000014, 54.500000000000156, 16.999999999999964, 74.89999999999945, -5.199999999999937, 22.700000000000053, 15.199999999999964, -647.1999999999999, 107.29999999999976, -73.30000000000032, -390.1, -59.80000000000048, 80.89999999999999, -309.29999999999995, 12.20000000000023, -291.0000000000002, -1.0000000000000382, 5.299999999999965, 20.000000000000014, -549.6, 13.69999999999997, -383.70000000000005, -66.70000000000078, 82.99999999999966, 25.400000000000105, -238.30000000000027, -188.9, 5.299999999999965, -128.30000000000004, 61.70000000000012, 20.000000000000014, -60.99999999999991, 65.00000000000003, 20.000000000000014, 5.299999999999972, -213.6000000000003, -444.1, 59.600000000000165, 20.000000000000014, -71.49999999999994, -196.00000000000026, 20.000000000000014, 80.2999999999995, 23.900000000000148, -136.2, 17.299999999999983, 73.09999999999978, -5.1999999999999265, 46.10000000000024, 68.59999999999997, -44.49999999999978, 25.700000000000127, 18.19999999999999, 20.000000000000014, -57.40000000000023, -104.50000000000028, -11.499999999999819, 189.5, -54.10000000000006, 20.000000000000014, 20.000000000000014, -118.60000000000025, -5.1999999999999265, -32.49999999999989, 62.00000000000015, 63.80000000000021, -15.699999999999875, 59.90000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.6999999999999, -185.8000000000005, -1.3000000000000118, 72.19999999999959, 78.80000000000001, 20.000000000000014, -8.199999999999902, -241.5, -45.39999999999983, 83.89999999999988, 102.79999999999941, 20.000000000000014, 114.49999999999974, -460.8, 20.000000000000014, 70.39999999999975, 20.000000000000014, -59.200000000000145, -309.1999999999999, -257.69999999999993, 25.4000000000001, 66.49999999999996, 20.000000000000014, 99.50000000000003], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 8.0, 0.0, 52.0, 0.0, 0.0, 3.0, 15.0, 52.0, 57.0, 63.0, 24.0, 0.0, 56.0, 56.0, 26.0, 9.0, 48.0, 9.0, 0.0, 0.0, 0.0, 78.0, 57.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 4.0, 0.0, 9.0, 7.0, 3.0, 0.0, 27.0, 12.0, 0.0, 60.0, 0.0, 13.0, 19.0, 0.0, 2.0, 23.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 4.0, 50.0, 21.0, 29.0, 21.0, 0.0, 0.0, 53.0, 35.0, 30.0, 17.0, 37.0, 22.0, 64.0, 11.0, 27.0, 15.0, 0.0, 21.0, 8.0, 25.0, 0.0, 23.0, 0.0, 0.0, 7.0, 8.0, 93.0, 1.0, 2.0, 0.0, 0.0, 21.0, 0.0, 0.0, 4.0, 68.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 0.0, 1.0, 86.0, 0.0, 0.0, 14.0, 1.0, 12.0, 0.0, 7.0, 0.0, 390.0, 307.0, 145.0, 233.0, 38.0, 4.0, 108.0, 257.0, 116.0, 107.0, 7.0, 0.0, 197.0, 367.0, 332.0, 159.0, 21.0, 0.0, 172.0, 181.0, 0.0, 88.0, 17.0, 0.0, 28.0, 20.0, 13.0, 0.0, 321.0, 222.0, 0.0, 0.0, 89.0, 63.0, 0.0, 0.0, 19.0, 80.0, 21.0, 0.0, 0.0, 12.0, 35.0, 0.0, 12.0, 20.0, 19.0, 38.0, 60.0, 50.0, 0.0, 44.0, 0.0, 0.0, 81.0, 0.0, 23.0, 15.0, 18.0, 0.0, 0.0, 11.0, 0.0, 0.0, 96.0, 69.0, 14.0, 21.0, 0.0, 20.0, 58.0, 199.0, 36.0, 2.0, 0.0, 0.0, 199.0, 198.0, 0.0, 0.0, 17.0, 47.0, 219.0, 240.0, 10.0, 0.0, 20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.097635785066647, "mean_inference_ms": 2.9448646006120778, "mean_action_processing_ms": 0.44308129121504863, "mean_env_wait_ms": 0.6810591572664794, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014683008193969727, "StateBufferConnector_ms": 0.01026618480682373, "ViewRequirementAgentConnector_ms": 0.24875807762145996}, "num_episodes": 23, "episode_return_max": 195.6999999999991, "episode_return_min": -115.50000000000003, "episode_return_mean": 47.61699999999974, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 248.8143504457771, "num_env_steps_trained_throughput_per_sec": 248.8143504457771, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 14144.328, "restore_workers_time_ms": 0.03, "training_step_time_ms": 14144.245, "sample_time_ms": 2462.867, "learn_time_ms": 11661.053, "learn_throughput": 343.022, "synch_weights_time_ms": 17.165}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "c52aa_00000", "date": "2024-08-12_23-52-15", "timestamp": 1723521135, "time_this_iter_s": 16.201317071914673, "time_total_s": 264.6416394710541, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x329e23ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 264.6416394710541, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 86.175, "ram_util_percent": 83.84166666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1242752537367835, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.935413896659064, "policy_loss": -0.003918898417417295, "vf_loss": 2.93810056315528, "vf_explained_var": 0.042985039255606435, "kl": 0.009736130684260885, "entropy": 1.430749531145449, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.26635304453078085, "cur_kl_coeff": 0.056250000000000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4795644765493101, "policy_loss": -0.0023466518435814473, "vf_loss": 1.4817075313241392, "vf_explained_var": 0.004168825143228763, "kl": 0.003619509501038805, "entropy": 1.5175946774936857, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 179.39999999999944, "episode_reward_min": -115.50000000000003, "episode_reward_mean": 44.216999999999786, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -647.1999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.5, "predator_policy": 390.0}, "policy_reward_mean": {"prey_policy": -16.811500000000034, "predator_policy": 38.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [101.49999999999858, 83.4999999999991, -34.399999999999594, 35.60000000000031, 34.40000000000022, -6.399999999999666, 130.89999999999898, 66.4000000000002, 117.3999999999994, 94.09999999999854, -38.099999999999554, -14.999999999999636, 138.9999999999989, -17.199999999999598, 57.60000000000024, 17.699999999999953, -21.799999999999812, 116.19999999999982, 16.899999999999917, 137.79999999999893, 102.89999999999881, 89.49999999999885, 89.49999999999943, -63.399999999999935, 49.50000000000047, 16.899999999999935, 143.4999999999993, -36.50000000000002, 79.5999999999994, -107.70000000000036, 69.70000000000009, 9.200000000000063, 16.899999999999935, -62.00000000000087, 121.89999999999935, 86.49999999999883, 81.69999999999911, 44.90000000000038, 157.09999999999974, -85.4000000000001, 63.10000000000024, 67.89999999999935, -69.00000000000018, 32.30000000000018, 28.10000000000018, 40.60000000000018, 129.3999999999991, -74.20000000000012, -34.999999999999964, 98.69999999999904, 52.00000000000023, 38.30000000000027, -114.70000000000027, 79.5999999999999, -115.50000000000003, 100.29999999999896, -13.299999999999798, 111.39999999999914, 52.90000000000048, 59.10000000000009, 75.89999999999957, 19.600000000000104, -5.999999999999995, 179.39999999999944, 40.0000000000003, -42.79999999999971, 67.49999999999999, 66.10000000000029, 90.89999999999904, 40.0000000000003, 88.89999999999978, 105.8999999999987, 118.79999999999944, 7.299999999999928, 76.49999999999999, 122.79999999999869, 50.69999999999985, 90.39999999999858, 24.800000000000143, -107.89999999999984, 101.89999999999898, 139.49999999999966, 70.79999999999995, 75.3999999999996, 82.19999999999908, 30.300000000000214, 40.0000000000003, 40.0000000000003, 52.30000000000042, 36.60000000000024, 80.69999999999966, -30.399999999999707, 80.69999999999912, 10.400000000000073, 142.6999999999992, 1.0000000000002356, 52.20000000000043, -70.10000000000062, -3.099999999999741, 27.40000000000009], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [78.49999999999935, 20.000000000000014, -16.899999999999807, 61.40000000000016, -51.39999999999996, -42.99999999999982, 28.100000000000158, -5.500000000000018, -19.899999999999743, 35.30000000000025, -3.0999999999999757, -28.299999999999756, 100.09999999999957, 30.800000000000203, 35.300000000000175, 1.099999999999967, 20.000000000000014, 97.39999999999979, 11.599999999999968, 78.49999999999926, -34.59999999999977, -74.50000000000077, 20.000000000000014, -85.00000000000065, 42.50000000000025, 96.49999999999956, -139.6000000000007, 34.400000000000134, -78.70000000000071, 89.29999999999976, -24.099999999999746, -17.199999999999882, -93.70000000000041, -3.099999999999972, 36.20000000000008, 38.00000000000007, 11.599999999999973, -15.699999999999747, 14.599999999999966, 90.19999999999948, -28.29999999999975, 108.19999999999942, 69.4999999999998, 20.000000000000014, 20.000000000000014, 54.49999999999997, -154.3000000000005, -3.099999999999958, 15.799999999999963, 31.700000000000216, 15.799999999999946, -19.899999999999842, 104.59999999999977, 38.90000000000024, -112.29999999999998, 3.7999999999999816, 42.50000000000025, 37.10000000000026, 20.000000000000014, -291.70000000000005, 49.70000000000024, 20.000000000000014, 20.000000000000014, -38.79999999999976, 20.000000000000014, -24.099999999999838, -101.8000000000005, -47.19999999999976, 101.89999999999978, 20.000000000000014, 54.500000000000156, 16.999999999999964, 74.89999999999945, -5.199999999999937, 22.700000000000053, 15.199999999999964, -647.1999999999999, 107.29999999999976, -73.30000000000032, -390.1, -59.80000000000048, 80.89999999999999, -309.29999999999995, 12.20000000000023, -291.0000000000002, -1.0000000000000382, 5.299999999999965, 20.000000000000014, -549.6, 13.69999999999997, -383.70000000000005, -66.70000000000078, 82.99999999999966, 25.400000000000105, -238.30000000000027, -188.9, 5.299999999999965, -128.30000000000004, 61.70000000000012, 20.000000000000014, -60.99999999999991, 65.00000000000003, 20.000000000000014, 5.299999999999972, -213.6000000000003, -444.1, 59.600000000000165, 20.000000000000014, -71.49999999999994, -196.00000000000026, 20.000000000000014, 80.2999999999995, 23.900000000000148, -136.2, 17.299999999999983, 73.09999999999978, -5.1999999999999265, 46.10000000000024, 68.59999999999997, -44.49999999999978, 25.700000000000127, 18.19999999999999, 20.000000000000014, -57.40000000000023, -104.50000000000028, -11.499999999999819, 189.5, -54.10000000000006, 20.000000000000014, 20.000000000000014, -118.60000000000025, -5.1999999999999265, -32.49999999999989, 62.00000000000015, 63.80000000000021, -15.699999999999875, 59.90000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.6999999999999, -185.8000000000005, -1.3000000000000118, 72.19999999999959, 78.80000000000001, 20.000000000000014, -8.199999999999902, -241.5, -45.39999999999983, 83.89999999999988, 102.79999999999941, 20.000000000000014, 114.49999999999974, -460.8, 20.000000000000014, 70.39999999999975, 20.000000000000014, -59.200000000000145, -309.1999999999999, -257.69999999999993, 25.4000000000001, 66.49999999999996, 20.000000000000014, 99.50000000000003, 33.80000000000018, 20.000000000000014, 16.399999999999967, 47.000000000000185, 26.60000000000014, 29.600000000000126, -7.3000000000000345, -6.400000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 66.80000000000001, -47.499999999999915, -6.399999999999958, 20.000000000000014, 20.000000000000014, 43.700000000000124, 20.000000000000014, -114.4000000000005, 43.700000000000124, 20.000000000000014, -30.39999999999975, 15.799999999999963, 44.30000000000013, 85.39999999999989, -7.299999999999891, -15.699999999999754, 20.60000000000003, 11.599999999999968, -32.49999999999991, -163.60000000000036, -64.00000000000065, 20.900000000000013, 26.30000000000013, -16.899999999999743], "policy_predator_policy_reward": [3.0, 0.0, 27.0, 12.0, 0.0, 60.0, 0.0, 13.0, 19.0, 0.0, 2.0, 23.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 0.0, 4.0, 50.0, 21.0, 29.0, 21.0, 0.0, 0.0, 53.0, 35.0, 30.0, 17.0, 37.0, 22.0, 64.0, 11.0, 27.0, 15.0, 0.0, 21.0, 8.0, 25.0, 0.0, 23.0, 0.0, 0.0, 7.0, 8.0, 93.0, 1.0, 2.0, 0.0, 0.0, 21.0, 0.0, 0.0, 4.0, 68.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 0.0, 1.0, 86.0, 0.0, 0.0, 14.0, 1.0, 12.0, 0.0, 7.0, 0.0, 390.0, 307.0, 145.0, 233.0, 38.0, 4.0, 108.0, 257.0, 116.0, 107.0, 7.0, 0.0, 197.0, 367.0, 332.0, 159.0, 21.0, 0.0, 172.0, 181.0, 0.0, 88.0, 17.0, 0.0, 28.0, 20.0, 13.0, 0.0, 321.0, 222.0, 0.0, 0.0, 89.0, 63.0, 0.0, 0.0, 19.0, 80.0, 21.0, 0.0, 0.0, 12.0, 35.0, 0.0, 12.0, 20.0, 19.0, 38.0, 60.0, 50.0, 0.0, 44.0, 0.0, 0.0, 81.0, 0.0, 23.0, 15.0, 18.0, 0.0, 0.0, 11.0, 0.0, 0.0, 96.0, 69.0, 14.0, 21.0, 0.0, 20.0, 58.0, 199.0, 36.0, 2.0, 0.0, 0.0, 199.0, 198.0, 0.0, 0.0, 17.0, 47.0, 219.0, 240.0, 10.0, 0.0, 20.0, 0.0, 2.0, 15.0, 12.0, 0.0, 26.0, 0.0, 13.0, 31.0, 0.0, 0.0, 0.0, 0.0, 10.0, 23.0, 1.0, 22.0, 17.0, 0.0, 0.0, 64.0, 8.0, 9.0, 0.0, 25.0, 0.0, 13.0, 24.0, 0.0, 20.0, 0.0, 79.0, 47.0, 8.0, 32.0, 0.0, 18.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1043550107950686, "mean_inference_ms": 2.9651206235170093, "mean_action_processing_ms": 0.44519012355971177, "mean_env_wait_ms": 0.6853138700045548, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012734770774841309, "StateBufferConnector_ms": 0.009874343872070312, "ViewRequirementAgentConnector_ms": 0.23603510856628418}, "num_episodes": 18, "episode_return_max": 179.39999999999944, "episode_return_min": -115.50000000000003, "episode_return_mean": 44.216999999999786, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 184.80247500167567, "num_env_steps_trained_throughput_per_sec": 184.80247500167567, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 15076.744, "restore_workers_time_ms": 0.032, "training_step_time_ms": 15076.658, "sample_time_ms": 2535.436, "learn_time_ms": 12519.115, "learn_throughput": 319.511, "synch_weights_time_ms": 18.462}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "c52aa_00000", "date": "2024-08-12_23-52-37", "timestamp": 1723521157, "time_this_iter_s": 21.71880793571472, "time_total_s": 286.3604474067688, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 286.3604474067688, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 91.69032258064516, "ram_util_percent": 83.75806451612905}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1797950459102158, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4538340205553348, "policy_loss": -0.0019211284174440952, "vf_loss": 1.4550112057930578, "vf_explained_var": 0.12824270766248147, "kl": 0.005878120354012019, "entropy": 1.4089266440855763, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.24889431049032187, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4935161340725485, "policy_loss": -0.003072745547132202, "vf_loss": 0.49634741646479125, "vf_explained_var": 0.012356483368646531, "kl": 0.008585339030068445, "entropy": 1.4974176698891575, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 179.39999999999944, "episode_reward_min": -115.50000000000003, "episode_reward_mean": 45.027999999999786, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -647.1999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.5, "predator_policy": 390.0}, "policy_reward_mean": {"prey_policy": -14.356000000000021, "predator_policy": 36.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.899999999999917, 137.79999999999893, 102.89999999999881, 89.49999999999885, 89.49999999999943, -63.399999999999935, 49.50000000000047, 16.899999999999935, 143.4999999999993, -36.50000000000002, 79.5999999999994, -107.70000000000036, 69.70000000000009, 9.200000000000063, 16.899999999999935, -62.00000000000087, 121.89999999999935, 86.49999999999883, 81.69999999999911, 44.90000000000038, 157.09999999999974, -85.4000000000001, 63.10000000000024, 67.89999999999935, -69.00000000000018, 32.30000000000018, 28.10000000000018, 40.60000000000018, 129.3999999999991, -74.20000000000012, -34.999999999999964, 98.69999999999904, 52.00000000000023, 38.30000000000027, -114.70000000000027, 79.5999999999999, -115.50000000000003, 100.29999999999896, -13.299999999999798, 111.39999999999914, 52.90000000000048, 59.10000000000009, 75.89999999999957, 19.600000000000104, -5.999999999999995, 179.39999999999944, 40.0000000000003, -42.79999999999971, 67.49999999999999, 66.10000000000029, 90.89999999999904, 40.0000000000003, 88.89999999999978, 105.8999999999987, 118.79999999999944, 7.299999999999928, 76.49999999999999, 122.79999999999869, 50.69999999999985, 90.39999999999858, 24.800000000000143, -107.89999999999984, 101.89999999999898, 139.49999999999966, 70.79999999999995, 75.3999999999996, 82.19999999999908, 30.300000000000214, 40.0000000000003, 40.0000000000003, 52.30000000000042, 36.60000000000024, 80.69999999999966, -30.399999999999707, 80.69999999999912, 10.400000000000073, 142.6999999999992, 1.0000000000002356, 52.20000000000043, -70.10000000000062, -3.099999999999741, 27.40000000000009, 99.49999999999896, 34.50000000000022, 23.800000000000097, 42.70000000000033, 0.40000000000016456, 36.70000000000024, 115.59999999999941, 37.200000000000266, 7.400000000000091, 60.700000000000436, 105.1999999999988, 67.00000000000028, 32.10000000000018, 97.5999999999987, 26.90000000000009, -3.999999999999845, 113.99999999999902, 45.20000000000033], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999973, -15.699999999999747, 14.599999999999966, 90.19999999999948, -28.29999999999975, 108.19999999999942, 69.4999999999998, 20.000000000000014, 20.000000000000014, 54.49999999999997, -154.3000000000005, -3.099999999999958, 15.799999999999963, 31.700000000000216, 15.799999999999946, -19.899999999999842, 104.59999999999977, 38.90000000000024, -112.29999999999998, 3.7999999999999816, 42.50000000000025, 37.10000000000026, 20.000000000000014, -291.70000000000005, 49.70000000000024, 20.000000000000014, 20.000000000000014, -38.79999999999976, 20.000000000000014, -24.099999999999838, -101.8000000000005, -47.19999999999976, 101.89999999999978, 20.000000000000014, 54.500000000000156, 16.999999999999964, 74.89999999999945, -5.199999999999937, 22.700000000000053, 15.199999999999964, -647.1999999999999, 107.29999999999976, -73.30000000000032, -390.1, -59.80000000000048, 80.89999999999999, -309.29999999999995, 12.20000000000023, -291.0000000000002, -1.0000000000000382, 5.299999999999965, 20.000000000000014, -549.6, 13.69999999999997, -383.70000000000005, -66.70000000000078, 82.99999999999966, 25.400000000000105, -238.30000000000027, -188.9, 5.299999999999965, -128.30000000000004, 61.70000000000012, 20.000000000000014, -60.99999999999991, 65.00000000000003, 20.000000000000014, 5.299999999999972, -213.6000000000003, -444.1, 59.600000000000165, 20.000000000000014, -71.49999999999994, -196.00000000000026, 20.000000000000014, 80.2999999999995, 23.900000000000148, -136.2, 17.299999999999983, 73.09999999999978, -5.1999999999999265, 46.10000000000024, 68.59999999999997, -44.49999999999978, 25.700000000000127, 18.19999999999999, 20.000000000000014, -57.40000000000023, -104.50000000000028, -11.499999999999819, 189.5, -54.10000000000006, 20.000000000000014, 20.000000000000014, -118.60000000000025, -5.1999999999999265, -32.49999999999989, 62.00000000000015, 63.80000000000021, -15.699999999999875, 59.90000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.6999999999999, -185.8000000000005, -1.3000000000000118, 72.19999999999959, 78.80000000000001, 20.000000000000014, -8.199999999999902, -241.5, -45.39999999999983, 83.89999999999988, 102.79999999999941, 20.000000000000014, 114.49999999999974, -460.8, 20.000000000000014, 70.39999999999975, 20.000000000000014, -59.200000000000145, -309.1999999999999, -257.69999999999993, 25.4000000000001, 66.49999999999996, 20.000000000000014, 99.50000000000003, 33.80000000000018, 20.000000000000014, 16.399999999999967, 47.000000000000185, 26.60000000000014, 29.600000000000126, -7.3000000000000345, -6.400000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 66.80000000000001, -47.499999999999915, -6.399999999999958, 20.000000000000014, 20.000000000000014, 43.700000000000124, 20.000000000000014, -114.4000000000005, 43.700000000000124, 20.000000000000014, -30.39999999999975, 15.799999999999963, 44.30000000000013, 85.39999999999989, -7.299999999999891, -15.699999999999754, 20.60000000000003, 11.599999999999968, -32.49999999999991, -163.60000000000036, -64.00000000000065, 20.900000000000013, 26.30000000000013, -16.899999999999743, 5.299999999999965, 81.19999999999949, 9.499999999999964, 20.000000000000014, 13.699999999999939, 1.0999999999999865, 21.800000000000047, 20.900000000000027, -21.99999999999976, -13.599999999999833, 20.000000000000014, 13.699999999999967, 20.000000000000014, 95.59999999999978, 12.199999999999966, 20.000000000000014, -30.39999999999977, 0.7999999999999652, 40.700000000000216, 20.000000000000014, 31.700000000000202, 66.49999999999996, 20.000000000000014, 47.00000000000024, -4.899999999999956, 20.000000000000014, 36.20000000000026, 61.400000000000176, 24.50000000000008, -22.59999999999978, -64.0000000000007, 20.000000000000014, 20.000000000000014, 85.99999999999957, 12.49999999999997, 22.700000000000053], "policy_predator_policy_reward": [0.0, 21.0, 8.0, 25.0, 0.0, 23.0, 0.0, 0.0, 7.0, 8.0, 93.0, 1.0, 2.0, 0.0, 0.0, 21.0, 0.0, 0.0, 4.0, 68.0, 0.0, 0.0, 164.0, 0.0, 0.0, 0.0, 28.0, 0.0, 21.0, 0.0, 1.0, 86.0, 0.0, 0.0, 14.0, 1.0, 12.0, 0.0, 7.0, 0.0, 390.0, 307.0, 145.0, 233.0, 38.0, 4.0, 108.0, 257.0, 116.0, 107.0, 7.0, 0.0, 197.0, 367.0, 332.0, 159.0, 21.0, 0.0, 172.0, 181.0, 0.0, 88.0, 17.0, 0.0, 28.0, 20.0, 13.0, 0.0, 321.0, 222.0, 0.0, 0.0, 89.0, 63.0, 0.0, 0.0, 19.0, 80.0, 21.0, 0.0, 0.0, 12.0, 35.0, 0.0, 12.0, 20.0, 19.0, 38.0, 60.0, 50.0, 0.0, 44.0, 0.0, 0.0, 81.0, 0.0, 23.0, 15.0, 18.0, 0.0, 0.0, 11.0, 0.0, 0.0, 96.0, 69.0, 14.0, 21.0, 0.0, 20.0, 58.0, 199.0, 36.0, 2.0, 0.0, 0.0, 199.0, 198.0, 0.0, 0.0, 17.0, 47.0, 219.0, 240.0, 10.0, 0.0, 20.0, 0.0, 2.0, 15.0, 12.0, 0.0, 26.0, 0.0, 13.0, 31.0, 0.0, 0.0, 0.0, 0.0, 10.0, 23.0, 1.0, 22.0, 17.0, 0.0, 0.0, 64.0, 8.0, 9.0, 0.0, 25.0, 0.0, 13.0, 24.0, 0.0, 20.0, 0.0, 79.0, 47.0, 8.0, 32.0, 0.0, 18.0, 0.0, 13.0, 0.0, 5.0, 9.0, 0.0, 0.0, 0.0, 36.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 5.0, 13.0, 24.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 3.0, 14.0, 0.0, 0.0, 7.0, 18.0, 29.0, 11.0, 0.0, 8.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1143352165469056, "mean_inference_ms": 2.999038793316192, "mean_action_processing_ms": 0.4493703224206611, "mean_env_wait_ms": 0.6932045736913155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01284170150756836, "StateBufferConnector_ms": 0.00984179973602295, "ViewRequirementAgentConnector_ms": 0.26383042335510254}, "num_episodes": 18, "episode_return_max": 179.39999999999944, "episode_return_min": -115.50000000000003, "episode_return_mean": 45.027999999999786, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.23138004788737, "num_env_steps_trained_throughput_per_sec": 202.23138004788737, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 15597.163, "restore_workers_time_ms": 0.032, "training_step_time_ms": 15597.076, "sample_time_ms": 2602.325, "learn_time_ms": 12972.253, "learn_throughput": 308.35, "synch_weights_time_ms": 18.714}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "c52aa_00000", "date": "2024-08-12_23-52-57", "timestamp": 1723521177, "time_this_iter_s": 19.86444401741028, "time_total_s": 306.2248914241791, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c58b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 306.2248914241791, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 89.575, "ram_util_percent": 83.70357142857142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.117429078863096, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.35025586763387, "policy_loss": -0.0037994658798669225, "vf_loss": 1.3527636000876704, "vf_explained_var": 0.1494991907997737, "kl": 0.01020629086254753, "entropy": 1.3956142224332013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.25834830355135696, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4455785124547898, "policy_loss": -0.002507517209138583, "vf_loss": 0.4478567021544136, "vf_explained_var": 0.013802381703462551, "kl": 0.008153846487225466, "entropy": 1.5240192681393296, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 179.39999999999944, "episode_reward_min": -115.50000000000003, "episode_reward_mean": 49.17099999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -647.1999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.5, "predator_policy": 390.0}, "policy_reward_mean": {"prey_policy": -10.18450000000002, "predator_policy": 34.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [81.69999999999911, 44.90000000000038, 157.09999999999974, -85.4000000000001, 63.10000000000024, 67.89999999999935, -69.00000000000018, 32.30000000000018, 28.10000000000018, 40.60000000000018, 129.3999999999991, -74.20000000000012, -34.999999999999964, 98.69999999999904, 52.00000000000023, 38.30000000000027, -114.70000000000027, 79.5999999999999, -115.50000000000003, 100.29999999999896, -13.299999999999798, 111.39999999999914, 52.90000000000048, 59.10000000000009, 75.89999999999957, 19.600000000000104, -5.999999999999995, 179.39999999999944, 40.0000000000003, -42.79999999999971, 67.49999999999999, 66.10000000000029, 90.89999999999904, 40.0000000000003, 88.89999999999978, 105.8999999999987, 118.79999999999944, 7.299999999999928, 76.49999999999999, 122.79999999999869, 50.69999999999985, 90.39999999999858, 24.800000000000143, -107.89999999999984, 101.89999999999898, 139.49999999999966, 70.79999999999995, 75.3999999999996, 82.19999999999908, 30.300000000000214, 40.0000000000003, 40.0000000000003, 52.30000000000042, 36.60000000000024, 80.69999999999966, -30.399999999999707, 80.69999999999912, 10.400000000000073, 142.6999999999992, 1.0000000000002356, 52.20000000000043, -70.10000000000062, -3.099999999999741, 27.40000000000009, 99.49999999999896, 34.50000000000022, 23.800000000000097, 42.70000000000033, 0.40000000000016456, 36.70000000000024, 115.59999999999941, 37.200000000000266, 7.400000000000091, 60.700000000000436, 105.1999999999988, 67.00000000000028, 32.10000000000018, 97.5999999999987, 26.90000000000009, -3.999999999999845, 113.99999999999902, 45.20000000000033, 74.89999999999962, 40.0000000000003, 128.99999999999855, 72.29999999999987, 55.00000000000034, 30.10000000000015, 25.700000000000067, 67.00000000000028, 72.59999999999982, 19.19999999999996, 35.90000000000024, 37.40000000000027, 40.0000000000003, 110.69999999999868, 114.6999999999982, 40.0000000000003, 112.89999999999861, 97.59999999999852], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [74.89999999999945, -5.199999999999937, 22.700000000000053, 15.199999999999964, -647.1999999999999, 107.29999999999976, -73.30000000000032, -390.1, -59.80000000000048, 80.89999999999999, -309.29999999999995, 12.20000000000023, -291.0000000000002, -1.0000000000000382, 5.299999999999965, 20.000000000000014, -549.6, 13.69999999999997, -383.70000000000005, -66.70000000000078, 82.99999999999966, 25.400000000000105, -238.30000000000027, -188.9, 5.299999999999965, -128.30000000000004, 61.70000000000012, 20.000000000000014, -60.99999999999991, 65.00000000000003, 20.000000000000014, 5.299999999999972, -213.6000000000003, -444.1, 59.600000000000165, 20.000000000000014, -71.49999999999994, -196.00000000000026, 20.000000000000014, 80.2999999999995, 23.900000000000148, -136.2, 17.299999999999983, 73.09999999999978, -5.1999999999999265, 46.10000000000024, 68.59999999999997, -44.49999999999978, 25.700000000000127, 18.19999999999999, 20.000000000000014, -57.40000000000023, -104.50000000000028, -11.499999999999819, 189.5, -54.10000000000006, 20.000000000000014, 20.000000000000014, -118.60000000000025, -5.1999999999999265, -32.49999999999989, 62.00000000000015, 63.80000000000021, -15.699999999999875, 59.90000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.6999999999999, -185.8000000000005, -1.3000000000000118, 72.19999999999959, 78.80000000000001, 20.000000000000014, -8.199999999999902, -241.5, -45.39999999999983, 83.89999999999988, 102.79999999999941, 20.000000000000014, 114.49999999999974, -460.8, 20.000000000000014, 70.39999999999975, 20.000000000000014, -59.200000000000145, -309.1999999999999, -257.69999999999993, 25.4000000000001, 66.49999999999996, 20.000000000000014, 99.50000000000003, 33.80000000000018, 20.000000000000014, 16.399999999999967, 47.000000000000185, 26.60000000000014, 29.600000000000126, -7.3000000000000345, -6.400000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 66.80000000000001, -47.499999999999915, -6.399999999999958, 20.000000000000014, 20.000000000000014, 43.700000000000124, 20.000000000000014, -114.4000000000005, 43.700000000000124, 20.000000000000014, -30.39999999999975, 15.799999999999963, 44.30000000000013, 85.39999999999989, -7.299999999999891, -15.699999999999754, 20.60000000000003, 11.599999999999968, -32.49999999999991, -163.60000000000036, -64.00000000000065, 20.900000000000013, 26.30000000000013, -16.899999999999743, 5.299999999999965, 81.19999999999949, 9.499999999999964, 20.000000000000014, 13.699999999999939, 1.0999999999999865, 21.800000000000047, 20.900000000000027, -21.99999999999976, -13.599999999999833, 20.000000000000014, 13.699999999999967, 20.000000000000014, 95.59999999999978, 12.199999999999966, 20.000000000000014, -30.39999999999977, 0.7999999999999652, 40.700000000000216, 20.000000000000014, 31.700000000000202, 66.49999999999996, 20.000000000000014, 47.00000000000024, -4.899999999999956, 20.000000000000014, 36.20000000000026, 61.400000000000176, 24.50000000000008, -22.59999999999978, -64.0000000000007, 20.000000000000014, 20.000000000000014, 85.99999999999957, 12.49999999999997, 22.700000000000053, 52.40000000000018, 12.499999999999968, 20.000000000000014, 20.000000000000014, 67.09999999999994, 56.900000000000205, 47.30000000000022, 20.000000000000014, 16.399999999999967, 14.599999999999966, 20.000000000000014, 1.0999999999999528, 13.699999999999967, -30.99999999999976, 20.000000000000014, 47.00000000000024, 44.60000000000021, 20.000000000000014, 23.600000000000065, -27.39999999999978, -9.09999999999992, 20.000000000000014, 9.499999999999977, 5.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 88.69999999999939, 49.70000000000024, 65.00000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999935, 77.59999999999926, 20.000000000000014], "policy_predator_policy_reward": [12.0, 0.0, 7.0, 0.0, 390.0, 307.0, 145.0, 233.0, 38.0, 4.0, 108.0, 257.0, 116.0, 107.0, 7.0, 0.0, 197.0, 367.0, 332.0, 159.0, 21.0, 0.0, 172.0, 181.0, 0.0, 88.0, 17.0, 0.0, 28.0, 20.0, 13.0, 0.0, 321.0, 222.0, 0.0, 0.0, 89.0, 63.0, 0.0, 0.0, 19.0, 80.0, 21.0, 0.0, 0.0, 12.0, 35.0, 0.0, 12.0, 20.0, 19.0, 38.0, 60.0, 50.0, 0.0, 44.0, 0.0, 0.0, 81.0, 0.0, 23.0, 15.0, 18.0, 0.0, 0.0, 11.0, 0.0, 0.0, 96.0, 69.0, 14.0, 21.0, 0.0, 20.0, 58.0, 199.0, 36.0, 2.0, 0.0, 0.0, 199.0, 198.0, 0.0, 0.0, 17.0, 47.0, 219.0, 240.0, 10.0, 0.0, 20.0, 0.0, 2.0, 15.0, 12.0, 0.0, 26.0, 0.0, 13.0, 31.0, 0.0, 0.0, 0.0, 0.0, 10.0, 23.0, 1.0, 22.0, 17.0, 0.0, 0.0, 64.0, 8.0, 9.0, 0.0, 25.0, 0.0, 13.0, 24.0, 0.0, 20.0, 0.0, 79.0, 47.0, 8.0, 32.0, 0.0, 18.0, 0.0, 13.0, 0.0, 5.0, 9.0, 0.0, 0.0, 0.0, 36.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 5.0, 13.0, 24.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 3.0, 14.0, 0.0, 0.0, 7.0, 18.0, 29.0, 11.0, 0.0, 8.0, 0.0, 10.0, 4.0, 6.0, 0.0, 0.0, 0.0, 5.0, 5.0, 0.0, 24.0, 0.0, 0.0, 9.0, 17.0, 26.0, 0.0, 0.0, 8.0, 0.0, 23.0, 0.0, 11.0, 14.0, 17.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1257569520200863, "mean_inference_ms": 3.0319673866942596, "mean_action_processing_ms": 0.4532450822626316, "mean_env_wait_ms": 0.7015670145181895, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012140512466430664, "StateBufferConnector_ms": 0.01111912727355957, "ViewRequirementAgentConnector_ms": 0.281177282333374}, "num_episodes": 18, "episode_return_max": 179.39999999999944, "episode_return_min": -115.50000000000003, "episode_return_mean": 49.17099999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 249.17389528251732, "num_env_steps_trained_throughput_per_sec": 249.17389528251732, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 16059.025, "restore_workers_time_ms": 0.034, "training_step_time_ms": 16058.934, "sample_time_ms": 2666.262, "learn_time_ms": 13370.284, "learn_throughput": 299.171, "synch_weights_time_ms": 18.642}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "c52aa_00000", "date": "2024-08-12_23-53-13", "timestamp": 1723521193, "time_this_iter_s": 16.12471604347229, "time_total_s": 322.34960746765137, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c5820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 322.34960746765137, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 85.28695652173914, "ram_util_percent": 83.8}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.71690402854845, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.6001715501149496, "policy_loss": -0.0019209803215094975, "vf_loss": 3.601022939959531, "vf_explained_var": 0.12383920597651649, "kl": 0.008451044331952087, "entropy": 1.4040701678190282, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.25928972461236216, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8557739099655202, "policy_loss": -0.002322249179065385, "vf_loss": 0.8579307832809352, "vf_explained_var": 0.005847579839999083, "kl": 0.005880039651432422, "entropy": 1.498336113949932, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 179.39999999999944, "episode_reward_min": -107.89999999999984, "episode_reward_mean": 63.61299999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -460.8, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 189.5, "predator_policy": 240.0}, "policy_reward_mean": {"prey_policy": 16.816499999999998, "predator_policy": 14.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [179.39999999999944, 40.0000000000003, -42.79999999999971, 67.49999999999999, 66.10000000000029, 90.89999999999904, 40.0000000000003, 88.89999999999978, 105.8999999999987, 118.79999999999944, 7.299999999999928, 76.49999999999999, 122.79999999999869, 50.69999999999985, 90.39999999999858, 24.800000000000143, -107.89999999999984, 101.89999999999898, 139.49999999999966, 70.79999999999995, 75.3999999999996, 82.19999999999908, 30.300000000000214, 40.0000000000003, 40.0000000000003, 52.30000000000042, 36.60000000000024, 80.69999999999966, -30.399999999999707, 80.69999999999912, 10.400000000000073, 142.6999999999992, 1.0000000000002356, 52.20000000000043, -70.10000000000062, -3.099999999999741, 27.40000000000009, 99.49999999999896, 34.50000000000022, 23.800000000000097, 42.70000000000033, 0.40000000000016456, 36.70000000000024, 115.59999999999941, 37.200000000000266, 7.400000000000091, 60.700000000000436, 105.1999999999988, 67.00000000000028, 32.10000000000018, 97.5999999999987, 26.90000000000009, -3.999999999999845, 113.99999999999902, 45.20000000000033, 74.89999999999962, 40.0000000000003, 128.99999999999855, 72.29999999999987, 55.00000000000034, 30.10000000000015, 25.700000000000067, 67.00000000000028, 72.59999999999982, 19.19999999999996, 35.90000000000024, 37.40000000000027, 40.0000000000003, 110.69999999999868, 114.6999999999982, 40.0000000000003, 112.89999999999861, 97.59999999999852, 13.599999999999941, 108.39999999999876, 39.7000000000003, 34.40000000000022, 163.79999999999944, 47.20000000000029, 137.29999999999902, 40.0000000000003, 155.2999999999989, 108.39999999999824, 44.50000000000029, 5.799999999999949, 60.500000000000455, 108.39999999999856, 96.49999999999852, 46.30000000000029, 149.79999999999959, 131.80000000000004, 85.49999999999895, 107.69999999999888, 101.29999999999907, 49.60000000000046, 69.70000000000006, 71.69999999999976, 107.89999999999885, 46.30000000000041, 132.59999999999968], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [189.5, -54.10000000000006, 20.000000000000014, 20.000000000000014, -118.60000000000025, -5.1999999999999265, -32.49999999999989, 62.00000000000015, 63.80000000000021, -15.699999999999875, 59.90000000000016, 20.000000000000014, 20.000000000000014, 20.000000000000014, 109.6999999999999, -185.8000000000005, -1.3000000000000118, 72.19999999999959, 78.80000000000001, 20.000000000000014, -8.199999999999902, -241.5, -45.39999999999983, 83.89999999999988, 102.79999999999941, 20.000000000000014, 114.49999999999974, -460.8, 20.000000000000014, 70.39999999999975, 20.000000000000014, -59.200000000000145, -309.1999999999999, -257.69999999999993, 25.4000000000001, 66.49999999999996, 20.000000000000014, 99.50000000000003, 33.80000000000018, 20.000000000000014, 16.399999999999967, 47.000000000000185, 26.60000000000014, 29.600000000000126, -7.3000000000000345, -6.400000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 66.80000000000001, -47.499999999999915, -6.399999999999958, 20.000000000000014, 20.000000000000014, 43.700000000000124, 20.000000000000014, -114.4000000000005, 43.700000000000124, 20.000000000000014, -30.39999999999975, 15.799999999999963, 44.30000000000013, 85.39999999999989, -7.299999999999891, -15.699999999999754, 20.60000000000003, 11.599999999999968, -32.49999999999991, -163.60000000000036, -64.00000000000065, 20.900000000000013, 26.30000000000013, -16.899999999999743, 5.299999999999965, 81.19999999999949, 9.499999999999964, 20.000000000000014, 13.699999999999939, 1.0999999999999865, 21.800000000000047, 20.900000000000027, -21.99999999999976, -13.599999999999833, 20.000000000000014, 13.699999999999967, 20.000000000000014, 95.59999999999978, 12.199999999999966, 20.000000000000014, -30.39999999999977, 0.7999999999999652, 40.700000000000216, 20.000000000000014, 31.700000000000202, 66.49999999999996, 20.000000000000014, 47.00000000000024, -4.899999999999956, 20.000000000000014, 36.20000000000026, 61.400000000000176, 24.50000000000008, -22.59999999999978, -64.0000000000007, 20.000000000000014, 20.000000000000014, 85.99999999999957, 12.49999999999997, 22.700000000000053, 52.40000000000018, 12.499999999999968, 20.000000000000014, 20.000000000000014, 67.09999999999994, 56.900000000000205, 47.30000000000022, 20.000000000000014, 16.399999999999967, 14.599999999999966, 20.000000000000014, 1.0999999999999528, 13.699999999999967, -30.99999999999976, 20.000000000000014, 47.00000000000024, 44.60000000000021, 20.000000000000014, 23.600000000000065, -27.39999999999978, -9.09999999999992, 20.000000000000014, 9.499999999999977, 5.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 88.69999999999939, 49.70000000000024, 65.00000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999935, 77.59999999999926, 20.000000000000014, -17.79999999999982, 7.399999999999967, 20.000000000000014, 88.39999999999941, 23.000000000000078, -7.299999999999891, 29.000000000000163, -34.59999999999975, 70.09999999999984, 82.69999999999999, 20.000000000000014, 27.20000000000003, 86.89999999999965, 25.400000000000126, 20.000000000000014, 20.000000000000014, 53.90000000000013, 79.39999999999947, 46.10000000000023, 62.30000000000022, 24.50000000000001, 20.000000000000014, -36.699999999999754, -8.499999999999979, 39.50000000000022, 20.000000000000014, 87.49999999999929, 20.900000000000013, 25.10000000000012, 61.40000000000021, 26.300000000000004, 20.000000000000014, 96.49999999999997, 35.30000000000025, 42.49999999999998, 89.30000000000015, 67.69999999999992, 15.799999999999963, 45.500000000000234, 30.200000000000124, 60.80000000000017, 18.499999999999993, 11.599999999999966, 32.00000000000022, 27.200000000000003, 42.50000000000022, 91.99999999999935, -124.30000000000061, 70.39999999999968, 3.499999999999978, 26.30000000000012, 20.000000000000014, 20.000000000000014, 107.6], "policy_predator_policy_reward": [0.0, 44.0, 0.0, 0.0, 81.0, 0.0, 23.0, 15.0, 18.0, 0.0, 0.0, 11.0, 0.0, 0.0, 96.0, 69.0, 14.0, 21.0, 0.0, 20.0, 58.0, 199.0, 36.0, 2.0, 0.0, 0.0, 199.0, 198.0, 0.0, 0.0, 17.0, 47.0, 219.0, 240.0, 10.0, 0.0, 20.0, 0.0, 2.0, 15.0, 12.0, 0.0, 26.0, 0.0, 13.0, 31.0, 0.0, 0.0, 0.0, 0.0, 10.0, 23.0, 1.0, 22.0, 17.0, 0.0, 0.0, 64.0, 8.0, 9.0, 0.0, 25.0, 0.0, 13.0, 24.0, 0.0, 20.0, 0.0, 79.0, 47.0, 8.0, 32.0, 0.0, 18.0, 0.0, 13.0, 0.0, 5.0, 9.0, 0.0, 0.0, 0.0, 36.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 5.0, 13.0, 24.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 3.0, 14.0, 0.0, 0.0, 7.0, 18.0, 29.0, 11.0, 0.0, 8.0, 0.0, 10.0, 4.0, 6.0, 0.0, 0.0, 0.0, 5.0, 5.0, 0.0, 24.0, 0.0, 0.0, 9.0, 17.0, 26.0, 0.0, 0.0, 8.0, 0.0, 23.0, 0.0, 11.0, 14.0, 17.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 24.0, 0.0, 14.0, 26.0, 0.0, 11.0, 0.0, 0.0, 3.0, 22.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 29.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 2.0, 19.0, 13.0, 5.0, 17.0, 4.0, 2.0, 0.0, 0.0, 51.0, 53.0, 1.0, 33.0, 0.0, 0.0, 5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1291226001088905, "mean_inference_ms": 3.042593955434084, "mean_action_processing_ms": 0.45764288468134784, "mean_env_wait_ms": 0.7066417715925176, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012077927589416504, "StateBufferConnector_ms": 0.011646866798400879, "ViewRequirementAgentConnector_ms": 0.27523088455200195}, "num_episodes": 27, "episode_return_max": 179.39999999999944, "episode_return_min": -107.89999999999984, "episode_return_mean": 63.61299999999974, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 254.20648203789244, "num_env_steps_trained_throughput_per_sec": 254.20648203789244, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 16368.054, "restore_workers_time_ms": 0.035, "training_step_time_ms": 16367.963, "sample_time_ms": 2747.923, "learn_time_ms": 13596.036, "learn_throughput": 294.203, "synch_weights_time_ms": 19.795}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "c52aa_00000", "date": "2024-08-12_23-53-29", "timestamp": 1723521209, "time_this_iter_s": 15.816922187805176, "time_total_s": 338.16652965545654, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87e940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 338.16652965545654, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 82.66363636363636, "ram_util_percent": 83.74545454545455}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.325592226688824, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9858401990441417, "policy_loss": -0.0024039198570544756, "vf_loss": 2.9869008849537564, "vf_explained_var": 0.08916146304241564, "kl": 0.010613203295066811, "entropy": 1.3864372824234936, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2725615723462647, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2427111754657099, "policy_loss": -0.0027131676454609506, "vf_loss": 1.245082815093969, "vf_explained_var": 0.003869000723753026, "kl": 0.012143206245808556, "entropy": 1.4333549264246825, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 163.79999999999944, "episode_reward_min": -70.10000000000062, "episode_reward_mean": 66.19699999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -163.60000000000036, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 119.89999999999955, "predator_policy": 79.0}, "policy_reward_mean": {"prey_policy": 24.5885, "predator_policy": 8.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [139.49999999999966, 70.79999999999995, 75.3999999999996, 82.19999999999908, 30.300000000000214, 40.0000000000003, 40.0000000000003, 52.30000000000042, 36.60000000000024, 80.69999999999966, -30.399999999999707, 80.69999999999912, 10.400000000000073, 142.6999999999992, 1.0000000000002356, 52.20000000000043, -70.10000000000062, -3.099999999999741, 27.40000000000009, 99.49999999999896, 34.50000000000022, 23.800000000000097, 42.70000000000033, 0.40000000000016456, 36.70000000000024, 115.59999999999941, 37.200000000000266, 7.400000000000091, 60.700000000000436, 105.1999999999988, 67.00000000000028, 32.10000000000018, 97.5999999999987, 26.90000000000009, -3.999999999999845, 113.99999999999902, 45.20000000000033, 74.89999999999962, 40.0000000000003, 128.99999999999855, 72.29999999999987, 55.00000000000034, 30.10000000000015, 25.700000000000067, 67.00000000000028, 72.59999999999982, 19.19999999999996, 35.90000000000024, 37.40000000000027, 40.0000000000003, 110.69999999999868, 114.6999999999982, 40.0000000000003, 112.89999999999861, 97.59999999999852, 13.599999999999941, 108.39999999999876, 39.7000000000003, 34.40000000000022, 163.79999999999944, 47.20000000000029, 137.29999999999902, 40.0000000000003, 155.2999999999989, 108.39999999999824, 44.50000000000029, 5.799999999999949, 60.500000000000455, 108.39999999999856, 96.49999999999852, 46.30000000000029, 149.79999999999959, 131.80000000000004, 85.49999999999895, 107.69999999999888, 101.29999999999907, 49.60000000000046, 69.70000000000006, 71.69999999999976, 107.89999999999885, 46.30000000000041, 132.59999999999968, 92.39999999999992, 128.79999999999956, 142.89999999999884, 47.80000000000043, 47.200000000000415, 109.29999999999914, 21.09999999999999, 73.99999999999987, 44.50000000000038, 40.0000000000003, 62.50000000000046, 43.40000000000033, 92.8000000000001, 16.899999999999928, 68.40000000000015, 147.19999999999877, 95.49999999999956, 104.89999999999941], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 99.50000000000003, 33.80000000000018, 20.000000000000014, 16.399999999999967, 47.000000000000185, 26.60000000000014, 29.600000000000126, -7.3000000000000345, -6.400000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 66.80000000000001, -47.499999999999915, -6.399999999999958, 20.000000000000014, 20.000000000000014, 43.700000000000124, 20.000000000000014, -114.4000000000005, 43.700000000000124, 20.000000000000014, -30.39999999999975, 15.799999999999963, 44.30000000000013, 85.39999999999989, -7.299999999999891, -15.699999999999754, 20.60000000000003, 11.599999999999968, -32.49999999999991, -163.60000000000036, -64.00000000000065, 20.900000000000013, 26.30000000000013, -16.899999999999743, 5.299999999999965, 81.19999999999949, 9.499999999999964, 20.000000000000014, 13.699999999999939, 1.0999999999999865, 21.800000000000047, 20.900000000000027, -21.99999999999976, -13.599999999999833, 20.000000000000014, 13.699999999999967, 20.000000000000014, 95.59999999999978, 12.199999999999966, 20.000000000000014, -30.39999999999977, 0.7999999999999652, 40.700000000000216, 20.000000000000014, 31.700000000000202, 66.49999999999996, 20.000000000000014, 47.00000000000024, -4.899999999999956, 20.000000000000014, 36.20000000000026, 61.400000000000176, 24.50000000000008, -22.59999999999978, -64.0000000000007, 20.000000000000014, 20.000000000000014, 85.99999999999957, 12.49999999999997, 22.700000000000053, 52.40000000000018, 12.499999999999968, 20.000000000000014, 20.000000000000014, 67.09999999999994, 56.900000000000205, 47.30000000000022, 20.000000000000014, 16.399999999999967, 14.599999999999966, 20.000000000000014, 1.0999999999999528, 13.699999999999967, -30.99999999999976, 20.000000000000014, 47.00000000000024, 44.60000000000021, 20.000000000000014, 23.600000000000065, -27.39999999999978, -9.09999999999992, 20.000000000000014, 9.499999999999977, 5.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 88.69999999999939, 49.70000000000024, 65.00000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999935, 77.59999999999926, 20.000000000000014, -17.79999999999982, 7.399999999999967, 20.000000000000014, 88.39999999999941, 23.000000000000078, -7.299999999999891, 29.000000000000163, -34.59999999999975, 70.09999999999984, 82.69999999999999, 20.000000000000014, 27.20000000000003, 86.89999999999965, 25.400000000000126, 20.000000000000014, 20.000000000000014, 53.90000000000013, 79.39999999999947, 46.10000000000023, 62.30000000000022, 24.50000000000001, 20.000000000000014, -36.699999999999754, -8.499999999999979, 39.50000000000022, 20.000000000000014, 87.49999999999929, 20.900000000000013, 25.10000000000012, 61.40000000000021, 26.300000000000004, 20.000000000000014, 96.49999999999997, 35.30000000000025, 42.49999999999998, 89.30000000000015, 67.69999999999992, 15.799999999999963, 45.500000000000234, 30.200000000000124, 60.80000000000017, 18.499999999999993, 11.599999999999966, 32.00000000000022, 27.200000000000003, 42.50000000000022, 91.99999999999935, -124.30000000000061, 70.39999999999968, 3.499999999999978, 26.30000000000012, 20.000000000000014, 20.000000000000014, 107.6, -1.0000000000000027, 13.400000000000055, 20.000000000000014, 102.79999999999987, 119.89999999999955, 20.000000000000014, 21.80000000000004, 20.000000000000014, 27.200000000000134, 20.000000000000014, 20.000000000000014, 89.29999999999963, -2.1999999999999926, 5.299999999999965, 22.400000000000087, 5.599999999999984, 20.90000000000003, 23.600000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000022, -13.60000000000015, 20.000000000000014, 44.30000000000019, -5.499999999999972, -24.099999999999753, 20.000000000000014, 37.4000000000002, 20.000000000000014, 52.40000000000022, 90.7999999999994, 20.000000000000014, 69.49999999999997, 106.99999999999973, -51.10000000000002], "policy_predator_policy_reward": [20.0, 0.0, 2.0, 15.0, 12.0, 0.0, 26.0, 0.0, 13.0, 31.0, 0.0, 0.0, 0.0, 0.0, 10.0, 23.0, 1.0, 22.0, 17.0, 0.0, 0.0, 64.0, 8.0, 9.0, 0.0, 25.0, 0.0, 13.0, 24.0, 0.0, 20.0, 0.0, 79.0, 47.0, 8.0, 32.0, 0.0, 18.0, 0.0, 13.0, 0.0, 5.0, 9.0, 0.0, 0.0, 0.0, 36.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 5.0, 13.0, 24.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 3.0, 14.0, 0.0, 0.0, 7.0, 18.0, 29.0, 11.0, 0.0, 8.0, 0.0, 10.0, 4.0, 6.0, 0.0, 0.0, 0.0, 5.0, 5.0, 0.0, 24.0, 0.0, 0.0, 9.0, 17.0, 26.0, 0.0, 0.0, 8.0, 0.0, 23.0, 0.0, 11.0, 14.0, 17.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 24.0, 0.0, 14.0, 26.0, 0.0, 11.0, 0.0, 0.0, 3.0, 22.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 29.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 2.0, 19.0, 13.0, 5.0, 17.0, 4.0, 2.0, 0.0, 0.0, 51.0, 53.0, 1.0, 33.0, 0.0, 0.0, 5.0, 0.0, 39.0, 41.0, 0.0, 6.0, 0.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 37.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 20.0, 29.0, 25.0, 0.0, 21.0, 0.0, 11.0, 0.0, 4.0, 6.0, 0.0, 36.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1315483929818961, "mean_inference_ms": 3.0462334659549826, "mean_action_processing_ms": 0.45753810193255257, "mean_env_wait_ms": 0.7078364058130328, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00818336009979248, "StateBufferConnector_ms": 0.0057947635650634766, "ViewRequirementAgentConnector_ms": 0.2189192771911621}, "num_episodes": 18, "episode_return_max": 163.79999999999944, "episode_return_min": -70.10000000000062, "episode_return_mean": 66.19699999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 149.43828114110232, "num_env_steps_trained_throughput_per_sec": 149.43828114110232, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 17791.447, "restore_workers_time_ms": 0.035, "training_step_time_ms": 17791.358, "sample_time_ms": 2761.656, "learn_time_ms": 15003.826, "learn_throughput": 266.599, "synch_weights_time_ms": 21.489}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "c52aa_00000", "date": "2024-08-12_23-53-56", "timestamp": 1723521236, "time_this_iter_s": 26.911176204681396, "time_total_s": 365.07770586013794, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9bcc10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 365.07770586013794, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 95.61052631578947, "ram_util_percent": 83.46052631578948}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3638206541538238, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.88845018741315, "policy_loss": -0.0021160813225876715, "vf_loss": 1.8892765911798628, "vf_explained_var": 0.11156905022247758, "kl": 0.010190037458348941, "entropy": 1.3815337765153755, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2912057873393808, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.419663822784941, "policy_loss": -0.0036234398652114485, "vf_loss": 0.42295785179305034, "vf_explained_var": 0.003638308041940921, "kl": 0.011712412143950668, "entropy": 1.4253889597912945, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 163.79999999999944, "episode_reward_min": -3.999999999999845, "episode_reward_mean": 67.86599999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -124.30000000000061, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 119.89999999999955, "predator_policy": 81.0}, "policy_reward_mean": {"prey_policy": 26.528000000000002, "predator_policy": 7.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [27.40000000000009, 99.49999999999896, 34.50000000000022, 23.800000000000097, 42.70000000000033, 0.40000000000016456, 36.70000000000024, 115.59999999999941, 37.200000000000266, 7.400000000000091, 60.700000000000436, 105.1999999999988, 67.00000000000028, 32.10000000000018, 97.5999999999987, 26.90000000000009, -3.999999999999845, 113.99999999999902, 45.20000000000033, 74.89999999999962, 40.0000000000003, 128.99999999999855, 72.29999999999987, 55.00000000000034, 30.10000000000015, 25.700000000000067, 67.00000000000028, 72.59999999999982, 19.19999999999996, 35.90000000000024, 37.40000000000027, 40.0000000000003, 110.69999999999868, 114.6999999999982, 40.0000000000003, 112.89999999999861, 97.59999999999852, 13.599999999999941, 108.39999999999876, 39.7000000000003, 34.40000000000022, 163.79999999999944, 47.20000000000029, 137.29999999999902, 40.0000000000003, 155.2999999999989, 108.39999999999824, 44.50000000000029, 5.799999999999949, 60.500000000000455, 108.39999999999856, 96.49999999999852, 46.30000000000029, 149.79999999999959, 131.80000000000004, 85.49999999999895, 107.69999999999888, 101.29999999999907, 49.60000000000046, 69.70000000000006, 71.69999999999976, 107.89999999999885, 46.30000000000041, 132.59999999999968, 92.39999999999992, 128.79999999999956, 142.89999999999884, 47.80000000000043, 47.200000000000415, 109.29999999999914, 21.09999999999999, 73.99999999999987, 44.50000000000038, 40.0000000000003, 62.50000000000046, 43.40000000000033, 92.8000000000001, 16.899999999999928, 68.40000000000015, 147.19999999999877, 95.49999999999956, 104.89999999999941, 51.300000000000175, 0.4000000000002356, 159.399999999999, 93.09999999999906, 40.0000000000003, 120.99999999999885, 9.600000000000204, 20.299999999999983, 77.1999999999994, 43.90000000000037, 84.3999999999994, 49.90000000000043, 59.800000000000416, 40.0000000000003, 49.00000000000039, 40.0000000000003, 37.5000000000002, 21.30000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [26.30000000000013, -16.899999999999743, 5.299999999999965, 81.19999999999949, 9.499999999999964, 20.000000000000014, 13.699999999999939, 1.0999999999999865, 21.800000000000047, 20.900000000000027, -21.99999999999976, -13.599999999999833, 20.000000000000014, 13.699999999999967, 20.000000000000014, 95.59999999999978, 12.199999999999966, 20.000000000000014, -30.39999999999977, 0.7999999999999652, 40.700000000000216, 20.000000000000014, 31.700000000000202, 66.49999999999996, 20.000000000000014, 47.00000000000024, -4.899999999999956, 20.000000000000014, 36.20000000000026, 61.400000000000176, 24.50000000000008, -22.59999999999978, -64.0000000000007, 20.000000000000014, 20.000000000000014, 85.99999999999957, 12.49999999999997, 22.700000000000053, 52.40000000000018, 12.499999999999968, 20.000000000000014, 20.000000000000014, 67.09999999999994, 56.900000000000205, 47.30000000000022, 20.000000000000014, 16.399999999999967, 14.599999999999966, 20.000000000000014, 1.0999999999999528, 13.699999999999967, -30.99999999999976, 20.000000000000014, 47.00000000000024, 44.60000000000021, 20.000000000000014, 23.600000000000065, -27.39999999999978, -9.09999999999992, 20.000000000000014, 9.499999999999977, 5.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 88.69999999999939, 49.70000000000024, 65.00000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999935, 77.59999999999926, 20.000000000000014, -17.79999999999982, 7.399999999999967, 20.000000000000014, 88.39999999999941, 23.000000000000078, -7.299999999999891, 29.000000000000163, -34.59999999999975, 70.09999999999984, 82.69999999999999, 20.000000000000014, 27.20000000000003, 86.89999999999965, 25.400000000000126, 20.000000000000014, 20.000000000000014, 53.90000000000013, 79.39999999999947, 46.10000000000023, 62.30000000000022, 24.50000000000001, 20.000000000000014, -36.699999999999754, -8.499999999999979, 39.50000000000022, 20.000000000000014, 87.49999999999929, 20.900000000000013, 25.10000000000012, 61.40000000000021, 26.300000000000004, 20.000000000000014, 96.49999999999997, 35.30000000000025, 42.49999999999998, 89.30000000000015, 67.69999999999992, 15.799999999999963, 45.500000000000234, 30.200000000000124, 60.80000000000017, 18.499999999999993, 11.599999999999966, 32.00000000000022, 27.200000000000003, 42.50000000000022, 91.99999999999935, -124.30000000000061, 70.39999999999968, 3.499999999999978, 26.30000000000012, 20.000000000000014, 20.000000000000014, 107.6, -1.0000000000000027, 13.400000000000055, 20.000000000000014, 102.79999999999987, 119.89999999999955, 20.000000000000014, 21.80000000000004, 20.000000000000014, 27.200000000000134, 20.000000000000014, 20.000000000000014, 89.29999999999963, -2.1999999999999926, 5.299999999999965, 22.400000000000087, 5.599999999999984, 20.90000000000003, 23.600000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000022, -13.60000000000015, 20.000000000000014, 44.30000000000019, -5.499999999999972, -24.099999999999753, 20.000000000000014, 37.4000000000002, 20.000000000000014, 52.40000000000022, 90.7999999999994, 20.000000000000014, 69.49999999999997, 106.99999999999973, -51.10000000000002, -3.099999999999958, 25.400000000000105, -32.49999999999976, -3.099999999999958, 62.90000000000018, 72.49999999999974, 73.09999999999954, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.99999999999977, 20.000000000000014, -117.40000000000018, 20.000000000000014, -7.299999999999894, 11.599999999999964, 27.20000000000013, 20.000000000000014, 11.899999999999974, 20.000000000000014, 36.2000000000002, 36.200000000000074, 26.30000000000013, 23.60000000000007, 39.8000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.000000000000178, 20.000000000000014, 20.000000000000014, 20.000000000000014, 0.5000000000000295, 20.000000000000014, -15.699999999999768, 20.000000000000014], "policy_predator_policy_reward": [0.0, 18.0, 0.0, 13.0, 0.0, 5.0, 9.0, 0.0, 0.0, 0.0, 36.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 5.0, 13.0, 24.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 3.0, 14.0, 0.0, 0.0, 7.0, 18.0, 29.0, 11.0, 0.0, 8.0, 0.0, 10.0, 4.0, 6.0, 0.0, 0.0, 0.0, 5.0, 5.0, 0.0, 24.0, 0.0, 0.0, 9.0, 17.0, 26.0, 0.0, 0.0, 8.0, 0.0, 23.0, 0.0, 11.0, 14.0, 17.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 24.0, 0.0, 14.0, 26.0, 0.0, 11.0, 0.0, 0.0, 3.0, 22.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 29.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 2.0, 19.0, 13.0, 5.0, 17.0, 4.0, 2.0, 0.0, 0.0, 51.0, 53.0, 1.0, 33.0, 0.0, 0.0, 5.0, 0.0, 39.0, 41.0, 0.0, 6.0, 0.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 37.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 20.0, 29.0, 25.0, 0.0, 21.0, 0.0, 11.0, 0.0, 4.0, 6.0, 0.0, 36.0, 13.0, 29.0, 0.0, 11.0, 25.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 81.0, 26.0, 0.0, 16.0, 0.0, 30.0, 12.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1301538751455005, "mean_inference_ms": 3.0439804847050094, "mean_action_processing_ms": 0.4581866647217235, "mean_env_wait_ms": 0.7080327127508074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008930325508117676, "StateBufferConnector_ms": 0.005941987037658691, "ViewRequirementAgentConnector_ms": 0.22881460189819336}, "num_episodes": 18, "episode_return_max": 163.79999999999944, "episode_return_min": -3.999999999999845, "episode_return_mean": 67.86599999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 231.64805799287004, "num_env_steps_trained_throughput_per_sec": 231.64805799287004, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 18162.516, "restore_workers_time_ms": 0.035, "training_step_time_ms": 18162.426, "sample_time_ms": 2700.183, "learn_time_ms": 15437.93, "learn_throughput": 259.102, "synch_weights_time_ms": 20.375}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "c52aa_00000", "date": "2024-08-12_23-54-14", "timestamp": 1723521254, "time_this_iter_s": 17.311551809310913, "time_total_s": 382.38925766944885, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9bcdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 382.38925766944885, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 82.69599999999998, "ram_util_percent": 83.06800000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.198619534217176, "cur_kl_coeff": 0.12656249999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.582889717344254, "policy_loss": -0.007161130312652815, "vf_loss": 3.5872901389207787, "vf_explained_var": 0.07149727215211858, "kl": 0.021813002566783153, "entropy": 1.3338204693541955, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27433187960001526, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.036787251599882, "policy_loss": -0.005186840143946625, "vf_loss": 1.0415464184586964, "vf_explained_var": 0.0014892872048433495, "kl": 0.01520623196912804, "entropy": 1.4844612746011643, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 198.79999999999959, "episode_reward_min": 0.4000000000002356, "episode_reward_mean": 72.00399999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -124.30000000000061, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 185.6, "predator_policy": 81.0}, "policy_reward_mean": {"prey_policy": 27.781999999999993, "predator_policy": 8.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.20000000000033, 74.89999999999962, 40.0000000000003, 128.99999999999855, 72.29999999999987, 55.00000000000034, 30.10000000000015, 25.700000000000067, 67.00000000000028, 72.59999999999982, 19.19999999999996, 35.90000000000024, 37.40000000000027, 40.0000000000003, 110.69999999999868, 114.6999999999982, 40.0000000000003, 112.89999999999861, 97.59999999999852, 13.599999999999941, 108.39999999999876, 39.7000000000003, 34.40000000000022, 163.79999999999944, 47.20000000000029, 137.29999999999902, 40.0000000000003, 155.2999999999989, 108.39999999999824, 44.50000000000029, 5.799999999999949, 60.500000000000455, 108.39999999999856, 96.49999999999852, 46.30000000000029, 149.79999999999959, 131.80000000000004, 85.49999999999895, 107.69999999999888, 101.29999999999907, 49.60000000000046, 69.70000000000006, 71.69999999999976, 107.89999999999885, 46.30000000000041, 132.59999999999968, 92.39999999999992, 128.79999999999956, 142.89999999999884, 47.80000000000043, 47.200000000000415, 109.29999999999914, 21.09999999999999, 73.99999999999987, 44.50000000000038, 40.0000000000003, 62.50000000000046, 43.40000000000033, 92.8000000000001, 16.899999999999928, 68.40000000000015, 147.19999999999877, 95.49999999999956, 104.89999999999941, 51.300000000000175, 0.4000000000002356, 159.399999999999, 93.09999999999906, 40.0000000000003, 120.99999999999885, 9.600000000000204, 20.299999999999983, 77.1999999999994, 43.90000000000037, 84.3999999999994, 49.90000000000043, 59.800000000000416, 40.0000000000003, 49.00000000000039, 40.0000000000003, 37.5000000000002, 21.30000000000003, 108.79999999999981, 67.10000000000021, 27.20000000000007, 198.79999999999959, 52.60000000000048, 72.10000000000018, 47.0000000000001, 40.0000000000003, 35.600000000000236, 34.50000000000022, 30.000000000000398, 49.00000000000041, 64.30000000000048, 145.19999999999857, 108.39999999999887, 43.10000000000021, 46.60000000000041, 168.1999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [12.49999999999997, 22.700000000000053, 52.40000000000018, 12.499999999999968, 20.000000000000014, 20.000000000000014, 67.09999999999994, 56.900000000000205, 47.30000000000022, 20.000000000000014, 16.399999999999967, 14.599999999999966, 20.000000000000014, 1.0999999999999528, 13.699999999999967, -30.99999999999976, 20.000000000000014, 47.00000000000024, 44.60000000000021, 20.000000000000014, 23.600000000000065, -27.39999999999978, -9.09999999999992, 20.000000000000014, 9.499999999999977, 5.899999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 88.69999999999939, 49.70000000000024, 65.00000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 92.89999999999935, 77.59999999999926, 20.000000000000014, -17.79999999999982, 7.399999999999967, 20.000000000000014, 88.39999999999941, 23.000000000000078, -7.299999999999891, 29.000000000000163, -34.59999999999975, 70.09999999999984, 82.69999999999999, 20.000000000000014, 27.20000000000003, 86.89999999999965, 25.400000000000126, 20.000000000000014, 20.000000000000014, 53.90000000000013, 79.39999999999947, 46.10000000000023, 62.30000000000022, 24.50000000000001, 20.000000000000014, -36.699999999999754, -8.499999999999979, 39.50000000000022, 20.000000000000014, 87.49999999999929, 20.900000000000013, 25.10000000000012, 61.40000000000021, 26.300000000000004, 20.000000000000014, 96.49999999999997, 35.30000000000025, 42.49999999999998, 89.30000000000015, 67.69999999999992, 15.799999999999963, 45.500000000000234, 30.200000000000124, 60.80000000000017, 18.499999999999993, 11.599999999999966, 32.00000000000022, 27.200000000000003, 42.50000000000022, 91.99999999999935, -124.30000000000061, 70.39999999999968, 3.499999999999978, 26.30000000000012, 20.000000000000014, 20.000000000000014, 107.6, -1.0000000000000027, 13.400000000000055, 20.000000000000014, 102.79999999999987, 119.89999999999955, 20.000000000000014, 21.80000000000004, 20.000000000000014, 27.200000000000134, 20.000000000000014, 20.000000000000014, 89.29999999999963, -2.1999999999999926, 5.299999999999965, 22.400000000000087, 5.599999999999984, 20.90000000000003, 23.600000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000022, -13.60000000000015, 20.000000000000014, 44.30000000000019, -5.499999999999972, -24.099999999999753, 20.000000000000014, 37.4000000000002, 20.000000000000014, 52.40000000000022, 90.7999999999994, 20.000000000000014, 69.49999999999997, 106.99999999999973, -51.10000000000002, -3.099999999999958, 25.400000000000105, -32.49999999999976, -3.099999999999958, 62.90000000000018, 72.49999999999974, 73.09999999999954, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.99999999999977, 20.000000000000014, -117.40000000000018, 20.000000000000014, -7.299999999999894, 11.599999999999964, 27.20000000000013, 20.000000000000014, 11.899999999999974, 20.000000000000014, 36.2000000000002, 36.200000000000074, 26.30000000000013, 23.60000000000007, 39.8000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.000000000000178, 20.000000000000014, 20.000000000000014, 20.000000000000014, 0.5000000000000295, 20.000000000000014, -15.699999999999768, 20.000000000000014, 24.500000000000085, 59.30000000000008, 51.50000000000002, 11.599999999999975, 23.90000000000005, -15.699999999999754, 103.39999999999998, 88.39999999999952, 32.60000000000023, 20.000000000000014, -116.20000000000022, 44.300000000000146, 1.0999999999999865, 35.89999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 9.499999999999964, 20.000000000000014, -20.199999999999747, 30.200000000000124, 20.000000000000014, 29.000000000000178, 20.000000000000014, 44.300000000000246, 82.9999999999994, 57.2000000000002, 77.59999999999943, 30.800000000000132, -89.50000000000074, 53.600000000000094, 14.599999999999968, 20.000000000000014, -69.40000000000049, 185.6], "policy_predator_policy_reward": [0.0, 10.0, 4.0, 6.0, 0.0, 0.0, 0.0, 5.0, 5.0, 0.0, 24.0, 0.0, 0.0, 9.0, 17.0, 26.0, 0.0, 0.0, 8.0, 0.0, 23.0, 0.0, 11.0, 14.0, 17.0, 5.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 0.0, 24.0, 0.0, 14.0, 26.0, 0.0, 11.0, 0.0, 0.0, 3.0, 22.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 29.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 2.0, 19.0, 13.0, 5.0, 17.0, 4.0, 2.0, 0.0, 0.0, 51.0, 53.0, 1.0, 33.0, 0.0, 0.0, 5.0, 0.0, 39.0, 41.0, 0.0, 6.0, 0.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 37.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 20.0, 29.0, 25.0, 0.0, 21.0, 0.0, 11.0, 0.0, 4.0, 6.0, 0.0, 36.0, 13.0, 29.0, 0.0, 11.0, 25.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 81.0, 26.0, 0.0, 16.0, 0.0, 30.0, 12.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 17.0, 0.0, 25.0, 2.0, 2.0, 0.0, 19.0, 7.0, 0.0, 0.0, 0.0, 70.0, 74.0, 1.0, 9.0, 0.0, 0.0, 0.0, 4.0, 0.0, 5.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 47.0, 32.0, 12.0, 0.0, 0.0, 52.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1253888325837393, "mean_inference_ms": 3.0289187402628426, "mean_action_processing_ms": 0.4569523333387723, "mean_env_wait_ms": 0.7051985448740293, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011193394660949707, "StateBufferConnector_ms": 0.005882740020751953, "ViewRequirementAgentConnector_ms": 0.1739445924758911}, "num_episodes": 18, "episode_return_max": 198.79999999999959, "episode_return_min": 0.4000000000002356, "episode_return_mean": 72.00399999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 298.67228819174426, "num_env_steps_trained_throughput_per_sec": 298.67228819174426, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 18141.644, "restore_workers_time_ms": 0.036, "training_step_time_ms": 18141.551, "sample_time_ms": 2703.667, "learn_time_ms": 15413.746, "learn_throughput": 259.509, "synch_weights_time_ms": 20.216}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "c52aa_00000", "date": "2024-08-12_23-54-27", "timestamp": 1723521267, "time_this_iter_s": 13.462059020996094, "time_total_s": 395.85131669044495, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87e280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 395.85131669044495, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 73.92631578947368, "ram_util_percent": 82.58421052631579}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2575561905782373, "cur_kl_coeff": 0.18984375000000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.244079850653492, "policy_loss": -0.00030864454589035143, "vf_loss": 2.244115172113691, "vf_explained_var": 0.11029486829641635, "kl": 0.0014397352423794136, "entropy": 1.3381561738473398, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28214661351469145, "cur_kl_coeff": 0.028125000000000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6917552252768209, "policy_loss": -0.0010406959789593226, "vf_loss": 0.6927156525550696, "vf_explained_var": 0.007372996006062422, "kl": 0.0028539935777655975, "entropy": 1.5114292522586843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 246.9999999999994, "episode_reward_min": 0.4000000000002356, "episode_reward_mean": 75.56999999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -124.30000000000061, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 187.39999999999992, "predator_policy": 81.0}, "policy_reward_mean": {"prey_policy": 28.4, "predator_policy": 9.385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.40000000000022, 163.79999999999944, 47.20000000000029, 137.29999999999902, 40.0000000000003, 155.2999999999989, 108.39999999999824, 44.50000000000029, 5.799999999999949, 60.500000000000455, 108.39999999999856, 96.49999999999852, 46.30000000000029, 149.79999999999959, 131.80000000000004, 85.49999999999895, 107.69999999999888, 101.29999999999907, 49.60000000000046, 69.70000000000006, 71.69999999999976, 107.89999999999885, 46.30000000000041, 132.59999999999968, 92.39999999999992, 128.79999999999956, 142.89999999999884, 47.80000000000043, 47.200000000000415, 109.29999999999914, 21.09999999999999, 73.99999999999987, 44.50000000000038, 40.0000000000003, 62.50000000000046, 43.40000000000033, 92.8000000000001, 16.899999999999928, 68.40000000000015, 147.19999999999877, 95.49999999999956, 104.89999999999941, 51.300000000000175, 0.4000000000002356, 159.399999999999, 93.09999999999906, 40.0000000000003, 120.99999999999885, 9.600000000000204, 20.299999999999983, 77.1999999999994, 43.90000000000037, 84.3999999999994, 49.90000000000043, 59.800000000000416, 40.0000000000003, 49.00000000000039, 40.0000000000003, 37.5000000000002, 21.30000000000003, 108.79999999999981, 67.10000000000021, 27.20000000000007, 198.79999999999959, 52.60000000000048, 72.10000000000018, 47.0000000000001, 40.0000000000003, 35.600000000000236, 34.50000000000022, 30.000000000000398, 49.00000000000041, 64.30000000000048, 145.19999999999857, 108.39999999999887, 43.10000000000021, 46.60000000000041, 168.1999999999995, 40.0000000000003, 69.70000000000009, 63.50000000000048, 175.89999999999898, 98.79999999999853, 25.000000000000117, 136.49999999999935, 31.900000000000276, 74.99999999999953, 110.19999999999987, 148.1999999999991, 46.700000000000394, 246.9999999999994, 82.09999999999944, 32.20000000000033, 43.90000000000027, 40.0000000000003, 103.0999999999998, 42.70000000000034, 58.50000000000036, 37.200000000000266, 30.40000000000016], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [29.000000000000163, -34.59999999999975, 70.09999999999984, 82.69999999999999, 20.000000000000014, 27.20000000000003, 86.89999999999965, 25.400000000000126, 20.000000000000014, 20.000000000000014, 53.90000000000013, 79.39999999999947, 46.10000000000023, 62.30000000000022, 24.50000000000001, 20.000000000000014, -36.699999999999754, -8.499999999999979, 39.50000000000022, 20.000000000000014, 87.49999999999929, 20.900000000000013, 25.10000000000012, 61.40000000000021, 26.300000000000004, 20.000000000000014, 96.49999999999997, 35.30000000000025, 42.49999999999998, 89.30000000000015, 67.69999999999992, 15.799999999999963, 45.500000000000234, 30.200000000000124, 60.80000000000017, 18.499999999999993, 11.599999999999966, 32.00000000000022, 27.200000000000003, 42.50000000000022, 91.99999999999935, -124.30000000000061, 70.39999999999968, 3.499999999999978, 26.30000000000012, 20.000000000000014, 20.000000000000014, 107.6, -1.0000000000000027, 13.400000000000055, 20.000000000000014, 102.79999999999987, 119.89999999999955, 20.000000000000014, 21.80000000000004, 20.000000000000014, 27.200000000000134, 20.000000000000014, 20.000000000000014, 89.29999999999963, -2.1999999999999926, 5.299999999999965, 22.400000000000087, 5.599999999999984, 20.90000000000003, 23.600000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000022, -13.60000000000015, 20.000000000000014, 44.30000000000019, -5.499999999999972, -24.099999999999753, 20.000000000000014, 37.4000000000002, 20.000000000000014, 52.40000000000022, 90.7999999999994, 20.000000000000014, 69.49999999999997, 106.99999999999973, -51.10000000000002, -3.099999999999958, 25.400000000000105, -32.49999999999976, -3.099999999999958, 62.90000000000018, 72.49999999999974, 73.09999999999954, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.99999999999977, 20.000000000000014, -117.40000000000018, 20.000000000000014, -7.299999999999894, 11.599999999999964, 27.20000000000013, 20.000000000000014, 11.899999999999974, 20.000000000000014, 36.2000000000002, 36.200000000000074, 26.30000000000013, 23.60000000000007, 39.8000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.000000000000178, 20.000000000000014, 20.000000000000014, 20.000000000000014, 0.5000000000000295, 20.000000000000014, -15.699999999999768, 20.000000000000014, 24.500000000000085, 59.30000000000008, 51.50000000000002, 11.599999999999975, 23.90000000000005, -15.699999999999754, 103.39999999999998, 88.39999999999952, 32.60000000000023, 20.000000000000014, -116.20000000000022, 44.300000000000146, 1.0999999999999865, 35.89999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 9.499999999999964, 20.000000000000014, -20.199999999999747, 30.200000000000124, 20.000000000000014, 29.000000000000178, 20.000000000000014, 44.300000000000246, 82.9999999999994, 57.2000000000002, 77.59999999999943, 30.800000000000132, -89.50000000000074, 53.600000000000094, 14.599999999999968, 20.000000000000014, -69.40000000000049, 185.6, 20.000000000000014, 20.000000000000014, 49.70000000000024, 20.000000000000014, 20.000000000000014, 39.500000000000234, 155.89999999999972, 20.000000000000014, 13.699999999999966, 82.09999999999926, -30.399999999999764, 4.39999999999999, 107.29999999999959, -5.799999999999962, 4.699999999999974, -47.79999999999988, 25.100000000000108, 14.899999999999965, 19.70000000000001, 36.49999999999996, 77.89999999999971, 62.30000000000022, 16.399999999999967, 5.300000000000011, 187.39999999999992, 59.600000000000115, 52.10000000000007, 20.000000000000014, -15.699999999999747, -3.1000000000000063, 57.800000000000225, -52.90000000000019, 20.000000000000014, 10.99999999999997, 20.000000000000014, 61.10000000000009, 21.80000000000004, 20.90000000000003, 5.299999999999965, 33.200000000000166, 32.60000000000014, -9.399999999999855, -1.599999999999985, 20.000000000000014], "policy_predator_policy_reward": [14.0, 26.0, 0.0, 11.0, 0.0, 0.0, 3.0, 22.0, 0.0, 0.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 29.0, 1.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 2.0, 19.0, 13.0, 5.0, 17.0, 4.0, 2.0, 0.0, 0.0, 51.0, 53.0, 1.0, 33.0, 0.0, 0.0, 5.0, 0.0, 39.0, 41.0, 0.0, 6.0, 0.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 37.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 20.0, 29.0, 25.0, 0.0, 21.0, 0.0, 11.0, 0.0, 4.0, 6.0, 0.0, 36.0, 13.0, 29.0, 0.0, 11.0, 25.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 81.0, 26.0, 0.0, 16.0, 0.0, 30.0, 12.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 17.0, 0.0, 25.0, 2.0, 2.0, 0.0, 19.0, 7.0, 0.0, 0.0, 0.0, 70.0, 74.0, 1.0, 9.0, 0.0, 0.0, 0.0, 4.0, 0.0, 5.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 47.0, 32.0, 12.0, 0.0, 0.0, 52.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 31.0, 20.0, 0.0, 35.0, 36.0, 39.0, 10.0, 25.0, 27.0, 27.0, 8.0, 0.0, 12.0, 13.0, 0.0, 0.0, 10.0, 0.0, 0.0, 51.0, 39.0, 0.0, 9.0, 0.0, 22.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 14.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1185157313773655, "mean_inference_ms": 3.0088905066733904, "mean_action_processing_ms": 0.45447291102629095, "mean_env_wait_ms": 0.7012456528840135, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014872193336486816, "StateBufferConnector_ms": 0.00854790210723877, "ViewRequirementAgentConnector_ms": 0.1821197271347046}, "num_episodes": 22, "episode_return_max": 246.9999999999994, "episode_return_min": 0.4000000000002356, "episode_return_mean": 75.56999999999985, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 301.96699165482477, "num_env_steps_trained_throughput_per_sec": 301.96699165482477, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 18290.062, "restore_workers_time_ms": 0.035, "training_step_time_ms": 18289.969, "sample_time_ms": 2687.505, "learn_time_ms": 15578.646, "learn_throughput": 256.762, "synch_weights_time_ms": 20.201}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "c52aa_00000", "date": "2024-08-12_23-54-40", "timestamp": 1723521280, "time_this_iter_s": 13.318958044052124, "time_total_s": 409.17027473449707, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87eee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 409.17027473449707, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 72.81052631578947, "ram_util_percent": 82.8421052631579}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.34831451168136, "cur_kl_coeff": 0.09492187500000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6178503513336182, "policy_loss": -0.007076241528965218, "vf_loss": 1.6234172469724424, "vf_explained_var": 0.2065856761402554, "kl": 0.015900913709806334, "entropy": 1.3345716222253425, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.261150901642426, "cur_kl_coeff": 0.014062500000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.23626041674897785, "policy_loss": -0.002726478681273798, "vf_loss": 0.23887060348735384, "vf_explained_var": -0.01894001074568935, "kl": 0.008269636426481005, "entropy": 1.4835084638898335, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 246.9999999999994, "episode_reward_min": 0.4000000000002356, "episode_reward_mean": 70.74099999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -117.40000000000018, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 187.39999999999992, "predator_policy": 81.0}, "policy_reward_mean": {"prey_policy": 26.895500000000016, "predator_policy": 8.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [132.59999999999968, 92.39999999999992, 128.79999999999956, 142.89999999999884, 47.80000000000043, 47.200000000000415, 109.29999999999914, 21.09999999999999, 73.99999999999987, 44.50000000000038, 40.0000000000003, 62.50000000000046, 43.40000000000033, 92.8000000000001, 16.899999999999928, 68.40000000000015, 147.19999999999877, 95.49999999999956, 104.89999999999941, 51.300000000000175, 0.4000000000002356, 159.399999999999, 93.09999999999906, 40.0000000000003, 120.99999999999885, 9.600000000000204, 20.299999999999983, 77.1999999999994, 43.90000000000037, 84.3999999999994, 49.90000000000043, 59.800000000000416, 40.0000000000003, 49.00000000000039, 40.0000000000003, 37.5000000000002, 21.30000000000003, 108.79999999999981, 67.10000000000021, 27.20000000000007, 198.79999999999959, 52.60000000000048, 72.10000000000018, 47.0000000000001, 40.0000000000003, 35.600000000000236, 34.50000000000022, 30.000000000000398, 49.00000000000041, 64.30000000000048, 145.19999999999857, 108.39999999999887, 43.10000000000021, 46.60000000000041, 168.1999999999995, 40.0000000000003, 69.70000000000009, 63.50000000000048, 175.89999999999898, 98.79999999999853, 25.000000000000117, 136.49999999999935, 31.900000000000276, 74.99999999999953, 110.19999999999987, 148.1999999999991, 46.700000000000394, 246.9999999999994, 82.09999999999944, 32.20000000000033, 43.90000000000027, 40.0000000000003, 103.0999999999998, 42.70000000000034, 58.50000000000036, 37.200000000000266, 30.40000000000016, 40.0000000000003, 40.90000000000031, 44.10000000000038, 62.10000000000039, 45.400000000000375, 36.40000000000029, 27.90000000000011, 59.8000000000005, 114.69999999999825, 104.79999999999917, 42.70000000000034, 33.5000000000002, 163.7999999999989, 49.00000000000043, 74.19999999999972, 102.99999999999861, 54.3000000000005, 70.60000000000002, 51.20000000000027, 56.70000000000047, 25.80000000000007, 145.89999999999887, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 107.6, -1.0000000000000027, 13.400000000000055, 20.000000000000014, 102.79999999999987, 119.89999999999955, 20.000000000000014, 21.80000000000004, 20.000000000000014, 27.200000000000134, 20.000000000000014, 20.000000000000014, 89.29999999999963, -2.1999999999999926, 5.299999999999965, 22.400000000000087, 5.599999999999984, 20.90000000000003, 23.600000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000022, -13.60000000000015, 20.000000000000014, 44.30000000000019, -5.499999999999972, -24.099999999999753, 20.000000000000014, 37.4000000000002, 20.000000000000014, 52.40000000000022, 90.7999999999994, 20.000000000000014, 69.49999999999997, 106.99999999999973, -51.10000000000002, -3.099999999999958, 25.400000000000105, -32.49999999999976, -3.099999999999958, 62.90000000000018, 72.49999999999974, 73.09999999999954, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.99999999999977, 20.000000000000014, -117.40000000000018, 20.000000000000014, -7.299999999999894, 11.599999999999964, 27.20000000000013, 20.000000000000014, 11.899999999999974, 20.000000000000014, 36.2000000000002, 36.200000000000074, 26.30000000000013, 23.60000000000007, 39.8000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.000000000000178, 20.000000000000014, 20.000000000000014, 20.000000000000014, 0.5000000000000295, 20.000000000000014, -15.699999999999768, 20.000000000000014, 24.500000000000085, 59.30000000000008, 51.50000000000002, 11.599999999999975, 23.90000000000005, -15.699999999999754, 103.39999999999998, 88.39999999999952, 32.60000000000023, 20.000000000000014, -116.20000000000022, 44.300000000000146, 1.0999999999999865, 35.89999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 9.499999999999964, 20.000000000000014, -20.199999999999747, 30.200000000000124, 20.000000000000014, 29.000000000000178, 20.000000000000014, 44.300000000000246, 82.9999999999994, 57.2000000000002, 77.59999999999943, 30.800000000000132, -89.50000000000074, 53.600000000000094, 14.599999999999968, 20.000000000000014, -69.40000000000049, 185.6, 20.000000000000014, 20.000000000000014, 49.70000000000024, 20.000000000000014, 20.000000000000014, 39.500000000000234, 155.89999999999972, 20.000000000000014, 13.699999999999966, 82.09999999999926, -30.399999999999764, 4.39999999999999, 107.29999999999959, -5.799999999999962, 4.699999999999974, -47.79999999999988, 25.100000000000108, 14.899999999999965, 19.70000000000001, 36.49999999999996, 77.89999999999971, 62.30000000000022, 16.399999999999967, 5.300000000000011, 187.39999999999992, 59.600000000000115, 52.10000000000007, 20.000000000000014, -15.699999999999747, -3.1000000000000063, 57.800000000000225, -52.90000000000019, 20.000000000000014, 10.99999999999997, 20.000000000000014, 61.10000000000009, 21.80000000000004, 20.90000000000003, 5.299999999999965, 33.200000000000166, 32.60000000000014, -9.399999999999855, -1.599999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 13.699999999999966, 10.399999999999979, 28.400000000000183, 22.700000000000053, 20.000000000000014, 25.400000000000087, -5.49999999999994, 5.899999999999988, -3.099999999999965, 20.000000000000014, 27.20000000000011, 32.60000000000023, 64.10000000000021, 50.60000000000022, 66.80000000000001, 20.000000000000014, 22.700000000000053, 20.000000000000014, 11.599999999999964, 17.899999999999988, 62.600000000000165, 90.19999999999952, 29.000000000000146, 20.000000000000014, 54.2000000000002, 20.000000000000014, 62.30000000000017, 40.70000000000025, 9.499999999999964, 39.80000000000025, 20.000000000000014, 50.600000000000236, -20.199999999999754, 46.40000000000014, 19.70000000000001, 26.000000000000117, -15.699999999999768, 24.500000000000096, 52.700000000000195, 66.19999999999995, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [5.0, 0.0, 39.0, 41.0, 0.0, 6.0, 0.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 37.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 20.0, 29.0, 25.0, 0.0, 21.0, 0.0, 11.0, 0.0, 4.0, 6.0, 0.0, 36.0, 13.0, 29.0, 0.0, 11.0, 25.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 81.0, 26.0, 0.0, 16.0, 0.0, 30.0, 12.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 17.0, 0.0, 25.0, 2.0, 2.0, 0.0, 19.0, 7.0, 0.0, 0.0, 0.0, 70.0, 74.0, 1.0, 9.0, 0.0, 0.0, 0.0, 4.0, 0.0, 5.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 47.0, 32.0, 12.0, 0.0, 0.0, 52.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 31.0, 20.0, 0.0, 35.0, 36.0, 39.0, 10.0, 25.0, 27.0, 27.0, 8.0, 0.0, 12.0, 13.0, 0.0, 0.0, 10.0, 0.0, 0.0, 51.0, 39.0, 0.0, 9.0, 0.0, 22.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 14.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 11.0, 0.0, 0.0, 11.0, 25.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 4.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 25.0, 0.0, 7.0, 4.0, 17.0, 0.0, 0.0, 27.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1106818306691018, "mean_inference_ms": 2.9851883273888586, "mean_action_processing_ms": 0.4852336797511982, "mean_env_wait_ms": 0.6956435574106713, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0152512788772583, "StateBufferConnector_ms": 0.008356332778930664, "ViewRequirementAgentConnector_ms": 0.1640695333480835}, "num_episodes": 23, "episode_return_max": 246.9999999999994, "episode_return_min": 0.4000000000002356, "episode_return_mean": 70.74099999999993, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 234.27429761275093, "num_env_steps_trained_throughput_per_sec": 234.27429761275093, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 17703.636, "restore_workers_time_ms": 0.036, "training_step_time_ms": 17702.731, "sample_time_ms": 2628.473, "learn_time_ms": 15050.942, "learn_throughput": 265.764, "synch_weights_time_ms": 18.729}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "c52aa_00000", "date": "2024-08-12_23-54-58", "timestamp": 1723521298, "time_this_iter_s": 17.12231206893921, "time_total_s": 426.2925868034363, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab8788b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 426.2925868034363, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 82.325, "ram_util_percent": 83.675}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4051726954402748, "cur_kl_coeff": 0.09492187500000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1552328831304317, "policy_loss": -0.00340220468961412, "vf_loss": 3.157332219963982, "vf_explained_var": 0.07154045609570055, "kl": 0.013725753598867059, "entropy": 1.3197020605127647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.27154288078860317, "cur_kl_coeff": 0.014062500000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.27137096480087, "policy_loss": -0.006642655623465697, "vf_loss": 1.2777017315701833, "vf_explained_var": 0.004106689540166703, "kl": 0.02217876233053359, "entropy": 1.5357593280297739, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 246.9999999999994, "episode_reward_min": 0.4000000000002356, "episode_reward_mean": 70.45099999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -117.40000000000018, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 187.39999999999992, "predator_policy": 81.0}, "policy_reward_mean": {"prey_policy": 27.31550000000002, "predator_policy": 7.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [104.89999999999941, 51.300000000000175, 0.4000000000002356, 159.399999999999, 93.09999999999906, 40.0000000000003, 120.99999999999885, 9.600000000000204, 20.299999999999983, 77.1999999999994, 43.90000000000037, 84.3999999999994, 49.90000000000043, 59.800000000000416, 40.0000000000003, 49.00000000000039, 40.0000000000003, 37.5000000000002, 21.30000000000003, 108.79999999999981, 67.10000000000021, 27.20000000000007, 198.79999999999959, 52.60000000000048, 72.10000000000018, 47.0000000000001, 40.0000000000003, 35.600000000000236, 34.50000000000022, 30.000000000000398, 49.00000000000041, 64.30000000000048, 145.19999999999857, 108.39999999999887, 43.10000000000021, 46.60000000000041, 168.1999999999995, 40.0000000000003, 69.70000000000009, 63.50000000000048, 175.89999999999898, 98.79999999999853, 25.000000000000117, 136.49999999999935, 31.900000000000276, 74.99999999999953, 110.19999999999987, 148.1999999999991, 46.700000000000394, 246.9999999999994, 82.09999999999944, 32.20000000000033, 43.90000000000027, 40.0000000000003, 103.0999999999998, 42.70000000000034, 58.50000000000036, 37.200000000000266, 30.40000000000016, 40.0000000000003, 40.90000000000031, 44.10000000000038, 62.10000000000039, 45.400000000000375, 36.40000000000029, 27.90000000000011, 59.8000000000005, 114.69999999999825, 104.79999999999917, 42.70000000000034, 33.5000000000002, 163.7999999999989, 49.00000000000043, 74.19999999999972, 102.99999999999861, 54.3000000000005, 70.60000000000002, 51.20000000000027, 56.70000000000047, 25.80000000000007, 145.89999999999887, 40.0000000000003, 84.09999999999904, 177.09999999999917, 40.9000000000003, 22.500000000000096, 21.800000000000015, 44.200000000000216, 71.49999999999999, 72.39999999999989, 73.30000000000018, 116.69999999999905, 129.79999999999922, 40.0000000000003, 110.19999999999983, 82.29999999999906, 65.20000000000041, 42.700000000000294, 87.69999999999999, 95.89999999999986], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [106.99999999999973, -51.10000000000002, -3.099999999999958, 25.400000000000105, -32.49999999999976, -3.099999999999958, 62.90000000000018, 72.49999999999974, 73.09999999999954, 20.000000000000014, 20.000000000000014, 20.000000000000014, 100.99999999999977, 20.000000000000014, -117.40000000000018, 20.000000000000014, -7.299999999999894, 11.599999999999964, 27.20000000000013, 20.000000000000014, 11.899999999999974, 20.000000000000014, 36.2000000000002, 36.200000000000074, 26.30000000000013, 23.60000000000007, 39.8000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 29.000000000000178, 20.000000000000014, 20.000000000000014, 20.000000000000014, 0.5000000000000295, 20.000000000000014, -15.699999999999768, 20.000000000000014, 24.500000000000085, 59.30000000000008, 51.50000000000002, 11.599999999999975, 23.90000000000005, -15.699999999999754, 103.39999999999998, 88.39999999999952, 32.60000000000023, 20.000000000000014, -116.20000000000022, 44.300000000000146, 1.0999999999999865, 35.89999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 9.499999999999964, 20.000000000000014, -20.199999999999747, 30.200000000000124, 20.000000000000014, 29.000000000000178, 20.000000000000014, 44.300000000000246, 82.9999999999994, 57.2000000000002, 77.59999999999943, 30.800000000000132, -89.50000000000074, 53.600000000000094, 14.599999999999968, 20.000000000000014, -69.40000000000049, 185.6, 20.000000000000014, 20.000000000000014, 49.70000000000024, 20.000000000000014, 20.000000000000014, 39.500000000000234, 155.89999999999972, 20.000000000000014, 13.699999999999966, 82.09999999999926, -30.399999999999764, 4.39999999999999, 107.29999999999959, -5.799999999999962, 4.699999999999974, -47.79999999999988, 25.100000000000108, 14.899999999999965, 19.70000000000001, 36.49999999999996, 77.89999999999971, 62.30000000000022, 16.399999999999967, 5.300000000000011, 187.39999999999992, 59.600000000000115, 52.10000000000007, 20.000000000000014, -15.699999999999747, -3.1000000000000063, 57.800000000000225, -52.90000000000019, 20.000000000000014, 10.99999999999997, 20.000000000000014, 61.10000000000009, 21.80000000000004, 20.90000000000003, 5.299999999999965, 33.200000000000166, 32.60000000000014, -9.399999999999855, -1.599999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 13.699999999999966, 10.399999999999979, 28.400000000000183, 22.700000000000053, 20.000000000000014, 25.400000000000087, -5.49999999999994, 5.899999999999988, -3.099999999999965, 20.000000000000014, 27.20000000000011, 32.60000000000023, 64.10000000000021, 50.60000000000022, 66.80000000000001, 20.000000000000014, 22.700000000000053, 20.000000000000014, 11.599999999999964, 17.899999999999988, 62.600000000000165, 90.19999999999952, 29.000000000000146, 20.000000000000014, 54.2000000000002, 20.000000000000014, 62.30000000000017, 40.70000000000025, 9.499999999999964, 39.80000000000025, 20.000000000000014, 50.600000000000236, -20.199999999999754, 46.40000000000014, 19.70000000000001, 26.000000000000117, -15.699999999999768, 24.500000000000096, 52.700000000000195, 66.19999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 64.10000000000021, 82.99999999999929, 82.09999999999998, 20.900000000000013, 20.000000000000014, 20.000000000000014, -26.499999999999815, 9.499999999999964, 5.299999999999965, 20.000000000000014, 0.20000000000010423, 31.700000000000212, 39.800000000000225, 52.40000000000023, 20.000000000000014, 20.000000000000014, 53.29999999999996, 35.60000000000002, 55.10000000000022, 25.400000000000105, 76.39999999999978, 20.000000000000014, 20.000000000000014, 90.19999999999992, 20.000000000000014, 44.30000000000016, 20.000000000000014, 45.200000000000244, 20.000000000000014, 20.000000000000014, 22.700000000000063, 20.000000000000014, 49.70000000000012, 53.90000000000011, 20.000000000000014], "policy_predator_policy_reward": [36.0, 13.0, 29.0, 0.0, 11.0, 25.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 81.0, 26.0, 0.0, 16.0, 0.0, 30.0, 12.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 17.0, 0.0, 25.0, 2.0, 2.0, 0.0, 19.0, 7.0, 0.0, 0.0, 0.0, 70.0, 74.0, 1.0, 9.0, 0.0, 0.0, 0.0, 4.0, 0.0, 5.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 47.0, 32.0, 12.0, 0.0, 0.0, 52.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 31.0, 20.0, 0.0, 35.0, 36.0, 39.0, 10.0, 25.0, 27.0, 27.0, 8.0, 0.0, 12.0, 13.0, 0.0, 0.0, 10.0, 0.0, 0.0, 51.0, 39.0, 0.0, 9.0, 0.0, 22.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 14.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 11.0, 0.0, 0.0, 11.0, 25.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 4.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 25.0, 0.0, 7.0, 4.0, 17.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 29.0, 0.0, 0.0, 7.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 8.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.103972987281501, "mean_inference_ms": 2.9649620533704155, "mean_action_processing_ms": 0.5072741132791315, "mean_env_wait_ms": 0.6908787269119051, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011873602867126465, "StateBufferConnector_ms": 0.00794529914855957, "ViewRequirementAgentConnector_ms": 0.15725326538085938}, "num_episodes": 18, "episode_return_max": 246.9999999999994, "episode_return_min": 0.4000000000002356, "episode_return_mean": 70.45099999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 284.1224087966024, "num_env_steps_trained_throughput_per_sec": 284.1224087966024, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 17503.845, "restore_workers_time_ms": 0.02, "training_step_time_ms": 17502.965, "sample_time_ms": 2520.713, "learn_time_ms": 14958.877, "learn_throughput": 267.4, "synch_weights_time_ms": 18.858}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "c52aa_00000", "date": "2024-08-12_23-55-12", "timestamp": 1723521312, "time_this_iter_s": 14.123650074005127, "time_total_s": 440.4162368774414, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab849ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 440.4162368774414, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 77.22500000000001, "ram_util_percent": 83.75}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4472880216108428, "cur_kl_coeff": 0.09492187500000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0107223615759895, "policy_loss": -3.476134444729834e-05, "vf_loss": 2.01065339714131, "vf_explained_var": 0.07233931939437907, "kl": 0.0010927856702953377, "entropy": 1.3282593564381675, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2775646698951879, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6523420809911041, "policy_loss": -0.00225475810064131, "vf_loss": 0.6544897187481482, "vf_explained_var": 0.002862864196615875, "kl": 0.00507839942510631, "entropy": 1.5074693413007827, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 246.9999999999994, "episode_reward_min": -14.799999999999523, "episode_reward_mean": 68.40499999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -116.20000000000022, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 187.39999999999992, "predator_policy": 88.0}, "policy_reward_mean": {"prey_policy": 25.75250000000002, "predator_policy": 8.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.30000000000003, 108.79999999999981, 67.10000000000021, 27.20000000000007, 198.79999999999959, 52.60000000000048, 72.10000000000018, 47.0000000000001, 40.0000000000003, 35.600000000000236, 34.50000000000022, 30.000000000000398, 49.00000000000041, 64.30000000000048, 145.19999999999857, 108.39999999999887, 43.10000000000021, 46.60000000000041, 168.1999999999995, 40.0000000000003, 69.70000000000009, 63.50000000000048, 175.89999999999898, 98.79999999999853, 25.000000000000117, 136.49999999999935, 31.900000000000276, 74.99999999999953, 110.19999999999987, 148.1999999999991, 46.700000000000394, 246.9999999999994, 82.09999999999944, 32.20000000000033, 43.90000000000027, 40.0000000000003, 103.0999999999998, 42.70000000000034, 58.50000000000036, 37.200000000000266, 30.40000000000016, 40.0000000000003, 40.90000000000031, 44.10000000000038, 62.10000000000039, 45.400000000000375, 36.40000000000029, 27.90000000000011, 59.8000000000005, 114.69999999999825, 104.79999999999917, 42.70000000000034, 33.5000000000002, 163.7999999999989, 49.00000000000043, 74.19999999999972, 102.99999999999861, 54.3000000000005, 70.60000000000002, 51.20000000000027, 56.70000000000047, 25.80000000000007, 145.89999999999887, 40.0000000000003, 84.09999999999904, 177.09999999999917, 40.9000000000003, 22.500000000000096, 21.800000000000015, 44.200000000000216, 71.49999999999999, 72.39999999999989, 73.30000000000018, 116.69999999999905, 129.79999999999922, 40.0000000000003, 110.19999999999983, 82.29999999999906, 65.20000000000041, 42.700000000000294, 87.69999999999999, 95.89999999999986, 25.19999999999988, 35.00000000000023, 4.200000000000012, 37.80000000000027, 49.10000000000045, 40.80000000000009, 64.30000000000047, -3.999999999999852, 25.60000000000033, 56.60000000000048, 30.100000000000154, 94.89999999999844, 145.29999999999882, 50.80000000000048, 175.49999999999898, -14.799999999999523, 8.099999999999929, 52.600000000000406], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-15.699999999999768, 20.000000000000014, 24.500000000000085, 59.30000000000008, 51.50000000000002, 11.599999999999975, 23.90000000000005, -15.699999999999754, 103.39999999999998, 88.39999999999952, 32.60000000000023, 20.000000000000014, -116.20000000000022, 44.300000000000146, 1.0999999999999865, 35.89999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 9.499999999999964, 20.000000000000014, -20.199999999999747, 30.200000000000124, 20.000000000000014, 29.000000000000178, 20.000000000000014, 44.300000000000246, 82.9999999999994, 57.2000000000002, 77.59999999999943, 30.800000000000132, -89.50000000000074, 53.600000000000094, 14.599999999999968, 20.000000000000014, -69.40000000000049, 185.6, 20.000000000000014, 20.000000000000014, 49.70000000000024, 20.000000000000014, 20.000000000000014, 39.500000000000234, 155.89999999999972, 20.000000000000014, 13.699999999999966, 82.09999999999926, -30.399999999999764, 4.39999999999999, 107.29999999999959, -5.799999999999962, 4.699999999999974, -47.79999999999988, 25.100000000000108, 14.899999999999965, 19.70000000000001, 36.49999999999996, 77.89999999999971, 62.30000000000022, 16.399999999999967, 5.300000000000011, 187.39999999999992, 59.600000000000115, 52.10000000000007, 20.000000000000014, -15.699999999999747, -3.1000000000000063, 57.800000000000225, -52.90000000000019, 20.000000000000014, 10.99999999999997, 20.000000000000014, 61.10000000000009, 21.80000000000004, 20.90000000000003, 5.299999999999965, 33.200000000000166, 32.60000000000014, -9.399999999999855, -1.599999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 13.699999999999966, 10.399999999999979, 28.400000000000183, 22.700000000000053, 20.000000000000014, 25.400000000000087, -5.49999999999994, 5.899999999999988, -3.099999999999965, 20.000000000000014, 27.20000000000011, 32.60000000000023, 64.10000000000021, 50.60000000000022, 66.80000000000001, 20.000000000000014, 22.700000000000053, 20.000000000000014, 11.599999999999964, 17.899999999999988, 62.600000000000165, 90.19999999999952, 29.000000000000146, 20.000000000000014, 54.2000000000002, 20.000000000000014, 62.30000000000017, 40.70000000000025, 9.499999999999964, 39.80000000000025, 20.000000000000014, 50.600000000000236, -20.199999999999754, 46.40000000000014, 19.70000000000001, 26.000000000000117, -15.699999999999768, 24.500000000000096, 52.700000000000195, 66.19999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 64.10000000000021, 82.99999999999929, 82.09999999999998, 20.900000000000013, 20.000000000000014, 20.000000000000014, -26.499999999999815, 9.499999999999964, 5.299999999999965, 20.000000000000014, 0.20000000000010423, 31.700000000000212, 39.800000000000225, 52.40000000000023, 20.000000000000014, 20.000000000000014, 53.29999999999996, 35.60000000000002, 55.10000000000022, 25.400000000000105, 76.39999999999978, 20.000000000000014, 20.000000000000014, 90.19999999999992, 20.000000000000014, 44.30000000000016, 20.000000000000014, 45.200000000000244, 20.000000000000014, 20.000000000000014, 22.700000000000063, 20.000000000000014, 49.70000000000012, 53.90000000000011, 20.000000000000014, -29.200000000000045, -103.60000000000016, 7.999999999999966, 20.000000000000014, -11.799999999999828, -36.999999999999886, 20.000000000000014, 15.799999999999963, 33.500000000000234, 11.599999999999964, -3.3999999999998622, 3.1999999999999615, 44.30000000000024, 20.000000000000014, -64.00000000000071, 20.000000000000014, -24.9999999999998, -3.3999999999998693, 20.000000000000014, 29.600000000000183, 1.0999999999999723, 20.000000000000014, 73.09999999999955, 21.80000000000004, 122.59999999999954, 22.700000000000024, 20.000000000000014, 30.800000000000196, 36.20000000000026, 128.29999999999987, -15.699999999999761, -24.099999999999746, -40.89999999999983, 20.000000000000014, 25.400000000000112, 27.20000000000013], "policy_predator_policy_reward": [0.0, 17.0, 0.0, 25.0, 2.0, 2.0, 0.0, 19.0, 7.0, 0.0, 0.0, 0.0, 70.0, 74.0, 1.0, 9.0, 0.0, 0.0, 0.0, 4.0, 0.0, 5.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 47.0, 32.0, 12.0, 0.0, 0.0, 52.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 31.0, 20.0, 0.0, 35.0, 36.0, 39.0, 10.0, 25.0, 27.0, 27.0, 8.0, 0.0, 12.0, 13.0, 0.0, 0.0, 10.0, 0.0, 0.0, 51.0, 39.0, 0.0, 9.0, 0.0, 22.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 14.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 11.0, 0.0, 0.0, 11.0, 25.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 4.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 25.0, 0.0, 7.0, 4.0, 17.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 29.0, 0.0, 0.0, 7.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 8.0, 14.0, 88.0, 70.0, 0.0, 7.0, 16.0, 37.0, 0.0, 2.0, 4.0, 0.0, 14.0, 27.0, 0.0, 0.0, 40.0, 0.0, 24.0, 30.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 25.0, 0.0, 29.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.097760037126242, "mean_inference_ms": 2.9446238740589763, "mean_action_processing_ms": 0.5283026642233404, "mean_env_wait_ms": 0.686069989906247, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011070847511291504, "StateBufferConnector_ms": 0.007922053337097168, "ViewRequirementAgentConnector_ms": 0.14768636226654053}, "num_episodes": 18, "episode_return_max": 246.9999999999994, "episode_return_min": -14.799999999999523, "episode_return_mean": 68.40499999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 303.88888355556105, "num_env_steps_trained_throughput_per_sec": 303.88888355556105, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 16655.642, "restore_workers_time_ms": 0.018, "training_step_time_ms": 16654.767, "sample_time_ms": 2454.786, "learn_time_ms": 14178.086, "learn_throughput": 282.126, "synch_weights_time_ms": 17.747}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "c52aa_00000", "date": "2024-08-12_23-55-25", "timestamp": 1723521325, "time_this_iter_s": 13.213227987289429, "time_total_s": 453.62946486473083, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab849040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 453.62946486473083, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 72.66315789473686, "ram_util_percent": 83.35263157894735}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3855092689946846, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2183333721741167, "policy_loss": -0.00433179139438031, "vf_loss": 2.2222559604695236, "vf_explained_var": 0.12905604747868088, "kl": 0.008622000813452062, "entropy": 1.3470742842507741, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29618150760178213, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5153987210421335, "policy_loss": -0.0039214865979615345, "vf_loss": 0.5191018597075343, "vf_explained_var": 0.0038451139573697692, "kl": 0.010351334195032416, "entropy": 1.4685117063698945, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 246.9999999999994, "episode_reward_min": -14.799999999999523, "episode_reward_mean": 66.25899999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -103.60000000000016, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 187.39999999999992, "predator_policy": 88.0}, "policy_reward_mean": {"prey_policy": 24.549500000000027, "predator_policy": 8.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [168.1999999999995, 40.0000000000003, 69.70000000000009, 63.50000000000048, 175.89999999999898, 98.79999999999853, 25.000000000000117, 136.49999999999935, 31.900000000000276, 74.99999999999953, 110.19999999999987, 148.1999999999991, 46.700000000000394, 246.9999999999994, 82.09999999999944, 32.20000000000033, 43.90000000000027, 40.0000000000003, 103.0999999999998, 42.70000000000034, 58.50000000000036, 37.200000000000266, 30.40000000000016, 40.0000000000003, 40.90000000000031, 44.10000000000038, 62.10000000000039, 45.400000000000375, 36.40000000000029, 27.90000000000011, 59.8000000000005, 114.69999999999825, 104.79999999999917, 42.70000000000034, 33.5000000000002, 163.7999999999989, 49.00000000000043, 74.19999999999972, 102.99999999999861, 54.3000000000005, 70.60000000000002, 51.20000000000027, 56.70000000000047, 25.80000000000007, 145.89999999999887, 40.0000000000003, 84.09999999999904, 177.09999999999917, 40.9000000000003, 22.500000000000096, 21.800000000000015, 44.200000000000216, 71.49999999999999, 72.39999999999989, 73.30000000000018, 116.69999999999905, 129.79999999999922, 40.0000000000003, 110.19999999999983, 82.29999999999906, 65.20000000000041, 42.700000000000294, 87.69999999999999, 95.89999999999986, 25.19999999999988, 35.00000000000023, 4.200000000000012, 37.80000000000027, 49.10000000000045, 40.80000000000009, 64.30000000000047, -3.999999999999852, 25.60000000000033, 56.60000000000048, 30.100000000000154, 94.89999999999844, 145.29999999999882, 50.80000000000048, 175.49999999999898, -14.799999999999523, 8.099999999999929, 52.600000000000406, 75.09999999999968, 40.0000000000003, 64.9000000000003, 45.10000000000029, 32.100000000000186, 74.79999999999966, 30.500000000000156, 47.300000000000324, 8.900000000000237, 103.39999999999903, 10.30000000000006, 40.0000000000003, 116.1999999999988, 99.39999999999864, 19.400000000000052, 67.1, 40.0000000000003, 62.500000000000504], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-69.40000000000049, 185.6, 20.000000000000014, 20.000000000000014, 49.70000000000024, 20.000000000000014, 20.000000000000014, 39.500000000000234, 155.89999999999972, 20.000000000000014, 13.699999999999966, 82.09999999999926, -30.399999999999764, 4.39999999999999, 107.29999999999959, -5.799999999999962, 4.699999999999974, -47.79999999999988, 25.100000000000108, 14.899999999999965, 19.70000000000001, 36.49999999999996, 77.89999999999971, 62.30000000000022, 16.399999999999967, 5.300000000000011, 187.39999999999992, 59.600000000000115, 52.10000000000007, 20.000000000000014, -15.699999999999747, -3.1000000000000063, 57.800000000000225, -52.90000000000019, 20.000000000000014, 10.99999999999997, 20.000000000000014, 61.10000000000009, 21.80000000000004, 20.90000000000003, 5.299999999999965, 33.200000000000166, 32.60000000000014, -9.399999999999855, -1.599999999999985, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 13.699999999999966, 10.399999999999979, 28.400000000000183, 22.700000000000053, 20.000000000000014, 25.400000000000087, -5.49999999999994, 5.899999999999988, -3.099999999999965, 20.000000000000014, 27.20000000000011, 32.60000000000023, 64.10000000000021, 50.60000000000022, 66.80000000000001, 20.000000000000014, 22.700000000000053, 20.000000000000014, 11.599999999999964, 17.899999999999988, 62.600000000000165, 90.19999999999952, 29.000000000000146, 20.000000000000014, 54.2000000000002, 20.000000000000014, 62.30000000000017, 40.70000000000025, 9.499999999999964, 39.80000000000025, 20.000000000000014, 50.600000000000236, -20.199999999999754, 46.40000000000014, 19.70000000000001, 26.000000000000117, -15.699999999999768, 24.500000000000096, 52.700000000000195, 66.19999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 64.10000000000021, 82.99999999999929, 82.09999999999998, 20.900000000000013, 20.000000000000014, 20.000000000000014, -26.499999999999815, 9.499999999999964, 5.299999999999965, 20.000000000000014, 0.20000000000010423, 31.700000000000212, 39.800000000000225, 52.40000000000023, 20.000000000000014, 20.000000000000014, 53.29999999999996, 35.60000000000002, 55.10000000000022, 25.400000000000105, 76.39999999999978, 20.000000000000014, 20.000000000000014, 90.19999999999992, 20.000000000000014, 44.30000000000016, 20.000000000000014, 45.200000000000244, 20.000000000000014, 20.000000000000014, 22.700000000000063, 20.000000000000014, 49.70000000000012, 53.90000000000011, 20.000000000000014, -29.200000000000045, -103.60000000000016, 7.999999999999966, 20.000000000000014, -11.799999999999828, -36.999999999999886, 20.000000000000014, 15.799999999999963, 33.500000000000234, 11.599999999999964, -3.3999999999998622, 3.1999999999999615, 44.30000000000024, 20.000000000000014, -64.00000000000071, 20.000000000000014, -24.9999999999998, -3.3999999999998693, 20.000000000000014, 29.600000000000183, 1.0999999999999723, 20.000000000000014, 73.09999999999955, 21.80000000000004, 122.59999999999954, 22.700000000000024, 20.000000000000014, 30.800000000000196, 36.20000000000026, 128.29999999999987, -15.699999999999761, -24.099999999999746, -40.89999999999983, 20.000000000000014, 25.400000000000112, 27.20000000000013, 24.50000000000008, 50.60000000000023, 20.000000000000014, 20.000000000000014, 30.80000000000011, 28.100000000000158, -16.900000000000553, 20.000000000000014, -15.699999999999747, 21.800000000000043, 42.800000000000196, 20.000000000000014, 20.000000000000014, -14.499999999999808, 5.300000000000033, 20.000000000000014, -63.10000000000061, 20.000000000000014, -9.399999999999947, 75.79999999999956, -36.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.900000000000084, 80.29999999999947, 79.39999999999932, 20.000000000000014, -0.7000000000000294, -37.899999999999764, -10.900000000000018, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000025], "policy_predator_policy_reward": [0.0, 52.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 3.0, 31.0, 20.0, 0.0, 35.0, 36.0, 39.0, 10.0, 25.0, 27.0, 27.0, 8.0, 0.0, 12.0, 13.0, 0.0, 0.0, 10.0, 0.0, 0.0, 51.0, 39.0, 0.0, 9.0, 0.0, 22.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 14.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 0.0, 11.0, 0.0, 0.0, 11.0, 25.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 4.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 25.0, 0.0, 7.0, 4.0, 17.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 29.0, 0.0, 0.0, 7.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 8.0, 14.0, 88.0, 70.0, 0.0, 7.0, 16.0, 37.0, 0.0, 2.0, 4.0, 0.0, 14.0, 27.0, 0.0, 0.0, 40.0, 0.0, 24.0, 30.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 25.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 42.0, 0.0, 17.0, 9.0, 1.0, 11.0, 0.0, 25.0, 22.0, 0.0, 50.0, 2.0, 37.0, 0.0, 27.0, 0.0, 0.0, 0.0, 1.0, 11.0, 0.0, 0.0, 35.0, 23.0, 15.0, 43.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.091766730204076, "mean_inference_ms": 2.9240961417071287, "mean_action_processing_ms": 0.548597939147009, "mean_env_wait_ms": 0.680946726974299, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008348226547241211, "StateBufferConnector_ms": 0.007806301116943359, "ViewRequirementAgentConnector_ms": 0.13663828372955322}, "num_episodes": 18, "episode_return_max": 246.9999999999994, "episode_return_min": -14.799999999999523, "episode_return_mean": 66.25899999999992, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 247.060570027973, "num_env_steps_trained_throughput_per_sec": 247.060570027973, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 16296.745, "restore_workers_time_ms": 0.017, "training_step_time_ms": 16295.871, "sample_time_ms": 2306.464, "learn_time_ms": 13967.834, "learn_throughput": 286.372, "synch_weights_time_ms": 17.628}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "c52aa_00000", "date": "2024-08-12_23-55-41", "timestamp": 1723521341, "time_this_iter_s": 16.243609189987183, "time_total_s": 469.873074054718, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c58b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 469.873074054718, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 79.44347826086957, "ram_util_percent": 83.4391304347826}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4660977825364738, "cur_kl_coeff": 0.047460937500000015, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.023957612274816, "policy_loss": -0.005422079616605684, "vf_loss": 5.028419149111188, "vf_explained_var": 0.09665521641887685, "kl": 0.020238603586120455, "entropy": 1.2917629925662248, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.38119596039886194, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1922763547569355, "policy_loss": -0.005970787597701899, "vf_loss": 1.1979349585594954, "vf_explained_var": 0.012056842840537823, "kl": 0.014800029227903884, "entropy": 1.5003864649111631, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 237.89999999999955, "episode_reward_min": -38.69999999999977, "episode_reward_mean": 69.72299999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -141.7000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.99999999999966, "predator_policy": 88.0}, "policy_reward_mean": {"prey_policy": 26.001500000000014, "predator_policy": 8.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [45.400000000000375, 36.40000000000029, 27.90000000000011, 59.8000000000005, 114.69999999999825, 104.79999999999917, 42.70000000000034, 33.5000000000002, 163.7999999999989, 49.00000000000043, 74.19999999999972, 102.99999999999861, 54.3000000000005, 70.60000000000002, 51.20000000000027, 56.70000000000047, 25.80000000000007, 145.89999999999887, 40.0000000000003, 84.09999999999904, 177.09999999999917, 40.9000000000003, 22.500000000000096, 21.800000000000015, 44.200000000000216, 71.49999999999999, 72.39999999999989, 73.30000000000018, 116.69999999999905, 129.79999999999922, 40.0000000000003, 110.19999999999983, 82.29999999999906, 65.20000000000041, 42.700000000000294, 87.69999999999999, 95.89999999999986, 25.19999999999988, 35.00000000000023, 4.200000000000012, 37.80000000000027, 49.10000000000045, 40.80000000000009, 64.30000000000047, -3.999999999999852, 25.60000000000033, 56.60000000000048, 30.100000000000154, 94.89999999999844, 145.29999999999882, 50.80000000000048, 175.49999999999898, -14.799999999999523, 8.099999999999929, 52.600000000000406, 75.09999999999968, 40.0000000000003, 64.9000000000003, 45.10000000000029, 32.100000000000186, 74.79999999999966, 30.500000000000156, 47.300000000000324, 8.900000000000237, 103.39999999999903, 10.30000000000006, 40.0000000000003, 116.1999999999988, 99.39999999999864, 19.400000000000052, 67.1, 40.0000000000003, 62.500000000000504, 102.7999999999987, 87.59999999999977, 154.89999999999972, 137.3999999999997, 174.09999999999897, -38.69999999999977, 41.90000000000024, 138.79999999999959, 79.89999999999932, 46.30000000000029, 62.00000000000011, 46.00000000000015, 165.99999999999892, 146.49999999999974, 62.500000000000355, 44.50000000000036, 157.39999999999972, 87.99999999999974, 189.2999999999991, 121.79999999999896, 89.49999999999928, 34.50000000000023, 237.89999999999955, -18.999999999999517, 10.299999999999988, 9.199999999999926, 68.80000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 25.400000000000087, -5.49999999999994, 5.899999999999988, -3.099999999999965, 20.000000000000014, 27.20000000000011, 32.60000000000023, 64.10000000000021, 50.60000000000022, 66.80000000000001, 20.000000000000014, 22.700000000000053, 20.000000000000014, 11.599999999999964, 17.899999999999988, 62.600000000000165, 90.19999999999952, 29.000000000000146, 20.000000000000014, 54.2000000000002, 20.000000000000014, 62.30000000000017, 40.70000000000025, 9.499999999999964, 39.80000000000025, 20.000000000000014, 50.600000000000236, -20.199999999999754, 46.40000000000014, 19.70000000000001, 26.000000000000117, -15.699999999999768, 24.500000000000096, 52.700000000000195, 66.19999999999995, 20.000000000000014, 20.000000000000014, 20.000000000000014, 64.10000000000021, 82.99999999999929, 82.09999999999998, 20.900000000000013, 20.000000000000014, 20.000000000000014, -26.499999999999815, 9.499999999999964, 5.299999999999965, 20.000000000000014, 0.20000000000010423, 31.700000000000212, 39.800000000000225, 52.40000000000023, 20.000000000000014, 20.000000000000014, 53.29999999999996, 35.60000000000002, 55.10000000000022, 25.400000000000105, 76.39999999999978, 20.000000000000014, 20.000000000000014, 90.19999999999992, 20.000000000000014, 44.30000000000016, 20.000000000000014, 45.200000000000244, 20.000000000000014, 20.000000000000014, 22.700000000000063, 20.000000000000014, 49.70000000000012, 53.90000000000011, 20.000000000000014, -29.200000000000045, -103.60000000000016, 7.999999999999966, 20.000000000000014, -11.799999999999828, -36.999999999999886, 20.000000000000014, 15.799999999999963, 33.500000000000234, 11.599999999999964, -3.3999999999998622, 3.1999999999999615, 44.30000000000024, 20.000000000000014, -64.00000000000071, 20.000000000000014, -24.9999999999998, -3.3999999999998693, 20.000000000000014, 29.600000000000183, 1.0999999999999723, 20.000000000000014, 73.09999999999955, 21.80000000000004, 122.59999999999954, 22.700000000000024, 20.000000000000014, 30.800000000000196, 36.20000000000026, 128.29999999999987, -15.699999999999761, -24.099999999999746, -40.89999999999983, 20.000000000000014, 25.400000000000112, 27.20000000000013, 24.50000000000008, 50.60000000000023, 20.000000000000014, 20.000000000000014, 30.80000000000011, 28.100000000000158, -16.900000000000553, 20.000000000000014, -15.699999999999747, 21.800000000000043, 42.800000000000196, 20.000000000000014, 20.000000000000014, -14.499999999999808, 5.300000000000033, 20.000000000000014, -63.10000000000061, 20.000000000000014, -9.399999999999947, 75.79999999999956, -36.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.900000000000084, 80.29999999999947, 79.39999999999932, 20.000000000000014, -0.7000000000000294, -37.899999999999764, -10.900000000000018, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000025, 81.79999999999939, 20.000000000000014, 37.70000000000005, 17.899999999999988, -23.80000000000028, 127.69999999999985, 131.59999999999994, -20.199999999999747, 28.10000000000005, 145.99999999999966, 20.000000000000014, -141.7000000000004, 20.000000000000014, -3.099999999999869, 67.39999999999989, 34.40000000000003, 53.900000000000205, 20.000000000000014, 26.300000000000058, 20.000000000000014, -15.999999999999774, 11.0000000000001, 42.5000000000001, -11.49999999999983, 20.000000000000014, 145.99999999999966, 104.90000000000009, 29.600000000000115, 5.299999999999965, 42.200000000000145, 20.000000000000014, 24.50000000000008, 64.10000000000021, 86.29999999999993, -10.599999999999886, 74.59999999999988, 135.49999999999986, 21.800000000000047, 78.4999999999994, 38.29999999999998, 20.000000000000014, 69.49999999999977, 20.000000000000014, 9.499999999999966, 51.800000000000026, 145.09999999999965, -24.099999999999746, -61.900000000000766, -26.199999999999783, 9.499999999999964, -38.79999999999983, 20.000000000000014, 48.80000000000024, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 11.0, 25.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 4.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 25.0, 0.0, 7.0, 4.0, 17.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 29.0, 0.0, 0.0, 7.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 8.0, 14.0, 88.0, 70.0, 0.0, 7.0, 16.0, 37.0, 0.0, 2.0, 4.0, 0.0, 14.0, 27.0, 0.0, 0.0, 40.0, 0.0, 24.0, 30.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 25.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 42.0, 0.0, 17.0, 9.0, 1.0, 11.0, 0.0, 25.0, 22.0, 0.0, 50.0, 2.0, 37.0, 0.0, 27.0, 0.0, 0.0, 0.0, 1.0, 11.0, 0.0, 0.0, 35.0, 23.0, 15.0, 43.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 30.0, 51.0, 0.0, 6.0, 20.0, 0.0, 0.0, 77.0, 6.0, 10.0, 15.0, 0.0, 37.0, 3.0, 3.0, 0.0, 0.0, 55.0, 12.0, 0.0, 15.0, 0.0, 0.0, 0.0, 12.0, 15.0, 0.0, 0.0, 0.0, 7.0, 0.0, 24.0, 0.0, 18.0, 14.0, 5.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 41.0, 39.0, 28.0, 27.0, 0.0, 0.0, 28.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0806005338208768, "mean_inference_ms": 2.892353270302524, "mean_action_processing_ms": 0.5745275062558806, "mean_env_wait_ms": 0.6737374355704117, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004758238792419434, "StateBufferConnector_ms": 0.0034112930297851562, "ViewRequirementAgentConnector_ms": 0.12171614170074463}, "num_episodes": 27, "episode_return_max": 237.89999999999955, "episode_return_min": -38.69999999999977, "episode_return_mean": 69.72299999999987, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 298.52764438582193, "num_env_steps_trained_throughput_per_sec": 298.52764438582193, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 16031.349, "restore_workers_time_ms": 0.015, "training_step_time_ms": 16030.48, "sample_time_ms": 2278.308, "learn_time_ms": 13730.593, "learn_throughput": 291.32, "synch_weights_time_ms": 17.643}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "c52aa_00000", "date": "2024-08-12_23-55-55", "timestamp": 1723521355, "time_this_iter_s": 13.457329034805298, "time_total_s": 483.3304030895233, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc09670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 483.3304030895233, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 74.09473684210525, "ram_util_percent": 83.53157894736843}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3904470157213311, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.357334362388288, "policy_loss": -0.006826706723280488, "vf_loss": 2.362811360094282, "vf_explained_var": 0.21922238122218501, "kl": 0.018958886025148017, "entropy": 1.3346909046803832, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3300337258489832, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3657235572498942, "policy_loss": -0.003101457908463778, "vf_loss": 0.36862894184185224, "vf_explained_var": 0.019040847549993526, "kl": 0.009295362353627408, "entropy": 1.503210345777885, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 237.89999999999955, "episode_reward_min": -38.69999999999977, "episode_reward_mean": 71.36599999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -141.7000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 145.99999999999966, "predator_policy": 88.0}, "policy_reward_mean": {"prey_policy": 26.632999999999996, "predator_policy": 9.05}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 84.09999999999904, 177.09999999999917, 40.9000000000003, 22.500000000000096, 21.800000000000015, 44.200000000000216, 71.49999999999999, 72.39999999999989, 73.30000000000018, 116.69999999999905, 129.79999999999922, 40.0000000000003, 110.19999999999983, 82.29999999999906, 65.20000000000041, 42.700000000000294, 87.69999999999999, 95.89999999999986, 25.19999999999988, 35.00000000000023, 4.200000000000012, 37.80000000000027, 49.10000000000045, 40.80000000000009, 64.30000000000047, -3.999999999999852, 25.60000000000033, 56.60000000000048, 30.100000000000154, 94.89999999999844, 145.29999999999882, 50.80000000000048, 175.49999999999898, -14.799999999999523, 8.099999999999929, 52.600000000000406, 75.09999999999968, 40.0000000000003, 64.9000000000003, 45.10000000000029, 32.100000000000186, 74.79999999999966, 30.500000000000156, 47.300000000000324, 8.900000000000237, 103.39999999999903, 10.30000000000006, 40.0000000000003, 116.1999999999988, 99.39999999999864, 19.400000000000052, 67.1, 40.0000000000003, 62.500000000000504, 102.7999999999987, 87.59999999999977, 154.89999999999972, 137.3999999999997, 174.09999999999897, -38.69999999999977, 41.90000000000024, 138.79999999999959, 79.89999999999932, 46.30000000000029, 62.00000000000011, 46.00000000000015, 165.99999999999892, 146.49999999999974, 62.500000000000355, 44.50000000000036, 157.39999999999972, 87.99999999999974, 189.2999999999991, 121.79999999999896, 89.49999999999928, 34.50000000000023, 237.89999999999955, -18.999999999999517, 10.299999999999988, 9.199999999999926, 68.80000000000015, 147.09999999999954, 42.700000000000294, 40.0000000000003, 46.30000000000029, 87.89999999999904, 62.800000000000445, 173.6999999999992, 40.0000000000003, 63.400000000000404, 40.0000000000003, 101.19999999999925, 142.1999999999989, 74.69999999999966, 47.90000000000024, 120.79999999999836, 40.0000000000003, 113.29999999999872, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 64.10000000000021, 82.99999999999929, 82.09999999999998, 20.900000000000013, 20.000000000000014, 20.000000000000014, -26.499999999999815, 9.499999999999964, 5.299999999999965, 20.000000000000014, 0.20000000000010423, 31.700000000000212, 39.800000000000225, 52.40000000000023, 20.000000000000014, 20.000000000000014, 53.29999999999996, 35.60000000000002, 55.10000000000022, 25.400000000000105, 76.39999999999978, 20.000000000000014, 20.000000000000014, 90.19999999999992, 20.000000000000014, 44.30000000000016, 20.000000000000014, 45.200000000000244, 20.000000000000014, 20.000000000000014, 22.700000000000063, 20.000000000000014, 49.70000000000012, 53.90000000000011, 20.000000000000014, -29.200000000000045, -103.60000000000016, 7.999999999999966, 20.000000000000014, -11.799999999999828, -36.999999999999886, 20.000000000000014, 15.799999999999963, 33.500000000000234, 11.599999999999964, -3.3999999999998622, 3.1999999999999615, 44.30000000000024, 20.000000000000014, -64.00000000000071, 20.000000000000014, -24.9999999999998, -3.3999999999998693, 20.000000000000014, 29.600000000000183, 1.0999999999999723, 20.000000000000014, 73.09999999999955, 21.80000000000004, 122.59999999999954, 22.700000000000024, 20.000000000000014, 30.800000000000196, 36.20000000000026, 128.29999999999987, -15.699999999999761, -24.099999999999746, -40.89999999999983, 20.000000000000014, 25.400000000000112, 27.20000000000013, 24.50000000000008, 50.60000000000023, 20.000000000000014, 20.000000000000014, 30.80000000000011, 28.100000000000158, -16.900000000000553, 20.000000000000014, -15.699999999999747, 21.800000000000043, 42.800000000000196, 20.000000000000014, 20.000000000000014, -14.499999999999808, 5.300000000000033, 20.000000000000014, -63.10000000000061, 20.000000000000014, -9.399999999999947, 75.79999999999956, -36.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.900000000000084, 80.29999999999947, 79.39999999999932, 20.000000000000014, -0.7000000000000294, -37.899999999999764, -10.900000000000018, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000025, 81.79999999999939, 20.000000000000014, 37.70000000000005, 17.899999999999988, -23.80000000000028, 127.69999999999985, 131.59999999999994, -20.199999999999747, 28.10000000000005, 145.99999999999966, 20.000000000000014, -141.7000000000004, 20.000000000000014, -3.099999999999869, 67.39999999999989, 34.40000000000003, 53.900000000000205, 20.000000000000014, 26.300000000000058, 20.000000000000014, -15.999999999999774, 11.0000000000001, 42.5000000000001, -11.49999999999983, 20.000000000000014, 145.99999999999966, 104.90000000000009, 29.600000000000115, 5.299999999999965, 42.200000000000145, 20.000000000000014, 24.50000000000008, 64.10000000000021, 86.29999999999993, -10.599999999999886, 74.59999999999988, 135.49999999999986, 21.800000000000047, 78.4999999999994, 38.29999999999998, 20.000000000000014, 69.49999999999977, 20.000000000000014, 9.499999999999966, 51.800000000000026, 145.09999999999965, -24.099999999999746, -61.900000000000766, -26.199999999999783, 9.499999999999964, -38.79999999999983, 20.000000000000014, 48.80000000000024, 20.000000000000014, 106.0999999999997, -21.9999999999999, 22.70000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, -4.600000000000019, -3.1000000000000187, 20.000000000000014, 50.90000000000013, 20.000000000000014, 39.80000000000021, 73.39999999999952, 74.29999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 43.4000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 81.19999999999959, 51.50000000000015, 88.69999999999953, 43.70000000000019, 20.000000000000014, 20.000000000000014, 17.90000000000005, 58.70000000000021, 52.1000000000002, 20.000000000000014, 20.000000000000014, 94.6999999999994, 11.599999999999964, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 29.0, 0.0, 0.0, 7.0, 0.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 8.0, 14.0, 88.0, 70.0, 0.0, 7.0, 16.0, 37.0, 0.0, 2.0, 4.0, 0.0, 14.0, 27.0, 0.0, 0.0, 40.0, 0.0, 24.0, 30.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 25.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 42.0, 0.0, 17.0, 9.0, 1.0, 11.0, 0.0, 25.0, 22.0, 0.0, 50.0, 2.0, 37.0, 0.0, 27.0, 0.0, 0.0, 0.0, 1.0, 11.0, 0.0, 0.0, 35.0, 23.0, 15.0, 43.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 30.0, 51.0, 0.0, 6.0, 20.0, 0.0, 0.0, 77.0, 6.0, 10.0, 15.0, 0.0, 37.0, 3.0, 3.0, 0.0, 0.0, 55.0, 12.0, 0.0, 15.0, 0.0, 0.0, 0.0, 12.0, 15.0, 0.0, 0.0, 0.0, 7.0, 0.0, 24.0, 0.0, 18.0, 14.0, 5.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 41.0, 39.0, 28.0, 27.0, 0.0, 0.0, 28.0, 0.0, 0.0, 49.0, 14.0, 0.0, 0.0, 0.0, 0.0, 31.0, 23.0, 17.0, 0.0, 0.0, 3.0, 3.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 11.0, 0.0, 10.0, 7.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0776390200381782, "mean_inference_ms": 2.8794024337456476, "mean_action_processing_ms": 0.5657394120663725, "mean_env_wait_ms": 0.6688423416767377, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003977656364440918, "StateBufferConnector_ms": 0.0033545494079589844, "ViewRequirementAgentConnector_ms": 0.11955749988555908}, "num_episodes": 18, "episode_return_max": 237.89999999999955, "episode_return_min": -38.69999999999977, "episode_return_mean": 71.36599999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 269.38704310124353, "num_env_steps_trained_throughput_per_sec": 269.38704310124353, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 15942.678, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15941.808, "sample_time_ms": 2194.708, "learn_time_ms": 13727.052, "learn_throughput": 291.395, "synch_weights_time_ms": 16.644}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "c52aa_00000", "date": "2024-08-12_23-56-10", "timestamp": 1723521370, "time_this_iter_s": 14.919287919998169, "time_total_s": 498.2496910095215, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab878f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 498.2496910095215, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 80.46190476190476, "ram_util_percent": 83.31904761904764}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4504029994919188, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.68882331633694, "policy_loss": -0.004999139447322007, "vf_loss": 4.6930007361861135, "vf_explained_var": 0.08417561161455023, "kl": 0.011542351928147185, "entropy": 1.3226441429405615, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3763417714960361, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9034497212165247, "policy_loss": -0.004440406452317441, "vf_loss": 1.9075142938308616, "vf_explained_var": 0.005325525683700723, "kl": 0.01781692658122643, "entropy": 1.4262709797374786, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 237.89999999999955, "episode_reward_min": -64.60000000000016, "episode_reward_mean": 74.29199999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -182.5000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 154.99999999999986, "predator_policy": 122.0}, "policy_reward_mean": {"prey_policy": 26.350999999999985, "predator_policy": 10.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [95.89999999999986, 25.19999999999988, 35.00000000000023, 4.200000000000012, 37.80000000000027, 49.10000000000045, 40.80000000000009, 64.30000000000047, -3.999999999999852, 25.60000000000033, 56.60000000000048, 30.100000000000154, 94.89999999999844, 145.29999999999882, 50.80000000000048, 175.49999999999898, -14.799999999999523, 8.099999999999929, 52.600000000000406, 75.09999999999968, 40.0000000000003, 64.9000000000003, 45.10000000000029, 32.100000000000186, 74.79999999999966, 30.500000000000156, 47.300000000000324, 8.900000000000237, 103.39999999999903, 10.30000000000006, 40.0000000000003, 116.1999999999988, 99.39999999999864, 19.400000000000052, 67.1, 40.0000000000003, 62.500000000000504, 102.7999999999987, 87.59999999999977, 154.89999999999972, 137.3999999999997, 174.09999999999897, -38.69999999999977, 41.90000000000024, 138.79999999999959, 79.89999999999932, 46.30000000000029, 62.00000000000011, 46.00000000000015, 165.99999999999892, 146.49999999999974, 62.500000000000355, 44.50000000000036, 157.39999999999972, 87.99999999999974, 189.2999999999991, 121.79999999999896, 89.49999999999928, 34.50000000000023, 237.89999999999955, -18.999999999999517, 10.299999999999988, 9.199999999999926, 68.80000000000015, 147.09999999999954, 42.700000000000294, 40.0000000000003, 46.30000000000029, 87.89999999999904, 62.800000000000445, 173.6999999999992, 40.0000000000003, 63.400000000000404, 40.0000000000003, 101.19999999999925, 142.1999999999989, 74.69999999999966, 47.90000000000024, 120.79999999999836, 40.0000000000003, 113.29999999999872, 40.0000000000003, 89.99999999999861, 122.49999999999983, 38.90000000000028, 177.5999999999998, 102.80000000000013, 174.9999999999992, 40.0000000000003, 72.30000000000005, 48.600000000000385, 67.0000000000003, 167.79999999999893, 129.59999999999985, 148.69999999999882, -64.60000000000016, 161.59999999999923, 40.0000000000003, 82.29999999999917, 14.90000000000012], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [53.90000000000011, 20.000000000000014, -29.200000000000045, -103.60000000000016, 7.999999999999966, 20.000000000000014, -11.799999999999828, -36.999999999999886, 20.000000000000014, 15.799999999999963, 33.500000000000234, 11.599999999999964, -3.3999999999998622, 3.1999999999999615, 44.30000000000024, 20.000000000000014, -64.00000000000071, 20.000000000000014, -24.9999999999998, -3.3999999999998693, 20.000000000000014, 29.600000000000183, 1.0999999999999723, 20.000000000000014, 73.09999999999955, 21.80000000000004, 122.59999999999954, 22.700000000000024, 20.000000000000014, 30.800000000000196, 36.20000000000026, 128.29999999999987, -15.699999999999761, -24.099999999999746, -40.89999999999983, 20.000000000000014, 25.400000000000112, 27.20000000000013, 24.50000000000008, 50.60000000000023, 20.000000000000014, 20.000000000000014, 30.80000000000011, 28.100000000000158, -16.900000000000553, 20.000000000000014, -15.699999999999747, 21.800000000000043, 42.800000000000196, 20.000000000000014, 20.000000000000014, -14.499999999999808, 5.300000000000033, 20.000000000000014, -63.10000000000061, 20.000000000000014, -9.399999999999947, 75.79999999999956, -36.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.900000000000084, 80.29999999999947, 79.39999999999932, 20.000000000000014, -0.7000000000000294, -37.899999999999764, -10.900000000000018, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000025, 81.79999999999939, 20.000000000000014, 37.70000000000005, 17.899999999999988, -23.80000000000028, 127.69999999999985, 131.59999999999994, -20.199999999999747, 28.10000000000005, 145.99999999999966, 20.000000000000014, -141.7000000000004, 20.000000000000014, -3.099999999999869, 67.39999999999989, 34.40000000000003, 53.900000000000205, 20.000000000000014, 26.300000000000058, 20.000000000000014, -15.999999999999774, 11.0000000000001, 42.5000000000001, -11.49999999999983, 20.000000000000014, 145.99999999999966, 104.90000000000009, 29.600000000000115, 5.299999999999965, 42.200000000000145, 20.000000000000014, 24.50000000000008, 64.10000000000021, 86.29999999999993, -10.599999999999886, 74.59999999999988, 135.49999999999986, 21.800000000000047, 78.4999999999994, 38.29999999999998, 20.000000000000014, 69.49999999999977, 20.000000000000014, 9.499999999999966, 51.800000000000026, 145.09999999999965, -24.099999999999746, -61.900000000000766, -26.199999999999783, 9.499999999999964, -38.79999999999983, 20.000000000000014, 48.80000000000024, 20.000000000000014, 106.0999999999997, -21.9999999999999, 22.70000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, -4.600000000000019, -3.1000000000000187, 20.000000000000014, 50.90000000000013, 20.000000000000014, 39.80000000000021, 73.39999999999952, 74.29999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 43.4000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 81.19999999999959, 51.50000000000015, 88.69999999999953, 43.70000000000019, 20.000000000000014, 20.000000000000014, 17.90000000000005, 58.70000000000021, 52.1000000000002, 20.000000000000014, 20.000000000000014, 94.6999999999994, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.99999999999991, 43.40000000000003, 46.10000000000008, 17.899999999999988, 20.000000000000014, -6.400000000000077, 97.99999999999977, 72.80000000000001, 20.000000000000014, 154.99999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, 45.50000000000001, -23.199999999999747, 20.000000000000014, 17.59999999999999, 47.000000000000085, 20.000000000000014, 20.90000000000003, 146.8999999999999, 107.00000000000006, 2.5999999999999694, 127.69999999999956, 20.000000000000014, -182.5000000000001, -78.10000000000005, 107.59999999999982, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 62.30000000000022, 1.0999999999999865, -53.19999999999995], "policy_predator_policy_reward": [8.0, 14.0, 88.0, 70.0, 0.0, 7.0, 16.0, 37.0, 0.0, 2.0, 4.0, 0.0, 14.0, 27.0, 0.0, 0.0, 40.0, 0.0, 24.0, 30.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 25.0, 0.0, 29.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 42.0, 0.0, 17.0, 9.0, 1.0, 11.0, 0.0, 25.0, 22.0, 0.0, 50.0, 2.0, 37.0, 0.0, 27.0, 0.0, 0.0, 0.0, 1.0, 11.0, 0.0, 0.0, 35.0, 23.0, 15.0, 43.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 30.0, 51.0, 0.0, 6.0, 20.0, 0.0, 0.0, 77.0, 6.0, 10.0, 15.0, 0.0, 37.0, 3.0, 3.0, 0.0, 0.0, 55.0, 12.0, 0.0, 15.0, 0.0, 0.0, 0.0, 12.0, 15.0, 0.0, 0.0, 0.0, 7.0, 0.0, 24.0, 0.0, 18.0, 14.0, 5.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 41.0, 39.0, 28.0, 27.0, 0.0, 0.0, 28.0, 0.0, 0.0, 49.0, 14.0, 0.0, 0.0, 0.0, 0.0, 31.0, 23.0, 17.0, 0.0, 0.0, 3.0, 3.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 11.0, 0.0, 10.0, 7.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 2.0, 9.0, 24.0, 1.0, 0.0, 64.0, 22.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 1.0, 0.0, 122.0, 74.0, 16.0, 18.0, 0.0, 0.0, 0.0, 0.0, 9.0, 58.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.07174787860639, "mean_inference_ms": 2.8603791633632216, "mean_action_processing_ms": 0.5593298315076559, "mean_env_wait_ms": 0.6639506974924011, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003845810890197754, "StateBufferConnector_ms": 0.003316640853881836, "ViewRequirementAgentConnector_ms": 0.1165928840637207}, "num_episodes": 18, "episode_return_max": 237.89999999999955, "episode_return_min": -64.60000000000016, "episode_return_mean": 74.29199999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 285.3910205543019, "num_env_steps_trained_throughput_per_sec": 285.3910205543019, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 14667.574, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14666.702, "sample_time_ms": 2146.002, "learn_time_ms": 12501.811, "learn_throughput": 319.954, "synch_weights_time_ms": 15.257}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "c52aa_00000", "date": "2024-08-12_23-56-24", "timestamp": 1723521384, "time_this_iter_s": 14.10013198852539, "time_total_s": 512.3498229980469, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab873af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 512.3498229980469, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 77.695, "ram_util_percent": 82.97999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5063867045852242, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.573496040591487, "policy_loss": -0.005807703001197999, "vf_loss": 4.578371046838306, "vf_explained_var": 0.04965729631444134, "kl": 0.013101351080690837, "entropy": 1.3384170309576409, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.409713118956991, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.226895079852412, "policy_loss": -0.0038587627321402863, "vf_loss": 2.230519979214542, "vf_explained_var": 0.010547980681929008, "kl": 0.011086753005518113, "entropy": 1.3750843888237363, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 237.89999999999955, "episode_reward_min": -64.60000000000016, "episode_reward_mean": 81.83799999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -182.5000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 154.99999999999986, "predator_policy": 122.0}, "policy_reward_mean": {"prey_policy": 28.36399999999997, "predator_policy": 12.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [52.600000000000406, 75.09999999999968, 40.0000000000003, 64.9000000000003, 45.10000000000029, 32.100000000000186, 74.79999999999966, 30.500000000000156, 47.300000000000324, 8.900000000000237, 103.39999999999903, 10.30000000000006, 40.0000000000003, 116.1999999999988, 99.39999999999864, 19.400000000000052, 67.1, 40.0000000000003, 62.500000000000504, 102.7999999999987, 87.59999999999977, 154.89999999999972, 137.3999999999997, 174.09999999999897, -38.69999999999977, 41.90000000000024, 138.79999999999959, 79.89999999999932, 46.30000000000029, 62.00000000000011, 46.00000000000015, 165.99999999999892, 146.49999999999974, 62.500000000000355, 44.50000000000036, 157.39999999999972, 87.99999999999974, 189.2999999999991, 121.79999999999896, 89.49999999999928, 34.50000000000023, 237.89999999999955, -18.999999999999517, 10.299999999999988, 9.199999999999926, 68.80000000000015, 147.09999999999954, 42.700000000000294, 40.0000000000003, 46.30000000000029, 87.89999999999904, 62.800000000000445, 173.6999999999992, 40.0000000000003, 63.400000000000404, 40.0000000000003, 101.19999999999925, 142.1999999999989, 74.69999999999966, 47.90000000000024, 120.79999999999836, 40.0000000000003, 113.29999999999872, 40.0000000000003, 89.99999999999861, 122.49999999999983, 38.90000000000028, 177.5999999999998, 102.80000000000013, 174.9999999999992, 40.0000000000003, 72.30000000000005, 48.600000000000385, 67.0000000000003, 167.79999999999893, 129.59999999999985, 148.69999999999882, -64.60000000000016, 161.59999999999923, 40.0000000000003, 82.29999999999917, 14.90000000000012, 27.900000000000123, 91.89999999999927, -15.000000000000512, 34.40000000000021, 210.9999999999999, 12.899999999999958, 62.99999999999973, 73.79999999999967, 166.89999999999958, 124.29999999999879, 156.39999999999955, 40.0000000000003, 207.49999999999963, 163.19999999999953, 110.09999999999933, -41.499999999999865, 146.69999999999982, 101.49999999999923], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [25.400000000000112, 27.20000000000013, 24.50000000000008, 50.60000000000023, 20.000000000000014, 20.000000000000014, 30.80000000000011, 28.100000000000158, -16.900000000000553, 20.000000000000014, -15.699999999999747, 21.800000000000043, 42.800000000000196, 20.000000000000014, 20.000000000000014, -14.499999999999808, 5.300000000000033, 20.000000000000014, -63.10000000000061, 20.000000000000014, -9.399999999999947, 75.79999999999956, -36.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.900000000000084, 80.29999999999947, 79.39999999999932, 20.000000000000014, -0.7000000000000294, -37.899999999999764, -10.900000000000018, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 42.50000000000025, 81.79999999999939, 20.000000000000014, 37.70000000000005, 17.899999999999988, -23.80000000000028, 127.69999999999985, 131.59999999999994, -20.199999999999747, 28.10000000000005, 145.99999999999966, 20.000000000000014, -141.7000000000004, 20.000000000000014, -3.099999999999869, 67.39999999999989, 34.40000000000003, 53.900000000000205, 20.000000000000014, 26.300000000000058, 20.000000000000014, -15.999999999999774, 11.0000000000001, 42.5000000000001, -11.49999999999983, 20.000000000000014, 145.99999999999966, 104.90000000000009, 29.600000000000115, 5.299999999999965, 42.200000000000145, 20.000000000000014, 24.50000000000008, 64.10000000000021, 86.29999999999993, -10.599999999999886, 74.59999999999988, 135.49999999999986, 21.800000000000047, 78.4999999999994, 38.29999999999998, 20.000000000000014, 69.49999999999977, 20.000000000000014, 9.499999999999966, 51.800000000000026, 145.09999999999965, -24.099999999999746, -61.900000000000766, -26.199999999999783, 9.499999999999964, -38.79999999999983, 20.000000000000014, 48.80000000000024, 20.000000000000014, 106.0999999999997, -21.9999999999999, 22.70000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, -4.600000000000019, -3.1000000000000187, 20.000000000000014, 50.90000000000013, 20.000000000000014, 39.80000000000021, 73.39999999999952, 74.29999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 43.4000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 81.19999999999959, 51.50000000000015, 88.69999999999953, 43.70000000000019, 20.000000000000014, 20.000000000000014, 17.90000000000005, 58.70000000000021, 52.1000000000002, 20.000000000000014, 20.000000000000014, 94.6999999999994, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.99999999999991, 43.40000000000003, 46.10000000000008, 17.899999999999988, 20.000000000000014, -6.400000000000077, 97.99999999999977, 72.80000000000001, 20.000000000000014, 154.99999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, 45.50000000000001, -23.199999999999747, 20.000000000000014, 17.59999999999999, 47.000000000000085, 20.000000000000014, 20.90000000000003, 146.8999999999999, 107.00000000000006, 2.5999999999999694, 127.69999999999956, 20.000000000000014, -182.5000000000001, -78.10000000000005, 107.59999999999982, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 62.30000000000022, 1.0999999999999865, -53.19999999999995, -21.099999999999802, 20.000000000000014, 20.000000000000014, -0.0999999999999904, -179.50000000000054, 69.49999999999997, 18.8, 11.599999999999964, 59.599999999999966, 151.4000000000001, -39.099999999999774, 20.000000000000014, -27.4, 25.40000000000011, 56.000000000000085, 15.799999999999962, 80.2999999999997, 86.59999999999985, 20.000000000000014, 98.29999999999947, -43.599999999999895, 110.0, 20.000000000000014, 20.000000000000014, 44.000000000000014, 96.49999999999969, 38.30000000000002, 74.89999999999945, 118.9999999999995, -103.90000000000023, -149.50000000000009, 20.000000000000014, 23.899999999999977, 90.79999999999998, 121.69999999999956, -107.20000000000041], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 42.0, 0.0, 17.0, 9.0, 1.0, 11.0, 0.0, 25.0, 22.0, 0.0, 50.0, 2.0, 37.0, 0.0, 27.0, 0.0, 0.0, 0.0, 1.0, 11.0, 0.0, 0.0, 35.0, 23.0, 15.0, 43.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 30.0, 51.0, 0.0, 6.0, 20.0, 0.0, 0.0, 77.0, 6.0, 10.0, 15.0, 0.0, 37.0, 3.0, 3.0, 0.0, 0.0, 55.0, 12.0, 0.0, 15.0, 0.0, 0.0, 0.0, 12.0, 15.0, 0.0, 0.0, 0.0, 7.0, 0.0, 24.0, 0.0, 18.0, 14.0, 5.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 41.0, 39.0, 28.0, 27.0, 0.0, 0.0, 28.0, 0.0, 0.0, 49.0, 14.0, 0.0, 0.0, 0.0, 0.0, 31.0, 23.0, 17.0, 0.0, 0.0, 3.0, 3.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 11.0, 0.0, 10.0, 7.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 2.0, 9.0, 24.0, 1.0, 0.0, 64.0, 22.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 1.0, 0.0, 122.0, 74.0, 16.0, 18.0, 0.0, 0.0, 0.0, 0.0, 9.0, 58.0, 15.0, 14.0, 44.0, 28.0, 95.0, 0.0, 4.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 65.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 46.0, 44.0, 0.0, 0.0, 49.0, 18.0, 24.0, 26.0, 26.0, 69.0, 35.0, 53.0, 14.0, 18.0, 66.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0663307918137297, "mean_inference_ms": 2.8422986438325695, "mean_action_processing_ms": 0.5535429174606775, "mean_env_wait_ms": 0.6593700256670669, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041654109954833984, "StateBufferConnector_ms": 0.0034418106079101562, "ViewRequirementAgentConnector_ms": 0.13075053691864014}, "num_episodes": 18, "episode_return_max": 237.89999999999955, "episode_return_min": -64.60000000000016, "episode_return_mean": 81.83799999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.4024196647456, "num_env_steps_trained_throughput_per_sec": 290.4024196647456, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 14318.215, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14317.344, "sample_time_ms": 2124.059, "learn_time_ms": 12174.206, "learn_throughput": 328.564, "synch_weights_time_ms": 15.11}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "c52aa_00000", "date": "2024-08-12_23-56-38", "timestamp": 1723521398, "time_this_iter_s": 13.897425889968872, "time_total_s": 526.2472488880157, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc095e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 526.2472488880157, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 74.605, "ram_util_percent": 83.04499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.520733272970196, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.035181630729999, "policy_loss": -0.0011656783014861128, "vf_loss": 4.035920274699175, "vf_explained_var": 0.10343810174831007, "kl": 0.00599841916918748, "entropy": 1.3044564296959569, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4267654167911994, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4767868276626344, "policy_loss": -0.003116283279956964, "vf_loss": 1.4796322810744482, "vf_explained_var": 0.006193953531759756, "kl": 0.012839364667600484, "entropy": 1.314268781583776, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 237.89999999999955, "episode_reward_min": -69.60000000000096, "episode_reward_mean": 80.99199999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -182.5000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 167.3, "predator_policy": 122.0}, "policy_reward_mean": {"prey_policy": 25.900999999999957, "predator_policy": 14.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [137.3999999999997, 174.09999999999897, -38.69999999999977, 41.90000000000024, 138.79999999999959, 79.89999999999932, 46.30000000000029, 62.00000000000011, 46.00000000000015, 165.99999999999892, 146.49999999999974, 62.500000000000355, 44.50000000000036, 157.39999999999972, 87.99999999999974, 189.2999999999991, 121.79999999999896, 89.49999999999928, 34.50000000000023, 237.89999999999955, -18.999999999999517, 10.299999999999988, 9.199999999999926, 68.80000000000015, 147.09999999999954, 42.700000000000294, 40.0000000000003, 46.30000000000029, 87.89999999999904, 62.800000000000445, 173.6999999999992, 40.0000000000003, 63.400000000000404, 40.0000000000003, 101.19999999999925, 142.1999999999989, 74.69999999999966, 47.90000000000024, 120.79999999999836, 40.0000000000003, 113.29999999999872, 40.0000000000003, 89.99999999999861, 122.49999999999983, 38.90000000000028, 177.5999999999998, 102.80000000000013, 174.9999999999992, 40.0000000000003, 72.30000000000005, 48.600000000000385, 67.0000000000003, 167.79999999999893, 129.59999999999985, 148.69999999999882, -64.60000000000016, 161.59999999999923, 40.0000000000003, 82.29999999999917, 14.90000000000012, 27.900000000000123, 91.89999999999927, -15.000000000000512, 34.40000000000021, 210.9999999999999, 12.899999999999958, 62.99999999999973, 73.79999999999967, 166.89999999999958, 124.29999999999879, 156.39999999999955, 40.0000000000003, 207.49999999999963, 163.19999999999953, 110.09999999999933, -41.499999999999865, 146.69999999999982, 101.49999999999923, 36.10000000000021, 171.9999999999995, 127.7999999999995, 4.800000000000143, 53.600000000000215, 180.19999999999936, 22.100000000000243, 43.40000000000028, 22.900000000000027, 87.29999999999991, -10.199999999999685, 200.79999999999893, 64.30000000000037, 32.30000000000019, -69.60000000000096, 33.0000000000002, 100.99999999999869, -47.399999999999835, -2.799999999999591, 187.79999999999924, -31.599999999999817, 82.49999999999906], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [131.59999999999994, -20.199999999999747, 28.10000000000005, 145.99999999999966, 20.000000000000014, -141.7000000000004, 20.000000000000014, -3.099999999999869, 67.39999999999989, 34.40000000000003, 53.900000000000205, 20.000000000000014, 26.300000000000058, 20.000000000000014, -15.999999999999774, 11.0000000000001, 42.5000000000001, -11.49999999999983, 20.000000000000014, 145.99999999999966, 104.90000000000009, 29.600000000000115, 5.299999999999965, 42.200000000000145, 20.000000000000014, 24.50000000000008, 64.10000000000021, 86.29999999999993, -10.599999999999886, 74.59999999999988, 135.49999999999986, 21.800000000000047, 78.4999999999994, 38.29999999999998, 20.000000000000014, 69.49999999999977, 20.000000000000014, 9.499999999999966, 51.800000000000026, 145.09999999999965, -24.099999999999746, -61.900000000000766, -26.199999999999783, 9.499999999999964, -38.79999999999983, 20.000000000000014, 48.80000000000024, 20.000000000000014, 106.0999999999997, -21.9999999999999, 22.70000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, -4.600000000000019, -3.1000000000000187, 20.000000000000014, 50.90000000000013, 20.000000000000014, 39.80000000000021, 73.39999999999952, 74.29999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 43.4000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 81.19999999999959, 51.50000000000015, 88.69999999999953, 43.70000000000019, 20.000000000000014, 20.000000000000014, 17.90000000000005, 58.70000000000021, 52.1000000000002, 20.000000000000014, 20.000000000000014, 94.6999999999994, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.99999999999991, 43.40000000000003, 46.10000000000008, 17.899999999999988, 20.000000000000014, -6.400000000000077, 97.99999999999977, 72.80000000000001, 20.000000000000014, 154.99999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, 45.50000000000001, -23.199999999999747, 20.000000000000014, 17.59999999999999, 47.000000000000085, 20.000000000000014, 20.90000000000003, 146.8999999999999, 107.00000000000006, 2.5999999999999694, 127.69999999999956, 20.000000000000014, -182.5000000000001, -78.10000000000005, 107.59999999999982, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 62.30000000000022, 1.0999999999999865, -53.19999999999995, -21.099999999999802, 20.000000000000014, 20.000000000000014, -0.0999999999999904, -179.50000000000054, 69.49999999999997, 18.8, 11.599999999999964, 59.599999999999966, 151.4000000000001, -39.099999999999774, 20.000000000000014, -27.4, 25.40000000000011, 56.000000000000085, 15.799999999999962, 80.2999999999997, 86.59999999999985, 20.000000000000014, 98.29999999999947, -43.599999999999895, 110.0, 20.000000000000014, 20.000000000000014, 44.000000000000014, 96.49999999999969, 38.30000000000002, 74.89999999999945, 118.9999999999995, -103.90000000000023, -149.50000000000009, 20.000000000000014, 23.899999999999977, 90.79999999999998, 121.69999999999956, -107.20000000000041, 22.700000000000028, 7.399999999999979, 167.3, -28.29999999999975, -24.999999999999844, 93.79999999999986, 20.000000000000014, -47.19999999999977, 28.70000000000008, 20.90000000000003, 141.2, 20.000000000000014, -52.60000000000007, 13.699999999999967, 22.400000000000066, 20.000000000000014, 20.90000000000003, -15.999999999999746, 12.500000000000107, 9.799999999999983, -57.70000000000045, -74.50000000000014, 114.49999999999946, 71.29999999999961, 35.30000000000004, 10.99999999999998, 20.000000000000014, 5.299999999999974, -114.40000000000049, -26.199999999999918, 20.000000000000014, 4.999999999999968, 82.09999999999937, 17.899999999999988, -130.6000000000001, 3.199999999999992, 8.90000000000004, -57.69999999999977, 20.000000000000014, 147.79999999999995, -72.40000000000026, -92.20000000000066, -36.099999999999824, 68.59999999999988], "policy_predator_policy_reward": [6.0, 20.0, 0.0, 0.0, 77.0, 6.0, 10.0, 15.0, 0.0, 37.0, 3.0, 3.0, 0.0, 0.0, 55.0, 12.0, 0.0, 15.0, 0.0, 0.0, 0.0, 12.0, 15.0, 0.0, 0.0, 0.0, 7.0, 0.0, 24.0, 0.0, 18.0, 14.0, 5.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 41.0, 39.0, 28.0, 27.0, 0.0, 0.0, 28.0, 0.0, 0.0, 49.0, 14.0, 0.0, 0.0, 0.0, 0.0, 31.0, 23.0, 17.0, 0.0, 0.0, 3.0, 3.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 11.0, 0.0, 10.0, 7.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 2.0, 9.0, 24.0, 1.0, 0.0, 64.0, 22.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 1.0, 0.0, 122.0, 74.0, 16.0, 18.0, 0.0, 0.0, 0.0, 0.0, 9.0, 58.0, 15.0, 14.0, 44.0, 28.0, 95.0, 0.0, 4.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 65.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 46.0, 44.0, 0.0, 0.0, 49.0, 18.0, 24.0, 26.0, 26.0, 69.0, 35.0, 53.0, 14.0, 18.0, 66.0, 21.0, 6.0, 0.0, 23.0, 10.0, 21.0, 38.0, 32.0, 0.0, 0.0, 4.0, 8.0, 11.0, 21.0, 40.0, 1.0, 0.0, 18.0, 0.0, 40.0, 25.0, 34.0, 88.0, 15.0, 0.0, 0.0, 18.0, 0.0, 7.0, 71.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 80.0, 24.0, 22.0, 12.0, 8.0, 45.0, 88.0, 40.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0599753551382034, "mean_inference_ms": 2.82525387381781, "mean_action_processing_ms": 0.5464759537768629, "mean_env_wait_ms": 0.6551865637786358, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004262804985046387, "StateBufferConnector_ms": 0.0035043954849243164, "ViewRequirementAgentConnector_ms": 0.13661456108093262}, "num_episodes": 22, "episode_return_max": 237.89999999999955, "episode_return_min": -69.60000000000096, "episode_return_mean": 80.99199999999978, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 260.8529490867683, "num_env_steps_trained_throughput_per_sec": 260.8529490867683, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 14512.385, "restore_workers_time_ms": 0.014, "training_step_time_ms": 14511.515, "sample_time_ms": 2138.415, "learn_time_ms": 12354.142, "learn_throughput": 323.778, "synch_weights_time_ms": 14.854}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "c52aa_00000", "date": "2024-08-12_23-56-53", "timestamp": 1723521413, "time_this_iter_s": 15.419946908950806, "time_total_s": 541.6671957969666, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc09700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 541.6671957969666, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 80.24285714285715, "ram_util_percent": 83.45238095238096}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.671123516007706, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5645205712192274, "policy_loss": -0.0016381326056376258, "vf_loss": 3.565419935044788, "vf_explained_var": 0.04748352362365319, "kl": 0.010377225778517284, "entropy": 1.2569679490472905, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4429992875133557, "cur_kl_coeff": 0.02109375, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5197176325258124, "policy_loss": -0.002166306343368161, "vf_loss": 1.521821313024198, "vf_explained_var": 0.001600193252008428, "kl": 0.002968758501757668, "entropy": 1.304264216700559, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 223.2999999999991, "episode_reward_min": -123.500000000001, "episode_reward_mean": 75.73799999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -262.6999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 167.3, "predator_policy": 157.0}, "policy_reward_mean": {"prey_policy": 22.20899999999996, "predator_policy": 15.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [68.80000000000015, 147.09999999999954, 42.700000000000294, 40.0000000000003, 46.30000000000029, 87.89999999999904, 62.800000000000445, 173.6999999999992, 40.0000000000003, 63.400000000000404, 40.0000000000003, 101.19999999999925, 142.1999999999989, 74.69999999999966, 47.90000000000024, 120.79999999999836, 40.0000000000003, 113.29999999999872, 40.0000000000003, 89.99999999999861, 122.49999999999983, 38.90000000000028, 177.5999999999998, 102.80000000000013, 174.9999999999992, 40.0000000000003, 72.30000000000005, 48.600000000000385, 67.0000000000003, 167.79999999999893, 129.59999999999985, 148.69999999999882, -64.60000000000016, 161.59999999999923, 40.0000000000003, 82.29999999999917, 14.90000000000012, 27.900000000000123, 91.89999999999927, -15.000000000000512, 34.40000000000021, 210.9999999999999, 12.899999999999958, 62.99999999999973, 73.79999999999967, 166.89999999999958, 124.29999999999879, 156.39999999999955, 40.0000000000003, 207.49999999999963, 163.19999999999953, 110.09999999999933, -41.499999999999865, 146.69999999999982, 101.49999999999923, 36.10000000000021, 171.9999999999995, 127.7999999999995, 4.800000000000143, 53.600000000000215, 180.19999999999936, 22.100000000000243, 43.40000000000028, 22.900000000000027, 87.29999999999991, -10.199999999999685, 200.79999999999893, 64.30000000000037, 32.30000000000019, -69.60000000000096, 33.0000000000002, 100.99999999999869, -47.399999999999835, -2.799999999999591, 187.79999999999924, -31.599999999999817, 82.49999999999906, -43.89999999999983, 142.79999999999936, 18.100000000000065, 58.00000000000034, 77.59999999999992, 6.000000000000156, 32.400000000000176, 2.599999999999947, 202.09999999999903, 86.99999999999883, -123.500000000001, 108.79999999999984, 28.200000000000003, 95.79999999999967, 60.100000000000335, 223.2999999999991, 143.59999999999874, 135.89999999999876, 57.70000000000019, 24.100000000000048, 84.09999999999904, 75.09999999999968, 4.80000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [48.80000000000024, 20.000000000000014, 106.0999999999997, -21.9999999999999, 22.70000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, -4.600000000000019, -3.1000000000000187, 20.000000000000014, 50.90000000000013, 20.000000000000014, 39.80000000000021, 73.39999999999952, 74.29999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 43.4000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 81.19999999999959, 51.50000000000015, 88.69999999999953, 43.70000000000019, 20.000000000000014, 20.000000000000014, 17.90000000000005, 58.70000000000021, 52.1000000000002, 20.000000000000014, 20.000000000000014, 94.6999999999994, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 67.99999999999991, 43.40000000000003, 46.10000000000008, 17.899999999999988, 20.000000000000014, -6.400000000000077, 97.99999999999977, 72.80000000000001, 20.000000000000014, 154.99999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, 45.50000000000001, -23.199999999999747, 20.000000000000014, 17.59999999999999, 47.000000000000085, 20.000000000000014, 20.90000000000003, 146.8999999999999, 107.00000000000006, 2.5999999999999694, 127.69999999999956, 20.000000000000014, -182.5000000000001, -78.10000000000005, 107.59999999999982, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 62.30000000000022, 1.0999999999999865, -53.19999999999995, -21.099999999999802, 20.000000000000014, 20.000000000000014, -0.0999999999999904, -179.50000000000054, 69.49999999999997, 18.8, 11.599999999999964, 59.599999999999966, 151.4000000000001, -39.099999999999774, 20.000000000000014, -27.4, 25.40000000000011, 56.000000000000085, 15.799999999999962, 80.2999999999997, 86.59999999999985, 20.000000000000014, 98.29999999999947, -43.599999999999895, 110.0, 20.000000000000014, 20.000000000000014, 44.000000000000014, 96.49999999999969, 38.30000000000002, 74.89999999999945, 118.9999999999995, -103.90000000000023, -149.50000000000009, 20.000000000000014, 23.899999999999977, 90.79999999999998, 121.69999999999956, -107.20000000000041, 22.700000000000028, 7.399999999999979, 167.3, -28.29999999999975, -24.999999999999844, 93.79999999999986, 20.000000000000014, -47.19999999999977, 28.70000000000008, 20.90000000000003, 141.2, 20.000000000000014, -52.60000000000007, 13.699999999999967, 22.400000000000066, 20.000000000000014, 20.90000000000003, -15.999999999999746, 12.500000000000107, 9.799999999999983, -57.70000000000045, -74.50000000000014, 114.49999999999946, 71.29999999999961, 35.30000000000004, 10.99999999999998, 20.000000000000014, 5.299999999999974, -114.40000000000049, -26.199999999999918, 20.000000000000014, 4.999999999999968, 82.09999999999937, 17.899999999999988, -130.6000000000001, 3.199999999999992, 8.90000000000004, -57.69999999999977, 20.000000000000014, 147.79999999999995, -72.40000000000026, -92.20000000000066, -36.099999999999824, 68.59999999999988, -110.80000000000064, -24.099999999999746, 34.40000000000006, 100.39999999999976, -24.099999999999746, 0.2000000000001143, 20.000000000000014, 38.00000000000016, 50.30000000000023, 26.30000000000001, -53.500000000000135, 24.500000000000096, 1.4000000000000619, 20.000000000000014, 20.000000000000014, -51.399999999999885, 131.5999999999996, 57.50000000000016, 26.30000000000012, 52.70000000000022, -262.6999999999996, -17.79999999999977, -17.799999999999756, 104.59999999999997, 13.699999999999964, -128.5000000000004, 51.50000000000004, 44.300000000000246, -50.200000000000685, 71.29999999999964, 85.69999999999945, 125.59999999999964, 83.89999999999932, 19.700000000000124, 118.09999999999948, 15.799999999999963, 20.000000000000014, 13.69999999999997, 27.20000000000013, -24.099999999999746, 64.10000000000021, 20.000000000000014, 20.000000000000014, 55.10000000000022, -45.09999999999977, 17.899999999999988], "policy_predator_policy_reward": [0.0, 0.0, 49.0, 14.0, 0.0, 0.0, 0.0, 0.0, 31.0, 23.0, 17.0, 0.0, 0.0, 3.0, 3.0, 23.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 11.0, 0.0, 10.0, 7.0, 3.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 2.0, 9.0, 24.0, 1.0, 0.0, 64.0, 22.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 1.0, 0.0, 122.0, 74.0, 16.0, 18.0, 0.0, 0.0, 0.0, 0.0, 9.0, 58.0, 15.0, 14.0, 44.0, 28.0, 95.0, 0.0, 4.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 65.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 46.0, 44.0, 0.0, 0.0, 49.0, 18.0, 24.0, 26.0, 26.0, 69.0, 35.0, 53.0, 14.0, 18.0, 66.0, 21.0, 6.0, 0.0, 23.0, 10.0, 21.0, 38.0, 32.0, 0.0, 0.0, 4.0, 8.0, 11.0, 21.0, 40.0, 1.0, 0.0, 18.0, 0.0, 40.0, 25.0, 34.0, 88.0, 15.0, 0.0, 0.0, 18.0, 0.0, 7.0, 71.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 80.0, 24.0, 22.0, 12.0, 8.0, 45.0, 88.0, 40.0, 10.0, 81.0, 10.0, 8.0, 0.0, 21.0, 21.0, 0.0, 0.0, 0.0, 1.0, 0.0, 35.0, 0.0, 11.0, 26.0, 8.0, 13.0, 0.0, 8.0, 0.0, 0.0, 157.0, 22.0, 0.0, 62.0, 81.0, 0.0, 0.0, 39.0, 0.0, 0.0, 12.0, 15.0, 25.0, 2.0, 0.0, 0.0, 24.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 31.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0556991544879655, "mean_inference_ms": 2.8100526899827956, "mean_action_processing_ms": 0.5407857538305527, "mean_env_wait_ms": 0.6520846033149517, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004230380058288574, "StateBufferConnector_ms": 0.0034750699996948242, "ViewRequirementAgentConnector_ms": 0.15489792823791504}, "num_episodes": 23, "episode_return_max": 223.2999999999991, "episode_return_min": -123.500000000001, "episode_return_mean": 75.73799999999974, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.0067602605232, "num_env_steps_trained_throughput_per_sec": 210.0067602605232, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 15092.438, "restore_workers_time_ms": 0.014, "training_step_time_ms": 15091.567, "sample_time_ms": 2181.332, "learn_time_ms": 12890.782, "learn_throughput": 310.299, "synch_weights_time_ms": 15.597}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "c52aa_00000", "date": "2024-08-12_23-57-13", "timestamp": 1723521433, "time_this_iter_s": 19.163621187210083, "time_total_s": 560.8308169841766, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87e310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 560.8308169841766, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 92.42857142857142, "ram_util_percent": 83.43928571428572}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.529376475907192, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2177760987054733, "policy_loss": -0.001756248666742255, "vf_loss": 2.2188615592068466, "vf_explained_var": 0.03785240164509526, "kl": 0.00942238255518077, "entropy": 1.2534278740958562, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4485362613563815, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1404282722523604, "policy_loss": -0.002577535333062606, "vf_loss": 1.142910522443277, "vf_explained_var": 0.0006262592537693246, "kl": 0.009034224128714626, "entropy": 1.289564813444854, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 223.2999999999991, "episode_reward_min": -152.5000000000006, "episode_reward_mean": 67.76099999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -262.6999999999996, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 167.3, "predator_policy": 157.0}, "policy_reward_mean": {"prey_policy": 17.065499999999965, "predator_policy": 16.815}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 89.99999999999861, 122.49999999999983, 38.90000000000028, 177.5999999999998, 102.80000000000013, 174.9999999999992, 40.0000000000003, 72.30000000000005, 48.600000000000385, 67.0000000000003, 167.79999999999893, 129.59999999999985, 148.69999999999882, -64.60000000000016, 161.59999999999923, 40.0000000000003, 82.29999999999917, 14.90000000000012, 27.900000000000123, 91.89999999999927, -15.000000000000512, 34.40000000000021, 210.9999999999999, 12.899999999999958, 62.99999999999973, 73.79999999999967, 166.89999999999958, 124.29999999999879, 156.39999999999955, 40.0000000000003, 207.49999999999963, 163.19999999999953, 110.09999999999933, -41.499999999999865, 146.69999999999982, 101.49999999999923, 36.10000000000021, 171.9999999999995, 127.7999999999995, 4.800000000000143, 53.600000000000215, 180.19999999999936, 22.100000000000243, 43.40000000000028, 22.900000000000027, 87.29999999999991, -10.199999999999685, 200.79999999999893, 64.30000000000037, 32.30000000000019, -69.60000000000096, 33.0000000000002, 100.99999999999869, -47.399999999999835, -2.799999999999591, 187.79999999999924, -31.599999999999817, 82.49999999999906, -43.89999999999983, 142.79999999999936, 18.100000000000065, 58.00000000000034, 77.59999999999992, 6.000000000000156, 32.400000000000176, 2.599999999999947, 202.09999999999903, 86.99999999999883, -123.500000000001, 108.79999999999984, 28.200000000000003, 95.79999999999967, 60.100000000000335, 223.2999999999991, 143.59999999999874, 135.89999999999876, 57.70000000000019, 24.100000000000048, 84.09999999999904, 75.09999999999968, 4.80000000000015, 34.8000000000002, -152.5000000000006, 23.800000000000058, 35.80000000000044, 40.0000000000003, 19.099999999999955, 45.2000000000003, 36.70000000000025, -21.000000000000036, 40.40000000000032, 108.39999999999876, 51.90000000000046, 73.29999999999983, 48.10000000000043, 27.80000000000016, 54.40000000000052, 57.100000000000456, 131.7999999999984], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 67.99999999999991, 43.40000000000003, 46.10000000000008, 17.899999999999988, 20.000000000000014, -6.400000000000077, 97.99999999999977, 72.80000000000001, 20.000000000000014, 154.99999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, 45.50000000000001, -23.199999999999747, 20.000000000000014, 17.59999999999999, 47.000000000000085, 20.000000000000014, 20.90000000000003, 146.8999999999999, 107.00000000000006, 2.5999999999999694, 127.69999999999956, 20.000000000000014, -182.5000000000001, -78.10000000000005, 107.59999999999982, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 62.30000000000022, 1.0999999999999865, -53.19999999999995, -21.099999999999802, 20.000000000000014, 20.000000000000014, -0.0999999999999904, -179.50000000000054, 69.49999999999997, 18.8, 11.599999999999964, 59.599999999999966, 151.4000000000001, -39.099999999999774, 20.000000000000014, -27.4, 25.40000000000011, 56.000000000000085, 15.799999999999962, 80.2999999999997, 86.59999999999985, 20.000000000000014, 98.29999999999947, -43.599999999999895, 110.0, 20.000000000000014, 20.000000000000014, 44.000000000000014, 96.49999999999969, 38.30000000000002, 74.89999999999945, 118.9999999999995, -103.90000000000023, -149.50000000000009, 20.000000000000014, 23.899999999999977, 90.79999999999998, 121.69999999999956, -107.20000000000041, 22.700000000000028, 7.399999999999979, 167.3, -28.29999999999975, -24.999999999999844, 93.79999999999986, 20.000000000000014, -47.19999999999977, 28.70000000000008, 20.90000000000003, 141.2, 20.000000000000014, -52.60000000000007, 13.699999999999967, 22.400000000000066, 20.000000000000014, 20.90000000000003, -15.999999999999746, 12.500000000000107, 9.799999999999983, -57.70000000000045, -74.50000000000014, 114.49999999999946, 71.29999999999961, 35.30000000000004, 10.99999999999998, 20.000000000000014, 5.299999999999974, -114.40000000000049, -26.199999999999918, 20.000000000000014, 4.999999999999968, 82.09999999999937, 17.899999999999988, -130.6000000000001, 3.199999999999992, 8.90000000000004, -57.69999999999977, 20.000000000000014, 147.79999999999995, -72.40000000000026, -92.20000000000066, -36.099999999999824, 68.59999999999988, -110.80000000000064, -24.099999999999746, 34.40000000000006, 100.39999999999976, -24.099999999999746, 0.2000000000001143, 20.000000000000014, 38.00000000000016, 50.30000000000023, 26.30000000000001, -53.500000000000135, 24.500000000000096, 1.4000000000000619, 20.000000000000014, 20.000000000000014, -51.399999999999885, 131.5999999999996, 57.50000000000016, 26.30000000000012, 52.70000000000022, -262.6999999999996, -17.79999999999977, -17.799999999999756, 104.59999999999997, 13.699999999999964, -128.5000000000004, 51.50000000000004, 44.300000000000246, -50.200000000000685, 71.29999999999964, 85.69999999999945, 125.59999999999964, 83.89999999999932, 19.700000000000124, 118.09999999999948, 15.799999999999963, 20.000000000000014, 13.69999999999997, 27.20000000000013, -24.099999999999746, 64.10000000000021, 20.000000000000014, 20.000000000000014, 55.10000000000022, -45.09999999999977, 17.899999999999988, 28.10000000000016, -28.299999999999883, -194.20000000000005, -133.30000000000072, -3.6999999999999975, 9.49999999999997, 20.000000000000014, -14.199999999999838, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.899999999999743, 20.000000000000014, 24.20000000000009, 20.000000000000014, 13.699999999999964, -67.90000000000063, -30.099999999999845, 7.39999999999997, 20.00000000000002, 88.39999999999941, 20.000000000000014, -30.39999999999975, 53.30000000000023, 20.000000000000014, 53.30000000000023, 20.000000000000014, 28.100000000000147, -26.199999999999818, 20.000000000000014, 20.000000000000014, 34.40000000000026, 20.000000000000014, 37.10000000000022, 56.90000000000022, 74.89999999999941], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 2.0, 9.0, 24.0, 1.0, 0.0, 64.0, 22.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 1.0, 0.0, 122.0, 74.0, 16.0, 18.0, 0.0, 0.0, 0.0, 0.0, 9.0, 58.0, 15.0, 14.0, 44.0, 28.0, 95.0, 0.0, 4.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 65.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 46.0, 44.0, 0.0, 0.0, 49.0, 18.0, 24.0, 26.0, 26.0, 69.0, 35.0, 53.0, 14.0, 18.0, 66.0, 21.0, 6.0, 0.0, 23.0, 10.0, 21.0, 38.0, 32.0, 0.0, 0.0, 4.0, 8.0, 11.0, 21.0, 40.0, 1.0, 0.0, 18.0, 0.0, 40.0, 25.0, 34.0, 88.0, 15.0, 0.0, 0.0, 18.0, 0.0, 7.0, 71.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 80.0, 24.0, 22.0, 12.0, 8.0, 45.0, 88.0, 40.0, 10.0, 81.0, 10.0, 8.0, 0.0, 21.0, 21.0, 0.0, 0.0, 0.0, 1.0, 0.0, 35.0, 0.0, 11.0, 26.0, 8.0, 13.0, 0.0, 8.0, 0.0, 0.0, 157.0, 22.0, 0.0, 62.0, 81.0, 0.0, 0.0, 39.0, 0.0, 0.0, 12.0, 15.0, 25.0, 2.0, 0.0, 0.0, 24.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 31.0, 1.0, 35.0, 0.0, 73.0, 102.0, 0.0, 18.0, 30.0, 0.0, 0.0, 0.0, 18.0, 1.0, 1.0, 0.0, 0.0, 3.0, 4.0, 73.0, 0.0, 13.0, 0.0, 0.0, 5.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0583497786721912, "mean_inference_ms": 2.817516366814753, "mean_action_processing_ms": 0.5386847970579962, "mean_env_wait_ms": 0.6536788870318736, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004373788833618164, "StateBufferConnector_ms": 0.0036170482635498047, "ViewRequirementAgentConnector_ms": 0.18998181819915771}, "num_episodes": 18, "episode_return_max": 223.2999999999991, "episode_return_min": -152.5000000000006, "episode_return_mean": 67.76099999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 234.3879084052291, "num_env_steps_trained_throughput_per_sec": 234.3879084052291, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 15091.61, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15091.55, "sample_time_ms": 2304.614, "learn_time_ms": 12766.897, "learn_throughput": 313.31, "synch_weights_time_ms": 16.581}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "c52aa_00000", "date": "2024-08-12_23-57-30", "timestamp": 1723521450, "time_this_iter_s": 17.119285106658936, "time_total_s": 577.9501020908356, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab873940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 577.9501020908356, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 80.9625, "ram_util_percent": 83.74166666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9351372262748776, "cur_kl_coeff": 0.07119140624999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.803364970129003, "policy_loss": -0.005743452209348559, "vf_loss": 2.807184613949407, "vf_explained_var": 0.006076087459685311, "kl": 0.02702307874338954, "entropy": 1.1674893270724664, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4174836696968192, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9077361042222019, "policy_loss": -0.003573201635665206, "vf_loss": 1.911171792518525, "vf_explained_var": 0.0003931013680008984, "kl": 0.013038377100992768, "entropy": 1.2578621987943297, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 223.2999999999991, "episode_reward_min": -612.9, "episode_reward_mean": 49.11599999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -547.4000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 167.3, "predator_policy": 434.0}, "policy_reward_mean": {"prey_policy": 4.712999999999971, "predator_policy": 19.845}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.90000000000012, 27.900000000000123, 91.89999999999927, -15.000000000000512, 34.40000000000021, 210.9999999999999, 12.899999999999958, 62.99999999999973, 73.79999999999967, 166.89999999999958, 124.29999999999879, 156.39999999999955, 40.0000000000003, 207.49999999999963, 163.19999999999953, 110.09999999999933, -41.499999999999865, 146.69999999999982, 101.49999999999923, 36.10000000000021, 171.9999999999995, 127.7999999999995, 4.800000000000143, 53.600000000000215, 180.19999999999936, 22.100000000000243, 43.40000000000028, 22.900000000000027, 87.29999999999991, -10.199999999999685, 200.79999999999893, 64.30000000000037, 32.30000000000019, -69.60000000000096, 33.0000000000002, 100.99999999999869, -47.399999999999835, -2.799999999999591, 187.79999999999924, -31.599999999999817, 82.49999999999906, -43.89999999999983, 142.79999999999936, 18.100000000000065, 58.00000000000034, 77.59999999999992, 6.000000000000156, 32.400000000000176, 2.599999999999947, 202.09999999999903, 86.99999999999883, -123.500000000001, 108.79999999999984, 28.200000000000003, 95.79999999999967, 60.100000000000335, 223.2999999999991, 143.59999999999874, 135.89999999999876, 57.70000000000019, 24.100000000000048, 84.09999999999904, 75.09999999999968, 4.80000000000015, 34.8000000000002, -152.5000000000006, 23.800000000000058, 35.80000000000044, 40.0000000000003, 19.099999999999955, 45.2000000000003, 36.70000000000025, -21.000000000000036, 40.40000000000032, 108.39999999999876, 51.90000000000046, 73.29999999999983, 48.10000000000043, 27.80000000000016, 54.40000000000052, 57.100000000000456, 131.7999999999984, 43.699999999999946, -44.19999999999965, -92.89999999999989, 3.200000000000159, 71.49999999999999, 70.5, 58.100000000000456, 40.0000000000003, 58.10000000000027, 82.29999999999917, -24.899999999999537, 40.0000000000003, -612.9, 68.19999999999868, 47.90000000000044, 62.50000000000051, 71.79999999999977, -167.30000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999865, -53.19999999999995, -21.099999999999802, 20.000000000000014, 20.000000000000014, -0.0999999999999904, -179.50000000000054, 69.49999999999997, 18.8, 11.599999999999964, 59.599999999999966, 151.4000000000001, -39.099999999999774, 20.000000000000014, -27.4, 25.40000000000011, 56.000000000000085, 15.799999999999962, 80.2999999999997, 86.59999999999985, 20.000000000000014, 98.29999999999947, -43.599999999999895, 110.0, 20.000000000000014, 20.000000000000014, 44.000000000000014, 96.49999999999969, 38.30000000000002, 74.89999999999945, 118.9999999999995, -103.90000000000023, -149.50000000000009, 20.000000000000014, 23.899999999999977, 90.79999999999998, 121.69999999999956, -107.20000000000041, 22.700000000000028, 7.399999999999979, 167.3, -28.29999999999975, -24.999999999999844, 93.79999999999986, 20.000000000000014, -47.19999999999977, 28.70000000000008, 20.90000000000003, 141.2, 20.000000000000014, -52.60000000000007, 13.699999999999967, 22.400000000000066, 20.000000000000014, 20.90000000000003, -15.999999999999746, 12.500000000000107, 9.799999999999983, -57.70000000000045, -74.50000000000014, 114.49999999999946, 71.29999999999961, 35.30000000000004, 10.99999999999998, 20.000000000000014, 5.299999999999974, -114.40000000000049, -26.199999999999918, 20.000000000000014, 4.999999999999968, 82.09999999999937, 17.899999999999988, -130.6000000000001, 3.199999999999992, 8.90000000000004, -57.69999999999977, 20.000000000000014, 147.79999999999995, -72.40000000000026, -92.20000000000066, -36.099999999999824, 68.59999999999988, -110.80000000000064, -24.099999999999746, 34.40000000000006, 100.39999999999976, -24.099999999999746, 0.2000000000001143, 20.000000000000014, 38.00000000000016, 50.30000000000023, 26.30000000000001, -53.500000000000135, 24.500000000000096, 1.4000000000000619, 20.000000000000014, 20.000000000000014, -51.399999999999885, 131.5999999999996, 57.50000000000016, 26.30000000000012, 52.70000000000022, -262.6999999999996, -17.79999999999977, -17.799999999999756, 104.59999999999997, 13.699999999999964, -128.5000000000004, 51.50000000000004, 44.300000000000246, -50.200000000000685, 71.29999999999964, 85.69999999999945, 125.59999999999964, 83.89999999999932, 19.700000000000124, 118.09999999999948, 15.799999999999963, 20.000000000000014, 13.69999999999997, 27.20000000000013, -24.099999999999746, 64.10000000000021, 20.000000000000014, 20.000000000000014, 55.10000000000022, -45.09999999999977, 17.899999999999988, 28.10000000000016, -28.299999999999883, -194.20000000000005, -133.30000000000072, -3.6999999999999975, 9.49999999999997, 20.000000000000014, -14.199999999999838, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.899999999999743, 20.000000000000014, 24.20000000000009, 20.000000000000014, 13.699999999999964, -67.90000000000063, -30.099999999999845, 7.39999999999997, 20.00000000000002, 88.39999999999941, 20.000000000000014, -30.39999999999975, 53.30000000000023, 20.000000000000014, 53.30000000000023, 20.000000000000014, 28.100000000000147, -26.199999999999818, 20.000000000000014, 20.000000000000014, 34.40000000000026, 20.000000000000014, 37.10000000000022, 56.90000000000022, 74.89999999999941, 55.10000000000023, -42.400000000000006, -17.799999999999827, -114.40000000000002, -127.0000000000004, -103.8999999999999, -59.800000000000594, 20.000000000000014, 33.50000000000024, 38.000000000000256, 45.50000000000022, 20.000000000000014, 20.000000000000014, 34.1000000000002, 20.000000000000014, 20.000000000000014, 24.50000000000008, 2.600000000000011, 38.900000000000254, 43.400000000000205, -99.70000000000076, 15.799999999999963, 20.000000000000014, 20.000000000000014, -499.5, -547.4000000000001, 18.19999999999945, 20.000000000000014, 13.999999999999966, 26.900000000000134, 42.50000000000025, 20.000000000000014, 20.000000000000014, 39.800000000000196, -332.80000000000007, -2.499999999999787], "policy_predator_policy_reward": [9.0, 58.0, 15.0, 14.0, 44.0, 28.0, 95.0, 0.0, 4.0, 0.0, 0.0, 0.0, 32.0, 0.0, 0.0, 65.0, 2.0, 0.0, 0.0, 0.0, 6.0, 0.0, 46.0, 44.0, 0.0, 0.0, 49.0, 18.0, 24.0, 26.0, 26.0, 69.0, 35.0, 53.0, 14.0, 18.0, 66.0, 21.0, 6.0, 0.0, 23.0, 10.0, 21.0, 38.0, 32.0, 0.0, 0.0, 4.0, 8.0, 11.0, 21.0, 40.0, 1.0, 0.0, 18.0, 0.0, 40.0, 25.0, 34.0, 88.0, 15.0, 0.0, 0.0, 18.0, 0.0, 7.0, 71.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 80.0, 24.0, 22.0, 12.0, 8.0, 45.0, 88.0, 40.0, 10.0, 81.0, 10.0, 8.0, 0.0, 21.0, 21.0, 0.0, 0.0, 0.0, 1.0, 0.0, 35.0, 0.0, 11.0, 26.0, 8.0, 13.0, 0.0, 8.0, 0.0, 0.0, 157.0, 22.0, 0.0, 62.0, 81.0, 0.0, 0.0, 39.0, 0.0, 0.0, 12.0, 15.0, 25.0, 2.0, 0.0, 0.0, 24.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 31.0, 1.0, 35.0, 0.0, 73.0, 102.0, 0.0, 18.0, 30.0, 0.0, 0.0, 0.0, 18.0, 1.0, 1.0, 0.0, 0.0, 3.0, 4.0, 73.0, 0.0, 13.0, 0.0, 0.0, 5.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 64.0, 24.0, 138.0, 0.0, 13.0, 30.0, 0.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 2.0, 57.0, 0.0, 0.0, 0.0, 434.0, 28.0, 2.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 168.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0645857754025947, "mean_inference_ms": 2.8378512759680774, "mean_action_processing_ms": 0.5389957064538582, "mean_env_wait_ms": 0.6570863755494989, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009290218353271484, "StateBufferConnector_ms": 0.0037643909454345703, "ViewRequirementAgentConnector_ms": 0.20253455638885498}, "num_episodes": 18, "episode_return_max": 223.2999999999991, "episode_return_min": -612.9, "episode_return_mean": 49.11599999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 249.68094914982626, "num_env_steps_trained_throughput_per_sec": 249.68094914982626, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 15285.81, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15285.756, "sample_time_ms": 2491.716, "learn_time_ms": 12773.742, "learn_throughput": 313.142, "synch_weights_time_ms": 16.872}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "c52aa_00000", "date": "2024-08-12_23-57-46", "timestamp": 1723521466, "time_this_iter_s": 16.089915990829468, "time_total_s": 594.040018081665, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab873310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 594.040018081665, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 79.20869565217392, "ram_util_percent": 83.48260869565217}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9366480142311759, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6238364830218925, "policy_loss": -0.001621473776964993, "vf_loss": 2.624737237874793, "vf_explained_var": -0.0003785346550916238, "kl": 0.0067492400849135875, "entropy": 1.1857941177156237, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43881019294734985, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7231666554849614, "policy_loss": -0.0023109932321680603, "vf_loss": 1.7253193006944405, "vf_explained_var": 0.00021286004434817682, "kl": 0.015013991608747208, "entropy": 1.18820962193151, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 223.2999999999991, "episode_reward_min": -612.9, "episode_reward_mean": 30.640999999999927, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -554.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 147.79999999999995, "predator_policy": 530.0}, "policy_reward_mean": {"prey_policy": -5.414500000000009, "predator_policy": 20.735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.800000000000143, 53.600000000000215, 180.19999999999936, 22.100000000000243, 43.40000000000028, 22.900000000000027, 87.29999999999991, -10.199999999999685, 200.79999999999893, 64.30000000000037, 32.30000000000019, -69.60000000000096, 33.0000000000002, 100.99999999999869, -47.399999999999835, -2.799999999999591, 187.79999999999924, -31.599999999999817, 82.49999999999906, -43.89999999999983, 142.79999999999936, 18.100000000000065, 58.00000000000034, 77.59999999999992, 6.000000000000156, 32.400000000000176, 2.599999999999947, 202.09999999999903, 86.99999999999883, -123.500000000001, 108.79999999999984, 28.200000000000003, 95.79999999999967, 60.100000000000335, 223.2999999999991, 143.59999999999874, 135.89999999999876, 57.70000000000019, 24.100000000000048, 84.09999999999904, 75.09999999999968, 4.80000000000015, 34.8000000000002, -152.5000000000006, 23.800000000000058, 35.80000000000044, 40.0000000000003, 19.099999999999955, 45.2000000000003, 36.70000000000025, -21.000000000000036, 40.40000000000032, 108.39999999999876, 51.90000000000046, 73.29999999999983, 48.10000000000043, 27.80000000000016, 54.40000000000052, 57.100000000000456, 131.7999999999984, 43.699999999999946, -44.19999999999965, -92.89999999999989, 3.200000000000159, 71.49999999999999, 70.5, 58.100000000000456, 40.0000000000003, 58.10000000000027, 82.29999999999917, -24.899999999999537, 40.0000000000003, -612.9, 68.19999999999868, 47.90000000000044, 62.50000000000051, 71.79999999999977, -167.30000000000015, -37.59999999999989, -81.90000000000126, 40.0000000000003, 86.29999999999883, -122.50000000000026, 54.40000000000052, 44.10000000000037, 37.80000000000027, 40.0000000000003, 40.0000000000003, 63.10000000000048, -233.60000000000002, 24.600000000000062, 40.0000000000003, -38.599999999999774, -68.69999999999985, 50.80000000000048, 76.6999999999996, 40.0000000000003, 27.90000000000011, 39.30000000000029, 56.20000000000046], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -47.19999999999977, 28.70000000000008, 20.90000000000003, 141.2, 20.000000000000014, -52.60000000000007, 13.699999999999967, 22.400000000000066, 20.000000000000014, 20.90000000000003, -15.999999999999746, 12.500000000000107, 9.799999999999983, -57.70000000000045, -74.50000000000014, 114.49999999999946, 71.29999999999961, 35.30000000000004, 10.99999999999998, 20.000000000000014, 5.299999999999974, -114.40000000000049, -26.199999999999918, 20.000000000000014, 4.999999999999968, 82.09999999999937, 17.899999999999988, -130.6000000000001, 3.199999999999992, 8.90000000000004, -57.69999999999977, 20.000000000000014, 147.79999999999995, -72.40000000000026, -92.20000000000066, -36.099999999999824, 68.59999999999988, -110.80000000000064, -24.099999999999746, 34.40000000000006, 100.39999999999976, -24.099999999999746, 0.2000000000001143, 20.000000000000014, 38.00000000000016, 50.30000000000023, 26.30000000000001, -53.500000000000135, 24.500000000000096, 1.4000000000000619, 20.000000000000014, 20.000000000000014, -51.399999999999885, 131.5999999999996, 57.50000000000016, 26.30000000000012, 52.70000000000022, -262.6999999999996, -17.79999999999977, -17.799999999999756, 104.59999999999997, 13.699999999999964, -128.5000000000004, 51.50000000000004, 44.300000000000246, -50.200000000000685, 71.29999999999964, 85.69999999999945, 125.59999999999964, 83.89999999999932, 19.700000000000124, 118.09999999999948, 15.799999999999963, 20.000000000000014, 13.69999999999997, 27.20000000000013, -24.099999999999746, 64.10000000000021, 20.000000000000014, 20.000000000000014, 55.10000000000022, -45.09999999999977, 17.899999999999988, 28.10000000000016, -28.299999999999883, -194.20000000000005, -133.30000000000072, -3.6999999999999975, 9.49999999999997, 20.000000000000014, -14.199999999999838, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.899999999999743, 20.000000000000014, 24.20000000000009, 20.000000000000014, 13.699999999999964, -67.90000000000063, -30.099999999999845, 7.39999999999997, 20.00000000000002, 88.39999999999941, 20.000000000000014, -30.39999999999975, 53.30000000000023, 20.000000000000014, 53.30000000000023, 20.000000000000014, 28.100000000000147, -26.199999999999818, 20.000000000000014, 20.000000000000014, 34.40000000000026, 20.000000000000014, 37.10000000000022, 56.90000000000022, 74.89999999999941, 55.10000000000023, -42.400000000000006, -17.799999999999827, -114.40000000000002, -127.0000000000004, -103.8999999999999, -59.800000000000594, 20.000000000000014, 33.50000000000024, 38.000000000000256, 45.50000000000022, 20.000000000000014, 20.000000000000014, 34.1000000000002, 20.000000000000014, 20.000000000000014, 24.50000000000008, 2.600000000000011, 38.900000000000254, 43.400000000000205, -99.70000000000076, 15.799999999999963, 20.000000000000014, 20.000000000000014, -499.5, -547.4000000000001, 18.19999999999945, 20.000000000000014, 13.999999999999966, 26.900000000000134, 42.50000000000025, 20.000000000000014, 20.000000000000014, 39.800000000000196, -332.80000000000007, -2.499999999999787, -130.60000000000002, 20.000000000000014, -144.40000000000052, -32.49999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 59.30000000000019, 20.000000000000014, -311.5, 34.400000000000254, 20.000000000000014, 13.099999999999973, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.100000000000158, 20.000000000000014, -209.10000000000002, -554.5, -9.39999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999986, -162.10000000000008, -195.70000000000005, 20.000000000000014, 30.800000000000196, 20.000000000000014, 35.90000000000024, 39.80000000000025, 20.000000000000014, 20.000000000000014, -3.099999999999965, 20.000000000000014, 11.299999999999969, 20.000000000000014, 27.20000000000014, 29.000000000000163], "policy_predator_policy_reward": [32.0, 0.0, 0.0, 4.0, 8.0, 11.0, 21.0, 40.0, 1.0, 0.0, 18.0, 0.0, 40.0, 25.0, 34.0, 88.0, 15.0, 0.0, 0.0, 18.0, 0.0, 7.0, 71.0, 0.0, 0.0, 8.0, 1.0, 0.0, 0.0, 80.0, 24.0, 22.0, 12.0, 8.0, 45.0, 88.0, 40.0, 10.0, 81.0, 10.0, 8.0, 0.0, 21.0, 21.0, 0.0, 0.0, 0.0, 1.0, 0.0, 35.0, 0.0, 11.0, 26.0, 8.0, 13.0, 0.0, 8.0, 0.0, 0.0, 157.0, 22.0, 0.0, 62.0, 81.0, 0.0, 0.0, 39.0, 0.0, 0.0, 12.0, 15.0, 25.0, 2.0, 0.0, 0.0, 24.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 31.0, 1.0, 35.0, 0.0, 73.0, 102.0, 0.0, 18.0, 30.0, 0.0, 0.0, 0.0, 18.0, 1.0, 1.0, 0.0, 0.0, 3.0, 4.0, 73.0, 0.0, 13.0, 0.0, 0.0, 5.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 64.0, 24.0, 138.0, 0.0, 13.0, 30.0, 0.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 2.0, 57.0, 0.0, 0.0, 0.0, 434.0, 28.0, 2.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 168.0, 0.0, 73.0, 0.0, 95.0, 0.0, 0.0, 7.0, 0.0, 169.0, 0.0, 0.0, 0.0, 5.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 530.0, 14.0, 0.0, 0.0, 0.0, 94.0, 20.0, 107.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 11.0, 0.0, 0.0, 8.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0719443075684274, "mean_inference_ms": 2.867257678553153, "mean_action_processing_ms": 0.539840602393355, "mean_env_wait_ms": 0.6619526535878086, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009480953216552734, "StateBufferConnector_ms": 0.0037279129028320312, "ViewRequirementAgentConnector_ms": 0.21659839153289795}, "num_episodes": 22, "episode_return_max": 223.2999999999991, "episode_return_min": -612.9, "episode_return_mean": 30.640999999999927, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 278.88508375313086, "num_env_steps_trained_throughput_per_sec": 278.88508375313086, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 15403.822, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15403.766, "sample_time_ms": 2544.058, "learn_time_ms": 12838.409, "learn_throughput": 311.565, "synch_weights_time_ms": 17.864}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "c52aa_00000", "date": "2024-08-12_23-58-00", "timestamp": 1723521480, "time_this_iter_s": 14.416577100753784, "time_total_s": 608.4565951824188, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87ef70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 608.4565951824188, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 76.245, "ram_util_percent": 83.785}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0212880043835235, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.275809297990547, "policy_loss": -0.003691940991671155, "vf_loss": 4.2779691731488265, "vf_explained_var": 0.002658075630349457, "kl": 0.014346995211626617, "entropy": 1.0898105609984625, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6068399765701206, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.473814334818926, "policy_loss": -0.0018278796201148045, "vf_loss": 3.4755537350972494, "vf_explained_var": 0.002535082738866251, "kl": 0.00838872621849873, "entropy": 1.22630354304793, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 223.2999999999991, "episode_reward_min": -772.4999999999999, "episode_reward_mean": 6.471999999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1022.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 131.5999999999996, "predator_policy": 1104.0}, "policy_reward_mean": {"prey_policy": -30.10399999999999, "predator_policy": 33.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [77.59999999999992, 6.000000000000156, 32.400000000000176, 2.599999999999947, 202.09999999999903, 86.99999999999883, -123.500000000001, 108.79999999999984, 28.200000000000003, 95.79999999999967, 60.100000000000335, 223.2999999999991, 143.59999999999874, 135.89999999999876, 57.70000000000019, 24.100000000000048, 84.09999999999904, 75.09999999999968, 4.80000000000015, 34.8000000000002, -152.5000000000006, 23.800000000000058, 35.80000000000044, 40.0000000000003, 19.099999999999955, 45.2000000000003, 36.70000000000025, -21.000000000000036, 40.40000000000032, 108.39999999999876, 51.90000000000046, 73.29999999999983, 48.10000000000043, 27.80000000000016, 54.40000000000052, 57.100000000000456, 131.7999999999984, 43.699999999999946, -44.19999999999965, -92.89999999999989, 3.200000000000159, 71.49999999999999, 70.5, 58.100000000000456, 40.0000000000003, 58.10000000000027, 82.29999999999917, -24.899999999999537, 40.0000000000003, -612.9, 68.19999999999868, 47.90000000000044, 62.50000000000051, 71.79999999999977, -167.30000000000015, -37.59999999999989, -81.90000000000126, 40.0000000000003, 86.29999999999883, -122.50000000000026, 54.40000000000052, 44.10000000000037, 37.80000000000027, 40.0000000000003, 40.0000000000003, 63.10000000000048, -233.60000000000002, 24.600000000000062, 40.0000000000003, -38.599999999999774, -68.69999999999985, 50.80000000000048, 76.6999999999996, 40.0000000000003, 27.90000000000011, 39.30000000000029, 56.20000000000046, -95.39999999999964, 73.79999999999978, 21.099999999999994, 19.500000000000206, 60.20000000000045, -147.00000000000045, 41.800000000000324, -123.70000000000002, 16.30000000000033, 27.100000000000147, 24.60000000000005, -772.4999999999999, 46.000000000000455, 40.0000000000003, -134.59999999999997, -68.69999999999999, 25.000000000000426, 40.0000000000003, -130.50000000000037, 13.300000000000297, -285.3, 0.20000000000038654, 21.299999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [50.30000000000023, 26.30000000000001, -53.500000000000135, 24.500000000000096, 1.4000000000000619, 20.000000000000014, 20.000000000000014, -51.399999999999885, 131.5999999999996, 57.50000000000016, 26.30000000000012, 52.70000000000022, -262.6999999999996, -17.79999999999977, -17.799999999999756, 104.59999999999997, 13.699999999999964, -128.5000000000004, 51.50000000000004, 44.300000000000246, -50.200000000000685, 71.29999999999964, 85.69999999999945, 125.59999999999964, 83.89999999999932, 19.700000000000124, 118.09999999999948, 15.799999999999963, 20.000000000000014, 13.69999999999997, 27.20000000000013, -24.099999999999746, 64.10000000000021, 20.000000000000014, 20.000000000000014, 55.10000000000022, -45.09999999999977, 17.899999999999988, 28.10000000000016, -28.299999999999883, -194.20000000000005, -133.30000000000072, -3.6999999999999975, 9.49999999999997, 20.000000000000014, -14.199999999999838, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.899999999999743, 20.000000000000014, 24.20000000000009, 20.000000000000014, 13.699999999999964, -67.90000000000063, -30.099999999999845, 7.39999999999997, 20.00000000000002, 88.39999999999941, 20.000000000000014, -30.39999999999975, 53.30000000000023, 20.000000000000014, 53.30000000000023, 20.000000000000014, 28.100000000000147, -26.199999999999818, 20.000000000000014, 20.000000000000014, 34.40000000000026, 20.000000000000014, 37.10000000000022, 56.90000000000022, 74.89999999999941, 55.10000000000023, -42.400000000000006, -17.799999999999827, -114.40000000000002, -127.0000000000004, -103.8999999999999, -59.800000000000594, 20.000000000000014, 33.50000000000024, 38.000000000000256, 45.50000000000022, 20.000000000000014, 20.000000000000014, 34.1000000000002, 20.000000000000014, 20.000000000000014, 24.50000000000008, 2.600000000000011, 38.900000000000254, 43.400000000000205, -99.70000000000076, 15.799999999999963, 20.000000000000014, 20.000000000000014, -499.5, -547.4000000000001, 18.19999999999945, 20.000000000000014, 13.999999999999966, 26.900000000000134, 42.50000000000025, 20.000000000000014, 20.000000000000014, 39.800000000000196, -332.80000000000007, -2.499999999999787, -130.60000000000002, 20.000000000000014, -144.40000000000052, -32.49999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 59.30000000000019, 20.000000000000014, -311.5, 34.400000000000254, 20.000000000000014, 13.099999999999973, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.100000000000158, 20.000000000000014, -209.10000000000002, -554.5, -9.39999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999986, -162.10000000000008, -195.70000000000005, 20.000000000000014, 30.800000000000196, 20.000000000000014, 35.90000000000024, 39.80000000000025, 20.000000000000014, 20.000000000000014, -3.099999999999965, 20.000000000000014, 11.299999999999969, 20.000000000000014, 27.20000000000014, 29.000000000000163, -58.89999999999983, -127.50000000000003, 56.00000000000023, 15.799999999999963, -16.899999999999743, 20.000000000000014, -6.099999999999952, -9.400000000000006, -22.00000000000003, 54.20000000000022, 3.199999999999965, -320.2, 20.000000000000014, 21.80000000000004, -261.9, -113.80000000000004, -45.70000000000002, 20.000000000000014, -40.8999999999998, 20.000000000000014, 20.000000000000014, -9.399999999999855, -1022.5, -873.0, 20.000000000000014, 20.000000000000114, 20.000000000000014, 20.000000000000014, -79.60000000000002, -536.0, -137.10000000000002, -13.600000000000023, -28.300000000000036, 23.300000000000068, 20.000000000000014, 20.000000000000014, 17.899999999999988, -303.4, -608.8999999999999, 63.20000000000021, -269.6, -249.69999999999996, 20.000000000000014, -65.79999999999987, 20.000000000000014, -15.699999999999747], "policy_predator_policy_reward": [0.0, 1.0, 0.0, 35.0, 0.0, 11.0, 26.0, 8.0, 13.0, 0.0, 8.0, 0.0, 0.0, 157.0, 22.0, 0.0, 62.0, 81.0, 0.0, 0.0, 39.0, 0.0, 0.0, 12.0, 15.0, 25.0, 2.0, 0.0, 0.0, 24.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 31.0, 1.0, 35.0, 0.0, 73.0, 102.0, 0.0, 18.0, 30.0, 0.0, 0.0, 0.0, 18.0, 1.0, 1.0, 0.0, 0.0, 3.0, 4.0, 73.0, 0.0, 13.0, 0.0, 0.0, 5.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 64.0, 24.0, 138.0, 0.0, 13.0, 30.0, 0.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 2.0, 57.0, 0.0, 0.0, 0.0, 434.0, 28.0, 2.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 168.0, 0.0, 73.0, 0.0, 95.0, 0.0, 0.0, 7.0, 0.0, 169.0, 0.0, 0.0, 0.0, 5.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 530.0, 14.0, 0.0, 0.0, 0.0, 94.0, 20.0, 107.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 11.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 91.0, 2.0, 0.0, 18.0, 0.0, 14.0, 21.0, 15.0, 13.0, 162.0, 8.0, 0.0, 0.0, 119.0, 133.0, 14.0, 28.0, 37.0, 11.0, 0.0, 14.0, 1104.0, 19.0, 0.0, 6.0, 0.0, 0.0, 19.0, 462.0, 79.0, 3.0, 23.0, 7.0, 0.0, 0.0, 1.0, 154.0, 547.0, 12.0, 234.0, 0.0, 0.0, 46.0, 17.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0772603442743547, "mean_inference_ms": 2.8869764870746093, "mean_action_processing_ms": 0.5428352795385006, "mean_env_wait_ms": 0.6661418107431085, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009563565254211426, "StateBufferConnector_ms": 0.0038509368896484375, "ViewRequirementAgentConnector_ms": 0.20932376384735107}, "num_episodes": 23, "episode_return_max": 223.2999999999991, "episode_return_min": -772.4999999999999, "episode_return_mean": 6.471999999999985, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 314.1617958670457, "num_env_steps_trained_throughput_per_sec": 314.1617958670457, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 15058.016, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15057.956, "sample_time_ms": 2547.919, "learn_time_ms": 12487.385, "learn_throughput": 320.323, "synch_weights_time_ms": 18.946}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "c52aa_00000", "date": "2024-08-12_23-58-13", "timestamp": 1723521493, "time_this_iter_s": 12.782719135284424, "time_total_s": 621.2393143177032, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87eee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 621.2393143177032, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 71.99444444444444, "ram_util_percent": 83.51111111111112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8689079501444386, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.62204454765118, "policy_loss": -0.0030866132723906684, "vf_loss": 3.6243591198845517, "vf_explained_var": 0.0002231435800986315, "kl": 0.0072298064838053604, "entropy": 1.0526341755554158, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.533286192857478, "cur_kl_coeff": 0.010546875, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.07460291391958, "policy_loss": -0.006135604860477898, "vf_loss": 3.0804983414670146, "vf_explained_var": 0.0007008413789133546, "kl": 0.02277237361192969, "entropy": 1.2912859533198926, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 131.7999999999984, "episode_reward_min": -772.4999999999999, "episode_reward_mean": -14.363999999999944, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1022.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 88.39999999999941, "predator_policy": 1104.0}, "policy_reward_mean": {"prey_policy": -51.31199999999999, "predator_policy": 44.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.80000000000015, 34.8000000000002, -152.5000000000006, 23.800000000000058, 35.80000000000044, 40.0000000000003, 19.099999999999955, 45.2000000000003, 36.70000000000025, -21.000000000000036, 40.40000000000032, 108.39999999999876, 51.90000000000046, 73.29999999999983, 48.10000000000043, 27.80000000000016, 54.40000000000052, 57.100000000000456, 131.7999999999984, 43.699999999999946, -44.19999999999965, -92.89999999999989, 3.200000000000159, 71.49999999999999, 70.5, 58.100000000000456, 40.0000000000003, 58.10000000000027, 82.29999999999917, -24.899999999999537, 40.0000000000003, -612.9, 68.19999999999868, 47.90000000000044, 62.50000000000051, 71.79999999999977, -167.30000000000015, -37.59999999999989, -81.90000000000126, 40.0000000000003, 86.29999999999883, -122.50000000000026, 54.40000000000052, 44.10000000000037, 37.80000000000027, 40.0000000000003, 40.0000000000003, 63.10000000000048, -233.60000000000002, 24.600000000000062, 40.0000000000003, -38.599999999999774, -68.69999999999985, 50.80000000000048, 76.6999999999996, 40.0000000000003, 27.90000000000011, 39.30000000000029, 56.20000000000046, -95.39999999999964, 73.79999999999978, 21.099999999999994, 19.500000000000206, 60.20000000000045, -147.00000000000045, 41.800000000000324, -123.70000000000002, 16.30000000000033, 27.100000000000147, 24.60000000000005, -772.4999999999999, 46.000000000000455, 40.0000000000003, -134.59999999999997, -68.69999999999999, 25.000000000000426, 40.0000000000003, -130.50000000000037, 13.300000000000297, -285.3, 0.20000000000038654, 21.299999999999994, 5.900000000000089, -112.90000000000026, -164.8000000000003, -8.399999999999764, 43.60000000000035, 42.600000000000335, 20.999999999999996, -317.4, -75.40000000000111, 65.20000000000039, 8.899999999999917, -33.699999999999875, 24.900000000000063, 34.50000000000022, -219.600000000001, -56.59999999999994, -60.499999999999915, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-45.09999999999977, 17.899999999999988, 28.10000000000016, -28.299999999999883, -194.20000000000005, -133.30000000000072, -3.6999999999999975, 9.49999999999997, 20.000000000000014, -14.199999999999838, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.899999999999743, 20.000000000000014, 24.20000000000009, 20.000000000000014, 13.699999999999964, -67.90000000000063, -30.099999999999845, 7.39999999999997, 20.00000000000002, 88.39999999999941, 20.000000000000014, -30.39999999999975, 53.30000000000023, 20.000000000000014, 53.30000000000023, 20.000000000000014, 28.100000000000147, -26.199999999999818, 20.000000000000014, 20.000000000000014, 34.40000000000026, 20.000000000000014, 37.10000000000022, 56.90000000000022, 74.89999999999941, 55.10000000000023, -42.400000000000006, -17.799999999999827, -114.40000000000002, -127.0000000000004, -103.8999999999999, -59.800000000000594, 20.000000000000014, 33.50000000000024, 38.000000000000256, 45.50000000000022, 20.000000000000014, 20.000000000000014, 34.1000000000002, 20.000000000000014, 20.000000000000014, 24.50000000000008, 2.600000000000011, 38.900000000000254, 43.400000000000205, -99.70000000000076, 15.799999999999963, 20.000000000000014, 20.000000000000014, -499.5, -547.4000000000001, 18.19999999999945, 20.000000000000014, 13.999999999999966, 26.900000000000134, 42.50000000000025, 20.000000000000014, 20.000000000000014, 39.800000000000196, -332.80000000000007, -2.499999999999787, -130.60000000000002, 20.000000000000014, -144.40000000000052, -32.49999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 59.30000000000019, 20.000000000000014, -311.5, 34.400000000000254, 20.000000000000014, 13.099999999999973, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.100000000000158, 20.000000000000014, -209.10000000000002, -554.5, -9.39999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999986, -162.10000000000008, -195.70000000000005, 20.000000000000014, 30.800000000000196, 20.000000000000014, 35.90000000000024, 39.80000000000025, 20.000000000000014, 20.000000000000014, -3.099999999999965, 20.000000000000014, 11.299999999999969, 20.000000000000014, 27.20000000000014, 29.000000000000163, -58.89999999999983, -127.50000000000003, 56.00000000000023, 15.799999999999963, -16.899999999999743, 20.000000000000014, -6.099999999999952, -9.400000000000006, -22.00000000000003, 54.20000000000022, 3.199999999999965, -320.2, 20.000000000000014, 21.80000000000004, -261.9, -113.80000000000004, -45.70000000000002, 20.000000000000014, -40.8999999999998, 20.000000000000014, 20.000000000000014, -9.399999999999855, -1022.5, -873.0, 20.000000000000014, 20.000000000000114, 20.000000000000014, 20.000000000000014, -79.60000000000002, -536.0, -137.10000000000002, -13.600000000000023, -28.300000000000036, 23.300000000000068, 20.000000000000014, 20.000000000000014, 17.899999999999988, -303.4, -608.8999999999999, 63.20000000000021, -269.6, -249.69999999999996, 20.000000000000014, -65.79999999999987, 20.000000000000014, -15.699999999999747, -19.899999999999743, -5.199999999999962, 20.000000000000014, -360.9, -641.4, -30.399999999999963, -26.200000000000017, -26.200000000000017, 20.000000000000014, 23.600000000000065, 20.000000000000014, 17.599999999999984, -21.999999999999766, 20.000000000000014, -822.5, -229.90000000000003, -82.90000000000066, -74.50000000000048, -14.19999999999981, 34.40000000000026, -108.09999999999982, 20.000000000000014, 20.000000000000014, -120.70000000000027, 23.600000000000065, -15.699999999999754, 20.000000000000014, 9.499999999999968, -209.20000000000047, -120.40000000000052, 20.000000000000014, -523.6, -17.799999999999784, -319.70000000000005, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [31.0, 1.0, 35.0, 0.0, 73.0, 102.0, 0.0, 18.0, 30.0, 0.0, 0.0, 0.0, 18.0, 1.0, 1.0, 0.0, 0.0, 3.0, 4.0, 73.0, 0.0, 13.0, 0.0, 0.0, 5.0, 24.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 64.0, 24.0, 138.0, 0.0, 13.0, 30.0, 0.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 2.0, 57.0, 0.0, 0.0, 0.0, 434.0, 28.0, 2.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 168.0, 0.0, 73.0, 0.0, 95.0, 0.0, 0.0, 7.0, 0.0, 169.0, 0.0, 0.0, 0.0, 5.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 530.0, 14.0, 0.0, 0.0, 0.0, 94.0, 20.0, 107.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 11.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 91.0, 2.0, 0.0, 18.0, 0.0, 14.0, 21.0, 15.0, 13.0, 162.0, 8.0, 0.0, 0.0, 119.0, 133.0, 14.0, 28.0, 37.0, 11.0, 0.0, 14.0, 1104.0, 19.0, 0.0, 6.0, 0.0, 0.0, 19.0, 462.0, 79.0, 3.0, 23.0, 7.0, 0.0, 0.0, 1.0, 154.0, 547.0, 12.0, 234.0, 0.0, 0.0, 46.0, 17.0, 0.0, 24.0, 7.0, 223.0, 5.0, 12.0, 495.0, 22.0, 22.0, 0.0, 0.0, 5.0, 0.0, 23.0, 0.0, 735.0, 0.0, 82.0, 0.0, 24.0, 21.0, 49.0, 48.0, 67.0, 0.0, 17.0, 0.0, 5.0, 0.0, 110.0, 0.0, 0.0, 447.0, 277.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0881395099648032, "mean_inference_ms": 2.9174606269762466, "mean_action_processing_ms": 0.542536018977715, "mean_env_wait_ms": 0.6703480642136053, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013224005699157715, "StateBufferConnector_ms": 0.003944873809814453, "ViewRequirementAgentConnector_ms": 0.19573569297790527}, "num_episodes": 18, "episode_return_max": 131.7999999999984, "episode_return_min": -772.4999999999999, "episode_return_mean": -14.363999999999944, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 235.60406034784722, "num_env_steps_trained_throughput_per_sec": 235.60406034784722, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 15415.87, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15415.809, "sample_time_ms": 2665.658, "learn_time_ms": 12726.208, "learn_throughput": 314.312, "synch_weights_time_ms": 20.097}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "c52aa_00000", "date": "2024-08-12_23-58-30", "timestamp": 1723521510, "time_this_iter_s": 17.162902116775513, "time_total_s": 638.4022164344788, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc09dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 638.4022164344788, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 88.8, "ram_util_percent": 83.476}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1260972237697353, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4518675879195886, "policy_loss": -0.0014997007655443023, "vf_loss": 2.4527561970488736, "vf_explained_var": 0.001081685603611053, "kl": 0.005722568017172973, "entropy": 1.0881567787241053, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5022644450148893, "cur_kl_coeff": 0.015820312499999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7621739448693696, "policy_loss": -0.004427584756298789, "vf_loss": 2.7663677277388397, "vf_explained_var": 0.0007595471919529022, "kl": 0.014778334416036487, "entropy": 1.2273495854524077, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 151.8000000000002, "episode_reward_min": -772.4999999999999, "episode_reward_mean": -13.869999999999916, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1022.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 74.89999999999941, "predator_policy": 1104.0}, "policy_reward_mean": {"prey_policy": -61.95499999999999, "predator_policy": 55.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.7999999999984, 43.699999999999946, -44.19999999999965, -92.89999999999989, 3.200000000000159, 71.49999999999999, 70.5, 58.100000000000456, 40.0000000000003, 58.10000000000027, 82.29999999999917, -24.899999999999537, 40.0000000000003, -612.9, 68.19999999999868, 47.90000000000044, 62.50000000000051, 71.79999999999977, -167.30000000000015, -37.59999999999989, -81.90000000000126, 40.0000000000003, 86.29999999999883, -122.50000000000026, 54.40000000000052, 44.10000000000037, 37.80000000000027, 40.0000000000003, 40.0000000000003, 63.10000000000048, -233.60000000000002, 24.600000000000062, 40.0000000000003, -38.599999999999774, -68.69999999999985, 50.80000000000048, 76.6999999999996, 40.0000000000003, 27.90000000000011, 39.30000000000029, 56.20000000000046, -95.39999999999964, 73.79999999999978, 21.099999999999994, 19.500000000000206, 60.20000000000045, -147.00000000000045, 41.800000000000324, -123.70000000000002, 16.30000000000033, 27.100000000000147, 24.60000000000005, -772.4999999999999, 46.000000000000455, 40.0000000000003, -134.59999999999997, -68.69999999999999, 25.000000000000426, 40.0000000000003, -130.50000000000037, 13.300000000000297, -285.3, 0.20000000000038654, 21.299999999999994, 5.900000000000089, -112.90000000000026, -164.8000000000003, -8.399999999999764, 43.60000000000035, 42.600000000000335, 20.999999999999996, -317.4, -75.40000000000111, 65.20000000000039, 8.899999999999917, -33.699999999999875, 24.900000000000063, 34.50000000000022, -219.600000000001, -56.59999999999994, -60.499999999999915, 40.0000000000003, 45.40000000000038, 60.40000000000052, -24.19999999999999, -60.39999999999986, -8.599999999999921, 21.300000000000274, 57.90000000000047, 40.0000000000003, 60.70000000000051, 42.90000000000035, 35.00000000000023, 41.00000000000033, 1.5000000000002005, 4.400000000000137, 46.800000000000416, 8.60000000000002, 53.00000000000046, 151.8000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [56.90000000000022, 74.89999999999941, 55.10000000000023, -42.400000000000006, -17.799999999999827, -114.40000000000002, -127.0000000000004, -103.8999999999999, -59.800000000000594, 20.000000000000014, 33.50000000000024, 38.000000000000256, 45.50000000000022, 20.000000000000014, 20.000000000000014, 34.1000000000002, 20.000000000000014, 20.000000000000014, 24.50000000000008, 2.600000000000011, 38.900000000000254, 43.400000000000205, -99.70000000000076, 15.799999999999963, 20.000000000000014, 20.000000000000014, -499.5, -547.4000000000001, 18.19999999999945, 20.000000000000014, 13.999999999999966, 26.900000000000134, 42.50000000000025, 20.000000000000014, 20.000000000000014, 39.800000000000196, -332.80000000000007, -2.499999999999787, -130.60000000000002, 20.000000000000014, -144.40000000000052, -32.49999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 59.30000000000019, 20.000000000000014, -311.5, 34.400000000000254, 20.000000000000014, 13.099999999999973, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.100000000000158, 20.000000000000014, -209.10000000000002, -554.5, -9.39999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999986, -162.10000000000008, -195.70000000000005, 20.000000000000014, 30.800000000000196, 20.000000000000014, 35.90000000000024, 39.80000000000025, 20.000000000000014, 20.000000000000014, -3.099999999999965, 20.000000000000014, 11.299999999999969, 20.000000000000014, 27.20000000000014, 29.000000000000163, -58.89999999999983, -127.50000000000003, 56.00000000000023, 15.799999999999963, -16.899999999999743, 20.000000000000014, -6.099999999999952, -9.400000000000006, -22.00000000000003, 54.20000000000022, 3.199999999999965, -320.2, 20.000000000000014, 21.80000000000004, -261.9, -113.80000000000004, -45.70000000000002, 20.000000000000014, -40.8999999999998, 20.000000000000014, 20.000000000000014, -9.399999999999855, -1022.5, -873.0, 20.000000000000014, 20.000000000000114, 20.000000000000014, 20.000000000000014, -79.60000000000002, -536.0, -137.10000000000002, -13.600000000000023, -28.300000000000036, 23.300000000000068, 20.000000000000014, 20.000000000000014, 17.899999999999988, -303.4, -608.8999999999999, 63.20000000000021, -269.6, -249.69999999999996, 20.000000000000014, -65.79999999999987, 20.000000000000014, -15.699999999999747, -19.899999999999743, -5.199999999999962, 20.000000000000014, -360.9, -641.4, -30.399999999999963, -26.200000000000017, -26.200000000000017, 20.000000000000014, 23.600000000000065, 20.000000000000014, 17.599999999999984, -21.999999999999766, 20.000000000000014, -822.5, -229.90000000000003, -82.90000000000066, -74.50000000000048, -14.19999999999981, 34.40000000000026, -108.09999999999982, 20.000000000000014, 20.000000000000014, -120.70000000000027, 23.600000000000065, -15.699999999999754, 20.000000000000014, 9.499999999999968, -209.20000000000047, -120.40000000000052, 20.000000000000014, -523.6, -17.799999999999784, -319.70000000000005, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, 38.900000000000254, 15.499999999999963, -192.10000000000002, -464.1, -884.9, 9.499999999999954, 20.000000000000014, -347.5999999999999, -15.70000000000001, 20.000000000000014, -5.499999999999961, 28.400000000000155, 20.000000000000014, 20.000000000000014, 21.80000000000004, 38.90000000000025, 14.899999999999965, 20.000000000000014, 20.000000000000014, 7.999999999999966, 35.30000000000026, -7.2999999999999154, 20.000000000000014, -53.50000000000019, 20.000000000000014, -55.60000000000031, 20.000000000000014, 15.79999999999996, -177.40000000000003, 20.000000000000014, 26.00000000000012, 20.000000000000014, 43.400000000000226, -424.6], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 31.0, 64.0, 24.0, 138.0, 0.0, 13.0, 30.0, 0.0, 0.0, 0.0, 5.0, 4.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 2.0, 57.0, 0.0, 0.0, 0.0, 434.0, 28.0, 2.0, 7.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 168.0, 0.0, 73.0, 0.0, 95.0, 0.0, 0.0, 7.0, 0.0, 169.0, 0.0, 0.0, 0.0, 5.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 530.0, 14.0, 0.0, 0.0, 0.0, 94.0, 20.0, 107.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 11.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 91.0, 2.0, 0.0, 18.0, 0.0, 14.0, 21.0, 15.0, 13.0, 162.0, 8.0, 0.0, 0.0, 119.0, 133.0, 14.0, 28.0, 37.0, 11.0, 0.0, 14.0, 1104.0, 19.0, 0.0, 6.0, 0.0, 0.0, 19.0, 462.0, 79.0, 3.0, 23.0, 7.0, 0.0, 0.0, 1.0, 154.0, 547.0, 12.0, 234.0, 0.0, 0.0, 46.0, 17.0, 0.0, 24.0, 7.0, 223.0, 5.0, 12.0, 495.0, 22.0, 22.0, 0.0, 0.0, 5.0, 0.0, 23.0, 0.0, 735.0, 0.0, 82.0, 0.0, 24.0, 21.0, 49.0, 48.0, 67.0, 0.0, 17.0, 0.0, 5.0, 0.0, 110.0, 0.0, 0.0, 447.0, 277.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 252.0, 380.0, 815.0, 0.0, 196.0, 123.0, 0.0, 17.0, 19.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 7.0, 0.0, 13.0, 35.0, 0.0, 21.0, 19.0, 11.0, 0.0, 72.0, 94.0, 0.0, 7.0, 383.0, 150.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0931081307426638, "mean_inference_ms": 2.9311637002272564, "mean_action_processing_ms": 0.5425663703943009, "mean_env_wait_ms": 0.6722680325018405, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014958977699279785, "StateBufferConnector_ms": 0.004183530807495117, "ViewRequirementAgentConnector_ms": 0.16835391521453857}, "num_episodes": 18, "episode_return_max": 151.8000000000002, "episode_return_min": -772.4999999999999, "episode_return_mean": -13.869999999999916, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 233.1663517587878, "num_env_steps_trained_throughput_per_sec": 233.1663517587878, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 15646.531, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15646.471, "sample_time_ms": 2815.482, "learn_time_ms": 12806.75, "learn_throughput": 312.335, "synch_weights_time_ms": 20.443}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "c52aa_00000", "date": "2024-08-12_23-58-48", "timestamp": 1723521528, "time_this_iter_s": 17.26144504547119, "time_total_s": 655.66366147995, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87ef70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 655.66366147995, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 84.368, "ram_util_percent": 83.484}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9811342979470888, "cur_kl_coeff": 0.10678710937499997, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8473345572355564, "policy_loss": -0.0011149272041779661, "vf_loss": 2.84812393554304, "vf_explained_var": 0.0022571602195659013, "kl": 0.0030485266566530763, "entropy": 1.1058709284615895, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5152096248650677, "cur_kl_coeff": 0.015820312499999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4458784692501894, "policy_loss": -0.00516226557847211, "vf_loss": 2.4507463940236933, "vf_explained_var": 0.0009355208230397057, "kl": 0.018605452136856576, "entropy": 1.2529590614258297, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 151.8000000000002, "episode_reward_min": -772.4999999999999, "episode_reward_mean": -15.8009999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1022.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 63.20000000000021, "predator_policy": 1104.0}, "policy_reward_mean": {"prey_policy": -69.56549999999997, "predator_policy": 61.665}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-167.30000000000015, -37.59999999999989, -81.90000000000126, 40.0000000000003, 86.29999999999883, -122.50000000000026, 54.40000000000052, 44.10000000000037, 37.80000000000027, 40.0000000000003, 40.0000000000003, 63.10000000000048, -233.60000000000002, 24.600000000000062, 40.0000000000003, -38.599999999999774, -68.69999999999985, 50.80000000000048, 76.6999999999996, 40.0000000000003, 27.90000000000011, 39.30000000000029, 56.20000000000046, -95.39999999999964, 73.79999999999978, 21.099999999999994, 19.500000000000206, 60.20000000000045, -147.00000000000045, 41.800000000000324, -123.70000000000002, 16.30000000000033, 27.100000000000147, 24.60000000000005, -772.4999999999999, 46.000000000000455, 40.0000000000003, -134.59999999999997, -68.69999999999999, 25.000000000000426, 40.0000000000003, -130.50000000000037, 13.300000000000297, -285.3, 0.20000000000038654, 21.299999999999994, 5.900000000000089, -112.90000000000026, -164.8000000000003, -8.399999999999764, 43.60000000000035, 42.600000000000335, 20.999999999999996, -317.4, -75.40000000000111, 65.20000000000039, 8.899999999999917, -33.699999999999875, 24.900000000000063, 34.50000000000022, -219.600000000001, -56.59999999999994, -60.499999999999915, 40.0000000000003, 45.40000000000038, 60.40000000000052, -24.19999999999999, -60.39999999999986, -8.599999999999921, 21.300000000000274, 57.90000000000047, 40.0000000000003, 60.70000000000051, 42.90000000000035, 35.00000000000023, 41.00000000000033, 1.5000000000002005, 4.400000000000137, 46.800000000000416, 8.60000000000002, 53.00000000000046, 151.8000000000002, 54.40000000000048, 18.099999999999945, 40.0000000000003, -114.80000000000022, 52.60000000000051, 63.50000000000052, -67.80000000000118, 41.800000000000324, -103.0999999999997, 53.300000000000516, -187.7000000000009, -71.2999999999999, -9.400000000000022, 40.0000000000003, 51.5000000000005, 83.49999999999909, 32.500000000000185, -95.50000000000031], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-332.80000000000007, -2.499999999999787, -130.60000000000002, 20.000000000000014, -144.40000000000052, -32.49999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 59.30000000000019, 20.000000000000014, -311.5, 34.400000000000254, 20.000000000000014, 13.099999999999973, 20.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.100000000000158, 20.000000000000014, -209.10000000000002, -554.5, -9.39999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 9.499999999999986, -162.10000000000008, -195.70000000000005, 20.000000000000014, 30.800000000000196, 20.000000000000014, 35.90000000000024, 39.80000000000025, 20.000000000000014, 20.000000000000014, -3.099999999999965, 20.000000000000014, 11.299999999999969, 20.000000000000014, 27.20000000000014, 29.000000000000163, -58.89999999999983, -127.50000000000003, 56.00000000000023, 15.799999999999963, -16.899999999999743, 20.000000000000014, -6.099999999999952, -9.400000000000006, -22.00000000000003, 54.20000000000022, 3.199999999999965, -320.2, 20.000000000000014, 21.80000000000004, -261.9, -113.80000000000004, -45.70000000000002, 20.000000000000014, -40.8999999999998, 20.000000000000014, 20.000000000000014, -9.399999999999855, -1022.5, -873.0, 20.000000000000014, 20.000000000000114, 20.000000000000014, 20.000000000000014, -79.60000000000002, -536.0, -137.10000000000002, -13.600000000000023, -28.300000000000036, 23.300000000000068, 20.000000000000014, 20.000000000000014, 17.899999999999988, -303.4, -608.8999999999999, 63.20000000000021, -269.6, -249.69999999999996, 20.000000000000014, -65.79999999999987, 20.000000000000014, -15.699999999999747, -19.899999999999743, -5.199999999999962, 20.000000000000014, -360.9, -641.4, -30.399999999999963, -26.200000000000017, -26.200000000000017, 20.000000000000014, 23.600000000000065, 20.000000000000014, 17.599999999999984, -21.999999999999766, 20.000000000000014, -822.5, -229.90000000000003, -82.90000000000066, -74.50000000000048, -14.19999999999981, 34.40000000000026, -108.09999999999982, 20.000000000000014, 20.000000000000014, -120.70000000000027, 23.600000000000065, -15.699999999999754, 20.000000000000014, 9.499999999999968, -209.20000000000047, -120.40000000000052, 20.000000000000014, -523.6, -17.799999999999784, -319.70000000000005, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, 38.900000000000254, 15.499999999999963, -192.10000000000002, -464.1, -884.9, 9.499999999999954, 20.000000000000014, -347.5999999999999, -15.70000000000001, 20.000000000000014, -5.499999999999961, 28.400000000000155, 20.000000000000014, 20.000000000000014, 21.80000000000004, 38.90000000000025, 14.899999999999965, 20.000000000000014, 20.000000000000014, 7.999999999999966, 35.30000000000026, -7.2999999999999154, 20.000000000000014, -53.50000000000019, 20.000000000000014, -55.60000000000031, 20.000000000000014, 15.79999999999996, -177.40000000000003, 20.000000000000014, 26.00000000000012, 20.000000000000014, 43.400000000000226, -424.6, 46.10000000000024, -15.699999999999783, 20.000000000000014, -25.899999999999764, 20.000000000000014, 20.000000000000014, -255.10000000000002, 5.299999999999984, 32.60000000000023, 20.000000000000014, 24.20000000000008, 35.30000000000026, -76.60000000000075, -215.19999999999987, 21.80000000000004, 20.000000000000014, -96.99999999999991, -66.10000000000004, 32.300000000000225, 20.000000000000014, -693.1, -43.599999999999774, -304.30000000000007, -106.0000000000008, 20.000000000000014, -391.40000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.500000000000192, 33.50000000000024, 47.00000000000022, -2.499999999999993, 20.000000000000014, 20.000000000000014, -585.5], "policy_predator_policy_reward": [0.0, 168.0, 0.0, 73.0, 0.0, 95.0, 0.0, 0.0, 7.0, 0.0, 169.0, 0.0, 0.0, 0.0, 5.0, 6.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 530.0, 14.0, 0.0, 0.0, 0.0, 94.0, 20.0, 107.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 11.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 91.0, 2.0, 0.0, 18.0, 0.0, 14.0, 21.0, 15.0, 13.0, 162.0, 8.0, 0.0, 0.0, 119.0, 133.0, 14.0, 28.0, 37.0, 11.0, 0.0, 14.0, 1104.0, 19.0, 0.0, 6.0, 0.0, 0.0, 19.0, 462.0, 79.0, 3.0, 23.0, 7.0, 0.0, 0.0, 1.0, 154.0, 547.0, 12.0, 234.0, 0.0, 0.0, 46.0, 17.0, 0.0, 24.0, 7.0, 223.0, 5.0, 12.0, 495.0, 22.0, 22.0, 0.0, 0.0, 5.0, 0.0, 23.0, 0.0, 735.0, 0.0, 82.0, 0.0, 24.0, 21.0, 49.0, 48.0, 67.0, 0.0, 17.0, 0.0, 5.0, 0.0, 110.0, 0.0, 0.0, 447.0, 277.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 252.0, 380.0, 815.0, 0.0, 196.0, 123.0, 0.0, 17.0, 19.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 7.0, 0.0, 13.0, 35.0, 0.0, 21.0, 19.0, 11.0, 0.0, 72.0, 94.0, 0.0, 7.0, 383.0, 150.0, 12.0, 12.0, 24.0, 0.0, 0.0, 0.0, 0.0, 135.0, 0.0, 0.0, 0.0, 4.0, 144.0, 80.0, 0.0, 0.0, 60.0, 0.0, 1.0, 0.0, 0.0, 549.0, 339.0, 0.0, 0.0, 362.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 15.0, 0.0, 0.0, 470.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0964590114332133, "mean_inference_ms": 2.939851995338307, "mean_action_processing_ms": 0.5419879910539013, "mean_env_wait_ms": 0.6740195926889269, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010280489921569824, "StateBufferConnector_ms": 0.004975795745849609, "ViewRequirementAgentConnector_ms": 0.20599019527435303}, "num_episodes": 18, "episode_return_max": 151.8000000000002, "episode_return_min": -772.4999999999999, "episode_return_mean": -15.8009999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 266.7515325335692, "num_env_steps_trained_throughput_per_sec": 266.7515325335692, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 15744.468, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15744.41, "sample_time_ms": 2968.688, "learn_time_ms": 12752.634, "learn_throughput": 313.661, "synch_weights_time_ms": 19.987}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "c52aa_00000", "date": "2024-08-12_23-59-03", "timestamp": 1723521543, "time_this_iter_s": 15.082389831542969, "time_total_s": 670.7460513114929, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc87e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 670.7460513114929, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 75.12857142857143, "ram_util_percent": 83.31904761904761}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9108171473498697, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.063416013231984, "policy_loss": -0.003906344200691415, "vf_loss": 2.066585255741442, "vf_explained_var": 0.0022851603687124907, "kl": 0.013805062373821474, "entropy": 1.075471047749595, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4797319383769439, "cur_kl_coeff": 0.015820312499999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9300829893697506, "policy_loss": -0.004418252373395103, "vf_loss": 1.9341819846125508, "vf_explained_var": 0.0004251150857834589, "kl": 0.02018018517433761, "entropy": 1.247503313122603, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 151.8000000000002, "episode_reward_min": -772.4999999999999, "episode_reward_mean": -13.885999999999889, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -1022.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 63.20000000000021, "predator_policy": 1104.0}, "policy_reward_mean": {"prey_policy": -68.13799999999998, "predator_policy": 61.195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [56.20000000000046, -95.39999999999964, 73.79999999999978, 21.099999999999994, 19.500000000000206, 60.20000000000045, -147.00000000000045, 41.800000000000324, -123.70000000000002, 16.30000000000033, 27.100000000000147, 24.60000000000005, -772.4999999999999, 46.000000000000455, 40.0000000000003, -134.59999999999997, -68.69999999999999, 25.000000000000426, 40.0000000000003, -130.50000000000037, 13.300000000000297, -285.3, 0.20000000000038654, 21.299999999999994, 5.900000000000089, -112.90000000000026, -164.8000000000003, -8.399999999999764, 43.60000000000035, 42.600000000000335, 20.999999999999996, -317.4, -75.40000000000111, 65.20000000000039, 8.899999999999917, -33.699999999999875, 24.900000000000063, 34.50000000000022, -219.600000000001, -56.59999999999994, -60.499999999999915, 40.0000000000003, 45.40000000000038, 60.40000000000052, -24.19999999999999, -60.39999999999986, -8.599999999999921, 21.300000000000274, 57.90000000000047, 40.0000000000003, 60.70000000000051, 42.90000000000035, 35.00000000000023, 41.00000000000033, 1.5000000000002005, 4.400000000000137, 46.800000000000416, 8.60000000000002, 53.00000000000046, 151.8000000000002, 54.40000000000048, 18.099999999999945, 40.0000000000003, -114.80000000000022, 52.60000000000051, 63.50000000000052, -67.80000000000118, 41.800000000000324, -103.0999999999997, 53.300000000000516, -187.7000000000009, -71.2999999999999, -9.400000000000022, 40.0000000000003, 51.5000000000005, 83.49999999999909, 32.500000000000185, -95.50000000000031, 44.50000000000036, -208.50000000000048, 58.00000000000052, 36.70000000000025, 43.20000000000035, 55.30000000000046, 44.50000000000036, 17.199999999999935, 22.50000000000003, 16.19999999999996, 55.10000000000052, -65.30000000000085, -116.00000000000045, 44.50000000000036, -31.499999999999915, 40.0000000000003, 55.700000000000486, 19.199999999999967, 30.100000000000126, 40.0000000000003, -95.10000000000005, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [27.20000000000014, 29.000000000000163, -58.89999999999983, -127.50000000000003, 56.00000000000023, 15.799999999999963, -16.899999999999743, 20.000000000000014, -6.099999999999952, -9.400000000000006, -22.00000000000003, 54.20000000000022, 3.199999999999965, -320.2, 20.000000000000014, 21.80000000000004, -261.9, -113.80000000000004, -45.70000000000002, 20.000000000000014, -40.8999999999998, 20.000000000000014, 20.000000000000014, -9.399999999999855, -1022.5, -873.0, 20.000000000000014, 20.000000000000114, 20.000000000000014, 20.000000000000014, -79.60000000000002, -536.0, -137.10000000000002, -13.600000000000023, -28.300000000000036, 23.300000000000068, 20.000000000000014, 20.000000000000014, 17.899999999999988, -303.4, -608.8999999999999, 63.20000000000021, -269.6, -249.69999999999996, 20.000000000000014, -65.79999999999987, 20.000000000000014, -15.699999999999747, -19.899999999999743, -5.199999999999962, 20.000000000000014, -360.9, -641.4, -30.399999999999963, -26.200000000000017, -26.200000000000017, 20.000000000000014, 23.600000000000065, 20.000000000000014, 17.599999999999984, -21.999999999999766, 20.000000000000014, -822.5, -229.90000000000003, -82.90000000000066, -74.50000000000048, -14.19999999999981, 34.40000000000026, -108.09999999999982, 20.000000000000014, 20.000000000000014, -120.70000000000027, 23.600000000000065, -15.699999999999754, 20.000000000000014, 9.499999999999968, -209.20000000000047, -120.40000000000052, 20.000000000000014, -523.6, -17.799999999999784, -319.70000000000005, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, 38.900000000000254, 15.499999999999963, -192.10000000000002, -464.1, -884.9, 9.499999999999954, 20.000000000000014, -347.5999999999999, -15.70000000000001, 20.000000000000014, -5.499999999999961, 28.400000000000155, 20.000000000000014, 20.000000000000014, 21.80000000000004, 38.90000000000025, 14.899999999999965, 20.000000000000014, 20.000000000000014, 7.999999999999966, 35.30000000000026, -7.2999999999999154, 20.000000000000014, -53.50000000000019, 20.000000000000014, -55.60000000000031, 20.000000000000014, 15.79999999999996, -177.40000000000003, 20.000000000000014, 26.00000000000012, 20.000000000000014, 43.400000000000226, -424.6, 46.10000000000024, -15.699999999999783, 20.000000000000014, -25.899999999999764, 20.000000000000014, 20.000000000000014, -255.10000000000002, 5.299999999999984, 32.60000000000023, 20.000000000000014, 24.20000000000008, 35.30000000000026, -76.60000000000075, -215.19999999999987, 21.80000000000004, 20.000000000000014, -96.99999999999991, -66.10000000000004, 32.300000000000225, 20.000000000000014, -693.1, -43.599999999999774, -304.30000000000007, -106.0000000000008, 20.000000000000014, -391.40000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.500000000000192, 33.50000000000024, 47.00000000000022, -2.499999999999993, 20.000000000000014, 20.000000000000014, -585.5, 20.000000000000014, 24.50000000000008, -120.70000000000027, -185.8000000000002, 38.000000000000256, 20.000000000000014, 13.699999999999969, 20.000000000000014, 12.199999999999973, 20.000000000000014, 26.300000000000125, 20.000000000000014, 24.50000000000008, 20.000000000000014, -36.699999999999775, 20.900000000000027, -5.199999999999934, 13.69999999999997, -353.8, 20.000000000000014, 36.20000000000026, 17.899999999999988, -74.50000000000068, -248.80000000000015, 20.000000000000014, -337.0, 24.50000000000008, 20.000000000000014, -116.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.900000000000134, 21.80000000000004, -23.799999999999763, 20.000000000000014, 1.0999999999999688, 20.000000000000014, 20.000000000000014, 20.000000000000014, 48.80000000000022, -292.8999999999999, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 91.0, 2.0, 0.0, 18.0, 0.0, 14.0, 21.0, 15.0, 13.0, 162.0, 8.0, 0.0, 0.0, 119.0, 133.0, 14.0, 28.0, 37.0, 11.0, 0.0, 14.0, 1104.0, 19.0, 0.0, 6.0, 0.0, 0.0, 19.0, 462.0, 79.0, 3.0, 23.0, 7.0, 0.0, 0.0, 1.0, 154.0, 547.0, 12.0, 234.0, 0.0, 0.0, 46.0, 17.0, 0.0, 24.0, 7.0, 223.0, 5.0, 12.0, 495.0, 22.0, 22.0, 0.0, 0.0, 5.0, 0.0, 23.0, 0.0, 735.0, 0.0, 82.0, 0.0, 24.0, 21.0, 49.0, 48.0, 67.0, 0.0, 17.0, 0.0, 5.0, 0.0, 110.0, 0.0, 0.0, 447.0, 277.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 252.0, 380.0, 815.0, 0.0, 196.0, 123.0, 0.0, 17.0, 19.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 7.0, 0.0, 13.0, 35.0, 0.0, 21.0, 19.0, 11.0, 0.0, 72.0, 94.0, 0.0, 7.0, 383.0, 150.0, 12.0, 12.0, 24.0, 0.0, 0.0, 0.0, 0.0, 135.0, 0.0, 0.0, 0.0, 4.0, 144.0, 80.0, 0.0, 0.0, 60.0, 0.0, 1.0, 0.0, 0.0, 549.0, 339.0, 0.0, 0.0, 362.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 15.0, 0.0, 0.0, 470.0, 0.0, 0.0, 98.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 9.0, 0.0, 0.0, 0.0, 6.0, 27.0, 0.0, 14.0, 177.0, 173.0, 1.0, 0.0, 125.0, 133.0, 31.0, 170.0, 0.0, 0.0, 0.0, 65.0, 0.0, 0.0, 0.0, 7.0, 23.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 149.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1002613555370158, "mean_inference_ms": 2.9495683377233077, "mean_action_processing_ms": 0.5414447127484473, "mean_env_wait_ms": 0.6758088495638277, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010587930679321289, "StateBufferConnector_ms": 0.00494694709777832, "ViewRequirementAgentConnector_ms": 0.2168576717376709}, "num_episodes": 22, "episode_return_max": 151.8000000000002, "episode_return_min": -772.4999999999999, "episode_return_mean": -13.885999999999889, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 297.21013850324334, "num_env_steps_trained_throughput_per_sec": 297.21013850324334, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 15712.918, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15712.861, "sample_time_ms": 3016.114, "learn_time_ms": 12673.469, "learn_throughput": 315.62, "synch_weights_time_ms": 20.535}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "c52aa_00000", "date": "2024-08-12_23-59-17", "timestamp": 1723521557, "time_this_iter_s": 13.632757902145386, "time_total_s": 684.3788092136383, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc87430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 684.3788092136383, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 72.49473684210528, "ram_util_percent": 83.21578947368421}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9666222906420155, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5185111973020766, "policy_loss": -0.0023308666371223, "vf_loss": 2.5204245910442697, "vf_explained_var": 0.004219325761946421, "kl": 0.007818831316590183, "entropy": 1.118869211938646, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5055181401865507, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5514050687431657, "policy_loss": -0.00232804678479042, "vf_loss": 2.5535818171248863, "vf_explained_var": 0.0007004597515025467, "kl": 0.006375629284122504, "entropy": 1.2604896290592416, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 637.9000000000017, "episode_reward_min": -317.4, "episode_reward_mean": 6.546000000000109, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -884.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 65.00000000000014, "predator_policy": 815.0}, "policy_reward_mean": {"prey_policy": -55.75699999999999, "predator_policy": 59.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.299999999999994, 5.900000000000089, -112.90000000000026, -164.8000000000003, -8.399999999999764, 43.60000000000035, 42.600000000000335, 20.999999999999996, -317.4, -75.40000000000111, 65.20000000000039, 8.899999999999917, -33.699999999999875, 24.900000000000063, 34.50000000000022, -219.600000000001, -56.59999999999994, -60.499999999999915, 40.0000000000003, 45.40000000000038, 60.40000000000052, -24.19999999999999, -60.39999999999986, -8.599999999999921, 21.300000000000274, 57.90000000000047, 40.0000000000003, 60.70000000000051, 42.90000000000035, 35.00000000000023, 41.00000000000033, 1.5000000000002005, 4.400000000000137, 46.800000000000416, 8.60000000000002, 53.00000000000046, 151.8000000000002, 54.40000000000048, 18.099999999999945, 40.0000000000003, -114.80000000000022, 52.60000000000051, 63.50000000000052, -67.80000000000118, 41.800000000000324, -103.0999999999997, 53.300000000000516, -187.7000000000009, -71.2999999999999, -9.400000000000022, 40.0000000000003, 51.5000000000005, 83.49999999999909, 32.500000000000185, -95.50000000000031, 44.50000000000036, -208.50000000000048, 58.00000000000052, 36.70000000000025, 43.20000000000035, 55.30000000000046, 44.50000000000036, 17.199999999999935, 22.50000000000003, 16.19999999999996, 55.10000000000052, -65.30000000000085, -116.00000000000045, 44.50000000000036, -31.499999999999915, 40.0000000000003, 55.700000000000486, 19.199999999999967, 30.100000000000126, 40.0000000000003, -95.10000000000005, 40.0000000000003, -77.80000000000021, 49.90000000000046, -44.69999999999981, 50.80000000000048, 40.0000000000003, 22.100000000000076, 40.0000000000003, -8.199999999999923, 20.300000000000015, 72.39999999999989, 63.400000000000496, 637.9000000000017, 30.0000000000003, -114.60000000000105, -97.90000000000009, -39.199999999999996, -46.69999999999976, 61.10000000000049, 40.0000000000003, 42.800000000000345, 92.39999999999843, 54.40000000000051, -97.80000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -15.699999999999747, -19.899999999999743, -5.199999999999962, 20.000000000000014, -360.9, -641.4, -30.399999999999963, -26.200000000000017, -26.200000000000017, 20.000000000000014, 23.600000000000065, 20.000000000000014, 17.599999999999984, -21.999999999999766, 20.000000000000014, -822.5, -229.90000000000003, -82.90000000000066, -74.50000000000048, -14.19999999999981, 34.40000000000026, -108.09999999999982, 20.000000000000014, 20.000000000000014, -120.70000000000027, 23.600000000000065, -15.699999999999754, 20.000000000000014, 9.499999999999968, -209.20000000000047, -120.40000000000052, 20.000000000000014, -523.6, -17.799999999999784, -319.70000000000005, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, 38.900000000000254, 15.499999999999963, -192.10000000000002, -464.1, -884.9, 9.499999999999954, 20.000000000000014, -347.5999999999999, -15.70000000000001, 20.000000000000014, -5.499999999999961, 28.400000000000155, 20.000000000000014, 20.000000000000014, 21.80000000000004, 38.90000000000025, 14.899999999999965, 20.000000000000014, 20.000000000000014, 7.999999999999966, 35.30000000000026, -7.2999999999999154, 20.000000000000014, -53.50000000000019, 20.000000000000014, -55.60000000000031, 20.000000000000014, 15.79999999999996, -177.40000000000003, 20.000000000000014, 26.00000000000012, 20.000000000000014, 43.400000000000226, -424.6, 46.10000000000024, -15.699999999999783, 20.000000000000014, -25.899999999999764, 20.000000000000014, 20.000000000000014, -255.10000000000002, 5.299999999999984, 32.60000000000023, 20.000000000000014, 24.20000000000008, 35.30000000000026, -76.60000000000075, -215.19999999999987, 21.80000000000004, 20.000000000000014, -96.99999999999991, -66.10000000000004, 32.300000000000225, 20.000000000000014, -693.1, -43.599999999999774, -304.30000000000007, -106.0000000000008, 20.000000000000014, -391.40000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.500000000000192, 33.50000000000024, 47.00000000000022, -2.499999999999993, 20.000000000000014, 20.000000000000014, -585.5, 20.000000000000014, 24.50000000000008, -120.70000000000027, -185.8000000000002, 38.000000000000256, 20.000000000000014, 13.699999999999969, 20.000000000000014, 12.199999999999973, 20.000000000000014, 26.300000000000125, 20.000000000000014, 24.50000000000008, 20.000000000000014, -36.699999999999775, 20.900000000000027, -5.199999999999934, 13.69999999999997, -353.8, 20.000000000000014, 36.20000000000026, 17.899999999999988, -74.50000000000068, -248.80000000000015, 20.000000000000014, -337.0, 24.50000000000008, 20.000000000000014, -116.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.900000000000134, 21.80000000000004, -23.799999999999763, 20.000000000000014, 1.0999999999999688, 20.000000000000014, 20.000000000000014, 20.000000000000014, 48.80000000000022, -292.8999999999999, 20.000000000000014, 20.000000000000014, -11.500000000000025, -259.3, 23.600000000000065, 26.300000000000114, -40.89999999999976, -80.80000000000064, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.89999999999992, 20.000000000000014, 20.000000000000014, -110.20000000000037, 23.000000000000057, -30.699999999999783, 20.000000000000014, 20.000000000000014, 52.40000000000023, 20.90000000000003, 42.50000000000024, 35.000000000000256, -841.1, 38.00000000000024, -169.00000000000043, -122.8000000000005, -59.80000000000025, -151.8999999999999, -109.0000000000006, -114.40000000000003, 3.1999999999999633, -328.6, -24.09999999999976, 17.899999999999988, 36.20000000000026, 20.000000000000014, 20.000000000000014, 6.199999999999973, 23.600000000000065, 65.00000000000014, 19.400000000000006, 20.000000000000014, 34.40000000000025, 22.400000000000052, -459.2], "policy_predator_policy_reward": [17.0, 0.0, 24.0, 7.0, 223.0, 5.0, 12.0, 495.0, 22.0, 22.0, 0.0, 0.0, 5.0, 0.0, 23.0, 0.0, 735.0, 0.0, 82.0, 0.0, 24.0, 21.0, 49.0, 48.0, 67.0, 0.0, 17.0, 0.0, 5.0, 0.0, 110.0, 0.0, 0.0, 447.0, 277.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 252.0, 380.0, 815.0, 0.0, 196.0, 123.0, 0.0, 17.0, 19.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 7.0, 0.0, 13.0, 35.0, 0.0, 21.0, 19.0, 11.0, 0.0, 72.0, 94.0, 0.0, 7.0, 383.0, 150.0, 12.0, 12.0, 24.0, 0.0, 0.0, 0.0, 0.0, 135.0, 0.0, 0.0, 0.0, 4.0, 144.0, 80.0, 0.0, 0.0, 60.0, 0.0, 1.0, 0.0, 0.0, 549.0, 339.0, 0.0, 0.0, 362.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 15.0, 0.0, 0.0, 470.0, 0.0, 0.0, 98.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 9.0, 0.0, 0.0, 0.0, 6.0, 27.0, 0.0, 14.0, 177.0, 173.0, 1.0, 0.0, 125.0, 133.0, 31.0, 170.0, 0.0, 0.0, 0.0, 65.0, 0.0, 0.0, 0.0, 7.0, 23.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 149.0, 0.0, 0.0, 59.0, 134.0, 0.0, 0.0, 0.0, 77.0, 0.0, 0.0, 0.0, 0.0, 14.0, 8.0, 0.0, 0.0, 61.0, 18.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 698.0, 746.0, 85.0, 76.0, 0.0, 68.0, 0.0, 163.0, 64.0, 8.0, 166.0, 140.0, 0.0, 7.0, 0.0, 0.0, 0.0, 13.0, 0.0, 8.0, 0.0, 0.0, 332.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1063064800213909, "mean_inference_ms": 2.9639131845582893, "mean_action_processing_ms": 0.541238236110782, "mean_env_wait_ms": 0.6788772239426152, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010989785194396973, "StateBufferConnector_ms": 0.004866480827331543, "ViewRequirementAgentConnector_ms": 0.2281205654144287}, "num_episodes": 23, "episode_return_max": 637.9000000000017, "episode_return_min": -317.4, "episode_return_mean": 6.546000000000109, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 223.00806396985772, "num_env_steps_trained_throughput_per_sec": 223.00806396985772, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 15973.144, "restore_workers_time_ms": 0.017, "training_step_time_ms": 15973.087, "sample_time_ms": 3089.048, "learn_time_ms": 12858.381, "learn_throughput": 311.081, "synch_weights_time_ms": 22.915}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "c52aa_00000", "date": "2024-08-12_23-59-35", "timestamp": 1723521575, "time_this_iter_s": 18.095058917999268, "time_total_s": 702.4738681316376, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab849ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 702.4738681316376, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 85.51538461538462, "ram_util_percent": 83.11153846153844}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0224356525789493, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6396007229096043, "policy_loss": -0.005376012894329886, "vf_loss": 1.6439641487346124, "vf_explained_var": 0.0025869307379243235, "kl": 0.018964611390667623, "entropy": 1.1304332446799708, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4507132798590988, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8890453606686264, "policy_loss": -0.004233929759788292, "vf_loss": 1.893080858326463, "vf_explained_var": 0.0006501792599915197, "kl": 0.008362102411210133, "entropy": 1.2843373313151971, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 637.9000000000017, "episode_reward_min": -208.50000000000048, "episode_reward_mean": 19.673000000000144, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -884.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 65.00000000000014, "predator_policy": 815.0}, "policy_reward_mean": {"prey_policy": -41.59849999999999, "predator_policy": 51.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 45.40000000000038, 60.40000000000052, -24.19999999999999, -60.39999999999986, -8.599999999999921, 21.300000000000274, 57.90000000000047, 40.0000000000003, 60.70000000000051, 42.90000000000035, 35.00000000000023, 41.00000000000033, 1.5000000000002005, 4.400000000000137, 46.800000000000416, 8.60000000000002, 53.00000000000046, 151.8000000000002, 54.40000000000048, 18.099999999999945, 40.0000000000003, -114.80000000000022, 52.60000000000051, 63.50000000000052, -67.80000000000118, 41.800000000000324, -103.0999999999997, 53.300000000000516, -187.7000000000009, -71.2999999999999, -9.400000000000022, 40.0000000000003, 51.5000000000005, 83.49999999999909, 32.500000000000185, -95.50000000000031, 44.50000000000036, -208.50000000000048, 58.00000000000052, 36.70000000000025, 43.20000000000035, 55.30000000000046, 44.50000000000036, 17.199999999999935, 22.50000000000003, 16.19999999999996, 55.10000000000052, -65.30000000000085, -116.00000000000045, 44.50000000000036, -31.499999999999915, 40.0000000000003, 55.700000000000486, 19.199999999999967, 30.100000000000126, 40.0000000000003, -95.10000000000005, 40.0000000000003, -77.80000000000021, 49.90000000000046, -44.69999999999981, 50.80000000000048, 40.0000000000003, 22.100000000000076, 40.0000000000003, -8.199999999999923, 20.300000000000015, 72.39999999999989, 63.400000000000496, 637.9000000000017, 30.0000000000003, -114.60000000000105, -97.90000000000009, -39.199999999999996, -46.69999999999976, 61.10000000000049, 40.0000000000003, 42.800000000000345, 92.39999999999843, 54.40000000000051, -97.80000000000018, 38.300000000000274, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.10000000000034, 46.300000000000395, 43.60000000000036, 40.0000000000003, 59.800000000000516, 40.80000000000029, 40.0000000000003, -63.4000000000011, 33.900000000000205, 95.10000000000008, -16.000000000000053, 40.0000000000003, -76.30000000000007, 23.100000000000033], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, 38.900000000000254, 15.499999999999963, -192.10000000000002, -464.1, -884.9, 9.499999999999954, 20.000000000000014, -347.5999999999999, -15.70000000000001, 20.000000000000014, -5.499999999999961, 28.400000000000155, 20.000000000000014, 20.000000000000014, 21.80000000000004, 38.90000000000025, 14.899999999999965, 20.000000000000014, 20.000000000000014, 7.999999999999966, 35.30000000000026, -7.2999999999999154, 20.000000000000014, -53.50000000000019, 20.000000000000014, -55.60000000000031, 20.000000000000014, 15.79999999999996, -177.40000000000003, 20.000000000000014, 26.00000000000012, 20.000000000000014, 43.400000000000226, -424.6, 46.10000000000024, -15.699999999999783, 20.000000000000014, -25.899999999999764, 20.000000000000014, 20.000000000000014, -255.10000000000002, 5.299999999999984, 32.60000000000023, 20.000000000000014, 24.20000000000008, 35.30000000000026, -76.60000000000075, -215.19999999999987, 21.80000000000004, 20.000000000000014, -96.99999999999991, -66.10000000000004, 32.300000000000225, 20.000000000000014, -693.1, -43.599999999999774, -304.30000000000007, -106.0000000000008, 20.000000000000014, -391.40000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.500000000000192, 33.50000000000024, 47.00000000000022, -2.499999999999993, 20.000000000000014, 20.000000000000014, -585.5, 20.000000000000014, 24.50000000000008, -120.70000000000027, -185.8000000000002, 38.000000000000256, 20.000000000000014, 13.699999999999969, 20.000000000000014, 12.199999999999973, 20.000000000000014, 26.300000000000125, 20.000000000000014, 24.50000000000008, 20.000000000000014, -36.699999999999775, 20.900000000000027, -5.199999999999934, 13.69999999999997, -353.8, 20.000000000000014, 36.20000000000026, 17.899999999999988, -74.50000000000068, -248.80000000000015, 20.000000000000014, -337.0, 24.50000000000008, 20.000000000000014, -116.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.900000000000134, 21.80000000000004, -23.799999999999763, 20.000000000000014, 1.0999999999999688, 20.000000000000014, 20.000000000000014, 20.000000000000014, 48.80000000000022, -292.8999999999999, 20.000000000000014, 20.000000000000014, -11.500000000000025, -259.3, 23.600000000000065, 26.300000000000114, -40.89999999999976, -80.80000000000064, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.89999999999992, 20.000000000000014, 20.000000000000014, -110.20000000000037, 23.000000000000057, -30.699999999999783, 20.000000000000014, 20.000000000000014, 52.40000000000023, 20.90000000000003, 42.50000000000024, 35.000000000000256, -841.1, 38.00000000000024, -169.00000000000043, -122.8000000000005, -59.80000000000025, -151.8999999999999, -109.0000000000006, -114.40000000000003, 3.1999999999999633, -328.6, -24.09999999999976, 17.899999999999988, 36.20000000000026, 20.000000000000014, 20.000000000000014, 6.199999999999973, 23.600000000000065, 65.00000000000014, 19.400000000000006, 20.000000000000014, 34.40000000000025, 22.400000000000052, -459.2, 14.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 46.100000000000236, 20.000000000000014, 26.300000000000114, 20.000000000000014, 14.599999999999966, 20.000000000000014, 20.000000000000014, 39.80000000000025, 20.000000000000014, 39.80000000000025, -316.0, 20.000000000000014, 20.000000000000014, -112.30000000000078, -54.09999999999987, -3.0999999999999934, 20.000000000000014, -429.59999999999997, -10.299999999999894, -127.00000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, -1.0000000000000346, -191.3, 31.700000000000212, -34.59999999999975], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 252.0, 380.0, 815.0, 0.0, 196.0, 123.0, 0.0, 17.0, 19.0, 16.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 7.0, 0.0, 13.0, 35.0, 0.0, 21.0, 19.0, 11.0, 0.0, 72.0, 94.0, 0.0, 7.0, 383.0, 150.0, 12.0, 12.0, 24.0, 0.0, 0.0, 0.0, 0.0, 135.0, 0.0, 0.0, 0.0, 4.0, 144.0, 80.0, 0.0, 0.0, 60.0, 0.0, 1.0, 0.0, 0.0, 549.0, 339.0, 0.0, 0.0, 362.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 15.0, 0.0, 0.0, 470.0, 0.0, 0.0, 98.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 9.0, 0.0, 0.0, 0.0, 6.0, 27.0, 0.0, 14.0, 177.0, 173.0, 1.0, 0.0, 125.0, 133.0, 31.0, 170.0, 0.0, 0.0, 0.0, 65.0, 0.0, 0.0, 0.0, 7.0, 23.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 149.0, 0.0, 0.0, 59.0, 134.0, 0.0, 0.0, 0.0, 77.0, 0.0, 0.0, 0.0, 0.0, 14.0, 8.0, 0.0, 0.0, 61.0, 18.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 698.0, 746.0, 85.0, 76.0, 0.0, 68.0, 0.0, 163.0, 64.0, 8.0, 166.0, 140.0, 0.0, 7.0, 0.0, 0.0, 0.0, 13.0, 0.0, 8.0, 0.0, 0.0, 332.0, 7.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 158.0, 159.0, 0.0, 0.0, 103.0, 0.0, 0.0, 17.0, 331.0, 204.0, 70.0, 21.0, 0.0, 0.0, 116.0, 0.0, 0.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.119123859772944, "mean_inference_ms": 3.007735154402255, "mean_action_processing_ms": 0.5458769760473302, "mean_env_wait_ms": 0.688801886165381, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04618990421295166, "StateBufferConnector_ms": 0.0054590702056884766, "ViewRequirementAgentConnector_ms": 0.3314402103424072}, "num_episodes": 18, "episode_return_max": 637.9000000000017, "episode_return_min": -208.50000000000048, "episode_return_mean": 19.673000000000144, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 157.75263693250002, "num_env_steps_trained_throughput_per_sec": 157.75263693250002, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 16604.06, "restore_workers_time_ms": 0.02, "training_step_time_ms": 16603.999, "sample_time_ms": 3878.21, "learn_time_ms": 12697.959, "learn_throughput": 315.011, "synch_weights_time_ms": 25.018}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "c52aa_00000", "date": "2024-08-13_00-00-01", "timestamp": 1723521601, "time_this_iter_s": 25.694069862365723, "time_total_s": 728.1679379940033, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c5790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 728.1679379940033, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 88.03714285714287, "ram_util_percent": 83.69142857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.930327789166144, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4600089429547547, "policy_loss": -0.0032348278609336052, "vf_loss": 1.4624820345608647, "vf_explained_var": 0.00229884007620433, "kl": 0.014266400293757862, "entropy": 1.1926018930616833, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4943267274904188, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2197709581523977, "policy_loss": -0.004969583991200481, "vf_loss": 1.2244627164785193, "vf_explained_var": 0.00195377544751243, "kl": 0.011707592367929141, "entropy": 1.2912845713751657, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 637.9000000000017, "episode_reward_min": -208.50000000000048, "episode_reward_mean": 19.573000000000135, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -841.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 65.00000000000014, "predator_policy": 746.0}, "policy_reward_mean": {"prey_policy": -32.96849999999999, "predator_policy": 42.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [151.8000000000002, 54.40000000000048, 18.099999999999945, 40.0000000000003, -114.80000000000022, 52.60000000000051, 63.50000000000052, -67.80000000000118, 41.800000000000324, -103.0999999999997, 53.300000000000516, -187.7000000000009, -71.2999999999999, -9.400000000000022, 40.0000000000003, 51.5000000000005, 83.49999999999909, 32.500000000000185, -95.50000000000031, 44.50000000000036, -208.50000000000048, 58.00000000000052, 36.70000000000025, 43.20000000000035, 55.30000000000046, 44.50000000000036, 17.199999999999935, 22.50000000000003, 16.19999999999996, 55.10000000000052, -65.30000000000085, -116.00000000000045, 44.50000000000036, -31.499999999999915, 40.0000000000003, 55.700000000000486, 19.199999999999967, 30.100000000000126, 40.0000000000003, -95.10000000000005, 40.0000000000003, -77.80000000000021, 49.90000000000046, -44.69999999999981, 50.80000000000048, 40.0000000000003, 22.100000000000076, 40.0000000000003, -8.199999999999923, 20.300000000000015, 72.39999999999989, 63.400000000000496, 637.9000000000017, 30.0000000000003, -114.60000000000105, -97.90000000000009, -39.199999999999996, -46.69999999999976, 61.10000000000049, 40.0000000000003, 42.800000000000345, 92.39999999999843, 54.40000000000051, -97.80000000000018, 38.300000000000274, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.10000000000034, 46.300000000000395, 43.60000000000036, 40.0000000000003, 59.800000000000516, 40.80000000000029, 40.0000000000003, -63.4000000000011, 33.900000000000205, 95.10000000000008, -16.000000000000053, 40.0000000000003, -76.30000000000007, 23.100000000000033, 42.70000000000034, 38.90000000000028, -38.70000000000004, -21.299999999999535, 31.200000000000166, 52.60000000000051, 42.500000000000355, -71.80000000000015, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 70.10000000000004, 40.2000000000003, 40.0000000000003, 10.900000000000079, 41.60000000000033, 16.799999999999976], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [43.400000000000226, -424.6, 46.10000000000024, -15.699999999999783, 20.000000000000014, -25.899999999999764, 20.000000000000014, 20.000000000000014, -255.10000000000002, 5.299999999999984, 32.60000000000023, 20.000000000000014, 24.20000000000008, 35.30000000000026, -76.60000000000075, -215.19999999999987, 21.80000000000004, 20.000000000000014, -96.99999999999991, -66.10000000000004, 32.300000000000225, 20.000000000000014, -693.1, -43.599999999999774, -304.30000000000007, -106.0000000000008, 20.000000000000014, -391.40000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.500000000000192, 33.50000000000024, 47.00000000000022, -2.499999999999993, 20.000000000000014, 20.000000000000014, -585.5, 20.000000000000014, 24.50000000000008, -120.70000000000027, -185.8000000000002, 38.000000000000256, 20.000000000000014, 13.699999999999969, 20.000000000000014, 12.199999999999973, 20.000000000000014, 26.300000000000125, 20.000000000000014, 24.50000000000008, 20.000000000000014, -36.699999999999775, 20.900000000000027, -5.199999999999934, 13.69999999999997, -353.8, 20.000000000000014, 36.20000000000026, 17.899999999999988, -74.50000000000068, -248.80000000000015, 20.000000000000014, -337.0, 24.50000000000008, 20.000000000000014, -116.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.900000000000134, 21.80000000000004, -23.799999999999763, 20.000000000000014, 1.0999999999999688, 20.000000000000014, 20.000000000000014, 20.000000000000014, 48.80000000000022, -292.8999999999999, 20.000000000000014, 20.000000000000014, -11.500000000000025, -259.3, 23.600000000000065, 26.300000000000114, -40.89999999999976, -80.80000000000064, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.89999999999992, 20.000000000000014, 20.000000000000014, -110.20000000000037, 23.000000000000057, -30.699999999999783, 20.000000000000014, 20.000000000000014, 52.40000000000023, 20.90000000000003, 42.50000000000024, 35.000000000000256, -841.1, 38.00000000000024, -169.00000000000043, -122.8000000000005, -59.80000000000025, -151.8999999999999, -109.0000000000006, -114.40000000000003, 3.1999999999999633, -328.6, -24.09999999999976, 17.899999999999988, 36.20000000000026, 20.000000000000014, 20.000000000000014, 6.199999999999973, 23.600000000000065, 65.00000000000014, 19.400000000000006, 20.000000000000014, 34.40000000000025, 22.400000000000052, -459.2, 14.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 46.100000000000236, 20.000000000000014, 26.300000000000114, 20.000000000000014, 14.599999999999966, 20.000000000000014, 20.000000000000014, 39.80000000000025, 20.000000000000014, 39.80000000000025, -316.0, 20.000000000000014, 20.000000000000014, -112.30000000000078, -54.09999999999987, -3.0999999999999934, 20.000000000000014, -429.59999999999997, -10.299999999999894, -127.00000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, -1.0000000000000346, -191.3, 31.700000000000212, -34.59999999999975, 20.000000000000014, 22.700000000000053, 17.899999999999988, 20.000000000000014, -13.599999999999783, -66.1000000000009, -3.099999999999965, -68.20000000000083, 9.499999999999964, 13.699999999999964, 20.000000000000014, 32.60000000000023, 20.000000000000014, 3.499999999999976, -114.40000000000029, -135.40000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.80000000000022, 5.299999999999965, 20.000000000000014, 12.199999999999969, 20.000000000000014, 20.000000000000014, -55.59999999999989, 24.50000000000009, 20.60000000000003, 20.000000000000014, -5.199999999999969, 1.9999999999999731], "policy_predator_policy_reward": [383.0, 150.0, 12.0, 12.0, 24.0, 0.0, 0.0, 0.0, 0.0, 135.0, 0.0, 0.0, 0.0, 4.0, 144.0, 80.0, 0.0, 0.0, 60.0, 0.0, 1.0, 0.0, 0.0, 549.0, 339.0, 0.0, 0.0, 362.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 15.0, 0.0, 0.0, 470.0, 0.0, 0.0, 98.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 11.0, 9.0, 0.0, 0.0, 0.0, 6.0, 27.0, 0.0, 14.0, 177.0, 173.0, 1.0, 0.0, 125.0, 133.0, 31.0, 170.0, 0.0, 0.0, 0.0, 65.0, 0.0, 0.0, 0.0, 7.0, 23.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 149.0, 0.0, 0.0, 59.0, 134.0, 0.0, 0.0, 0.0, 77.0, 0.0, 0.0, 0.0, 0.0, 14.0, 8.0, 0.0, 0.0, 61.0, 18.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 698.0, 746.0, 85.0, 76.0, 0.0, 68.0, 0.0, 163.0, 64.0, 8.0, 166.0, 140.0, 0.0, 7.0, 0.0, 0.0, 0.0, 13.0, 0.0, 8.0, 0.0, 0.0, 332.0, 7.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 158.0, 159.0, 0.0, 0.0, 103.0, 0.0, 0.0, 17.0, 331.0, 204.0, 70.0, 21.0, 0.0, 0.0, 116.0, 0.0, 0.0, 26.0, 0.0, 0.0, 1.0, 0.0, 0.0, 41.0, 50.0, 0.0, 5.0, 3.0, 0.0, 0.0, 0.0, 19.0, 104.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 36.0, 6.0, 0.0, 1.0, 6.0, 14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.135359250981342, "mean_inference_ms": 3.060356637853759, "mean_action_processing_ms": 0.5523253711978459, "mean_env_wait_ms": 0.70165375633521, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04630410671234131, "StateBufferConnector_ms": 0.006302475929260254, "ViewRequirementAgentConnector_ms": 0.3375363349914551}, "num_episodes": 18, "episode_return_max": 637.9000000000017, "episode_return_min": -208.50000000000048, "episode_return_mean": 19.573000000000135, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 211.2887012929425, "num_env_steps_trained_throughput_per_sec": 211.2887012929425, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 16790.634, "restore_workers_time_ms": 0.022, "training_step_time_ms": 16790.568, "sample_time_ms": 3952.729, "learn_time_ms": 12812.003, "learn_throughput": 312.207, "synch_weights_time_ms": 23.278}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "c52aa_00000", "date": "2024-08-13_00-00-20", "timestamp": 1723521620, "time_this_iter_s": 19.03113603591919, "time_total_s": 747.1990740299225, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87edc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 747.1990740299225, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 86.42592592592592, "ram_util_percent": 83.88518518518516}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.312560248635118, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5880229384810836, "policy_loss": -0.0012774758844109125, "vf_loss": 2.5889248982308404, "vf_explained_var": 0.021153066839490618, "kl": 0.007033146972162501, "entropy": 1.182076700465389, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.560877930952443, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5054954888013306, "policy_loss": -0.004054675965013091, "vf_loss": 1.5092815842893388, "vf_explained_var": 0.002225143032729941, "kl": 0.011318161574738226, "entropy": 1.2395272310448702, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 637.9000000000017, "episode_reward_min": -116.00000000000045, "episode_reward_mean": 27.94800000000011, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -841.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 89.2999999999999, "predator_policy": 746.0}, "policy_reward_mean": {"prey_policy": -17.14099999999999, "predator_policy": 31.115}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.70000000000025, 43.20000000000035, 55.30000000000046, 44.50000000000036, 17.199999999999935, 22.50000000000003, 16.19999999999996, 55.10000000000052, -65.30000000000085, -116.00000000000045, 44.50000000000036, -31.499999999999915, 40.0000000000003, 55.700000000000486, 19.199999999999967, 30.100000000000126, 40.0000000000003, -95.10000000000005, 40.0000000000003, -77.80000000000021, 49.90000000000046, -44.69999999999981, 50.80000000000048, 40.0000000000003, 22.100000000000076, 40.0000000000003, -8.199999999999923, 20.300000000000015, 72.39999999999989, 63.400000000000496, 637.9000000000017, 30.0000000000003, -114.60000000000105, -97.90000000000009, -39.199999999999996, -46.69999999999976, 61.10000000000049, 40.0000000000003, 42.800000000000345, 92.39999999999843, 54.40000000000051, -97.80000000000018, 38.300000000000274, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.10000000000034, 46.300000000000395, 43.60000000000036, 40.0000000000003, 59.800000000000516, 40.80000000000029, 40.0000000000003, -63.4000000000011, 33.900000000000205, 95.10000000000008, -16.000000000000053, 40.0000000000003, -76.30000000000007, 23.100000000000033, 42.70000000000034, 38.90000000000028, -38.70000000000004, -21.299999999999535, 31.200000000000166, 52.60000000000051, 42.500000000000355, -71.80000000000015, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 70.10000000000004, 40.2000000000003, 40.0000000000003, 10.900000000000079, 41.60000000000033, 16.799999999999976, 59.50000000000049, 31.200000000000166, 71.79999999999983, 47.200000000000415, 40.0000000000003, 35.60000000000029, 34.30000000000022, -54.599999999999866, 40.0000000000003, 0.5999999999999972, 92.1999999999986, 81.49999999999915, -63.50000000000187, 67.50000000000011, 131.79999999999856, 61.300000000000416, -75.50000000000001, 40.0000000000003, 40.0000000000003, 42.700000000000344, 73.29999999999993, -31.999999999999602], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999969, 20.000000000000014, 12.199999999999973, 20.000000000000014, 26.300000000000125, 20.000000000000014, 24.50000000000008, 20.000000000000014, -36.699999999999775, 20.900000000000027, -5.199999999999934, 13.69999999999997, -353.8, 20.000000000000014, 36.20000000000026, 17.899999999999988, -74.50000000000068, -248.80000000000015, 20.000000000000014, -337.0, 24.50000000000008, 20.000000000000014, -116.5, 20.000000000000014, 20.000000000000014, 20.000000000000014, 26.900000000000134, 21.80000000000004, -23.799999999999763, 20.000000000000014, 1.0999999999999688, 20.000000000000014, 20.000000000000014, 20.000000000000014, 48.80000000000022, -292.8999999999999, 20.000000000000014, 20.000000000000014, -11.500000000000025, -259.3, 23.600000000000065, 26.300000000000114, -40.89999999999976, -80.80000000000064, 20.000000000000014, 30.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, -19.89999999999992, 20.000000000000014, 20.000000000000014, -110.20000000000037, 23.000000000000057, -30.699999999999783, 20.000000000000014, 20.000000000000014, 52.40000000000023, 20.90000000000003, 42.50000000000024, 35.000000000000256, -841.1, 38.00000000000024, -169.00000000000043, -122.8000000000005, -59.80000000000025, -151.8999999999999, -109.0000000000006, -114.40000000000003, 3.1999999999999633, -328.6, -24.09999999999976, 17.899999999999988, 36.20000000000026, 20.000000000000014, 20.000000000000014, 6.199999999999973, 23.600000000000065, 65.00000000000014, 19.400000000000006, 20.000000000000014, 34.40000000000025, 22.400000000000052, -459.2, 14.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 46.100000000000236, 20.000000000000014, 26.300000000000114, 20.000000000000014, 14.599999999999966, 20.000000000000014, 20.000000000000014, 39.80000000000025, 20.000000000000014, 39.80000000000025, -316.0, 20.000000000000014, 20.000000000000014, -112.30000000000078, -54.09999999999987, -3.0999999999999934, 20.000000000000014, -429.59999999999997, -10.299999999999894, -127.00000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, -1.0000000000000346, -191.3, 31.700000000000212, -34.59999999999975, 20.000000000000014, 22.700000000000053, 17.899999999999988, 20.000000000000014, -13.599999999999783, -66.1000000000009, -3.099999999999965, -68.20000000000083, 9.499999999999964, 13.699999999999964, 20.000000000000014, 32.60000000000023, 20.000000000000014, 3.499999999999976, -114.40000000000029, -135.40000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.80000000000022, 5.299999999999965, 20.000000000000014, 12.199999999999969, 20.000000000000014, 20.000000000000014, -55.59999999999989, 24.50000000000009, 20.60000000000003, 20.000000000000014, -5.199999999999969, 1.9999999999999731, 20.90000000000004, 23.60000000000007, 20.000000000000014, 3.1999999999999615, 46.10000000000018, -4.300000000000029, 27.20000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999953, 20.000000000000014, 7.399999999999967, 20.90000000000003, -135.4000000000001, -86.20000000000059, 20.000000000000014, 20.000000000000014, -42.999999999999915, -18.399999999999807, 72.1999999999996, 20.000000000000014, 45.50000000000017, 20.000000000000014, -49.299999999999905, -47.19999999999976, 51.50000000000001, 5.0000000000000515, 42.50000000000025, 89.2999999999999, 17.299999999999976, 20.000000000000014, -200.50000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.700000000000063, 20.000000000000014, 39.800000000000196, 33.50000000000024, -47.1999999999998, -17.799999999999795], "policy_predator_policy_reward": [0.0, 3.0, 0.0, 11.0, 9.0, 0.0, 0.0, 0.0, 6.0, 27.0, 0.0, 14.0, 177.0, 173.0, 1.0, 0.0, 125.0, 133.0, 31.0, 170.0, 0.0, 0.0, 0.0, 65.0, 0.0, 0.0, 0.0, 7.0, 23.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 149.0, 0.0, 0.0, 59.0, 134.0, 0.0, 0.0, 0.0, 77.0, 0.0, 0.0, 0.0, 0.0, 14.0, 8.0, 0.0, 0.0, 61.0, 18.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 698.0, 746.0, 85.0, 76.0, 0.0, 68.0, 0.0, 163.0, 64.0, 8.0, 166.0, 140.0, 0.0, 7.0, 0.0, 0.0, 0.0, 13.0, 0.0, 8.0, 0.0, 0.0, 332.0, 7.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 158.0, 159.0, 0.0, 0.0, 103.0, 0.0, 0.0, 17.0, 331.0, 204.0, 70.0, 21.0, 0.0, 0.0, 116.0, 0.0, 0.0, 26.0, 0.0, 0.0, 1.0, 0.0, 0.0, 41.0, 50.0, 0.0, 5.0, 3.0, 0.0, 0.0, 0.0, 19.0, 104.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 36.0, 6.0, 0.0, 1.0, 6.0, 14.0, 10.0, 5.0, 2.0, 6.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 66.0, 101.0, 0.0, 0.0, 8.0, 54.0, 0.0, 0.0, 4.0, 12.0, 0.0, 33.0, 0.0, 11.0, 0.0, 0.0, 13.0, 11.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.153349760758905, "mean_inference_ms": 3.12073539622818, "mean_action_processing_ms": 0.5588843899318381, "mean_env_wait_ms": 0.7161255452877137, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0624699592590332, "StateBufferConnector_ms": 0.0054798126220703125, "ViewRequirementAgentConnector_ms": 0.30394208431243896}, "num_episodes": 22, "episode_return_max": 637.9000000000017, "episode_return_min": -116.00000000000045, "episode_return_mean": 27.94800000000011, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 282.2727840180846, "num_env_steps_trained_throughput_per_sec": 282.2727840180846, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 16605.659, "restore_workers_time_ms": 0.022, "training_step_time_ms": 16605.593, "sample_time_ms": 3837.221, "learn_time_ms": 12743.608, "learn_throughput": 313.883, "synch_weights_time_ms": 22.37}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "c52aa_00000", "date": "2024-08-13_00-00-34", "timestamp": 1723521634, "time_this_iter_s": 14.261329174041748, "time_total_s": 761.4604032039642, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9bac10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 761.4604032039642, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 76.5047619047619, "ram_util_percent": 83.37619047619049}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0763076344416256, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.207874143659753, "policy_loss": -0.0024691028177994427, "vf_loss": 1.2096029818373382, "vf_explained_var": 0.01948972391703772, "kl": 0.013864251413135395, "entropy": 1.1318216415309401, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.415349213309862, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9611612474634534, "policy_loss": -0.0016866822291545017, "vf_loss": 0.9627082191210575, "vf_explained_var": 0.001846358195814506, "kl": 0.005887273007084205, "entropy": 1.2609630949282773, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 637.9000000000017, "episode_reward_min": -114.60000000000105, "episode_reward_mean": 33.66000000000011, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -841.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 89.2999999999999, "predator_policy": 746.0}, "policy_reward_mean": {"prey_policy": -10.54999999999999, "predator_policy": 27.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 22.100000000000076, 40.0000000000003, -8.199999999999923, 20.300000000000015, 72.39999999999989, 63.400000000000496, 637.9000000000017, 30.0000000000003, -114.60000000000105, -97.90000000000009, -39.199999999999996, -46.69999999999976, 61.10000000000049, 40.0000000000003, 42.800000000000345, 92.39999999999843, 54.40000000000051, -97.80000000000018, 38.300000000000274, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.10000000000034, 46.300000000000395, 43.60000000000036, 40.0000000000003, 59.800000000000516, 40.80000000000029, 40.0000000000003, -63.4000000000011, 33.900000000000205, 95.10000000000008, -16.000000000000053, 40.0000000000003, -76.30000000000007, 23.100000000000033, 42.70000000000034, 38.90000000000028, -38.70000000000004, -21.299999999999535, 31.200000000000166, 52.60000000000051, 42.500000000000355, -71.80000000000015, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 70.10000000000004, 40.2000000000003, 40.0000000000003, 10.900000000000079, 41.60000000000033, 16.799999999999976, 59.50000000000049, 31.200000000000166, 71.79999999999983, 47.200000000000415, 40.0000000000003, 35.60000000000029, 34.30000000000022, -54.599999999999866, 40.0000000000003, 0.5999999999999972, 92.1999999999986, 81.49999999999915, -63.50000000000187, 67.50000000000011, 131.79999999999856, 61.300000000000416, -75.50000000000001, 40.0000000000003, 40.0000000000003, 42.700000000000344, 73.29999999999993, -31.999999999999602, 58.60000000000047, 45.300000000000395, 21.300000000000008, 40.0000000000003, -71.40000000000009, 48.000000000000426, 40.0000000000003, 11.300000000000042, -36.69999999999998, 54.10000000000042, 73.1999999999998, 55.800000000000175, 65.70000000000036, 51.9000000000005, 103.89999999999867, 38.300000000000324, 65.20000000000039, 40.0000000000003, 71.79999999999993, 71.49999999999999, -28.199999999999662, -6.199999999999688, -11.699999999999598], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, -19.89999999999992, 20.000000000000014, 20.000000000000014, -110.20000000000037, 23.000000000000057, -30.699999999999783, 20.000000000000014, 20.000000000000014, 52.40000000000023, 20.90000000000003, 42.50000000000024, 35.000000000000256, -841.1, 38.00000000000024, -169.00000000000043, -122.8000000000005, -59.80000000000025, -151.8999999999999, -109.0000000000006, -114.40000000000003, 3.1999999999999633, -328.6, -24.09999999999976, 17.899999999999988, 36.20000000000026, 20.000000000000014, 20.000000000000014, 6.199999999999973, 23.600000000000065, 65.00000000000014, 19.400000000000006, 20.000000000000014, 34.40000000000025, 22.400000000000052, -459.2, 14.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 46.100000000000236, 20.000000000000014, 26.300000000000114, 20.000000000000014, 14.599999999999966, 20.000000000000014, 20.000000000000014, 39.80000000000025, 20.000000000000014, 39.80000000000025, -316.0, 20.000000000000014, 20.000000000000014, -112.30000000000078, -54.09999999999987, -3.0999999999999934, 20.000000000000014, -429.59999999999997, -10.299999999999894, -127.00000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, -1.0000000000000346, -191.3, 31.700000000000212, -34.59999999999975, 20.000000000000014, 22.700000000000053, 17.899999999999988, 20.000000000000014, -13.599999999999783, -66.1000000000009, -3.099999999999965, -68.20000000000083, 9.499999999999964, 13.699999999999964, 20.000000000000014, 32.60000000000023, 20.000000000000014, 3.499999999999976, -114.40000000000029, -135.40000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.80000000000022, 5.299999999999965, 20.000000000000014, 12.199999999999969, 20.000000000000014, 20.000000000000014, -55.59999999999989, 24.50000000000009, 20.60000000000003, 20.000000000000014, -5.199999999999969, 1.9999999999999731, 20.90000000000004, 23.60000000000007, 20.000000000000014, 3.1999999999999615, 46.10000000000018, -4.300000000000029, 27.20000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999953, 20.000000000000014, 7.399999999999967, 20.90000000000003, -135.4000000000001, -86.20000000000059, 20.000000000000014, 20.000000000000014, -42.999999999999915, -18.399999999999807, 72.1999999999996, 20.000000000000014, 45.50000000000017, 20.000000000000014, -49.299999999999905, -47.19999999999976, 51.50000000000001, 5.0000000000000515, 42.50000000000025, 89.2999999999999, 17.299999999999976, 20.000000000000014, -200.50000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.700000000000063, 20.000000000000014, 39.800000000000196, 33.50000000000024, -47.1999999999998, -17.799999999999795, 20.000000000000014, 32.60000000000023, 20.000000000000014, 11.299999999999974, -15.699999999999768, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, -297.1, 20.000000000000014, 16.999999999999975, 20.000000000000014, 20.000000000000014, 15.199999999999964, -40.89999999999976, 5.2999999999999705, -189.99999999999994, 20.000000000000014, 19.1, 48.200000000000216, 20.000000000000014, 26.00000000000015, 6.800000000000041, 20.000000000000014, 43.70000000000023, 23.90000000000008, 20.000000000000014, 78.49999999999936, 25.400000000000098, -12.699999999999871, 20.000000000000014, 45.20000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 55.10000000000023, 34.400000000000254, 37.10000000000026, -59.80000000000037, -30.39999999999992, 13.699999999999967, -61.90000000000075, 1.0999999999999688, -59.80000000000062], "policy_predator_policy_reward": [0.0, 0.0, 14.0, 8.0, 0.0, 0.0, 61.0, 18.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 698.0, 746.0, 85.0, 76.0, 0.0, 68.0, 0.0, 163.0, 64.0, 8.0, 166.0, 140.0, 0.0, 7.0, 0.0, 0.0, 0.0, 13.0, 0.0, 8.0, 0.0, 0.0, 332.0, 7.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 158.0, 159.0, 0.0, 0.0, 103.0, 0.0, 0.0, 17.0, 331.0, 204.0, 70.0, 21.0, 0.0, 0.0, 116.0, 0.0, 0.0, 26.0, 0.0, 0.0, 1.0, 0.0, 0.0, 41.0, 50.0, 0.0, 5.0, 3.0, 0.0, 0.0, 0.0, 19.0, 104.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 36.0, 6.0, 0.0, 1.0, 6.0, 14.0, 10.0, 5.0, 2.0, 6.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 66.0, 101.0, 0.0, 0.0, 8.0, 54.0, 0.0, 0.0, 4.0, 12.0, 0.0, 33.0, 0.0, 11.0, 0.0, 0.0, 13.0, 11.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 6.0, 0.0, 0.0, 14.0, 0.0, 17.0, 0.0, 0.0, 151.0, 34.0, 6.0, 5.0, 0.0, 0.0, 29.0, 8.0, 70.0, 78.0, 0.0, 15.0, 5.0, 0.0, 0.0, 23.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 62.0, 39.0, 3.0, 38.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1673852362210921, "mean_inference_ms": 3.169115706958053, "mean_action_processing_ms": 0.5655677306339001, "mean_env_wait_ms": 0.7290149734222622, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0645902156829834, "StateBufferConnector_ms": 0.0053899288177490234, "ViewRequirementAgentConnector_ms": 0.28004956245422363}, "num_episodes": 23, "episode_return_max": 637.9000000000017, "episode_return_min": -114.60000000000105, "episode_return_mean": 33.66000000000011, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 272.6879659280473, "num_env_steps_trained_throughput_per_sec": 272.6879659280473, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 16638.254, "restore_workers_time_ms": 0.021, "training_step_time_ms": 16638.189, "sample_time_ms": 3788.479, "learn_time_ms": 12824.564, "learn_throughput": 311.901, "synch_weights_time_ms": 22.381}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "c52aa_00000", "date": "2024-08-13_00-00-49", "timestamp": 1723521649, "time_this_iter_s": 14.786015033721924, "time_total_s": 776.2464182376862, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87eee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 776.2464182376862, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 77.36666666666667, "ram_util_percent": 83.32380952380954}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0507484360267876, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0491059985819948, "policy_loss": -0.002916641235745773, "vf_loss": 1.0512368541388284, "vf_explained_var": -0.014883651556792082, "kl": 0.014716842923098992, "entropy": 1.185403928996394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.38800880819874467, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6830026970180885, "policy_loss": -0.0039471793000798215, "vf_loss": 0.686719004979367, "vf_explained_var": 0.005955369857253221, "kl": 0.00972883478636804, "entropy": 1.269281185808636, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 131.79999999999856, "episode_reward_min": -97.80000000000018, "episode_reward_mean": 29.589000000000123, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -459.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 89.2999999999999, "predator_policy": 332.0}, "policy_reward_mean": {"prey_policy": -2.4854999999999876, "predator_policy": 17.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-97.80000000000018, 38.300000000000274, 40.0000000000003, 40.0000000000003, 40.0000000000003, 66.10000000000034, 46.300000000000395, 43.60000000000036, 40.0000000000003, 59.800000000000516, 40.80000000000029, 40.0000000000003, -63.4000000000011, 33.900000000000205, 95.10000000000008, -16.000000000000053, 40.0000000000003, -76.30000000000007, 23.100000000000033, 42.70000000000034, 38.90000000000028, -38.70000000000004, -21.299999999999535, 31.200000000000166, 52.60000000000051, 42.500000000000355, -71.80000000000015, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 70.10000000000004, 40.2000000000003, 40.0000000000003, 10.900000000000079, 41.60000000000033, 16.799999999999976, 59.50000000000049, 31.200000000000166, 71.79999999999983, 47.200000000000415, 40.0000000000003, 35.60000000000029, 34.30000000000022, -54.599999999999866, 40.0000000000003, 0.5999999999999972, 92.1999999999986, 81.49999999999915, -63.50000000000187, 67.50000000000011, 131.79999999999856, 61.300000000000416, -75.50000000000001, 40.0000000000003, 40.0000000000003, 42.700000000000344, 73.29999999999993, -31.999999999999602, 58.60000000000047, 45.300000000000395, 21.300000000000008, 40.0000000000003, -71.40000000000009, 48.000000000000426, 40.0000000000003, 11.300000000000042, -36.69999999999998, 54.10000000000042, 73.1999999999998, 55.800000000000175, 65.70000000000036, 51.9000000000005, 103.89999999999867, 38.300000000000324, 65.20000000000039, 40.0000000000003, 71.79999999999993, 71.49999999999999, -28.199999999999662, -6.199999999999688, -11.699999999999598, 24.400000000000055, -21.799999999999564, 67.90000000000019, -72.70000000000148, 51.8000000000005, 56.10000000000051, 36.60000000000025, 50.80000000000048, 46.300000000000395, 56.200000000000514, -19.199999999999697, 23.500000000000032, 40.0000000000003, 40.0000000000003, 27.000000000000096, 46.20000000000041, -0.3999999999998781, 50.400000000000475], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [22.400000000000052, -459.2, 14.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 46.100000000000236, 20.000000000000014, 26.300000000000114, 20.000000000000014, 14.599999999999966, 20.000000000000014, 20.000000000000014, 39.80000000000025, 20.000000000000014, 39.80000000000025, -316.0, 20.000000000000014, 20.000000000000014, -112.30000000000078, -54.09999999999987, -3.0999999999999934, 20.000000000000014, -429.59999999999997, -10.299999999999894, -127.00000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, -1.0000000000000346, -191.3, 31.700000000000212, -34.59999999999975, 20.000000000000014, 22.700000000000053, 17.899999999999988, 20.000000000000014, -13.599999999999783, -66.1000000000009, -3.099999999999965, -68.20000000000083, 9.499999999999964, 13.699999999999964, 20.000000000000014, 32.60000000000023, 20.000000000000014, 3.499999999999976, -114.40000000000029, -135.40000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.80000000000022, 5.299999999999965, 20.000000000000014, 12.199999999999969, 20.000000000000014, 20.000000000000014, -55.59999999999989, 24.50000000000009, 20.60000000000003, 20.000000000000014, -5.199999999999969, 1.9999999999999731, 20.90000000000004, 23.60000000000007, 20.000000000000014, 3.1999999999999615, 46.10000000000018, -4.300000000000029, 27.20000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999953, 20.000000000000014, 7.399999999999967, 20.90000000000003, -135.4000000000001, -86.20000000000059, 20.000000000000014, 20.000000000000014, -42.999999999999915, -18.399999999999807, 72.1999999999996, 20.000000000000014, 45.50000000000017, 20.000000000000014, -49.299999999999905, -47.19999999999976, 51.50000000000001, 5.0000000000000515, 42.50000000000025, 89.2999999999999, 17.299999999999976, 20.000000000000014, -200.50000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.700000000000063, 20.000000000000014, 39.800000000000196, 33.50000000000024, -47.1999999999998, -17.799999999999795, 20.000000000000014, 32.60000000000023, 20.000000000000014, 11.299999999999974, -15.699999999999768, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, -297.1, 20.000000000000014, 16.999999999999975, 20.000000000000014, 20.000000000000014, 15.199999999999964, -40.89999999999976, 5.2999999999999705, -189.99999999999994, 20.000000000000014, 19.1, 48.200000000000216, 20.000000000000014, 26.00000000000015, 6.800000000000041, 20.000000000000014, 43.70000000000023, 23.90000000000008, 20.000000000000014, 78.49999999999936, 25.400000000000098, -12.699999999999871, 20.000000000000014, 45.20000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 55.10000000000023, 34.400000000000254, 37.10000000000026, -59.80000000000037, -30.39999999999992, 13.699999999999967, -61.90000000000075, 1.0999999999999688, -59.80000000000062, 30.800000000000196, -30.39999999999975, -21.099999999999746, -57.70000000000031, 20.000000000000014, 47.90000000000021, -87.10000000000075, -88.6000000000007, 29.900000000000183, 17.899999999999984, 23.00000000000006, 28.100000000000147, 11.599999999999964, 20.000000000000014, 30.800000000000196, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 36.20000000000026, -59.80000000000021, -30.399999999999793, 3.1999999999999615, 5.299999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -12.9999999999998, 15.199999999999967, 20.000000000000014, 9.499999999999979, -46.899999999999814, 28.400000000000155, 20.000000000000014], "policy_predator_policy_reward": [332.0, 7.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 158.0, 159.0, 0.0, 0.0, 103.0, 0.0, 0.0, 17.0, 331.0, 204.0, 70.0, 21.0, 0.0, 0.0, 116.0, 0.0, 0.0, 26.0, 0.0, 0.0, 1.0, 0.0, 0.0, 41.0, 50.0, 0.0, 5.0, 3.0, 0.0, 0.0, 0.0, 19.0, 104.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 36.0, 6.0, 0.0, 1.0, 6.0, 14.0, 10.0, 5.0, 2.0, 6.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 66.0, 101.0, 0.0, 0.0, 8.0, 54.0, 0.0, 0.0, 4.0, 12.0, 0.0, 33.0, 0.0, 11.0, 0.0, 0.0, 13.0, 11.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 6.0, 0.0, 0.0, 14.0, 0.0, 17.0, 0.0, 0.0, 151.0, 34.0, 6.0, 5.0, 0.0, 0.0, 29.0, 8.0, 70.0, 78.0, 0.0, 15.0, 5.0, 0.0, 0.0, 23.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 62.0, 39.0, 3.0, 38.0, 9.0, 24.0, 0.0, 57.0, 0.0, 0.0, 0.0, 66.0, 37.0, 1.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 71.0, 8.0, 7.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 1.0, 0.0, 37.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1840717678124368, "mean_inference_ms": 3.224466823866404, "mean_action_processing_ms": 0.5702838497915199, "mean_env_wait_ms": 0.7405952368288373, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.06414103507995605, "StateBufferConnector_ms": 0.005401253700256348, "ViewRequirementAgentConnector_ms": 0.2745985984802246}, "num_episodes": 18, "episode_return_max": 131.79999999999856, "episode_return_min": -97.80000000000018, "episode_return_mean": 29.589000000000123, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 238.36054158477643, "num_env_steps_trained_throughput_per_sec": 238.36054158477643, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 17043.155, "restore_workers_time_ms": 0.021, "training_step_time_ms": 17043.084, "sample_time_ms": 3912.684, "learn_time_ms": 13105.022, "learn_throughput": 305.227, "synch_weights_time_ms": 22.366}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "c52aa_00000", "date": "2024-08-13_00-01-06", "timestamp": 1723521666, "time_this_iter_s": 16.857350826263428, "time_total_s": 793.1037690639496, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab878e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 793.1037690639496, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 83.21666666666667, "ram_util_percent": 83.62916666666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1116370640340305, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.197795128167937, "policy_loss": -0.002645839553045493, "vf_loss": 1.1997975321043106, "vf_explained_var": 0.04985917125429426, "kl": 0.012050819663227954, "entropy": 1.2232193230321167, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.35920579923839163, "cur_kl_coeff": 0.023730468750000008, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.75683735914962, "policy_loss": -0.0006983440534443294, "vf_loss": 0.7574208342918644, "vf_explained_var": 0.005020373965066577, "kl": 0.004840630851016652, "entropy": 1.2402909300945424, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 131.79999999999856, "episode_reward_min": -75.50000000000001, "episode_reward_mean": 33.47500000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -297.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 89.2999999999999, "predator_policy": 151.0}, "policy_reward_mean": {"prey_policy": 6.342500000000026, "predator_policy": 10.395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [23.100000000000033, 42.70000000000034, 38.90000000000028, -38.70000000000004, -21.299999999999535, 31.200000000000166, 52.60000000000051, 42.500000000000355, -71.80000000000015, 40.0000000000003, 40.0000000000003, 40.0000000000003, 40.0000000000003, 70.10000000000004, 40.2000000000003, 40.0000000000003, 10.900000000000079, 41.60000000000033, 16.799999999999976, 59.50000000000049, 31.200000000000166, 71.79999999999983, 47.200000000000415, 40.0000000000003, 35.60000000000029, 34.30000000000022, -54.599999999999866, 40.0000000000003, 0.5999999999999972, 92.1999999999986, 81.49999999999915, -63.50000000000187, 67.50000000000011, 131.79999999999856, 61.300000000000416, -75.50000000000001, 40.0000000000003, 40.0000000000003, 42.700000000000344, 73.29999999999993, -31.999999999999602, 58.60000000000047, 45.300000000000395, 21.300000000000008, 40.0000000000003, -71.40000000000009, 48.000000000000426, 40.0000000000003, 11.300000000000042, -36.69999999999998, 54.10000000000042, 73.1999999999998, 55.800000000000175, 65.70000000000036, 51.9000000000005, 103.89999999999867, 38.300000000000324, 65.20000000000039, 40.0000000000003, 71.79999999999993, 71.49999999999999, -28.199999999999662, -6.199999999999688, -11.699999999999598, 24.400000000000055, -21.799999999999564, 67.90000000000019, -72.70000000000148, 51.8000000000005, 56.10000000000051, 36.60000000000025, 50.80000000000048, 46.300000000000395, 56.200000000000514, -19.199999999999697, 23.500000000000032, 40.0000000000003, 40.0000000000003, 27.000000000000096, 46.20000000000041, -0.3999999999998781, 50.400000000000475, 0.20000000000024978, 37.90000000000027, 40.0000000000003, 31.70000000000021, 61.60000000000051, 71.89999999999986, 63.40000000000053, 52.10000000000048, 15.799999999999919, 35.600000000000236, 48.70000000000045, 58.00000000000051, 59.800000000000516, 47.200000000000415, 14.799999999999937, 41.80000000000033, 57.10000000000053, 61.4000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [31.700000000000212, -34.59999999999975, 20.000000000000014, 22.700000000000053, 17.899999999999988, 20.000000000000014, -13.599999999999783, -66.1000000000009, -3.099999999999965, -68.20000000000083, 9.499999999999964, 13.699999999999964, 20.000000000000014, 32.60000000000023, 20.000000000000014, 3.499999999999976, -114.40000000000029, -135.40000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 57.80000000000022, 5.299999999999965, 20.000000000000014, 12.199999999999969, 20.000000000000014, 20.000000000000014, -55.59999999999989, 24.50000000000009, 20.60000000000003, 20.000000000000014, -5.199999999999969, 1.9999999999999731, 20.90000000000004, 23.60000000000007, 20.000000000000014, 3.1999999999999615, 46.10000000000018, -4.300000000000029, 27.20000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999953, 20.000000000000014, 7.399999999999967, 20.90000000000003, -135.4000000000001, -86.20000000000059, 20.000000000000014, 20.000000000000014, -42.999999999999915, -18.399999999999807, 72.1999999999996, 20.000000000000014, 45.50000000000017, 20.000000000000014, -49.299999999999905, -47.19999999999976, 51.50000000000001, 5.0000000000000515, 42.50000000000025, 89.2999999999999, 17.299999999999976, 20.000000000000014, -200.50000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.700000000000063, 20.000000000000014, 39.800000000000196, 33.50000000000024, -47.1999999999998, -17.799999999999795, 20.000000000000014, 32.60000000000023, 20.000000000000014, 11.299999999999974, -15.699999999999768, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, -297.1, 20.000000000000014, 16.999999999999975, 20.000000000000014, 20.000000000000014, 15.199999999999964, -40.89999999999976, 5.2999999999999705, -189.99999999999994, 20.000000000000014, 19.1, 48.200000000000216, 20.000000000000014, 26.00000000000015, 6.800000000000041, 20.000000000000014, 43.70000000000023, 23.90000000000008, 20.000000000000014, 78.49999999999936, 25.400000000000098, -12.699999999999871, 20.000000000000014, 45.20000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 55.10000000000023, 34.400000000000254, 37.10000000000026, -59.80000000000037, -30.39999999999992, 13.699999999999967, -61.90000000000075, 1.0999999999999688, -59.80000000000062, 30.800000000000196, -30.39999999999975, -21.099999999999746, -57.70000000000031, 20.000000000000014, 47.90000000000021, -87.10000000000075, -88.6000000000007, 29.900000000000183, 17.899999999999984, 23.00000000000006, 28.100000000000147, 11.599999999999964, 20.000000000000014, 30.800000000000196, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 36.20000000000026, -59.80000000000021, -30.399999999999793, 3.1999999999999615, 5.299999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -12.9999999999998, 15.199999999999967, 20.000000000000014, 9.499999999999979, -46.899999999999814, 28.400000000000155, 20.000000000000014, -19.899999999999743, 1.0999999999999794, -9.399999999999912, 23.30000000000006, 20.000000000000014, 20.000000000000014, -5.200000000000037, 8.899999999999983, 41.60000000000025, 20.000000000000014, 40.40000000000019, 24.50000000000008, 35.30000000000026, 28.100000000000147, 23.300000000000068, 21.80000000000004, -26.199999999999797, 20.000000000000014, 11.59999999999997, 20.000000000000014, 21.80000000000004, 20.900000000000027, 20.000000000000014, 38.000000000000256, 39.80000000000025, 20.000000000000014, 20.000000000000014, 27.20000000000013, 21.800000000000043, -42.99999999999977, 20.000000000000014, 21.800000000000047, 30.800000000000196, 26.300000000000114, 40.40000000000025, 20.000000000000014], "policy_predator_policy_reward": [0.0, 26.0, 0.0, 0.0, 1.0, 0.0, 0.0, 41.0, 50.0, 0.0, 5.0, 3.0, 0.0, 0.0, 0.0, 19.0, 104.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0, 0.0, 36.0, 6.0, 0.0, 1.0, 6.0, 14.0, 10.0, 5.0, 2.0, 6.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 66.0, 101.0, 0.0, 0.0, 8.0, 54.0, 0.0, 0.0, 4.0, 12.0, 0.0, 33.0, 0.0, 11.0, 0.0, 0.0, 13.0, 11.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 6.0, 0.0, 0.0, 14.0, 0.0, 17.0, 0.0, 0.0, 151.0, 34.0, 6.0, 5.0, 0.0, 0.0, 29.0, 8.0, 70.0, 78.0, 0.0, 15.0, 5.0, 0.0, 0.0, 23.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 62.0, 39.0, 3.0, 38.0, 9.0, 24.0, 0.0, 57.0, 0.0, 0.0, 0.0, 66.0, 37.0, 1.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 71.0, 8.0, 7.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 1.0, 0.0, 37.0, 2.0, 0.0, 19.0, 0.0, 7.0, 17.0, 0.0, 0.0, 12.0, 16.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 22.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1904335741723238, "mean_inference_ms": 3.245591839844958, "mean_action_processing_ms": 0.5715878401378753, "mean_env_wait_ms": 0.7463597375074414, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.025247931480407715, "StateBufferConnector_ms": 0.004704833030700684, "ViewRequirementAgentConnector_ms": 0.20021581649780273}, "num_episodes": 18, "episode_return_max": 131.79999999999856, "episode_return_min": -75.50000000000001, "episode_return_mean": 33.47500000000016, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 220.62638254636204, "num_env_steps_trained_throughput_per_sec": 220.62638254636204, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 17158.412, "restore_workers_time_ms": 0.021, "training_step_time_ms": 17158.34, "sample_time_ms": 4056.546, "learn_time_ms": 13077.46, "learn_throughput": 305.87, "synch_weights_time_ms": 21.394}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "c52aa_00000", "date": "2024-08-13_00-01-25", "timestamp": 1723521685, "time_this_iter_s": 18.49023699760437, "time_total_s": 811.594006061554, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc87ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 811.594006061554, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 86.46153846153847, "ram_util_percent": 83.36923076923077}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6522699183138905, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5644320035106922, "policy_loss": -0.003482795941332976, "vf_loss": 3.567088892724779, "vf_explained_var": 0.07148256364953581, "kl": 0.01546844113979035, "entropy": 1.239141285041022, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5096700619728792, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4917843853670454, "policy_loss": -0.004907036737031328, "vf_loss": 1.4965490417821066, "vf_explained_var": 0.001299432219651641, "kl": 0.011999504307996947, "entropy": 1.2229153944701745, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 131.79999999999856, "episode_reward_min": -75.50000000000001, "episode_reward_mean": 35.68900000000015, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -297.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 109.09999999999943, "predator_policy": 151.0}, "policy_reward_mean": {"prey_policy": 6.654500000000026, "predator_policy": 11.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.799999999999976, 59.50000000000049, 31.200000000000166, 71.79999999999983, 47.200000000000415, 40.0000000000003, 35.60000000000029, 34.30000000000022, -54.599999999999866, 40.0000000000003, 0.5999999999999972, 92.1999999999986, 81.49999999999915, -63.50000000000187, 67.50000000000011, 131.79999999999856, 61.300000000000416, -75.50000000000001, 40.0000000000003, 40.0000000000003, 42.700000000000344, 73.29999999999993, -31.999999999999602, 58.60000000000047, 45.300000000000395, 21.300000000000008, 40.0000000000003, -71.40000000000009, 48.000000000000426, 40.0000000000003, 11.300000000000042, -36.69999999999998, 54.10000000000042, 73.1999999999998, 55.800000000000175, 65.70000000000036, 51.9000000000005, 103.89999999999867, 38.300000000000324, 65.20000000000039, 40.0000000000003, 71.79999999999993, 71.49999999999999, -28.199999999999662, -6.199999999999688, -11.699999999999598, 24.400000000000055, -21.799999999999564, 67.90000000000019, -72.70000000000148, 51.8000000000005, 56.10000000000051, 36.60000000000025, 50.80000000000048, 46.300000000000395, 56.200000000000514, -19.199999999999697, 23.500000000000032, 40.0000000000003, 40.0000000000003, 27.000000000000096, 46.20000000000041, -0.3999999999998781, 50.400000000000475, 0.20000000000024978, 37.90000000000027, 40.0000000000003, 31.70000000000021, 61.60000000000051, 71.89999999999986, 63.40000000000053, 52.10000000000048, 15.799999999999919, 35.600000000000236, 48.70000000000045, 58.00000000000051, 59.800000000000516, 47.200000000000415, 14.799999999999937, 41.80000000000033, 57.10000000000053, 61.4000000000005, -27.299999999999663, 46.3000000000003, 64.00000000000038, 84.699999999999, 40.0000000000003, 23.50000000000004, 40.50000000000032, 52.600000000000364, 47.00000000000043, 44.70000000000034, -41.79999999999985, 0.39999999999947855, 46.10000000000039, 40.0000000000003, 40.0000000000003, 66.2000000000001, 45.0000000000001, 71.5000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-5.199999999999969, 1.9999999999999731, 20.90000000000004, 23.60000000000007, 20.000000000000014, 3.1999999999999615, 46.10000000000018, -4.300000000000029, 27.20000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999953, 20.000000000000014, 7.399999999999967, 20.90000000000003, -135.4000000000001, -86.20000000000059, 20.000000000000014, 20.000000000000014, -42.999999999999915, -18.399999999999807, 72.1999999999996, 20.000000000000014, 45.50000000000017, 20.000000000000014, -49.299999999999905, -47.19999999999976, 51.50000000000001, 5.0000000000000515, 42.50000000000025, 89.2999999999999, 17.299999999999976, 20.000000000000014, -200.50000000000003, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.700000000000063, 20.000000000000014, 39.800000000000196, 33.50000000000024, -47.1999999999998, -17.799999999999795, 20.000000000000014, 32.60000000000023, 20.000000000000014, 11.299999999999974, -15.699999999999768, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, -297.1, 20.000000000000014, 16.999999999999975, 20.000000000000014, 20.000000000000014, 15.199999999999964, -40.89999999999976, 5.2999999999999705, -189.99999999999994, 20.000000000000014, 19.1, 48.200000000000216, 20.000000000000014, 26.00000000000015, 6.800000000000041, 20.000000000000014, 43.70000000000023, 23.90000000000008, 20.000000000000014, 78.49999999999936, 25.400000000000098, -12.699999999999871, 20.000000000000014, 45.20000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 55.10000000000023, 34.400000000000254, 37.10000000000026, -59.80000000000037, -30.39999999999992, 13.699999999999967, -61.90000000000075, 1.0999999999999688, -59.80000000000062, 30.800000000000196, -30.39999999999975, -21.099999999999746, -57.70000000000031, 20.000000000000014, 47.90000000000021, -87.10000000000075, -88.6000000000007, 29.900000000000183, 17.899999999999984, 23.00000000000006, 28.100000000000147, 11.599999999999964, 20.000000000000014, 30.800000000000196, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 36.20000000000026, -59.80000000000021, -30.399999999999793, 3.1999999999999615, 5.299999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -12.9999999999998, 15.199999999999967, 20.000000000000014, 9.499999999999979, -46.899999999999814, 28.400000000000155, 20.000000000000014, -19.899999999999743, 1.0999999999999794, -9.399999999999912, 23.30000000000006, 20.000000000000014, 20.000000000000014, -5.200000000000037, 8.899999999999983, 41.60000000000025, 20.000000000000014, 40.40000000000019, 24.50000000000008, 35.30000000000026, 28.100000000000147, 23.300000000000068, 21.80000000000004, -26.199999999999797, 20.000000000000014, 11.59999999999997, 20.000000000000014, 21.80000000000004, 20.900000000000027, 20.000000000000014, 38.000000000000256, 39.80000000000025, 20.000000000000014, 20.000000000000014, 27.20000000000013, 21.800000000000043, -42.99999999999977, 20.000000000000014, 21.800000000000047, 30.800000000000196, 26.300000000000114, 40.40000000000025, 20.000000000000014, 40.70000000000025, -148.00000000000043, 26.30000000000008, 20.000000000000014, 70.39999999999972, -30.399999999999793, -123.40000000000043, 109.09999999999943, 20.000000000000014, 20.000000000000014, -11.499999999999833, 20.000000000000014, -55.600000000000335, 55.10000000000023, 20.000000000000014, 32.600000000000186, 0.1999999999999599, 24.800000000000097, 32.60000000000016, -22.899999999999814, 6.800000000000111, -160.60000000000022, -1.599999999999866, -33.9999999999998, 20.000000000000014, 16.099999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, -10.599999999999993, 37.09999999999999, -3.100000000000001, 20.000000000000014, 51.499999999999964], "policy_predator_policy_reward": [6.0, 14.0, 10.0, 5.0, 2.0, 6.0, 0.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 66.0, 101.0, 0.0, 0.0, 8.0, 54.0, 0.0, 0.0, 4.0, 12.0, 0.0, 33.0, 0.0, 11.0, 0.0, 0.0, 13.0, 11.0, 105.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.0, 6.0, 0.0, 0.0, 14.0, 0.0, 17.0, 0.0, 0.0, 151.0, 34.0, 6.0, 5.0, 0.0, 0.0, 29.0, 8.0, 70.0, 78.0, 0.0, 15.0, 5.0, 0.0, 0.0, 23.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 62.0, 39.0, 3.0, 38.0, 9.0, 24.0, 0.0, 57.0, 0.0, 0.0, 0.0, 66.0, 37.0, 1.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 71.0, 8.0, 7.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 1.0, 0.0, 37.0, 2.0, 0.0, 19.0, 0.0, 7.0, 17.0, 0.0, 0.0, 12.0, 16.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 22.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 77.0, 3.0, 0.0, 0.0, 24.0, 0.0, 16.0, 83.0, 0.0, 0.0, 15.0, 0.0, 5.0, 36.0, 0.0, 0.0, 0.0, 22.0, 0.0, 35.0, 26.0, 86.0, 36.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 51.0, 4.0, 11.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1937824684105862, "mean_inference_ms": 3.259872478034124, "mean_action_processing_ms": 0.572029415820287, "mean_env_wait_ms": 0.7494207813939876, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02451157569885254, "StateBufferConnector_ms": 0.003621816635131836, "ViewRequirementAgentConnector_ms": 0.20402371883392334}, "num_episodes": 18, "episode_return_max": 131.79999999999856, "episode_return_min": -75.50000000000001, "episode_return_mean": 35.68900000000015, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 223.26522809076633, "num_env_steps_trained_throughput_per_sec": 223.26522809076633, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 17234.489, "restore_workers_time_ms": 0.021, "training_step_time_ms": 17234.417, "sample_time_ms": 4186.107, "learn_time_ms": 13022.871, "learn_throughput": 307.152, "synch_weights_time_ms": 21.853}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "c52aa_00000", "date": "2024-08-13_00-01-43", "timestamp": 1723521703, "time_this_iter_s": 18.060466289520264, "time_total_s": 829.6544723510742, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9baee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 829.6544723510742, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 84.04999999999998, "ram_util_percent": 83.78461538461539}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5506124056363233, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.420414353426171, "policy_loss": -0.0035214098506710597, "vf_loss": 5.423207225622954, "vf_explained_var": 0.02852215047866579, "kl": 0.013644476246329163, "entropy": 1.2291083294878562, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49037552075805485, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.286829247928801, "policy_loss": -0.0036701486919016118, "vf_loss": 2.2903504286178205, "vf_explained_var": -0.0012267497481492462, "kl": 0.012554799815475269, "entropy": 1.1262519283269448, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 278.39999999999986, "episode_reward_min": -72.70000000000148, "episode_reward_mean": 45.05400000000009, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -297.1, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 168.4999999999998, "predator_policy": 151.0}, "policy_reward_mean": {"prey_policy": 9.66200000000001, "predator_policy": 12.865}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-31.999999999999602, 58.60000000000047, 45.300000000000395, 21.300000000000008, 40.0000000000003, -71.40000000000009, 48.000000000000426, 40.0000000000003, 11.300000000000042, -36.69999999999998, 54.10000000000042, 73.1999999999998, 55.800000000000175, 65.70000000000036, 51.9000000000005, 103.89999999999867, 38.300000000000324, 65.20000000000039, 40.0000000000003, 71.79999999999993, 71.49999999999999, -28.199999999999662, -6.199999999999688, -11.699999999999598, 24.400000000000055, -21.799999999999564, 67.90000000000019, -72.70000000000148, 51.8000000000005, 56.10000000000051, 36.60000000000025, 50.80000000000048, 46.300000000000395, 56.200000000000514, -19.199999999999697, 23.500000000000032, 40.0000000000003, 40.0000000000003, 27.000000000000096, 46.20000000000041, -0.3999999999998781, 50.400000000000475, 0.20000000000024978, 37.90000000000027, 40.0000000000003, 31.70000000000021, 61.60000000000051, 71.89999999999986, 63.40000000000053, 52.10000000000048, 15.799999999999919, 35.600000000000236, 48.70000000000045, 58.00000000000051, 59.800000000000516, 47.200000000000415, 14.799999999999937, 41.80000000000033, 57.10000000000053, 61.4000000000005, -27.299999999999663, 46.3000000000003, 64.00000000000038, 84.699999999999, 40.0000000000003, 23.50000000000004, 40.50000000000032, 52.600000000000364, 47.00000000000043, 44.70000000000034, -41.79999999999985, 0.39999999999947855, 46.10000000000039, 40.0000000000003, 40.0000000000003, 66.2000000000001, 45.0000000000001, 71.5000000000002, 83.29999999999984, 0.4000000000001539, 120.09999999999955, 54.50000000000034, 278.39999999999986, 26.900000000000194, 15.200000000000246, 97.29999999999924, 45.999999999999964, 101.79999999999924, 81.40000000000015, 69.59999999999923, 24.60000000000007, 92.19999999999987, 76.09999999999931, 102.09999999999852, 216.29999999999933, 160.69999999999987, 25.90000000000002, 0.19999999999994192, 111.99999999999858, -34.800000000000566], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-47.1999999999998, -17.799999999999795, 20.000000000000014, 32.60000000000023, 20.000000000000014, 11.299999999999974, -15.699999999999768, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, -297.1, 20.000000000000014, 16.999999999999975, 20.000000000000014, 20.000000000000014, 15.199999999999964, -40.89999999999976, 5.2999999999999705, -189.99999999999994, 20.000000000000014, 19.1, 48.200000000000216, 20.000000000000014, 26.00000000000015, 6.800000000000041, 20.000000000000014, 43.70000000000023, 23.90000000000008, 20.000000000000014, 78.49999999999936, 25.400000000000098, -12.699999999999871, 20.000000000000014, 45.20000000000022, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.699999999999966, 55.10000000000023, 34.400000000000254, 37.10000000000026, -59.80000000000037, -30.39999999999992, 13.699999999999967, -61.90000000000075, 1.0999999999999688, -59.80000000000062, 30.800000000000196, -30.39999999999975, -21.099999999999746, -57.70000000000031, 20.000000000000014, 47.90000000000021, -87.10000000000075, -88.6000000000007, 29.900000000000183, 17.899999999999984, 23.00000000000006, 28.100000000000147, 11.599999999999964, 20.000000000000014, 30.800000000000196, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 36.20000000000026, -59.80000000000021, -30.399999999999793, 3.1999999999999615, 5.299999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -12.9999999999998, 15.199999999999967, 20.000000000000014, 9.499999999999979, -46.899999999999814, 28.400000000000155, 20.000000000000014, -19.899999999999743, 1.0999999999999794, -9.399999999999912, 23.30000000000006, 20.000000000000014, 20.000000000000014, -5.200000000000037, 8.899999999999983, 41.60000000000025, 20.000000000000014, 40.40000000000019, 24.50000000000008, 35.30000000000026, 28.100000000000147, 23.300000000000068, 21.80000000000004, -26.199999999999797, 20.000000000000014, 11.59999999999997, 20.000000000000014, 21.80000000000004, 20.900000000000027, 20.000000000000014, 38.000000000000256, 39.80000000000025, 20.000000000000014, 20.000000000000014, 27.20000000000013, 21.800000000000043, -42.99999999999977, 20.000000000000014, 21.800000000000047, 30.800000000000196, 26.300000000000114, 40.40000000000025, 20.000000000000014, 40.70000000000025, -148.00000000000043, 26.30000000000008, 20.000000000000014, 70.39999999999972, -30.399999999999793, -123.40000000000043, 109.09999999999943, 20.000000000000014, 20.000000000000014, -11.499999999999833, 20.000000000000014, -55.600000000000335, 55.10000000000023, 20.000000000000014, 32.600000000000186, 0.1999999999999599, 24.800000000000097, 32.60000000000016, -22.899999999999814, 6.800000000000111, -160.60000000000022, -1.599999999999866, -33.9999999999998, 20.000000000000014, 16.099999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, -10.599999999999993, 37.09999999999999, -3.100000000000001, 20.000000000000014, 51.499999999999964, 31.70000000000008, 11.599999999999964, -55.60000000000022, 20.000000000000014, 64.10000000000002, 20.000000000000014, 9.799999999999976, 22.70000000000006, 104.89999999999966, 168.4999999999998, 44.300000000000104, -51.40000000000005, -74.80000000000004, 20.000000000000014, 20.000000000000014, 62.30000000000013, -33.99999999999992, 20.000000000000014, 49.70000000000009, 1.0999999999999865, 20.000000000000014, 61.40000000000007, 16.999999999999808, 11.599999999999964, 20.000000000000014, -9.399999999999883, 20.000000000000014, 72.20000000000007, -85.89999999999996, 79.99999999999982, 82.09999999999926, 20.000000000000014, 93.80000000000001, 96.49999999999945, 92.60000000000002, 19.1, -7.299999999999905, -5.799999999999944, -57.6999999999999, 20.90000000000003, 20.000000000000014, 91.99999999999932, -34.300000000000466, -179.5000000000005], "policy_predator_policy_reward": [0.0, 33.0, 6.0, 0.0, 0.0, 14.0, 0.0, 17.0, 0.0, 0.0, 151.0, 34.0, 6.0, 5.0, 0.0, 0.0, 29.0, 8.0, 70.0, 78.0, 0.0, 15.0, 5.0, 0.0, 0.0, 23.0, 2.0, 0.0, 0.0, 8.0, 0.0, 0.0, 31.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 62.0, 39.0, 3.0, 38.0, 9.0, 24.0, 0.0, 57.0, 0.0, 0.0, 0.0, 66.0, 37.0, 1.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 71.0, 8.0, 7.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 1.0, 0.0, 37.0, 2.0, 0.0, 19.0, 0.0, 7.0, 17.0, 0.0, 0.0, 12.0, 16.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 22.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 77.0, 3.0, 0.0, 0.0, 24.0, 0.0, 16.0, 83.0, 0.0, 0.0, 15.0, 0.0, 5.0, 36.0, 0.0, 0.0, 0.0, 22.0, 0.0, 35.0, 26.0, 86.0, 36.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 51.0, 4.0, 11.0, 0.0, 0.0, 0.0, 4.0, 36.0, 21.0, 15.0, 36.0, 0.0, 0.0, 22.0, 5.0, 0.0, 0.0, 34.0, 70.0, 0.0, 15.0, 0.0, 0.0, 60.0, 18.0, 33.0, 0.0, 0.0, 41.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 82.0, 0.0, 0.0, 0.0, 26.0, 13.0, 36.0, 0.0, 39.0, 27.0, 10.0, 0.0, 0.0, 71.0, 108.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1979165673288963, "mean_inference_ms": 3.2777609257150084, "mean_action_processing_ms": 0.5728241781586211, "mean_env_wait_ms": 0.7535815637843295, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014284968376159668, "StateBufferConnector_ms": 0.0036410093307495117, "ViewRequirementAgentConnector_ms": 0.2133272886276245}, "num_episodes": 22, "episode_return_max": 278.39999999999986, "episode_return_min": -72.70000000000148, "episode_return_mean": 45.05400000000009, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 237.2631814567769, "num_env_steps_trained_throughput_per_sec": 237.2631814567769, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 17420.858, "restore_workers_time_ms": 0.021, "training_step_time_ms": 17420.786, "sample_time_ms": 4159.683, "learn_time_ms": 13234.287, "learn_throughput": 302.245, "synch_weights_time_ms": 22.707}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "c52aa_00000", "date": "2024-08-13_00-02-00", "timestamp": 1723521720, "time_this_iter_s": 16.941774129867554, "time_total_s": 846.5962464809418, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab878e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 846.5962464809418, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 84.3125, "ram_util_percent": 83.725}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2844314071591254, "cur_kl_coeff": 0.05339355468749998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5839702741178887, "policy_loss": -0.0004326705971151275, "vf_loss": 3.5842540693030784, "vf_explained_var": 0.044085783176321204, "kl": 0.0027882821151563116, "entropy": 1.2399287003057975, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.46976058735418574, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.8528850826952192, "policy_loss": -0.0022197017796022236, "vf_loss": 1.8550367375845631, "vf_explained_var": 0.004519089252229721, "kl": 0.005735054081939346, "entropy": 1.1276369666927075, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 278.39999999999986, "episode_reward_min": -73.90000000000062, "episode_reward_mean": 49.59600000000003, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -253.9000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.29999999999998, "predator_policy": 142.0}, "policy_reward_mean": {"prey_policy": 10.627999999999993, "predator_policy": 14.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-11.699999999999598, 24.400000000000055, -21.799999999999564, 67.90000000000019, -72.70000000000148, 51.8000000000005, 56.10000000000051, 36.60000000000025, 50.80000000000048, 46.300000000000395, 56.200000000000514, -19.199999999999697, 23.500000000000032, 40.0000000000003, 40.0000000000003, 27.000000000000096, 46.20000000000041, -0.3999999999998781, 50.400000000000475, 0.20000000000024978, 37.90000000000027, 40.0000000000003, 31.70000000000021, 61.60000000000051, 71.89999999999986, 63.40000000000053, 52.10000000000048, 15.799999999999919, 35.600000000000236, 48.70000000000045, 58.00000000000051, 59.800000000000516, 47.200000000000415, 14.799999999999937, 41.80000000000033, 57.10000000000053, 61.4000000000005, -27.299999999999663, 46.3000000000003, 64.00000000000038, 84.699999999999, 40.0000000000003, 23.50000000000004, 40.50000000000032, 52.600000000000364, 47.00000000000043, 44.70000000000034, -41.79999999999985, 0.39999999999947855, 46.10000000000039, 40.0000000000003, 40.0000000000003, 66.2000000000001, 45.0000000000001, 71.5000000000002, 83.29999999999984, 0.4000000000001539, 120.09999999999955, 54.50000000000034, 278.39999999999986, 26.900000000000194, 15.200000000000246, 97.29999999999924, 45.999999999999964, 101.79999999999924, 81.40000000000015, 69.59999999999923, 24.60000000000007, 92.19999999999987, 76.09999999999931, 102.09999999999852, 216.29999999999933, 160.69999999999987, 25.90000000000002, 0.19999999999994192, 111.99999999999858, -34.800000000000566, 65.20000000000039, -63.40000000000093, 29.800000000000292, 28.199999999999918, 103.89999999999984, 147.29999999999916, 47.200000000000415, 49.90000000000028, 208.2999999999993, 40.0000000000003, 34.30000000000025, -49.59999999999996, 30.100000000000144, 150.99999999999946, -73.90000000000062, 40.0000000000003, 3.300000000000212, 139.89999999999918, 47.80000000000044, -25.400000000000013, 157.6999999999995, 2.1000000000001156, 121.8999999999987], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999688, -59.80000000000062, 30.800000000000196, -30.39999999999975, -21.099999999999746, -57.70000000000031, 20.000000000000014, 47.90000000000021, -87.10000000000075, -88.6000000000007, 29.900000000000183, 17.899999999999984, 23.00000000000006, 28.100000000000147, 11.599999999999964, 20.000000000000014, 30.800000000000196, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 36.20000000000026, -59.80000000000021, -30.399999999999793, 3.1999999999999615, 5.299999999999969, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -12.9999999999998, 15.199999999999967, 20.000000000000014, 9.499999999999979, -46.899999999999814, 28.400000000000155, 20.000000000000014, -19.899999999999743, 1.0999999999999794, -9.399999999999912, 23.30000000000006, 20.000000000000014, 20.000000000000014, -5.200000000000037, 8.899999999999983, 41.60000000000025, 20.000000000000014, 40.40000000000019, 24.50000000000008, 35.30000000000026, 28.100000000000147, 23.300000000000068, 21.80000000000004, -26.199999999999797, 20.000000000000014, 11.59999999999997, 20.000000000000014, 21.80000000000004, 20.900000000000027, 20.000000000000014, 38.000000000000256, 39.80000000000025, 20.000000000000014, 20.000000000000014, 27.20000000000013, 21.800000000000043, -42.99999999999977, 20.000000000000014, 21.800000000000047, 30.800000000000196, 26.300000000000114, 40.40000000000025, 20.000000000000014, 40.70000000000025, -148.00000000000043, 26.30000000000008, 20.000000000000014, 70.39999999999972, -30.399999999999793, -123.40000000000043, 109.09999999999943, 20.000000000000014, 20.000000000000014, -11.499999999999833, 20.000000000000014, -55.600000000000335, 55.10000000000023, 20.000000000000014, 32.600000000000186, 0.1999999999999599, 24.800000000000097, 32.60000000000016, -22.899999999999814, 6.800000000000111, -160.60000000000022, -1.599999999999866, -33.9999999999998, 20.000000000000014, 16.099999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, -10.599999999999993, 37.09999999999999, -3.100000000000001, 20.000000000000014, 51.499999999999964, 31.70000000000008, 11.599999999999964, -55.60000000000022, 20.000000000000014, 64.10000000000002, 20.000000000000014, 9.799999999999976, 22.70000000000006, 104.89999999999966, 168.4999999999998, 44.300000000000104, -51.40000000000005, -74.80000000000004, 20.000000000000014, 20.000000000000014, 62.30000000000013, -33.99999999999992, 20.000000000000014, 49.70000000000009, 1.0999999999999865, 20.000000000000014, 61.40000000000007, 16.999999999999808, 11.599999999999964, 20.000000000000014, -9.399999999999883, 20.000000000000014, 72.20000000000007, -85.89999999999996, 79.99999999999982, 82.09999999999926, 20.000000000000014, 93.80000000000001, 96.49999999999945, 92.60000000000002, 19.1, -7.299999999999905, -5.799999999999944, -57.6999999999999, 20.90000000000003, 20.000000000000014, 91.99999999999932, -34.300000000000466, -179.5000000000005, 20.000000000000014, 45.20000000000023, 20.000000000000014, -177.40000000000057, 20.000000000000014, -50.199999999999896, -17.199999999999797, -13.599999999999989, -99.99999999999986, 122.9, 20.000000000000014, 119.29999999999973, 27.20000000000013, 20.000000000000014, 20.000000000000014, 29.9, 188.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, -30.399999999999757, -253.9000000000001, 71.29999999999967, 1.0999999999999688, 20.000000000000014, 112.39999999999993, 17.60000000000013, -9.09999999999998, -206.80000000000052, 20.000000000000014, 20.000000000000014, 4.700000000000122, -72.40000000000056, 38.90000000000024, 100.9999999999999, 21.80000000000004, 20.000000000000014, -42.99999999999976, -54.39999999999995, 185.5999999999999, -109.89999999999993, -58.900000000000354, 20.000000000000014, 100.99999999999943, 20.90000000000003], "policy_predator_policy_reward": [38.0, 9.0, 24.0, 0.0, 57.0, 0.0, 0.0, 0.0, 66.0, 37.0, 1.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 71.0, 8.0, 7.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 1.0, 0.0, 37.0, 2.0, 0.0, 19.0, 0.0, 7.0, 17.0, 0.0, 0.0, 12.0, 16.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 22.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 77.0, 3.0, 0.0, 0.0, 24.0, 0.0, 16.0, 83.0, 0.0, 0.0, 15.0, 0.0, 5.0, 36.0, 0.0, 0.0, 0.0, 22.0, 0.0, 35.0, 26.0, 86.0, 36.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 51.0, 4.0, 11.0, 0.0, 0.0, 0.0, 4.0, 36.0, 21.0, 15.0, 36.0, 0.0, 0.0, 22.0, 5.0, 0.0, 0.0, 34.0, 70.0, 0.0, 15.0, 0.0, 0.0, 60.0, 18.0, 33.0, 0.0, 0.0, 41.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 82.0, 0.0, 0.0, 0.0, 26.0, 13.0, 36.0, 0.0, 39.0, 27.0, 10.0, 0.0, 0.0, 71.0, 108.0, 0.0, 0.0, 0.0, 94.0, 60.0, 0.0, 0.0, 59.0, 64.0, 17.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 2.0, 131.0, 0.0, 9.0, 21.0, 0.0, 0.0, 142.0, 0.0, 0.0, 71.0, 0.0, 0.0, 0.0, 6.0, 0.0, 43.0, 29.0, 82.0, 0.0, 0.0, 41.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2038472675169276, "mean_inference_ms": 3.2995732683280483, "mean_action_processing_ms": 0.5735902863803403, "mean_env_wait_ms": 0.7590672353515981, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011495232582092285, "StateBufferConnector_ms": 0.003707289695739746, "ViewRequirementAgentConnector_ms": 0.2095855474472046}, "num_episodes": 23, "episode_return_max": 278.39999999999986, "episode_return_min": -73.90000000000062, "episode_return_mean": 49.59600000000003, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.1979326897929, "num_env_steps_trained_throughput_per_sec": 210.1979326897929, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 17977.978, "restore_workers_time_ms": 0.023, "training_step_time_ms": 17977.87, "sample_time_ms": 4224.883, "learn_time_ms": 13724.361, "learn_throughput": 291.453, "synch_weights_time_ms": 23.492}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "c52aa_00000", "date": "2024-08-13_00-02-19", "timestamp": 1723521739, "time_this_iter_s": 19.174216985702515, "time_total_s": 865.7704634666443, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c5790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 865.7704634666443, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 85.91851851851852, "ram_util_percent": 83.55185185185188}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0379415152052407, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.223096892442653, "policy_loss": -0.0018389842455723772, "vf_loss": 4.224672512150315, "vf_explained_var": 0.0022676671623552917, "kl": 0.009865313812301418, "entropy": 1.2783232097903257, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4576242535675644, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2494509696960447, "policy_loss": -0.003910597840018531, "vf_loss": 3.253246124900838, "vf_explained_var": 0.006524844680513654, "kl": 0.009728674867342928, "entropy": 1.0918796686899095, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 278.39999999999986, "episode_reward_min": -128.00000000000045, "episode_reward_mean": 46.45999999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -272.2000000000003, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.29999999999998, "predator_policy": 151.0}, "policy_reward_mean": {"prey_policy": 4.624999999999978, "predator_policy": 18.605}, "custom_metrics": {}, "hist_stats": {"episode_reward": [50.400000000000475, 0.20000000000024978, 37.90000000000027, 40.0000000000003, 31.70000000000021, 61.60000000000051, 71.89999999999986, 63.40000000000053, 52.10000000000048, 15.799999999999919, 35.600000000000236, 48.70000000000045, 58.00000000000051, 59.800000000000516, 47.200000000000415, 14.799999999999937, 41.80000000000033, 57.10000000000053, 61.4000000000005, -27.299999999999663, 46.3000000000003, 64.00000000000038, 84.699999999999, 40.0000000000003, 23.50000000000004, 40.50000000000032, 52.600000000000364, 47.00000000000043, 44.70000000000034, -41.79999999999985, 0.39999999999947855, 46.10000000000039, 40.0000000000003, 40.0000000000003, 66.2000000000001, 45.0000000000001, 71.5000000000002, 83.29999999999984, 0.4000000000001539, 120.09999999999955, 54.50000000000034, 278.39999999999986, 26.900000000000194, 15.200000000000246, 97.29999999999924, 45.999999999999964, 101.79999999999924, 81.40000000000015, 69.59999999999923, 24.60000000000007, 92.19999999999987, 76.09999999999931, 102.09999999999852, 216.29999999999933, 160.69999999999987, 25.90000000000002, 0.19999999999994192, 111.99999999999858, -34.800000000000566, 65.20000000000039, -63.40000000000093, 29.800000000000292, 28.199999999999918, 103.89999999999984, 147.29999999999916, 47.200000000000415, 49.90000000000028, 208.2999999999993, 40.0000000000003, 34.30000000000025, -49.59999999999996, 30.100000000000144, 150.99999999999946, -73.90000000000062, 40.0000000000003, 3.300000000000212, 139.89999999999918, 47.80000000000044, -25.400000000000013, 157.6999999999995, 2.1000000000001156, 121.8999999999987, -12.799999999999885, -21.199999999999832, -36.99999999999998, -120.20000000000036, 27.70000000000026, 94.89999999999844, 40.0000000000003, 40.0000000000003, 27.900000000000233, 17.800000000000093, -128.00000000000045, 127.19999999999834, -107.80000000000112, 54.00000000000038, -93.2999999999999, 80.69999999999925, 66.10000000000018, 71.39999999999989], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [28.400000000000155, 20.000000000000014, -19.899999999999743, 1.0999999999999794, -9.399999999999912, 23.30000000000006, 20.000000000000014, 20.000000000000014, -5.200000000000037, 8.899999999999983, 41.60000000000025, 20.000000000000014, 40.40000000000019, 24.50000000000008, 35.30000000000026, 28.100000000000147, 23.300000000000068, 21.80000000000004, -26.199999999999797, 20.000000000000014, 11.59999999999997, 20.000000000000014, 21.80000000000004, 20.900000000000027, 20.000000000000014, 38.000000000000256, 39.80000000000025, 20.000000000000014, 20.000000000000014, 27.20000000000013, 21.800000000000043, -42.99999999999977, 20.000000000000014, 21.800000000000047, 30.800000000000196, 26.300000000000114, 40.40000000000025, 20.000000000000014, 40.70000000000025, -148.00000000000043, 26.30000000000008, 20.000000000000014, 70.39999999999972, -30.399999999999793, -123.40000000000043, 109.09999999999943, 20.000000000000014, 20.000000000000014, -11.499999999999833, 20.000000000000014, -55.600000000000335, 55.10000000000023, 20.000000000000014, 32.600000000000186, 0.1999999999999599, 24.800000000000097, 32.60000000000016, -22.899999999999814, 6.800000000000111, -160.60000000000022, -1.599999999999866, -33.9999999999998, 20.000000000000014, 16.099999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, -10.599999999999993, 37.09999999999999, -3.100000000000001, 20.000000000000014, 51.499999999999964, 31.70000000000008, 11.599999999999964, -55.60000000000022, 20.000000000000014, 64.10000000000002, 20.000000000000014, 9.799999999999976, 22.70000000000006, 104.89999999999966, 168.4999999999998, 44.300000000000104, -51.40000000000005, -74.80000000000004, 20.000000000000014, 20.000000000000014, 62.30000000000013, -33.99999999999992, 20.000000000000014, 49.70000000000009, 1.0999999999999865, 20.000000000000014, 61.40000000000007, 16.999999999999808, 11.599999999999964, 20.000000000000014, -9.399999999999883, 20.000000000000014, 72.20000000000007, -85.89999999999996, 79.99999999999982, 82.09999999999926, 20.000000000000014, 93.80000000000001, 96.49999999999945, 92.60000000000002, 19.1, -7.299999999999905, -5.799999999999944, -57.6999999999999, 20.90000000000003, 20.000000000000014, 91.99999999999932, -34.300000000000466, -179.5000000000005, 20.000000000000014, 45.20000000000023, 20.000000000000014, -177.40000000000057, 20.000000000000014, -50.199999999999896, -17.199999999999797, -13.599999999999989, -99.99999999999986, 122.9, 20.000000000000014, 119.29999999999973, 27.20000000000013, 20.000000000000014, 20.000000000000014, 29.9, 188.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, -30.399999999999757, -253.9000000000001, 71.29999999999967, 1.0999999999999688, 20.000000000000014, 112.39999999999993, 17.60000000000013, -9.09999999999998, -206.80000000000052, 20.000000000000014, 20.000000000000014, 4.700000000000122, -72.40000000000056, 38.90000000000024, 100.9999999999999, 21.80000000000004, 20.000000000000014, -42.99999999999976, -54.39999999999995, 185.5999999999999, -109.89999999999993, -58.900000000000354, 20.000000000000014, 100.99999999999943, 20.90000000000003, 20.000000000000014, -80.80000000000035, -121.60000000000053, -100.59999999999985, 27.19999999999976, -215.2000000000004, -16.599999999999838, -238.60000000000008, -67.00000000000054, 1.7000000000000384, 22.700000000000053, 72.19999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.1000000000000454, 90.49999999999993, -201.70000000000033, -272.2000000000003, -59.79999999999999, 72.19999999999962, 50.00000000000021, -167.20000000000016, -76.60000000000076, 20.000000000000014, 13.999999999999966, 20.000000000000014, -244.30000000000032, 20.000000000000014, 52.700000000000195, 20.000000000000014, 46.10000000000015, 20.000000000000014, 37.400000000000176], "policy_predator_policy_reward": [2.0, 0.0, 19.0, 0.0, 7.0, 17.0, 0.0, 0.0, 12.0, 16.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 22.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 77.0, 3.0, 0.0, 0.0, 24.0, 0.0, 16.0, 83.0, 0.0, 0.0, 15.0, 0.0, 5.0, 36.0, 0.0, 0.0, 0.0, 22.0, 0.0, 35.0, 26.0, 86.0, 36.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 51.0, 4.0, 11.0, 0.0, 0.0, 0.0, 4.0, 36.0, 21.0, 15.0, 36.0, 0.0, 0.0, 22.0, 5.0, 0.0, 0.0, 34.0, 70.0, 0.0, 15.0, 0.0, 0.0, 60.0, 18.0, 33.0, 0.0, 0.0, 41.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 82.0, 0.0, 0.0, 0.0, 26.0, 13.0, 36.0, 0.0, 39.0, 27.0, 10.0, 0.0, 0.0, 71.0, 108.0, 0.0, 0.0, 0.0, 94.0, 60.0, 0.0, 0.0, 59.0, 64.0, 17.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 2.0, 131.0, 0.0, 9.0, 21.0, 0.0, 0.0, 142.0, 0.0, 0.0, 71.0, 0.0, 0.0, 0.0, 6.0, 0.0, 43.0, 29.0, 82.0, 0.0, 0.0, 41.0, 0.0, 0.0, 0.0, 48.0, 74.0, 127.0, 0.0, 151.0, 135.0, 0.0, 33.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 129.0, 144.0, 60.0, 0.0, 5.0, 103.0, 33.0, 20.0, 0.0, 51.0, 80.0, 8.0, 0.0, 0.0, 0.0, 14.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.209474774058207, "mean_inference_ms": 3.3191102953365172, "mean_action_processing_ms": 0.5744658791069333, "mean_env_wait_ms": 0.763266296726416, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011660575866699219, "StateBufferConnector_ms": 0.004393935203552246, "ViewRequirementAgentConnector_ms": 0.26215362548828125}, "num_episodes": 18, "episode_return_max": 278.39999999999986, "episode_return_min": -128.00000000000045, "episode_return_mean": 46.45999999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 233.17127093968008, "num_env_steps_trained_throughput_per_sec": 233.17127093968008, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 17899.798, "restore_workers_time_ms": 0.023, "training_step_time_ms": 17899.691, "sample_time_ms": 4295.29, "learn_time_ms": 13576.735, "learn_throughput": 294.622, "synch_weights_time_ms": 22.57}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "c52aa_00000", "date": "2024-08-13_00-02-37", "timestamp": 1723521757, "time_this_iter_s": 17.238182067871094, "time_total_s": 883.0086455345154, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 883.0086455345154, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 78.756, "ram_util_percent": 83.04400000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5506319874887744, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.067923427511144, "policy_loss": -0.00164204767619373, "vf_loss": 6.069208568239969, "vf_explained_var": 0.04274726049609916, "kl": 0.013368779947037305, "entropy": 1.2724519431275665, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5903715189920846, "cur_kl_coeff": 0.011865234375000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.236949710618882, "policy_loss": -0.001183555270027783, "vf_loss": 3.238089460544485, "vf_explained_var": 0.00350281936781747, "kl": 0.0036919436047663547, "entropy": 1.12321077698753, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 278.39999999999986, "episode_reward_min": -288.4999999999991, "episode_reward_mean": 41.564999999999884, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -281.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.29999999999998, "predator_policy": 151.0}, "policy_reward_mean": {"prey_policy": -3.30250000000006, "predator_policy": 24.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [61.4000000000005, -27.299999999999663, 46.3000000000003, 64.00000000000038, 84.699999999999, 40.0000000000003, 23.50000000000004, 40.50000000000032, 52.600000000000364, 47.00000000000043, 44.70000000000034, -41.79999999999985, 0.39999999999947855, 46.10000000000039, 40.0000000000003, 40.0000000000003, 66.2000000000001, 45.0000000000001, 71.5000000000002, 83.29999999999984, 0.4000000000001539, 120.09999999999955, 54.50000000000034, 278.39999999999986, 26.900000000000194, 15.200000000000246, 97.29999999999924, 45.999999999999964, 101.79999999999924, 81.40000000000015, 69.59999999999923, 24.60000000000007, 92.19999999999987, 76.09999999999931, 102.09999999999852, 216.29999999999933, 160.69999999999987, 25.90000000000002, 0.19999999999994192, 111.99999999999858, -34.800000000000566, 65.20000000000039, -63.40000000000093, 29.800000000000292, 28.199999999999918, 103.89999999999984, 147.29999999999916, 47.200000000000415, 49.90000000000028, 208.2999999999993, 40.0000000000003, 34.30000000000025, -49.59999999999996, 30.100000000000144, 150.99999999999946, -73.90000000000062, 40.0000000000003, 3.300000000000212, 139.89999999999918, 47.80000000000044, -25.400000000000013, 157.6999999999995, 2.1000000000001156, 121.8999999999987, -12.799999999999885, -21.199999999999832, -36.99999999999998, -120.20000000000036, 27.70000000000026, 94.89999999999844, 40.0000000000003, 40.0000000000003, 27.900000000000233, 17.800000000000093, -128.00000000000045, 127.19999999999834, -107.80000000000112, 54.00000000000038, -93.2999999999999, 80.69999999999925, 66.10000000000018, 71.39999999999989, 40.0000000000003, -67.30000000000113, -54.599999999999696, 206.49999999999923, -288.4999999999991, 69.20000000000013, 108.69999999999936, -24.599999999999575, -27.199999999999818, 147.5999999999991, 40.0000000000003, -88.20000000000068, -96.80000000000015, 55.500000000000135, 157.79999999999956, 44.80000000000009, 105.69999999999985, -30.09999999999966], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [40.40000000000025, 20.000000000000014, 40.70000000000025, -148.00000000000043, 26.30000000000008, 20.000000000000014, 70.39999999999972, -30.399999999999793, -123.40000000000043, 109.09999999999943, 20.000000000000014, 20.000000000000014, -11.499999999999833, 20.000000000000014, -55.600000000000335, 55.10000000000023, 20.000000000000014, 32.600000000000186, 0.1999999999999599, 24.800000000000097, 32.60000000000016, -22.899999999999814, 6.800000000000111, -160.60000000000022, -1.599999999999866, -33.9999999999998, 20.000000000000014, 16.099999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 21.800000000000047, -10.599999999999993, 37.09999999999999, -3.100000000000001, 20.000000000000014, 51.499999999999964, 31.70000000000008, 11.599999999999964, -55.60000000000022, 20.000000000000014, 64.10000000000002, 20.000000000000014, 9.799999999999976, 22.70000000000006, 104.89999999999966, 168.4999999999998, 44.300000000000104, -51.40000000000005, -74.80000000000004, 20.000000000000014, 20.000000000000014, 62.30000000000013, -33.99999999999992, 20.000000000000014, 49.70000000000009, 1.0999999999999865, 20.000000000000014, 61.40000000000007, 16.999999999999808, 11.599999999999964, 20.000000000000014, -9.399999999999883, 20.000000000000014, 72.20000000000007, -85.89999999999996, 79.99999999999982, 82.09999999999926, 20.000000000000014, 93.80000000000001, 96.49999999999945, 92.60000000000002, 19.1, -7.299999999999905, -5.799999999999944, -57.6999999999999, 20.90000000000003, 20.000000000000014, 91.99999999999932, -34.300000000000466, -179.5000000000005, 20.000000000000014, 45.20000000000023, 20.000000000000014, -177.40000000000057, 20.000000000000014, -50.199999999999896, -17.199999999999797, -13.599999999999989, -99.99999999999986, 122.9, 20.000000000000014, 119.29999999999973, 27.20000000000013, 20.000000000000014, 20.000000000000014, 29.9, 188.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, -30.399999999999757, -253.9000000000001, 71.29999999999967, 1.0999999999999688, 20.000000000000014, 112.39999999999993, 17.60000000000013, -9.09999999999998, -206.80000000000052, 20.000000000000014, 20.000000000000014, 4.700000000000122, -72.40000000000056, 38.90000000000024, 100.9999999999999, 21.80000000000004, 20.000000000000014, -42.99999999999976, -54.39999999999995, 185.5999999999999, -109.89999999999993, -58.900000000000354, 20.000000000000014, 100.99999999999943, 20.90000000000003, 20.000000000000014, -80.80000000000035, -121.60000000000053, -100.59999999999985, 27.19999999999976, -215.2000000000004, -16.599999999999838, -238.60000000000008, -67.00000000000054, 1.7000000000000384, 22.700000000000053, 72.19999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.1000000000000454, 90.49999999999993, -201.70000000000033, -272.2000000000003, -59.79999999999999, 72.19999999999962, 50.00000000000021, -167.20000000000016, -76.60000000000076, 20.000000000000014, 13.999999999999966, 20.000000000000014, -244.30000000000032, 20.000000000000014, 52.700000000000195, 20.000000000000014, 46.10000000000015, 20.000000000000014, 37.400000000000176, 20.000000000000014, 20.000000000000014, -89.20000000000059, -39.09999999999988, -91.30000000000084, -217.30000000000013, 20.000000000000014, 186.49999999999994, -246.70000000000002, -194.80000000000024, -89.20000000000078, 106.40000000000006, 36.200000000000244, 69.49999999999973, 13.69999999999997, -91.30000000000068, -80.49999999999991, -57.70000000000048, 116.59999999999972, 20.000000000000014, 20.000000000000014, 20.000000000000014, -80.19999999999996, -127.00000000000074, 31.70000000000004, -281.5, 5.900000000000043, 32.599999999999994, 30.800000000000207, 122.00000000000001, 62.600000000000094, -101.80000000000003, 20.000000000000014, 85.69999999999999, 2.5999999999999734, -207.70000000000041], "policy_predator_policy_reward": [1.0, 0.0, 77.0, 3.0, 0.0, 0.0, 24.0, 0.0, 16.0, 83.0, 0.0, 0.0, 15.0, 0.0, 5.0, 36.0, 0.0, 0.0, 0.0, 22.0, 0.0, 35.0, 26.0, 86.0, 36.0, 0.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 51.0, 4.0, 11.0, 0.0, 0.0, 0.0, 4.0, 36.0, 21.0, 15.0, 36.0, 0.0, 0.0, 22.0, 5.0, 0.0, 0.0, 34.0, 70.0, 0.0, 15.0, 0.0, 0.0, 60.0, 18.0, 33.0, 0.0, 0.0, 41.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 82.0, 0.0, 0.0, 0.0, 26.0, 13.0, 36.0, 0.0, 39.0, 27.0, 10.0, 0.0, 0.0, 71.0, 108.0, 0.0, 0.0, 0.0, 94.0, 60.0, 0.0, 0.0, 59.0, 64.0, 17.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 2.0, 131.0, 0.0, 9.0, 21.0, 0.0, 0.0, 142.0, 0.0, 0.0, 71.0, 0.0, 0.0, 0.0, 6.0, 0.0, 43.0, 29.0, 82.0, 0.0, 0.0, 41.0, 0.0, 0.0, 0.0, 48.0, 74.0, 127.0, 0.0, 151.0, 135.0, 0.0, 33.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 129.0, 144.0, 60.0, 0.0, 5.0, 103.0, 33.0, 20.0, 0.0, 51.0, 80.0, 8.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 61.0, 150.0, 104.0, 0.0, 0.0, 145.0, 8.0, 52.0, 0.0, 3.0, 0.0, 0.0, 53.0, 2.0, 109.0, 11.0, 0.0, 0.0, 0.0, 21.0, 98.0, 3.0, 150.0, 17.0, 0.0, 0.0, 5.0, 84.0, 0.0, 0.0, 0.0, 117.0, 58.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.213798817170727, "mean_inference_ms": 3.334308602657785, "mean_action_processing_ms": 0.5748588924029194, "mean_env_wait_ms": 0.7660414251559982, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01165628433227539, "StateBufferConnector_ms": 0.007578253746032715, "ViewRequirementAgentConnector_ms": 0.2397845983505249}, "num_episodes": 18, "episode_return_max": 278.39999999999986, "episode_return_min": -288.4999999999991, "episode_return_mean": 41.564999999999884, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 215.7833570704403, "num_env_steps_trained_throughput_per_sec": 215.7833570704403, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 17217.893, "restore_workers_time_ms": 0.02, "training_step_time_ms": 17217.789, "sample_time_ms": 3622.821, "learn_time_ms": 13569.727, "learn_throughput": 294.774, "synch_weights_time_ms": 20.301}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "c52aa_00000", "date": "2024-08-13_00-02-55", "timestamp": 1723521775, "time_this_iter_s": 18.634541034698486, "time_total_s": 901.6431865692139, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c64c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 901.6431865692139, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 81.32307692307693, "ram_util_percent": 83.03461538461536}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4600475614348416, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.270169692695456, "policy_loss": -0.0035505054299300783, "vf_loss": 4.273512398881256, "vf_explained_var": -0.005144737006495238, "kl": 0.007783276304857638, "entropy": 1.29723742430803, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6124511905684673, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2844511140591255, "policy_loss": -0.0019236098329423281, "vf_loss": 2.2863154010797935, "vf_explained_var": 0.0010300051913690314, "kl": 0.009999447362446904, "entropy": 1.099418038665933, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 278.39999999999986, "episode_reward_min": -288.4999999999991, "episode_reward_mean": 46.7719999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -281.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.29999999999998, "predator_policy": 151.0}, "policy_reward_mean": {"prey_policy": -2.2540000000000684, "predator_policy": 25.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [54.50000000000034, 278.39999999999986, 26.900000000000194, 15.200000000000246, 97.29999999999924, 45.999999999999964, 101.79999999999924, 81.40000000000015, 69.59999999999923, 24.60000000000007, 92.19999999999987, 76.09999999999931, 102.09999999999852, 216.29999999999933, 160.69999999999987, 25.90000000000002, 0.19999999999994192, 111.99999999999858, -34.800000000000566, 65.20000000000039, -63.40000000000093, 29.800000000000292, 28.199999999999918, 103.89999999999984, 147.29999999999916, 47.200000000000415, 49.90000000000028, 208.2999999999993, 40.0000000000003, 34.30000000000025, -49.59999999999996, 30.100000000000144, 150.99999999999946, -73.90000000000062, 40.0000000000003, 3.300000000000212, 139.89999999999918, 47.80000000000044, -25.400000000000013, 157.6999999999995, 2.1000000000001156, 121.8999999999987, -12.799999999999885, -21.199999999999832, -36.99999999999998, -120.20000000000036, 27.70000000000026, 94.89999999999844, 40.0000000000003, 40.0000000000003, 27.900000000000233, 17.800000000000093, -128.00000000000045, 127.19999999999834, -107.80000000000112, 54.00000000000038, -93.2999999999999, 80.69999999999925, 66.10000000000018, 71.39999999999989, 40.0000000000003, -67.30000000000113, -54.599999999999696, 206.49999999999923, -288.4999999999991, 69.20000000000013, 108.69999999999936, -24.599999999999575, -27.199999999999818, 147.5999999999991, 40.0000000000003, -88.20000000000068, -96.80000000000015, 55.500000000000135, 157.79999999999956, 44.80000000000009, 105.69999999999985, -30.09999999999966, 69.29999999999993, 52.600000000000065, 62.50000000000023, 196.9999999999999, 92.19999999999852, 44.60000000000041, 80.09999999999926, 184.19999999999942, 39.20000000000048, 20.400000000000198, 55.70000000000022, 178.599999999999, -109.50000000000007, 10.900000000000077, 110.09999999999995, 80.49999999999925, 2.3000000000000917, 61.60000000000047, 141.49999999999963, -32.59999999999996, 117.19999999999855, 10.899999999999965], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.799999999999976, 22.70000000000006, 104.89999999999966, 168.4999999999998, 44.300000000000104, -51.40000000000005, -74.80000000000004, 20.000000000000014, 20.000000000000014, 62.30000000000013, -33.99999999999992, 20.000000000000014, 49.70000000000009, 1.0999999999999865, 20.000000000000014, 61.40000000000007, 16.999999999999808, 11.599999999999964, 20.000000000000014, -9.399999999999883, 20.000000000000014, 72.20000000000007, -85.89999999999996, 79.99999999999982, 82.09999999999926, 20.000000000000014, 93.80000000000001, 96.49999999999945, 92.60000000000002, 19.1, -7.299999999999905, -5.799999999999944, -57.6999999999999, 20.90000000000003, 20.000000000000014, 91.99999999999932, -34.300000000000466, -179.5000000000005, 20.000000000000014, 45.20000000000023, 20.000000000000014, -177.40000000000057, 20.000000000000014, -50.199999999999896, -17.199999999999797, -13.599999999999989, -99.99999999999986, 122.9, 20.000000000000014, 119.29999999999973, 27.20000000000013, 20.000000000000014, 20.000000000000014, 29.9, 188.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, -30.399999999999757, -253.9000000000001, 71.29999999999967, 1.0999999999999688, 20.000000000000014, 112.39999999999993, 17.60000000000013, -9.09999999999998, -206.80000000000052, 20.000000000000014, 20.000000000000014, 4.700000000000122, -72.40000000000056, 38.90000000000024, 100.9999999999999, 21.80000000000004, 20.000000000000014, -42.99999999999976, -54.39999999999995, 185.5999999999999, -109.89999999999993, -58.900000000000354, 20.000000000000014, 100.99999999999943, 20.90000000000003, 20.000000000000014, -80.80000000000035, -121.60000000000053, -100.59999999999985, 27.19999999999976, -215.2000000000004, -16.599999999999838, -238.60000000000008, -67.00000000000054, 1.7000000000000384, 22.700000000000053, 72.19999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.1000000000000454, 90.49999999999993, -201.70000000000033, -272.2000000000003, -59.79999999999999, 72.19999999999962, 50.00000000000021, -167.20000000000016, -76.60000000000076, 20.000000000000014, 13.999999999999966, 20.000000000000014, -244.30000000000032, 20.000000000000014, 52.700000000000195, 20.000000000000014, 46.10000000000015, 20.000000000000014, 37.400000000000176, 20.000000000000014, 20.000000000000014, -89.20000000000059, -39.09999999999988, -91.30000000000084, -217.30000000000013, 20.000000000000014, 186.49999999999994, -246.70000000000002, -194.80000000000024, -89.20000000000078, 106.40000000000006, 36.200000000000244, 69.49999999999973, 13.69999999999997, -91.30000000000068, -80.49999999999991, -57.70000000000048, 116.59999999999972, 20.000000000000014, 20.000000000000014, 20.000000000000014, -80.19999999999996, -127.00000000000074, 31.70000000000004, -281.5, 5.900000000000043, 32.599999999999994, 30.800000000000207, 122.00000000000001, 62.600000000000094, -101.80000000000003, 20.000000000000014, 85.69999999999999, 2.5999999999999734, -207.70000000000041, -3.0999999999999828, 61.40000000000012, 14.600000000000117, 20.000000000000014, 24.500000000000185, 20.000000000000014, -37.60000000000008, 125.59999999999985, 72.1999999999996, 20.000000000000014, 43.40000000000021, -38.799999999999855, 82.99999999999974, -58.89999999999986, 20.000000000000014, 147.2, -2.799999999999818, 20.000000000000014, -28.29999999999999, -4.29999999999993, 5.299999999999965, 43.4000000000001, 20.000000000000014, 158.59999999999974, -222.40000000000018, -18.10000000000003, -153.10000000000034, 49.99999999999981, -93.4000000000006, 144.49999999999974, 60.500000000000185, 20.000000000000014, 42.20000000000019, -169.9000000000001, 41.60000000000023, 20.000000000000014, 132.5, -1.0000000000000382, 3.1999999999999686, -101.80000000000007, 75.79999999999941, 34.40000000000023, 95.59999999999997, -180.70000000000016], "policy_predator_policy_reward": [0.0, 22.0, 5.0, 0.0, 0.0, 34.0, 70.0, 0.0, 15.0, 0.0, 0.0, 60.0, 18.0, 33.0, 0.0, 0.0, 41.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 82.0, 0.0, 0.0, 0.0, 26.0, 13.0, 36.0, 0.0, 39.0, 27.0, 10.0, 0.0, 0.0, 71.0, 108.0, 0.0, 0.0, 0.0, 94.0, 60.0, 0.0, 0.0, 59.0, 64.0, 17.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 2.0, 131.0, 0.0, 9.0, 21.0, 0.0, 0.0, 142.0, 0.0, 0.0, 71.0, 0.0, 0.0, 0.0, 6.0, 0.0, 43.0, 29.0, 82.0, 0.0, 0.0, 41.0, 0.0, 0.0, 0.0, 48.0, 74.0, 127.0, 0.0, 151.0, 135.0, 0.0, 33.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 129.0, 144.0, 60.0, 0.0, 5.0, 103.0, 33.0, 20.0, 0.0, 51.0, 80.0, 8.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 61.0, 150.0, 104.0, 0.0, 0.0, 145.0, 8.0, 52.0, 0.0, 3.0, 0.0, 0.0, 53.0, 2.0, 109.0, 11.0, 0.0, 0.0, 0.0, 21.0, 98.0, 3.0, 150.0, 17.0, 0.0, 0.0, 5.0, 84.0, 0.0, 0.0, 0.0, 117.0, 58.0, 11.0, 0.0, 0.0, 18.0, 18.0, 0.0, 65.0, 44.0, 0.0, 0.0, 21.0, 19.0, 0.0, 56.0, 17.0, 0.0, 22.0, 0.0, 36.0, 17.0, 0.0, 7.0, 0.0, 0.0, 131.0, 0.0, 0.0, 114.0, 0.0, 59.0, 0.0, 0.0, 13.0, 117.0, 0.0, 0.0, 10.0, 0.0, 8.0, 58.0, 1.0, 6.0, 96.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2164469332329615, "mean_inference_ms": 3.3464212950312073, "mean_action_processing_ms": 0.5740367371483484, "mean_env_wait_ms": 0.7682999386886948, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010728597640991211, "StateBufferConnector_ms": 0.007748723030090332, "ViewRequirementAgentConnector_ms": 0.21889019012451172}, "num_episodes": 22, "episode_return_max": 278.39999999999986, "episode_return_min": -288.4999999999991, "episode_return_mean": 46.7719999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 250.01715613907606, "num_env_steps_trained_throughput_per_sec": 250.01715613907606, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 16924.636, "restore_workers_time_ms": 0.018, "training_step_time_ms": 16924.531, "sample_time_ms": 3370.604, "learn_time_ms": 13527.864, "learn_throughput": 295.686, "synch_weights_time_ms": 21.138}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "c52aa_00000", "date": "2024-08-13_00-03-11", "timestamp": 1723521791, "time_this_iter_s": 16.0523841381073, "time_total_s": 917.6955707073212, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c5790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 917.6955707073212, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 76.21304347826086, "ram_util_percent": 83.49999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3209820164180306, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.934933503973421, "policy_loss": -0.003429852515242245, "vf_loss": 5.937975291600303, "vf_explained_var": 0.027408197285637023, "kl": 0.014535431711417808, "entropy": 1.2586123099402775, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5856875933115444, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.9370244023661134, "policy_loss": -0.004661248494481678, "vf_loss": 3.941618719302788, "vf_explained_var": 0.002551115978331793, "kl": 0.011280919665859214, "entropy": 1.0638539490245638, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 208.2999999999993, "episode_reward_min": -288.4999999999991, "episode_reward_mean": 31.681999999999853, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -285.0999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 188.29999999999998, "predator_policy": 151.0}, "policy_reward_mean": {"prey_policy": -14.624000000000065, "predator_policy": 30.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-34.800000000000566, 65.20000000000039, -63.40000000000093, 29.800000000000292, 28.199999999999918, 103.89999999999984, 147.29999999999916, 47.200000000000415, 49.90000000000028, 208.2999999999993, 40.0000000000003, 34.30000000000025, -49.59999999999996, 30.100000000000144, 150.99999999999946, -73.90000000000062, 40.0000000000003, 3.300000000000212, 139.89999999999918, 47.80000000000044, -25.400000000000013, 157.6999999999995, 2.1000000000001156, 121.8999999999987, -12.799999999999885, -21.199999999999832, -36.99999999999998, -120.20000000000036, 27.70000000000026, 94.89999999999844, 40.0000000000003, 40.0000000000003, 27.900000000000233, 17.800000000000093, -128.00000000000045, 127.19999999999834, -107.80000000000112, 54.00000000000038, -93.2999999999999, 80.69999999999925, 66.10000000000018, 71.39999999999989, 40.0000000000003, -67.30000000000113, -54.599999999999696, 206.49999999999923, -288.4999999999991, 69.20000000000013, 108.69999999999936, -24.599999999999575, -27.199999999999818, 147.5999999999991, 40.0000000000003, -88.20000000000068, -96.80000000000015, 55.500000000000135, 157.79999999999956, 44.80000000000009, 105.69999999999985, -30.09999999999966, 69.29999999999993, 52.600000000000065, 62.50000000000023, 196.9999999999999, 92.19999999999852, 44.60000000000041, 80.09999999999926, 184.19999999999942, 39.20000000000048, 20.400000000000198, 55.70000000000022, 178.599999999999, -109.50000000000007, 10.900000000000077, 110.09999999999995, 80.49999999999925, 2.3000000000000917, 61.60000000000047, 141.49999999999963, -32.59999999999996, 117.19999999999855, 10.899999999999965, 31.900000000000027, -118.10000000000079, 56.40000000000017, -11.199999999999868, -280.99999999999886, 180.3999999999994, 157.69999999999885, 169.59999999999894, -3.9999999999999836, 42.00000000000047, -5.999999999999789, -137.20000000000044, 40.0000000000003, 114.69999999999968, 53.50000000000044, -37.199999999999925, -45.09999999999983, -134.20000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-34.300000000000466, -179.5000000000005, 20.000000000000014, 45.20000000000023, 20.000000000000014, -177.40000000000057, 20.000000000000014, -50.199999999999896, -17.199999999999797, -13.599999999999989, -99.99999999999986, 122.9, 20.000000000000014, 119.29999999999973, 27.20000000000013, 20.000000000000014, 20.000000000000014, 29.9, 188.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 40.70000000000025, -30.399999999999757, -253.9000000000001, 71.29999999999967, 1.0999999999999688, 20.000000000000014, 112.39999999999993, 17.60000000000013, -9.09999999999998, -206.80000000000052, 20.000000000000014, 20.000000000000014, 4.700000000000122, -72.40000000000056, 38.90000000000024, 100.9999999999999, 21.80000000000004, 20.000000000000014, -42.99999999999976, -54.39999999999995, 185.5999999999999, -109.89999999999993, -58.900000000000354, 20.000000000000014, 100.99999999999943, 20.90000000000003, 20.000000000000014, -80.80000000000035, -121.60000000000053, -100.59999999999985, 27.19999999999976, -215.2000000000004, -16.599999999999838, -238.60000000000008, -67.00000000000054, 1.7000000000000384, 22.700000000000053, 72.19999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.1000000000000454, 90.49999999999993, -201.70000000000033, -272.2000000000003, -59.79999999999999, 72.19999999999962, 50.00000000000021, -167.20000000000016, -76.60000000000076, 20.000000000000014, 13.999999999999966, 20.000000000000014, -244.30000000000032, 20.000000000000014, 52.700000000000195, 20.000000000000014, 46.10000000000015, 20.000000000000014, 37.400000000000176, 20.000000000000014, 20.000000000000014, -89.20000000000059, -39.09999999999988, -91.30000000000084, -217.30000000000013, 20.000000000000014, 186.49999999999994, -246.70000000000002, -194.80000000000024, -89.20000000000078, 106.40000000000006, 36.200000000000244, 69.49999999999973, 13.69999999999997, -91.30000000000068, -80.49999999999991, -57.70000000000048, 116.59999999999972, 20.000000000000014, 20.000000000000014, 20.000000000000014, -80.19999999999996, -127.00000000000074, 31.70000000000004, -281.5, 5.900000000000043, 32.599999999999994, 30.800000000000207, 122.00000000000001, 62.600000000000094, -101.80000000000003, 20.000000000000014, 85.69999999999999, 2.5999999999999734, -207.70000000000041, -3.0999999999999828, 61.40000000000012, 14.600000000000117, 20.000000000000014, 24.500000000000185, 20.000000000000014, -37.60000000000008, 125.59999999999985, 72.1999999999996, 20.000000000000014, 43.40000000000021, -38.799999999999855, 82.99999999999974, -58.89999999999986, 20.000000000000014, 147.2, -2.799999999999818, 20.000000000000014, -28.29999999999999, -4.29999999999993, 5.299999999999965, 43.4000000000001, 20.000000000000014, 158.59999999999974, -222.40000000000018, -18.10000000000003, -153.10000000000034, 49.99999999999981, -93.4000000000006, 144.49999999999974, 60.500000000000185, 20.000000000000014, 42.20000000000019, -169.9000000000001, 41.60000000000023, 20.000000000000014, 132.5, -1.0000000000000382, 3.1999999999999686, -101.80000000000007, 75.79999999999941, 34.40000000000023, 95.59999999999997, -180.70000000000016, -22.299999999999955, -35.800000000000026, 20.000000000000014, -285.0999999999991, 73.10000000000001, -96.70000000000022, 19.700000000000045, -124.90000000000003, -261.3999999999994, -202.6000000000002, 160.39999999999998, 20.000000000000014, 98.8999999999994, 57.80000000000014, 20.000000000000014, 149.59999999999968, -106.60000000000002, -18.39999999999985, 3.200000000000003, 30.800000000000196, -127.00000000000074, 20.000000000000014, -245.1000000000005, -123.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 94.6999999999999, 33.50000000000022, 20.000000000000014, -66.39999999999998, -122.80000000000018, -177.10000000000005, -0.9999999999999917, -205.3000000000003, -97.90000000000005], "policy_predator_policy_reward": [71.0, 108.0, 0.0, 0.0, 0.0, 94.0, 60.0, 0.0, 0.0, 59.0, 64.0, 17.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 0.0, 2.0, 131.0, 0.0, 9.0, 21.0, 0.0, 0.0, 142.0, 0.0, 0.0, 71.0, 0.0, 0.0, 0.0, 6.0, 0.0, 43.0, 29.0, 82.0, 0.0, 0.0, 41.0, 0.0, 0.0, 0.0, 48.0, 74.0, 127.0, 0.0, 151.0, 135.0, 0.0, 33.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 129.0, 144.0, 60.0, 0.0, 5.0, 103.0, 33.0, 20.0, 0.0, 51.0, 80.0, 8.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 61.0, 150.0, 104.0, 0.0, 0.0, 145.0, 8.0, 52.0, 0.0, 3.0, 0.0, 0.0, 53.0, 2.0, 109.0, 11.0, 0.0, 0.0, 0.0, 21.0, 98.0, 3.0, 150.0, 17.0, 0.0, 0.0, 5.0, 84.0, 0.0, 0.0, 0.0, 117.0, 58.0, 11.0, 0.0, 0.0, 18.0, 18.0, 0.0, 65.0, 44.0, 0.0, 0.0, 21.0, 19.0, 0.0, 56.0, 17.0, 0.0, 22.0, 0.0, 36.0, 17.0, 0.0, 7.0, 0.0, 0.0, 131.0, 0.0, 0.0, 114.0, 0.0, 59.0, 0.0, 0.0, 13.0, 117.0, 0.0, 0.0, 10.0, 0.0, 8.0, 58.0, 1.0, 6.0, 96.0, 0.0, 75.0, 15.0, 147.0, 0.0, 80.0, 0.0, 28.0, 66.0, 92.0, 91.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 111.0, 10.0, 8.0, 0.0, 54.0, 47.0, 84.0, 147.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 68.0, 84.0, 10.0, 123.0, 60.0, 109.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2213547317339724, "mean_inference_ms": 3.3599443113576246, "mean_action_processing_ms": 0.5735403376849986, "mean_env_wait_ms": 0.7694273261234086, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008631587028503418, "StateBufferConnector_ms": 0.011656045913696289, "ViewRequirementAgentConnector_ms": 0.262418270111084}, "num_episodes": 18, "episode_return_max": 208.2999999999993, "episode_return_min": -288.4999999999991, "episode_return_mean": 31.681999999999853, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 193.55807739922946, "num_env_steps_trained_throughput_per_sec": 193.55807739922946, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 17574.13, "restore_workers_time_ms": 0.018, "training_step_time_ms": 17574.025, "sample_time_ms": 3481.931, "learn_time_ms": 14061.479, "learn_throughput": 284.465, "synch_weights_time_ms": 25.688}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "c52aa_00000", "date": "2024-08-13_00-03-32", "timestamp": 1723521812, "time_this_iter_s": 20.87281370162964, "time_total_s": 938.5683844089508, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c0040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 938.5683844089508, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 87.67241379310344, "ram_util_percent": 83.39999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8575444293400598, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.793819445403165, "policy_loss": -0.006128817378351139, "vf_loss": 5.7994490895952495, "vf_explained_var": 0.06262978122978614, "kl": 0.01869759238562236, "entropy": 1.2242575336385657, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6895277476263425, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0167787315353514, "policy_loss": -0.004854792693664354, "vf_loss": 2.021551277997002, "vf_explained_var": 0.00992343236529638, "kl": 0.013863832553473704, "entropy": 0.9971708317282338, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 336.79999999999995, "episode_reward_min": -288.4999999999991, "episode_reward_mean": 37.8869999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.19999999999976, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 186.49999999999994, "predator_policy": 168.0}, "policy_reward_mean": {"prey_policy": -11.331500000000078, "predator_policy": 30.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [121.8999999999987, -12.799999999999885, -21.199999999999832, -36.99999999999998, -120.20000000000036, 27.70000000000026, 94.89999999999844, 40.0000000000003, 40.0000000000003, 27.900000000000233, 17.800000000000093, -128.00000000000045, 127.19999999999834, -107.80000000000112, 54.00000000000038, -93.2999999999999, 80.69999999999925, 66.10000000000018, 71.39999999999989, 40.0000000000003, -67.30000000000113, -54.599999999999696, 206.49999999999923, -288.4999999999991, 69.20000000000013, 108.69999999999936, -24.599999999999575, -27.199999999999818, 147.5999999999991, 40.0000000000003, -88.20000000000068, -96.80000000000015, 55.500000000000135, 157.79999999999956, 44.80000000000009, 105.69999999999985, -30.09999999999966, 69.29999999999993, 52.600000000000065, 62.50000000000023, 196.9999999999999, 92.19999999999852, 44.60000000000041, 80.09999999999926, 184.19999999999942, 39.20000000000048, 20.400000000000198, 55.70000000000022, 178.599999999999, -109.50000000000007, 10.900000000000077, 110.09999999999995, 80.49999999999925, 2.3000000000000917, 61.60000000000047, 141.49999999999963, -32.59999999999996, 117.19999999999855, 10.899999999999965, 31.900000000000027, -118.10000000000079, 56.40000000000017, -11.199999999999868, -280.99999999999886, 180.3999999999994, 157.69999999999885, 169.59999999999894, -3.9999999999999836, 42.00000000000047, -5.999999999999789, -137.20000000000044, 40.0000000000003, 114.69999999999968, 53.50000000000044, -37.199999999999925, -45.09999999999983, -134.20000000000002, -11.799999999999809, 110.19999999999911, 40.900000000000134, 207.39999999999878, 227.19999999999922, -155.00000000000097, 336.79999999999995, 129.49999999999937, 114.19999999999939, -50.80000000000035, 101.1999999999999, -23.700000000000077, 133.59999999999982, 14.300000000000097, 102.99999999999997, 40.20000000000015, 184.99999999999926, -132.20000000000067, 61.600000000000506, 256.8999999999994, -88.30000000000142, 30.100000000000172, 69.09999999999982], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [100.99999999999943, 20.90000000000003, 20.000000000000014, -80.80000000000035, -121.60000000000053, -100.59999999999985, 27.19999999999976, -215.2000000000004, -16.599999999999838, -238.60000000000008, -67.00000000000054, 1.7000000000000384, 22.700000000000053, 72.19999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.1000000000000454, 90.49999999999993, -201.70000000000033, -272.2000000000003, -59.79999999999999, 72.19999999999962, 50.00000000000021, -167.20000000000016, -76.60000000000076, 20.000000000000014, 13.999999999999966, 20.000000000000014, -244.30000000000032, 20.000000000000014, 52.700000000000195, 20.000000000000014, 46.10000000000015, 20.000000000000014, 37.400000000000176, 20.000000000000014, 20.000000000000014, -89.20000000000059, -39.09999999999988, -91.30000000000084, -217.30000000000013, 20.000000000000014, 186.49999999999994, -246.70000000000002, -194.80000000000024, -89.20000000000078, 106.40000000000006, 36.200000000000244, 69.49999999999973, 13.69999999999997, -91.30000000000068, -80.49999999999991, -57.70000000000048, 116.59999999999972, 20.000000000000014, 20.000000000000014, 20.000000000000014, -80.19999999999996, -127.00000000000074, 31.70000000000004, -281.5, 5.900000000000043, 32.599999999999994, 30.800000000000207, 122.00000000000001, 62.600000000000094, -101.80000000000003, 20.000000000000014, 85.69999999999999, 2.5999999999999734, -207.70000000000041, -3.0999999999999828, 61.40000000000012, 14.600000000000117, 20.000000000000014, 24.500000000000185, 20.000000000000014, -37.60000000000008, 125.59999999999985, 72.1999999999996, 20.000000000000014, 43.40000000000021, -38.799999999999855, 82.99999999999974, -58.89999999999986, 20.000000000000014, 147.2, -2.799999999999818, 20.000000000000014, -28.29999999999999, -4.29999999999993, 5.299999999999965, 43.4000000000001, 20.000000000000014, 158.59999999999974, -222.40000000000018, -18.10000000000003, -153.10000000000034, 49.99999999999981, -93.4000000000006, 144.49999999999974, 60.500000000000185, 20.000000000000014, 42.20000000000019, -169.9000000000001, 41.60000000000023, 20.000000000000014, 132.5, -1.0000000000000382, 3.1999999999999686, -101.80000000000007, 75.79999999999941, 34.40000000000023, 95.59999999999997, -180.70000000000016, -22.299999999999955, -35.800000000000026, 20.000000000000014, -285.0999999999991, 73.10000000000001, -96.70000000000022, 19.700000000000045, -124.90000000000003, -261.3999999999994, -202.6000000000002, 160.39999999999998, 20.000000000000014, 98.8999999999994, 57.80000000000014, 20.000000000000014, 149.59999999999968, -106.60000000000002, -18.39999999999985, 3.200000000000003, 30.800000000000196, -127.00000000000074, 20.000000000000014, -245.1000000000005, -123.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 94.6999999999999, 33.50000000000022, 20.000000000000014, -66.39999999999998, -122.80000000000018, -177.10000000000005, -0.9999999999999917, -205.3000000000003, -97.90000000000005, -27.400000000000023, -87.40000000000015, -3.1000000000000463, 95.2999999999996, 43.40000000000003, -83.50000000000004, 72.2000000000002, 135.1999999999996, 108.19999999999942, 118.99999999999974, -127.90000000000057, -207.10000000000042, 146.9, 170.89999999999998, 20.000000000000014, 66.5, 20.000000000000014, 78.1999999999999, -15.699999999999768, -108.10000000000065, 81.19999999999999, 20.000000000000014, -114.69999999999985, 20.000000000000014, 113.60000000000004, 20.000000000000014, -75.70000000000041, 20.000000000000014, 20.000000000000014, 83.00000000000009, 29.0, 3.1999999999999704, 41.60000000000016, 139.3999999999999, 20.000000000000014, -320.19999999999976, 20.000000000000014, 41.60000000000025, 100.09999999999971, 156.79999999999976, -55.90000000000013, -114.40000000000069, 1.0999999999999688, 20.000000000000014, 62.30000000000021, -92.20000000000044], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 48.0, 74.0, 127.0, 0.0, 151.0, 135.0, 0.0, 33.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 129.0, 144.0, 60.0, 0.0, 5.0, 103.0, 33.0, 20.0, 0.0, 51.0, 80.0, 8.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 61.0, 150.0, 104.0, 0.0, 0.0, 145.0, 8.0, 52.0, 0.0, 3.0, 0.0, 0.0, 53.0, 2.0, 109.0, 11.0, 0.0, 0.0, 0.0, 21.0, 98.0, 3.0, 150.0, 17.0, 0.0, 0.0, 5.0, 84.0, 0.0, 0.0, 0.0, 117.0, 58.0, 11.0, 0.0, 0.0, 18.0, 18.0, 0.0, 65.0, 44.0, 0.0, 0.0, 21.0, 19.0, 0.0, 56.0, 17.0, 0.0, 22.0, 0.0, 36.0, 17.0, 0.0, 7.0, 0.0, 0.0, 131.0, 0.0, 0.0, 114.0, 0.0, 59.0, 0.0, 0.0, 13.0, 117.0, 0.0, 0.0, 10.0, 0.0, 8.0, 58.0, 1.0, 6.0, 96.0, 0.0, 75.0, 15.0, 147.0, 0.0, 80.0, 0.0, 28.0, 66.0, 92.0, 91.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 111.0, 10.0, 8.0, 0.0, 54.0, 47.0, 84.0, 147.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 68.0, 84.0, 10.0, 123.0, 60.0, 109.0, 103.0, 0.0, 18.0, 0.0, 0.0, 81.0, 0.0, 0.0, 0.0, 0.0, 76.0, 104.0, 0.0, 19.0, 0.0, 43.0, 0.0, 16.0, 73.0, 0.0, 0.0, 0.0, 48.0, 23.0, 0.0, 0.0, 0.0, 70.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 168.0, 0.0, 0.0, 0.0, 0.0, 82.0, 0.0, 9.0, 0.0, 27.0, 72.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.229459638785543, "mean_inference_ms": 3.387845968005877, "mean_action_processing_ms": 0.5743930917963008, "mean_env_wait_ms": 0.773467774593482, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0316847562789917, "StateBufferConnector_ms": 0.0152205228805542, "ViewRequirementAgentConnector_ms": 0.3557819128036499}, "num_episodes": 23, "episode_return_max": 336.79999999999995, "episode_return_min": -288.4999999999991, "episode_return_mean": 37.8869999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 192.4763956730964, "num_env_steps_trained_throughput_per_sec": 192.4763956730964, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 18185.429, "restore_workers_time_ms": 0.019, "training_step_time_ms": 18185.323, "sample_time_ms": 3848.594, "learn_time_ms": 14306.221, "learn_throughput": 279.599, "synch_weights_time_ms": 26.016}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "c52aa_00000", "date": "2024-08-13_00-03-53", "timestamp": 1723521833, "time_this_iter_s": 20.862696409225464, "time_total_s": 959.4310808181763, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87e280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 959.4310808181763, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 86.60666666666667, "ram_util_percent": 83.52333333333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.815827639700559, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.796056474453557, "policy_loss": -0.005908627860080549, "vf_loss": 5.8015112728038165, "vf_explained_var": 0.027295286251754355, "kl": 0.01699989039601189, "entropy": 1.237818297696492, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5679181233679176, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.157547236371923, "policy_loss": -0.0061417709797049165, "vf_loss": 4.163609382336732, "vf_explained_var": 0.0002828768636814501, "kl": 0.013421658417168586, "entropy": 1.0208409234014137, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 336.79999999999995, "episode_reward_min": -288.4999999999991, "episode_reward_mean": 37.60099999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.19999999999976, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 186.49999999999994, "predator_policy": 168.0}, "policy_reward_mean": {"prey_policy": -11.544500000000063, "predator_policy": 30.345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [71.39999999999989, 40.0000000000003, -67.30000000000113, -54.599999999999696, 206.49999999999923, -288.4999999999991, 69.20000000000013, 108.69999999999936, -24.599999999999575, -27.199999999999818, 147.5999999999991, 40.0000000000003, -88.20000000000068, -96.80000000000015, 55.500000000000135, 157.79999999999956, 44.80000000000009, 105.69999999999985, -30.09999999999966, 69.29999999999993, 52.600000000000065, 62.50000000000023, 196.9999999999999, 92.19999999999852, 44.60000000000041, 80.09999999999926, 184.19999999999942, 39.20000000000048, 20.400000000000198, 55.70000000000022, 178.599999999999, -109.50000000000007, 10.900000000000077, 110.09999999999995, 80.49999999999925, 2.3000000000000917, 61.60000000000047, 141.49999999999963, -32.59999999999996, 117.19999999999855, 10.899999999999965, 31.900000000000027, -118.10000000000079, 56.40000000000017, -11.199999999999868, -280.99999999999886, 180.3999999999994, 157.69999999999885, 169.59999999999894, -3.9999999999999836, 42.00000000000047, -5.999999999999789, -137.20000000000044, 40.0000000000003, 114.69999999999968, 53.50000000000044, -37.199999999999925, -45.09999999999983, -134.20000000000002, -11.799999999999809, 110.19999999999911, 40.900000000000134, 207.39999999999878, 227.19999999999922, -155.00000000000097, 336.79999999999995, 129.49999999999937, 114.19999999999939, -50.80000000000035, 101.1999999999999, -23.700000000000077, 133.59999999999982, 14.300000000000097, 102.99999999999997, 40.20000000000015, 184.99999999999926, -132.20000000000067, 61.600000000000506, 256.8999999999994, -88.30000000000142, 30.100000000000172, 69.09999999999982, 40.0000000000003, 1.09999999999998, 82.19999999999985, -77.10000000000012, 77.5999999999996, 51.300000000000246, 71.59999999999911, 63.300000000000125, -21.5999999999998, 73.0999999999996, -107.00000000000102, -14.20000000000027, 55.300000000000104, -23.799999999999542, 27.900000000000126, -118.20000000000084, 2.7999999999997502, -34.99999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 37.400000000000176, 20.000000000000014, 20.000000000000014, -89.20000000000059, -39.09999999999988, -91.30000000000084, -217.30000000000013, 20.000000000000014, 186.49999999999994, -246.70000000000002, -194.80000000000024, -89.20000000000078, 106.40000000000006, 36.200000000000244, 69.49999999999973, 13.69999999999997, -91.30000000000068, -80.49999999999991, -57.70000000000048, 116.59999999999972, 20.000000000000014, 20.000000000000014, 20.000000000000014, -80.19999999999996, -127.00000000000074, 31.70000000000004, -281.5, 5.900000000000043, 32.599999999999994, 30.800000000000207, 122.00000000000001, 62.600000000000094, -101.80000000000003, 20.000000000000014, 85.69999999999999, 2.5999999999999734, -207.70000000000041, -3.0999999999999828, 61.40000000000012, 14.600000000000117, 20.000000000000014, 24.500000000000185, 20.000000000000014, -37.60000000000008, 125.59999999999985, 72.1999999999996, 20.000000000000014, 43.40000000000021, -38.799999999999855, 82.99999999999974, -58.89999999999986, 20.000000000000014, 147.2, -2.799999999999818, 20.000000000000014, -28.29999999999999, -4.29999999999993, 5.299999999999965, 43.4000000000001, 20.000000000000014, 158.59999999999974, -222.40000000000018, -18.10000000000003, -153.10000000000034, 49.99999999999981, -93.4000000000006, 144.49999999999974, 60.500000000000185, 20.000000000000014, 42.20000000000019, -169.9000000000001, 41.60000000000023, 20.000000000000014, 132.5, -1.0000000000000382, 3.1999999999999686, -101.80000000000007, 75.79999999999941, 34.40000000000023, 95.59999999999997, -180.70000000000016, -22.299999999999955, -35.800000000000026, 20.000000000000014, -285.0999999999991, 73.10000000000001, -96.70000000000022, 19.700000000000045, -124.90000000000003, -261.3999999999994, -202.6000000000002, 160.39999999999998, 20.000000000000014, 98.8999999999994, 57.80000000000014, 20.000000000000014, 149.59999999999968, -106.60000000000002, -18.39999999999985, 3.200000000000003, 30.800000000000196, -127.00000000000074, 20.000000000000014, -245.1000000000005, -123.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 94.6999999999999, 33.50000000000022, 20.000000000000014, -66.39999999999998, -122.80000000000018, -177.10000000000005, -0.9999999999999917, -205.3000000000003, -97.90000000000005, -27.400000000000023, -87.40000000000015, -3.1000000000000463, 95.2999999999996, 43.40000000000003, -83.50000000000004, 72.2000000000002, 135.1999999999996, 108.19999999999942, 118.99999999999974, -127.90000000000057, -207.10000000000042, 146.9, 170.89999999999998, 20.000000000000014, 66.5, 20.000000000000014, 78.1999999999999, -15.699999999999768, -108.10000000000065, 81.19999999999999, 20.000000000000014, -114.69999999999985, 20.000000000000014, 113.60000000000004, 20.000000000000014, -75.70000000000041, 20.000000000000014, 20.000000000000014, 83.00000000000009, 29.0, 3.1999999999999704, 41.60000000000016, 139.3999999999999, 20.000000000000014, -320.19999999999976, 20.000000000000014, 41.60000000000025, 100.09999999999971, 156.79999999999976, -55.90000000000013, -114.40000000000069, 1.0999999999999688, 20.000000000000014, 62.30000000000021, -92.20000000000044, 20.000000000000014, 20.000000000000014, -9.70000000000001, -26.199999999999903, 39.20000000000001, 20.000000000000014, 15.499999999999963, -286.60000000000014, -95.8000000000003, 73.39999999999999, 29.29999999999997, 20.000000000000014, 20.000000000000014, -87.40000000000013, 20.000000000000014, -27.69999999999996, -13.600000000000026, -43.00000000000001, 9.499999999999936, 5.600000000000179, -164.8000000000006, -38.199999999999896, 43.70000000000013, -166.90000000000052, 20.000000000000014, 8.30000000000011, 20.000000000000014, -101.80000000000081, -3.09999999999999, 20.000000000000014, -258.3999999999998, -17.79999999999982, -113.20000000000013, 20.000000000000014, -19.90000000000005, -87.10000000000004], "policy_predator_policy_reward": [14.0, 0.0, 0.0, 0.0, 0.0, 61.0, 150.0, 104.0, 0.0, 0.0, 145.0, 8.0, 52.0, 0.0, 3.0, 0.0, 0.0, 53.0, 2.0, 109.0, 11.0, 0.0, 0.0, 0.0, 21.0, 98.0, 3.0, 150.0, 17.0, 0.0, 0.0, 5.0, 84.0, 0.0, 0.0, 0.0, 117.0, 58.0, 11.0, 0.0, 0.0, 18.0, 18.0, 0.0, 65.0, 44.0, 0.0, 0.0, 21.0, 19.0, 0.0, 56.0, 17.0, 0.0, 22.0, 0.0, 36.0, 17.0, 0.0, 7.0, 0.0, 0.0, 131.0, 0.0, 0.0, 114.0, 0.0, 59.0, 0.0, 0.0, 13.0, 117.0, 0.0, 0.0, 10.0, 0.0, 8.0, 58.0, 1.0, 6.0, 96.0, 0.0, 75.0, 15.0, 147.0, 0.0, 80.0, 0.0, 28.0, 66.0, 92.0, 91.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 111.0, 10.0, 8.0, 0.0, 54.0, 47.0, 84.0, 147.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 68.0, 84.0, 10.0, 123.0, 60.0, 109.0, 103.0, 0.0, 18.0, 0.0, 0.0, 81.0, 0.0, 0.0, 0.0, 0.0, 76.0, 104.0, 0.0, 19.0, 0.0, 43.0, 0.0, 16.0, 73.0, 0.0, 0.0, 0.0, 48.0, 23.0, 0.0, 0.0, 0.0, 70.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 168.0, 0.0, 0.0, 0.0, 0.0, 82.0, 0.0, 9.0, 0.0, 27.0, 72.0, 0.0, 0.0, 0.0, 37.0, 0.0, 23.0, 54.0, 140.0, 26.0, 74.0, 2.0, 0.0, 77.0, 62.0, 66.0, 5.0, 35.0, 0.0, 35.0, 23.0, 96.0, 0.0, 20.0, 89.0, 27.0, 0.0, 0.0, 58.0, 0.0, 11.0, 94.0, 64.0, 93.0, 3.0, 17.0, 55.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.23547066521733, "mean_inference_ms": 3.4079216381790287, "mean_action_processing_ms": 0.5750795209569491, "mean_env_wait_ms": 0.7764569280527382, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03422653675079346, "StateBufferConnector_ms": 0.0164792537689209, "ViewRequirementAgentConnector_ms": 0.31217634677886963}, "num_episodes": 18, "episode_return_max": 336.79999999999995, "episode_return_min": -288.4999999999991, "episode_return_mean": 37.60099999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 215.83208081497102, "num_env_steps_trained_throughput_per_sec": 215.83208081497102, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 18360.592, "restore_workers_time_ms": 0.02, "training_step_time_ms": 18360.493, "sample_time_ms": 3855.507, "learn_time_ms": 14474.398, "learn_throughput": 276.35, "synch_weights_time_ms": 26.028}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "c52aa_00000", "date": "2024-08-13_00-04-12", "timestamp": 1723521852, "time_this_iter_s": 18.61554718017578, "time_total_s": 978.046627998352, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c6af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 978.046627998352, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 83.84444444444443, "ram_util_percent": 83.34074074074073}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0352306424231124, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.512138643971196, "policy_loss": -0.0010572150401357147, "vf_loss": 5.512965142033088, "vf_explained_var": 0.052295591906895714, "kl": 0.008641610143822653, "entropy": 1.2115585731450842, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6089564229603167, "cur_kl_coeff": 0.005932617187500002, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5973934165384405, "policy_loss": -0.0034474304836568615, "vf_loss": 2.6007199572507664, "vf_explained_var": 0.00647009775121376, "kl": 0.020377511405824646, "entropy": 1.0352978940678652, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 336.79999999999995, "episode_reward_min": -280.99999999999886, "episode_reward_mean": 42.4249999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.19999999999976, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 168.0}, "policy_reward_mean": {"prey_policy": -7.48250000000005, "predator_policy": 28.695}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.09999999999966, 69.29999999999993, 52.600000000000065, 62.50000000000023, 196.9999999999999, 92.19999999999852, 44.60000000000041, 80.09999999999926, 184.19999999999942, 39.20000000000048, 20.400000000000198, 55.70000000000022, 178.599999999999, -109.50000000000007, 10.900000000000077, 110.09999999999995, 80.49999999999925, 2.3000000000000917, 61.60000000000047, 141.49999999999963, -32.59999999999996, 117.19999999999855, 10.899999999999965, 31.900000000000027, -118.10000000000079, 56.40000000000017, -11.199999999999868, -280.99999999999886, 180.3999999999994, 157.69999999999885, 169.59999999999894, -3.9999999999999836, 42.00000000000047, -5.999999999999789, -137.20000000000044, 40.0000000000003, 114.69999999999968, 53.50000000000044, -37.199999999999925, -45.09999999999983, -134.20000000000002, -11.799999999999809, 110.19999999999911, 40.900000000000134, 207.39999999999878, 227.19999999999922, -155.00000000000097, 336.79999999999995, 129.49999999999937, 114.19999999999939, -50.80000000000035, 101.1999999999999, -23.700000000000077, 133.59999999999982, 14.300000000000097, 102.99999999999997, 40.20000000000015, 184.99999999999926, -132.20000000000067, 61.600000000000506, 256.8999999999994, -88.30000000000142, 30.100000000000172, 69.09999999999982, 40.0000000000003, 1.09999999999998, 82.19999999999985, -77.10000000000012, 77.5999999999996, 51.300000000000246, 71.59999999999911, 63.300000000000125, -21.5999999999998, 73.0999999999996, -107.00000000000102, -14.20000000000027, 55.300000000000104, -23.799999999999542, 27.900000000000126, -118.20000000000084, 2.7999999999997502, -34.99999999999992, 73.20000000000006, 217.29999999999924, -190.000000000001, 54.400000000000496, 69.70000000000023, 56.20000000000027, 22.400000000000276, 40.0000000000003, -193.00000000000048, 198.09999999999926, 39.90000000000028, 55.10000000000013, 200.19999999999933, 27.900000000000123, 87.69999999999878, 267.6999999999996, -169.60000000000048, 25.19999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [2.5999999999999734, -207.70000000000041, -3.0999999999999828, 61.40000000000012, 14.600000000000117, 20.000000000000014, 24.500000000000185, 20.000000000000014, -37.60000000000008, 125.59999999999985, 72.1999999999996, 20.000000000000014, 43.40000000000021, -38.799999999999855, 82.99999999999974, -58.89999999999986, 20.000000000000014, 147.2, -2.799999999999818, 20.000000000000014, -28.29999999999999, -4.29999999999993, 5.299999999999965, 43.4000000000001, 20.000000000000014, 158.59999999999974, -222.40000000000018, -18.10000000000003, -153.10000000000034, 49.99999999999981, -93.4000000000006, 144.49999999999974, 60.500000000000185, 20.000000000000014, 42.20000000000019, -169.9000000000001, 41.60000000000023, 20.000000000000014, 132.5, -1.0000000000000382, 3.1999999999999686, -101.80000000000007, 75.79999999999941, 34.40000000000023, 95.59999999999997, -180.70000000000016, -22.299999999999955, -35.800000000000026, 20.000000000000014, -285.0999999999991, 73.10000000000001, -96.70000000000022, 19.700000000000045, -124.90000000000003, -261.3999999999994, -202.6000000000002, 160.39999999999998, 20.000000000000014, 98.8999999999994, 57.80000000000014, 20.000000000000014, 149.59999999999968, -106.60000000000002, -18.39999999999985, 3.200000000000003, 30.800000000000196, -127.00000000000074, 20.000000000000014, -245.1000000000005, -123.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 94.6999999999999, 33.50000000000022, 20.000000000000014, -66.39999999999998, -122.80000000000018, -177.10000000000005, -0.9999999999999917, -205.3000000000003, -97.90000000000005, -27.400000000000023, -87.40000000000015, -3.1000000000000463, 95.2999999999996, 43.40000000000003, -83.50000000000004, 72.2000000000002, 135.1999999999996, 108.19999999999942, 118.99999999999974, -127.90000000000057, -207.10000000000042, 146.9, 170.89999999999998, 20.000000000000014, 66.5, 20.000000000000014, 78.1999999999999, -15.699999999999768, -108.10000000000065, 81.19999999999999, 20.000000000000014, -114.69999999999985, 20.000000000000014, 113.60000000000004, 20.000000000000014, -75.70000000000041, 20.000000000000014, 20.000000000000014, 83.00000000000009, 29.0, 3.1999999999999704, 41.60000000000016, 139.3999999999999, 20.000000000000014, -320.19999999999976, 20.000000000000014, 41.60000000000025, 100.09999999999971, 156.79999999999976, -55.90000000000013, -114.40000000000069, 1.0999999999999688, 20.000000000000014, 62.30000000000021, -92.20000000000044, 20.000000000000014, 20.000000000000014, -9.70000000000001, -26.199999999999903, 39.20000000000001, 20.000000000000014, 15.499999999999963, -286.60000000000014, -95.8000000000003, 73.39999999999999, 29.29999999999997, 20.000000000000014, 20.000000000000014, -87.40000000000013, 20.000000000000014, -27.69999999999996, -13.600000000000026, -43.00000000000001, 9.499999999999936, 5.600000000000179, -164.8000000000006, -38.199999999999896, 43.70000000000013, -166.90000000000052, 20.000000000000014, 8.30000000000011, 20.000000000000014, -101.80000000000081, -3.09999999999999, 20.000000000000014, -258.3999999999998, -17.79999999999982, -113.20000000000013, 20.000000000000014, -19.90000000000005, -87.10000000000004, 20.000000000000014, -41.80000000000001, 197.29999999999998, 20.000000000000014, -110.20000000000036, -206.80000000000052, 20.000000000000014, 34.40000000000024, -80.80000000000067, 78.4999999999998, 36.20000000000003, 20.000000000000014, -13.600000000000033, 20.000000000000014, 20.000000000000014, 20.000000000000014, -280.30000000000007, -57.69999999999991, 20.000000000000014, 172.1, 25.40000000000004, 9.500000000000005, -46.900000000000006, 20.000000000000014, 20.900000000000013, 179.29999999999998, 20.000000000000014, -3.0999999999999828, 59.60000000000022, 19.100000000000204, 165.79999999999995, 101.89999999999941, -262.59999999999957, -70.00000000000004, -40.899999999999864, 37.10000000000004], "policy_predator_policy_reward": [117.0, 58.0, 11.0, 0.0, 0.0, 18.0, 18.0, 0.0, 65.0, 44.0, 0.0, 0.0, 21.0, 19.0, 0.0, 56.0, 17.0, 0.0, 22.0, 0.0, 36.0, 17.0, 0.0, 7.0, 0.0, 0.0, 131.0, 0.0, 0.0, 114.0, 0.0, 59.0, 0.0, 0.0, 13.0, 117.0, 0.0, 0.0, 10.0, 0.0, 8.0, 58.0, 1.0, 6.0, 96.0, 0.0, 75.0, 15.0, 147.0, 0.0, 80.0, 0.0, 28.0, 66.0, 92.0, 91.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 111.0, 10.0, 8.0, 0.0, 54.0, 47.0, 84.0, 147.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 68.0, 84.0, 10.0, 123.0, 60.0, 109.0, 103.0, 0.0, 18.0, 0.0, 0.0, 81.0, 0.0, 0.0, 0.0, 0.0, 76.0, 104.0, 0.0, 19.0, 0.0, 43.0, 0.0, 16.0, 73.0, 0.0, 0.0, 0.0, 48.0, 23.0, 0.0, 0.0, 0.0, 70.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 168.0, 0.0, 0.0, 0.0, 0.0, 82.0, 0.0, 9.0, 0.0, 27.0, 72.0, 0.0, 0.0, 0.0, 37.0, 0.0, 23.0, 54.0, 140.0, 26.0, 74.0, 2.0, 0.0, 77.0, 62.0, 66.0, 5.0, 35.0, 0.0, 35.0, 23.0, 96.0, 0.0, 20.0, 89.0, 27.0, 0.0, 0.0, 58.0, 0.0, 11.0, 94.0, 64.0, 93.0, 3.0, 17.0, 55.0, 37.0, 58.0, 0.0, 0.0, 127.0, 0.0, 0.0, 0.0, 72.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 100.0, 45.0, 6.0, 0.0, 0.0, 5.0, 0.0, 82.0, 0.0, 0.0, 11.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 163.0, 29.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2417552634538638, "mean_inference_ms": 3.429129268721151, "mean_action_processing_ms": 0.5759919357722605, "mean_env_wait_ms": 0.7793692770833465, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.034480929374694824, "StateBufferConnector_ms": 0.013460397720336914, "ViewRequirementAgentConnector_ms": 0.3570295572280884}, "num_episodes": 18, "episode_return_max": 336.79999999999995, "episode_return_min": -280.99999999999886, "episode_return_mean": 42.4249999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.68589823598847, "num_env_steps_trained_throughput_per_sec": 195.68589823598847, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 18591.665, "restore_workers_time_ms": 0.02, "training_step_time_ms": 18591.566, "sample_time_ms": 3792.498, "learn_time_ms": 14766.707, "learn_throughput": 270.88, "synch_weights_time_ms": 27.613}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "c52aa_00000", "date": "2024-08-13_00-04-33", "timestamp": 1723521873, "time_this_iter_s": 20.54153871536255, "time_total_s": 998.5881667137146, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc87ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 998.5881667137146, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 87.53103448275863, "ram_util_percent": 83.59310344827587}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2043933650803944, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.488515734546399, "policy_loss": -0.003710894082874927, "vf_loss": 5.491971761082846, "vf_explained_var": 0.07104973039299092, "kl": 0.009547145559592022, "entropy": 1.193325664315905, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6267203611947557, "cur_kl_coeff": 0.008898925781249995, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.898471745422908, "policy_loss": -0.003967844851305166, "vf_loss": 2.902404652259968, "vf_explained_var": 0.0024056516627155283, "kl": 0.003926222133542425, "entropy": 1.052037249324183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 336.79999999999995, "episode_reward_min": -280.99999999999886, "episode_reward_mean": 35.40199999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.19999999999976, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": -13.349000000000071, "predator_policy": 31.05}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.899999999999965, 31.900000000000027, -118.10000000000079, 56.40000000000017, -11.199999999999868, -280.99999999999886, 180.3999999999994, 157.69999999999885, 169.59999999999894, -3.9999999999999836, 42.00000000000047, -5.999999999999789, -137.20000000000044, 40.0000000000003, 114.69999999999968, 53.50000000000044, -37.199999999999925, -45.09999999999983, -134.20000000000002, -11.799999999999809, 110.19999999999911, 40.900000000000134, 207.39999999999878, 227.19999999999922, -155.00000000000097, 336.79999999999995, 129.49999999999937, 114.19999999999939, -50.80000000000035, 101.1999999999999, -23.700000000000077, 133.59999999999982, 14.300000000000097, 102.99999999999997, 40.20000000000015, 184.99999999999926, -132.20000000000067, 61.600000000000506, 256.8999999999994, -88.30000000000142, 30.100000000000172, 69.09999999999982, 40.0000000000003, 1.09999999999998, 82.19999999999985, -77.10000000000012, 77.5999999999996, 51.300000000000246, 71.59999999999911, 63.300000000000125, -21.5999999999998, 73.0999999999996, -107.00000000000102, -14.20000000000027, 55.300000000000104, -23.799999999999542, 27.900000000000126, -118.20000000000084, 2.7999999999997502, -34.99999999999992, 73.20000000000006, 217.29999999999924, -190.000000000001, 54.400000000000496, 69.70000000000023, 56.20000000000027, 22.400000000000276, 40.0000000000003, -193.00000000000048, 198.09999999999926, 39.90000000000028, 55.10000000000013, 200.19999999999933, 27.900000000000123, 87.69999999999878, 267.6999999999996, -169.60000000000048, 25.19999999999992, -122.80000000000064, 86.79999999999885, 87.40000000000006, -28.299999999999926, 89.699999999999, 40.0000000000003, -26.099999999999916, 243.399999999999, 29.000000000000128, -84.30000000000032, 261.3999999999995, -139.1000000000009, 90.69999999999882, -72.09999999999991, 47.300000000000416, 8.200000000000124, -10.599999999999708, 205.59999999999917, 139.69999999999908, -96.30000000000058, -63.59999999999984, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [95.59999999999997, -180.70000000000016, -22.299999999999955, -35.800000000000026, 20.000000000000014, -285.0999999999991, 73.10000000000001, -96.70000000000022, 19.700000000000045, -124.90000000000003, -261.3999999999994, -202.6000000000002, 160.39999999999998, 20.000000000000014, 98.8999999999994, 57.80000000000014, 20.000000000000014, 149.59999999999968, -106.60000000000002, -18.39999999999985, 3.200000000000003, 30.800000000000196, -127.00000000000074, 20.000000000000014, -245.1000000000005, -123.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 94.6999999999999, 33.50000000000022, 20.000000000000014, -66.39999999999998, -122.80000000000018, -177.10000000000005, -0.9999999999999917, -205.3000000000003, -97.90000000000005, -27.400000000000023, -87.40000000000015, -3.1000000000000463, 95.2999999999996, 43.40000000000003, -83.50000000000004, 72.2000000000002, 135.1999999999996, 108.19999999999942, 118.99999999999974, -127.90000000000057, -207.10000000000042, 146.9, 170.89999999999998, 20.000000000000014, 66.5, 20.000000000000014, 78.1999999999999, -15.699999999999768, -108.10000000000065, 81.19999999999999, 20.000000000000014, -114.69999999999985, 20.000000000000014, 113.60000000000004, 20.000000000000014, -75.70000000000041, 20.000000000000014, 20.000000000000014, 83.00000000000009, 29.0, 3.1999999999999704, 41.60000000000016, 139.3999999999999, 20.000000000000014, -320.19999999999976, 20.000000000000014, 41.60000000000025, 100.09999999999971, 156.79999999999976, -55.90000000000013, -114.40000000000069, 1.0999999999999688, 20.000000000000014, 62.30000000000021, -92.20000000000044, 20.000000000000014, 20.000000000000014, -9.70000000000001, -26.199999999999903, 39.20000000000001, 20.000000000000014, 15.499999999999963, -286.60000000000014, -95.8000000000003, 73.39999999999999, 29.29999999999997, 20.000000000000014, 20.000000000000014, -87.40000000000013, 20.000000000000014, -27.69999999999996, -13.600000000000026, -43.00000000000001, 9.499999999999936, 5.600000000000179, -164.8000000000006, -38.199999999999896, 43.70000000000013, -166.90000000000052, 20.000000000000014, 8.30000000000011, 20.000000000000014, -101.80000000000081, -3.09999999999999, 20.000000000000014, -258.3999999999998, -17.79999999999982, -113.20000000000013, 20.000000000000014, -19.90000000000005, -87.10000000000004, 20.000000000000014, -41.80000000000001, 197.29999999999998, 20.000000000000014, -110.20000000000036, -206.80000000000052, 20.000000000000014, 34.40000000000024, -80.80000000000067, 78.4999999999998, 36.20000000000003, 20.000000000000014, -13.600000000000033, 20.000000000000014, 20.000000000000014, 20.000000000000014, -280.30000000000007, -57.69999999999991, 20.000000000000014, 172.1, 25.40000000000004, 9.500000000000005, -46.900000000000006, 20.000000000000014, 20.900000000000013, 179.29999999999998, 20.000000000000014, -3.0999999999999828, 59.60000000000022, 19.100000000000204, 165.79999999999995, 101.89999999999941, -262.59999999999957, -70.00000000000004, -40.899999999999864, 37.10000000000004, -314.2, 22.39999999999997, 20.000000000000014, 66.80000000000001, 123.50000000000006, -87.10000000000079, 25.700000000000024, -232.00000000000045, -11.199999999999891, 68.89999999999979, 20.000000000000014, 20.000000000000014, -184.3000000000002, 42.20000000000002, 89.2999999999993, 154.10000000000008, -0.9999999999999846, 20.000000000000014, -73.60000000000008, -141.7000000000006, 139.70000000000002, 121.69999999999956, -76.60000000000062, -242.50000000000026, -39.99999999999976, 100.69999999999939, -135.10000000000065, -42.99999999999976, 43.40000000000024, -87.10000000000005, -137.50000000000026, 46.700000000000045, 20.000000000000014, -76.6000000000007, 20.000000000000014, 185.5999999999999, 148.69999999999968, -42.99999999999976, -158.50000000000034, -38.79999999999981, 20.000000000000014, -223.60000000000002, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [96.0, 0.0, 75.0, 15.0, 147.0, 0.0, 80.0, 0.0, 28.0, 66.0, 92.0, 91.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 111.0, 10.0, 8.0, 0.0, 54.0, 47.0, 84.0, 147.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 68.0, 84.0, 10.0, 123.0, 60.0, 109.0, 103.0, 0.0, 18.0, 0.0, 0.0, 81.0, 0.0, 0.0, 0.0, 0.0, 76.0, 104.0, 0.0, 19.0, 0.0, 43.0, 0.0, 16.0, 73.0, 0.0, 0.0, 0.0, 48.0, 23.0, 0.0, 0.0, 0.0, 70.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 168.0, 0.0, 0.0, 0.0, 0.0, 82.0, 0.0, 9.0, 0.0, 27.0, 72.0, 0.0, 0.0, 0.0, 37.0, 0.0, 23.0, 54.0, 140.0, 26.0, 74.0, 2.0, 0.0, 77.0, 62.0, 66.0, 5.0, 35.0, 0.0, 35.0, 23.0, 96.0, 0.0, 20.0, 89.0, 27.0, 0.0, 0.0, 58.0, 0.0, 11.0, 94.0, 64.0, 93.0, 3.0, 17.0, 55.0, 37.0, 58.0, 0.0, 0.0, 127.0, 0.0, 0.0, 0.0, 72.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 100.0, 45.0, 6.0, 0.0, 0.0, 5.0, 0.0, 82.0, 0.0, 0.0, 11.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 163.0, 29.0, 0.0, 169.0, 0.0, 0.0, 0.0, 51.0, 0.0, 103.0, 75.0, 0.0, 32.0, 0.0, 0.0, 0.0, 116.0, 0.0, 0.0, 0.0, 10.0, 54.0, 77.0, 0.0, 0.0, 46.0, 134.0, 0.0, 30.0, 76.0, 30.0, 51.0, 40.0, 99.0, 0.0, 46.0, 0.0, 0.0, 0.0, 13.0, 21.0, 11.0, 90.0, 0.0, 140.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2514455869892587, "mean_inference_ms": 3.4629393979124394, "mean_action_processing_ms": 0.5779862728056644, "mean_env_wait_ms": 0.7846093073749973, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03469669818878174, "StateBufferConnector_ms": 0.01380455493927002, "ViewRequirementAgentConnector_ms": 0.3878748416900635}, "num_episodes": 22, "episode_return_max": 336.79999999999995, "episode_return_min": -280.99999999999886, "episode_return_mean": 35.40199999999977, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 190.01573009175377, "num_env_steps_trained_throughput_per_sec": 190.01573009175377, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 18905.162, "restore_workers_time_ms": 0.02, "training_step_time_ms": 18905.063, "sample_time_ms": 3865.952, "learn_time_ms": 15007.195, "learn_throughput": 266.539, "synch_weights_time_ms": 27.578}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "c52aa_00000", "date": "2024-08-13_00-04-54", "timestamp": 1723521894, "time_this_iter_s": 21.119261264801025, "time_total_s": 1019.7074279785156, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9ca310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1019.7074279785156, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 87.13666666666667, "ram_util_percent": 83.55666666666664}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1115298448337447, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.09023602324188, "policy_loss": -0.002578836287711821, "vf_loss": 6.092491102218628, "vf_explained_var": 0.0007040269160396838, "kl": 0.012126927424827306, "entropy": 1.1830871828018672, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8223870832689856, "cur_kl_coeff": 0.004449462890624998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0099533444359188, "policy_loss": -0.0031571805065685006, "vf_loss": 3.01306561433449, "vf_explained_var": 0.013348334649252513, "kl": 0.010093441230732038, "entropy": 1.030225904183413, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 336.79999999999995, "episode_reward_min": -216.7000000000003, "episode_reward_mean": 35.818999999999754, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.19999999999976, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.29999999999998, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -13.400500000000086, "predator_policy": 31.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [227.19999999999922, -155.00000000000097, 336.79999999999995, 129.49999999999937, 114.19999999999939, -50.80000000000035, 101.1999999999999, -23.700000000000077, 133.59999999999982, 14.300000000000097, 102.99999999999997, 40.20000000000015, 184.99999999999926, -132.20000000000067, 61.600000000000506, 256.8999999999994, -88.30000000000142, 30.100000000000172, 69.09999999999982, 40.0000000000003, 1.09999999999998, 82.19999999999985, -77.10000000000012, 77.5999999999996, 51.300000000000246, 71.59999999999911, 63.300000000000125, -21.5999999999998, 73.0999999999996, -107.00000000000102, -14.20000000000027, 55.300000000000104, -23.799999999999542, 27.900000000000126, -118.20000000000084, 2.7999999999997502, -34.99999999999992, 73.20000000000006, 217.29999999999924, -190.000000000001, 54.400000000000496, 69.70000000000023, 56.20000000000027, 22.400000000000276, 40.0000000000003, -193.00000000000048, 198.09999999999926, 39.90000000000028, 55.10000000000013, 200.19999999999933, 27.900000000000123, 87.69999999999878, 267.6999999999996, -169.60000000000048, 25.19999999999992, -122.80000000000064, 86.79999999999885, 87.40000000000006, -28.299999999999926, 89.699999999999, 40.0000000000003, -26.099999999999916, 243.399999999999, 29.000000000000128, -84.30000000000032, 261.3999999999995, -139.1000000000009, 90.69999999999882, -72.09999999999991, 47.300000000000416, 8.200000000000124, -10.599999999999708, 205.59999999999917, 139.69999999999908, -96.30000000000058, -63.59999999999984, 40.0000000000003, 145.29999999999876, -43.500000000000504, -50.29999999999981, 106.89999999999912, -3.3999999999998547, -99.10000000000022, -79.3000000000013, 40.0000000000003, 132.39999999999966, 215.49999999999923, -15.399999999999977, 29.300000000000168, -125.20000000000115, 47.30000000000016, 91.0, 215.3999999999995, 59.800000000000054, 76.3000000000001, -79.29999999999993, -103.20000000000005, 58.00000000000027, 69.70000000000003, -216.7000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [108.19999999999942, 118.99999999999974, -127.90000000000057, -207.10000000000042, 146.9, 170.89999999999998, 20.000000000000014, 66.5, 20.000000000000014, 78.1999999999999, -15.699999999999768, -108.10000000000065, 81.19999999999999, 20.000000000000014, -114.69999999999985, 20.000000000000014, 113.60000000000004, 20.000000000000014, -75.70000000000041, 20.000000000000014, 20.000000000000014, 83.00000000000009, 29.0, 3.1999999999999704, 41.60000000000016, 139.3999999999999, 20.000000000000014, -320.19999999999976, 20.000000000000014, 41.60000000000025, 100.09999999999971, 156.79999999999976, -55.90000000000013, -114.40000000000069, 1.0999999999999688, 20.000000000000014, 62.30000000000021, -92.20000000000044, 20.000000000000014, 20.000000000000014, -9.70000000000001, -26.199999999999903, 39.20000000000001, 20.000000000000014, 15.499999999999963, -286.60000000000014, -95.8000000000003, 73.39999999999999, 29.29999999999997, 20.000000000000014, 20.000000000000014, -87.40000000000013, 20.000000000000014, -27.69999999999996, -13.600000000000026, -43.00000000000001, 9.499999999999936, 5.600000000000179, -164.8000000000006, -38.199999999999896, 43.70000000000013, -166.90000000000052, 20.000000000000014, 8.30000000000011, 20.000000000000014, -101.80000000000081, -3.09999999999999, 20.000000000000014, -258.3999999999998, -17.79999999999982, -113.20000000000013, 20.000000000000014, -19.90000000000005, -87.10000000000004, 20.000000000000014, -41.80000000000001, 197.29999999999998, 20.000000000000014, -110.20000000000036, -206.80000000000052, 20.000000000000014, 34.40000000000024, -80.80000000000067, 78.4999999999998, 36.20000000000003, 20.000000000000014, -13.600000000000033, 20.000000000000014, 20.000000000000014, 20.000000000000014, -280.30000000000007, -57.69999999999991, 20.000000000000014, 172.1, 25.40000000000004, 9.500000000000005, -46.900000000000006, 20.000000000000014, 20.900000000000013, 179.29999999999998, 20.000000000000014, -3.0999999999999828, 59.60000000000022, 19.100000000000204, 165.79999999999995, 101.89999999999941, -262.59999999999957, -70.00000000000004, -40.899999999999864, 37.10000000000004, -314.2, 22.39999999999997, 20.000000000000014, 66.80000000000001, 123.50000000000006, -87.10000000000079, 25.700000000000024, -232.00000000000045, -11.199999999999891, 68.89999999999979, 20.000000000000014, 20.000000000000014, -184.3000000000002, 42.20000000000002, 89.2999999999993, 154.10000000000008, -0.9999999999999846, 20.000000000000014, -73.60000000000008, -141.7000000000006, 139.70000000000002, 121.69999999999956, -76.60000000000062, -242.50000000000026, -39.99999999999976, 100.69999999999939, -135.10000000000065, -42.99999999999976, 43.40000000000024, -87.10000000000005, -137.50000000000026, 46.700000000000045, 20.000000000000014, -76.6000000000007, 20.000000000000014, 185.5999999999999, 148.69999999999968, -42.99999999999976, -158.50000000000034, -38.79999999999981, 20.000000000000014, -223.60000000000002, 20.000000000000014, 20.000000000000014, 124.39999999999952, 20.90000000000003, -47.19999999999976, -28.29999999999975, -156.40000000000043, -13.900000000000015, 20.000000000000014, 83.89999999999964, 100.09999999999971, -221.50000000000026, -283.59999999999997, 24.500000000000096, -172.00000000000057, -7.299999999999891, 20.000000000000014, 20.000000000000014, 196.39999999999998, -142.0000000000002, 195.49999999999997, 20.000000000000014, -114.40000000000008, 20.000000000000014, 12.199999999999818, -154.90000000000006, -99.70000000000081, -194.50000000000037, -122.50000000000026, 84.80000000000018, 20.000000000000014, 19.999999999999968, 118.99999999999949, 73.39999999999996, 168.5, -225.70000000000044, 65.00000000000014, -48.69999999999984, -232.0000000000002, 19.70000000000021, -47.8, -216.40000000000038, 37.999999999999986, 20.000000000000014, 31.70000000000008, 38.00000000000021, -185.80000000000058, -229.9], "policy_predator_policy_reward": [0.0, 0.0, 76.0, 104.0, 0.0, 19.0, 0.0, 43.0, 0.0, 16.0, 73.0, 0.0, 0.0, 0.0, 48.0, 23.0, 0.0, 0.0, 0.0, 70.0, 0.0, 0.0, 0.0, 8.0, 0.0, 4.0, 0.0, 168.0, 0.0, 0.0, 0.0, 0.0, 82.0, 0.0, 9.0, 0.0, 27.0, 72.0, 0.0, 0.0, 0.0, 37.0, 0.0, 23.0, 54.0, 140.0, 26.0, 74.0, 2.0, 0.0, 77.0, 62.0, 66.0, 5.0, 35.0, 0.0, 35.0, 23.0, 96.0, 0.0, 20.0, 89.0, 27.0, 0.0, 0.0, 58.0, 0.0, 11.0, 94.0, 64.0, 93.0, 3.0, 17.0, 55.0, 37.0, 58.0, 0.0, 0.0, 127.0, 0.0, 0.0, 0.0, 72.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 100.0, 45.0, 6.0, 0.0, 0.0, 5.0, 0.0, 82.0, 0.0, 0.0, 11.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 163.0, 29.0, 0.0, 169.0, 0.0, 0.0, 0.0, 51.0, 0.0, 103.0, 75.0, 0.0, 32.0, 0.0, 0.0, 0.0, 116.0, 0.0, 0.0, 0.0, 10.0, 54.0, 77.0, 0.0, 0.0, 46.0, 134.0, 0.0, 30.0, 76.0, 30.0, 51.0, 40.0, 99.0, 0.0, 46.0, 0.0, 0.0, 0.0, 13.0, 21.0, 11.0, 90.0, 0.0, 140.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 120.0, 3.0, 0.0, 115.0, 3.0, 160.0, 0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 0.0, 79.0, 129.0, 43.0, 112.0, 57.0, 0.0, 85.0, 51.0, 0.0, 23.0, 0.0, 117.0, 0.0, 12.0, 48.0, 13.0, 120.0, 161.0, 0.0, 0.0, 0.0, 0.0, 0.0, 199.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.25397347248547, "mean_inference_ms": 3.479526487182145, "mean_action_processing_ms": 0.5792907325167309, "mean_env_wait_ms": 0.7874380517189651, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.04835927486419678, "StateBufferConnector_ms": 0.008250832557678223, "ViewRequirementAgentConnector_ms": 0.35159361362457275}, "num_episodes": 23, "episode_return_max": 336.79999999999995, "episode_return_min": -216.7000000000003, "episode_return_mean": 35.818999999999754, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 188.84122876933924, "num_env_steps_trained_throughput_per_sec": 188.84122876933924, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 19337.452, "restore_workers_time_ms": 0.02, "training_step_time_ms": 19337.336, "sample_time_ms": 3929.884, "learn_time_ms": 15374.466, "learn_throughput": 260.172, "synch_weights_time_ms": 28.969}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "c52aa_00000", "date": "2024-08-13_00-05-15", "timestamp": 1723521915, "time_this_iter_s": 21.3139169216156, "time_total_s": 1041.0213449001312, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9caee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1041.0213449001312, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 87.83333333333331, "ram_util_percent": 83.59333333333332}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.088343636313128, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.089488944300899, "policy_loss": -0.002636746149608698, "vf_loss": 6.091816995257423, "vf_explained_var": 0.13038060097467333, "kl": 0.01156318452907195, "entropy": 1.1669877438318161, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6944680922167011, "cur_kl_coeff": 0.004449462890624998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.677905008591041, "policy_loss": -0.004174310785949861, "vf_loss": 2.6820434943708795, "vf_explained_var": 0.007570598554358912, "kl": 0.008050461088021947, "entropy": 0.972698477651707, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 281.9000000000003, "episode_reward_min": -216.7000000000003, "episode_reward_mean": 45.16799999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -314.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -7.696000000000079, "predator_policy": 30.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [69.09999999999982, 40.0000000000003, 1.09999999999998, 82.19999999999985, -77.10000000000012, 77.5999999999996, 51.300000000000246, 71.59999999999911, 63.300000000000125, -21.5999999999998, 73.0999999999996, -107.00000000000102, -14.20000000000027, 55.300000000000104, -23.799999999999542, 27.900000000000126, -118.20000000000084, 2.7999999999997502, -34.99999999999992, 73.20000000000006, 217.29999999999924, -190.000000000001, 54.400000000000496, 69.70000000000023, 56.20000000000027, 22.400000000000276, 40.0000000000003, -193.00000000000048, 198.09999999999926, 39.90000000000028, 55.10000000000013, 200.19999999999933, 27.900000000000123, 87.69999999999878, 267.6999999999996, -169.60000000000048, 25.19999999999992, -122.80000000000064, 86.79999999999885, 87.40000000000006, -28.299999999999926, 89.699999999999, 40.0000000000003, -26.099999999999916, 243.399999999999, 29.000000000000128, -84.30000000000032, 261.3999999999995, -139.1000000000009, 90.69999999999882, -72.09999999999991, 47.300000000000416, 8.200000000000124, -10.599999999999708, 205.59999999999917, 139.69999999999908, -96.30000000000058, -63.59999999999984, 40.0000000000003, 145.29999999999876, -43.500000000000504, -50.29999999999981, 106.89999999999912, -3.3999999999998547, -99.10000000000022, -79.3000000000013, 40.0000000000003, 132.39999999999966, 215.49999999999923, -15.399999999999977, 29.300000000000168, -125.20000000000115, 47.30000000000016, 91.0, 215.3999999999995, 59.800000000000054, 76.3000000000001, -79.29999999999993, -103.20000000000005, 58.00000000000027, 69.70000000000003, -216.7000000000003, 142.49999999999898, -43.79999999999976, 42.700000000000344, 13.000000000000165, 195.69999999999905, 251.69999999999973, 227.79999999999964, 10.300000000000045, 126.09999999999937, 40.0000000000003, 85.50000000000003, -52.4999999999997, 149.7999999999993, 244.29999999999953, 58.400000000000404, 196.89999999999938, 281.9000000000003, 248.19999999999982], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [62.30000000000021, -92.20000000000044, 20.000000000000014, 20.000000000000014, -9.70000000000001, -26.199999999999903, 39.20000000000001, 20.000000000000014, 15.499999999999963, -286.60000000000014, -95.8000000000003, 73.39999999999999, 29.29999999999997, 20.000000000000014, 20.000000000000014, -87.40000000000013, 20.000000000000014, -27.69999999999996, -13.600000000000026, -43.00000000000001, 9.499999999999936, 5.600000000000179, -164.8000000000006, -38.199999999999896, 43.70000000000013, -166.90000000000052, 20.000000000000014, 8.30000000000011, 20.000000000000014, -101.80000000000081, -3.09999999999999, 20.000000000000014, -258.3999999999998, -17.79999999999982, -113.20000000000013, 20.000000000000014, -19.90000000000005, -87.10000000000004, 20.000000000000014, -41.80000000000001, 197.29999999999998, 20.000000000000014, -110.20000000000036, -206.80000000000052, 20.000000000000014, 34.40000000000024, -80.80000000000067, 78.4999999999998, 36.20000000000003, 20.000000000000014, -13.600000000000033, 20.000000000000014, 20.000000000000014, 20.000000000000014, -280.30000000000007, -57.69999999999991, 20.000000000000014, 172.1, 25.40000000000004, 9.500000000000005, -46.900000000000006, 20.000000000000014, 20.900000000000013, 179.29999999999998, 20.000000000000014, -3.0999999999999828, 59.60000000000022, 19.100000000000204, 165.79999999999995, 101.89999999999941, -262.59999999999957, -70.00000000000004, -40.899999999999864, 37.10000000000004, -314.2, 22.39999999999997, 20.000000000000014, 66.80000000000001, 123.50000000000006, -87.10000000000079, 25.700000000000024, -232.00000000000045, -11.199999999999891, 68.89999999999979, 20.000000000000014, 20.000000000000014, -184.3000000000002, 42.20000000000002, 89.2999999999993, 154.10000000000008, -0.9999999999999846, 20.000000000000014, -73.60000000000008, -141.7000000000006, 139.70000000000002, 121.69999999999956, -76.60000000000062, -242.50000000000026, -39.99999999999976, 100.69999999999939, -135.10000000000065, -42.99999999999976, 43.40000000000024, -87.10000000000005, -137.50000000000026, 46.700000000000045, 20.000000000000014, -76.6000000000007, 20.000000000000014, 185.5999999999999, 148.69999999999968, -42.99999999999976, -158.50000000000034, -38.79999999999981, 20.000000000000014, -223.60000000000002, 20.000000000000014, 20.000000000000014, 124.39999999999952, 20.90000000000003, -47.19999999999976, -28.29999999999975, -156.40000000000043, -13.900000000000015, 20.000000000000014, 83.89999999999964, 100.09999999999971, -221.50000000000026, -283.59999999999997, 24.500000000000096, -172.00000000000057, -7.299999999999891, 20.000000000000014, 20.000000000000014, 196.39999999999998, -142.0000000000002, 195.49999999999997, 20.000000000000014, -114.40000000000008, 20.000000000000014, 12.199999999999818, -154.90000000000006, -99.70000000000081, -194.50000000000037, -122.50000000000026, 84.80000000000018, 20.000000000000014, 19.999999999999968, 118.99999999999949, 73.39999999999996, 168.5, -225.70000000000044, 65.00000000000014, -48.69999999999984, -232.0000000000002, 19.70000000000021, -47.8, -216.40000000000038, 37.999999999999986, 20.000000000000014, 31.70000000000008, 38.00000000000021, -185.80000000000058, -229.9, 76.0999999999996, 55.40000000000014, -218.2000000000004, 34.39999999999999, 20.000000000000014, 22.70000000000006, -74.50000000000009, 42.500000000000085, 32.600000000000136, 163.0999999999998, 170.0, 46.70000000000007, 111.79999999999968, 109.99999999999989, -36.69999999999976, 20.000000000000014, 20.000000000000014, 64.09999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.499999999999993, 20.000000000000014, -170.50000000000048, 26.30000000000001, 123.49999999999986, 74.89999999999986, 160.39999999999992, 20.000000000000014, 22.39999999999999, -5.199999999999955, 190.1, 200.0, 53.899999999999636, 55.99999999999999, 162.1999999999998], "policy_predator_policy_reward": [27.0, 72.0, 0.0, 0.0, 0.0, 37.0, 0.0, 23.0, 54.0, 140.0, 26.0, 74.0, 2.0, 0.0, 77.0, 62.0, 66.0, 5.0, 35.0, 0.0, 35.0, 23.0, 96.0, 0.0, 20.0, 89.0, 27.0, 0.0, 0.0, 58.0, 0.0, 11.0, 94.0, 64.0, 93.0, 3.0, 17.0, 55.0, 37.0, 58.0, 0.0, 0.0, 127.0, 0.0, 0.0, 0.0, 72.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 100.0, 45.0, 6.0, 0.0, 0.0, 5.0, 0.0, 82.0, 0.0, 0.0, 11.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 163.0, 29.0, 0.0, 169.0, 0.0, 0.0, 0.0, 51.0, 0.0, 103.0, 75.0, 0.0, 32.0, 0.0, 0.0, 0.0, 116.0, 0.0, 0.0, 0.0, 10.0, 54.0, 77.0, 0.0, 0.0, 46.0, 134.0, 0.0, 30.0, 76.0, 30.0, 51.0, 40.0, 99.0, 0.0, 46.0, 0.0, 0.0, 0.0, 13.0, 21.0, 11.0, 90.0, 0.0, 140.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 120.0, 3.0, 0.0, 115.0, 3.0, 160.0, 0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 0.0, 79.0, 129.0, 43.0, 112.0, 57.0, 0.0, 85.0, 51.0, 0.0, 23.0, 0.0, 117.0, 0.0, 12.0, 48.0, 13.0, 120.0, 161.0, 0.0, 0.0, 0.0, 0.0, 0.0, 199.0, 0.0, 7.0, 4.0, 65.0, 75.0, 0.0, 0.0, 45.0, 0.0, 0.0, 0.0, 25.0, 10.0, 6.0, 0.0, 27.0, 0.0, 25.0, 17.0, 0.0, 0.0, 0.0, 38.0, 0.0, 98.0, 0.0, 0.0, 9.0, 0.0, 16.0, 0.0, 0.0, 12.0, 1.0, 27.0, 0.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2657978716768725, "mean_inference_ms": 3.515797280144219, "mean_action_processing_ms": 0.5809761852496261, "mean_env_wait_ms": 0.7919610336988654, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027841687202453613, "StateBufferConnector_ms": 0.007189750671386719, "ViewRequirementAgentConnector_ms": 0.297127366065979}, "num_episodes": 18, "episode_return_max": 281.9000000000003, "episode_return_min": -216.7000000000003, "episode_return_mean": 45.16799999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 175.4649468387903, "num_env_steps_trained_throughput_per_sec": 175.4649468387903, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 19714.141, "restore_workers_time_ms": 0.017, "training_step_time_ms": 19714.019, "sample_time_ms": 4085.777, "learn_time_ms": 15594.858, "learn_throughput": 256.495, "synch_weights_time_ms": 29.801}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "c52aa_00000", "date": "2024-08-13_00-05-38", "timestamp": 1723521938, "time_this_iter_s": 22.9171142578125, "time_total_s": 1063.9384591579437, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c08b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1063.9384591579437, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 87.54848484848486, "ram_util_percent": 83.65151515151516}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3039244389644375, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.396545297632772, "policy_loss": -0.0017866219349560284, "vf_loss": 4.398112701991248, "vf_explained_var": 0.10883574000111333, "kl": 0.008210869106038961, "entropy": 1.1942431437906134, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6701939094397756, "cur_kl_coeff": 0.004449462890624998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3528304464917964, "policy_loss": -0.002620558280044447, "vf_loss": 1.3553948869623205, "vf_explained_var": 0.007834194040803051, "kl": 0.012612308543586716, "entropy": 0.926467145813836, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 281.9000000000003, "episode_reward_min": -216.7000000000003, "episode_reward_mean": 60.27099999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -314.2, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 3.210499999999912, "predator_policy": 26.925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-34.99999999999992, 73.20000000000006, 217.29999999999924, -190.000000000001, 54.400000000000496, 69.70000000000023, 56.20000000000027, 22.400000000000276, 40.0000000000003, -193.00000000000048, 198.09999999999926, 39.90000000000028, 55.10000000000013, 200.19999999999933, 27.900000000000123, 87.69999999999878, 267.6999999999996, -169.60000000000048, 25.19999999999992, -122.80000000000064, 86.79999999999885, 87.40000000000006, -28.299999999999926, 89.699999999999, 40.0000000000003, -26.099999999999916, 243.399999999999, 29.000000000000128, -84.30000000000032, 261.3999999999995, -139.1000000000009, 90.69999999999882, -72.09999999999991, 47.300000000000416, 8.200000000000124, -10.599999999999708, 205.59999999999917, 139.69999999999908, -96.30000000000058, -63.59999999999984, 40.0000000000003, 145.29999999999876, -43.500000000000504, -50.29999999999981, 106.89999999999912, -3.3999999999998547, -99.10000000000022, -79.3000000000013, 40.0000000000003, 132.39999999999966, 215.49999999999923, -15.399999999999977, 29.300000000000168, -125.20000000000115, 47.30000000000016, 91.0, 215.3999999999995, 59.800000000000054, 76.3000000000001, -79.29999999999993, -103.20000000000005, 58.00000000000027, 69.70000000000003, -216.7000000000003, 142.49999999999898, -43.79999999999976, 42.700000000000344, 13.000000000000165, 195.69999999999905, 251.69999999999973, 227.79999999999964, 10.300000000000045, 126.09999999999937, 40.0000000000003, 85.50000000000003, -52.4999999999997, 149.7999999999993, 244.29999999999953, 58.400000000000404, 196.89999999999938, 281.9000000000003, 248.19999999999982, 180.8999999999991, 142.09999999999982, 104.79999999999856, 56.700000000000394, -25.299999999999635, 109.99999999999865, 0.30000000000006855, 228.0999999999992, 241.5999999999994, 40.0000000000003, 32.30000000000017, 128.1999999999988, -19.39999999999975, 24.60000000000008, 201.09999999999914, 68.60000000000028, 166.59999999999897, 82.49999999999991], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-19.90000000000005, -87.10000000000004, 20.000000000000014, -41.80000000000001, 197.29999999999998, 20.000000000000014, -110.20000000000036, -206.80000000000052, 20.000000000000014, 34.40000000000024, -80.80000000000067, 78.4999999999998, 36.20000000000003, 20.000000000000014, -13.600000000000033, 20.000000000000014, 20.000000000000014, 20.000000000000014, -280.30000000000007, -57.69999999999991, 20.000000000000014, 172.1, 25.40000000000004, 9.500000000000005, -46.900000000000006, 20.000000000000014, 20.900000000000013, 179.29999999999998, 20.000000000000014, -3.0999999999999828, 59.60000000000022, 19.100000000000204, 165.79999999999995, 101.89999999999941, -262.59999999999957, -70.00000000000004, -40.899999999999864, 37.10000000000004, -314.2, 22.39999999999997, 20.000000000000014, 66.80000000000001, 123.50000000000006, -87.10000000000079, 25.700000000000024, -232.00000000000045, -11.199999999999891, 68.89999999999979, 20.000000000000014, 20.000000000000014, -184.3000000000002, 42.20000000000002, 89.2999999999993, 154.10000000000008, -0.9999999999999846, 20.000000000000014, -73.60000000000008, -141.7000000000006, 139.70000000000002, 121.69999999999956, -76.60000000000062, -242.50000000000026, -39.99999999999976, 100.69999999999939, -135.10000000000065, -42.99999999999976, 43.40000000000024, -87.10000000000005, -137.50000000000026, 46.700000000000045, 20.000000000000014, -76.6000000000007, 20.000000000000014, 185.5999999999999, 148.69999999999968, -42.99999999999976, -158.50000000000034, -38.79999999999981, 20.000000000000014, -223.60000000000002, 20.000000000000014, 20.000000000000014, 124.39999999999952, 20.90000000000003, -47.19999999999976, -28.29999999999975, -156.40000000000043, -13.900000000000015, 20.000000000000014, 83.89999999999964, 100.09999999999971, -221.50000000000026, -283.59999999999997, 24.500000000000096, -172.00000000000057, -7.299999999999891, 20.000000000000014, 20.000000000000014, 196.39999999999998, -142.0000000000002, 195.49999999999997, 20.000000000000014, -114.40000000000008, 20.000000000000014, 12.199999999999818, -154.90000000000006, -99.70000000000081, -194.50000000000037, -122.50000000000026, 84.80000000000018, 20.000000000000014, 19.999999999999968, 118.99999999999949, 73.39999999999996, 168.5, -225.70000000000044, 65.00000000000014, -48.69999999999984, -232.0000000000002, 19.70000000000021, -47.8, -216.40000000000038, 37.999999999999986, 20.000000000000014, 31.70000000000008, 38.00000000000021, -185.80000000000058, -229.9, 76.0999999999996, 55.40000000000014, -218.2000000000004, 34.39999999999999, 20.000000000000014, 22.70000000000006, -74.50000000000009, 42.500000000000085, 32.600000000000136, 163.0999999999998, 170.0, 46.70000000000007, 111.79999999999968, 109.99999999999989, -36.69999999999976, 20.000000000000014, 20.000000000000014, 64.09999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.499999999999993, 20.000000000000014, -170.50000000000048, 26.30000000000001, 123.49999999999986, 74.89999999999986, 160.39999999999992, 20.000000000000014, 22.39999999999999, -5.199999999999955, 190.1, 200.0, 53.899999999999636, 55.99999999999999, 162.1999999999998, 134.89999999999984, 20.000000000000014, -151.30000000000018, 187.40000000000003, 20.000000000000014, 84.7999999999993, -27.39999999999982, 46.10000000000024, -217.30000000000047, 20.000000000000014, 17.899999999999977, 91.09999999999945, -152.20000000000013, 24.500000000000085, 125.29999999999956, 102.7999999999997, 96.49999999999997, 145.09999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.29999999999999, 108.19999999999949, 20.000000000000014, 79.39999999999995, -206.8000000000004, 20.000000000000014, -9.399999999999912, 36.200000000000166, 164.89999999999978, -1.0000000000000204, 59.600000000000165, 21.800000000000026, 138.79999999999964, 20.000000000000014, 36.500000000000036], "policy_predator_policy_reward": [17.0, 55.0, 37.0, 58.0, 0.0, 0.0, 127.0, 0.0, 0.0, 0.0, 72.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 100.0, 45.0, 6.0, 0.0, 0.0, 5.0, 0.0, 82.0, 0.0, 0.0, 11.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 163.0, 29.0, 0.0, 169.0, 0.0, 0.0, 0.0, 51.0, 0.0, 103.0, 75.0, 0.0, 32.0, 0.0, 0.0, 0.0, 116.0, 0.0, 0.0, 0.0, 10.0, 54.0, 77.0, 0.0, 0.0, 46.0, 134.0, 0.0, 30.0, 76.0, 30.0, 51.0, 40.0, 99.0, 0.0, 46.0, 0.0, 0.0, 0.0, 13.0, 21.0, 11.0, 90.0, 0.0, 140.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 120.0, 3.0, 0.0, 115.0, 3.0, 160.0, 0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 0.0, 79.0, 129.0, 43.0, 112.0, 57.0, 0.0, 85.0, 51.0, 0.0, 23.0, 0.0, 117.0, 0.0, 12.0, 48.0, 13.0, 120.0, 161.0, 0.0, 0.0, 0.0, 0.0, 0.0, 199.0, 0.0, 7.0, 4.0, 65.0, 75.0, 0.0, 0.0, 45.0, 0.0, 0.0, 0.0, 25.0, 10.0, 6.0, 0.0, 27.0, 0.0, 25.0, 17.0, 0.0, 0.0, 0.0, 38.0, 0.0, 98.0, 0.0, 0.0, 9.0, 0.0, 16.0, 0.0, 0.0, 12.0, 1.0, 27.0, 0.0, 30.0, 13.0, 13.0, 106.0, 0.0, 0.0, 0.0, 0.0, 38.0, 80.0, 92.0, 0.0, 1.0, 54.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 108.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 26.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2728040760060848, "mean_inference_ms": 3.544161700967298, "mean_action_processing_ms": 0.5827222783208651, "mean_env_wait_ms": 0.7955578842547248, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02592337131500244, "StateBufferConnector_ms": 0.005513310432434082, "ViewRequirementAgentConnector_ms": 0.32395148277282715}, "num_episodes": 18, "episode_return_max": 281.9000000000003, "episode_return_min": -216.7000000000003, "episode_return_mean": 60.27099999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 174.2230778315613, "num_env_steps_trained_throughput_per_sec": 174.2230778315613, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 20294.571, "restore_workers_time_ms": 0.017, "training_step_time_ms": 20294.449, "sample_time_ms": 4221.572, "learn_time_ms": 16039.542, "learn_throughput": 249.384, "synch_weights_time_ms": 28.995}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "c52aa_00000", "date": "2024-08-13_00-06-01", "timestamp": 1723521961, "time_this_iter_s": 23.073565006256104, "time_total_s": 1087.0120241641998, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c0ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1087.0120241641998, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 91.153125, "ram_util_percent": 83.73124999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.167906732916359, "cur_kl_coeff": 0.02669677734374999, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.399127895869906, "policy_loss": -0.003928451259526863, "vf_loss": 5.402494945727959, "vf_explained_var": 0.07448753023904467, "kl": 0.021029205537176333, "entropy": 1.1558312855700337, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4876863026823947, "cur_kl_coeff": 0.004449462890624998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7613084871932942, "policy_loss": -0.0036006332141046643, "vf_loss": 1.7648323522042977, "vf_explained_var": -0.0008711171528649708, "kl": 0.017252116464281077, "entropy": 0.8303418309284897, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 285.7000000000007, "episode_reward_min": -216.7000000000003, "episode_reward_mean": 66.43999999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.29999999999984, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 7.1299999999999155, "predator_policy": 26.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.299999999999926, 89.699999999999, 40.0000000000003, -26.099999999999916, 243.399999999999, 29.000000000000128, -84.30000000000032, 261.3999999999995, -139.1000000000009, 90.69999999999882, -72.09999999999991, 47.300000000000416, 8.200000000000124, -10.599999999999708, 205.59999999999917, 139.69999999999908, -96.30000000000058, -63.59999999999984, 40.0000000000003, 145.29999999999876, -43.500000000000504, -50.29999999999981, 106.89999999999912, -3.3999999999998547, -99.10000000000022, -79.3000000000013, 40.0000000000003, 132.39999999999966, 215.49999999999923, -15.399999999999977, 29.300000000000168, -125.20000000000115, 47.30000000000016, 91.0, 215.3999999999995, 59.800000000000054, 76.3000000000001, -79.29999999999993, -103.20000000000005, 58.00000000000027, 69.70000000000003, -216.7000000000003, 142.49999999999898, -43.79999999999976, 42.700000000000344, 13.000000000000165, 195.69999999999905, 251.69999999999973, 227.79999999999964, 10.300000000000045, 126.09999999999937, 40.0000000000003, 85.50000000000003, -52.4999999999997, 149.7999999999993, 244.29999999999953, 58.400000000000404, 196.89999999999938, 281.9000000000003, 248.19999999999982, 180.8999999999991, 142.09999999999982, 104.79999999999856, 56.700000000000394, -25.299999999999635, 109.99999999999865, 0.30000000000006855, 228.0999999999992, 241.5999999999994, 40.0000000000003, 32.30000000000017, 128.1999999999988, -19.39999999999975, 24.60000000000008, 201.09999999999914, 68.60000000000028, 166.59999999999897, 82.49999999999991, 158.79999999999913, -104.10000000000039, 118.6999999999992, 219.99999999999903, 7.6000000000001275, 35.60000000000038, 40.0000000000003, -39.79999999999984, 204.69999999999916, 38.400000000000276, 40.0000000000003, 173.69999999999976, 11.399999999999972, -42.199999999999946, 181.89999999999944, -91.69999999999997, 48.100000000000286, 84.10000000000034, 47.20000000000029, 159.69999999999905, 285.7000000000007, -62.099999999999824], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [25.700000000000024, -232.00000000000045, -11.199999999999891, 68.89999999999979, 20.000000000000014, 20.000000000000014, -184.3000000000002, 42.20000000000002, 89.2999999999993, 154.10000000000008, -0.9999999999999846, 20.000000000000014, -73.60000000000008, -141.7000000000006, 139.70000000000002, 121.69999999999956, -76.60000000000062, -242.50000000000026, -39.99999999999976, 100.69999999999939, -135.10000000000065, -42.99999999999976, 43.40000000000024, -87.10000000000005, -137.50000000000026, 46.700000000000045, 20.000000000000014, -76.6000000000007, 20.000000000000014, 185.5999999999999, 148.69999999999968, -42.99999999999976, -158.50000000000034, -38.79999999999981, 20.000000000000014, -223.60000000000002, 20.000000000000014, 20.000000000000014, 124.39999999999952, 20.90000000000003, -47.19999999999976, -28.29999999999975, -156.40000000000043, -13.900000000000015, 20.000000000000014, 83.89999999999964, 100.09999999999971, -221.50000000000026, -283.59999999999997, 24.500000000000096, -172.00000000000057, -7.299999999999891, 20.000000000000014, 20.000000000000014, 196.39999999999998, -142.0000000000002, 195.49999999999997, 20.000000000000014, -114.40000000000008, 20.000000000000014, 12.199999999999818, -154.90000000000006, -99.70000000000081, -194.50000000000037, -122.50000000000026, 84.80000000000018, 20.000000000000014, 19.999999999999968, 118.99999999999949, 73.39999999999996, 168.5, -225.70000000000044, 65.00000000000014, -48.69999999999984, -232.0000000000002, 19.70000000000021, -47.8, -216.40000000000038, 37.999999999999986, 20.000000000000014, 31.70000000000008, 38.00000000000021, -185.80000000000058, -229.9, 76.0999999999996, 55.40000000000014, -218.2000000000004, 34.39999999999999, 20.000000000000014, 22.70000000000006, -74.50000000000009, 42.500000000000085, 32.600000000000136, 163.0999999999998, 170.0, 46.70000000000007, 111.79999999999968, 109.99999999999989, -36.69999999999976, 20.000000000000014, 20.000000000000014, 64.09999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.499999999999993, 20.000000000000014, -170.50000000000048, 26.30000000000001, 123.49999999999986, 74.89999999999986, 160.39999999999992, 20.000000000000014, 22.39999999999999, -5.199999999999955, 190.1, 200.0, 53.899999999999636, 55.99999999999999, 162.1999999999998, 134.89999999999984, 20.000000000000014, -151.30000000000018, 187.40000000000003, 20.000000000000014, 84.7999999999993, -27.39999999999982, 46.10000000000024, -217.30000000000047, 20.000000000000014, 17.899999999999977, 91.09999999999945, -152.20000000000013, 24.500000000000085, 125.29999999999956, 102.7999999999997, 96.49999999999997, 145.09999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.29999999999999, 108.19999999999949, 20.000000000000014, 79.39999999999995, -206.8000000000004, 20.000000000000014, -9.399999999999912, 36.200000000000166, 164.89999999999978, -1.0000000000000204, 59.600000000000165, 21.800000000000026, 138.79999999999964, 20.000000000000014, 36.500000000000036, 36.2000000000002, 122.59999999999977, 20.000000000000014, -255.10000000000005, -51.399999999999864, 136.09999999999968, 47.90000000000024, 172.0999999999999, -74.50000000000051, 37.100000000000016, 20.000000000000014, 2.600000000000078, 20.000000000000014, 20.000000000000014, 42.50000000000009, -175.3000000000003, 184.6999999999999, 20.000000000000014, 50.600000000000236, -47.19999999999976, 20.000000000000014, 20.000000000000014, 83.89999999999996, 87.79999999999993, 15.799999999999965, -30.399999999999906, 118.09999999999991, -364.29999999999984, -11.499999999999819, 178.4, -252.70000000000007, 20.000000000000014, 28.10000000000008, 20.000000000000014, 64.10000000000022, 20.000000000000014, 27.200000000000003, 20.000000000000014, 78.49999999999962, 81.19999999999945, 100.9999999999997, 184.69999999999996, 78.49999999999952, -286.5999999999995], "policy_predator_policy_reward": [103.0, 75.0, 0.0, 32.0, 0.0, 0.0, 0.0, 116.0, 0.0, 0.0, 0.0, 10.0, 54.0, 77.0, 0.0, 0.0, 46.0, 134.0, 0.0, 30.0, 76.0, 30.0, 51.0, 40.0, 99.0, 0.0, 46.0, 0.0, 0.0, 0.0, 13.0, 21.0, 11.0, 90.0, 0.0, 140.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 120.0, 3.0, 0.0, 115.0, 3.0, 160.0, 0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 0.0, 79.0, 129.0, 43.0, 112.0, 57.0, 0.0, 85.0, 51.0, 0.0, 23.0, 0.0, 117.0, 0.0, 12.0, 48.0, 13.0, 120.0, 161.0, 0.0, 0.0, 0.0, 0.0, 0.0, 199.0, 0.0, 7.0, 4.0, 65.0, 75.0, 0.0, 0.0, 45.0, 0.0, 0.0, 0.0, 25.0, 10.0, 6.0, 0.0, 27.0, 0.0, 25.0, 17.0, 0.0, 0.0, 0.0, 38.0, 0.0, 98.0, 0.0, 0.0, 9.0, 0.0, 16.0, 0.0, 0.0, 12.0, 1.0, 27.0, 0.0, 30.0, 13.0, 13.0, 106.0, 0.0, 0.0, 0.0, 0.0, 38.0, 80.0, 92.0, 0.0, 1.0, 54.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 108.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 26.0, 0.0, 0.0, 0.0, 131.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 45.0, 13.0, 0.0, 0.0, 0.0, 93.0, 0.0, 0.0, 0.0, 7.0, 28.0, 0.0, 0.0, 2.0, 0.0, 26.0, 0.0, 183.0, 21.0, 15.0, 0.0, 141.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 146.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2801073151771063, "mean_inference_ms": 3.578149925837501, "mean_action_processing_ms": 0.5852270819280152, "mean_env_wait_ms": 0.8009319844173615, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.025909900665283203, "StateBufferConnector_ms": 0.00888049602508545, "ViewRequirementAgentConnector_ms": 0.3511699438095093}, "num_episodes": 22, "episode_return_max": 285.7000000000007, "episode_return_min": -216.7000000000003, "episode_return_mean": 66.43999999999977, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.8405155436593, "num_env_steps_trained_throughput_per_sec": 212.8405155436593, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 20320.201, "restore_workers_time_ms": 0.017, "training_step_time_ms": 20320.079, "sample_time_ms": 4299.983, "learn_time_ms": 15985.304, "learn_throughput": 250.23, "synch_weights_time_ms": 30.335}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "c52aa_00000", "date": "2024-08-13_00-06-20", "timestamp": 1723521980, "time_this_iter_s": 18.9269540309906, "time_total_s": 1105.9389781951904, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87ee50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1105.9389781951904, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 83.11851851851853, "ram_util_percent": 83.37407407407409}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0634879713887893, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.405318102130184, "policy_loss": -0.009657789548494356, "vf_loss": 4.414276394263777, "vf_explained_var": -0.018960846164239147, "kl": 0.017467528321451996, "entropy": 1.1884446225469074, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.723193151081996, "cur_kl_coeff": 0.004449462890624998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.707733138023861, "policy_loss": -0.0020954590702242162, "vf_loss": 2.709798778364898, "vf_explained_var": 0.003782362250423936, "kl": 0.006701093217649397, "entropy": 0.7945892251673199, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 323.49999999999955, "episode_reward_min": -216.7000000000003, "episode_reward_mean": 74.59199999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.29999999999984, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 14.815999999999933, "predator_policy": 22.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 145.29999999999876, -43.500000000000504, -50.29999999999981, 106.89999999999912, -3.3999999999998547, -99.10000000000022, -79.3000000000013, 40.0000000000003, 132.39999999999966, 215.49999999999923, -15.399999999999977, 29.300000000000168, -125.20000000000115, 47.30000000000016, 91.0, 215.3999999999995, 59.800000000000054, 76.3000000000001, -79.29999999999993, -103.20000000000005, 58.00000000000027, 69.70000000000003, -216.7000000000003, 142.49999999999898, -43.79999999999976, 42.700000000000344, 13.000000000000165, 195.69999999999905, 251.69999999999973, 227.79999999999964, 10.300000000000045, 126.09999999999937, 40.0000000000003, 85.50000000000003, -52.4999999999997, 149.7999999999993, 244.29999999999953, 58.400000000000404, 196.89999999999938, 281.9000000000003, 248.19999999999982, 180.8999999999991, 142.09999999999982, 104.79999999999856, 56.700000000000394, -25.299999999999635, 109.99999999999865, 0.30000000000006855, 228.0999999999992, 241.5999999999994, 40.0000000000003, 32.30000000000017, 128.1999999999988, -19.39999999999975, 24.60000000000008, 201.09999999999914, 68.60000000000028, 166.59999999999897, 82.49999999999991, 158.79999999999913, -104.10000000000039, 118.6999999999992, 219.99999999999903, 7.6000000000001275, 35.60000000000038, 40.0000000000003, -39.79999999999984, 204.69999999999916, 38.400000000000276, 40.0000000000003, 173.69999999999976, 11.399999999999972, -42.199999999999946, 181.89999999999944, -91.69999999999997, 48.100000000000286, 84.10000000000034, 47.20000000000029, 159.69999999999905, 285.7000000000007, -62.099999999999824, 65.50000000000036, -110.60000000000122, 23.900000000000176, 87.89999999999964, 120.9999999999992, 4.799999999999933, 40.0000000000003, 65.30000000000022, 172.29999999999933, 32.30000000000016, 323.49999999999955, 186.8999999999992, 40.0000000000003, 21.79999999999979, 168.69999999999905, 91.59999999999928, 80.39999999999937, 34.50000000000022], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 124.39999999999952, 20.90000000000003, -47.19999999999976, -28.29999999999975, -156.40000000000043, -13.900000000000015, 20.000000000000014, 83.89999999999964, 100.09999999999971, -221.50000000000026, -283.59999999999997, 24.500000000000096, -172.00000000000057, -7.299999999999891, 20.000000000000014, 20.000000000000014, 196.39999999999998, -142.0000000000002, 195.49999999999997, 20.000000000000014, -114.40000000000008, 20.000000000000014, 12.199999999999818, -154.90000000000006, -99.70000000000081, -194.50000000000037, -122.50000000000026, 84.80000000000018, 20.000000000000014, 19.999999999999968, 118.99999999999949, 73.39999999999996, 168.5, -225.70000000000044, 65.00000000000014, -48.69999999999984, -232.0000000000002, 19.70000000000021, -47.8, -216.40000000000038, 37.999999999999986, 20.000000000000014, 31.70000000000008, 38.00000000000021, -185.80000000000058, -229.9, 76.0999999999996, 55.40000000000014, -218.2000000000004, 34.39999999999999, 20.000000000000014, 22.70000000000006, -74.50000000000009, 42.500000000000085, 32.600000000000136, 163.0999999999998, 170.0, 46.70000000000007, 111.79999999999968, 109.99999999999989, -36.69999999999976, 20.000000000000014, 20.000000000000014, 64.09999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.499999999999993, 20.000000000000014, -170.50000000000048, 26.30000000000001, 123.49999999999986, 74.89999999999986, 160.39999999999992, 20.000000000000014, 22.39999999999999, -5.199999999999955, 190.1, 200.0, 53.899999999999636, 55.99999999999999, 162.1999999999998, 134.89999999999984, 20.000000000000014, -151.30000000000018, 187.40000000000003, 20.000000000000014, 84.7999999999993, -27.39999999999982, 46.10000000000024, -217.30000000000047, 20.000000000000014, 17.899999999999977, 91.09999999999945, -152.20000000000013, 24.500000000000085, 125.29999999999956, 102.7999999999997, 96.49999999999997, 145.09999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.29999999999999, 108.19999999999949, 20.000000000000014, 79.39999999999995, -206.8000000000004, 20.000000000000014, -9.399999999999912, 36.200000000000166, 164.89999999999978, -1.0000000000000204, 59.600000000000165, 21.800000000000026, 138.79999999999964, 20.000000000000014, 36.500000000000036, 36.2000000000002, 122.59999999999977, 20.000000000000014, -255.10000000000005, -51.399999999999864, 136.09999999999968, 47.90000000000024, 172.0999999999999, -74.50000000000051, 37.100000000000016, 20.000000000000014, 2.600000000000078, 20.000000000000014, 20.000000000000014, 42.50000000000009, -175.3000000000003, 184.6999999999999, 20.000000000000014, 50.600000000000236, -47.19999999999976, 20.000000000000014, 20.000000000000014, 83.89999999999996, 87.79999999999993, 15.799999999999965, -30.399999999999906, 118.09999999999991, -364.29999999999984, -11.499999999999819, 178.4, -252.70000000000007, 20.000000000000014, 28.10000000000008, 20.000000000000014, 64.10000000000022, 20.000000000000014, 27.200000000000003, 20.000000000000014, 78.49999999999962, 81.19999999999945, 100.9999999999997, 184.69999999999996, 78.49999999999952, -286.5999999999995, 57.800000000000225, -13.299999999999812, -28.29999999999975, -223.30000000000044, 20.000000000000014, -54.09999999999987, -110.20000000000053, 136.09999999999982, 100.9999999999997, 20.000000000000014, 20.000000000000014, -47.199999999999896, 20.000000000000014, 20.000000000000014, 66.49999999999997, -26.199999999999775, 119.30000000000001, 20.000000000000014, 5.299999999999988, 20.000000000000014, 146.0, 177.49999999999986, 113.59999999999994, 65.2999999999996, 20.000000000000014, 20.000000000000014, 56.900000000000226, -135.10000000000022, 148.69999999999976, 20.000000000000014, -50.19999999999998, 66.79999999999995, 65.90000000000008, 9.499999999999964, 9.499999999999964, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 32.0, 0.0, 120.0, 3.0, 0.0, 115.0, 3.0, 160.0, 0.0, 0.0, 100.0, 0.0, 0.0, 0.0, 78.0, 0.0, 0.0, 0.0, 79.0, 129.0, 43.0, 112.0, 57.0, 0.0, 85.0, 51.0, 0.0, 23.0, 0.0, 117.0, 0.0, 12.0, 48.0, 13.0, 120.0, 161.0, 0.0, 0.0, 0.0, 0.0, 0.0, 199.0, 0.0, 7.0, 4.0, 65.0, 75.0, 0.0, 0.0, 45.0, 0.0, 0.0, 0.0, 25.0, 10.0, 6.0, 0.0, 27.0, 0.0, 25.0, 17.0, 0.0, 0.0, 0.0, 38.0, 0.0, 98.0, 0.0, 0.0, 9.0, 0.0, 16.0, 0.0, 0.0, 12.0, 1.0, 27.0, 0.0, 30.0, 13.0, 13.0, 106.0, 0.0, 0.0, 0.0, 0.0, 38.0, 80.0, 92.0, 0.0, 1.0, 54.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 108.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 26.0, 0.0, 0.0, 0.0, 131.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 45.0, 13.0, 0.0, 0.0, 0.0, 93.0, 0.0, 0.0, 0.0, 7.0, 28.0, 0.0, 0.0, 2.0, 0.0, 26.0, 0.0, 183.0, 21.0, 15.0, 0.0, 141.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 146.0, 0.0, 21.0, 0.0, 118.0, 23.0, 0.0, 58.0, 0.0, 62.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 25.0, 21.0, 12.0, 7.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 69.0, 6.0, 5.0, 0.0, 0.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.285323916966254, "mean_inference_ms": 3.5986609946382035, "mean_action_processing_ms": 0.5858486408184301, "mean_env_wait_ms": 0.8027035498324055, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.025769352912902832, "StateBufferConnector_ms": 0.008409857749938965, "ViewRequirementAgentConnector_ms": 0.3245772123336792}, "num_episodes": 18, "episode_return_max": 323.49999999999955, "episode_return_min": -216.7000000000003, "episode_return_mean": 74.59199999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 253.56543367723046, "num_env_steps_trained_throughput_per_sec": 253.56543367723046, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 20297.813, "restore_workers_time_ms": 0.017, "training_step_time_ms": 20297.686, "sample_time_ms": 4238.682, "learn_time_ms": 16025.421, "learn_throughput": 249.603, "synch_weights_time_ms": 29.369}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "c52aa_00000", "date": "2024-08-13_00-06-36", "timestamp": 1723521996, "time_this_iter_s": 15.829247236251831, "time_total_s": 1121.7682254314423, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c6280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1121.7682254314423, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 76.0, "ram_util_percent": 83.48181818181818}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4266207408810418, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.095418380807947, "policy_loss": -0.0027758034716099107, "vf_loss": 4.097697200976983, "vf_explained_var": 0.008206130051739001, "kl": 0.012410845371938352, "entropy": 1.1759688705363602, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8595721286007021, "cur_kl_coeff": 0.004449462890624998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.5195514752751307, "policy_loss": -0.003101750011629765, "vf_loss": 2.522613486095711, "vf_explained_var": 0.01977035330716895, "kl": 0.008931080305548372, "entropy": 0.7790309263915612, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 323.49999999999955, "episode_reward_min": -216.7000000000003, "episode_reward_mean": 69.77699999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.29999999999984, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": 13.548499999999922, "predator_policy": 21.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-216.7000000000003, 142.49999999999898, -43.79999999999976, 42.700000000000344, 13.000000000000165, 195.69999999999905, 251.69999999999973, 227.79999999999964, 10.300000000000045, 126.09999999999937, 40.0000000000003, 85.50000000000003, -52.4999999999997, 149.7999999999993, 244.29999999999953, 58.400000000000404, 196.89999999999938, 281.9000000000003, 248.19999999999982, 180.8999999999991, 142.09999999999982, 104.79999999999856, 56.700000000000394, -25.299999999999635, 109.99999999999865, 0.30000000000006855, 228.0999999999992, 241.5999999999994, 40.0000000000003, 32.30000000000017, 128.1999999999988, -19.39999999999975, 24.60000000000008, 201.09999999999914, 68.60000000000028, 166.59999999999897, 82.49999999999991, 158.79999999999913, -104.10000000000039, 118.6999999999992, 219.99999999999903, 7.6000000000001275, 35.60000000000038, 40.0000000000003, -39.79999999999984, 204.69999999999916, 38.400000000000276, 40.0000000000003, 173.69999999999976, 11.399999999999972, -42.199999999999946, 181.89999999999944, -91.69999999999997, 48.100000000000286, 84.10000000000034, 47.20000000000029, 159.69999999999905, 285.7000000000007, -62.099999999999824, 65.50000000000036, -110.60000000000122, 23.900000000000176, 87.89999999999964, 120.9999999999992, 4.799999999999933, 40.0000000000003, 65.30000000000022, 172.29999999999933, 32.30000000000016, 323.49999999999955, 186.8999999999992, 40.0000000000003, 21.79999999999979, 168.69999999999905, 91.59999999999928, 80.39999999999937, 34.50000000000022, -155.9000000000004, 116.49999999999879, 32.30000000000019, 39.40000000000031, -53.09999999999985, 24.300000000000058, 112.89999999999861, 53.800000000000054, -16.89999999999987, 164.1999999999991, -36.99999999999986, -106.70000000000141, 38.00000000000028, 153.399999999999, 145.29999999999964, 2.49999999999991, -82.40000000000111, -132.20000000000118, 40.0000000000003, 6.100000000000033, -72.60000000000036, 12.10000000000012, -37.2999999999996], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-185.80000000000058, -229.9, 76.0999999999996, 55.40000000000014, -218.2000000000004, 34.39999999999999, 20.000000000000014, 22.70000000000006, -74.50000000000009, 42.500000000000085, 32.600000000000136, 163.0999999999998, 170.0, 46.70000000000007, 111.79999999999968, 109.99999999999989, -36.69999999999976, 20.000000000000014, 20.000000000000014, 64.09999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.499999999999993, 20.000000000000014, -170.50000000000048, 26.30000000000001, 123.49999999999986, 74.89999999999986, 160.39999999999992, 20.000000000000014, 22.39999999999999, -5.199999999999955, 190.1, 200.0, 53.899999999999636, 55.99999999999999, 162.1999999999998, 134.89999999999984, 20.000000000000014, -151.30000000000018, 187.40000000000003, 20.000000000000014, 84.7999999999993, -27.39999999999982, 46.10000000000024, -217.30000000000047, 20.000000000000014, 17.899999999999977, 91.09999999999945, -152.20000000000013, 24.500000000000085, 125.29999999999956, 102.7999999999997, 96.49999999999997, 145.09999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.29999999999999, 108.19999999999949, 20.000000000000014, 79.39999999999995, -206.8000000000004, 20.000000000000014, -9.399999999999912, 36.200000000000166, 164.89999999999978, -1.0000000000000204, 59.600000000000165, 21.800000000000026, 138.79999999999964, 20.000000000000014, 36.500000000000036, 36.2000000000002, 122.59999999999977, 20.000000000000014, -255.10000000000005, -51.399999999999864, 136.09999999999968, 47.90000000000024, 172.0999999999999, -74.50000000000051, 37.100000000000016, 20.000000000000014, 2.600000000000078, 20.000000000000014, 20.000000000000014, 42.50000000000009, -175.3000000000003, 184.6999999999999, 20.000000000000014, 50.600000000000236, -47.19999999999976, 20.000000000000014, 20.000000000000014, 83.89999999999996, 87.79999999999993, 15.799999999999965, -30.399999999999906, 118.09999999999991, -364.29999999999984, -11.499999999999819, 178.4, -252.70000000000007, 20.000000000000014, 28.10000000000008, 20.000000000000014, 64.10000000000022, 20.000000000000014, 27.200000000000003, 20.000000000000014, 78.49999999999962, 81.19999999999945, 100.9999999999997, 184.69999999999996, 78.49999999999952, -286.5999999999995, 57.800000000000225, -13.299999999999812, -28.29999999999975, -223.30000000000044, 20.000000000000014, -54.09999999999987, -110.20000000000053, 136.09999999999982, 100.9999999999997, 20.000000000000014, 20.000000000000014, -47.199999999999896, 20.000000000000014, 20.000000000000014, 66.49999999999997, -26.199999999999775, 119.30000000000001, 20.000000000000014, 5.299999999999988, 20.000000000000014, 146.0, 177.49999999999986, 113.59999999999994, 65.2999999999996, 20.000000000000014, 20.000000000000014, 56.900000000000226, -135.10000000000022, 148.69999999999976, 20.000000000000014, -50.19999999999998, 66.79999999999995, 65.90000000000008, 9.499999999999964, 9.499999999999964, 20.000000000000014, -190.00000000000014, -187.9000000000005, 20.000000000000014, 96.49999999999946, 20.000000000000014, 5.299999999999965, 16.39999999999994, 20.000000000000014, -124.90000000000056, -50.199999999999996, -15.699999999999761, 10.999999999999973, 92.89999999999935, 20.000000000000014, -5.1999999999999265, 46.999999999999986, 12.199999999999953, -186.10000000000002, 67.69999999999986, 96.49999999999963, -127.0000000000002, 20.000000000000014, -99.70000000000061, -106.0000000000008, -9.99999999999991, 20.000000000000014, 133.3999999999997, 20.000000000000014, 20.000000000000014, 125.30000000000001, -95.50000000000043, 20.000000000000014, -156.40000000000066, -51.99999999999983, -219.40000000000043, -29.799999999999812, 20.000000000000014, 20.000000000000014, -79.90000000000032, 38.00000000000023, -273.99999999999943, 61.400000000000176, -186.10000000000056, 99.19999999999968, -133.30000000000067, 20.000000000000014], "policy_predator_policy_reward": [199.0, 0.0, 7.0, 4.0, 65.0, 75.0, 0.0, 0.0, 45.0, 0.0, 0.0, 0.0, 25.0, 10.0, 6.0, 0.0, 27.0, 0.0, 25.0, 17.0, 0.0, 0.0, 0.0, 38.0, 0.0, 98.0, 0.0, 0.0, 9.0, 0.0, 16.0, 0.0, 0.0, 12.0, 1.0, 27.0, 0.0, 30.0, 13.0, 13.0, 106.0, 0.0, 0.0, 0.0, 0.0, 38.0, 80.0, 92.0, 0.0, 1.0, 54.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 108.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 26.0, 0.0, 0.0, 0.0, 131.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 45.0, 13.0, 0.0, 0.0, 0.0, 93.0, 0.0, 0.0, 0.0, 7.0, 28.0, 0.0, 0.0, 2.0, 0.0, 26.0, 0.0, 183.0, 21.0, 15.0, 0.0, 141.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 146.0, 0.0, 21.0, 0.0, 118.0, 23.0, 0.0, 58.0, 0.0, 62.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 25.0, 21.0, 12.0, 7.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 69.0, 6.0, 5.0, 0.0, 0.0, 5.0, 114.0, 108.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 122.0, 0.0, 17.0, 12.0, 0.0, 0.0, 0.0, 12.0, 83.0, 74.0, 0.0, 0.0, 70.0, 0.0, 16.0, 83.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 41.0, 42.0, 84.0, 0.0, 117.0, 0.0, 0.0, 48.0, 0.0, 140.0, 0.0, 99.0, 0.0, 76.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2896143430447362, "mean_inference_ms": 3.6191533794313244, "mean_action_processing_ms": 0.5865197122274416, "mean_env_wait_ms": 0.8047223658846699, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.015351176261901855, "StateBufferConnector_ms": 0.008588194847106934, "ViewRequirementAgentConnector_ms": 0.30533790588378906}, "num_episodes": 23, "episode_return_max": 323.49999999999955, "episode_return_min": -216.7000000000003, "episode_return_mean": 69.77699999999977, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 242.3174324429155, "num_env_steps_trained_throughput_per_sec": 242.3174324429155, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 19881.977, "restore_workers_time_ms": 0.017, "training_step_time_ms": 19881.851, "sample_time_ms": 4140.117, "learn_time_ms": 15711.835, "learn_throughput": 254.585, "synch_weights_time_ms": 25.347}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "c52aa_00000", "date": "2024-08-13_00-06-53", "timestamp": 1723522013, "time_this_iter_s": 16.564015865325928, "time_total_s": 1138.3322412967682, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c0ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1138.3322412967682, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 78.72916666666667, "ram_util_percent": 83.60000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.378465907002686, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3155497789382935, "policy_loss": -0.0024448630284202633, "vf_loss": 1.3174499267938906, "vf_explained_var": -0.011432282539902541, "kl": 0.013602537961335148, "entropy": 1.1026112592409527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7075301548475942, "cur_kl_coeff": 0.004449462890624998, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8500966646368542, "policy_loss": -0.003937201835486111, "vf_loss": 0.8539766810479619, "vf_explained_var": 0.02191361945772928, "kl": 0.012852564227515212, "entropy": 0.7956929122644757, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 323.49999999999955, "episode_reward_min": -155.9000000000004, "episode_reward_mean": 59.523999999999795, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.29999999999984, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 187.40000000000003, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": 10.396999999999935, "predator_policy": 19.365}, "custom_metrics": {}, "hist_stats": {"episode_reward": [248.19999999999982, 180.8999999999991, 142.09999999999982, 104.79999999999856, 56.700000000000394, -25.299999999999635, 109.99999999999865, 0.30000000000006855, 228.0999999999992, 241.5999999999994, 40.0000000000003, 32.30000000000017, 128.1999999999988, -19.39999999999975, 24.60000000000008, 201.09999999999914, 68.60000000000028, 166.59999999999897, 82.49999999999991, 158.79999999999913, -104.10000000000039, 118.6999999999992, 219.99999999999903, 7.6000000000001275, 35.60000000000038, 40.0000000000003, -39.79999999999984, 204.69999999999916, 38.400000000000276, 40.0000000000003, 173.69999999999976, 11.399999999999972, -42.199999999999946, 181.89999999999944, -91.69999999999997, 48.100000000000286, 84.10000000000034, 47.20000000000029, 159.69999999999905, 285.7000000000007, -62.099999999999824, 65.50000000000036, -110.60000000000122, 23.900000000000176, 87.89999999999964, 120.9999999999992, 4.799999999999933, 40.0000000000003, 65.30000000000022, 172.29999999999933, 32.30000000000016, 323.49999999999955, 186.8999999999992, 40.0000000000003, 21.79999999999979, 168.69999999999905, 91.59999999999928, 80.39999999999937, 34.50000000000022, -155.9000000000004, 116.49999999999879, 32.30000000000019, 39.40000000000031, -53.09999999999985, 24.300000000000058, 112.89999999999861, 53.800000000000054, -16.89999999999987, 164.1999999999991, -36.99999999999986, -106.70000000000141, 38.00000000000028, 153.399999999999, 145.29999999999964, 2.49999999999991, -82.40000000000111, -132.20000000000118, 40.0000000000003, 6.100000000000033, -72.60000000000036, 12.10000000000012, -37.2999999999996, 13.099999999999948, 36.70000000000025, -35.59999999999966, 56.200000000000514, 40.0000000000003, 28.900000000000144, 40.0000000000003, 36.70000000000024, 45.80000000000045, 43.60000000000035, 61.40000000000031, 40.0000000000003, 104.79999999999842, 22.400000000000073, 147.0999999999985, 40.0000000000003, 40.0000000000003, -32.79999999999956], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [55.99999999999999, 162.1999999999998, 134.89999999999984, 20.000000000000014, -151.30000000000018, 187.40000000000003, 20.000000000000014, 84.7999999999993, -27.39999999999982, 46.10000000000024, -217.30000000000047, 20.000000000000014, 17.899999999999977, 91.09999999999945, -152.20000000000013, 24.500000000000085, 125.29999999999956, 102.7999999999997, 96.49999999999997, 145.09999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.29999999999999, 108.19999999999949, 20.000000000000014, 79.39999999999995, -206.8000000000004, 20.000000000000014, -9.399999999999912, 36.200000000000166, 164.89999999999978, -1.0000000000000204, 59.600000000000165, 21.800000000000026, 138.79999999999964, 20.000000000000014, 36.500000000000036, 36.2000000000002, 122.59999999999977, 20.000000000000014, -255.10000000000005, -51.399999999999864, 136.09999999999968, 47.90000000000024, 172.0999999999999, -74.50000000000051, 37.100000000000016, 20.000000000000014, 2.600000000000078, 20.000000000000014, 20.000000000000014, 42.50000000000009, -175.3000000000003, 184.6999999999999, 20.000000000000014, 50.600000000000236, -47.19999999999976, 20.000000000000014, 20.000000000000014, 83.89999999999996, 87.79999999999993, 15.799999999999965, -30.399999999999906, 118.09999999999991, -364.29999999999984, -11.499999999999819, 178.4, -252.70000000000007, 20.000000000000014, 28.10000000000008, 20.000000000000014, 64.10000000000022, 20.000000000000014, 27.200000000000003, 20.000000000000014, 78.49999999999962, 81.19999999999945, 100.9999999999997, 184.69999999999996, 78.49999999999952, -286.5999999999995, 57.800000000000225, -13.299999999999812, -28.29999999999975, -223.30000000000044, 20.000000000000014, -54.09999999999987, -110.20000000000053, 136.09999999999982, 100.9999999999997, 20.000000000000014, 20.000000000000014, -47.199999999999896, 20.000000000000014, 20.000000000000014, 66.49999999999997, -26.199999999999775, 119.30000000000001, 20.000000000000014, 5.299999999999988, 20.000000000000014, 146.0, 177.49999999999986, 113.59999999999994, 65.2999999999996, 20.000000000000014, 20.000000000000014, 56.900000000000226, -135.10000000000022, 148.69999999999976, 20.000000000000014, -50.19999999999998, 66.79999999999995, 65.90000000000008, 9.499999999999964, 9.499999999999964, 20.000000000000014, -190.00000000000014, -187.9000000000005, 20.000000000000014, 96.49999999999946, 20.000000000000014, 5.299999999999965, 16.39999999999994, 20.000000000000014, -124.90000000000056, -50.199999999999996, -15.699999999999761, 10.999999999999973, 92.89999999999935, 20.000000000000014, -5.1999999999999265, 46.999999999999986, 12.199999999999953, -186.10000000000002, 67.69999999999986, 96.49999999999963, -127.0000000000002, 20.000000000000014, -99.70000000000061, -106.0000000000008, -9.99999999999991, 20.000000000000014, 133.3999999999997, 20.000000000000014, 20.000000000000014, 125.30000000000001, -95.50000000000043, 20.000000000000014, -156.40000000000066, -51.99999999999983, -219.40000000000043, -29.799999999999812, 20.000000000000014, 20.000000000000014, -79.90000000000032, 38.00000000000023, -273.99999999999943, 61.400000000000176, -186.10000000000056, 99.19999999999968, -133.30000000000067, 20.000000000000014, -46.8999999999998, 20.000000000000014, 13.699999999999966, 20.000000000000014, -42.99999999999982, -34.599999999999824, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 39.80000000000025, -64.0000000000008, 20.000000000000014, 23.600000000000065, 62.30000000000019, -19.899999999999928, 20.000000000000014, 20.000000000000014, 33.50000000000024, 71.29999999999967, -31.599999999999845, 20.000000000000014, 78.49999999999929, 68.59999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -119.80000000000067], "policy_predator_policy_reward": [0.0, 30.0, 13.0, 13.0, 106.0, 0.0, 0.0, 0.0, 0.0, 38.0, 80.0, 92.0, 0.0, 1.0, 54.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 108.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 10.0, 6.0, 0.0, 26.0, 0.0, 0.0, 0.0, 131.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 45.0, 13.0, 0.0, 0.0, 0.0, 93.0, 0.0, 0.0, 0.0, 7.0, 28.0, 0.0, 0.0, 2.0, 0.0, 26.0, 0.0, 183.0, 21.0, 15.0, 0.0, 141.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 146.0, 0.0, 21.0, 0.0, 118.0, 23.0, 0.0, 58.0, 0.0, 62.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 25.0, 21.0, 12.0, 7.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 69.0, 6.0, 5.0, 0.0, 0.0, 5.0, 114.0, 108.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 122.0, 0.0, 17.0, 12.0, 0.0, 0.0, 0.0, 12.0, 83.0, 74.0, 0.0, 0.0, 70.0, 0.0, 16.0, 83.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 41.0, 42.0, 84.0, 0.0, 117.0, 0.0, 0.0, 48.0, 0.0, 140.0, 0.0, 99.0, 0.0, 76.0, 0.0, 0.0, 40.0, 3.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 21.0, 0.0, 0.0, 0.0, 3.0, 39.0, 31.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 67.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2909016913363778, "mean_inference_ms": 3.628078608708453, "mean_action_processing_ms": 0.5862626271842309, "mean_env_wait_ms": 0.8047757988649991, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013538241386413574, "StateBufferConnector_ms": 0.009487509727478027, "ViewRequirementAgentConnector_ms": 0.2564373016357422}, "num_episodes": 18, "episode_return_max": 323.49999999999955, "episode_return_min": -155.9000000000004, "episode_return_mean": 59.523999999999795, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 220.16678419811012, "num_env_steps_trained_throughput_per_sec": 220.16678419811012, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 19620.608, "restore_workers_time_ms": 0.016, "training_step_time_ms": 19620.466, "sample_time_ms": 3810.053, "learn_time_ms": 15781.297, "learn_throughput": 253.465, "synch_weights_time_ms": 24.36}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "c52aa_00000", "date": "2024-08-13_00-07-11", "timestamp": 1723522031, "time_this_iter_s": 18.231621980667114, "time_total_s": 1156.5638632774353, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab84e550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1156.5638632774353, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 82.86153846153846, "ram_util_percent": 83.4346153846154}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8063155305783742, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9225397713916013, "policy_loss": -0.0029530472366050596, "vf_loss": 1.9251500399655135, "vf_explained_var": -0.019663416267072083, "kl": 0.008559715233513733, "entropy": 1.0111970694922896, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7361926603687818, "cur_kl_coeff": 0.004449462890624998, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4558018929743892, "policy_loss": -0.005968418879626644, "vf_loss": 1.4616474806316315, "vf_explained_var": 0.0362179247475175, "kl": 0.027605753946971935, "entropy": 0.7509263037058411, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 323.49999999999955, "episode_reward_min": -155.9000000000004, "episode_reward_mean": 47.17399999999989, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -364.29999999999984, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 184.69999999999996, "predator_policy": 183.0}, "policy_reward_mean": {"prey_policy": 5.866999999999966, "predator_policy": 17.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [82.49999999999991, 158.79999999999913, -104.10000000000039, 118.6999999999992, 219.99999999999903, 7.6000000000001275, 35.60000000000038, 40.0000000000003, -39.79999999999984, 204.69999999999916, 38.400000000000276, 40.0000000000003, 173.69999999999976, 11.399999999999972, -42.199999999999946, 181.89999999999944, -91.69999999999997, 48.100000000000286, 84.10000000000034, 47.20000000000029, 159.69999999999905, 285.7000000000007, -62.099999999999824, 65.50000000000036, -110.60000000000122, 23.900000000000176, 87.89999999999964, 120.9999999999992, 4.799999999999933, 40.0000000000003, 65.30000000000022, 172.29999999999933, 32.30000000000016, 323.49999999999955, 186.8999999999992, 40.0000000000003, 21.79999999999979, 168.69999999999905, 91.59999999999928, 80.39999999999937, 34.50000000000022, -155.9000000000004, 116.49999999999879, 32.30000000000019, 39.40000000000031, -53.09999999999985, 24.300000000000058, 112.89999999999861, 53.800000000000054, -16.89999999999987, 164.1999999999991, -36.99999999999986, -106.70000000000141, 38.00000000000028, 153.399999999999, 145.29999999999964, 2.49999999999991, -82.40000000000111, -132.20000000000118, 40.0000000000003, 6.100000000000033, -72.60000000000036, 12.10000000000012, -37.2999999999996, 13.099999999999948, 36.70000000000025, -35.59999999999966, 56.200000000000514, 40.0000000000003, 28.900000000000144, 40.0000000000003, 36.70000000000024, 45.80000000000045, 43.60000000000035, 61.40000000000031, 40.0000000000003, 104.79999999999842, 22.400000000000073, 147.0999999999985, 40.0000000000003, 40.0000000000003, -32.79999999999956, 40.0000000000003, 30.10000000000016, 35.600000000000236, 45.90000000000047, 48.00000000000048, 16.899999999999938, 26.400000000000087, 64.30000000000045, 82.29999999999914, 29.000000000000128, 11.200000000000049, -5.199999999999802, 45.40000000000039, 28.70000000000045, 87.69999999999878, 33.00000000000021, 24.600000000000065, 50.50000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 36.500000000000036, 36.2000000000002, 122.59999999999977, 20.000000000000014, -255.10000000000005, -51.399999999999864, 136.09999999999968, 47.90000000000024, 172.0999999999999, -74.50000000000051, 37.100000000000016, 20.000000000000014, 2.600000000000078, 20.000000000000014, 20.000000000000014, 42.50000000000009, -175.3000000000003, 184.6999999999999, 20.000000000000014, 50.600000000000236, -47.19999999999976, 20.000000000000014, 20.000000000000014, 83.89999999999996, 87.79999999999993, 15.799999999999965, -30.399999999999906, 118.09999999999991, -364.29999999999984, -11.499999999999819, 178.4, -252.70000000000007, 20.000000000000014, 28.10000000000008, 20.000000000000014, 64.10000000000022, 20.000000000000014, 27.200000000000003, 20.000000000000014, 78.49999999999962, 81.19999999999945, 100.9999999999997, 184.69999999999996, 78.49999999999952, -286.5999999999995, 57.800000000000225, -13.299999999999812, -28.29999999999975, -223.30000000000044, 20.000000000000014, -54.09999999999987, -110.20000000000053, 136.09999999999982, 100.9999999999997, 20.000000000000014, 20.000000000000014, -47.199999999999896, 20.000000000000014, 20.000000000000014, 66.49999999999997, -26.199999999999775, 119.30000000000001, 20.000000000000014, 5.299999999999988, 20.000000000000014, 146.0, 177.49999999999986, 113.59999999999994, 65.2999999999996, 20.000000000000014, 20.000000000000014, 56.900000000000226, -135.10000000000022, 148.69999999999976, 20.000000000000014, -50.19999999999998, 66.79999999999995, 65.90000000000008, 9.499999999999964, 9.499999999999964, 20.000000000000014, -190.00000000000014, -187.9000000000005, 20.000000000000014, 96.49999999999946, 20.000000000000014, 5.299999999999965, 16.39999999999994, 20.000000000000014, -124.90000000000056, -50.199999999999996, -15.699999999999761, 10.999999999999973, 92.89999999999935, 20.000000000000014, -5.1999999999999265, 46.999999999999986, 12.199999999999953, -186.10000000000002, 67.69999999999986, 96.49999999999963, -127.0000000000002, 20.000000000000014, -99.70000000000061, -106.0000000000008, -9.99999999999991, 20.000000000000014, 133.3999999999997, 20.000000000000014, 20.000000000000014, 125.30000000000001, -95.50000000000043, 20.000000000000014, -156.40000000000066, -51.99999999999983, -219.40000000000043, -29.799999999999812, 20.000000000000014, 20.000000000000014, -79.90000000000032, 38.00000000000023, -273.99999999999943, 61.400000000000176, -186.10000000000056, 99.19999999999968, -133.30000000000067, 20.000000000000014, -46.8999999999998, 20.000000000000014, 13.699999999999966, 20.000000000000014, -42.99999999999982, -34.599999999999824, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 39.80000000000025, -64.0000000000008, 20.000000000000014, 23.600000000000065, 62.30000000000019, -19.899999999999928, 20.000000000000014, 20.000000000000014, 33.50000000000024, 71.29999999999967, -31.599999999999845, 20.000000000000014, 78.49999999999929, 68.59999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -119.80000000000067, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999581, 11.599999999999964, 20.000000000000014, 20.000000000000014, 5.9, 20.000000000000014, 13.999999999999961, 20.000000000000014, -24.099999999999774, 20.000000000000014, -7.599999999999897, 20.000000000000014, 44.300000000000225, 62.300000000000196, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -35.799999999999756, 20.000000000000014, 18.799999999999997, -64.00000000000048, 20.000000000000014, 25.4000000000001, -80.80000000000003, 33.50000000000024, 37.10000000000026, 50.600000000000186, -30.09999999999976, 37.10000000000026, 20.000000000000014, -9.399999999999883, -36.69999999999976, 45.200000000000244], "policy_predator_policy_reward": [26.0, 0.0, 0.0, 0.0, 131.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 45.0, 13.0, 0.0, 0.0, 0.0, 93.0, 0.0, 0.0, 0.0, 7.0, 28.0, 0.0, 0.0, 2.0, 0.0, 26.0, 0.0, 183.0, 21.0, 15.0, 0.0, 141.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 146.0, 0.0, 21.0, 0.0, 118.0, 23.0, 0.0, 58.0, 0.0, 62.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 25.0, 21.0, 12.0, 7.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 69.0, 6.0, 5.0, 0.0, 0.0, 5.0, 114.0, 108.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 122.0, 0.0, 17.0, 12.0, 0.0, 0.0, 0.0, 12.0, 83.0, 74.0, 0.0, 0.0, 70.0, 0.0, 16.0, 83.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 41.0, 42.0, 84.0, 0.0, 117.0, 0.0, 0.0, 48.0, 0.0, 140.0, 0.0, 99.0, 0.0, 76.0, 0.0, 0.0, 40.0, 3.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 21.0, 0.0, 0.0, 0.0, 3.0, 39.0, 31.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 67.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 4.0, 0.0, 20.0, 14.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 27.0, 0.0, 40.0, 0.0, 0.0, 46.0, 30.0, 0.0, 0.0, 26.0, 0.0, 14.0, 0.0, 15.0, 27.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.291374215754004, "mean_inference_ms": 3.63376751614123, "mean_action_processing_ms": 0.58571549835377, "mean_env_wait_ms": 0.8048245697129349, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014124393463134766, "StateBufferConnector_ms": 0.00939178466796875, "ViewRequirementAgentConnector_ms": 0.22721433639526367}, "num_episodes": 18, "episode_return_max": 323.49999999999955, "episode_return_min": -155.9000000000004, "episode_return_mean": 47.17399999999989, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 234.71155193219667, "num_env_steps_trained_throughput_per_sec": 234.71155193219667, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 19471.534, "restore_workers_time_ms": 0.015, "training_step_time_ms": 19471.395, "sample_time_ms": 3915.377, "learn_time_ms": 15528.536, "learn_throughput": 257.59, "synch_weights_time_ms": 23.322}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "c52aa_00000", "date": "2024-08-13_00-07-28", "timestamp": 1723522048, "time_this_iter_s": 17.095359086990356, "time_total_s": 1173.6592223644257, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c0e50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1173.6592223644257, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 78.06666666666666, "ram_util_percent": 83.6125}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4726427933329311, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6557593014820542, "policy_loss": -0.0005874090045739813, "vf_loss": 1.6560969915339556, "vf_explained_var": -0.051853988788746024, "kl": 0.006235973451740042, "entropy": 0.9401358094795671, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.965176318526741, "cur_kl_coeff": 0.006674194335937498, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3003832338348267, "policy_loss": -0.0037911721087607836, "vf_loss": 1.3040437646328458, "vf_explained_var": 0.1009074553926155, "kl": 0.019574101538625675, "entropy": 0.6490160523583649, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 323.49999999999955, "episode_reward_min": -155.9000000000004, "episode_reward_mean": 37.223999999999954, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -286.5999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 177.49999999999986, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": 2.4469999999999716, "predator_policy": 16.165}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-62.099999999999824, 65.50000000000036, -110.60000000000122, 23.900000000000176, 87.89999999999964, 120.9999999999992, 4.799999999999933, 40.0000000000003, 65.30000000000022, 172.29999999999933, 32.30000000000016, 323.49999999999955, 186.8999999999992, 40.0000000000003, 21.79999999999979, 168.69999999999905, 91.59999999999928, 80.39999999999937, 34.50000000000022, -155.9000000000004, 116.49999999999879, 32.30000000000019, 39.40000000000031, -53.09999999999985, 24.300000000000058, 112.89999999999861, 53.800000000000054, -16.89999999999987, 164.1999999999991, -36.99999999999986, -106.70000000000141, 38.00000000000028, 153.399999999999, 145.29999999999964, 2.49999999999991, -82.40000000000111, -132.20000000000118, 40.0000000000003, 6.100000000000033, -72.60000000000036, 12.10000000000012, -37.2999999999996, 13.099999999999948, 36.70000000000025, -35.59999999999966, 56.200000000000514, 40.0000000000003, 28.900000000000144, 40.0000000000003, 36.70000000000024, 45.80000000000045, 43.60000000000035, 61.40000000000031, 40.0000000000003, 104.79999999999842, 22.400000000000073, 147.0999999999985, 40.0000000000003, 40.0000000000003, -32.79999999999956, 40.0000000000003, 30.10000000000016, 35.600000000000236, 45.90000000000047, 48.00000000000048, 16.899999999999938, 26.400000000000087, 64.30000000000045, 82.29999999999914, 29.000000000000128, 11.200000000000049, -5.199999999999802, 45.40000000000039, 28.70000000000045, 87.69999999999878, 33.00000000000021, 24.600000000000065, 50.50000000000048, -17.099999999999596, -8.399999999999709, 9.899999999999915, 61.600000000000506, 20.800000000000114, 17.89999999999995, 40.0000000000003, 40.0000000000003, 62.50000000000051, 2.600000000000147, 33.400000000000205, 40.00000000000029, 19.799999999999955, 27.900000000000166, 47.30000000000042, 19.09999999999997, 84.09999999999904, 40.0000000000003, 40.00000000000036, 29.000000000000128, 6.80000000000004, 48.10000000000043], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [78.49999999999952, -286.5999999999995, 57.800000000000225, -13.299999999999812, -28.29999999999975, -223.30000000000044, 20.000000000000014, -54.09999999999987, -110.20000000000053, 136.09999999999982, 100.9999999999997, 20.000000000000014, 20.000000000000014, -47.199999999999896, 20.000000000000014, 20.000000000000014, 66.49999999999997, -26.199999999999775, 119.30000000000001, 20.000000000000014, 5.299999999999988, 20.000000000000014, 146.0, 177.49999999999986, 113.59999999999994, 65.2999999999996, 20.000000000000014, 20.000000000000014, 56.900000000000226, -135.10000000000022, 148.69999999999976, 20.000000000000014, -50.19999999999998, 66.79999999999995, 65.90000000000008, 9.499999999999964, 9.499999999999964, 20.000000000000014, -190.00000000000014, -187.9000000000005, 20.000000000000014, 96.49999999999946, 20.000000000000014, 5.299999999999965, 16.39999999999994, 20.000000000000014, -124.90000000000056, -50.199999999999996, -15.699999999999761, 10.999999999999973, 92.89999999999935, 20.000000000000014, -5.1999999999999265, 46.999999999999986, 12.199999999999953, -186.10000000000002, 67.69999999999986, 96.49999999999963, -127.0000000000002, 20.000000000000014, -99.70000000000061, -106.0000000000008, -9.99999999999991, 20.000000000000014, 133.3999999999997, 20.000000000000014, 20.000000000000014, 125.30000000000001, -95.50000000000043, 20.000000000000014, -156.40000000000066, -51.99999999999983, -219.40000000000043, -29.799999999999812, 20.000000000000014, 20.000000000000014, -79.90000000000032, 38.00000000000023, -273.99999999999943, 61.400000000000176, -186.10000000000056, 99.19999999999968, -133.30000000000067, 20.000000000000014, -46.8999999999998, 20.000000000000014, 13.699999999999966, 20.000000000000014, -42.99999999999982, -34.599999999999824, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 39.80000000000025, -64.0000000000008, 20.000000000000014, 23.600000000000065, 62.30000000000019, -19.899999999999928, 20.000000000000014, 20.000000000000014, 33.50000000000024, 71.29999999999967, -31.599999999999845, 20.000000000000014, 78.49999999999929, 68.59999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -119.80000000000067, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999581, 11.599999999999964, 20.000000000000014, 20.000000000000014, 5.9, 20.000000000000014, 13.999999999999961, 20.000000000000014, -24.099999999999774, 20.000000000000014, -7.599999999999897, 20.000000000000014, 44.300000000000225, 62.300000000000196, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -35.799999999999756, 20.000000000000014, 18.799999999999997, -64.00000000000048, 20.000000000000014, 25.4000000000001, -80.80000000000003, 33.50000000000024, 37.10000000000026, 50.600000000000186, -30.09999999999976, 37.10000000000026, 20.000000000000014, -9.399999999999883, -36.69999999999976, 45.200000000000244, 13.699999999999953, -80.80000000000075, -72.40000000000089, 20.000000000000014, -66.09999999999978, 20.000000000000014, 20.000000000000014, 41.60000000000025, -8.500000000000023, 5.299999999999969, -13.599999999999797, -2.5000000000000075, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 38.00000000000025, 20.000000000000014, -51.399999999999764, 7.399999999999967, 20.000000000000014, 8.29999999999997, 22.700000000000053, -86.20000000000005, 20.000000000000014, 9.499999999999947, 7.399999999999965, -7.299999999999905, 41.60000000000025, -28.89999999999978, 20.000000000000014, 42.50000000000021, 41.60000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 10.999999999999948, -0.9999999999999846, 20.000000000000014, -64.00000000000082, 30.800000000000196, 20.000000000000014, 28.100000000000147], "policy_predator_policy_reward": [146.0, 0.0, 21.0, 0.0, 118.0, 23.0, 0.0, 58.0, 0.0, 62.0, 0.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 25.0, 21.0, 12.0, 7.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 100.0, 0.0, 0.0, 69.0, 6.0, 5.0, 0.0, 0.0, 5.0, 114.0, 108.0, 0.0, 0.0, 0.0, 7.0, 0.0, 3.0, 122.0, 0.0, 17.0, 12.0, 0.0, 0.0, 0.0, 12.0, 83.0, 74.0, 0.0, 0.0, 70.0, 0.0, 16.0, 83.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 41.0, 42.0, 84.0, 0.0, 117.0, 0.0, 0.0, 48.0, 0.0, 140.0, 0.0, 99.0, 0.0, 76.0, 0.0, 0.0, 40.0, 3.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 21.0, 0.0, 0.0, 0.0, 3.0, 39.0, 31.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 67.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 4.0, 0.0, 20.0, 14.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 27.0, 0.0, 40.0, 0.0, 0.0, 46.0, 30.0, 0.0, 0.0, 26.0, 0.0, 14.0, 0.0, 15.0, 27.0, 50.0, 0.0, 0.0, 44.0, 37.0, 19.0, 0.0, 0.0, 7.0, 17.0, 18.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 31.0, 6.0, 0.0, 9.0, 0.0, 39.0, 47.0, 5.0, 6.0, 13.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 9.0, 31.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2901019326346395, "mean_inference_ms": 3.6354594924304853, "mean_action_processing_ms": 0.5843061792718021, "mean_env_wait_ms": 0.8039261165006272, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014631271362304688, "StateBufferConnector_ms": 0.006139039993286133, "ViewRequirementAgentConnector_ms": 0.1796417236328125}, "num_episodes": 22, "episode_return_max": 323.49999999999955, "episode_return_min": -155.9000000000004, "episode_return_mean": 37.223999999999954, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 223.4883215168141, "num_env_steps_trained_throughput_per_sec": 223.4883215168141, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 19217.245, "restore_workers_time_ms": 0.015, "training_step_time_ms": 19217.103, "sample_time_ms": 3819.255, "learn_time_ms": 15370.174, "learn_throughput": 260.244, "synch_weights_time_ms": 22.682}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "c52aa_00000", "date": "2024-08-13_00-07-46", "timestamp": 1723522066, "time_this_iter_s": 17.95919680595398, "time_total_s": 1191.6184191703796, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab868b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1191.6184191703796, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 79.59615384615384, "ram_util_percent": 83.56153846153846}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8152096051742475, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.2158921948501042, "policy_loss": -0.0018500859159286376, "vf_loss": 2.2174132179961634, "vf_explained_var": -0.037594502596628096, "kl": 0.008217182607930322, "entropy": 0.8213832987994744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9198939104125928, "cur_kl_coeff": 0.006674194335937498, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4689576590818072, "policy_loss": -0.003889185774864422, "vf_loss": 1.4727380577533964, "vf_explained_var": 0.07078435052008857, "kl": 0.016299958013486514, "entropy": 0.6318731342989301, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 164.1999999999991, "episode_reward_min": -132.20000000000118, "episode_reward_mean": 30.287000000000052, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -273.99999999999943, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 133.3999999999997, "predator_policy": 140.0}, "policy_reward_mean": {"prey_policy": 1.7135000000000016, "predator_policy": 13.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-53.09999999999985, 24.300000000000058, 112.89999999999861, 53.800000000000054, -16.89999999999987, 164.1999999999991, -36.99999999999986, -106.70000000000141, 38.00000000000028, 153.399999999999, 145.29999999999964, 2.49999999999991, -82.40000000000111, -132.20000000000118, 40.0000000000003, 6.100000000000033, -72.60000000000036, 12.10000000000012, -37.2999999999996, 13.099999999999948, 36.70000000000025, -35.59999999999966, 56.200000000000514, 40.0000000000003, 28.900000000000144, 40.0000000000003, 36.70000000000024, 45.80000000000045, 43.60000000000035, 61.40000000000031, 40.0000000000003, 104.79999999999842, 22.400000000000073, 147.0999999999985, 40.0000000000003, 40.0000000000003, -32.79999999999956, 40.0000000000003, 30.10000000000016, 35.600000000000236, 45.90000000000047, 48.00000000000048, 16.899999999999938, 26.400000000000087, 64.30000000000045, 82.29999999999914, 29.000000000000128, 11.200000000000049, -5.199999999999802, 45.40000000000039, 28.70000000000045, 87.69999999999878, 33.00000000000021, 24.600000000000065, 50.50000000000048, -17.099999999999596, -8.399999999999709, 9.899999999999915, 61.600000000000506, 20.800000000000114, 17.89999999999995, 40.0000000000003, 40.0000000000003, 62.50000000000051, 2.600000000000147, 33.400000000000205, 40.00000000000029, 19.799999999999955, 27.900000000000166, 47.30000000000042, 19.09999999999997, 84.09999999999904, 40.0000000000003, 40.00000000000036, 29.000000000000128, 6.80000000000004, 48.10000000000043, 33.500000000000206, 84.09999999999907, 37.60000000000026, 17.899999999999956, 31.100000000000183, 38.90000000000028, 30.000000000000146, 0.2999999999999643, 22.400000000000013, 68.80000000000018, 50.80000000000048, 53.500000000000526, -1.7999999999999012, 4.000000000000086, 25.100000000000062, 49.90000000000046, -10.799999999999669, 63.40000000000047, 60.700000000000486, 37.80000000000049, 8.100000000000088, 40.0000000000003, -18.999999999999865], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-124.90000000000056, -50.199999999999996, -15.699999999999761, 10.999999999999973, 92.89999999999935, 20.000000000000014, -5.1999999999999265, 46.999999999999986, 12.199999999999953, -186.10000000000002, 67.69999999999986, 96.49999999999963, -127.0000000000002, 20.000000000000014, -99.70000000000061, -106.0000000000008, -9.99999999999991, 20.000000000000014, 133.3999999999997, 20.000000000000014, 20.000000000000014, 125.30000000000001, -95.50000000000043, 20.000000000000014, -156.40000000000066, -51.99999999999983, -219.40000000000043, -29.799999999999812, 20.000000000000014, 20.000000000000014, -79.90000000000032, 38.00000000000023, -273.99999999999943, 61.400000000000176, -186.10000000000056, 99.19999999999968, -133.30000000000067, 20.000000000000014, -46.8999999999998, 20.000000000000014, 13.699999999999966, 20.000000000000014, -42.99999999999982, -34.599999999999824, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 39.80000000000025, -64.0000000000008, 20.000000000000014, 23.600000000000065, 62.30000000000019, -19.899999999999928, 20.000000000000014, 20.000000000000014, 33.50000000000024, 71.29999999999967, -31.599999999999845, 20.000000000000014, 78.49999999999929, 68.59999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -119.80000000000067, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999581, 11.599999999999964, 20.000000000000014, 20.000000000000014, 5.9, 20.000000000000014, 13.999999999999961, 20.000000000000014, -24.099999999999774, 20.000000000000014, -7.599999999999897, 20.000000000000014, 44.300000000000225, 62.300000000000196, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -35.799999999999756, 20.000000000000014, 18.799999999999997, -64.00000000000048, 20.000000000000014, 25.4000000000001, -80.80000000000003, 33.50000000000024, 37.10000000000026, 50.600000000000186, -30.09999999999976, 37.10000000000026, 20.000000000000014, -9.399999999999883, -36.69999999999976, 45.200000000000244, 13.699999999999953, -80.80000000000075, -72.40000000000089, 20.000000000000014, -66.09999999999978, 20.000000000000014, 20.000000000000014, 41.60000000000025, -8.500000000000023, 5.299999999999969, -13.599999999999797, -2.5000000000000075, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 38.00000000000025, 20.000000000000014, -51.399999999999764, 7.399999999999967, 20.000000000000014, 8.29999999999997, 22.700000000000053, -86.20000000000005, 20.000000000000014, 9.499999999999947, 7.399999999999965, -7.299999999999905, 41.60000000000025, -28.89999999999978, 20.000000000000014, 42.50000000000021, 41.60000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 10.999999999999948, -0.9999999999999846, 20.000000000000014, -64.00000000000082, 30.800000000000196, 20.000000000000014, 28.100000000000147, 3.4999999999999654, 20.000000000000014, 39.80000000000025, 44.300000000000246, 5.599999999999971, 20.000000000000014, -6.699999999999992, -9.39999999999989, 20.000000000000014, -10.899999999999913, 20.000000000000014, 17.899999999999988, 20.000000000000014, -0.9999999999999846, -5.200000000000038, -32.49999999999982, 1.0999999999999865, 5.2999999999999705, 35.30000000000026, 33.50000000000024, 20.000000000000014, 30.800000000000196, 33.50000000000024, 20.000000000000014, -59.799999999999805, 20.000000000000014, -35.19999999999978, -2.800000000000048, -32.49999999999975, 32.60000000000023, 29.90000000000018, 20.000000000000014, -28.299999999999862, -26.49999999999975, 20.000000000000014, 43.400000000000226, 20.000000000000014, 40.70000000000024, -2.2000000000000286, 20.000000000000014, 20.000000000000014, -40.89999999999976, 20.000000000000014, 20.000000000000014, -100.00000000000026, 20.000000000000014], "policy_predator_policy_reward": [122.0, 0.0, 17.0, 12.0, 0.0, 0.0, 0.0, 12.0, 83.0, 74.0, 0.0, 0.0, 70.0, 0.0, 16.0, 83.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 37.0, 41.0, 42.0, 84.0, 0.0, 117.0, 0.0, 0.0, 48.0, 0.0, 140.0, 0.0, 99.0, 0.0, 76.0, 0.0, 0.0, 40.0, 3.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 21.0, 0.0, 0.0, 0.0, 3.0, 39.0, 31.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 67.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 4.0, 0.0, 20.0, 14.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 27.0, 0.0, 40.0, 0.0, 0.0, 46.0, 30.0, 0.0, 0.0, 26.0, 0.0, 14.0, 0.0, 15.0, 27.0, 50.0, 0.0, 0.0, 44.0, 37.0, 19.0, 0.0, 0.0, 7.0, 17.0, 18.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 31.0, 6.0, 0.0, 9.0, 0.0, 39.0, 47.0, 5.0, 6.0, 13.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 9.0, 31.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 12.0, 0.0, 14.0, 20.0, 0.0, 22.0, 1.0, 0.0, 10.0, 1.0, 38.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 34.0, 4.0, 38.0, 25.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 26.0, 3.0, 0.0, 0.0, 61.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2847837143836545, "mean_inference_ms": 3.623924477360459, "mean_action_processing_ms": 0.5823880079229424, "mean_env_wait_ms": 0.8013049274119652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.017821431159973145, "StateBufferConnector_ms": 0.007225751876831055, "ViewRequirementAgentConnector_ms": 0.19809961318969727}, "num_episodes": 23, "episode_return_max": 164.1999999999991, "episode_return_min": -132.20000000000118, "episode_return_mean": 30.287000000000052, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 193.6189209308799, "num_env_steps_trained_throughput_per_sec": 193.6189209308799, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 19178.07, "restore_workers_time_ms": 0.015, "training_step_time_ms": 19177.802, "sample_time_ms": 3662.3, "learn_time_ms": 15487.262, "learn_throughput": 258.277, "synch_weights_time_ms": 23.415}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "c52aa_00000", "date": "2024-08-13_00-08-07", "timestamp": 1723522087, "time_this_iter_s": 20.770368099212646, "time_total_s": 1212.3887872695923, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab868f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1212.3887872695923, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 85.33103448275864, "ram_util_percent": 83.46896551724137}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6592996261264912, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1278479151782534, "policy_loss": -0.002784736244569695, "vf_loss": 1.1303012580152543, "vf_explained_var": -0.01677223387218657, "kl": 0.008275478411501693, "entropy": 0.8362804392027476, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6559012227134887, "cur_kl_coeff": 0.006674194335937498, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6825046941716835, "policy_loss": -0.003432661849295809, "vf_loss": 0.685872391733543, "vf_explained_var": 0.10092975547704747, "kl": 0.009733394870501953, "entropy": 0.5952033867596318, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 147.0999999999985, "episode_reward_min": -37.2999999999996, "episode_reward_mean": 33.24000000000016, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -133.30000000000067, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 78.49999999999929, "predator_policy": 76.0}, "policy_reward_mean": {"prey_policy": 7.62500000000004, "predator_policy": 8.995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-37.2999999999996, 13.099999999999948, 36.70000000000025, -35.59999999999966, 56.200000000000514, 40.0000000000003, 28.900000000000144, 40.0000000000003, 36.70000000000024, 45.80000000000045, 43.60000000000035, 61.40000000000031, 40.0000000000003, 104.79999999999842, 22.400000000000073, 147.0999999999985, 40.0000000000003, 40.0000000000003, -32.79999999999956, 40.0000000000003, 30.10000000000016, 35.600000000000236, 45.90000000000047, 48.00000000000048, 16.899999999999938, 26.400000000000087, 64.30000000000045, 82.29999999999914, 29.000000000000128, 11.200000000000049, -5.199999999999802, 45.40000000000039, 28.70000000000045, 87.69999999999878, 33.00000000000021, 24.600000000000065, 50.50000000000048, -17.099999999999596, -8.399999999999709, 9.899999999999915, 61.600000000000506, 20.800000000000114, 17.89999999999995, 40.0000000000003, 40.0000000000003, 62.50000000000051, 2.600000000000147, 33.400000000000205, 40.00000000000029, 19.799999999999955, 27.900000000000166, 47.30000000000042, 19.09999999999997, 84.09999999999904, 40.0000000000003, 40.00000000000036, 29.000000000000128, 6.80000000000004, 48.10000000000043, 33.500000000000206, 84.09999999999907, 37.60000000000026, 17.899999999999956, 31.100000000000183, 38.90000000000028, 30.000000000000146, 0.2999999999999643, 22.400000000000013, 68.80000000000018, 50.80000000000048, 53.500000000000526, -1.7999999999999012, 4.000000000000086, 25.100000000000062, 49.90000000000046, -10.799999999999669, 63.40000000000047, 60.700000000000486, 37.80000000000049, 8.100000000000088, 40.0000000000003, -18.999999999999865, 27.70000000000012, 16.89999999999995, 9.300000000000084, 54.40000000000054, 12.800000000000015, 33.3000000000002, 7.000000000000121, 23.500000000000117, 21.1, 10.300000000000024, 54.4000000000005, 30.10000000000015, 59.80000000000054, 47.200000000000415, 37.800000000000296, 40.1000000000003, 40.0000000000003, 21.30000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-133.30000000000067, 20.000000000000014, -46.8999999999998, 20.000000000000014, 13.699999999999966, 20.000000000000014, -42.99999999999982, -34.599999999999824, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, 13.69999999999997, 39.80000000000025, -64.0000000000008, 20.000000000000014, 23.600000000000065, 62.30000000000019, -19.899999999999928, 20.000000000000014, 20.000000000000014, 33.50000000000024, 71.29999999999967, -31.599999999999845, 20.000000000000014, 78.49999999999929, 68.59999999999987, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -119.80000000000067, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999581, 11.599999999999964, 20.000000000000014, 20.000000000000014, 5.9, 20.000000000000014, 13.999999999999961, 20.000000000000014, -24.099999999999774, 20.000000000000014, -7.599999999999897, 20.000000000000014, 44.300000000000225, 62.300000000000196, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -35.799999999999756, 20.000000000000014, 18.799999999999997, -64.00000000000048, 20.000000000000014, 25.4000000000001, -80.80000000000003, 33.50000000000024, 37.10000000000026, 50.600000000000186, -30.09999999999976, 37.10000000000026, 20.000000000000014, -9.399999999999883, -36.69999999999976, 45.200000000000244, 13.699999999999953, -80.80000000000075, -72.40000000000089, 20.000000000000014, -66.09999999999978, 20.000000000000014, 20.000000000000014, 41.60000000000025, -8.500000000000023, 5.299999999999969, -13.599999999999797, -2.5000000000000075, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 38.00000000000025, 20.000000000000014, -51.399999999999764, 7.399999999999967, 20.000000000000014, 8.29999999999997, 22.700000000000053, -86.20000000000005, 20.000000000000014, 9.499999999999947, 7.399999999999965, -7.299999999999905, 41.60000000000025, -28.89999999999978, 20.000000000000014, 42.50000000000021, 41.60000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 10.999999999999948, -0.9999999999999846, 20.000000000000014, -64.00000000000082, 30.800000000000196, 20.000000000000014, 28.100000000000147, 3.4999999999999654, 20.000000000000014, 39.80000000000025, 44.300000000000246, 5.599999999999971, 20.000000000000014, -6.699999999999992, -9.39999999999989, 20.000000000000014, -10.899999999999913, 20.000000000000014, 17.899999999999988, 20.000000000000014, -0.9999999999999846, -5.200000000000038, -32.49999999999982, 1.0999999999999865, 5.2999999999999705, 35.30000000000026, 33.50000000000024, 20.000000000000014, 30.800000000000196, 33.50000000000024, 20.000000000000014, -59.799999999999805, 20.000000000000014, -35.19999999999978, -2.800000000000048, -32.49999999999975, 32.60000000000023, 29.90000000000018, 20.000000000000014, -28.299999999999862, -26.49999999999975, 20.000000000000014, 43.400000000000226, 20.000000000000014, 40.70000000000024, -2.2000000000000286, 20.000000000000014, 20.000000000000014, -40.89999999999976, 20.000000000000014, 20.000000000000014, -100.00000000000026, 20.000000000000014, -3.099999999999979, 18.799999999999994, 0.1999999999999599, -16.29999999999975, -11.199999999999834, -11.499999999999833, 26.300000000000114, 28.100000000000147, 23.600000000000065, -38.799999999999756, -3.0999999999999615, 25.400000000000098, -42.99999999999976, 20.000000000000014, -11.500000000000028, 20.000000000000014, 20.90000000000003, -17.799999999999756, 3.1999999999999615, -19.89999999999977, 20.000000000000014, 34.400000000000254, 20.000000000000014, 1.0999999999999759, 33.50000000000024, 26.300000000000114, 25.400000000000098, 21.80000000000004, 20.000000000000014, 15.799999999999946, 24.50000000000008, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999974], "policy_predator_policy_reward": [76.0, 0.0, 0.0, 40.0, 3.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 21.0, 0.0, 0.0, 0.0, 3.0, 39.0, 31.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 67.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 4.0, 0.0, 20.0, 14.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 27.0, 0.0, 40.0, 0.0, 0.0, 46.0, 30.0, 0.0, 0.0, 26.0, 0.0, 14.0, 0.0, 15.0, 27.0, 50.0, 0.0, 0.0, 44.0, 37.0, 19.0, 0.0, 0.0, 7.0, 17.0, 18.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 31.0, 6.0, 0.0, 9.0, 0.0, 39.0, 47.0, 5.0, 6.0, 13.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 9.0, 31.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 12.0, 0.0, 14.0, 20.0, 0.0, 22.0, 1.0, 0.0, 10.0, 1.0, 38.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 34.0, 4.0, 38.0, 25.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 26.0, 3.0, 0.0, 0.0, 61.0, 0.0, 11.0, 1.0, 33.0, 0.0, 18.0, 14.0, 0.0, 0.0, 28.0, 0.0, 1.0, 10.0, 30.0, 0.0, 15.0, 0.0, 0.0, 18.0, 27.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2916689392812974, "mean_inference_ms": 3.6439551722144152, "mean_action_processing_ms": 0.5826944906705486, "mean_env_wait_ms": 0.8033250376042287, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010913848876953125, "StateBufferConnector_ms": 0.007415294647216797, "ViewRequirementAgentConnector_ms": 0.2138458490371704}, "num_episodes": 18, "episode_return_max": 147.0999999999985, "episode_return_min": -37.2999999999996, "episode_return_mean": 33.24000000000016, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 213.5393698041374, "num_env_steps_trained_throughput_per_sec": 213.5393698041374, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 18933.08, "restore_workers_time_ms": 0.015, "training_step_time_ms": 18932.829, "sample_time_ms": 3590.388, "learn_time_ms": 15315.705, "learn_throughput": 261.17, "synch_weights_time_ms": 21.935}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "c52aa_00000", "date": "2024-08-13_00-08-26", "timestamp": 1723522106, "time_this_iter_s": 18.82855200767517, "time_total_s": 1231.2173392772675, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3accd0b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1231.2173392772675, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 85.3925925925926, "ram_util_percent": 83.17037037037038}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2900438750349972, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2381030681429717, "policy_loss": -0.0016055536330751483, "vf_loss": 1.2394142648215016, "vf_explained_var": 0.0034143918090396457, "kl": 0.007350667189723154, "entropy": 0.7464720891581641, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8811036390129221, "cur_kl_coeff": 0.006674194335937498, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8966614230442299, "policy_loss": -0.004085190901187835, "vf_loss": 0.9006999621315608, "vf_explained_var": 0.09483658053256848, "kl": 0.006990014191688535, "entropy": 0.5537273126777518, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 87.69999999999878, "episode_reward_min": -34.19999999999975, "episode_reward_mean": 31.78100000000019, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -141.7000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 62.300000000000196, "predator_policy": 74.0}, "policy_reward_mean": {"prey_policy": 7.15550000000005, "predator_policy": 8.735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.79999999999956, 40.0000000000003, 30.10000000000016, 35.600000000000236, 45.90000000000047, 48.00000000000048, 16.899999999999938, 26.400000000000087, 64.30000000000045, 82.29999999999914, 29.000000000000128, 11.200000000000049, -5.199999999999802, 45.40000000000039, 28.70000000000045, 87.69999999999878, 33.00000000000021, 24.600000000000065, 50.50000000000048, -17.099999999999596, -8.399999999999709, 9.899999999999915, 61.600000000000506, 20.800000000000114, 17.89999999999995, 40.0000000000003, 40.0000000000003, 62.50000000000051, 2.600000000000147, 33.400000000000205, 40.00000000000029, 19.799999999999955, 27.900000000000166, 47.30000000000042, 19.09999999999997, 84.09999999999904, 40.0000000000003, 40.00000000000036, 29.000000000000128, 6.80000000000004, 48.10000000000043, 33.500000000000206, 84.09999999999907, 37.60000000000026, 17.899999999999956, 31.100000000000183, 38.90000000000028, 30.000000000000146, 0.2999999999999643, 22.400000000000013, 68.80000000000018, 50.80000000000048, 53.500000000000526, -1.7999999999999012, 4.000000000000086, 25.100000000000062, 49.90000000000046, -10.799999999999669, 63.40000000000047, 60.700000000000486, 37.80000000000049, 8.100000000000088, 40.0000000000003, -18.999999999999865, 27.70000000000012, 16.89999999999995, 9.300000000000084, 54.40000000000054, 12.800000000000015, 33.3000000000002, 7.000000000000121, 23.500000000000117, 21.1, 10.300000000000024, 54.4000000000005, 30.10000000000015, 59.80000000000054, 47.200000000000415, 37.800000000000296, 40.1000000000003, 40.0000000000003, 21.30000000000002, 40.0000000000003, 43.60000000000035, 10.300000000000008, 56.20000000000052, 40.90000000000031, 45.200000000000394, 1.0000000000000344, 53.50000000000052, 37.800000000000296, 49.90000000000047, 33.400000000000205, 5.299999999999998, 52.40000000000049, 40.0000000000003, -34.19999999999975, 29.40000000000014, 50.80000000000048, 22.400000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -119.80000000000067, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999581, 11.599999999999964, 20.000000000000014, 20.000000000000014, 5.9, 20.000000000000014, 13.999999999999961, 20.000000000000014, -24.099999999999774, 20.000000000000014, -7.599999999999897, 20.000000000000014, 44.300000000000225, 62.300000000000196, 20.000000000000014, 20.000000000000014, -0.9999999999999846, -35.799999999999756, 20.000000000000014, 18.799999999999997, -64.00000000000048, 20.000000000000014, 25.4000000000001, -80.80000000000003, 33.50000000000024, 37.10000000000026, 50.600000000000186, -30.09999999999976, 37.10000000000026, 20.000000000000014, -9.399999999999883, -36.69999999999976, 45.200000000000244, 13.699999999999953, -80.80000000000075, -72.40000000000089, 20.000000000000014, -66.09999999999978, 20.000000000000014, 20.000000000000014, 41.60000000000025, -8.500000000000023, 5.299999999999969, -13.599999999999797, -2.5000000000000075, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 38.00000000000025, 20.000000000000014, -51.399999999999764, 7.399999999999967, 20.000000000000014, 8.29999999999997, 22.700000000000053, -86.20000000000005, 20.000000000000014, 9.499999999999947, 7.399999999999965, -7.299999999999905, 41.60000000000025, -28.89999999999978, 20.000000000000014, 42.50000000000021, 41.60000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 10.999999999999948, -0.9999999999999846, 20.000000000000014, -64.00000000000082, 30.800000000000196, 20.000000000000014, 28.100000000000147, 3.4999999999999654, 20.000000000000014, 39.80000000000025, 44.300000000000246, 5.599999999999971, 20.000000000000014, -6.699999999999992, -9.39999999999989, 20.000000000000014, -10.899999999999913, 20.000000000000014, 17.899999999999988, 20.000000000000014, -0.9999999999999846, -5.200000000000038, -32.49999999999982, 1.0999999999999865, 5.2999999999999705, 35.30000000000026, 33.50000000000024, 20.000000000000014, 30.800000000000196, 33.50000000000024, 20.000000000000014, -59.799999999999805, 20.000000000000014, -35.19999999999978, -2.800000000000048, -32.49999999999975, 32.60000000000023, 29.90000000000018, 20.000000000000014, -28.299999999999862, -26.49999999999975, 20.000000000000014, 43.400000000000226, 20.000000000000014, 40.70000000000024, -2.2000000000000286, 20.000000000000014, 20.000000000000014, -40.89999999999976, 20.000000000000014, 20.000000000000014, -100.00000000000026, 20.000000000000014, -3.099999999999979, 18.799999999999994, 0.1999999999999599, -16.29999999999975, -11.199999999999834, -11.499999999999833, 26.300000000000114, 28.100000000000147, 23.600000000000065, -38.799999999999756, -3.0999999999999615, 25.400000000000098, -42.99999999999976, 20.000000000000014, -11.500000000000028, 20.000000000000014, 20.90000000000003, -17.799999999999756, 3.1999999999999615, -19.89999999999977, 20.000000000000014, 34.400000000000254, 20.000000000000014, 1.0999999999999759, 33.50000000000024, 26.300000000000114, 25.400000000000098, 21.80000000000004, 20.000000000000014, 15.799999999999946, 24.50000000000008, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999974, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, -36.699999999999754, 34.40000000000026, 21.80000000000004, 20.90000000000003, 20.000000000000014, -1.0000000000000133, 36.20000000000024, 35.000000000000256, -85.00000000000078, 20.000000000000014, 33.50000000000024, 15.799999999999956, 20.000000000000014, 34.40000000000025, 6.499999999999968, 7.399999999999965, 20.000000000000014, 20.000000000000014, -57.69999999999979, -0.9999999999999881, 43.40000000000025, 20.000000000000014, 20.000000000000014, -141.7000000000004, 30.500000000000203, -7.599999999999904, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999804, 20.000000000000014], "policy_predator_policy_reward": [67.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 4.0, 0.0, 20.0, 14.0, 0.0, 21.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 27.0, 0.0, 40.0, 0.0, 0.0, 46.0, 30.0, 0.0, 0.0, 26.0, 0.0, 14.0, 0.0, 15.0, 27.0, 50.0, 0.0, 0.0, 44.0, 37.0, 19.0, 0.0, 0.0, 7.0, 17.0, 18.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 31.0, 6.0, 0.0, 9.0, 0.0, 39.0, 47.0, 5.0, 6.0, 13.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 9.0, 31.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 12.0, 0.0, 14.0, 20.0, 0.0, 22.0, 1.0, 0.0, 10.0, 1.0, 38.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 34.0, 4.0, 38.0, 25.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 26.0, 3.0, 0.0, 0.0, 61.0, 0.0, 11.0, 1.0, 33.0, 0.0, 18.0, 14.0, 0.0, 0.0, 28.0, 0.0, 1.0, 10.0, 30.0, 0.0, 15.0, 0.0, 0.0, 18.0, 27.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 50.0, 1.0, 0.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 6.0, 30.0, 13.0, 10.0, 0.0, 0.0, 0.0, 74.0, 3.0, 0.0, 17.0, 0.0, 0.0, 0.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2934736378286371, "mean_inference_ms": 3.6512410263525856, "mean_action_processing_ms": 0.5825189120047124, "mean_env_wait_ms": 0.8036436493211658, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0117875337600708, "StateBufferConnector_ms": 0.008325815200805664, "ViewRequirementAgentConnector_ms": 0.27354931831359863}, "num_episodes": 18, "episode_return_max": 87.69999999999878, "episode_return_min": -34.19999999999975, "episode_return_mean": 31.78100000000019, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 229.64158183494825, "num_env_steps_trained_throughput_per_sec": 229.64158183494825, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 18395.267, "restore_workers_time_ms": 0.015, "training_step_time_ms": 18395.055, "sample_time_ms": 3473.733, "learn_time_ms": 14897.07, "learn_throughput": 268.509, "synch_weights_time_ms": 20.025}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "c52aa_00000", "date": "2024-08-13_00-08-44", "timestamp": 1723522124, "time_this_iter_s": 17.4925377368927, "time_total_s": 1248.7098770141602, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3accd0550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1248.7098770141602, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 78.30799999999999, "ram_util_percent": 82.96799999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2747244762187755, "cur_kl_coeff": 0.04004516601562501, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.0697971406437103, "policy_loss": -0.0005690021101612026, "vf_loss": 2.070279317400443, "vf_explained_var": -0.013160510069478756, "kl": 0.002168113410408976, "entropy": 0.6950501870541346, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7858333790862055, "cur_kl_coeff": 0.006674194335937498, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9702301635313286, "policy_loss": -0.001410389203509247, "vf_loss": 1.9716113383807834, "vf_explained_var": 0.040408606472469515, "kl": 0.004376313601164673, "entropy": 0.45017877303103293, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 84.09999999999907, "episode_reward_min": -208.00000000000125, "episode_reward_mean": 28.301000000000176, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -196.30000000000055, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 44.300000000000246, "predator_policy": 79.0}, "policy_reward_mean": {"prey_policy": 5.6405000000000545, "predator_policy": 8.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [61.600000000000506, 20.800000000000114, 17.89999999999995, 40.0000000000003, 40.0000000000003, 62.50000000000051, 2.600000000000147, 33.400000000000205, 40.00000000000029, 19.799999999999955, 27.900000000000166, 47.30000000000042, 19.09999999999997, 84.09999999999904, 40.0000000000003, 40.00000000000036, 29.000000000000128, 6.80000000000004, 48.10000000000043, 33.500000000000206, 84.09999999999907, 37.60000000000026, 17.899999999999956, 31.100000000000183, 38.90000000000028, 30.000000000000146, 0.2999999999999643, 22.400000000000013, 68.80000000000018, 50.80000000000048, 53.500000000000526, -1.7999999999999012, 4.000000000000086, 25.100000000000062, 49.90000000000046, -10.799999999999669, 63.40000000000047, 60.700000000000486, 37.80000000000049, 8.100000000000088, 40.0000000000003, -18.999999999999865, 27.70000000000012, 16.89999999999995, 9.300000000000084, 54.40000000000054, 12.800000000000015, 33.3000000000002, 7.000000000000121, 23.500000000000117, 21.1, 10.300000000000024, 54.4000000000005, 30.10000000000015, 59.80000000000054, 47.200000000000415, 37.800000000000296, 40.1000000000003, 40.0000000000003, 21.30000000000002, 40.0000000000003, 43.60000000000035, 10.300000000000008, 56.20000000000052, 40.90000000000031, 45.200000000000394, 1.0000000000000344, 53.50000000000052, 37.800000000000296, 49.90000000000047, 33.400000000000205, 5.299999999999998, 52.40000000000049, 40.0000000000003, -34.19999999999975, 29.40000000000014, 50.80000000000048, 22.400000000000027, 40.0000000000003, 8.699999999999964, 37.800000000000296, 19.399999999999967, -50.200000000000855, 37.80000000000027, 33.90000000000025, 25.70000000000008, 40.0000000000003, 33.0000000000002, 31.90000000000019, 2.8999999999999333, 40.0000000000003, 54.40000000000051, 52.70000000000051, 25.70000000000007, -33.700000000000024, 74.19999999999978, 25.70000000000007, -208.00000000000125, -27.099999999999874, 33.2000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 41.60000000000025, -8.500000000000023, 5.299999999999969, -13.599999999999797, -2.5000000000000075, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 38.00000000000025, 20.000000000000014, -51.399999999999764, 7.399999999999967, 20.000000000000014, 8.29999999999997, 22.700000000000053, -86.20000000000005, 20.000000000000014, 9.499999999999947, 7.399999999999965, -7.299999999999905, 41.60000000000025, -28.89999999999978, 20.000000000000014, 42.50000000000021, 41.60000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 10.999999999999948, -0.9999999999999846, 20.000000000000014, -64.00000000000082, 30.800000000000196, 20.000000000000014, 28.100000000000147, 3.4999999999999654, 20.000000000000014, 39.80000000000025, 44.300000000000246, 5.599999999999971, 20.000000000000014, -6.699999999999992, -9.39999999999989, 20.000000000000014, -10.899999999999913, 20.000000000000014, 17.899999999999988, 20.000000000000014, -0.9999999999999846, -5.200000000000038, -32.49999999999982, 1.0999999999999865, 5.2999999999999705, 35.30000000000026, 33.50000000000024, 20.000000000000014, 30.800000000000196, 33.50000000000024, 20.000000000000014, -59.799999999999805, 20.000000000000014, -35.19999999999978, -2.800000000000048, -32.49999999999975, 32.60000000000023, 29.90000000000018, 20.000000000000014, -28.299999999999862, -26.49999999999975, 20.000000000000014, 43.400000000000226, 20.000000000000014, 40.70000000000024, -2.2000000000000286, 20.000000000000014, 20.000000000000014, -40.89999999999976, 20.000000000000014, 20.000000000000014, -100.00000000000026, 20.000000000000014, -3.099999999999979, 18.799999999999994, 0.1999999999999599, -16.29999999999975, -11.199999999999834, -11.499999999999833, 26.300000000000114, 28.100000000000147, 23.600000000000065, -38.799999999999756, -3.0999999999999615, 25.400000000000098, -42.99999999999976, 20.000000000000014, -11.500000000000028, 20.000000000000014, 20.90000000000003, -17.799999999999756, 3.1999999999999615, -19.89999999999977, 20.000000000000014, 34.400000000000254, 20.000000000000014, 1.0999999999999759, 33.50000000000024, 26.300000000000114, 25.400000000000098, 21.80000000000004, 20.000000000000014, 15.799999999999946, 24.50000000000008, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999974, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, -36.699999999999754, 34.40000000000026, 21.80000000000004, 20.90000000000003, 20.000000000000014, -1.0000000000000133, 36.20000000000024, 35.000000000000256, -85.00000000000078, 20.000000000000014, 33.50000000000024, 15.799999999999956, 20.000000000000014, 34.40000000000025, 6.499999999999968, 7.399999999999965, 20.000000000000014, 20.000000000000014, -57.69999999999979, -0.9999999999999881, 43.40000000000025, 20.000000000000014, 20.000000000000014, -141.7000000000004, 30.500000000000203, -7.599999999999904, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999804, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -46.29999999999978, 15.800000000000011, 20.000000000000014, 23.600000000000065, -26.199999999999747, -30.399999999999764, -59.80000000000062, 15.799999999999963, 20.000000000000014, 20.000000000000014, 5.899999999999976, -7.299999999999912, 20.000000000000014, 20.000000000000014, 20.000000000000014, 31.700000000000212, -15.699999999999754, 21.80000000000004, 1.0999999999999723, 20.000000000000014, -63.099999999999866, 20.000000000000014, 20.000000000000014, 34.400000000000254, 20.000000000000014, 28.70000000000025, 20.000000000000014, 20.000000000000014, -7.299999999999894, 20.000000000000014, -120.69999999999996, 39.800000000000246, 34.400000000000254, 20.000000000000014, -7.299999999999891, -196.30000000000055, -141.70000000000059, -108.1, 20.000000000000014, 20.000000000000014, 6.1999999999999655], "policy_predator_policy_reward": [0.0, 0.0, 7.0, 17.0, 18.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 31.0, 6.0, 0.0, 9.0, 0.0, 39.0, 47.0, 5.0, 6.0, 13.0, 0.0, 0.0, 28.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0, 0.0, 9.0, 31.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 12.0, 0.0, 14.0, 20.0, 0.0, 22.0, 1.0, 0.0, 10.0, 1.0, 38.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 34.0, 4.0, 38.0, 25.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 26.0, 3.0, 0.0, 0.0, 61.0, 0.0, 11.0, 1.0, 33.0, 0.0, 18.0, 14.0, 0.0, 0.0, 28.0, 0.0, 1.0, 10.0, 30.0, 0.0, 15.0, 0.0, 0.0, 18.0, 27.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 50.0, 1.0, 0.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 6.0, 30.0, 13.0, 10.0, 0.0, 0.0, 0.0, 74.0, 3.0, 0.0, 17.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 35.0, 0.0, 2.0, 0.0, 22.0, 2.0, 38.0, 0.0, 2.0, 0.0, 8.0, 0.0, 13.0, 0.0, 0.0, 16.0, 1.0, 9.0, 0.0, 0.0, 46.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 13.0, 0.0, 67.0, 0.0, 0.0, 13.0, 0.0, 51.0, 79.0, 0.0, 61.0, 0.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.292942171739024, "mean_inference_ms": 3.6546436745420805, "mean_action_processing_ms": 0.582115452581057, "mean_env_wait_ms": 0.802550194339225, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010408759117126465, "StateBufferConnector_ms": 0.008277297019958496, "ViewRequirementAgentConnector_ms": 0.27118051052093506}, "num_episodes": 22, "episode_return_max": 84.09999999999907, "episode_return_min": -208.00000000000125, "episode_return_mean": 28.301000000000176, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 266.3180865956151, "num_env_steps_trained_throughput_per_sec": 266.3180865956151, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 17601.323, "restore_workers_time_ms": 0.015, "training_step_time_ms": 17601.048, "sample_time_ms": 3244.723, "learn_time_ms": 14332.79, "learn_throughput": 279.08, "synch_weights_time_ms": 20.058}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "c52aa_00000", "date": "2024-08-13_00-08-59", "timestamp": 1723522139, "time_this_iter_s": 15.068296909332275, "time_total_s": 1263.7781739234924, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c55e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1263.7781739234924, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 75.84761904761906, "ram_util_percent": 83.16666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9727730100156453, "cur_kl_coeff": 0.020022583007812504, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3113873655833894, "policy_loss": -0.0011827899103678723, "vf_loss": 1.312513027793516, "vf_explained_var": -0.003161231645200618, "kl": 0.002853092025114935, "entropy": 0.6967968047611297, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5522656099939788, "cur_kl_coeff": 0.003337097167968749, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2246423126213135, "policy_loss": -0.003275642998605257, "vf_loss": 1.227894823671018, "vf_explained_var": 0.046536747173026756, "kl": 0.0069323688360930485, "entropy": 0.4274467264849042, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 84.09999999999907, "episode_reward_min": -208.00000000000125, "episode_reward_mean": 24.99000000000019, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -227.50000000000043, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 44.300000000000246, "predator_policy": 101.0}, "policy_reward_mean": {"prey_policy": 2.645000000000043, "predator_policy": 9.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [48.10000000000043, 33.500000000000206, 84.09999999999907, 37.60000000000026, 17.899999999999956, 31.100000000000183, 38.90000000000028, 30.000000000000146, 0.2999999999999643, 22.400000000000013, 68.80000000000018, 50.80000000000048, 53.500000000000526, -1.7999999999999012, 4.000000000000086, 25.100000000000062, 49.90000000000046, -10.799999999999669, 63.40000000000047, 60.700000000000486, 37.80000000000049, 8.100000000000088, 40.0000000000003, -18.999999999999865, 27.70000000000012, 16.89999999999995, 9.300000000000084, 54.40000000000054, 12.800000000000015, 33.3000000000002, 7.000000000000121, 23.500000000000117, 21.1, 10.300000000000024, 54.4000000000005, 30.10000000000015, 59.80000000000054, 47.200000000000415, 37.800000000000296, 40.1000000000003, 40.0000000000003, 21.30000000000002, 40.0000000000003, 43.60000000000035, 10.300000000000008, 56.20000000000052, 40.90000000000031, 45.200000000000394, 1.0000000000000344, 53.50000000000052, 37.800000000000296, 49.90000000000047, 33.400000000000205, 5.299999999999998, 52.40000000000049, 40.0000000000003, -34.19999999999975, 29.40000000000014, 50.80000000000048, 22.400000000000027, 40.0000000000003, 8.699999999999964, 37.800000000000296, 19.399999999999967, -50.200000000000855, 37.80000000000027, 33.90000000000025, 25.70000000000008, 40.0000000000003, 33.0000000000002, 31.90000000000019, 2.8999999999999333, 40.0000000000003, 54.40000000000051, 52.70000000000051, 25.70000000000007, -33.700000000000024, 74.19999999999978, 25.70000000000007, -208.00000000000125, -27.099999999999874, 33.2000000000002, 40.0000000000003, 1.600000000000011, 40.0000000000003, 48.20000000000044, 40.0000000000003, 47.80000000000043, 57.10000000000054, -67.80000000000086, -41.99999999999972, 38.9000000000003, 40.0000000000003, 47.200000000000415, 24.600000000000062, -46.599999999999675, -64.19999999999965, 18.899999999999988, 40.0000000000003, 38.00000000000026], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 28.100000000000147, 3.4999999999999654, 20.000000000000014, 39.80000000000025, 44.300000000000246, 5.599999999999971, 20.000000000000014, -6.699999999999992, -9.39999999999989, 20.000000000000014, -10.899999999999913, 20.000000000000014, 17.899999999999988, 20.000000000000014, -0.9999999999999846, -5.200000000000038, -32.49999999999982, 1.0999999999999865, 5.2999999999999705, 35.30000000000026, 33.50000000000024, 20.000000000000014, 30.800000000000196, 33.50000000000024, 20.000000000000014, -59.799999999999805, 20.000000000000014, -35.19999999999978, -2.800000000000048, -32.49999999999975, 32.60000000000023, 29.90000000000018, 20.000000000000014, -28.299999999999862, -26.49999999999975, 20.000000000000014, 43.400000000000226, 20.000000000000014, 40.70000000000024, -2.2000000000000286, 20.000000000000014, 20.000000000000014, -40.89999999999976, 20.000000000000014, 20.000000000000014, -100.00000000000026, 20.000000000000014, -3.099999999999979, 18.799999999999994, 0.1999999999999599, -16.29999999999975, -11.199999999999834, -11.499999999999833, 26.300000000000114, 28.100000000000147, 23.600000000000065, -38.799999999999756, -3.0999999999999615, 25.400000000000098, -42.99999999999976, 20.000000000000014, -11.500000000000028, 20.000000000000014, 20.90000000000003, -17.799999999999756, 3.1999999999999615, -19.89999999999977, 20.000000000000014, 34.400000000000254, 20.000000000000014, 1.0999999999999759, 33.50000000000024, 26.300000000000114, 25.400000000000098, 21.80000000000004, 20.000000000000014, 15.799999999999946, 24.50000000000008, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999974, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, -36.699999999999754, 34.40000000000026, 21.80000000000004, 20.90000000000003, 20.000000000000014, -1.0000000000000133, 36.20000000000024, 35.000000000000256, -85.00000000000078, 20.000000000000014, 33.50000000000024, 15.799999999999956, 20.000000000000014, 34.40000000000025, 6.499999999999968, 7.399999999999965, 20.000000000000014, 20.000000000000014, -57.69999999999979, -0.9999999999999881, 43.40000000000025, 20.000000000000014, 20.000000000000014, -141.7000000000004, 30.500000000000203, -7.599999999999904, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999804, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -46.29999999999978, 15.800000000000011, 20.000000000000014, 23.600000000000065, -26.199999999999747, -30.399999999999764, -59.80000000000062, 15.799999999999963, 20.000000000000014, 20.000000000000014, 5.899999999999976, -7.299999999999912, 20.000000000000014, 20.000000000000014, 20.000000000000014, 31.700000000000212, -15.699999999999754, 21.80000000000004, 1.0999999999999723, 20.000000000000014, -63.099999999999866, 20.000000000000014, 20.000000000000014, 34.400000000000254, 20.000000000000014, 28.70000000000025, 20.000000000000014, 20.000000000000014, -7.299999999999894, 20.000000000000014, -120.69999999999996, 39.800000000000246, 34.400000000000254, 20.000000000000014, -7.299999999999891, -196.30000000000055, -141.70000000000059, -108.1, 20.000000000000014, 20.000000000000014, 6.1999999999999655, 20.000000000000014, 20.000000000000014, 34.40000000000026, -80.80000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.200000000000085, 20.000000000000014, 20.000000000000014, 7.399999999999965, 34.40000000000025, 27.20000000000013, 29.90000000000018, -185.8000000000005, 20.000000000000014, -158.50000000000045, 24.50000000000008, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 27.20000000000013, 20.000000000000014, 29.90000000000018, -28.299999999999756, 20.900000000000027, -158.5000000000005, -227.50000000000043, -15.699999999999747, 5.299999999999965, -6.400000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.99999999999997], "policy_predator_policy_reward": [0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 12.0, 0.0, 14.0, 20.0, 0.0, 22.0, 1.0, 0.0, 10.0, 1.0, 38.0, 0.0, 7.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 34.0, 4.0, 38.0, 25.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 0.0, 0.0, 0.0, 20.0, 0.0, 26.0, 3.0, 0.0, 0.0, 61.0, 0.0, 11.0, 1.0, 33.0, 0.0, 18.0, 14.0, 0.0, 0.0, 28.0, 0.0, 1.0, 10.0, 30.0, 0.0, 15.0, 0.0, 0.0, 18.0, 27.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 50.0, 1.0, 0.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 6.0, 30.0, 13.0, 10.0, 0.0, 0.0, 0.0, 74.0, 3.0, 0.0, 17.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 35.0, 0.0, 2.0, 0.0, 22.0, 2.0, 38.0, 0.0, 2.0, 0.0, 8.0, 0.0, 13.0, 0.0, 0.0, 16.0, 1.0, 9.0, 0.0, 0.0, 46.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 13.0, 0.0, 67.0, 0.0, 0.0, 13.0, 0.0, 51.0, 79.0, 0.0, 61.0, 0.0, 7.0, 0.0, 0.0, 48.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 98.0, 0.0, 58.0, 34.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 6.0, 85.0, 101.0, 78.0, 13.0, 7.0, 0.0, 0.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2952713653641277, "mean_inference_ms": 3.6593029101743473, "mean_action_processing_ms": 0.5813731438440787, "mean_env_wait_ms": 0.8019597536602747, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009890317916870117, "StateBufferConnector_ms": 0.008051514625549316, "ViewRequirementAgentConnector_ms": 0.26133596897125244}, "num_episodes": 18, "episode_return_max": 84.09999999999907, "episode_return_min": -208.00000000000125, "episode_return_mean": 24.99000000000019, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 201.87519025201212, "num_env_steps_trained_throughput_per_sec": 201.87519025201212, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 17703.404, "restore_workers_time_ms": 0.015, "training_step_time_ms": 17703.129, "sample_time_ms": 3187.881, "learn_time_ms": 14493.892, "learn_throughput": 275.978, "synch_weights_time_ms": 17.933}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "c52aa_00000", "date": "2024-08-13_00-09-19", "timestamp": 1723522159, "time_this_iter_s": 19.87532091140747, "time_total_s": 1283.6534948349, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c0a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1283.6534948349, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 84.25357142857145, "ram_util_percent": 83.16785714285713}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7807108189792387, "cur_kl_coeff": 0.010011291503906252, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.935196192964675, "policy_loss": -0.0017460274139281225, "vf_loss": 1.9368363330603908, "vf_explained_var": -0.011139202433288413, "kl": 0.01057705215832421, "entropy": 0.5986953728098087, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.38966137624133834, "cur_kl_coeff": 0.003337097167968749, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6342296071468838, "policy_loss": -0.0035886944926999233, "vf_loss": 1.637804239578348, "vf_explained_var": 0.008975778527991482, "kl": 0.004212452090331256, "entropy": 0.3447415045644871, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 75.99999999999964, "episode_reward_min": -215.30000000000103, "episode_reward_mean": 16.328000000000163, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -309.7, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 43.40000000000025, "predator_policy": 157.0}, "policy_reward_mean": {"prey_policy": -4.695999999999977, "predator_policy": 12.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-18.999999999999865, 27.70000000000012, 16.89999999999995, 9.300000000000084, 54.40000000000054, 12.800000000000015, 33.3000000000002, 7.000000000000121, 23.500000000000117, 21.1, 10.300000000000024, 54.4000000000005, 30.10000000000015, 59.80000000000054, 47.200000000000415, 37.800000000000296, 40.1000000000003, 40.0000000000003, 21.30000000000002, 40.0000000000003, 43.60000000000035, 10.300000000000008, 56.20000000000052, 40.90000000000031, 45.200000000000394, 1.0000000000000344, 53.50000000000052, 37.800000000000296, 49.90000000000047, 33.400000000000205, 5.299999999999998, 52.40000000000049, 40.0000000000003, -34.19999999999975, 29.40000000000014, 50.80000000000048, 22.400000000000027, 40.0000000000003, 8.699999999999964, 37.800000000000296, 19.399999999999967, -50.200000000000855, 37.80000000000027, 33.90000000000025, 25.70000000000008, 40.0000000000003, 33.0000000000002, 31.90000000000019, 2.8999999999999333, 40.0000000000003, 54.40000000000051, 52.70000000000051, 25.70000000000007, -33.700000000000024, 74.19999999999978, 25.70000000000007, -208.00000000000125, -27.099999999999874, 33.2000000000002, 40.0000000000003, 1.600000000000011, 40.0000000000003, 48.20000000000044, 40.0000000000003, 47.80000000000043, 57.10000000000054, -67.80000000000086, -41.99999999999972, 38.9000000000003, 40.0000000000003, 47.200000000000415, 24.600000000000062, -46.599999999999675, -64.19999999999965, 18.899999999999988, 40.0000000000003, 38.00000000000026, -132.7000000000004, 40.0000000000003, -119.50000000000017, 27.90000000000011, 55.30000000000052, 26.800000000000107, 40.0000000000003, -50.19999999999983, 33.60000000000021, 56.200000000000514, 40.0000000000003, 44.80000000000038, -102.60000000000079, -96.00000000000003, 31.20000000000017, 75.99999999999964, 32.20000000000019, 40.0000000000003, 42.70000000000034, -215.30000000000103, 12.499999999999995, -12.799999999999608, 57.1000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-100.00000000000026, 20.000000000000014, -3.099999999999979, 18.799999999999994, 0.1999999999999599, -16.29999999999975, -11.199999999999834, -11.499999999999833, 26.300000000000114, 28.100000000000147, 23.600000000000065, -38.799999999999756, -3.0999999999999615, 25.400000000000098, -42.99999999999976, 20.000000000000014, -11.500000000000028, 20.000000000000014, 20.90000000000003, -17.799999999999756, 3.1999999999999615, -19.89999999999977, 20.000000000000014, 34.400000000000254, 20.000000000000014, 1.0999999999999759, 33.50000000000024, 26.300000000000114, 25.400000000000098, 21.80000000000004, 20.000000000000014, 15.799999999999946, 24.50000000000008, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, -15.699999999999974, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, -36.699999999999754, 34.40000000000026, 21.80000000000004, 20.90000000000003, 20.000000000000014, -1.0000000000000133, 36.20000000000024, 35.000000000000256, -85.00000000000078, 20.000000000000014, 33.50000000000024, 15.799999999999956, 20.000000000000014, 34.40000000000025, 6.499999999999968, 7.399999999999965, 20.000000000000014, 20.000000000000014, -57.69999999999979, -0.9999999999999881, 43.40000000000025, 20.000000000000014, 20.000000000000014, -141.7000000000004, 30.500000000000203, -7.599999999999904, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999804, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -46.29999999999978, 15.800000000000011, 20.000000000000014, 23.600000000000065, -26.199999999999747, -30.399999999999764, -59.80000000000062, 15.799999999999963, 20.000000000000014, 20.000000000000014, 5.899999999999976, -7.299999999999912, 20.000000000000014, 20.000000000000014, 20.000000000000014, 31.700000000000212, -15.699999999999754, 21.80000000000004, 1.0999999999999723, 20.000000000000014, -63.099999999999866, 20.000000000000014, 20.000000000000014, 34.400000000000254, 20.000000000000014, 28.70000000000025, 20.000000000000014, 20.000000000000014, -7.299999999999894, 20.000000000000014, -120.69999999999996, 39.800000000000246, 34.400000000000254, 20.000000000000014, -7.299999999999891, -196.30000000000055, -141.70000000000059, -108.1, 20.000000000000014, 20.000000000000014, 6.1999999999999655, 20.000000000000014, 20.000000000000014, 34.40000000000026, -80.80000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.200000000000085, 20.000000000000014, 20.000000000000014, 7.399999999999965, 34.40000000000025, 27.20000000000013, 29.90000000000018, -185.8000000000005, 20.000000000000014, -158.50000000000045, 24.50000000000008, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 27.20000000000013, 20.000000000000014, 29.90000000000018, -28.299999999999756, 20.900000000000027, -158.5000000000005, -227.50000000000043, -15.699999999999747, 5.299999999999965, -6.400000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.99999999999997, -309.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -234.70000000000036, -38.799999999999976, 20.000000000000014, -3.099999999999958, 34.40000000000026, 20.90000000000003, -5.199999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, -152.2000000000002, 20.000000000000014, -0.40000000000001346, 20.000000000000014, 20.90000000000003, 35.30000000000026, 20.000000000000014, 20.000000000000014, -11.499999999999819, 35.30000000000026, -17.79999999999975, -230.80000000000027, -274.0000000000002, 38.00000000000024, 20.000000000000014, 3.1999999999999633, 35.30000000000025, 40.70000000000025, 17.899999999999988, -15.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.700000000000053, -145.60000000000053, -165.70000000000047, -32.499999999999766, 20.000000000000014, -80.80000000000084, 20.000000000000014, 20.000000000000014, 37.10000000000025], "policy_predator_policy_reward": [61.0, 0.0, 11.0, 1.0, 33.0, 0.0, 18.0, 14.0, 0.0, 0.0, 28.0, 0.0, 1.0, 10.0, 30.0, 0.0, 15.0, 0.0, 0.0, 18.0, 27.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 50.0, 1.0, 0.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 6.0, 30.0, 13.0, 10.0, 0.0, 0.0, 0.0, 74.0, 3.0, 0.0, 17.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 35.0, 0.0, 2.0, 0.0, 22.0, 2.0, 38.0, 0.0, 2.0, 0.0, 8.0, 0.0, 13.0, 0.0, 0.0, 16.0, 1.0, 9.0, 0.0, 0.0, 46.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 13.0, 0.0, 67.0, 0.0, 0.0, 13.0, 0.0, 51.0, 79.0, 0.0, 61.0, 0.0, 7.0, 0.0, 0.0, 48.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 98.0, 0.0, 58.0, 34.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 6.0, 85.0, 101.0, 78.0, 13.0, 7.0, 0.0, 0.0, 10.0, 0.0, 157.0, 0.0, 0.0, 0.0, 126.0, 28.0, 11.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 82.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 9.0, 12.0, 128.0, 18.0, 0.0, 140.0, 0.0, 8.0, 0.0, 0.0, 16.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 16.0, 9.0, 45.0, 3.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.29578719667191, "mean_inference_ms": 3.6633209837962415, "mean_action_processing_ms": 0.5805576028055384, "mean_env_wait_ms": 0.8008739176573378, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0062215328216552734, "StateBufferConnector_ms": 0.007549881935119629, "ViewRequirementAgentConnector_ms": 0.2557486295700073}, "num_episodes": 23, "episode_return_max": 75.99999999999964, "episode_return_min": -215.30000000000103, "episode_return_mean": 16.328000000000163, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 244.52740516869216, "num_env_steps_trained_throughput_per_sec": 244.52740516869216, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 17761.711, "restore_workers_time_ms": 0.015, "training_step_time_ms": 17761.448, "sample_time_ms": 3230.242, "learn_time_ms": 14509.969, "learn_throughput": 275.673, "synch_weights_time_ms": 17.859}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "c52aa_00000", "date": "2024-08-13_00-09-35", "timestamp": 1723522175, "time_this_iter_s": 16.40487289428711, "time_total_s": 1300.058367729187, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3accd0550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1300.058367729187, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 81.47500000000001, "ram_util_percent": 83.33333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8209003843229126, "cur_kl_coeff": 0.010011291503906252, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1645430013616247, "policy_loss": -0.0014064358860234577, "vf_loss": 3.1658875668490376, "vf_explained_var": -0.0035951705836745167, "kl": 0.006179690236686519, "entropy": 0.64557475785099, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4982940097413366, "cur_kl_coeff": 0.0016685485839843745, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.811108165821701, "policy_loss": -0.002713818244498085, "vf_loss": 2.81380592414311, "vf_explained_var": 0.012083137161517269, "kl": 0.009623545910224652, "entropy": 0.4225182929524669, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 75.99999999999964, "episode_reward_min": -366.6, "episode_reward_mean": 0.09800000000017317, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -353.79999999999984, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 43.40000000000025, "predator_policy": 168.0}, "policy_reward_mean": {"prey_policy": -17.040999999999993, "predator_policy": 17.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.30000000000002, 40.0000000000003, 43.60000000000035, 10.300000000000008, 56.20000000000052, 40.90000000000031, 45.200000000000394, 1.0000000000000344, 53.50000000000052, 37.800000000000296, 49.90000000000047, 33.400000000000205, 5.299999999999998, 52.40000000000049, 40.0000000000003, -34.19999999999975, 29.40000000000014, 50.80000000000048, 22.400000000000027, 40.0000000000003, 8.699999999999964, 37.800000000000296, 19.399999999999967, -50.200000000000855, 37.80000000000027, 33.90000000000025, 25.70000000000008, 40.0000000000003, 33.0000000000002, 31.90000000000019, 2.8999999999999333, 40.0000000000003, 54.40000000000051, 52.70000000000051, 25.70000000000007, -33.700000000000024, 74.19999999999978, 25.70000000000007, -208.00000000000125, -27.099999999999874, 33.2000000000002, 40.0000000000003, 1.600000000000011, 40.0000000000003, 48.20000000000044, 40.0000000000003, 47.80000000000043, 57.10000000000054, -67.80000000000086, -41.99999999999972, 38.9000000000003, 40.0000000000003, 47.200000000000415, 24.600000000000062, -46.599999999999675, -64.19999999999965, 18.899999999999988, 40.0000000000003, 38.00000000000026, -132.7000000000004, 40.0000000000003, -119.50000000000017, 27.90000000000011, 55.30000000000052, 26.800000000000107, 40.0000000000003, -50.19999999999983, 33.60000000000021, 56.200000000000514, 40.0000000000003, 44.80000000000038, -102.60000000000079, -96.00000000000003, 31.20000000000017, 75.99999999999964, 32.20000000000019, 40.0000000000003, 42.70000000000034, -215.30000000000103, 12.499999999999995, -12.799999999999608, 57.1000000000005, 40.0000000000003, 40.0000000000003, 40.90000000000031, 40.0000000000003, 45.40000000000038, -115.30000000000007, -49.500000000000675, 25.700000000000262, -346.29999999999666, 17.999999999999975, 37.80000000000027, 38.90000000000028, -366.6, 31.400000000000418, -314.3999999999997, -155.8000000000006, -155.1000000000001, 28.600000000000104], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -15.699999999999974, 20.000000000000014, 20.000000000000014, 20.000000000000014, 23.600000000000065, 20.000000000000014, -36.699999999999754, 34.40000000000026, 21.80000000000004, 20.90000000000003, 20.000000000000014, -1.0000000000000133, 36.20000000000024, 35.000000000000256, -85.00000000000078, 20.000000000000014, 33.50000000000024, 15.799999999999956, 20.000000000000014, 34.40000000000025, 6.499999999999968, 7.399999999999965, 20.000000000000014, 20.000000000000014, -57.69999999999979, -0.9999999999999881, 43.40000000000025, 20.000000000000014, 20.000000000000014, -141.7000000000004, 30.500000000000203, -7.599999999999904, 20.000000000000014, 20.000000000000014, 30.800000000000196, -13.599999999999804, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -46.29999999999978, 15.800000000000011, 20.000000000000014, 23.600000000000065, -26.199999999999747, -30.399999999999764, -59.80000000000062, 15.799999999999963, 20.000000000000014, 20.000000000000014, 5.899999999999976, -7.299999999999912, 20.000000000000014, 20.000000000000014, 20.000000000000014, 31.700000000000212, -15.699999999999754, 21.80000000000004, 1.0999999999999723, 20.000000000000014, -63.099999999999866, 20.000000000000014, 20.000000000000014, 34.400000000000254, 20.000000000000014, 28.70000000000025, 20.000000000000014, 20.000000000000014, -7.299999999999894, 20.000000000000014, -120.69999999999996, 39.800000000000246, 34.400000000000254, 20.000000000000014, -7.299999999999891, -196.30000000000055, -141.70000000000059, -108.1, 20.000000000000014, 20.000000000000014, 6.1999999999999655, 20.000000000000014, 20.000000000000014, 34.40000000000026, -80.80000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.200000000000085, 20.000000000000014, 20.000000000000014, 7.399999999999965, 34.40000000000025, 27.20000000000013, 29.90000000000018, -185.8000000000005, 20.000000000000014, -158.50000000000045, 24.50000000000008, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 27.20000000000013, 20.000000000000014, 29.90000000000018, -28.299999999999756, 20.900000000000027, -158.5000000000005, -227.50000000000043, -15.699999999999747, 5.299999999999965, -6.400000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.99999999999997, -309.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -234.70000000000036, -38.799999999999976, 20.000000000000014, -3.099999999999958, 34.40000000000026, 20.90000000000003, -5.199999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, -152.2000000000002, 20.000000000000014, -0.40000000000001346, 20.000000000000014, 20.90000000000003, 35.30000000000026, 20.000000000000014, 20.000000000000014, -11.499999999999819, 35.30000000000026, -17.79999999999975, -230.80000000000027, -274.0000000000002, 38.00000000000024, 20.000000000000014, 3.1999999999999633, 35.30000000000025, 40.70000000000025, 17.899999999999988, -15.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.700000000000053, -145.60000000000053, -165.70000000000047, -32.499999999999766, 20.000000000000014, -80.80000000000084, 20.000000000000014, 20.000000000000014, 37.10000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -192.10000000000002, -74.19999999999987, -78.70000000000087, -17.79999999999974, -16.29999999999985, 20.000000000000014, -229.9000000000004, -240.4000000000004, 20.000000000000014, -21.999999999999744, -3.0999999999999615, 29.90000000000018, 20.000000000000014, 17.899999999999988, -246.7, -250.9, 35.30000000000025, -118.90000000000003, -215.20000000000002, -236.2, 20.000000000000014, -353.79999999999984, -206.8000000000001, -127.30000000000004, -3.400000000000042, 20.000000000000014], "policy_predator_policy_reward": [0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 27.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 50.0, 1.0, 0.0, 0.0, 0.0, 2.0, 9.0, 0.0, 0.0, 6.0, 30.0, 13.0, 10.0, 0.0, 0.0, 0.0, 74.0, 3.0, 0.0, 17.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 35.0, 0.0, 2.0, 0.0, 22.0, 2.0, 38.0, 0.0, 2.0, 0.0, 8.0, 0.0, 13.0, 0.0, 0.0, 16.0, 1.0, 9.0, 0.0, 0.0, 46.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 13.0, 0.0, 67.0, 0.0, 0.0, 13.0, 0.0, 51.0, 79.0, 0.0, 61.0, 0.0, 7.0, 0.0, 0.0, 48.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 98.0, 0.0, 58.0, 34.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 6.0, 85.0, 101.0, 78.0, 13.0, 7.0, 0.0, 0.0, 10.0, 0.0, 157.0, 0.0, 0.0, 0.0, 126.0, 28.0, 11.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 82.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 9.0, 12.0, 128.0, 18.0, 0.0, 140.0, 0.0, 8.0, 0.0, 0.0, 16.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 16.0, 9.0, 45.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 101.0, 50.0, 0.0, 47.0, 0.0, 22.0, 124.0, 0.0, 0.0, 20.0, 0.0, 11.0, 1.0, 0.0, 0.0, 131.0, 66.0, 49.0, 0.0, 137.0, 10.0, 168.0, 71.0, 108.0, 0.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3030116408361918, "mean_inference_ms": 3.6816284525372476, "mean_action_processing_ms": 0.5813952887168312, "mean_env_wait_ms": 0.8026336332287366, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0062596797943115234, "StateBufferConnector_ms": 0.013492703437805176, "ViewRequirementAgentConnector_ms": 0.36504673957824707}, "num_episodes": 18, "episode_return_max": 75.99999999999964, "episode_return_min": -366.6, "episode_return_mean": 0.09800000000017317, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 166.44700713294174, "num_env_steps_trained_throughput_per_sec": 166.44700713294174, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 18514.151, "restore_workers_time_ms": 0.015, "training_step_time_ms": 18513.888, "sample_time_ms": 3839.693, "learn_time_ms": 14650.902, "learn_throughput": 273.021, "synch_weights_time_ms": 20.073}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "c52aa_00000", "date": "2024-08-13_00-10-00", "timestamp": 1723522200, "time_this_iter_s": 24.211518049240112, "time_total_s": 1324.2698857784271, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acc38700>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1324.2698857784271, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 90.61515151515151, "ram_util_percent": 83.55757575757576}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6969627733899172, "cur_kl_coeff": 0.010011291503906252, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.581371365022407, "policy_loss": -0.002427298489406153, "vf_loss": 3.5837192879152044, "vf_explained_var": -0.00669174210104362, "kl": 0.007928212538356499, "entropy": 0.6754298792314277, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5217080213425178, "cur_kl_coeff": 0.0016685485839843745, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5921456755784456, "policy_loss": -0.002823694501806386, "vf_loss": 3.594963842724997, "vf_explained_var": 0.007634124364802446, "kl": 0.0033119795173603165, "entropy": 0.40237896125468, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 75.99999999999964, "episode_reward_min": -366.6, "episode_reward_mean": -17.14999999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -34.28499999999999, "predator_policy": 25.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.399999999999967, -50.200000000000855, 37.80000000000027, 33.90000000000025, 25.70000000000008, 40.0000000000003, 33.0000000000002, 31.90000000000019, 2.8999999999999333, 40.0000000000003, 54.40000000000051, 52.70000000000051, 25.70000000000007, -33.700000000000024, 74.19999999999978, 25.70000000000007, -208.00000000000125, -27.099999999999874, 33.2000000000002, 40.0000000000003, 1.600000000000011, 40.0000000000003, 48.20000000000044, 40.0000000000003, 47.80000000000043, 57.10000000000054, -67.80000000000086, -41.99999999999972, 38.9000000000003, 40.0000000000003, 47.200000000000415, 24.600000000000062, -46.599999999999675, -64.19999999999965, 18.899999999999988, 40.0000000000003, 38.00000000000026, -132.7000000000004, 40.0000000000003, -119.50000000000017, 27.90000000000011, 55.30000000000052, 26.800000000000107, 40.0000000000003, -50.19999999999983, 33.60000000000021, 56.200000000000514, 40.0000000000003, 44.80000000000038, -102.60000000000079, -96.00000000000003, 31.20000000000017, 75.99999999999964, 32.20000000000019, 40.0000000000003, 42.70000000000034, -215.30000000000103, 12.499999999999995, -12.799999999999608, 57.1000000000005, 40.0000000000003, 40.0000000000003, 40.90000000000031, 40.0000000000003, 45.40000000000038, -115.30000000000007, -49.500000000000675, 25.700000000000262, -346.29999999999666, 17.999999999999975, 37.80000000000027, 38.90000000000028, -366.6, 31.400000000000418, -314.3999999999997, -155.8000000000006, -155.1000000000001, 28.600000000000104, -141.50000000000057, -274.3999999999984, -115.0000000000006, 29.000000000000128, 46.300000000000395, -67.59999999999997, 57.10000000000054, 40.0000000000003, 38.90000000000028, 40.0000000000003, -328.29999999999745, -78.69999999999999, -50.19999999999997, -13.899999999999851, -88.9000000000004, 47.20000000000042, 40.0000000000003, 51.100000000000506, 33.1000000000002, -303.19999999999993, 27.90000000000011, -27.9999999999999], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [23.600000000000065, -26.199999999999747, -30.399999999999764, -59.80000000000062, 15.799999999999963, 20.000000000000014, 20.000000000000014, 5.899999999999976, -7.299999999999912, 20.000000000000014, 20.000000000000014, 20.000000000000014, 31.700000000000212, -15.699999999999754, 21.80000000000004, 1.0999999999999723, 20.000000000000014, -63.099999999999866, 20.000000000000014, 20.000000000000014, 34.400000000000254, 20.000000000000014, 28.70000000000025, 20.000000000000014, 20.000000000000014, -7.299999999999894, 20.000000000000014, -120.69999999999996, 39.800000000000246, 34.400000000000254, 20.000000000000014, -7.299999999999891, -196.30000000000055, -141.70000000000059, -108.1, 20.000000000000014, 20.000000000000014, 6.1999999999999655, 20.000000000000014, 20.000000000000014, 34.40000000000026, -80.80000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.200000000000085, 20.000000000000014, 20.000000000000014, 7.399999999999965, 34.40000000000025, 27.20000000000013, 29.90000000000018, -185.8000000000005, 20.000000000000014, -158.50000000000045, 24.50000000000008, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 27.20000000000013, 20.000000000000014, 29.90000000000018, -28.299999999999756, 20.900000000000027, -158.5000000000005, -227.50000000000043, -15.699999999999747, 5.299999999999965, -6.400000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.99999999999997, -309.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -234.70000000000036, -38.799999999999976, 20.000000000000014, -3.099999999999958, 34.40000000000026, 20.90000000000003, -5.199999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, -152.2000000000002, 20.000000000000014, -0.40000000000001346, 20.000000000000014, 20.90000000000003, 35.30000000000026, 20.000000000000014, 20.000000000000014, -11.499999999999819, 35.30000000000026, -17.79999999999975, -230.80000000000027, -274.0000000000002, 38.00000000000024, 20.000000000000014, 3.1999999999999633, 35.30000000000025, 40.70000000000025, 17.899999999999988, -15.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.700000000000053, -145.60000000000053, -165.70000000000047, -32.499999999999766, 20.000000000000014, -80.80000000000084, 20.000000000000014, 20.000000000000014, 37.10000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -192.10000000000002, -74.19999999999987, -78.70000000000087, -17.79999999999974, -16.29999999999985, 20.000000000000014, -229.9000000000004, -240.4000000000004, 20.000000000000014, -21.999999999999744, -3.0999999999999615, 29.90000000000018, 20.000000000000014, 17.899999999999988, -246.7, -250.9, 35.30000000000025, -118.90000000000003, -215.20000000000002, -236.2, 20.000000000000014, -353.79999999999984, -206.8000000000001, -127.30000000000004, -3.400000000000042, 20.000000000000014, 20.000000000000014, -326.5, -279.39999999999907, -148.00000000000017, 20.000000000000014, -312.9999999999993, 20.000000000000014, -0.9999999999999846, 26.300000000000114, 20.000000000000014, -30.69999999999979, -397.9, 29.000000000000163, 28.100000000000147, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -225.7000000000003, -223.6000000000003, -354.7, 20.000000000000014, 20.000000000000014, -152.2, 20.000000000000014, -82.90000000000002, 20.000000000000014, -235.90000000000015, 33.50000000000024, -7.299999999999901, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.100000000000154, 1.0999999999999723, 20.000000000000014, -139.6, -343.6, -3.0999999999999615, 20.000000000000014, -364.0, 20.000000000000014], "policy_predator_policy_reward": [0.0, 22.0, 2.0, 38.0, 0.0, 2.0, 0.0, 8.0, 0.0, 13.0, 0.0, 0.0, 16.0, 1.0, 9.0, 0.0, 0.0, 46.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 13.0, 0.0, 67.0, 0.0, 0.0, 13.0, 0.0, 51.0, 79.0, 0.0, 61.0, 0.0, 7.0, 0.0, 0.0, 48.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 98.0, 0.0, 58.0, 34.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 6.0, 85.0, 101.0, 78.0, 13.0, 7.0, 0.0, 0.0, 10.0, 0.0, 157.0, 0.0, 0.0, 0.0, 126.0, 28.0, 11.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 82.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 9.0, 12.0, 128.0, 18.0, 0.0, 140.0, 0.0, 8.0, 0.0, 0.0, 16.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 16.0, 9.0, 45.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 101.0, 50.0, 0.0, 47.0, 0.0, 22.0, 124.0, 0.0, 0.0, 20.0, 0.0, 11.0, 1.0, 0.0, 0.0, 131.0, 66.0, 49.0, 0.0, 137.0, 10.0, 168.0, 71.0, 108.0, 0.0, 12.0, 165.0, 0.0, 153.0, 0.0, 16.0, 162.0, 0.0, 10.0, 0.0, 0.0, 199.0, 162.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 121.0, 0.0, 72.0, 184.0, 82.0, 0.0, 2.0, 47.0, 127.0, 0.0, 11.0, 10.0, 0.0, 0.0, 3.0, 0.0, 0.0, 12.0, 0.0, 180.0, 0.0, 11.0, 185.0, 131.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3153803203243226, "mean_inference_ms": 3.715854583629639, "mean_action_processing_ms": 0.5841072246734899, "mean_env_wait_ms": 0.8065431881804639, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004755616188049316, "StateBufferConnector_ms": 0.012452244758605957, "ViewRequirementAgentConnector_ms": 0.4637798070907593}, "num_episodes": 22, "episode_return_max": 75.99999999999964, "episode_return_min": -366.6, "episode_return_mean": -17.14999999999982, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 140.80350913042392, "num_env_steps_trained_throughput_per_sec": 140.80350913042392, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 19538.18, "restore_workers_time_ms": 0.015, "training_step_time_ms": 19537.935, "sample_time_ms": 4321.791, "learn_time_ms": 15192.026, "learn_throughput": 263.296, "synch_weights_time_ms": 20.444}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "c52aa_00000", "date": "2024-08-13_00-10-29", "timestamp": 1723522229, "time_this_iter_s": 28.92616891860962, "time_total_s": 1353.1960546970367, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9cac10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1353.1960546970367, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 98.99999999999999, "ram_util_percent": 83.63658536585366}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3050935893758107, "cur_kl_coeff": 0.010011291503906252, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.8331062989260154, "policy_loss": -0.0020644700068428562, "vf_loss": 2.8350981861195237, "vf_explained_var": -0.00891270741583809, "kl": 0.0072509599992852, "entropy": 0.5839161603854447, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6425044297856629, "cur_kl_coeff": 0.0008342742919921872, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.3344036897023517, "policy_loss": -0.002290203252427832, "vf_loss": 2.3366907042801066, "vf_explained_var": 0.007655811215203906, "kl": 0.0038276833239722936, "entropy": 0.3562516402630579, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 75.99999999999964, "episode_reward_min": -494.2, "episode_reward_mean": -30.825999999999816, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -45.687999999999995, "predator_policy": 30.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.2000000000002, 40.0000000000003, 1.600000000000011, 40.0000000000003, 48.20000000000044, 40.0000000000003, 47.80000000000043, 57.10000000000054, -67.80000000000086, -41.99999999999972, 38.9000000000003, 40.0000000000003, 47.200000000000415, 24.600000000000062, -46.599999999999675, -64.19999999999965, 18.899999999999988, 40.0000000000003, 38.00000000000026, -132.7000000000004, 40.0000000000003, -119.50000000000017, 27.90000000000011, 55.30000000000052, 26.800000000000107, 40.0000000000003, -50.19999999999983, 33.60000000000021, 56.200000000000514, 40.0000000000003, 44.80000000000038, -102.60000000000079, -96.00000000000003, 31.20000000000017, 75.99999999999964, 32.20000000000019, 40.0000000000003, 42.70000000000034, -215.30000000000103, 12.499999999999995, -12.799999999999608, 57.1000000000005, 40.0000000000003, 40.0000000000003, 40.90000000000031, 40.0000000000003, 45.40000000000038, -115.30000000000007, -49.500000000000675, 25.700000000000262, -346.29999999999666, 17.999999999999975, 37.80000000000027, 38.90000000000028, -366.6, 31.400000000000418, -314.3999999999997, -155.8000000000006, -155.1000000000001, 28.600000000000104, -141.50000000000057, -274.3999999999984, -115.0000000000006, 29.000000000000128, 46.300000000000395, -67.59999999999997, 57.10000000000054, 40.0000000000003, 38.90000000000028, 40.0000000000003, -328.29999999999745, -78.69999999999999, -50.19999999999997, -13.899999999999851, -88.9000000000004, 47.20000000000042, 40.0000000000003, 51.100000000000506, 33.1000000000002, -303.19999999999993, 27.90000000000011, -27.9999999999999, 40.0000000000003, 17.99999999999995, 20.199999999999985, -484.5, -93.20000000000013, 39.10000000000046, 44.9000000000004, -494.2, -149.8000000000005, 13.49999999999997, 45.40000000000038, 40.70000000000032, 40.0000000000003, 40.0000000000003, -161.60000000000056, -94.20000000000113, -79.30000000000004, 25.70000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 6.1999999999999655, 20.000000000000014, 20.000000000000014, 34.40000000000026, -80.80000000000072, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.200000000000085, 20.000000000000014, 20.000000000000014, 7.399999999999965, 34.40000000000025, 27.20000000000013, 29.90000000000018, -185.8000000000005, 20.000000000000014, -158.50000000000045, 24.50000000000008, 20.000000000000014, 17.900000000000013, 20.000000000000014, 20.000000000000014, 27.20000000000013, 20.000000000000014, 29.90000000000018, -28.299999999999756, 20.900000000000027, -158.5000000000005, -227.50000000000043, -15.699999999999747, 5.299999999999965, -6.400000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.99999999999997, -309.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, -234.70000000000036, -38.799999999999976, 20.000000000000014, -3.099999999999958, 34.40000000000026, 20.90000000000003, -5.199999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, -152.2000000000002, 20.000000000000014, -0.40000000000001346, 20.000000000000014, 20.90000000000003, 35.30000000000026, 20.000000000000014, 20.000000000000014, -11.499999999999819, 35.30000000000026, -17.79999999999975, -230.80000000000027, -274.0000000000002, 38.00000000000024, 20.000000000000014, 3.1999999999999633, 35.30000000000025, 40.70000000000025, 17.899999999999988, -15.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.700000000000053, -145.60000000000053, -165.70000000000047, -32.499999999999766, 20.000000000000014, -80.80000000000084, 20.000000000000014, 20.000000000000014, 37.10000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -192.10000000000002, -74.19999999999987, -78.70000000000087, -17.79999999999974, -16.29999999999985, 20.000000000000014, -229.9000000000004, -240.4000000000004, 20.000000000000014, -21.999999999999744, -3.0999999999999615, 29.90000000000018, 20.000000000000014, 17.899999999999988, -246.7, -250.9, 35.30000000000025, -118.90000000000003, -215.20000000000002, -236.2, 20.000000000000014, -353.79999999999984, -206.8000000000001, -127.30000000000004, -3.400000000000042, 20.000000000000014, 20.000000000000014, -326.5, -279.39999999999907, -148.00000000000017, 20.000000000000014, -312.9999999999993, 20.000000000000014, -0.9999999999999846, 26.300000000000114, 20.000000000000014, -30.69999999999979, -397.9, 29.000000000000163, 28.100000000000147, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -225.7000000000003, -223.6000000000003, -354.7, 20.000000000000014, 20.000000000000014, -152.2, 20.000000000000014, -82.90000000000002, 20.000000000000014, -235.90000000000015, 33.50000000000024, -7.299999999999901, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.100000000000154, 1.0999999999999723, 20.000000000000014, -139.6, -343.6, -3.0999999999999615, 20.000000000000014, -364.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999766, 20.000000000000014, -17.799999999999756, -336.09999999999997, -339.4, 20.000000000000014, -248.20000000000002, 20.000000000000014, 1.0999999999999557, 17.899999999999984, 20.000000000000014, -383.2, -385.0, -347.5, 22.700000000000053, -59.80000000000062, 35.30000000000026, 20.000000000000014, 25.400000000000098, 21.80000000000004, 17.90000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -370.6, -234.10000000000045, 17.899999999999988, 20.000000000000014, -256.3000000000001, 15.799999999999962, -3.0999999999999615], "policy_predator_policy_reward": [0.0, 7.0, 0.0, 0.0, 48.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 98.0, 0.0, 58.0, 34.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 23.0, 0.0, 6.0, 85.0, 101.0, 78.0, 13.0, 7.0, 0.0, 0.0, 10.0, 0.0, 157.0, 0.0, 0.0, 0.0, 126.0, 28.0, 11.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 82.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 9.0, 12.0, 128.0, 18.0, 0.0, 140.0, 0.0, 8.0, 0.0, 0.0, 16.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 16.0, 9.0, 45.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 101.0, 50.0, 0.0, 47.0, 0.0, 22.0, 124.0, 0.0, 0.0, 20.0, 0.0, 11.0, 1.0, 0.0, 0.0, 131.0, 66.0, 49.0, 0.0, 137.0, 10.0, 168.0, 71.0, 108.0, 0.0, 12.0, 165.0, 0.0, 153.0, 0.0, 16.0, 162.0, 0.0, 10.0, 0.0, 0.0, 199.0, 162.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 121.0, 0.0, 72.0, 184.0, 82.0, 0.0, 2.0, 47.0, 127.0, 0.0, 11.0, 10.0, 0.0, 0.0, 3.0, 0.0, 0.0, 12.0, 0.0, 180.0, 0.0, 11.0, 185.0, 131.0, 0.0, 0.0, 0.0, 20.0, 17.0, 1.0, 0.0, 191.0, 0.0, 135.0, 0.0, 18.0, 0.0, 7.0, 197.0, 77.0, 175.0, 0.0, 0.0, 38.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 189.0, 0.0, 1.0, 121.0, 121.0, 36.0, 2.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3292757924239516, "mean_inference_ms": 3.7504928066786167, "mean_action_processing_ms": 0.5870659762065401, "mean_env_wait_ms": 0.8109617232447485, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006867647171020508, "StateBufferConnector_ms": 0.01437675952911377, "ViewRequirementAgentConnector_ms": 0.5051943063735962}, "num_episodes": 18, "episode_return_max": 75.99999999999964, "episode_return_min": -494.2, "episode_return_mean": -30.825999999999816, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 180.26749710350276, "num_env_steps_trained_throughput_per_sec": 180.26749710350276, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 20052.886, "restore_workers_time_ms": 0.015, "training_step_time_ms": 20052.64, "sample_time_ms": 4450.687, "learn_time_ms": 15574.263, "learn_throughput": 256.834, "synch_weights_time_ms": 23.777}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "c52aa_00000", "date": "2024-08-13_00-10-51", "timestamp": 1723522251, "time_this_iter_s": 22.44064164161682, "time_total_s": 1375.6366963386536, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab868310>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1375.6366963386536, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 89.62424242424244, "ram_util_percent": 83.71212121212122}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1405813819083273, "cur_kl_coeff": 0.010011291503906252, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6168824192077393, "policy_loss": -0.002558223441213606, "vf_loss": 1.6193456271968822, "vf_explained_var": -0.001271784368646208, "kl": 0.009490803298880005, "entropy": 0.5208154501265319, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5684908183478804, "cur_kl_coeff": 0.0004171371459960936, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7622602130370166, "policy_loss": -0.0026369481993021157, "vf_loss": 1.7648913270897335, "vf_explained_var": 0.007725721597671509, "kl": 0.01399290609581694, "entropy": 0.482840892420244, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 75.99999999999964, "episode_reward_min": -494.2, "episode_reward_mean": -32.32399999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -397.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 40.70000000000025, "predator_policy": 199.0}, "policy_reward_mean": {"prey_policy": -48.51699999999999, "predator_policy": 32.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [55.30000000000052, 26.800000000000107, 40.0000000000003, -50.19999999999983, 33.60000000000021, 56.200000000000514, 40.0000000000003, 44.80000000000038, -102.60000000000079, -96.00000000000003, 31.20000000000017, 75.99999999999964, 32.20000000000019, 40.0000000000003, 42.70000000000034, -215.30000000000103, 12.499999999999995, -12.799999999999608, 57.1000000000005, 40.0000000000003, 40.0000000000003, 40.90000000000031, 40.0000000000003, 45.40000000000038, -115.30000000000007, -49.500000000000675, 25.700000000000262, -346.29999999999666, 17.999999999999975, 37.80000000000027, 38.90000000000028, -366.6, 31.400000000000418, -314.3999999999997, -155.8000000000006, -155.1000000000001, 28.600000000000104, -141.50000000000057, -274.3999999999984, -115.0000000000006, 29.000000000000128, 46.300000000000395, -67.59999999999997, 57.10000000000054, 40.0000000000003, 38.90000000000028, 40.0000000000003, -328.29999999999745, -78.69999999999999, -50.19999999999997, -13.899999999999851, -88.9000000000004, 47.20000000000042, 40.0000000000003, 51.100000000000506, 33.1000000000002, -303.19999999999993, 27.90000000000011, -27.9999999999999, 40.0000000000003, 17.99999999999995, 20.199999999999985, -484.5, -93.20000000000013, 39.10000000000046, 44.9000000000004, -494.2, -149.8000000000005, 13.49999999999997, 45.40000000000038, 40.70000000000032, 40.0000000000003, 40.0000000000003, -161.60000000000056, -94.20000000000113, -79.30000000000004, 25.70000000000007, 48.10000000000044, 47.200000000000415, 40.0000000000003, 40.0000000000003, 30.100000000000183, -13.899999999999768, 44.50000000000036, -83.10000000000093, 45.40000000000038, 26.800000000000097, 54.400000000000524, -77.79999999999987, 35.80000000000024, 17.799999999999937, -85.70000000000067, -134.00000000000037, -92.00000000000028, 15.70000000000045, 40.0000000000003, 37.10000000000026, 18.59999999999996, 59.8000000000005, -114.000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [34.40000000000026, 20.90000000000003, -5.199999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, -152.2000000000002, 20.000000000000014, -0.40000000000001346, 20.000000000000014, 20.90000000000003, 35.30000000000026, 20.000000000000014, 20.000000000000014, -11.499999999999819, 35.30000000000026, -17.79999999999975, -230.80000000000027, -274.0000000000002, 38.00000000000024, 20.000000000000014, 3.1999999999999633, 35.30000000000025, 40.70000000000025, 17.899999999999988, -15.699999999999754, 20.000000000000014, 20.000000000000014, 20.000000000000014, 22.700000000000053, -145.60000000000053, -165.70000000000047, -32.499999999999766, 20.000000000000014, -80.80000000000084, 20.000000000000014, 20.000000000000014, 37.10000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -192.10000000000002, -74.19999999999987, -78.70000000000087, -17.79999999999974, -16.29999999999985, 20.000000000000014, -229.9000000000004, -240.4000000000004, 20.000000000000014, -21.999999999999744, -3.0999999999999615, 29.90000000000018, 20.000000000000014, 17.899999999999988, -246.7, -250.9, 35.30000000000025, -118.90000000000003, -215.20000000000002, -236.2, 20.000000000000014, -353.79999999999984, -206.8000000000001, -127.30000000000004, -3.400000000000042, 20.000000000000014, 20.000000000000014, -326.5, -279.39999999999907, -148.00000000000017, 20.000000000000014, -312.9999999999993, 20.000000000000014, -0.9999999999999846, 26.300000000000114, 20.000000000000014, -30.69999999999979, -397.9, 29.000000000000163, 28.100000000000147, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -225.7000000000003, -223.6000000000003, -354.7, 20.000000000000014, 20.000000000000014, -152.2, 20.000000000000014, -82.90000000000002, 20.000000000000014, -235.90000000000015, 33.50000000000024, -7.299999999999901, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.100000000000154, 1.0999999999999723, 20.000000000000014, -139.6, -343.6, -3.0999999999999615, 20.000000000000014, -364.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999766, 20.000000000000014, -17.799999999999756, -336.09999999999997, -339.4, 20.000000000000014, -248.20000000000002, 20.000000000000014, 1.0999999999999557, 17.899999999999984, 20.000000000000014, -383.2, -385.0, -347.5, 22.700000000000053, -59.80000000000062, 35.30000000000026, 20.000000000000014, 25.400000000000098, 21.80000000000004, 17.90000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -370.6, -234.10000000000045, 17.899999999999988, 20.000000000000014, -256.3000000000001, 15.799999999999962, -3.0999999999999615, 38.00000000000024, 1.0999999999999652, 27.20000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999686, 17.899999999999977, 20.000000000000014, -382.9, 20.000000000000014, 24.50000000000008, 20.000000000000014, -225.1000000000004, 20.000000000000014, 25.400000000000098, -5.199999999999937, 20.000000000000014, 34.40000000000026, 20.000000000000014, -242.50000000000026, 22.700000000000053, 0.19999999999998655, 23.600000000000065, -2.1999999999999713, -1.0000000000000133, 20.000000000000014, -234.70000000000027, -332.8, 30.800000000000196, 1.099999999999983, -213.10000000000008, 20.000000000000014, -40.29999999999981, 20.000000000000014, 20.000000000000014, 7.0999999999999694, 20.000000000000014, -2.199999999999989, -5.199999999999962, 27.20000000000013, 20.600000000000023, 20.000000000000014, -273.99999999999864], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 82.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 0.0, 9.0, 12.0, 128.0, 18.0, 0.0, 140.0, 0.0, 8.0, 0.0, 0.0, 16.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 16.0, 9.0, 45.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 101.0, 50.0, 0.0, 47.0, 0.0, 22.0, 124.0, 0.0, 0.0, 20.0, 0.0, 11.0, 1.0, 0.0, 0.0, 131.0, 66.0, 49.0, 0.0, 137.0, 10.0, 168.0, 71.0, 108.0, 0.0, 12.0, 165.0, 0.0, 153.0, 0.0, 16.0, 162.0, 0.0, 10.0, 0.0, 0.0, 199.0, 162.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 121.0, 0.0, 72.0, 184.0, 82.0, 0.0, 2.0, 47.0, 127.0, 0.0, 11.0, 10.0, 0.0, 0.0, 3.0, 0.0, 0.0, 12.0, 0.0, 180.0, 0.0, 11.0, 185.0, 131.0, 0.0, 0.0, 0.0, 20.0, 17.0, 1.0, 0.0, 191.0, 0.0, 135.0, 0.0, 18.0, 0.0, 7.0, 197.0, 77.0, 175.0, 0.0, 0.0, 38.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 189.0, 0.0, 1.0, 121.0, 121.0, 36.0, 2.0, 11.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 155.0, 194.0, 0.0, 0.0, 121.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 82.0, 60.0, 0.0, 12.0, 0.0, 21.0, 0.0, 129.0, 168.0, 0.0, 9.0, 111.0, 35.0, 1.0, 0.0, 0.0, 10.0, 0.0, 24.0, 2.0, 7.0, 5.0, 0.0, 140.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3457210226832554, "mean_inference_ms": 3.793538738104616, "mean_action_processing_ms": 0.5933260582709505, "mean_env_wait_ms": 0.8187554097372066, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009686946868896484, "StateBufferConnector_ms": 0.014242172241210938, "ViewRequirementAgentConnector_ms": 0.653929591178894}, "num_episodes": 23, "episode_return_max": 75.99999999999964, "episode_return_min": -494.2, "episode_return_mean": -32.32399999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 150.14506213954004, "num_env_steps_trained_throughput_per_sec": 150.14506213954004, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 20927.174, "restore_workers_time_ms": 0.017, "training_step_time_ms": 20926.923, "sample_time_ms": 5126.861, "learn_time_ms": 15770.852, "learn_throughput": 253.632, "synch_weights_time_ms": 26.108}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "c52aa_00000", "date": "2024-08-13_00-11-19", "timestamp": 1723522279, "time_this_iter_s": 27.04671001434326, "time_total_s": 1402.6834063529968, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3accf1430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1402.6834063529968, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 92.42368421052633, "ram_util_percent": 83.68684210526317}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9037234705966459, "cur_kl_coeff": 0.010011291503906252, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6184386431224764, "policy_loss": -0.00038014791078037685, "vf_loss": 2.618801090326259, "vf_explained_var": -0.008503783442986705, "kl": 0.001767448208648449, "entropy": 0.5519584366884182, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6527813769285641, "cur_kl_coeff": 0.0004171371459960936, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.819405152810314, "policy_loss": -0.0010761286805891408, "vf_loss": 2.82048001636273, "vf_explained_var": 0.009812900124403535, "kl": 0.0030194843681706596, "entropy": 0.4288964006635878, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 59.8000000000005, "episode_reward_min": -494.2, "episode_reward_mean": -42.098999999999826, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -59.17449999999997, "predator_policy": 38.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [57.1000000000005, 40.0000000000003, 40.0000000000003, 40.90000000000031, 40.0000000000003, 45.40000000000038, -115.30000000000007, -49.500000000000675, 25.700000000000262, -346.29999999999666, 17.999999999999975, 37.80000000000027, 38.90000000000028, -366.6, 31.400000000000418, -314.3999999999997, -155.8000000000006, -155.1000000000001, 28.600000000000104, -141.50000000000057, -274.3999999999984, -115.0000000000006, 29.000000000000128, 46.300000000000395, -67.59999999999997, 57.10000000000054, 40.0000000000003, 38.90000000000028, 40.0000000000003, -328.29999999999745, -78.69999999999999, -50.19999999999997, -13.899999999999851, -88.9000000000004, 47.20000000000042, 40.0000000000003, 51.100000000000506, 33.1000000000002, -303.19999999999993, 27.90000000000011, -27.9999999999999, 40.0000000000003, 17.99999999999995, 20.199999999999985, -484.5, -93.20000000000013, 39.10000000000046, 44.9000000000004, -494.2, -149.8000000000005, 13.49999999999997, 45.40000000000038, 40.70000000000032, 40.0000000000003, 40.0000000000003, -161.60000000000056, -94.20000000000113, -79.30000000000004, 25.70000000000007, 48.10000000000044, 47.200000000000415, 40.0000000000003, 40.0000000000003, 30.100000000000183, -13.899999999999768, 44.50000000000036, -83.10000000000093, 45.40000000000038, 26.800000000000097, 54.400000000000524, -77.79999999999987, 35.80000000000024, 17.799999999999937, -85.70000000000067, -134.00000000000037, -92.00000000000028, 15.70000000000045, 40.0000000000003, 37.10000000000026, 18.59999999999996, 59.8000000000005, -114.000000000001, -177.90000000000023, 32.500000000000206, 35.90000000000024, -346.4, 40.0000000000003, 40.0000000000003, -56.499999999999886, -459.09999999999997, 37.10000000000026, 42.00000000000033, 49.70000000000048, -49.89999999999969, 55.30000000000051, -14.499999999999837, 41.50000000000031, -169.4000000000006, 2.6000000000002084, -25.999999999999538], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 37.10000000000025, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.000000000000014, -192.10000000000002, -74.19999999999987, -78.70000000000087, -17.79999999999974, -16.29999999999985, 20.000000000000014, -229.9000000000004, -240.4000000000004, 20.000000000000014, -21.999999999999744, -3.0999999999999615, 29.90000000000018, 20.000000000000014, 17.899999999999988, -246.7, -250.9, 35.30000000000025, -118.90000000000003, -215.20000000000002, -236.2, 20.000000000000014, -353.79999999999984, -206.8000000000001, -127.30000000000004, -3.400000000000042, 20.000000000000014, 20.000000000000014, -326.5, -279.39999999999907, -148.00000000000017, 20.000000000000014, -312.9999999999993, 20.000000000000014, -0.9999999999999846, 26.300000000000114, 20.000000000000014, -30.69999999999979, -397.9, 29.000000000000163, 28.100000000000147, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -225.7000000000003, -223.6000000000003, -354.7, 20.000000000000014, 20.000000000000014, -152.2, 20.000000000000014, -82.90000000000002, 20.000000000000014, -235.90000000000015, 33.50000000000024, -7.299999999999901, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.100000000000154, 1.0999999999999723, 20.000000000000014, -139.6, -343.6, -3.0999999999999615, 20.000000000000014, -364.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999766, 20.000000000000014, -17.799999999999756, -336.09999999999997, -339.4, 20.000000000000014, -248.20000000000002, 20.000000000000014, 1.0999999999999557, 17.899999999999984, 20.000000000000014, -383.2, -385.0, -347.5, 22.700000000000053, -59.80000000000062, 35.30000000000026, 20.000000000000014, 25.400000000000098, 21.80000000000004, 17.90000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -370.6, -234.10000000000045, 17.899999999999988, 20.000000000000014, -256.3000000000001, 15.799999999999962, -3.0999999999999615, 38.00000000000024, 1.0999999999999652, 27.20000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999686, 17.899999999999977, 20.000000000000014, -382.9, 20.000000000000014, 24.50000000000008, 20.000000000000014, -225.1000000000004, 20.000000000000014, 25.400000000000098, -5.199999999999937, 20.000000000000014, 34.40000000000026, 20.000000000000014, -242.50000000000026, 22.700000000000053, 0.19999999999998655, 23.600000000000065, -2.1999999999999713, -1.0000000000000133, 20.000000000000014, -234.70000000000027, -332.8, 30.800000000000196, 1.099999999999983, -213.10000000000008, 20.000000000000014, -40.29999999999981, 20.000000000000014, 20.000000000000014, 7.0999999999999694, 20.000000000000014, -2.199999999999989, -5.199999999999962, 27.20000000000013, 20.600000000000023, 20.000000000000014, -273.99999999999864, -338.5, -51.400000000000034, -32.49999999999975, 20.000000000000014, 3.799999999999971, 1.0999999999999865, -400.0, -345.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.099999999999746, -123.40000000000026, -376.9, -383.2, 20.000000000000014, 7.0999999999999694, 24.50000000000008, 9.499999999999964, 30.800000000000196, 17.900000000000002, 20.000000000000014, -163.90000000000046, 35.30000000000025, 20.000000000000014, 20.000000000000014, -314.5, -3.0999999999999863, 23.600000000000065, -11.49999999999984, -358.9, -26.199999999999747, -5.199999999999937, -47.799999999999784, -26.199999999999747], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 101.0, 50.0, 0.0, 47.0, 0.0, 22.0, 124.0, 0.0, 0.0, 20.0, 0.0, 11.0, 1.0, 0.0, 0.0, 131.0, 66.0, 49.0, 0.0, 137.0, 10.0, 168.0, 71.0, 108.0, 0.0, 12.0, 165.0, 0.0, 153.0, 0.0, 16.0, 162.0, 0.0, 10.0, 0.0, 0.0, 199.0, 162.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 121.0, 0.0, 72.0, 184.0, 82.0, 0.0, 2.0, 47.0, 127.0, 0.0, 11.0, 10.0, 0.0, 0.0, 3.0, 0.0, 0.0, 12.0, 0.0, 180.0, 0.0, 11.0, 185.0, 131.0, 0.0, 0.0, 0.0, 20.0, 17.0, 1.0, 0.0, 191.0, 0.0, 135.0, 0.0, 18.0, 0.0, 7.0, 197.0, 77.0, 175.0, 0.0, 0.0, 38.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 189.0, 0.0, 1.0, 121.0, 121.0, 36.0, 2.0, 11.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 155.0, 194.0, 0.0, 0.0, 121.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 82.0, 60.0, 0.0, 12.0, 0.0, 21.0, 0.0, 129.0, 168.0, 0.0, 9.0, 111.0, 35.0, 1.0, 0.0, 0.0, 10.0, 0.0, 24.0, 2.0, 7.0, 5.0, 0.0, 140.0, 178.0, 34.0, 23.0, 22.0, 21.0, 10.0, 199.0, 200.0, 0.0, 0.0, 0.0, 0.0, 21.0, 70.0, 109.0, 192.0, 0.0, 10.0, 5.0, 3.0, 0.0, 1.0, 0.0, 94.0, 0.0, 0.0, 116.0, 164.0, 10.0, 11.0, 186.0, 15.0, 12.0, 22.0, 0.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3713835362466043, "mean_inference_ms": 3.863942669997631, "mean_action_processing_ms": 0.6010824916909756, "mean_env_wait_ms": 0.830411918288253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013015270233154297, "StateBufferConnector_ms": 0.014161109924316406, "ViewRequirementAgentConnector_ms": 0.6785080432891846}, "num_episodes": 18, "episode_return_max": 59.8000000000005, "episode_return_min": -494.2, "episode_return_mean": -42.098999999999826, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.92011076830389, "num_env_steps_trained_throughput_per_sec": 212.92011076830389, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 20739.9, "restore_workers_time_ms": 0.017, "training_step_time_ms": 20739.773, "sample_time_ms": 5306.529, "learn_time_ms": 15404.994, "learn_throughput": 259.656, "synch_weights_time_ms": 25.158}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "c52aa_00000", "date": "2024-08-13_00-11-38", "timestamp": 1723522298, "time_this_iter_s": 18.852168083190918, "time_total_s": 1421.5355744361877, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3accf1f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1421.5355744361877, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 84.2851851851852, "ram_util_percent": 83.08888888888887}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6885438426363247, "cur_kl_coeff": 0.005005645751953126, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.69757916693965, "policy_loss": -0.0010216292713290799, "vf_loss": 2.698570752963818, "vf_explained_var": -0.009948072830835979, "kl": 0.00600180023918882, "entropy": 0.6292225768011083, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5964950136524975, "cur_kl_coeff": 0.0002085685729980468, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7813930869733214, "policy_loss": -0.0018349228760661193, "vf_loss": 2.7832272318305162, "vf_explained_var": 0.005410709141423463, "kl": 0.0037067601558159087, "entropy": 0.4625980543238776, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 67.90000000000023, "episode_reward_min": -494.2, "episode_reward_mean": -34.278999999999876, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -54.76449999999997, "predator_policy": 37.625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.600000000000104, -141.50000000000057, -274.3999999999984, -115.0000000000006, 29.000000000000128, 46.300000000000395, -67.59999999999997, 57.10000000000054, 40.0000000000003, 38.90000000000028, 40.0000000000003, -328.29999999999745, -78.69999999999999, -50.19999999999997, -13.899999999999851, -88.9000000000004, 47.20000000000042, 40.0000000000003, 51.100000000000506, 33.1000000000002, -303.19999999999993, 27.90000000000011, -27.9999999999999, 40.0000000000003, 17.99999999999995, 20.199999999999985, -484.5, -93.20000000000013, 39.10000000000046, 44.9000000000004, -494.2, -149.8000000000005, 13.49999999999997, 45.40000000000038, 40.70000000000032, 40.0000000000003, 40.0000000000003, -161.60000000000056, -94.20000000000113, -79.30000000000004, 25.70000000000007, 48.10000000000044, 47.200000000000415, 40.0000000000003, 40.0000000000003, 30.100000000000183, -13.899999999999768, 44.50000000000036, -83.10000000000093, 45.40000000000038, 26.800000000000097, 54.400000000000524, -77.79999999999987, 35.80000000000024, 17.799999999999937, -85.70000000000067, -134.00000000000037, -92.00000000000028, 15.70000000000045, 40.0000000000003, 37.10000000000026, 18.59999999999996, 59.8000000000005, -114.000000000001, -177.90000000000023, 32.500000000000206, 35.90000000000024, -346.4, 40.0000000000003, 40.0000000000003, -56.499999999999886, -459.09999999999997, 37.10000000000026, 42.00000000000033, 49.70000000000048, -49.89999999999969, 55.30000000000051, -14.499999999999837, 41.50000000000031, -169.4000000000006, 2.6000000000002084, -25.999999999999538, 40.0000000000003, -160.20000000000056, 45.40000000000038, 40.0000000000003, 67.90000000000023, 49.90000000000046, 42.70000000000034, -75.60000000000088, 33.400000000000205, -98.80000000000052, 33.80000000000021, 49.00000000000045, -180.00000000000065, -151.40000000000052, -162.80000000000055, 48.10000000000043, 30.100000000000147, 42.70000000000034], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-3.400000000000042, 20.000000000000014, 20.000000000000014, -326.5, -279.39999999999907, -148.00000000000017, 20.000000000000014, -312.9999999999993, 20.000000000000014, -0.9999999999999846, 26.300000000000114, 20.000000000000014, -30.69999999999979, -397.9, 29.000000000000163, 28.100000000000147, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, -225.7000000000003, -223.6000000000003, -354.7, 20.000000000000014, 20.000000000000014, -152.2, 20.000000000000014, -82.90000000000002, 20.000000000000014, -235.90000000000015, 33.50000000000024, -7.299999999999901, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.100000000000154, 1.0999999999999723, 20.000000000000014, -139.6, -343.6, -3.0999999999999615, 20.000000000000014, -364.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999766, 20.000000000000014, -17.799999999999756, -336.09999999999997, -339.4, 20.000000000000014, -248.20000000000002, 20.000000000000014, 1.0999999999999557, 17.899999999999984, 20.000000000000014, -383.2, -385.0, -347.5, 22.700000000000053, -59.80000000000062, 35.30000000000026, 20.000000000000014, 25.400000000000098, 21.80000000000004, 17.90000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -370.6, -234.10000000000045, 17.899999999999988, 20.000000000000014, -256.3000000000001, 15.799999999999962, -3.0999999999999615, 38.00000000000024, 1.0999999999999652, 27.20000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999686, 17.899999999999977, 20.000000000000014, -382.9, 20.000000000000014, 24.50000000000008, 20.000000000000014, -225.1000000000004, 20.000000000000014, 25.400000000000098, -5.199999999999937, 20.000000000000014, 34.40000000000026, 20.000000000000014, -242.50000000000026, 22.700000000000053, 0.19999999999998655, 23.600000000000065, -2.1999999999999713, -1.0000000000000133, 20.000000000000014, -234.70000000000027, -332.8, 30.800000000000196, 1.099999999999983, -213.10000000000008, 20.000000000000014, -40.29999999999981, 20.000000000000014, 20.000000000000014, 7.0999999999999694, 20.000000000000014, -2.199999999999989, -5.199999999999962, 27.20000000000013, 20.600000000000023, 20.000000000000014, -273.99999999999864, -338.5, -51.400000000000034, -32.49999999999975, 20.000000000000014, 3.799999999999971, 1.0999999999999865, -400.0, -345.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.099999999999746, -123.40000000000026, -376.9, -383.2, 20.000000000000014, 7.0999999999999694, 24.50000000000008, 9.499999999999964, 30.800000000000196, 17.900000000000002, 20.000000000000014, -163.90000000000046, 35.30000000000025, 20.000000000000014, 20.000000000000014, -314.5, -3.0999999999999863, 23.600000000000065, -11.49999999999984, -358.9, -26.199999999999747, -5.199999999999937, -47.799999999999784, -26.199999999999747, 20.000000000000014, 20.000000000000014, -362.2, 20.000000000000014, 25.400000000000098, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000025, 32.60000000000023, 20.000000000000014, 29.90000000000018, 22.700000000000053, 20.000000000000014, -181.60000000000036, -3.9999999999999587, 7.399999999999965, 20.000000000000014, 20.000000000000014, -245.80000000000015, -7.299999999999891, 28.100000000000147, 20.000000000000014, 29.000000000000163, 20.000000000000014, -400.0, -345.4, 20.000000000000014, -361.0, 3.1999999999999615, 28.100000000000147, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, 22.700000000000053], "policy_predator_policy_reward": [0.0, 12.0, 165.0, 0.0, 153.0, 0.0, 16.0, 162.0, 0.0, 10.0, 0.0, 0.0, 199.0, 162.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 121.0, 0.0, 72.0, 184.0, 82.0, 0.0, 2.0, 47.0, 127.0, 0.0, 11.0, 10.0, 0.0, 0.0, 3.0, 0.0, 0.0, 12.0, 0.0, 180.0, 0.0, 11.0, 185.0, 131.0, 0.0, 0.0, 0.0, 20.0, 17.0, 1.0, 0.0, 191.0, 0.0, 135.0, 0.0, 18.0, 0.0, 7.0, 197.0, 77.0, 175.0, 0.0, 0.0, 38.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 189.0, 0.0, 1.0, 121.0, 121.0, 36.0, 2.0, 11.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 155.0, 194.0, 0.0, 0.0, 121.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 82.0, 60.0, 0.0, 12.0, 0.0, 21.0, 0.0, 129.0, 168.0, 0.0, 9.0, 111.0, 35.0, 1.0, 0.0, 0.0, 10.0, 0.0, 24.0, 2.0, 7.0, 5.0, 0.0, 140.0, 178.0, 34.0, 23.0, 22.0, 21.0, 10.0, 199.0, 200.0, 0.0, 0.0, 0.0, 0.0, 21.0, 70.0, 109.0, 192.0, 0.0, 10.0, 5.0, 3.0, 0.0, 1.0, 0.0, 94.0, 0.0, 0.0, 116.0, 164.0, 10.0, 11.0, 186.0, 15.0, 12.0, 22.0, 0.0, 48.0, 0.0, 0.0, 182.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 14.0, 0.0, 6.0, 127.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 200.0, 0.0, 174.0, 187.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.384689947289239, "mean_inference_ms": 3.905148986248312, "mean_action_processing_ms": 0.606645646004686, "mean_env_wait_ms": 0.8377562973501934, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01895928382873535, "StateBufferConnector_ms": 0.007921457290649414, "ViewRequirementAgentConnector_ms": 0.6616120338439941}, "num_episodes": 18, "episode_return_max": 67.90000000000023, "episode_return_min": -494.2, "episode_return_mean": -34.278999999999876, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 229.34569814757307, "num_env_steps_trained_throughput_per_sec": 229.34569814757307, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 20610.802, "restore_workers_time_ms": 0.018, "training_step_time_ms": 20610.674, "sample_time_ms": 5391.378, "learn_time_ms": 15190.517, "learn_throughput": 263.322, "synch_weights_time_ms": 25.743}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "c52aa_00000", "date": "2024-08-13_00-11-55", "timestamp": 1723522315, "time_this_iter_s": 17.54596209526062, "time_total_s": 1439.0815365314484, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3accf1820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1439.0815365314484, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 85.01599999999999, "ram_util_percent": 83.308}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8656021987901084, "cur_kl_coeff": 0.005005645751953126, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.3576030690834004, "policy_loss": -0.0006286112106252442, "vf_loss": 4.358197268733272, "vf_explained_var": -0.006477150179090954, "kl": 0.006875266087121, "entropy": 0.687977581553989, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7429325567863921, "cur_kl_coeff": 0.0001042842864990234, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.207485801959164, "policy_loss": -0.0035463345737231, "vf_loss": 4.211031573790091, "vf_explained_var": 0.006674136434282575, "kl": 0.005470031385574917, "entropy": 0.35811961714237456, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 67.90000000000023, "episode_reward_min": -510.6, "episode_reward_mean": -54.60899999999995, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -74.29449999999997, "predator_policy": 46.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-27.9999999999999, 40.0000000000003, 17.99999999999995, 20.199999999999985, -484.5, -93.20000000000013, 39.10000000000046, 44.9000000000004, -494.2, -149.8000000000005, 13.49999999999997, 45.40000000000038, 40.70000000000032, 40.0000000000003, 40.0000000000003, -161.60000000000056, -94.20000000000113, -79.30000000000004, 25.70000000000007, 48.10000000000044, 47.200000000000415, 40.0000000000003, 40.0000000000003, 30.100000000000183, -13.899999999999768, 44.50000000000036, -83.10000000000093, 45.40000000000038, 26.800000000000097, 54.400000000000524, -77.79999999999987, 35.80000000000024, 17.799999999999937, -85.70000000000067, -134.00000000000037, -92.00000000000028, 15.70000000000045, 40.0000000000003, 37.10000000000026, 18.59999999999996, 59.8000000000005, -114.000000000001, -177.90000000000023, 32.500000000000206, 35.90000000000024, -346.4, 40.0000000000003, 40.0000000000003, -56.499999999999886, -459.09999999999997, 37.10000000000026, 42.00000000000033, 49.70000000000048, -49.89999999999969, 55.30000000000051, -14.499999999999837, 41.50000000000031, -169.4000000000006, 2.6000000000002084, -25.999999999999538, 40.0000000000003, -160.20000000000056, 45.40000000000038, 40.0000000000003, 67.90000000000023, 49.90000000000046, 42.70000000000034, -75.60000000000088, 33.400000000000205, -98.80000000000052, 33.80000000000021, 49.00000000000045, -180.00000000000065, -151.40000000000052, -162.80000000000055, 48.10000000000043, 30.100000000000147, 42.70000000000034, -18.599999999999802, -171.2000000000006, -94.20000000000014, -371.69999999999993, -149.60000000000048, -509.6, 42.70000000000034, -67.0, -405.9, -510.6, -117.90000000000029, 19.09999999999997, -180.00000000000065, -163.80000000000055, -11.99999999999981, 45.40000000000038, 49.00000000000045, -358.7, 36.200000000000244, 1.500000000000165, 47.200000000000415, -125.80000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-364.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999766, 20.000000000000014, -17.799999999999756, -336.09999999999997, -339.4, 20.000000000000014, -248.20000000000002, 20.000000000000014, 1.0999999999999557, 17.899999999999984, 20.000000000000014, -383.2, -385.0, -347.5, 22.700000000000053, -59.80000000000062, 35.30000000000026, 20.000000000000014, 25.400000000000098, 21.80000000000004, 17.90000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -370.6, -234.10000000000045, 17.899999999999988, 20.000000000000014, -256.3000000000001, 15.799999999999962, -3.0999999999999615, 38.00000000000024, 1.0999999999999652, 27.20000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999686, 17.899999999999977, 20.000000000000014, -382.9, 20.000000000000014, 24.50000000000008, 20.000000000000014, -225.1000000000004, 20.000000000000014, 25.400000000000098, -5.199999999999937, 20.000000000000014, 34.40000000000026, 20.000000000000014, -242.50000000000026, 22.700000000000053, 0.19999999999998655, 23.600000000000065, -2.1999999999999713, -1.0000000000000133, 20.000000000000014, -234.70000000000027, -332.8, 30.800000000000196, 1.099999999999983, -213.10000000000008, 20.000000000000014, -40.29999999999981, 20.000000000000014, 20.000000000000014, 7.0999999999999694, 20.000000000000014, -2.199999999999989, -5.199999999999962, 27.20000000000013, 20.600000000000023, 20.000000000000014, -273.99999999999864, -338.5, -51.400000000000034, -32.49999999999975, 20.000000000000014, 3.799999999999971, 1.0999999999999865, -400.0, -345.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.099999999999746, -123.40000000000026, -376.9, -383.2, 20.000000000000014, 7.0999999999999694, 24.50000000000008, 9.499999999999964, 30.800000000000196, 17.900000000000002, 20.000000000000014, -163.90000000000046, 35.30000000000025, 20.000000000000014, 20.000000000000014, -314.5, -3.0999999999999863, 23.600000000000065, -11.49999999999984, -358.9, -26.199999999999747, -5.199999999999937, -47.799999999999784, -26.199999999999747, 20.000000000000014, 20.000000000000014, -362.2, 20.000000000000014, 25.400000000000098, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000025, 32.60000000000023, 20.000000000000014, 29.90000000000018, 22.700000000000053, 20.000000000000014, -181.60000000000036, -3.9999999999999587, 7.399999999999965, 20.000000000000014, 20.000000000000014, -245.80000000000015, -7.299999999999891, 28.100000000000147, 20.000000000000014, 29.000000000000163, 20.000000000000014, -400.0, -345.4, 20.000000000000014, -361.0, 3.1999999999999615, 28.100000000000147, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, 22.700000000000053, -343.6, 20.000000000000014, -383.2, 20.000000000000014, -393.7, 24.50000000000008, -395.8, -271.9, -352.6, 20.000000000000014, -338.2, -345.4, 22.700000000000053, 20.000000000000014, -5.1999999999999265, -164.8, -382.9, -400.0, -341.20000000000005, -357.4, 20.000000000000014, -292.9, -19.899999999999764, 20.000000000000014, 20.000000000000014, -400.0, 36.20000000000025, -400.0, -400.0, 20.000000000000014, 23.600000000000065, 21.80000000000004, 20.000000000000014, 29.000000000000163, -376.9, -362.8, -0.9999999999999917, 27.20000000000013, -53.500000000000135, 20.000000000000014, 20.000000000000014, 27.20000000000013, -299.8000000000001, 20.000000000000014], "policy_predator_policy_reward": [185.0, 131.0, 0.0, 0.0, 0.0, 20.0, 17.0, 1.0, 0.0, 191.0, 0.0, 135.0, 0.0, 18.0, 0.0, 7.0, 197.0, 77.0, 175.0, 0.0, 0.0, 38.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 189.0, 0.0, 1.0, 121.0, 121.0, 36.0, 2.0, 11.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 155.0, 194.0, 0.0, 0.0, 121.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 82.0, 60.0, 0.0, 12.0, 0.0, 21.0, 0.0, 129.0, 168.0, 0.0, 9.0, 111.0, 35.0, 1.0, 0.0, 0.0, 10.0, 0.0, 24.0, 2.0, 7.0, 5.0, 0.0, 140.0, 178.0, 34.0, 23.0, 22.0, 21.0, 10.0, 199.0, 200.0, 0.0, 0.0, 0.0, 0.0, 21.0, 70.0, 109.0, 192.0, 0.0, 10.0, 5.0, 3.0, 0.0, 1.0, 0.0, 94.0, 0.0, 0.0, 116.0, 164.0, 10.0, 11.0, 186.0, 15.0, 12.0, 22.0, 0.0, 48.0, 0.0, 0.0, 182.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 14.0, 0.0, 6.0, 127.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 200.0, 0.0, 174.0, 187.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 125.0, 180.0, 192.0, 0.0, 175.0, 100.0, 147.0, 149.0, 183.0, 0.0, 0.0, 174.0, 0.0, 0.0, 91.0, 12.0, 200.0, 177.0, 0.0, 188.0, 155.0, 0.0, 19.0, 0.0, 200.0, 0.0, 200.0, 0.0, 174.0, 194.0, 0.0, 0.0, 0.0, 0.0, 198.0, 183.0, 10.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 154.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3970180755389106, "mean_inference_ms": 3.9447655428614654, "mean_action_processing_ms": 0.6119715174725543, "mean_env_wait_ms": 0.8449899977048227, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019057631492614746, "StateBufferConnector_ms": 0.0064820051193237305, "ViewRequirementAgentConnector_ms": 0.45601367950439453}, "num_episodes": 22, "episode_return_max": 67.90000000000023, "episode_return_min": -510.6, "episode_return_mean": -54.60899999999995, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 185.54514334734392, "num_env_steps_trained_throughput_per_sec": 185.54514334734392, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 21024.767, "restore_workers_time_ms": 0.018, "training_step_time_ms": 21024.639, "sample_time_ms": 5406.549, "learn_time_ms": 15588.207, "learn_throughput": 256.604, "synch_weights_time_ms": 26.324}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "c52aa_00000", "date": "2024-08-13_00-12-17", "timestamp": 1723522337, "time_this_iter_s": 21.643691062927246, "time_total_s": 1460.7252275943756, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9caca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1460.7252275943756, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 94.07419354838709, "ram_util_percent": 83.79354838709679}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1623158334463677, "cur_kl_coeff": 0.005005645751953126, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.014889313808824, "policy_loss": -0.0005554992661234878, "vf_loss": 4.015418745979431, "vf_explained_var": -0.011055996966740441, "kl": 0.0052081817708253784, "entropy": 0.6494992161554004, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7466105148629852, "cur_kl_coeff": 0.0001042842864990234, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0964758293969292, "policy_loss": -0.002400903030490828, "vf_loss": 3.098876209233804, "vf_explained_var": 0.007002241333956441, "kl": 0.0050550507412718704, "entropy": 0.43162697668744143, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 71.49999999999997, "episode_reward_min": -510.6, "episode_reward_mean": -53.62399999999993, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -73.32699999999997, "predator_policy": 46.515}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.70000000000007, 48.10000000000044, 47.200000000000415, 40.0000000000003, 40.0000000000003, 30.100000000000183, -13.899999999999768, 44.50000000000036, -83.10000000000093, 45.40000000000038, 26.800000000000097, 54.400000000000524, -77.79999999999987, 35.80000000000024, 17.799999999999937, -85.70000000000067, -134.00000000000037, -92.00000000000028, 15.70000000000045, 40.0000000000003, 37.10000000000026, 18.59999999999996, 59.8000000000005, -114.000000000001, -177.90000000000023, 32.500000000000206, 35.90000000000024, -346.4, 40.0000000000003, 40.0000000000003, -56.499999999999886, -459.09999999999997, 37.10000000000026, 42.00000000000033, 49.70000000000048, -49.89999999999969, 55.30000000000051, -14.499999999999837, 41.50000000000031, -169.4000000000006, 2.6000000000002084, -25.999999999999538, 40.0000000000003, -160.20000000000056, 45.40000000000038, 40.0000000000003, 67.90000000000023, 49.90000000000046, 42.70000000000034, -75.60000000000088, 33.400000000000205, -98.80000000000052, 33.80000000000021, 49.00000000000045, -180.00000000000065, -151.40000000000052, -162.80000000000055, 48.10000000000043, 30.100000000000147, 42.70000000000034, -18.599999999999802, -171.2000000000006, -94.20000000000014, -371.69999999999993, -149.60000000000048, -509.6, 42.70000000000034, -67.0, -405.9, -510.6, -117.90000000000029, 19.09999999999997, -180.00000000000065, -163.80000000000055, -11.99999999999981, 45.40000000000038, 49.00000000000045, -358.7, 36.200000000000244, 1.500000000000165, 47.200000000000415, -125.80000000000025, 40.0000000000003, -149.40000000000046, 71.49999999999997, -160.00000000000054, -344.8, 58.00000000000051, 29.000000000000128, -311.2999999999991, -217.00000000000034, 40.0000000000003, 31.20000000000016, -49.099999999999646, 40.0000000000003, 63.400000000000496, 52.60000000000051, 29.100000000000154, 46.300000000000395, -414.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999962, -3.0999999999999615, 38.00000000000024, 1.0999999999999652, 27.20000000000013, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.1999999999999686, 17.899999999999977, 20.000000000000014, -382.9, 20.000000000000014, 24.50000000000008, 20.000000000000014, -225.1000000000004, 20.000000000000014, 25.400000000000098, -5.199999999999937, 20.000000000000014, 34.40000000000026, 20.000000000000014, -242.50000000000026, 22.700000000000053, 0.19999999999998655, 23.600000000000065, -2.1999999999999713, -1.0000000000000133, 20.000000000000014, -234.70000000000027, -332.8, 30.800000000000196, 1.099999999999983, -213.10000000000008, 20.000000000000014, -40.29999999999981, 20.000000000000014, 20.000000000000014, 7.0999999999999694, 20.000000000000014, -2.199999999999989, -5.199999999999962, 27.20000000000013, 20.600000000000023, 20.000000000000014, -273.99999999999864, -338.5, -51.400000000000034, -32.49999999999975, 20.000000000000014, 3.799999999999971, 1.0999999999999865, -400.0, -345.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.099999999999746, -123.40000000000026, -376.9, -383.2, 20.000000000000014, 7.0999999999999694, 24.50000000000008, 9.499999999999964, 30.800000000000196, 17.900000000000002, 20.000000000000014, -163.90000000000046, 35.30000000000025, 20.000000000000014, 20.000000000000014, -314.5, -3.0999999999999863, 23.600000000000065, -11.49999999999984, -358.9, -26.199999999999747, -5.199999999999937, -47.799999999999784, -26.199999999999747, 20.000000000000014, 20.000000000000014, -362.2, 20.000000000000014, 25.400000000000098, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000025, 32.60000000000023, 20.000000000000014, 29.90000000000018, 22.700000000000053, 20.000000000000014, -181.60000000000036, -3.9999999999999587, 7.399999999999965, 20.000000000000014, 20.000000000000014, -245.80000000000015, -7.299999999999891, 28.100000000000147, 20.000000000000014, 29.000000000000163, 20.000000000000014, -400.0, -345.4, 20.000000000000014, -361.0, 3.1999999999999615, 28.100000000000147, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, 22.700000000000053, -343.6, 20.000000000000014, -383.2, 20.000000000000014, -393.7, 24.50000000000008, -395.8, -271.9, -352.6, 20.000000000000014, -338.2, -345.4, 22.700000000000053, 20.000000000000014, -5.1999999999999265, -164.8, -382.9, -400.0, -341.20000000000005, -357.4, 20.000000000000014, -292.9, -19.899999999999764, 20.000000000000014, 20.000000000000014, -400.0, 36.20000000000025, -400.0, -400.0, 20.000000000000014, 23.600000000000065, 21.80000000000004, 20.000000000000014, 29.000000000000163, -376.9, -362.8, -0.9999999999999917, 27.20000000000013, -53.500000000000135, 20.000000000000014, 20.000000000000014, 27.20000000000013, -299.8000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -351.4, 35.30000000000026, 36.200000000000244, 20.000000000000014, -370.0, -359.2, -337.6, 20.000000000000014, 38.000000000000256, 20.000000000000014, -0.9999999999999846, -215.2000000000005, -213.1000000000005, -246.70000000000036, -220.29999999999995, 20.000000000000014, 20.000000000000014, 5.300000000000005, 17.899999999999977, -103.90000000000029, -26.199999999999747, 20.000000000000014, 20.000000000000014, 38.00000000000024, 25.400000000000098, 32.60000000000023, 20.000000000000014, 24.50000000000008, -9.399999999999944, 24.50000000000008, 21.80000000000004, -400.0, -376.0], "policy_predator_policy_reward": [2.0, 11.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 155.0, 194.0, 0.0, 0.0, 121.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 82.0, 60.0, 0.0, 12.0, 0.0, 21.0, 0.0, 129.0, 168.0, 0.0, 9.0, 111.0, 35.0, 1.0, 0.0, 0.0, 10.0, 0.0, 24.0, 2.0, 7.0, 5.0, 0.0, 140.0, 178.0, 34.0, 23.0, 22.0, 21.0, 10.0, 199.0, 200.0, 0.0, 0.0, 0.0, 0.0, 21.0, 70.0, 109.0, 192.0, 0.0, 10.0, 5.0, 3.0, 0.0, 1.0, 0.0, 94.0, 0.0, 0.0, 116.0, 164.0, 10.0, 11.0, 186.0, 15.0, 12.0, 22.0, 0.0, 48.0, 0.0, 0.0, 182.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 14.0, 0.0, 6.0, 127.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 200.0, 0.0, 174.0, 187.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 125.0, 180.0, 192.0, 0.0, 175.0, 100.0, 147.0, 149.0, 183.0, 0.0, 0.0, 174.0, 0.0, 0.0, 91.0, 12.0, 200.0, 177.0, 0.0, 188.0, 155.0, 0.0, 19.0, 0.0, 200.0, 0.0, 200.0, 0.0, 174.0, 194.0, 0.0, 0.0, 0.0, 0.0, 198.0, 183.0, 10.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 154.0, 0.0, 0.0, 0.0, 182.0, 0.0, 0.0, 190.0, 0.0, 183.0, 169.0, 0.0, 0.0, 10.0, 0.0, 0.0, 117.0, 127.0, 123.0, 0.0, 0.0, 0.0, 8.0, 22.0, 59.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 189.0, 173.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.406501362834645, "mean_inference_ms": 3.9745490753921207, "mean_action_processing_ms": 0.6160367534259238, "mean_env_wait_ms": 0.8510659713993312, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.016971707344055176, "StateBufferConnector_ms": 0.016866564750671387, "ViewRequirementAgentConnector_ms": 0.4726623296737671}, "num_episodes": 18, "episode_return_max": 71.49999999999997, "episode_return_min": -510.6, "episode_return_mean": -53.62399999999993, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 191.81333132021678, "num_env_steps_trained_throughput_per_sec": 191.81333132021678, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 21608.164, "restore_workers_time_ms": 0.018, "training_step_time_ms": 21608.101, "sample_time_ms": 5706.718, "learn_time_ms": 15871.639, "learn_throughput": 252.022, "synch_weights_time_ms": 26.146}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "c52aa_00000", "date": "2024-08-13_00-12-38", "timestamp": 1723522358, "time_this_iter_s": 20.967607975006104, "time_total_s": 1481.6928355693817, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c64c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1481.6928355693817, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 89.02413793103449, "ram_util_percent": 83.70344827586207}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7935222268025711, "cur_kl_coeff": 0.005005645751953126, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.57883335421325, "policy_loss": -0.0018012365358314976, "vf_loss": 3.5805898262710167, "vf_explained_var": -0.007361178959488238, "kl": 0.008943901527244294, "entropy": 0.6916033656824203, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7760481664112636, "cur_kl_coeff": 0.0001042842864990234, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.099145242272231, "policy_loss": -0.004235902122867407, "vf_loss": 4.103380232765561, "vf_explained_var": 0.010974462259383429, "kl": 0.008753534206368813, "entropy": 0.6015569218252071, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 71.49999999999997, "episode_reward_min": -546.0, "episode_reward_mean": -80.15899999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -97.18449999999997, "predator_policy": 57.105}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-114.000000000001, -177.90000000000023, 32.500000000000206, 35.90000000000024, -346.4, 40.0000000000003, 40.0000000000003, -56.499999999999886, -459.09999999999997, 37.10000000000026, 42.00000000000033, 49.70000000000048, -49.89999999999969, 55.30000000000051, -14.499999999999837, 41.50000000000031, -169.4000000000006, 2.6000000000002084, -25.999999999999538, 40.0000000000003, -160.20000000000056, 45.40000000000038, 40.0000000000003, 67.90000000000023, 49.90000000000046, 42.70000000000034, -75.60000000000088, 33.400000000000205, -98.80000000000052, 33.80000000000021, 49.00000000000045, -180.00000000000065, -151.40000000000052, -162.80000000000055, 48.10000000000043, 30.100000000000147, 42.70000000000034, -18.599999999999802, -171.2000000000006, -94.20000000000014, -371.69999999999993, -149.60000000000048, -509.6, 42.70000000000034, -67.0, -405.9, -510.6, -117.90000000000029, 19.09999999999997, -180.00000000000065, -163.80000000000055, -11.99999999999981, 45.40000000000038, 49.00000000000045, -358.7, 36.200000000000244, 1.500000000000165, 47.200000000000415, -125.80000000000025, 40.0000000000003, -149.40000000000046, 71.49999999999997, -160.00000000000054, -344.8, 58.00000000000051, 29.000000000000128, -311.2999999999991, -217.00000000000034, 40.0000000000003, 31.20000000000016, -49.099999999999646, 40.0000000000003, 63.400000000000496, 52.60000000000051, 29.100000000000154, 46.300000000000395, -414.0, -546.0, -165.70000000000056, 25.300000000000097, -152.50000000000048, 26.800000000000104, -80.79999999999993, -82.00000000000091, 53.50000000000052, 52.60000000000051, 9.300000000000056, 16.899999999999952, -142.10000000000042, -180.00000000000065, -59.00000000000017, -478.8, -417.0, -137.50000000000063, -397.29999999999995, 62.500000000000526, 43.60000000000035, 40.0000000000003, 55.300000000000495, -60.09999999999989], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -273.99999999999864, -338.5, -51.400000000000034, -32.49999999999975, 20.000000000000014, 3.799999999999971, 1.0999999999999865, -400.0, -345.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.099999999999746, -123.40000000000026, -376.9, -383.2, 20.000000000000014, 7.0999999999999694, 24.50000000000008, 9.499999999999964, 30.800000000000196, 17.900000000000002, 20.000000000000014, -163.90000000000046, 35.30000000000025, 20.000000000000014, 20.000000000000014, -314.5, -3.0999999999999863, 23.600000000000065, -11.49999999999984, -358.9, -26.199999999999747, -5.199999999999937, -47.799999999999784, -26.199999999999747, 20.000000000000014, 20.000000000000014, -362.2, 20.000000000000014, 25.400000000000098, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000025, 32.60000000000023, 20.000000000000014, 29.90000000000018, 22.700000000000053, 20.000000000000014, -181.60000000000036, -3.9999999999999587, 7.399999999999965, 20.000000000000014, 20.000000000000014, -245.80000000000015, -7.299999999999891, 28.100000000000147, 20.000000000000014, 29.000000000000163, 20.000000000000014, -400.0, -345.4, 20.000000000000014, -361.0, 3.1999999999999615, 28.100000000000147, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, 22.700000000000053, -343.6, 20.000000000000014, -383.2, 20.000000000000014, -393.7, 24.50000000000008, -395.8, -271.9, -352.6, 20.000000000000014, -338.2, -345.4, 22.700000000000053, 20.000000000000014, -5.1999999999999265, -164.8, -382.9, -400.0, -341.20000000000005, -357.4, 20.000000000000014, -292.9, -19.899999999999764, 20.000000000000014, 20.000000000000014, -400.0, 36.20000000000025, -400.0, -400.0, 20.000000000000014, 23.600000000000065, 21.80000000000004, 20.000000000000014, 29.000000000000163, -376.9, -362.8, -0.9999999999999917, 27.20000000000013, -53.500000000000135, 20.000000000000014, 20.000000000000014, 27.20000000000013, -299.8000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -351.4, 35.30000000000026, 36.200000000000244, 20.000000000000014, -370.0, -359.2, -337.6, 20.000000000000014, 38.000000000000256, 20.000000000000014, -0.9999999999999846, -215.2000000000005, -213.1000000000005, -246.70000000000036, -220.29999999999995, 20.000000000000014, 20.000000000000014, 5.300000000000005, 17.899999999999977, -103.90000000000029, -26.199999999999747, 20.000000000000014, 20.000000000000014, 38.00000000000024, 25.400000000000098, 32.60000000000023, 20.000000000000014, 24.50000000000008, -9.399999999999944, 24.50000000000008, 21.80000000000004, -400.0, -376.0, -367.0, -379.0, -372.70000000000005, 20.000000000000014, -383.2, 33.50000000000024, -347.5, 20.000000000000014, 20.000000000000014, -5.199999999999948, -301.00000000000017, 27.20000000000013, 34.40000000000026, -240.40000000000043, 33.50000000000024, 20.000000000000014, 32.60000000000023, 20.000000000000014, -354.7, 20.000000000000014, 20.000000000000014, -24.099999999999753, 20.000000000000014, -339.1, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -323.5, -334.3, -400.0, -376.0, 1.0999999999999865, -310.60000000000014, -334.9, -240.4, 34.400000000000254, 28.100000000000147, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 35.300000000000246, 20.000000000000014, 20.000000000000014, -171.10000000000002], "policy_predator_policy_reward": [0.0, 140.0, 178.0, 34.0, 23.0, 22.0, 21.0, 10.0, 199.0, 200.0, 0.0, 0.0, 0.0, 0.0, 21.0, 70.0, 109.0, 192.0, 0.0, 10.0, 5.0, 3.0, 0.0, 1.0, 0.0, 94.0, 0.0, 0.0, 116.0, 164.0, 10.0, 11.0, 186.0, 15.0, 12.0, 22.0, 0.0, 48.0, 0.0, 0.0, 182.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 14.0, 0.0, 6.0, 127.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 200.0, 0.0, 174.0, 187.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 125.0, 180.0, 192.0, 0.0, 175.0, 100.0, 147.0, 149.0, 183.0, 0.0, 0.0, 174.0, 0.0, 0.0, 91.0, 12.0, 200.0, 177.0, 0.0, 188.0, 155.0, 0.0, 19.0, 0.0, 200.0, 0.0, 200.0, 0.0, 174.0, 194.0, 0.0, 0.0, 0.0, 0.0, 198.0, 183.0, 10.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 154.0, 0.0, 0.0, 0.0, 182.0, 0.0, 0.0, 190.0, 0.0, 183.0, 169.0, 0.0, 0.0, 10.0, 0.0, 0.0, 117.0, 127.0, 123.0, 0.0, 0.0, 0.0, 8.0, 22.0, 59.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 189.0, 173.0, 0.0, 200.0, 187.0, 0.0, 184.0, 191.0, 175.0, 0.0, 12.0, 0.0, 158.0, 35.0, 0.0, 124.0, 0.0, 0.0, 0.0, 0.0, 163.0, 181.0, 0.0, 21.0, 0.0, 177.0, 200.0, 0.0, 189.0, 132.0, 179.0, 0.0, 200.0, 159.0, 9.0, 163.0, 178.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 91.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4133530565259123, "mean_inference_ms": 3.998518237437663, "mean_action_processing_ms": 0.6193649767629201, "mean_env_wait_ms": 0.8554373928414205, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014159917831420898, "StateBufferConnector_ms": 0.016399621963500977, "ViewRequirementAgentConnector_ms": 0.37281203269958496}, "num_episodes": 23, "episode_return_max": 71.49999999999997, "episode_return_min": -546.0, "episode_return_mean": -80.15899999999996, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 202.76258991484164, "num_env_steps_trained_throughput_per_sec": 202.76258991484164, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 21599.492, "restore_workers_time_ms": 0.018, "training_step_time_ms": 21599.429, "sample_time_ms": 5872.245, "learn_time_ms": 15696.406, "learn_throughput": 254.835, "synch_weights_time_ms": 27.253}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "c52aa_00000", "date": "2024-08-13_00-12-58", "timestamp": 1723522378, "time_this_iter_s": 19.852806091308594, "time_total_s": 1501.5456416606903, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ace7c670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1501.5456416606903, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 88.67931034482758, "ram_util_percent": 83.67241379310344}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.832555252001202, "cur_kl_coeff": 0.005005645751953126, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.600259721089923, "policy_loss": -0.0004084647317766828, "vf_loss": 3.600657266536087, "vf_explained_var": -0.0074480889020142734, "kl": 0.0021816029713281537, "entropy": 0.6909990886847178, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8644115440429203, "cur_kl_coeff": 0.0001042842864990234, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.590647330990544, "policy_loss": -0.004600536571963439, "vf_loss": 3.5952461757357157, "vf_explained_var": 0.01374829925557293, "kl": 0.016210158151433684, "entropy": 0.6862741398748267, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 71.49999999999997, "episode_reward_min": -546.0, "episode_reward_mean": -79.09599999999999, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -97.93299999999998, "predator_policy": 58.385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-25.999999999999538, 40.0000000000003, -160.20000000000056, 45.40000000000038, 40.0000000000003, 67.90000000000023, 49.90000000000046, 42.70000000000034, -75.60000000000088, 33.400000000000205, -98.80000000000052, 33.80000000000021, 49.00000000000045, -180.00000000000065, -151.40000000000052, -162.80000000000055, 48.10000000000043, 30.100000000000147, 42.70000000000034, -18.599999999999802, -171.2000000000006, -94.20000000000014, -371.69999999999993, -149.60000000000048, -509.6, 42.70000000000034, -67.0, -405.9, -510.6, -117.90000000000029, 19.09999999999997, -180.00000000000065, -163.80000000000055, -11.99999999999981, 45.40000000000038, 49.00000000000045, -358.7, 36.200000000000244, 1.500000000000165, 47.200000000000415, -125.80000000000025, 40.0000000000003, -149.40000000000046, 71.49999999999997, -160.00000000000054, -344.8, 58.00000000000051, 29.000000000000128, -311.2999999999991, -217.00000000000034, 40.0000000000003, 31.20000000000016, -49.099999999999646, 40.0000000000003, 63.400000000000496, 52.60000000000051, 29.100000000000154, 46.300000000000395, -414.0, -546.0, -165.70000000000056, 25.300000000000097, -152.50000000000048, 26.800000000000104, -80.79999999999993, -82.00000000000091, 53.50000000000052, 52.60000000000051, 9.300000000000056, 16.899999999999952, -142.10000000000042, -180.00000000000065, -59.00000000000017, -478.8, -417.0, -137.50000000000063, -397.29999999999995, 62.500000000000526, 43.60000000000035, 40.0000000000003, 55.300000000000495, -60.09999999999989, 40.0000000000003, 5.799999999999997, -49.09999999999987, 40.0000000000003, 33.400000000000205, -116.90000000000028, -157.70000000000053, -44.099999999999696, -64.49999999999986, -104.80000000000015, -162.40000000000055, -358.4, 36.50000000000025, 40.0000000000003, 40.0000000000003, -136.00000000000074, 21.300000000000104, 32.100000000000215], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-47.799999999999784, -26.199999999999747, 20.000000000000014, 20.000000000000014, -362.2, 20.000000000000014, 25.400000000000098, 20.000000000000014, 20.000000000000014, 20.000000000000014, 35.30000000000025, 32.60000000000023, 20.000000000000014, 29.90000000000018, 22.700000000000053, 20.000000000000014, -181.60000000000036, -3.9999999999999587, 7.399999999999965, 20.000000000000014, 20.000000000000014, -245.80000000000015, -7.299999999999891, 28.100000000000147, 20.000000000000014, 29.000000000000163, 20.000000000000014, -400.0, -345.4, 20.000000000000014, -361.0, 3.1999999999999615, 28.100000000000147, 20.000000000000014, 1.0999999999999794, 20.000000000000014, 20.000000000000014, 22.700000000000053, -343.6, 20.000000000000014, -383.2, 20.000000000000014, -393.7, 24.50000000000008, -395.8, -271.9, -352.6, 20.000000000000014, -338.2, -345.4, 22.700000000000053, 20.000000000000014, -5.1999999999999265, -164.8, -382.9, -400.0, -341.20000000000005, -357.4, 20.000000000000014, -292.9, -19.899999999999764, 20.000000000000014, 20.000000000000014, -400.0, 36.20000000000025, -400.0, -400.0, 20.000000000000014, 23.600000000000065, 21.80000000000004, 20.000000000000014, 29.000000000000163, -376.9, -362.8, -0.9999999999999917, 27.20000000000013, -53.500000000000135, 20.000000000000014, 20.000000000000014, 27.20000000000013, -299.8000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -351.4, 35.30000000000026, 36.200000000000244, 20.000000000000014, -370.0, -359.2, -337.6, 20.000000000000014, 38.000000000000256, 20.000000000000014, -0.9999999999999846, -215.2000000000005, -213.1000000000005, -246.70000000000036, -220.29999999999995, 20.000000000000014, 20.000000000000014, 5.300000000000005, 17.899999999999977, -103.90000000000029, -26.199999999999747, 20.000000000000014, 20.000000000000014, 38.00000000000024, 25.400000000000098, 32.60000000000023, 20.000000000000014, 24.50000000000008, -9.399999999999944, 24.50000000000008, 21.80000000000004, -400.0, -376.0, -367.0, -379.0, -372.70000000000005, 20.000000000000014, -383.2, 33.50000000000024, -347.5, 20.000000000000014, 20.000000000000014, -5.199999999999948, -301.00000000000017, 27.20000000000013, 34.40000000000026, -240.40000000000043, 33.50000000000024, 20.000000000000014, 32.60000000000023, 20.000000000000014, -354.7, 20.000000000000014, 20.000000000000014, -24.099999999999753, 20.000000000000014, -339.1, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -323.5, -334.3, -400.0, -376.0, 1.0999999999999865, -310.60000000000014, -334.9, -240.4, 34.400000000000254, 28.100000000000147, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 35.300000000000246, 20.000000000000014, 20.000000000000014, -171.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -50.199999999999775, -150.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, -82.90000000000036, -400.0, -342.4, -7.299999999999891, -173.20000000000002, 37.10000000000024, 20.000000000000014, -179.50000000000017, -271.9, 28.100000000000147, -15.699999999999747, -330.7, -351.7, -351.7, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -315.9999999999994, 35.30000000000025, -64.00000000000031, 20.000000000000014, -358.9], "policy_predator_policy_reward": [0.0, 48.0, 0.0, 0.0, 182.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 96.0, 14.0, 0.0, 6.0, 127.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 200.0, 0.0, 174.0, 187.0, 8.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 125.0, 180.0, 192.0, 0.0, 175.0, 100.0, 147.0, 149.0, 183.0, 0.0, 0.0, 174.0, 0.0, 0.0, 91.0, 12.0, 200.0, 177.0, 0.0, 188.0, 155.0, 0.0, 19.0, 0.0, 200.0, 0.0, 200.0, 0.0, 174.0, 194.0, 0.0, 0.0, 0.0, 0.0, 198.0, 183.0, 10.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 154.0, 0.0, 0.0, 0.0, 182.0, 0.0, 0.0, 190.0, 0.0, 183.0, 169.0, 0.0, 0.0, 10.0, 0.0, 0.0, 117.0, 127.0, 123.0, 0.0, 0.0, 0.0, 8.0, 22.0, 59.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 189.0, 173.0, 0.0, 200.0, 187.0, 0.0, 184.0, 191.0, 175.0, 0.0, 12.0, 0.0, 158.0, 35.0, 0.0, 124.0, 0.0, 0.0, 0.0, 0.0, 163.0, 181.0, 0.0, 21.0, 0.0, 177.0, 200.0, 0.0, 189.0, 132.0, 179.0, 0.0, 200.0, 159.0, 9.0, 163.0, 178.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 91.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 81.0, 0.0, 0.0, 6.0, 0.0, 193.0, 173.0, 13.0, 179.0, 92.0, 0.0, 2.0, 93.0, 139.0, 0.0, 17.0, 167.0, 168.0, 177.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 160.0, 13.0, 37.0, 186.0, 185.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4162742561811306, "mean_inference_ms": 4.0129448519629936, "mean_action_processing_ms": 0.6208176050855255, "mean_env_wait_ms": 0.8579993236198454, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011003613471984863, "StateBufferConnector_ms": 0.01844644546508789, "ViewRequirementAgentConnector_ms": 0.35799646377563477}, "num_episodes": 18, "episode_return_max": 71.49999999999997, "episode_return_min": -546.0, "episode_return_mean": -79.09599999999999, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 230.25205736148976, "num_env_steps_trained_throughput_per_sec": 230.25205736148976, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 21700.91, "restore_workers_time_ms": 0.018, "training_step_time_ms": 21700.847, "sample_time_ms": 5915.074, "learn_time_ms": 15753.84, "learn_throughput": 253.906, "synch_weights_time_ms": 27.745}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "c52aa_00000", "date": "2024-08-13_00-13-16", "timestamp": 1723522396, "time_this_iter_s": 17.474387168884277, "time_total_s": 1519.0200288295746, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ab87e8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1519.0200288295746, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 86.14399999999999, "ram_util_percent": 83.116}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.730020685490004, "cur_kl_coeff": 0.002502822875976563, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.2461589125729113, "policy_loss": -0.0006104775645311862, "vf_loss": 3.2467585160618735, "vf_explained_var": -0.0074015543889747095, "kl": 0.004343613786639, "entropy": 0.6116315757471418, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7077431115090216, "cur_kl_coeff": 0.0001042842864990234, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.165760196832122, "policy_loss": -0.001794315271187948, "vf_loss": 3.1675539614031556, "vf_explained_var": 0.008058820672766873, "kl": 0.005365096126600477, "entropy": 0.6431670713361609, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 71.49999999999997, "episode_reward_min": -583.2, "episode_reward_mean": -87.25399999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -103.49199999999998, "predator_policy": 59.865}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-371.69999999999993, -149.60000000000048, -509.6, 42.70000000000034, -67.0, -405.9, -510.6, -117.90000000000029, 19.09999999999997, -180.00000000000065, -163.80000000000055, -11.99999999999981, 45.40000000000038, 49.00000000000045, -358.7, 36.200000000000244, 1.500000000000165, 47.200000000000415, -125.80000000000025, 40.0000000000003, -149.40000000000046, 71.49999999999997, -160.00000000000054, -344.8, 58.00000000000051, 29.000000000000128, -311.2999999999991, -217.00000000000034, 40.0000000000003, 31.20000000000016, -49.099999999999646, 40.0000000000003, 63.400000000000496, 52.60000000000051, 29.100000000000154, 46.300000000000395, -414.0, -546.0, -165.70000000000056, 25.300000000000097, -152.50000000000048, 26.800000000000104, -80.79999999999993, -82.00000000000091, 53.50000000000052, 52.60000000000051, 9.300000000000056, 16.899999999999952, -142.10000000000042, -180.00000000000065, -59.00000000000017, -478.8, -417.0, -137.50000000000063, -397.29999999999995, 62.500000000000526, 43.60000000000035, 40.0000000000003, 55.300000000000495, -60.09999999999989, 40.0000000000003, 5.799999999999997, -49.09999999999987, 40.0000000000003, 33.400000000000205, -116.90000000000028, -157.70000000000053, -44.099999999999696, -64.49999999999986, -104.80000000000015, -162.40000000000055, -358.4, 36.50000000000025, 40.0000000000003, 40.0000000000003, -136.00000000000074, 21.300000000000104, 32.100000000000215, -98.30000000000015, 40.0000000000003, -205.6000000000004, -583.2, 40.0000000000003, 16.899999999999938, 40.0000000000003, -141.8000000000007, 30.500000000000192, 40.0000000000003, -569.1, -40.199999999999996, 40.0000000000003, 20.700000000000095, 26.400000000000084, 21.500000000000153, -43.800000000000075, 40.0000000000003, 24.600000000000055, -125.5000000000003, 40.0000000000003, -44.69999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-395.8, -271.9, -352.6, 20.000000000000014, -338.2, -345.4, 22.700000000000053, 20.000000000000014, -5.1999999999999265, -164.8, -382.9, -400.0, -341.20000000000005, -357.4, 20.000000000000014, -292.9, -19.899999999999764, 20.000000000000014, 20.000000000000014, -400.0, 36.20000000000025, -400.0, -400.0, 20.000000000000014, 23.600000000000065, 21.80000000000004, 20.000000000000014, 29.000000000000163, -376.9, -362.8, -0.9999999999999917, 27.20000000000013, -53.500000000000135, 20.000000000000014, 20.000000000000014, 27.20000000000013, -299.8000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -351.4, 35.30000000000026, 36.200000000000244, 20.000000000000014, -370.0, -359.2, -337.6, 20.000000000000014, 38.000000000000256, 20.000000000000014, -0.9999999999999846, -215.2000000000005, -213.1000000000005, -246.70000000000036, -220.29999999999995, 20.000000000000014, 20.000000000000014, 5.300000000000005, 17.899999999999977, -103.90000000000029, -26.199999999999747, 20.000000000000014, 20.000000000000014, 38.00000000000024, 25.400000000000098, 32.60000000000023, 20.000000000000014, 24.50000000000008, -9.399999999999944, 24.50000000000008, 21.80000000000004, -400.0, -376.0, -367.0, -379.0, -372.70000000000005, 20.000000000000014, -383.2, 33.50000000000024, -347.5, 20.000000000000014, 20.000000000000014, -5.199999999999948, -301.00000000000017, 27.20000000000013, 34.40000000000026, -240.40000000000043, 33.50000000000024, 20.000000000000014, 32.60000000000023, 20.000000000000014, -354.7, 20.000000000000014, 20.000000000000014, -24.099999999999753, 20.000000000000014, -339.1, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -323.5, -334.3, -400.0, -376.0, 1.0999999999999865, -310.60000000000014, -334.9, -240.4, 34.400000000000254, 28.100000000000147, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 35.300000000000246, 20.000000000000014, 20.000000000000014, -171.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -50.199999999999775, -150.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, -82.90000000000036, -400.0, -342.4, -7.299999999999891, -173.20000000000002, 37.10000000000024, 20.000000000000014, -179.50000000000017, -271.9, 28.100000000000147, -15.699999999999747, -330.7, -351.7, -351.7, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -315.9999999999994, 35.30000000000025, -64.00000000000031, 20.000000000000014, -358.9, -247.30000000000007, 20.000000000000014, 20.000000000000014, 20.000000000000014, -82.90000000000032, -381.7, -400.0, -383.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, -332.7999999999995, -400.0, 33.50000000000024, 20.000000000000014, 20.000000000000014, -382.0, -381.1, -28.299999999999756, -88.90000000000003, 20.000000000000014, 20.000000000000014, -347.8, 33.50000000000024, 21.80000000000004, -9.399999999999855, -23.49999999999997, 20.000000000000014, -19.59999999999997, -68.19999999999978, 20.000000000000014, 20.000000000000014, -5.199999999999937, 15.799999999999963, -334.0, 33.50000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, -141.70000000000067], "policy_predator_policy_reward": [147.0, 149.0, 183.0, 0.0, 0.0, 174.0, 0.0, 0.0, 91.0, 12.0, 200.0, 177.0, 0.0, 188.0, 155.0, 0.0, 19.0, 0.0, 200.0, 0.0, 200.0, 0.0, 174.0, 194.0, 0.0, 0.0, 0.0, 0.0, 198.0, 183.0, 10.0, 0.0, 0.0, 35.0, 0.0, 0.0, 0.0, 154.0, 0.0, 0.0, 0.0, 182.0, 0.0, 0.0, 190.0, 0.0, 183.0, 169.0, 0.0, 0.0, 10.0, 0.0, 0.0, 117.0, 127.0, 123.0, 0.0, 0.0, 0.0, 8.0, 22.0, 59.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 189.0, 173.0, 0.0, 200.0, 187.0, 0.0, 184.0, 191.0, 175.0, 0.0, 12.0, 0.0, 158.0, 35.0, 0.0, 124.0, 0.0, 0.0, 0.0, 0.0, 163.0, 181.0, 0.0, 21.0, 0.0, 177.0, 200.0, 0.0, 189.0, 132.0, 179.0, 0.0, 200.0, 159.0, 9.0, 163.0, 178.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 91.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 81.0, 0.0, 0.0, 6.0, 0.0, 193.0, 173.0, 13.0, 179.0, 92.0, 0.0, 2.0, 93.0, 139.0, 0.0, 17.0, 167.0, 168.0, 177.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 160.0, 13.0, 37.0, 186.0, 185.0, 129.0, 0.0, 0.0, 0.0, 193.0, 66.0, 0.0, 200.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 171.0, 0.0, 200.0, 197.0, 0.0, 0.0, 0.0, 194.0, 0.0, 77.0, 0.0, 0.0, 158.0, 177.0, 14.0, 0.0, 1.0, 24.0, 0.0, 44.0, 0.0, 0.0, 14.0, 0.0, 175.0, 0.0, 0.0, 0.0, 0.0, 77.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4178865803298777, "mean_inference_ms": 4.025315940536547, "mean_action_processing_ms": 0.6223373122218174, "mean_env_wait_ms": 0.8598543669105658, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004655003547668457, "StateBufferConnector_ms": 0.01831686496734619, "ViewRequirementAgentConnector_ms": 0.2923424243927002}, "num_episodes": 22, "episode_return_max": 71.49999999999997, "episode_return_min": -583.2, "episode_return_mean": -87.25399999999996, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 245.13413473060183, "num_env_steps_trained_throughput_per_sec": 245.13413473060183, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 20929.502, "restore_workers_time_ms": 0.018, "training_step_time_ms": 20929.439, "sample_time_ms": 5274.696, "learn_time_ms": 15625.003, "learn_throughput": 256.0, "synch_weights_time_ms": 25.585}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "c52aa_00000", "date": "2024-08-13_00-13-32", "timestamp": 1723522412, "time_this_iter_s": 16.42587685585022, "time_total_s": 1535.4459056854248, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9ba040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1535.4459056854248, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 88.58695652173913, "ram_util_percent": 83.37826086956521}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6812287538415855, "cur_kl_coeff": 0.0012514114379882815, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.468806387318505, "policy_loss": -0.002039400693620481, "vf_loss": 3.47083408252272, "vf_explained_var": -0.010970700701708516, "kl": 0.009351589807539374, "entropy": 0.5175472508977961, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7252682594907662, "cur_kl_coeff": 0.0001042842864990234, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0191958381385398, "policy_loss": -0.0021518380992193386, "vf_loss": 3.0213470145508095, "vf_explained_var": 0.008137010518835966, "kl": 0.006483844891481529, "entropy": 0.6689786335463246, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 71.49999999999997, "episode_reward_min": -583.2, "episode_reward_mean": -77.70599999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.000000000000256, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -93.32799999999997, "predator_policy": 54.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-125.80000000000025, 40.0000000000003, -149.40000000000046, 71.49999999999997, -160.00000000000054, -344.8, 58.00000000000051, 29.000000000000128, -311.2999999999991, -217.00000000000034, 40.0000000000003, 31.20000000000016, -49.099999999999646, 40.0000000000003, 63.400000000000496, 52.60000000000051, 29.100000000000154, 46.300000000000395, -414.0, -546.0, -165.70000000000056, 25.300000000000097, -152.50000000000048, 26.800000000000104, -80.79999999999993, -82.00000000000091, 53.50000000000052, 52.60000000000051, 9.300000000000056, 16.899999999999952, -142.10000000000042, -180.00000000000065, -59.00000000000017, -478.8, -417.0, -137.50000000000063, -397.29999999999995, 62.500000000000526, 43.60000000000035, 40.0000000000003, 55.300000000000495, -60.09999999999989, 40.0000000000003, 5.799999999999997, -49.09999999999987, 40.0000000000003, 33.400000000000205, -116.90000000000028, -157.70000000000053, -44.099999999999696, -64.49999999999986, -104.80000000000015, -162.40000000000055, -358.4, 36.50000000000025, 40.0000000000003, 40.0000000000003, -136.00000000000074, 21.300000000000104, 32.100000000000215, -98.30000000000015, 40.0000000000003, -205.6000000000004, -583.2, 40.0000000000003, 16.899999999999938, 40.0000000000003, -141.8000000000007, 30.500000000000192, 40.0000000000003, -569.1, -40.199999999999996, 40.0000000000003, 20.700000000000095, 26.400000000000084, 21.500000000000153, -43.800000000000075, 40.0000000000003, 24.600000000000055, -125.5000000000003, 40.0000000000003, -44.69999999999995, -181.7000000000007, -180.00000000000065, 10.300000000000066, -485.0, 46.300000000000395, 40.0000000000003, 47.90000000000046, -143.70000000000044, 66.10000000000036, 30.200000000000163, 42.70000000000034, 40.0000000000003, -128.3000000000003, -239.60000000000025, 5.300000000000111, -564.7, 40.0000000000003, -96.70000000000041], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-299.8000000000001, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -351.4, 35.30000000000026, 36.200000000000244, 20.000000000000014, -370.0, -359.2, -337.6, 20.000000000000014, 38.000000000000256, 20.000000000000014, -0.9999999999999846, -215.2000000000005, -213.1000000000005, -246.70000000000036, -220.29999999999995, 20.000000000000014, 20.000000000000014, 5.300000000000005, 17.899999999999977, -103.90000000000029, -26.199999999999747, 20.000000000000014, 20.000000000000014, 38.00000000000024, 25.400000000000098, 32.60000000000023, 20.000000000000014, 24.50000000000008, -9.399999999999944, 24.50000000000008, 21.80000000000004, -400.0, -376.0, -367.0, -379.0, -372.70000000000005, 20.000000000000014, -383.2, 33.50000000000024, -347.5, 20.000000000000014, 20.000000000000014, -5.199999999999948, -301.00000000000017, 27.20000000000013, 34.40000000000026, -240.40000000000043, 33.50000000000024, 20.000000000000014, 32.60000000000023, 20.000000000000014, -354.7, 20.000000000000014, 20.000000000000014, -24.099999999999753, 20.000000000000014, -339.1, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -323.5, -334.3, -400.0, -376.0, 1.0999999999999865, -310.60000000000014, -334.9, -240.4, 34.400000000000254, 28.100000000000147, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 35.300000000000246, 20.000000000000014, 20.000000000000014, -171.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -50.199999999999775, -150.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, -82.90000000000036, -400.0, -342.4, -7.299999999999891, -173.20000000000002, 37.10000000000024, 20.000000000000014, -179.50000000000017, -271.9, 28.100000000000147, -15.699999999999747, -330.7, -351.7, -351.7, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -315.9999999999994, 35.30000000000025, -64.00000000000031, 20.000000000000014, -358.9, -247.30000000000007, 20.000000000000014, 20.000000000000014, 20.000000000000014, -82.90000000000032, -381.7, -400.0, -383.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, -332.7999999999995, -400.0, 33.50000000000024, 20.000000000000014, 20.000000000000014, -382.0, -381.1, -28.299999999999756, -88.90000000000003, 20.000000000000014, 20.000000000000014, -347.8, 33.50000000000024, 21.80000000000004, -9.399999999999855, -23.49999999999997, 20.000000000000014, -19.59999999999997, -68.19999999999978, 20.000000000000014, 20.000000000000014, -5.199999999999937, 15.799999999999963, -334.0, 33.50000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, -141.70000000000067, -388.9, 3.199999999999967, 20.000000000000014, -400.0, -36.699999999999754, 20.000000000000014, -316.9, -339.1, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, -334.0, 5.299999999999965, 31.700000000000212, 34.40000000000025, 34.40000000000026, -26.199999999999747, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, -276.1, -5.1999999999999265, -345.4, -68.20000000000005, -25.59999999999998, -3.0999999999999757, -372.7, -388.0, 20.000000000000014, 20.000000000000014, 35.30000000000026, -367.0], "policy_predator_policy_reward": [0.0, 154.0, 0.0, 0.0, 0.0, 182.0, 0.0, 0.0, 190.0, 0.0, 183.0, 169.0, 0.0, 0.0, 10.0, 0.0, 0.0, 117.0, 127.0, 123.0, 0.0, 0.0, 0.0, 8.0, 22.0, 59.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 189.0, 173.0, 0.0, 200.0, 187.0, 0.0, 184.0, 191.0, 175.0, 0.0, 12.0, 0.0, 158.0, 35.0, 0.0, 124.0, 0.0, 0.0, 0.0, 0.0, 163.0, 181.0, 0.0, 21.0, 0.0, 177.0, 200.0, 0.0, 189.0, 132.0, 179.0, 0.0, 200.0, 159.0, 9.0, 163.0, 178.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 91.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 81.0, 0.0, 0.0, 6.0, 0.0, 193.0, 173.0, 13.0, 179.0, 92.0, 0.0, 2.0, 93.0, 139.0, 0.0, 17.0, 167.0, 168.0, 177.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 160.0, 13.0, 37.0, 186.0, 185.0, 129.0, 0.0, 0.0, 0.0, 193.0, 66.0, 0.0, 200.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 171.0, 0.0, 200.0, 197.0, 0.0, 0.0, 0.0, 194.0, 0.0, 77.0, 0.0, 0.0, 158.0, 177.0, 14.0, 0.0, 1.0, 24.0, 0.0, 44.0, 0.0, 0.0, 14.0, 0.0, 175.0, 0.0, 0.0, 0.0, 0.0, 77.0, 8.0, 196.0, 0.0, 200.0, 27.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 178.0, 7.0, 0.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 0.0, 12.0, 141.0, 0.0, 174.0, 34.0, 0.0, 196.0, 0.0, 0.0, 0.0, 46.0, 189.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.421675045950945, "mean_inference_ms": 4.038912665134381, "mean_action_processing_ms": 0.6231278013405245, "mean_env_wait_ms": 0.8625661526519697, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004609823226928711, "StateBufferConnector_ms": 0.018568038940429688, "ViewRequirementAgentConnector_ms": 0.3323361873626709}, "num_episodes": 18, "episode_return_max": 71.49999999999997, "episode_return_min": -583.2, "episode_return_mean": -77.70599999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 203.10771750601947, "num_env_steps_trained_throughput_per_sec": 203.10771750601947, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 20058.062, "restore_workers_time_ms": 0.018, "training_step_time_ms": 20057.998, "sample_time_ms": 5060.42, "learn_time_ms": 14966.922, "learn_throughput": 267.256, "synch_weights_time_ms": 25.605}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "c52aa_00000", "date": "2024-08-13_00-13-52", "timestamp": 1723522432, "time_this_iter_s": 19.763719081878662, "time_total_s": 1555.2096247673035, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9c55e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1555.2096247673035, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 88.35714285714285, "ram_util_percent": 83.53928571428573}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7546375718578775, "cur_kl_coeff": 0.0012514114379882815, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.297039626704322, "policy_loss": -0.001179226187289392, "vf_loss": 3.2982117080183886, "vf_explained_var": -0.00528256063738828, "kl": 0.005712365516230767, "entropy": 0.5846877138766031, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7191110144689601, "cur_kl_coeff": 0.0001042842864990234, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.787760837683602, "policy_loss": -0.0034753655696967765, "vf_loss": 2.7912347695814868, "vf_explained_var": 0.005970520727218143, "kl": 0.013830862453147031, "entropy": 0.6278069151141656, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 66.10000000000036, "episode_reward_min": -583.2, "episode_reward_mean": -70.68699999999997, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 37.10000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -86.51349999999998, "predator_policy": 51.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.800000000000104, -80.79999999999993, -82.00000000000091, 53.50000000000052, 52.60000000000051, 9.300000000000056, 16.899999999999952, -142.10000000000042, -180.00000000000065, -59.00000000000017, -478.8, -417.0, -137.50000000000063, -397.29999999999995, 62.500000000000526, 43.60000000000035, 40.0000000000003, 55.300000000000495, -60.09999999999989, 40.0000000000003, 5.799999999999997, -49.09999999999987, 40.0000000000003, 33.400000000000205, -116.90000000000028, -157.70000000000053, -44.099999999999696, -64.49999999999986, -104.80000000000015, -162.40000000000055, -358.4, 36.50000000000025, 40.0000000000003, 40.0000000000003, -136.00000000000074, 21.300000000000104, 32.100000000000215, -98.30000000000015, 40.0000000000003, -205.6000000000004, -583.2, 40.0000000000003, 16.899999999999938, 40.0000000000003, -141.8000000000007, 30.500000000000192, 40.0000000000003, -569.1, -40.199999999999996, 40.0000000000003, 20.700000000000095, 26.400000000000084, 21.500000000000153, -43.800000000000075, 40.0000000000003, 24.600000000000055, -125.5000000000003, 40.0000000000003, -44.69999999999995, -181.7000000000007, -180.00000000000065, 10.300000000000066, -485.0, 46.300000000000395, 40.0000000000003, 47.90000000000046, -143.70000000000044, 66.10000000000036, 30.200000000000163, 42.70000000000034, 40.0000000000003, -128.3000000000003, -239.60000000000025, 5.300000000000111, -564.7, 40.0000000000003, -96.70000000000041, -495.90000000000015, -111.40000000000019, 48.10000000000043, 30.100000000000144, -3.9999999999997597, 8.100000000000103, 52.60000000000051, -475.1, 44.50000000000036, -180.00000000000068, 31.900000000000333, -17.79999999999996, -158.00000000000054, -70.19999999999982, -28.89999999999973, 3.1000000000001804, 53.50000000000052, 31.200000000000166, 44.50000000000036, -180.00000000000068, 20.000000000000014, 53.500000000000526, -107.10000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -5.199999999999948, -301.00000000000017, 27.20000000000013, 34.40000000000026, -240.40000000000043, 33.50000000000024, 20.000000000000014, 32.60000000000023, 20.000000000000014, -354.7, 20.000000000000014, 20.000000000000014, -24.099999999999753, 20.000000000000014, -339.1, 20.000000000000014, -400.0, -400.0, 20.000000000000014, -323.5, -334.3, -400.0, -376.0, 1.0999999999999865, -310.60000000000014, -334.9, -240.4, 34.400000000000254, 28.100000000000147, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 35.300000000000246, 20.000000000000014, 20.000000000000014, -171.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -50.199999999999775, -150.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, -82.90000000000036, -400.0, -342.4, -7.299999999999891, -173.20000000000002, 37.10000000000024, 20.000000000000014, -179.50000000000017, -271.9, 28.100000000000147, -15.699999999999747, -330.7, -351.7, -351.7, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -315.9999999999994, 35.30000000000025, -64.00000000000031, 20.000000000000014, -358.9, -247.30000000000007, 20.000000000000014, 20.000000000000014, 20.000000000000014, -82.90000000000032, -381.7, -400.0, -383.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, -332.7999999999995, -400.0, 33.50000000000024, 20.000000000000014, 20.000000000000014, -382.0, -381.1, -28.299999999999756, -88.90000000000003, 20.000000000000014, 20.000000000000014, -347.8, 33.50000000000024, 21.80000000000004, -9.399999999999855, -23.49999999999997, 20.000000000000014, -19.59999999999997, -68.19999999999978, 20.000000000000014, 20.000000000000014, -5.199999999999937, 15.799999999999963, -334.0, 33.50000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, -141.70000000000067, -388.9, 3.199999999999967, 20.000000000000014, -400.0, -36.699999999999754, 20.000000000000014, -316.9, -339.1, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, -334.0, 5.299999999999965, 31.700000000000212, 34.40000000000025, 34.40000000000026, -26.199999999999747, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, -276.1, -5.1999999999999265, -345.4, -68.20000000000005, -25.59999999999998, -3.0999999999999757, -372.7, -388.0, 20.000000000000014, 20.000000000000014, 35.30000000000026, -367.0, -334.90000000000015, -355.0, -248.7999999999999, 7.399999999999967, 20.000000000000014, 28.100000000000147, 3.1999999999999615, 17.899999999999988, -64.00000000000085, 20.000000000000014, 20.000000000000014, -40.89999999999976, 20.000000000000014, 32.60000000000023, -311.8, -337.29999999999995, 20.000000000000014, 24.50000000000008, -400.0, 20.000000000000014, 14.899999999999965, -1.0, -3.0999999999999615, -57.70000000000003, -358.0, 20.000000000000014, 20.000000000000014, -200.2000000000003, 20.000000000000014, -118.89999999999996, -68.20000000000043, 26.300000000000114, 20.000000000000014, 33.50000000000024, 20.000000000000014, 3.1999999999999615, 24.50000000000008, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.000000000000014, 25.400000000000098, 28.100000000000147, 20.000000000000014, -273.1000000000002], "policy_predator_policy_reward": [12.0, 0.0, 158.0, 35.0, 0.0, 124.0, 0.0, 0.0, 0.0, 0.0, 163.0, 181.0, 0.0, 21.0, 0.0, 177.0, 200.0, 0.0, 189.0, 132.0, 179.0, 0.0, 200.0, 159.0, 9.0, 163.0, 178.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 91.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 81.0, 0.0, 0.0, 6.0, 0.0, 193.0, 173.0, 13.0, 179.0, 92.0, 0.0, 2.0, 93.0, 139.0, 0.0, 17.0, 167.0, 168.0, 177.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 160.0, 13.0, 37.0, 186.0, 185.0, 129.0, 0.0, 0.0, 0.0, 193.0, 66.0, 0.0, 200.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 171.0, 0.0, 200.0, 197.0, 0.0, 0.0, 0.0, 194.0, 0.0, 77.0, 0.0, 0.0, 158.0, 177.0, 14.0, 0.0, 1.0, 24.0, 0.0, 44.0, 0.0, 0.0, 14.0, 0.0, 175.0, 0.0, 0.0, 0.0, 0.0, 77.0, 8.0, 196.0, 0.0, 200.0, 27.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 178.0, 7.0, 0.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 0.0, 12.0, 141.0, 0.0, 174.0, 34.0, 0.0, 196.0, 0.0, 0.0, 0.0, 46.0, 189.0, 194.0, 0.0, 130.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 40.0, 10.0, 19.0, 0.0, 0.0, 0.0, 174.0, 0.0, 0.0, 200.0, 0.0, 0.0, 18.0, 43.0, 0.0, 0.0, 180.0, 110.0, 0.0, 0.0, 70.0, 45.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 200.0, 0.0, 200.0, 200.0, 0.0, 0.0, 145.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4158688161494095, "mean_inference_ms": 4.025612198460346, "mean_action_processing_ms": 0.6223429668648766, "mean_env_wait_ms": 0.8608716417335311, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005133867263793945, "StateBufferConnector_ms": 0.00637054443359375, "ViewRequirementAgentConnector_ms": 0.29081153869628906}, "num_episodes": 23, "episode_return_max": 66.10000000000036, "episode_return_min": -583.2, "episode_return_mean": -70.68699999999997, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 232.9182835805303, "num_env_steps_trained_throughput_per_sec": 232.9182835805303, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 19556.478, "restore_workers_time_ms": 0.018, "training_step_time_ms": 19556.415, "sample_time_ms": 4803.279, "learn_time_ms": 14725.294, "learn_throughput": 271.641, "synch_weights_time_ms": 22.987}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "c52aa_00000", "date": "2024-08-13_00-14-09", "timestamp": 1723522449, "time_this_iter_s": 17.275533199310303, "time_total_s": 1572.4851579666138, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3accf1160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1572.4851579666138, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 86.95599999999999, "ram_util_percent": 83.552}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3595378385511814, "cur_kl_coeff": 0.0012514114379882815, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.464586745494257, "policy_loss": -0.000270525626493273, "vf_loss": 5.464851504154306, "vf_explained_var": -0.007614732040930047, "kl": 0.0046032939444923945, "entropy": 0.6427231261969875, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8139395538224745, "cur_kl_coeff": 0.0001042842864990234, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.5610541958026785, "policy_loss": -0.002290147621918805, "vf_loss": 4.563343935038047, "vf_explained_var": 0.005173207527745968, "kl": 0.003852939822597751, "entropy": 0.45224572782794004, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 67.90000000000023, "episode_reward_min": -583.2, "episode_reward_mean": -75.46799999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 37.10000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -87.45399999999998, "predator_policy": 49.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-60.09999999999989, 40.0000000000003, 5.799999999999997, -49.09999999999987, 40.0000000000003, 33.400000000000205, -116.90000000000028, -157.70000000000053, -44.099999999999696, -64.49999999999986, -104.80000000000015, -162.40000000000055, -358.4, 36.50000000000025, 40.0000000000003, 40.0000000000003, -136.00000000000074, 21.300000000000104, 32.100000000000215, -98.30000000000015, 40.0000000000003, -205.6000000000004, -583.2, 40.0000000000003, 16.899999999999938, 40.0000000000003, -141.8000000000007, 30.500000000000192, 40.0000000000003, -569.1, -40.199999999999996, 40.0000000000003, 20.700000000000095, 26.400000000000084, 21.500000000000153, -43.800000000000075, 40.0000000000003, 24.600000000000055, -125.5000000000003, 40.0000000000003, -44.69999999999995, -181.7000000000007, -180.00000000000065, 10.300000000000066, -485.0, 46.300000000000395, 40.0000000000003, 47.90000000000046, -143.70000000000044, 66.10000000000036, 30.200000000000163, 42.70000000000034, 40.0000000000003, -128.3000000000003, -239.60000000000025, 5.300000000000111, -564.7, 40.0000000000003, -96.70000000000041, -495.90000000000015, -111.40000000000019, 48.10000000000043, 30.100000000000144, -3.9999999999997597, 8.100000000000103, 52.60000000000051, -475.1, 44.50000000000036, -180.00000000000068, 31.900000000000333, -17.79999999999996, -158.00000000000054, -70.19999999999982, -28.89999999999973, 3.1000000000001804, 53.50000000000052, 31.200000000000166, 44.50000000000036, -180.00000000000068, 20.000000000000014, 53.500000000000526, -107.10000000000048, 67.90000000000023, -183.9999999999999, -147.3000000000005, -115.10000000000016, -128.50000000000028, -317.59999999999997, 40.0000000000003, 35.60000000000029, -425.0, 10.10000000000043, -180.00000000000068, -49.09999999999987, -90.39999999999965, 40.0000000000003, -166.80000000000058, -564.0, 45.40000000000038, 36.700000000000294], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -171.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, -50.199999999999775, -150.10000000000002, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, -82.90000000000036, -400.0, -342.4, -7.299999999999891, -173.20000000000002, 37.10000000000024, 20.000000000000014, -179.50000000000017, -271.9, 28.100000000000147, -15.699999999999747, -330.7, -351.7, -351.7, 20.000000000000014, 9.499999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -315.9999999999994, 35.30000000000025, -64.00000000000031, 20.000000000000014, -358.9, -247.30000000000007, 20.000000000000014, 20.000000000000014, 20.000000000000014, -82.90000000000032, -381.7, -400.0, -383.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, -332.7999999999995, -400.0, 33.50000000000024, 20.000000000000014, 20.000000000000014, -382.0, -381.1, -28.299999999999756, -88.90000000000003, 20.000000000000014, 20.000000000000014, -347.8, 33.50000000000024, 21.80000000000004, -9.399999999999855, -23.49999999999997, 20.000000000000014, -19.59999999999997, -68.19999999999978, 20.000000000000014, 20.000000000000014, -5.199999999999937, 15.799999999999963, -334.0, 33.50000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, -141.70000000000067, -388.9, 3.199999999999967, 20.000000000000014, -400.0, -36.699999999999754, 20.000000000000014, -316.9, -339.1, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, -334.0, 5.299999999999965, 31.700000000000212, 34.40000000000025, 34.40000000000026, -26.199999999999747, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, -276.1, -5.1999999999999265, -345.4, -68.20000000000005, -25.59999999999998, -3.0999999999999757, -372.7, -388.0, 20.000000000000014, 20.000000000000014, 35.30000000000026, -367.0, -334.90000000000015, -355.0, -248.7999999999999, 7.399999999999967, 20.000000000000014, 28.100000000000147, 3.1999999999999615, 17.899999999999988, -64.00000000000085, 20.000000000000014, 20.000000000000014, -40.89999999999976, 20.000000000000014, 32.60000000000023, -311.8, -337.29999999999995, 20.000000000000014, 24.50000000000008, -400.0, 20.000000000000014, 14.899999999999965, -1.0, -3.0999999999999615, -57.70000000000003, -358.0, 20.000000000000014, 20.000000000000014, -200.2000000000003, 20.000000000000014, -118.89999999999996, -68.20000000000043, 26.300000000000114, 20.000000000000014, 33.50000000000024, 20.000000000000014, 3.1999999999999615, 24.50000000000008, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.000000000000014, 25.400000000000098, 28.100000000000147, 20.000000000000014, -273.1000000000002, 33.50000000000024, 34.40000000000026, -127.00000000000003, -127.00000000000003, -343.3, 20.000000000000014, 20.000000000000014, -276.0999999999999, 20.90000000000003, -303.4000000000001, -358.9, -288.69999999999993, 20.000000000000014, 20.000000000000014, 11.600000000000009, 20.000000000000014, -400.0, -373.0, -79.29999999999981, 34.40000000000026, -376.9, -3.099999999999958, -150.10000000000002, 20.000000000000014, -63.99999999999991, -72.40000000000003, 20.000000000000014, 20.000000000000014, 11.599999999999964, -366.4, -370.59999999999997, -387.4, 20.000000000000014, 25.400000000000098, 20.000000000000014, 13.70000000000001], "policy_predator_policy_reward": [91.0, 0.0, 0.0, 0.0, 30.0, 6.0, 0.0, 81.0, 0.0, 0.0, 6.0, 0.0, 193.0, 173.0, 13.0, 179.0, 92.0, 0.0, 2.0, 93.0, 139.0, 0.0, 17.0, 167.0, 168.0, 177.0, 4.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 160.0, 13.0, 37.0, 186.0, 185.0, 129.0, 0.0, 0.0, 0.0, 193.0, 66.0, 0.0, 200.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 171.0, 0.0, 200.0, 197.0, 0.0, 0.0, 0.0, 194.0, 0.0, 77.0, 0.0, 0.0, 158.0, 177.0, 14.0, 0.0, 1.0, 24.0, 0.0, 44.0, 0.0, 0.0, 14.0, 0.0, 175.0, 0.0, 0.0, 0.0, 0.0, 77.0, 8.0, 196.0, 0.0, 200.0, 27.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 178.0, 7.0, 0.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 0.0, 12.0, 141.0, 0.0, 174.0, 34.0, 0.0, 196.0, 0.0, 0.0, 0.0, 46.0, 189.0, 194.0, 0.0, 130.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 40.0, 10.0, 19.0, 0.0, 0.0, 0.0, 174.0, 0.0, 0.0, 200.0, 0.0, 0.0, 18.0, 43.0, 0.0, 0.0, 180.0, 110.0, 0.0, 0.0, 70.0, 45.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 200.0, 0.0, 200.0, 200.0, 0.0, 0.0, 145.0, 1.0, 0.0, 0.0, 70.0, 0.0, 0.0, 176.0, 141.0, 0.0, 0.0, 154.0, 147.0, 183.0, 0.0, 0.0, 4.0, 0.0, 157.0, 191.0, 0.0, 55.0, 11.0, 189.0, 0.0, 81.0, 0.0, 46.0, 0.0, 0.0, 184.0, 4.0, 194.0, 0.0, 0.0, 0.0, 0.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4227192257873162, "mean_inference_ms": 4.048390707111214, "mean_action_processing_ms": 0.622509623146522, "mean_env_wait_ms": 0.8636749758855893, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005389213562011719, "StateBufferConnector_ms": 0.006106734275817871, "ViewRequirementAgentConnector_ms": 0.2140885591506958}, "num_episodes": 18, "episode_return_max": 67.90000000000023, "episode_return_min": -583.2, "episode_return_mean": -75.46799999999996, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 243.71812172201567, "num_env_steps_trained_throughput_per_sec": 243.71812172201567, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 18533.627, "restore_workers_time_ms": 0.017, "training_step_time_ms": 18533.572, "sample_time_ms": 4115.323, "learn_time_ms": 14391.036, "learn_throughput": 277.951, "synch_weights_time_ms": 22.21}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "c52aa_00000", "date": "2024-08-13_00-14-26", "timestamp": 1723522466, "time_this_iter_s": 16.48685312271118, "time_total_s": 1588.972011089325, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ac9ba040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1588.972011089325, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 85.61739130434782, "ram_util_percent": 83.4217391304348}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9464713356245762, "cur_kl_coeff": 0.0006257057189941408, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.031259234241707, "policy_loss": -0.0017890795708077137, "vf_loss": 5.03304190496919, "vf_explained_var": -0.007095342622232185, "kl": 0.01022778240038513, "entropy": 0.7151448964441894, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7850065433435024, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.57054244664611, "policy_loss": -0.003979604916706208, "vf_loss": 4.574521539450953, "vf_explained_var": 0.009234515289780955, "kl": 0.010567794608863703, "entropy": 0.49977558343498796, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 67.90000000000023, "episode_reward_min": -600.0, "episode_reward_mean": -96.16399999999994, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 35.30000000000026, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -105.23199999999999, "predator_policy": 57.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.100000000000215, -98.30000000000015, 40.0000000000003, -205.6000000000004, -583.2, 40.0000000000003, 16.899999999999938, 40.0000000000003, -141.8000000000007, 30.500000000000192, 40.0000000000003, -569.1, -40.199999999999996, 40.0000000000003, 20.700000000000095, 26.400000000000084, 21.500000000000153, -43.800000000000075, 40.0000000000003, 24.600000000000055, -125.5000000000003, 40.0000000000003, -44.69999999999995, -181.7000000000007, -180.00000000000065, 10.300000000000066, -485.0, 46.300000000000395, 40.0000000000003, 47.90000000000046, -143.70000000000044, 66.10000000000036, 30.200000000000163, 42.70000000000034, 40.0000000000003, -128.3000000000003, -239.60000000000025, 5.300000000000111, -564.7, 40.0000000000003, -96.70000000000041, -495.90000000000015, -111.40000000000019, 48.10000000000043, 30.100000000000144, -3.9999999999997597, 8.100000000000103, 52.60000000000051, -475.1, 44.50000000000036, -180.00000000000068, 31.900000000000333, -17.79999999999996, -158.00000000000054, -70.19999999999982, -28.89999999999973, 3.1000000000001804, 53.50000000000052, 31.200000000000166, 44.50000000000036, -180.00000000000068, 20.000000000000014, 53.500000000000526, -107.10000000000048, 67.90000000000023, -183.9999999999999, -147.3000000000005, -115.10000000000016, -128.50000000000028, -317.59999999999997, 40.0000000000003, 35.60000000000029, -425.0, 10.10000000000043, -180.00000000000068, -49.09999999999987, -90.39999999999965, 40.0000000000003, -166.80000000000058, -564.0, 45.40000000000038, 36.700000000000294, -23.799999999999898, 6.999999999999957, 37.80000000000025, -379.8, 4.999999999999957, 42.700000000000344, -600.0, -44.69999999999996, -361.80000000000007, -487.79999999999995, -293.70000000000005, 55.10000000000051, -381.0999999999982, 49.90000000000046, -127.20000000000098, -114.00000000000026, -368.1, -82.1000000000002], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -358.9, -247.30000000000007, 20.000000000000014, 20.000000000000014, 20.000000000000014, -82.90000000000032, -381.7, -400.0, -383.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, -24.09999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, -332.7999999999995, -400.0, 33.50000000000024, 20.000000000000014, 20.000000000000014, -382.0, -381.1, -28.299999999999756, -88.90000000000003, 20.000000000000014, 20.000000000000014, -347.8, 33.50000000000024, 21.80000000000004, -9.399999999999855, -23.49999999999997, 20.000000000000014, -19.59999999999997, -68.19999999999978, 20.000000000000014, 20.000000000000014, -5.199999999999937, 15.799999999999963, -334.0, 33.50000000000024, 20.000000000000014, 20.000000000000014, 20.000000000000014, -141.70000000000067, -388.9, 3.199999999999967, 20.000000000000014, -400.0, -36.699999999999754, 20.000000000000014, -316.9, -339.1, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, -334.0, 5.299999999999965, 31.700000000000212, 34.40000000000025, 34.40000000000026, -26.199999999999747, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, -276.1, -5.1999999999999265, -345.4, -68.20000000000005, -25.59999999999998, -3.0999999999999757, -372.7, -388.0, 20.000000000000014, 20.000000000000014, 35.30000000000026, -367.0, -334.90000000000015, -355.0, -248.7999999999999, 7.399999999999967, 20.000000000000014, 28.100000000000147, 3.1999999999999615, 17.899999999999988, -64.00000000000085, 20.000000000000014, 20.000000000000014, -40.89999999999976, 20.000000000000014, 32.60000000000023, -311.8, -337.29999999999995, 20.000000000000014, 24.50000000000008, -400.0, 20.000000000000014, 14.899999999999965, -1.0, -3.0999999999999615, -57.70000000000003, -358.0, 20.000000000000014, 20.000000000000014, -200.2000000000003, 20.000000000000014, -118.89999999999996, -68.20000000000043, 26.300000000000114, 20.000000000000014, 33.50000000000024, 20.000000000000014, 3.1999999999999615, 24.50000000000008, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.000000000000014, 25.400000000000098, 28.100000000000147, 20.000000000000014, -273.1000000000002, 33.50000000000024, 34.40000000000026, -127.00000000000003, -127.00000000000003, -343.3, 20.000000000000014, 20.000000000000014, -276.0999999999999, 20.90000000000003, -303.4000000000001, -358.9, -288.69999999999993, 20.000000000000014, 20.000000000000014, 11.600000000000009, 20.000000000000014, -400.0, -373.0, -79.29999999999981, 34.40000000000026, -376.9, -3.099999999999958, -150.10000000000002, 20.000000000000014, -63.99999999999991, -72.40000000000003, 20.000000000000014, 20.000000000000014, 11.599999999999964, -366.4, -370.59999999999997, -387.4, 20.000000000000014, 25.400000000000098, 20.000000000000014, 13.70000000000001, 11.599999999999964, -93.40000000000003, 20.000000000000014, -400.0, 35.30000000000025, -359.5, -373.0, -395.8, -400.0, 20.000000000000014, 20.000000000000014, 22.700000000000056, -400.0, -400.0, -124.89999999999996, 3.2, -400.0, -161.7999999999999, -330.69999999999993, -339.1, -236.19999999999996, -179.5, 20.000000000000014, 34.10000000000026, -356.8, -217.30000000000047, 20.000000000000014, 29.90000000000018, -95.50000000000071, -183.7000000000003, 20.000000000000014, -274.00000000000006, -360.1, -379.0, 20.000000000000014, -213.10000000000025], "policy_predator_policy_reward": [186.0, 185.0, 129.0, 0.0, 0.0, 0.0, 193.0, 66.0, 0.0, 200.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 171.0, 0.0, 200.0, 197.0, 0.0, 0.0, 0.0, 194.0, 0.0, 77.0, 0.0, 0.0, 158.0, 177.0, 14.0, 0.0, 1.0, 24.0, 0.0, 44.0, 0.0, 0.0, 14.0, 0.0, 175.0, 0.0, 0.0, 0.0, 0.0, 77.0, 8.0, 196.0, 0.0, 200.0, 27.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 178.0, 7.0, 0.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 0.0, 12.0, 141.0, 0.0, 174.0, 34.0, 0.0, 196.0, 0.0, 0.0, 0.0, 46.0, 189.0, 194.0, 0.0, 130.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 40.0, 10.0, 19.0, 0.0, 0.0, 0.0, 174.0, 0.0, 0.0, 200.0, 0.0, 0.0, 18.0, 43.0, 0.0, 0.0, 180.0, 110.0, 0.0, 0.0, 70.0, 45.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 200.0, 0.0, 200.0, 200.0, 0.0, 0.0, 145.0, 1.0, 0.0, 0.0, 70.0, 0.0, 0.0, 176.0, 141.0, 0.0, 0.0, 154.0, 147.0, 183.0, 0.0, 0.0, 4.0, 0.0, 157.0, 191.0, 0.0, 55.0, 11.0, 189.0, 0.0, 81.0, 0.0, 46.0, 0.0, 0.0, 184.0, 4.0, 194.0, 0.0, 0.0, 0.0, 0.0, 3.0, 54.0, 4.0, 200.0, 187.0, 183.0, 179.0, 198.0, 191.0, 185.0, 200.0, 0.0, 0.0, 200.0, 0.0, 0.0, 77.0, 0.0, 200.0, 179.0, 3.0, 9.0, 113.0, 0.0, 1.0, 0.0, 193.0, 0.0, 0.0, 97.0, 55.0, 0.0, 140.0, 190.0, 181.0, 111.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4221251160323558, "mean_inference_ms": 4.046955594062971, "mean_action_processing_ms": 0.6212299733200652, "mean_env_wait_ms": 0.8630307167729544, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008621573448181152, "StateBufferConnector_ms": 0.004047989845275879, "ViewRequirementAgentConnector_ms": 0.20890724658966064}, "num_episodes": 18, "episode_return_max": 67.90000000000023, "episode_return_min": -600.0, "episode_return_mean": -96.16399999999994, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 233.28441427107686, "num_env_steps_trained_throughput_per_sec": 233.28441427107686, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 18369.632, "restore_workers_time_ms": 0.016, "training_step_time_ms": 18369.578, "sample_time_ms": 3835.916, "learn_time_ms": 14504.7, "learn_throughput": 275.773, "synch_weights_time_ms": 23.198}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "c52aa_00000", "date": "2024-08-13_00-14-43", "timestamp": 1723522483, "time_this_iter_s": 17.250439167022705, "time_total_s": 1606.2224502563477, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ace96ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1606.2224502563477, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 87.99166666666667, "ram_util_percent": 83.58333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8024480761240714, "cur_kl_coeff": 0.0006257057189941408, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.085099544096245, "policy_loss": -0.0006252776333697574, "vf_loss": 4.08572282097327, "vf_explained_var": -0.008442379589434024, "kl": 0.0032042182389227913, "entropy": 0.7286005937233173, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.82241388974051, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.790716063030183, "policy_loss": -0.0035209772386464964, "vf_loss": 4.794236596299227, "vf_explained_var": 0.01096245249112447, "kl": 0.007845954881177532, "entropy": 0.48163166719454303, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 67.90000000000023, "episode_reward_min": -600.0, "episode_reward_mean": -97.17399999999992, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 39.800000000000246, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -108.54699999999997, "predator_policy": 59.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.69999999999995, -181.7000000000007, -180.00000000000065, 10.300000000000066, -485.0, 46.300000000000395, 40.0000000000003, 47.90000000000046, -143.70000000000044, 66.10000000000036, 30.200000000000163, 42.70000000000034, 40.0000000000003, -128.3000000000003, -239.60000000000025, 5.300000000000111, -564.7, 40.0000000000003, -96.70000000000041, -495.90000000000015, -111.40000000000019, 48.10000000000043, 30.100000000000144, -3.9999999999997597, 8.100000000000103, 52.60000000000051, -475.1, 44.50000000000036, -180.00000000000068, 31.900000000000333, -17.79999999999996, -158.00000000000054, -70.19999999999982, -28.89999999999973, 3.1000000000001804, 53.50000000000052, 31.200000000000166, 44.50000000000036, -180.00000000000068, 20.000000000000014, 53.500000000000526, -107.10000000000048, 67.90000000000023, -183.9999999999999, -147.3000000000005, -115.10000000000016, -128.50000000000028, -317.59999999999997, 40.0000000000003, 35.60000000000029, -425.0, 10.10000000000043, -180.00000000000068, -49.09999999999987, -90.39999999999965, 40.0000000000003, -166.80000000000058, -564.0, 45.40000000000038, 36.700000000000294, -23.799999999999898, 6.999999999999957, 37.80000000000025, -379.8, 4.999999999999957, 42.700000000000344, -600.0, -44.69999999999996, -361.80000000000007, -487.79999999999995, -293.70000000000005, 55.10000000000051, -381.0999999999982, 49.90000000000046, -127.20000000000098, -114.00000000000026, -368.1, -82.1000000000002, -21.399999999999764, -155.00000000000045, 17.30000000000031, 55.300000000000516, -383.79999999999995, -135.90000000000038, 56.200000000000514, 40.0000000000003, -0.6999999999997852, -164.60000000000062, -172.90000000000063, -192.00000000000003, 40.0000000000003, 59.80000000000051, -357.3, -164.60000000000053, 12.499999999999932, 49.30000000000026, 41.800000000000324, 49.00000000000045, -89.80000000000013, -38.999999999999744], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -141.70000000000067, -388.9, 3.199999999999967, 20.000000000000014, -400.0, -36.699999999999754, 20.000000000000014, -316.9, -339.1, 20.000000000000014, 26.300000000000114, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, -334.0, 5.299999999999965, 31.700000000000212, 34.40000000000025, 34.40000000000026, -26.199999999999747, 20.000000000000014, 22.700000000000053, 20.000000000000014, 20.000000000000014, -276.1, -5.1999999999999265, -345.4, -68.20000000000005, -25.59999999999998, -3.0999999999999757, -372.7, -388.0, 20.000000000000014, 20.000000000000014, 35.30000000000026, -367.0, -334.90000000000015, -355.0, -248.7999999999999, 7.399999999999967, 20.000000000000014, 28.100000000000147, 3.1999999999999615, 17.899999999999988, -64.00000000000085, 20.000000000000014, 20.000000000000014, -40.89999999999976, 20.000000000000014, 32.60000000000023, -311.8, -337.29999999999995, 20.000000000000014, 24.50000000000008, -400.0, 20.000000000000014, 14.899999999999965, -1.0, -3.0999999999999615, -57.70000000000003, -358.0, 20.000000000000014, 20.000000000000014, -200.2000000000003, 20.000000000000014, -118.89999999999996, -68.20000000000043, 26.300000000000114, 20.000000000000014, 33.50000000000024, 20.000000000000014, 3.1999999999999615, 24.50000000000008, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.000000000000014, 25.400000000000098, 28.100000000000147, 20.000000000000014, -273.1000000000002, 33.50000000000024, 34.40000000000026, -127.00000000000003, -127.00000000000003, -343.3, 20.000000000000014, 20.000000000000014, -276.0999999999999, 20.90000000000003, -303.4000000000001, -358.9, -288.69999999999993, 20.000000000000014, 20.000000000000014, 11.600000000000009, 20.000000000000014, -400.0, -373.0, -79.29999999999981, 34.40000000000026, -376.9, -3.099999999999958, -150.10000000000002, 20.000000000000014, -63.99999999999991, -72.40000000000003, 20.000000000000014, 20.000000000000014, 11.599999999999964, -366.4, -370.59999999999997, -387.4, 20.000000000000014, 25.400000000000098, 20.000000000000014, 13.70000000000001, 11.599999999999964, -93.40000000000003, 20.000000000000014, -400.0, 35.30000000000025, -359.5, -373.0, -395.8, -400.0, 20.000000000000014, 20.000000000000014, 22.700000000000056, -400.0, -400.0, -124.89999999999996, 3.2, -400.0, -161.7999999999999, -330.69999999999993, -339.1, -236.19999999999996, -179.5, 20.000000000000014, 34.10000000000026, -356.8, -217.30000000000047, 20.000000000000014, 29.90000000000018, -95.50000000000071, -183.7000000000003, 20.000000000000014, -274.00000000000006, -360.1, -379.0, 20.000000000000014, -213.10000000000025, -243.39999999999995, 20.000000000000014, -358.0000000000001, 20.000000000000014, 38.000000000000234, -57.699999999999974, 35.30000000000025, 20.000000000000014, -332.79999999999995, -358.0, -328.9, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, -57.70000000000004, 20.000000000000014, -370.5999999999999, 20.000000000000014, -391.6, 22.700000000000053, -82.59999999999988, -342.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.800000000000246, -400.0, -343.3, -370.6000000000001, 20.000000000000014, -41.499999999999794, 20.000000000000014, 35.30000000000026, -355.0, 21.80000000000004, 20.000000000000014, 20.000000000000014, 29.000000000000163, -227.7999999999999, 20.000000000000014, 20.000000000000014, -400.0], "policy_predator_policy_reward": [0.0, 77.0, 8.0, 196.0, 0.0, 200.0, 27.0, 0.0, 0.0, 171.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 178.0, 7.0, 0.0, 0.0, 9.0, 13.0, 0.0, 0.0, 0.0, 0.0, 12.0, 141.0, 0.0, 174.0, 34.0, 0.0, 196.0, 0.0, 0.0, 0.0, 46.0, 189.0, 194.0, 0.0, 130.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 40.0, 10.0, 19.0, 0.0, 0.0, 0.0, 174.0, 0.0, 0.0, 200.0, 0.0, 0.0, 18.0, 43.0, 0.0, 0.0, 180.0, 110.0, 0.0, 0.0, 70.0, 45.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 200.0, 0.0, 200.0, 200.0, 0.0, 0.0, 145.0, 1.0, 0.0, 0.0, 70.0, 0.0, 0.0, 176.0, 141.0, 0.0, 0.0, 154.0, 147.0, 183.0, 0.0, 0.0, 4.0, 0.0, 157.0, 191.0, 0.0, 55.0, 11.0, 189.0, 0.0, 81.0, 0.0, 46.0, 0.0, 0.0, 184.0, 4.0, 194.0, 0.0, 0.0, 0.0, 0.0, 3.0, 54.0, 4.0, 200.0, 187.0, 183.0, 179.0, 198.0, 191.0, 185.0, 200.0, 0.0, 0.0, 200.0, 0.0, 0.0, 77.0, 0.0, 200.0, 179.0, 3.0, 9.0, 113.0, 0.0, 1.0, 0.0, 193.0, 0.0, 0.0, 97.0, 55.0, 0.0, 140.0, 190.0, 181.0, 111.0, 0.0, 134.0, 68.0, 180.0, 3.0, 0.0, 37.0, 0.0, 0.0, 150.0, 157.0, 0.0, 173.0, 0.0, 0.0, 0.0, 0.0, 37.0, 0.0, 186.0, 0.0, 196.0, 0.0, 54.0, 179.0, 0.0, 0.0, 0.0, 0.0, 186.0, 200.0, 0.0, 186.0, 34.0, 0.0, 185.0, 184.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 141.0, 200.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4247608769782625, "mean_inference_ms": 4.055563694765203, "mean_action_processing_ms": 0.6210258774903342, "mean_env_wait_ms": 0.8641763374586634, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013349175453186035, "StateBufferConnector_ms": 0.01684117317199707, "ViewRequirementAgentConnector_ms": 0.32009267807006836}, "num_episodes": 22, "episode_return_max": 67.90000000000023, "episode_return_min": -600.0, "episode_return_mean": -97.17399999999992, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 190.43891148667274, "num_env_steps_trained_throughput_per_sec": 190.43891148667274, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 18725.953, "restore_workers_time_ms": 0.015, "training_step_time_ms": 18725.852, "sample_time_ms": 4073.134, "learn_time_ms": 14601.323, "learn_throughput": 273.948, "synch_weights_time_ms": 43.438}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "c52aa_00000", "date": "2024-08-13_00-15-06", "timestamp": 1723522506, "time_this_iter_s": 22.533545970916748, "time_total_s": 1628.7559962272644, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3accf1790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1628.7559962272644, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 90.80000000000001, "ram_util_percent": 83.76875}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6871327175822838, "cur_kl_coeff": 0.0003128528594970704, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.99144589535143, "policy_loss": -0.0007284699860349218, "vf_loss": 3.9921727953764496, "vf_explained_var": -0.005732825603434648, "kl": 0.004977259157053239, "entropy": 0.7043517258747545, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7946761731196332, "cur_kl_coeff": 5.21421432495117e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.22870765161262, "policy_loss": -0.0015069318660559557, "vf_loss": 3.2302144373535477, "vf_explained_var": 0.013067807312364932, "kl": 0.002594082438852469, "entropy": 0.5877041646412441, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 67.90000000000023, "episode_reward_min": -600.0, "episode_reward_mean": -96.95199999999991, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 44.30000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -111.43599999999996, "predator_policy": 62.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-96.70000000000041, -495.90000000000015, -111.40000000000019, 48.10000000000043, 30.100000000000144, -3.9999999999997597, 8.100000000000103, 52.60000000000051, -475.1, 44.50000000000036, -180.00000000000068, 31.900000000000333, -17.79999999999996, -158.00000000000054, -70.19999999999982, -28.89999999999973, 3.1000000000001804, 53.50000000000052, 31.200000000000166, 44.50000000000036, -180.00000000000068, 20.000000000000014, 53.500000000000526, -107.10000000000048, 67.90000000000023, -183.9999999999999, -147.3000000000005, -115.10000000000016, -128.50000000000028, -317.59999999999997, 40.0000000000003, 35.60000000000029, -425.0, 10.10000000000043, -180.00000000000068, -49.09999999999987, -90.39999999999965, 40.0000000000003, -166.80000000000058, -564.0, 45.40000000000038, 36.700000000000294, -23.799999999999898, 6.999999999999957, 37.80000000000025, -379.8, 4.999999999999957, 42.700000000000344, -600.0, -44.69999999999996, -361.80000000000007, -487.79999999999995, -293.70000000000005, 55.10000000000051, -381.0999999999982, 49.90000000000046, -127.20000000000098, -114.00000000000026, -368.1, -82.1000000000002, -21.399999999999764, -155.00000000000045, 17.30000000000031, 55.300000000000516, -383.79999999999995, -135.90000000000038, 56.200000000000514, 40.0000000000003, -0.6999999999997852, -164.60000000000062, -172.90000000000063, -192.00000000000003, 40.0000000000003, 59.80000000000051, -357.3, -164.60000000000053, 12.499999999999932, 49.30000000000026, 41.800000000000324, 49.00000000000045, -89.80000000000013, -38.999999999999744, 49.00000000000045, -546.9999999999998, 10.400000000000414, 50.50000000000048, -3.2999999999997307, -526.0, -202.39999999999972, -124.90000000000026, -132.1000000000007, 40.90000000000031, 40.0000000000003, -17.999999999999538, -8.599999999999872, 40.0000000000003, 8.999999999999975, -354.9, 40.0000000000003, 60.7000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [35.30000000000026, -367.0, -334.90000000000015, -355.0, -248.7999999999999, 7.399999999999967, 20.000000000000014, 28.100000000000147, 3.1999999999999615, 17.899999999999988, -64.00000000000085, 20.000000000000014, 20.000000000000014, -40.89999999999976, 20.000000000000014, 32.60000000000023, -311.8, -337.29999999999995, 20.000000000000014, 24.50000000000008, -400.0, 20.000000000000014, 14.899999999999965, -1.0, -3.0999999999999615, -57.70000000000003, -358.0, 20.000000000000014, 20.000000000000014, -200.2000000000003, 20.000000000000014, -118.89999999999996, -68.20000000000043, 26.300000000000114, 20.000000000000014, 33.50000000000024, 20.000000000000014, 3.1999999999999615, 24.50000000000008, 20.000000000000014, -400.0, 20.000000000000014, -400.0, 20.000000000000014, 25.400000000000098, 28.100000000000147, 20.000000000000014, -273.1000000000002, 33.50000000000024, 34.40000000000026, -127.00000000000003, -127.00000000000003, -343.3, 20.000000000000014, 20.000000000000014, -276.0999999999999, 20.90000000000003, -303.4000000000001, -358.9, -288.69999999999993, 20.000000000000014, 20.000000000000014, 11.600000000000009, 20.000000000000014, -400.0, -373.0, -79.29999999999981, 34.40000000000026, -376.9, -3.099999999999958, -150.10000000000002, 20.000000000000014, -63.99999999999991, -72.40000000000003, 20.000000000000014, 20.000000000000014, 11.599999999999964, -366.4, -370.59999999999997, -387.4, 20.000000000000014, 25.400000000000098, 20.000000000000014, 13.70000000000001, 11.599999999999964, -93.40000000000003, 20.000000000000014, -400.0, 35.30000000000025, -359.5, -373.0, -395.8, -400.0, 20.000000000000014, 20.000000000000014, 22.700000000000056, -400.0, -400.0, -124.89999999999996, 3.2, -400.0, -161.7999999999999, -330.69999999999993, -339.1, -236.19999999999996, -179.5, 20.000000000000014, 34.10000000000026, -356.8, -217.30000000000047, 20.000000000000014, 29.90000000000018, -95.50000000000071, -183.7000000000003, 20.000000000000014, -274.00000000000006, -360.1, -379.0, 20.000000000000014, -213.10000000000025, -243.39999999999995, 20.000000000000014, -358.0000000000001, 20.000000000000014, 38.000000000000234, -57.699999999999974, 35.30000000000025, 20.000000000000014, -332.79999999999995, -358.0, -328.9, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, -57.70000000000004, 20.000000000000014, -370.5999999999999, 20.000000000000014, -391.6, 22.700000000000053, -82.59999999999988, -342.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.800000000000246, -400.0, -343.3, -370.6000000000001, 20.000000000000014, -41.499999999999794, 20.000000000000014, 35.30000000000026, -355.0, 21.80000000000004, 20.000000000000014, 20.000000000000014, 29.000000000000163, -227.7999999999999, 20.000000000000014, 20.000000000000014, -400.0, 29.000000000000163, 20.000000000000014, -397.9, -381.0999999999998, 44.30000000000024, -82.90000000000003, 32.90000000000023, 11.599999999999964, -1.0000000000000062, -28.29999999999975, -346.0, -370.0, -138.70000000000005, -153.69999999999987, -322.3, 34.40000000000026, -324.3999999999994, 26.300000000000114, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, -15.699999999999804, -25.3, 25.400000000000098, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -367.0, -340.9, -400.0, 20.000000000000014, 20.000000000000014, 40.700000000000244, 20.000000000000014], "policy_predator_policy_reward": [46.0, 189.0, 194.0, 0.0, 130.0, 0.0, 0.0, 0.0, 1.0, 8.0, 0.0, 40.0, 10.0, 19.0, 0.0, 0.0, 0.0, 174.0, 0.0, 0.0, 200.0, 0.0, 0.0, 18.0, 43.0, 0.0, 0.0, 180.0, 110.0, 0.0, 0.0, 70.0, 45.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 200.0, 0.0, 200.0, 200.0, 0.0, 0.0, 145.0, 1.0, 0.0, 0.0, 70.0, 0.0, 0.0, 176.0, 141.0, 0.0, 0.0, 154.0, 147.0, 183.0, 0.0, 0.0, 4.0, 0.0, 157.0, 191.0, 0.0, 55.0, 11.0, 189.0, 0.0, 81.0, 0.0, 46.0, 0.0, 0.0, 184.0, 4.0, 194.0, 0.0, 0.0, 0.0, 0.0, 3.0, 54.0, 4.0, 200.0, 187.0, 183.0, 179.0, 198.0, 191.0, 185.0, 200.0, 0.0, 0.0, 200.0, 0.0, 0.0, 77.0, 0.0, 200.0, 179.0, 3.0, 9.0, 113.0, 0.0, 1.0, 0.0, 193.0, 0.0, 0.0, 97.0, 55.0, 0.0, 140.0, 190.0, 181.0, 111.0, 0.0, 134.0, 68.0, 180.0, 3.0, 0.0, 37.0, 0.0, 0.0, 150.0, 157.0, 0.0, 173.0, 0.0, 0.0, 0.0, 0.0, 37.0, 0.0, 186.0, 0.0, 196.0, 0.0, 54.0, 179.0, 0.0, 0.0, 0.0, 0.0, 186.0, 200.0, 0.0, 186.0, 34.0, 0.0, 185.0, 184.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 141.0, 200.0, 0.0, 0.0, 32.0, 200.0, 0.0, 49.0, 4.0, 2.0, 0.0, 26.0, 0.0, 190.0, 0.0, 90.0, 0.0, 163.0, 141.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 200.0, 166.0, 0.0, 0.0, 177.0, 179.0, 200.0, 186.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4281046939026618, "mean_inference_ms": 4.064852392391895, "mean_action_processing_ms": 0.620895912715892, "mean_env_wait_ms": 0.8658815801814829, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03603231906890869, "StateBufferConnector_ms": 0.016865015029907227, "ViewRequirementAgentConnector_ms": 0.28337180614471436}, "num_episodes": 18, "episode_return_max": 67.90000000000023, "episode_return_min": -600.0, "episode_return_mean": -96.95199999999991, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 200.21026043073138, "num_env_steps_trained_throughput_per_sec": 200.21026043073138, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 18568.046, "restore_workers_time_ms": 0.019, "training_step_time_ms": 18567.938, "sample_time_ms": 4365.276, "learn_time_ms": 14149.028, "learn_throughput": 282.705, "synch_weights_time_ms": 45.885}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "c52aa_00000", "date": "2024-08-13_00-15-26", "timestamp": 1723522526, "time_this_iter_s": 20.07498025894165, "time_total_s": 1648.830976486206, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3accf1dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1648.830976486206, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 90.16206896551724, "ram_util_percent": 83.29655172413793}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9473276141439638, "cur_kl_coeff": 0.0001564264297485352, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.0444240877868, "policy_loss": -0.00024561698637193155, "vf_loss": 4.0446693366166775, "vf_explained_var": -0.0033872062882418356, "kl": 0.002449955271651015, "entropy": 0.6634097416880269, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.811580109245405, "cur_kl_coeff": 2.607107162475585e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.011519039749468, "policy_loss": -0.004514124413099751, "vf_loss": 4.016032847020992, "vf_explained_var": 0.011125434517229676, "kl": 0.011923772040758094, "entropy": 0.5736071568948251, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 67.90000000000023, "episode_reward_min": -600.0, "episode_reward_mean": -102.96799999999996, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 44.30000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -117.66399999999997, "predator_policy": 66.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-107.10000000000048, 67.90000000000023, -183.9999999999999, -147.3000000000005, -115.10000000000016, -128.50000000000028, -317.59999999999997, 40.0000000000003, 35.60000000000029, -425.0, 10.10000000000043, -180.00000000000068, -49.09999999999987, -90.39999999999965, 40.0000000000003, -166.80000000000058, -564.0, 45.40000000000038, 36.700000000000294, -23.799999999999898, 6.999999999999957, 37.80000000000025, -379.8, 4.999999999999957, 42.700000000000344, -600.0, -44.69999999999996, -361.80000000000007, -487.79999999999995, -293.70000000000005, 55.10000000000051, -381.0999999999982, 49.90000000000046, -127.20000000000098, -114.00000000000026, -368.1, -82.1000000000002, -21.399999999999764, -155.00000000000045, 17.30000000000031, 55.300000000000516, -383.79999999999995, -135.90000000000038, 56.200000000000514, 40.0000000000003, -0.6999999999997852, -164.60000000000062, -172.90000000000063, -192.00000000000003, 40.0000000000003, 59.80000000000051, -357.3, -164.60000000000053, 12.499999999999932, 49.30000000000026, 41.800000000000324, 49.00000000000045, -89.80000000000013, -38.999999999999744, 49.00000000000045, -546.9999999999998, 10.400000000000414, 50.50000000000048, -3.2999999999997307, -526.0, -202.39999999999972, -124.90000000000026, -132.1000000000007, 40.90000000000031, 40.0000000000003, -17.999999999999538, -8.599999999999872, 40.0000000000003, 8.999999999999975, -354.9, 40.0000000000003, 60.7000000000005, -311.8, -165.70000000000095, -160.20000000000053, -326.29999999999995, -126.8000000000005, 54.400000000000524, 40.0000000000003, 40.0000000000003, 40.0000000000003, 58.000000000000504, -191.20000000000073, 40.0000000000003, 40.0000000000003, -302.2000000000002, -144.00000000000043, -201.50000000000134, -140.3000000000004, -156.90000000000052, -186.20000000000053, 62.50000000000053, 40.0000000000003, -40.29999999999986, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -273.1000000000002, 33.50000000000024, 34.40000000000026, -127.00000000000003, -127.00000000000003, -343.3, 20.000000000000014, 20.000000000000014, -276.0999999999999, 20.90000000000003, -303.4000000000001, -358.9, -288.69999999999993, 20.000000000000014, 20.000000000000014, 11.600000000000009, 20.000000000000014, -400.0, -373.0, -79.29999999999981, 34.40000000000026, -376.9, -3.099999999999958, -150.10000000000002, 20.000000000000014, -63.99999999999991, -72.40000000000003, 20.000000000000014, 20.000000000000014, 11.599999999999964, -366.4, -370.59999999999997, -387.4, 20.000000000000014, 25.400000000000098, 20.000000000000014, 13.70000000000001, 11.599999999999964, -93.40000000000003, 20.000000000000014, -400.0, 35.30000000000025, -359.5, -373.0, -395.8, -400.0, 20.000000000000014, 20.000000000000014, 22.700000000000056, -400.0, -400.0, -124.89999999999996, 3.2, -400.0, -161.7999999999999, -330.69999999999993, -339.1, -236.19999999999996, -179.5, 20.000000000000014, 34.10000000000026, -356.8, -217.30000000000047, 20.000000000000014, 29.90000000000018, -95.50000000000071, -183.7000000000003, 20.000000000000014, -274.00000000000006, -360.1, -379.0, 20.000000000000014, -213.10000000000025, -243.39999999999995, 20.000000000000014, -358.0000000000001, 20.000000000000014, 38.000000000000234, -57.699999999999974, 35.30000000000025, 20.000000000000014, -332.79999999999995, -358.0, -328.9, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, -57.70000000000004, 20.000000000000014, -370.5999999999999, 20.000000000000014, -391.6, 22.700000000000053, -82.59999999999988, -342.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.800000000000246, -400.0, -343.3, -370.6000000000001, 20.000000000000014, -41.499999999999794, 20.000000000000014, 35.30000000000026, -355.0, 21.80000000000004, 20.000000000000014, 20.000000000000014, 29.000000000000163, -227.7999999999999, 20.000000000000014, 20.000000000000014, -400.0, 29.000000000000163, 20.000000000000014, -397.9, -381.0999999999998, 44.30000000000024, -82.90000000000003, 32.90000000000023, 11.599999999999964, -1.0000000000000062, -28.29999999999975, -346.0, -370.0, -138.70000000000005, -153.69999999999987, -322.3, 34.40000000000026, -324.3999999999994, 26.300000000000114, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, -15.699999999999804, -25.3, 25.400000000000098, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -367.0, -340.9, -400.0, 20.000000000000014, 20.000000000000014, 40.700000000000244, 20.000000000000014, -319.0, -341.8, -328.60000000000014, -24.099999999999746, 20.000000000000014, -362.2, -312.4, -355.9, -350.8, 20.000000000000014, 32.60000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.00000000000025, -5.1999999999999265, -397.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -236.19999999999987, -382.0, -346.0, 20.000000000000014, -177.4000000000006, -129.10000000000073, -351.7, 34.400000000000254, 20.000000000000014, -355.9, -337.9, -70.30000000000051, 31.700000000000212, 30.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.3, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [145.0, 1.0, 0.0, 0.0, 70.0, 0.0, 0.0, 176.0, 141.0, 0.0, 0.0, 154.0, 147.0, 183.0, 0.0, 0.0, 4.0, 0.0, 157.0, 191.0, 0.0, 55.0, 11.0, 189.0, 0.0, 81.0, 0.0, 46.0, 0.0, 0.0, 184.0, 4.0, 194.0, 0.0, 0.0, 0.0, 0.0, 3.0, 54.0, 4.0, 200.0, 187.0, 183.0, 179.0, 198.0, 191.0, 185.0, 200.0, 0.0, 0.0, 200.0, 0.0, 0.0, 77.0, 0.0, 200.0, 179.0, 3.0, 9.0, 113.0, 0.0, 1.0, 0.0, 193.0, 0.0, 0.0, 97.0, 55.0, 0.0, 140.0, 190.0, 181.0, 111.0, 0.0, 134.0, 68.0, 180.0, 3.0, 0.0, 37.0, 0.0, 0.0, 150.0, 157.0, 0.0, 173.0, 0.0, 0.0, 0.0, 0.0, 37.0, 0.0, 186.0, 0.0, 196.0, 0.0, 54.0, 179.0, 0.0, 0.0, 0.0, 0.0, 186.0, 200.0, 0.0, 186.0, 34.0, 0.0, 185.0, 184.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 141.0, 200.0, 0.0, 0.0, 32.0, 200.0, 0.0, 49.0, 4.0, 2.0, 0.0, 26.0, 0.0, 190.0, 0.0, 90.0, 0.0, 163.0, 141.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 200.0, 166.0, 0.0, 0.0, 177.0, 179.0, 200.0, 186.0, 0.0, 0.0, 0.0, 0.0, 180.0, 169.0, 103.0, 84.0, 182.0, 0.0, 179.0, 163.0, 24.0, 180.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 199.0, 0.0, 0.0, 0.0, 0.0, 122.0, 194.0, 0.0, 182.0, 11.0, 94.0, 0.0, 177.0, 0.0, 179.0, 179.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4324627820451215, "mean_inference_ms": 4.078160653894171, "mean_action_processing_ms": 0.6212519129526641, "mean_env_wait_ms": 0.8678068048511456, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03561580181121826, "StateBufferConnector_ms": 0.016584038734436035, "ViewRequirementAgentConnector_ms": 0.3411191701889038}, "num_episodes": 23, "episode_return_max": 67.90000000000023, "episode_return_min": -600.0, "episode_return_mean": -102.96799999999996, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 237.1762655280279, "num_env_steps_trained_throughput_per_sec": 237.1762655280279, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 18169.195, "restore_workers_time_ms": 0.02, "training_step_time_ms": 18169.085, "sample_time_ms": 4172.159, "learn_time_ms": 13942.125, "learn_throughput": 286.9, "synch_weights_time_ms": 47.092}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "c52aa_00000", "date": "2024-08-13_00-15-43", "timestamp": 1723522543, "time_this_iter_s": 16.994158029556274, "time_total_s": 1665.8251345157623, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ace7c790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1665.8251345157623, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 83.10833333333333, "ram_util_percent": 82.92083333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9733821842070453, "cur_kl_coeff": 7.82132148742676e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.976260918662661, "policy_loss": -0.0007346669310536334, "vf_loss": 4.976994873228527, "vf_explained_var": -0.006181659837248464, "kl": 0.008728748173116016, "entropy": 0.6942697231731717, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0942772345725822, "cur_kl_coeff": 2.607107162475585e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.617956886846552, "policy_loss": -0.00482882526567669, "vf_loss": 5.62278538582817, "vf_explained_var": 0.01876912489139214, "kl": 0.011865316225046123, "entropy": 0.4951793078392271, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 62.50000000000053, "episode_reward_min": -600.0, "episode_reward_mean": -100.49799999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 44.30000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -121.11399999999999, "predator_policy": 70.865}, "custom_metrics": {}, "hist_stats": {"episode_reward": [36.700000000000294, -23.799999999999898, 6.999999999999957, 37.80000000000025, -379.8, 4.999999999999957, 42.700000000000344, -600.0, -44.69999999999996, -361.80000000000007, -487.79999999999995, -293.70000000000005, 55.10000000000051, -381.0999999999982, 49.90000000000046, -127.20000000000098, -114.00000000000026, -368.1, -82.1000000000002, -21.399999999999764, -155.00000000000045, 17.30000000000031, 55.300000000000516, -383.79999999999995, -135.90000000000038, 56.200000000000514, 40.0000000000003, -0.6999999999997852, -164.60000000000062, -172.90000000000063, -192.00000000000003, 40.0000000000003, 59.80000000000051, -357.3, -164.60000000000053, 12.499999999999932, 49.30000000000026, 41.800000000000324, 49.00000000000045, -89.80000000000013, -38.999999999999744, 49.00000000000045, -546.9999999999998, 10.400000000000414, 50.50000000000048, -3.2999999999997307, -526.0, -202.39999999999972, -124.90000000000026, -132.1000000000007, 40.90000000000031, 40.0000000000003, -17.999999999999538, -8.599999999999872, 40.0000000000003, 8.999999999999975, -354.9, 40.0000000000003, 60.7000000000005, -311.8, -165.70000000000095, -160.20000000000053, -326.29999999999995, -126.8000000000005, 54.400000000000524, 40.0000000000003, 40.0000000000003, 40.0000000000003, 58.000000000000504, -191.20000000000073, 40.0000000000003, 40.0000000000003, -302.2000000000002, -144.00000000000043, -201.50000000000134, -140.3000000000004, -156.90000000000052, -186.20000000000053, 62.50000000000053, 40.0000000000003, -40.29999999999986, 40.0000000000003, 42.70000000000034, -13.899999999999931, -114.00000000000026, 0.5999999999999792, -122.6000000000003, -295.69999999999936, -172.00000000000068, -219.6000000000008, 40.0000000000003, -346.00000000000034, -321.2, 14.299999999999981, -7.899999999999878, -44.599999999999895, -167.90000000000057, -176.00000000000065, -139.50000000000028, 54.400000000000496], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 13.70000000000001, 11.599999999999964, -93.40000000000003, 20.000000000000014, -400.0, 35.30000000000025, -359.5, -373.0, -395.8, -400.0, 20.000000000000014, 20.000000000000014, 22.700000000000056, -400.0, -400.0, -124.89999999999996, 3.2, -400.0, -161.7999999999999, -330.69999999999993, -339.1, -236.19999999999996, -179.5, 20.000000000000014, 34.10000000000026, -356.8, -217.30000000000047, 20.000000000000014, 29.90000000000018, -95.50000000000071, -183.7000000000003, 20.000000000000014, -274.00000000000006, -360.1, -379.0, 20.000000000000014, -213.10000000000025, -243.39999999999995, 20.000000000000014, -358.0000000000001, 20.000000000000014, 38.000000000000234, -57.699999999999974, 35.30000000000025, 20.000000000000014, -332.79999999999995, -358.0, -328.9, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, -57.70000000000004, 20.000000000000014, -370.5999999999999, 20.000000000000014, -391.6, 22.700000000000053, -82.59999999999988, -342.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.800000000000246, -400.0, -343.3, -370.6000000000001, 20.000000000000014, -41.499999999999794, 20.000000000000014, 35.30000000000026, -355.0, 21.80000000000004, 20.000000000000014, 20.000000000000014, 29.000000000000163, -227.7999999999999, 20.000000000000014, 20.000000000000014, -400.0, 29.000000000000163, 20.000000000000014, -397.9, -381.0999999999998, 44.30000000000024, -82.90000000000003, 32.90000000000023, 11.599999999999964, -1.0000000000000062, -28.29999999999975, -346.0, -370.0, -138.70000000000005, -153.69999999999987, -322.3, 34.40000000000026, -324.3999999999994, 26.300000000000114, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, -15.699999999999804, -25.3, 25.400000000000098, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -367.0, -340.9, -400.0, 20.000000000000014, 20.000000000000014, 40.700000000000244, 20.000000000000014, -319.0, -341.8, -328.60000000000014, -24.099999999999746, 20.000000000000014, -362.2, -312.4, -355.9, -350.8, 20.000000000000014, 32.60000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.00000000000025, -5.1999999999999265, -397.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -236.19999999999987, -382.0, -346.0, 20.000000000000014, -177.4000000000006, -129.10000000000073, -351.7, 34.400000000000254, 20.000000000000014, -355.9, -337.9, -70.30000000000051, 31.700000000000212, 30.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.3, 20.000000000000014, 20.000000000000014, 22.700000000000053, 20.000000000000014, -229.9, 20.000000000000014, -76.30000000000078, -204.6999999999999, -366.4, 20.000000000000014, 29.000000000000163, -307.6, -208.90000000000015, -395.8, -400.0, 20.000000000000014, -397.9, -57.700000000000195, 20.000000000000014, 20.000000000000014, -311.8000000000002, -230.20000000000027, -346.6, -331.6, -32.49999999999976, 21.80000000000004, -9.399999999999855, -53.49999999999983, -331.6, 20.000000000000014, 20.000000000000014, -376.9, -394.0, 20.000000000000014, 13.699999999999964, -317.20000000000005, 34.40000000000025, 20.000000000000014], "policy_predator_policy_reward": [0.0, 3.0, 54.0, 4.0, 200.0, 187.0, 183.0, 179.0, 198.0, 191.0, 185.0, 200.0, 0.0, 0.0, 200.0, 0.0, 0.0, 77.0, 0.0, 200.0, 179.0, 3.0, 9.0, 113.0, 0.0, 1.0, 0.0, 193.0, 0.0, 0.0, 97.0, 55.0, 0.0, 140.0, 190.0, 181.0, 111.0, 0.0, 134.0, 68.0, 180.0, 3.0, 0.0, 37.0, 0.0, 0.0, 150.0, 157.0, 0.0, 173.0, 0.0, 0.0, 0.0, 0.0, 37.0, 0.0, 186.0, 0.0, 196.0, 0.0, 54.0, 179.0, 0.0, 0.0, 0.0, 0.0, 186.0, 200.0, 0.0, 186.0, 34.0, 0.0, 185.0, 184.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 141.0, 200.0, 0.0, 0.0, 32.0, 200.0, 0.0, 49.0, 4.0, 2.0, 0.0, 26.0, 0.0, 190.0, 0.0, 90.0, 0.0, 163.0, 141.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 200.0, 166.0, 0.0, 0.0, 177.0, 179.0, 200.0, 186.0, 0.0, 0.0, 0.0, 0.0, 180.0, 169.0, 103.0, 84.0, 182.0, 0.0, 179.0, 163.0, 24.0, 180.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 199.0, 0.0, 0.0, 0.0, 0.0, 122.0, 194.0, 0.0, 182.0, 11.0, 94.0, 0.0, 177.0, 0.0, 179.0, 179.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 0.0, 0.0, 0.0, 0.0, 77.0, 119.0, 0.0, 167.0, 163.0, 184.0, 156.0, 0.0, 133.0, 176.0, 8.0, 200.0, 37.0, 199.0, 0.0, 0.0, 74.0, 122.0, 176.0, 181.0, 0.0, 25.0, 55.0, 0.0, 176.0, 91.0, 0.0, 189.0, 198.0, 0.0, 3.0, 161.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4366250660415107, "mean_inference_ms": 4.090961397670298, "mean_action_processing_ms": 0.6219881425554245, "mean_env_wait_ms": 0.86987528284441, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03516674041748047, "StateBufferConnector_ms": 0.016567230224609375, "ViewRequirementAgentConnector_ms": 0.3592855930328369}, "num_episodes": 18, "episode_return_max": 62.50000000000053, "episode_return_min": -600.0, "episode_return_mean": -100.49799999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.86696684959094, "num_env_steps_trained_throughput_per_sec": 212.86696684959094, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 18075.553, "restore_workers_time_ms": 0.02, "training_step_time_ms": 18075.442, "sample_time_ms": 4012.88, "learn_time_ms": 14007.621, "learn_throughput": 285.559, "synch_weights_time_ms": 46.871}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "c52aa_00000", "date": "2024-08-13_00-16-02", "timestamp": 1723522562, "time_this_iter_s": 19.01422619819641, "time_total_s": 1684.8393607139587, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acec5550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1684.8393607139587, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 89.73333333333333, "ram_util_percent": 83.56296296296296}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0893100000287175, "cur_kl_coeff": 7.82132148742676e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.989010724314937, "policy_loss": -0.0003827548312348506, "vf_loss": 3.9893929448708025, "vf_explained_var": -0.005562580640984591, "kl": 0.0067900098928376056, "entropy": 0.6511695086640655, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5885199616746928, "cur_kl_coeff": 2.607107162475585e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8857435442152477, "policy_loss": -0.0018822663340461317, "vf_loss": 3.8876256822908997, "vf_explained_var": 0.02212628643348734, "kl": 0.006012765050347329, "entropy": 0.5484972251470758, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 62.50000000000053, "episode_reward_min": -546.9999999999998, "episode_reward_mean": -84.46699999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 44.30000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -107.42349999999999, "predator_policy": 65.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [55.300000000000516, -383.79999999999995, -135.90000000000038, 56.200000000000514, 40.0000000000003, -0.6999999999997852, -164.60000000000062, -172.90000000000063, -192.00000000000003, 40.0000000000003, 59.80000000000051, -357.3, -164.60000000000053, 12.499999999999932, 49.30000000000026, 41.800000000000324, 49.00000000000045, -89.80000000000013, -38.999999999999744, 49.00000000000045, -546.9999999999998, 10.400000000000414, 50.50000000000048, -3.2999999999997307, -526.0, -202.39999999999972, -124.90000000000026, -132.1000000000007, 40.90000000000031, 40.0000000000003, -17.999999999999538, -8.599999999999872, 40.0000000000003, 8.999999999999975, -354.9, 40.0000000000003, 60.7000000000005, -311.8, -165.70000000000095, -160.20000000000053, -326.29999999999995, -126.8000000000005, 54.400000000000524, 40.0000000000003, 40.0000000000003, 40.0000000000003, 58.000000000000504, -191.20000000000073, 40.0000000000003, 40.0000000000003, -302.2000000000002, -144.00000000000043, -201.50000000000134, -140.3000000000004, -156.90000000000052, -186.20000000000053, 62.50000000000053, 40.0000000000003, -40.29999999999986, 40.0000000000003, 42.70000000000034, -13.899999999999931, -114.00000000000026, 0.5999999999999792, -122.6000000000003, -295.69999999999936, -172.00000000000068, -219.6000000000008, 40.0000000000003, -346.00000000000034, -321.2, 14.299999999999981, -7.899999999999878, -44.599999999999895, -167.90000000000057, -176.00000000000065, -139.50000000000028, 54.400000000000496, -18.299999999999585, -176.7000000000007, 40.0000000000003, -56.899999999999984, -144.00000000000043, 57.100000000000506, -122.80000000000032, -176.70000000000064, -60.6, -44.79999999999964, -15.699999999999775, -151.00000000000048, -151.4000000000005, -38.89999999999971, 58.000000000000526, -9.499999999999641, -365.1, 4.799999999999953, 56.20000000000051, -193.20000000000078, 3.400000000000024, -79.80000000000007], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [35.30000000000025, 20.000000000000014, -332.79999999999995, -358.0, -328.9, 20.000000000000014, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, -57.70000000000004, 20.000000000000014, -370.5999999999999, 20.000000000000014, -391.6, 22.700000000000053, -82.59999999999988, -342.4, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.800000000000246, -400.0, -343.3, -370.6000000000001, 20.000000000000014, -41.499999999999794, 20.000000000000014, 35.30000000000026, -355.0, 21.80000000000004, 20.000000000000014, 20.000000000000014, 29.000000000000163, -227.7999999999999, 20.000000000000014, 20.000000000000014, -400.0, 29.000000000000163, 20.000000000000014, -397.9, -381.0999999999998, 44.30000000000024, -82.90000000000003, 32.90000000000023, 11.599999999999964, -1.0000000000000062, -28.29999999999975, -346.0, -370.0, -138.70000000000005, -153.69999999999987, -322.3, 34.40000000000026, -324.3999999999994, 26.300000000000114, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, -15.699999999999804, -25.3, 25.400000000000098, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -367.0, -340.9, -400.0, 20.000000000000014, 20.000000000000014, 40.700000000000244, 20.000000000000014, -319.0, -341.8, -328.60000000000014, -24.099999999999746, 20.000000000000014, -362.2, -312.4, -355.9, -350.8, 20.000000000000014, 32.60000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.00000000000025, -5.1999999999999265, -397.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -236.19999999999987, -382.0, -346.0, 20.000000000000014, -177.4000000000006, -129.10000000000073, -351.7, 34.400000000000254, 20.000000000000014, -355.9, -337.9, -70.30000000000051, 31.700000000000212, 30.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.3, 20.000000000000014, 20.000000000000014, 22.700000000000053, 20.000000000000014, -229.9, 20.000000000000014, -76.30000000000078, -204.6999999999999, -366.4, 20.000000000000014, 29.000000000000163, -307.6, -208.90000000000015, -395.8, -400.0, 20.000000000000014, -397.9, -57.700000000000195, 20.000000000000014, 20.000000000000014, -311.8000000000002, -230.20000000000027, -346.6, -331.6, -32.49999999999976, 21.80000000000004, -9.399999999999855, -53.49999999999983, -331.6, 20.000000000000014, 20.000000000000014, -376.9, -394.0, 20.000000000000014, 13.699999999999964, -317.20000000000005, 34.40000000000025, 20.000000000000014, 20.000000000000014, -91.3000000000007, -364.3, -9.399999999999855, 20.000000000000014, 20.000000000000014, -376.9, 20.000000000000014, 20.000000000000014, -346.0, 37.10000000000025, 20.000000000000014, -290.8, 20.000000000000014, -393.7, 20.000000000000014, -161.79999999999995, 3.200000000000003, -122.80000000000004, -12.999999999999773, -123.7, 20.000000000000014, -381.1, 37.10000000000025, -354.4, 20.000000000000014, 32.60000000000023, -173.50000000000037, 23.600000000000065, 34.40000000000026, 20.000000000000014, -74.50000000000088, -391.0, -333.1, -3.100000000000047, -3.100000000000047, 20.000000000000014, 36.20000000000025, -400.0, -5.199999999999951, -62.50000000000012, 17.899999999999988, -170.80000000000004, -21.99999999999976], "policy_predator_policy_reward": [0.0, 0.0, 150.0, 157.0, 0.0, 173.0, 0.0, 0.0, 0.0, 0.0, 37.0, 0.0, 186.0, 0.0, 196.0, 0.0, 54.0, 179.0, 0.0, 0.0, 0.0, 0.0, 186.0, 200.0, 0.0, 186.0, 34.0, 0.0, 185.0, 184.0, 0.0, 0.0, 0.0, 0.0, 118.0, 0.0, 141.0, 200.0, 0.0, 0.0, 32.0, 200.0, 0.0, 49.0, 4.0, 2.0, 0.0, 26.0, 0.0, 190.0, 0.0, 90.0, 0.0, 163.0, 141.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 200.0, 166.0, 0.0, 0.0, 177.0, 179.0, 200.0, 186.0, 0.0, 0.0, 0.0, 0.0, 180.0, 169.0, 103.0, 84.0, 182.0, 0.0, 179.0, 163.0, 24.0, 180.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 199.0, 0.0, 0.0, 0.0, 0.0, 122.0, 194.0, 0.0, 182.0, 11.0, 94.0, 0.0, 177.0, 0.0, 179.0, 179.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 0.0, 0.0, 0.0, 0.0, 77.0, 119.0, 0.0, 167.0, 163.0, 184.0, 156.0, 0.0, 133.0, 176.0, 8.0, 200.0, 37.0, 199.0, 0.0, 0.0, 74.0, 122.0, 176.0, 181.0, 0.0, 25.0, 55.0, 0.0, 176.0, 91.0, 0.0, 189.0, 198.0, 0.0, 3.0, 161.0, 0.0, 0.0, 53.0, 0.0, 183.0, 14.0, 0.0, 0.0, 189.0, 111.0, 0.0, 182.0, 0.0, 0.0, 0.0, 148.0, 197.0, 0.0, 8.0, 90.0, 68.0, 23.0, 71.0, 17.0, 3.0, 190.0, 0.0, 183.0, 102.0, 0.0, 0.0, 0.0, 0.0, 45.0, 194.0, 165.0, 11.0, 0.0, 0.0, 0.0, 200.0, 12.0, 44.0, 4.0, 109.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4429482236607751, "mean_inference_ms": 4.114252255395505, "mean_action_processing_ms": 0.6244474004584919, "mean_env_wait_ms": 0.8739244546914713, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.043424367904663086, "StateBufferConnector_ms": 0.016753673553466797, "ViewRequirementAgentConnector_ms": 0.3773115873336792}, "num_episodes": 22, "episode_return_max": 62.50000000000053, "episode_return_min": -546.9999999999998, "episode_return_mean": -84.46699999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 218.931704809689, "num_env_steps_trained_throughput_per_sec": 218.931704809689, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 18165.38, "restore_workers_time_ms": 0.02, "training_step_time_ms": 18165.269, "sample_time_ms": 4214.826, "learn_time_ms": 13895.575, "learn_throughput": 287.861, "synch_weights_time_ms": 47.523}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "c52aa_00000", "date": "2024-08-13_00-16-21", "timestamp": 1723522581, "time_this_iter_s": 18.442644357681274, "time_total_s": 1703.28200507164, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acec5f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1703.28200507164, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 87.73703703703703, "ram_util_percent": 83.42222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6895912975821861, "cur_kl_coeff": 7.82132148742676e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.015989948202063, "policy_loss": -0.0007992214464124233, "vf_loss": 5.016788846475107, "vf_explained_var": -0.006852516957691738, "kl": 0.004650210482524623, "entropy": 0.5820721693455226, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1767443450197341, "cur_kl_coeff": 2.607107162475585e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.999602411663721, "policy_loss": -0.0029530123887563904, "vf_loss": 5.002555235353096, "vf_explained_var": 0.006433336255411622, "kl": 0.008968780643791065, "entropy": 0.4309688004236373, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 62.50000000000053, "episode_reward_min": -546.9999999999998, "episode_reward_mean": -85.71300000000001, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 44.30000000000024, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -108.4465, "predator_policy": 65.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-38.999999999999744, 49.00000000000045, -546.9999999999998, 10.400000000000414, 50.50000000000048, -3.2999999999997307, -526.0, -202.39999999999972, -124.90000000000026, -132.1000000000007, 40.90000000000031, 40.0000000000003, -17.999999999999538, -8.599999999999872, 40.0000000000003, 8.999999999999975, -354.9, 40.0000000000003, 60.7000000000005, -311.8, -165.70000000000095, -160.20000000000053, -326.29999999999995, -126.8000000000005, 54.400000000000524, 40.0000000000003, 40.0000000000003, 40.0000000000003, 58.000000000000504, -191.20000000000073, 40.0000000000003, 40.0000000000003, -302.2000000000002, -144.00000000000043, -201.50000000000134, -140.3000000000004, -156.90000000000052, -186.20000000000053, 62.50000000000053, 40.0000000000003, -40.29999999999986, 40.0000000000003, 42.70000000000034, -13.899999999999931, -114.00000000000026, 0.5999999999999792, -122.6000000000003, -295.69999999999936, -172.00000000000068, -219.6000000000008, 40.0000000000003, -346.00000000000034, -321.2, 14.299999999999981, -7.899999999999878, -44.599999999999895, -167.90000000000057, -176.00000000000065, -139.50000000000028, 54.400000000000496, -18.299999999999585, -176.7000000000007, 40.0000000000003, -56.899999999999984, -144.00000000000043, 57.100000000000506, -122.80000000000032, -176.70000000000064, -60.6, -44.79999999999964, -15.699999999999775, -151.00000000000048, -151.4000000000005, -38.89999999999971, 58.000000000000526, -9.499999999999641, -365.1, 4.799999999999953, 56.20000000000051, -193.20000000000078, 3.400000000000024, -79.80000000000007, -351.00000000000045, 40.0000000000003, 6.299999999999956, -71.10000000000096, -124.20000000000033, 40.0000000000003, -228.4000000000003, 27.900000000000116, 44.50000000000036, -340.3, -60.09999999999998, -70.6999999999999, 22.400000000000023, -26.499999999999737, -384.9, 40.0000000000003, 40.0000000000003, 13.799999999999965], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -400.0, 29.000000000000163, 20.000000000000014, -397.9, -381.0999999999998, 44.30000000000024, -82.90000000000003, 32.90000000000023, 11.599999999999964, -1.0000000000000062, -28.29999999999975, -346.0, -370.0, -138.70000000000005, -153.69999999999987, -322.3, 34.40000000000026, -324.3999999999994, 26.300000000000114, 20.000000000000014, 20.90000000000003, 20.000000000000014, 20.000000000000014, -15.699999999999804, -25.3, 25.400000000000098, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -367.0, -340.9, -400.0, 20.000000000000014, 20.000000000000014, 40.700000000000244, 20.000000000000014, -319.0, -341.8, -328.60000000000014, -24.099999999999746, 20.000000000000014, -362.2, -312.4, -355.9, -350.8, 20.000000000000014, 32.60000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.00000000000025, -5.1999999999999265, -397.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -236.19999999999987, -382.0, -346.0, 20.000000000000014, -177.4000000000006, -129.10000000000073, -351.7, 34.400000000000254, 20.000000000000014, -355.9, -337.9, -70.30000000000051, 31.700000000000212, 30.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.3, 20.000000000000014, 20.000000000000014, 22.700000000000053, 20.000000000000014, -229.9, 20.000000000000014, -76.30000000000078, -204.6999999999999, -366.4, 20.000000000000014, 29.000000000000163, -307.6, -208.90000000000015, -395.8, -400.0, 20.000000000000014, -397.9, -57.700000000000195, 20.000000000000014, 20.000000000000014, -311.8000000000002, -230.20000000000027, -346.6, -331.6, -32.49999999999976, 21.80000000000004, -9.399999999999855, -53.49999999999983, -331.6, 20.000000000000014, 20.000000000000014, -376.9, -394.0, 20.000000000000014, 13.699999999999964, -317.20000000000005, 34.40000000000025, 20.000000000000014, 20.000000000000014, -91.3000000000007, -364.3, -9.399999999999855, 20.000000000000014, 20.000000000000014, -376.9, 20.000000000000014, 20.000000000000014, -346.0, 37.10000000000025, 20.000000000000014, -290.8, 20.000000000000014, -393.7, 20.000000000000014, -161.79999999999995, 3.200000000000003, -122.80000000000004, -12.999999999999773, -123.7, 20.000000000000014, -381.1, 37.10000000000025, -354.4, 20.000000000000014, 32.60000000000023, -173.50000000000037, 23.600000000000065, 34.40000000000026, 20.000000000000014, -74.50000000000088, -391.0, -333.1, -3.100000000000047, -3.100000000000047, 20.000000000000014, 36.20000000000025, -400.0, -5.199999999999951, -62.50000000000012, 17.899999999999988, -170.80000000000004, -21.99999999999976, -223.6000000000002, -261.4000000000002, 20.000000000000014, 20.000000000000014, -288.7, 20.000000000000014, -59.800000000000566, -112.30000000000044, 1.099999999999983, -289.29999999999995, 20.000000000000014, 20.000000000000014, -108.10000000000004, -364.3, -3.099999999999972, 20.000000000000014, 24.50000000000008, 20.000000000000014, -349.6, -348.7, 20.000000000000014, -171.10000000000002, -180.3999999999999, -7.299999999999894, -13.5999999999998, 20.000000000000014, -120.70000000000003, 27.20000000000013, -376.9, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -341.2], "policy_predator_policy_reward": [141.0, 200.0, 0.0, 0.0, 32.0, 200.0, 0.0, 49.0, 4.0, 2.0, 0.0, 26.0, 0.0, 190.0, 0.0, 90.0, 0.0, 163.0, 141.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 200.0, 166.0, 0.0, 0.0, 177.0, 179.0, 200.0, 186.0, 0.0, 0.0, 0.0, 0.0, 180.0, 169.0, 103.0, 84.0, 182.0, 0.0, 179.0, 163.0, 24.0, 180.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 199.0, 0.0, 0.0, 0.0, 0.0, 122.0, 194.0, 0.0, 182.0, 11.0, 94.0, 0.0, 177.0, 0.0, 179.0, 179.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 0.0, 0.0, 0.0, 0.0, 77.0, 119.0, 0.0, 167.0, 163.0, 184.0, 156.0, 0.0, 133.0, 176.0, 8.0, 200.0, 37.0, 199.0, 0.0, 0.0, 74.0, 122.0, 176.0, 181.0, 0.0, 25.0, 55.0, 0.0, 176.0, 91.0, 0.0, 189.0, 198.0, 0.0, 3.0, 161.0, 0.0, 0.0, 53.0, 0.0, 183.0, 14.0, 0.0, 0.0, 189.0, 111.0, 0.0, 182.0, 0.0, 0.0, 0.0, 148.0, 197.0, 0.0, 8.0, 90.0, 68.0, 23.0, 71.0, 17.0, 3.0, 190.0, 0.0, 183.0, 102.0, 0.0, 0.0, 0.0, 0.0, 45.0, 194.0, 165.0, 11.0, 0.0, 0.0, 0.0, 200.0, 12.0, 44.0, 4.0, 109.0, 4.0, 134.0, 0.0, 0.0, 0.0, 128.0, 147.0, 38.0, 63.0, 9.0, 155.0, 0.0, 0.0, 183.0, 61.0, 11.0, 0.0, 0.0, 0.0, 182.0, 176.0, 83.0, 8.0, 0.0, 117.0, 0.0, 16.0, 0.0, 67.0, 198.0, 194.0, 0.0, 0.0, 0.0, 0.0, 163.0, 172.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.447858913283192, "mean_inference_ms": 4.127472683887788, "mean_action_processing_ms": 0.6252467591512019, "mean_env_wait_ms": 0.8767685591633076, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.03901016712188721, "StateBufferConnector_ms": 0.018510103225708008, "ViewRequirementAgentConnector_ms": 0.3240896463394165}, "num_episodes": 18, "episode_return_max": 62.50000000000053, "episode_return_min": -546.9999999999998, "episode_return_mean": -85.71300000000001, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 246.07702362487953, "num_env_steps_trained_throughput_per_sec": 246.07702362487953, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 18159.128, "restore_workers_time_ms": 0.02, "training_step_time_ms": 18159.017, "sample_time_ms": 4332.729, "learn_time_ms": 13770.798, "learn_throughput": 290.47, "synch_weights_time_ms": 48.335}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "c52aa_00000", "date": "2024-08-13_00-16-38", "timestamp": 1723522598, "time_this_iter_s": 16.343071937561035, "time_total_s": 1719.625077009201, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3acec5940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1719.625077009201, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 83.78695652173911, "ram_util_percent": 83.2826086956522}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0075867148421744, "cur_kl_coeff": 3.91066074371338e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.424984892587813, "policy_loss": -6.964978757043364e-05, "vf_loss": 4.4250545110652055, "vf_explained_var": -0.0055693087754426175, "kl": 0.0027604658763945664, "entropy": 0.5362246574232818, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1493718195568632, "cur_kl_coeff": 2.607107162475585e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.219404933313844, "policy_loss": -0.0015905658246348144, "vf_loss": 4.220995324755472, "vf_explained_var": 0.022244983438461544, "kl": 0.007694825444819065, "entropy": 0.6011337595168875, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 70.60000000000005, "episode_reward_min": -589.5, "episode_reward_mean": -83.205, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -400.0, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 38.00000000000025, "predator_policy": 200.0}, "policy_reward_mean": {"prey_policy": -104.6575, "predator_policy": 63.055}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-126.8000000000005, 54.400000000000524, 40.0000000000003, 40.0000000000003, 40.0000000000003, 58.000000000000504, -191.20000000000073, 40.0000000000003, 40.0000000000003, -302.2000000000002, -144.00000000000043, -201.50000000000134, -140.3000000000004, -156.90000000000052, -186.20000000000053, 62.50000000000053, 40.0000000000003, -40.29999999999986, 40.0000000000003, 42.70000000000034, -13.899999999999931, -114.00000000000026, 0.5999999999999792, -122.6000000000003, -295.69999999999936, -172.00000000000068, -219.6000000000008, 40.0000000000003, -346.00000000000034, -321.2, 14.299999999999981, -7.899999999999878, -44.599999999999895, -167.90000000000057, -176.00000000000065, -139.50000000000028, 54.400000000000496, -18.299999999999585, -176.7000000000007, 40.0000000000003, -56.899999999999984, -144.00000000000043, 57.100000000000506, -122.80000000000032, -176.70000000000064, -60.6, -44.79999999999964, -15.699999999999775, -151.00000000000048, -151.4000000000005, -38.89999999999971, 58.000000000000526, -9.499999999999641, -365.1, 4.799999999999953, 56.20000000000051, -193.20000000000078, 3.400000000000024, -79.80000000000007, -351.00000000000045, 40.0000000000003, 6.299999999999956, -71.10000000000096, -124.20000000000033, 40.0000000000003, -228.4000000000003, 27.900000000000116, 44.50000000000036, -340.3, -60.09999999999998, -70.6999999999999, 22.400000000000023, -26.499999999999737, -384.9, 40.0000000000003, 40.0000000000003, 13.799999999999965, -136.6000000000004, -23.49999999999976, -589.5, 70.60000000000005, -35.80000000000002, -180.00000000000068, -140.50000000000023, 45.40000000000038, -340.3, 7.300000000000075, 29.600000000000264, -381.3, -42.499999999999886, -2.7999999999997374, 47.30000000000043, 56.2000000000005, -44.89999999999971, -536.4, -60.09999999999989, -163.10000000000008, 3.600000000000304, 51.70000000000049, 36.70000000000025], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-350.8, 20.000000000000014, 32.60000000000023, 21.80000000000004, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.00000000000025, -5.1999999999999265, -397.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -236.19999999999987, -382.0, -346.0, 20.000000000000014, -177.4000000000006, -129.10000000000073, -351.7, 34.400000000000254, 20.000000000000014, -355.9, -337.9, -70.30000000000051, 31.700000000000212, 30.800000000000196, 20.000000000000014, 20.000000000000014, 20.000000000000014, -133.3, 20.000000000000014, 20.000000000000014, 22.700000000000053, 20.000000000000014, -229.9, 20.000000000000014, -76.30000000000078, -204.6999999999999, -366.4, 20.000000000000014, 29.000000000000163, -307.6, -208.90000000000015, -395.8, -400.0, 20.000000000000014, -397.9, -57.700000000000195, 20.000000000000014, 20.000000000000014, -311.8000000000002, -230.20000000000027, -346.6, -331.6, -32.49999999999976, 21.80000000000004, -9.399999999999855, -53.49999999999983, -331.6, 20.000000000000014, 20.000000000000014, -376.9, -394.0, 20.000000000000014, 13.699999999999964, -317.20000000000005, 34.40000000000025, 20.000000000000014, 20.000000000000014, -91.3000000000007, -364.3, -9.399999999999855, 20.000000000000014, 20.000000000000014, -376.9, 20.000000000000014, 20.000000000000014, -346.0, 37.10000000000025, 20.000000000000014, -290.8, 20.000000000000014, -393.7, 20.000000000000014, -161.79999999999995, 3.200000000000003, -122.80000000000004, -12.999999999999773, -123.7, 20.000000000000014, -381.1, 37.10000000000025, -354.4, 20.000000000000014, 32.60000000000023, -173.50000000000037, 23.600000000000065, 34.40000000000026, 20.000000000000014, -74.50000000000088, -391.0, -333.1, -3.100000000000047, -3.100000000000047, 20.000000000000014, 36.20000000000025, -400.0, -5.199999999999951, -62.50000000000012, 17.899999999999988, -170.80000000000004, -21.99999999999976, -223.6000000000002, -261.4000000000002, 20.000000000000014, 20.000000000000014, -288.7, 20.000000000000014, -59.800000000000566, -112.30000000000044, 1.099999999999983, -289.29999999999995, 20.000000000000014, 20.000000000000014, -108.10000000000004, -364.3, -3.099999999999972, 20.000000000000014, 24.50000000000008, 20.000000000000014, -349.6, -348.7, 20.000000000000014, -171.10000000000002, -180.3999999999999, -7.299999999999894, -13.5999999999998, 20.000000000000014, -120.70000000000003, 27.20000000000013, -376.9, -400.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -341.2, -328.6, 20.000000000000014, -400.0, -11.499999999999837, -389.5, -400.0, 34.40000000000026, 36.20000000000025, -70.59999999999997, -47.19999999999978, -400.0, 20.000000000000014, -330.7, 12.200000000000244, 20.000000000000014, 25.400000000000098, -343.3, -355.0, -213.10000000000045, 34.40000000000025, -13.600000000000039, 27.20000000000013, -333.7, -391.6, -137.50000000000003, 20.000000000000014, -47.19999999999977, 7.399999999999965, 34.400000000000254, -87.10000000000004, 36.200000000000244, 20.000000000000014, -151.89999999999992, 20.000000000000014, -400.0, -336.4, 20.000000000000014, -171.10000000000002, -215.50000000000006, -139.60000000000002, -54.399999999999956, 20.000000000000014, 31.700000000000212, 20.000000000000014, 13.699999999999964, 20.000000000000014], "policy_predator_policy_reward": [24.0, 180.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 199.0, 0.0, 0.0, 0.0, 0.0, 122.0, 194.0, 0.0, 182.0, 11.0, 94.0, 0.0, 177.0, 0.0, 179.0, 179.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 0.0, 0.0, 0.0, 0.0, 77.0, 119.0, 0.0, 167.0, 163.0, 184.0, 156.0, 0.0, 133.0, 176.0, 8.0, 200.0, 37.0, 199.0, 0.0, 0.0, 74.0, 122.0, 176.0, 181.0, 0.0, 25.0, 55.0, 0.0, 176.0, 91.0, 0.0, 189.0, 198.0, 0.0, 3.0, 161.0, 0.0, 0.0, 53.0, 0.0, 183.0, 14.0, 0.0, 0.0, 189.0, 111.0, 0.0, 182.0, 0.0, 0.0, 0.0, 148.0, 197.0, 0.0, 8.0, 90.0, 68.0, 23.0, 71.0, 17.0, 3.0, 190.0, 0.0, 183.0, 102.0, 0.0, 0.0, 0.0, 0.0, 45.0, 194.0, 165.0, 11.0, 0.0, 0.0, 0.0, 200.0, 12.0, 44.0, 4.0, 109.0, 4.0, 134.0, 0.0, 0.0, 0.0, 128.0, 147.0, 38.0, 63.0, 9.0, 155.0, 0.0, 0.0, 183.0, 61.0, 11.0, 0.0, 0.0, 0.0, 182.0, 176.0, 83.0, 8.0, 0.0, 117.0, 0.0, 16.0, 0.0, 67.0, 198.0, 194.0, 0.0, 0.0, 0.0, 0.0, 163.0, 172.0, 172.0, 0.0, 200.0, 188.0, 200.0, 0.0, 0.0, 0.0, 50.0, 32.0, 200.0, 0.0, 11.0, 167.0, 0.0, 0.0, 173.0, 185.0, 75.0, 111.0, 0.0, 16.0, 148.0, 196.0, 0.0, 75.0, 37.0, 0.0, 49.0, 51.0, 0.0, 0.0, 87.0, 0.0, 200.0, 0.0, 91.0, 0.0, 76.0, 116.0, 38.0, 0.0, 0.0, 0.0, 3.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4426116973788916, "mean_inference_ms": 4.114770051423331, "mean_action_processing_ms": 0.6253149439084932, "mean_env_wait_ms": 0.8753402901378253, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0185014009475708, "StateBufferConnector_ms": 0.020091652870178223, "ViewRequirementAgentConnector_ms": 0.2979346513748169}, "num_episodes": 23, "episode_return_max": 70.60000000000005, "episode_return_min": -589.5, "episode_return_mean": -83.205, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 222.53817806385177, "num_env_steps_trained_throughput_per_sec": 222.53817806385177, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 17987.174, "restore_workers_time_ms": 0.02, "training_step_time_ms": 17987.064, "sample_time_ms": 4229.3, "learn_time_ms": 13703.233, "learn_throughput": 291.902, "synch_weights_time_ms": 48.864}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "c52aa_00000", "date": "2024-08-13_00-16-56", "timestamp": 1723522616, "time_this_iter_s": 18.083545207977295, "time_total_s": 1737.7086222171783, "pid": 40587, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3ace7c9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1737.7086222171783, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 87.37199999999999, "ram_util_percent": 83.428}}
