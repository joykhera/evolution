{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4164930564858926, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.903407829905313, "policy_loss": -0.0023103902587006805, "vf_loss": 4.904623303211555, "vf_explained_var": -0.00013256577587632276, "kl": 0.005474560128991864, "entropy": 1.604013960008268, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8213228123114695, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 8.406841030322685, "policy_loss": -0.00241876517560471, "vf_loss": 8.408161677002276, "vf_explained_var": 0.004453366395657655, "kl": 0.005490647890376953, "entropy": 1.6038559029342006, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 945.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "env_runners": {"episode_reward_max": 204.09999999999937, "episode_reward_min": -203.10000000000042, "episode_reward_mean": 19.194444444444255, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 3600, "policy_reward_min": {"prey_policy": -266.1999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.79999999999984, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -29.291666666666806, "predator_policy": 38.888888888888886}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.10000000000073, -52.8999999999996, 56.70000000000038, 144.79999999999933, 43.10000000000002, 58.69999999999966, 93.49999999999983, 116.99999999999983, 41.500000000000064, 204.09999999999937, 103.69999999999854, -42.299999999999955, -16.399999999999842, 50.29999999999951, 9.500000000000014, -32.19999999999974, -203.10000000000042, -60.399999999999686], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-242.80000000000018, -136.30000000000055, -164.50000000000054, 20.599999999999994, -91.0000000000008, 64.69999999999942, 114.49999999999986, 5.299999999999967, 40.70000000000008, -76.60000000000069, 8.000000000000004, 31.70000000000021, 27.500000000000036, 13.999999999999961, 18.50000000000006, 96.50000000000003, -97.60000000000002, -7.900000000000006, 20.29999999999999, 165.79999999999984, 20.000000000000014, 82.69999999999928, -89.50000000000009, -59.79999999999999, 67.70000000000007, -195.10000000000036, -24.400000000000066, 7.700000000000072, 25.400000000000006, -61.900000000000006, -112.3000000000004, -19.900000000000013, -82.90000000000033, -266.1999999999994, 20.000000000000014, -177.40000000000038], "policy_predator_policy_reward": [96.0, 113.0, 42.0, 49.0, 25.0, 58.0, 12.0, 13.0, 4.0, 75.0, 13.0, 6.0, 47.0, 5.0, 2.0, 0.0, 82.0, 65.0, 16.0, 2.0, 0.0, 1.0, 67.0, 40.0, 111.0, 0.0, 3.0, 64.0, 45.0, 1.0, 100.0, 0.0, 146.0, 0.0, 49.0, 48.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1545342192906622, "mean_inference_ms": 2.871832857178781, "mean_action_processing_ms": 0.4887093312308278, "mean_env_wait_ms": 0.7064398271665921, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006154510709974501, "StateBufferConnector_ms": 0.0037742985619439017, "ViewRequirementAgentConnector_ms": 0.15559991200764975}, "num_episodes": 18, "episode_return_max": 204.09999999999937, "episode_return_min": -203.10000000000042, "episode_return_mean": 19.194444444444255, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 249.2184968338577, "num_env_steps_trained_throughput_per_sec": 249.2184968338577, "timesteps_total": 4000, "num_env_steps_sampled_lifetime": 4000, "num_agent_steps_sampled_lifetime": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 16050.181, "restore_workers_time_ms": 0.018, "training_step_time_ms": 16049.312, "sample_time_ms": 2483.253, "learn_time_ms": 13517.945, "learn_throughput": 295.903, "synch_weights_time_ms": 36.771}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "training_iteration": 1, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-52-18", "timestamp": 1723521138, "time_this_iter_s": 16.173673152923584, "time_total_s": 16.173673152923584, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28419d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 16.173673152923584, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 81.32608695652173, "ram_util_percent": 83.82173913043478}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2676595974654432, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.648722822199423, "policy_loss": -0.0013984709199537676, "vf_loss": 3.649576045722558, "vf_explained_var": 0.0005974838973353149, "kl": 0.0027262239383412947, "entropy": 1.6028212638128372, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7358983023141428, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.608593107657458, "policy_loss": -0.006790034711439774, "vf_loss": 7.6126325912576505, "vf_explained_var": 0.009475819774405666, "kl": 0.013752798264379987, "entropy": 1.5803295129190678, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 2835.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "env_runners": {"episode_reward_max": 204.09999999999937, "episode_reward_min": -203.10000000000042, "episode_reward_mean": 22.972222222222026, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 7200, "policy_reward_min": {"prey_policy": -266.1999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.79999999999984, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -25.18055555555565, "predator_policy": 36.666666666666664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.10000000000073, -52.8999999999996, 56.70000000000038, 144.79999999999933, 43.10000000000002, 58.69999999999966, 93.49999999999983, 116.99999999999983, 41.500000000000064, 204.09999999999937, 103.69999999999854, -42.299999999999955, -16.399999999999842, 50.29999999999951, 9.500000000000014, -32.19999999999974, -203.10000000000042, -60.399999999999686, 116.69999999999983, -43.90000000000037, 161.20000000000016, 71.79999999999912, -188.10000000000036, 42.2000000000002, 76.39999999999884, 31.800000000000153, 10.400000000000183, -41.40000000000002, -108.80000000000018, 107.29999999999926, 38.80000000000024, 33.400000000000205, -5.10000000000006, -29.400000000000908, 24.00000000000022, 184.19999999999965], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-242.80000000000018, -136.30000000000055, -164.50000000000054, 20.599999999999994, -91.0000000000008, 64.69999999999942, 114.49999999999986, 5.299999999999967, 40.70000000000008, -76.60000000000069, 8.000000000000004, 31.70000000000021, 27.500000000000036, 13.999999999999961, 18.50000000000006, 96.50000000000003, -97.60000000000002, -7.900000000000006, 20.29999999999999, 165.79999999999984, 20.000000000000014, 82.69999999999928, -89.50000000000009, -59.79999999999999, 67.70000000000007, -195.10000000000036, -24.400000000000066, 7.700000000000072, 25.400000000000006, -61.900000000000006, -112.3000000000004, -19.900000000000013, -82.90000000000033, -266.1999999999994, 20.000000000000014, -177.40000000000038, 34.70000000000016, -10.0, 32.90000000000002, -212.80000000000047, 90.80000000000005, 19.400000000000162, 114.49999999999953, -99.70000000000019, -211.0000000000002, -183.1000000000002, -32.2, -31.599999999999902, 34.999999999999545, 7.399999999999949, -36.7, 3.5000000000000706, 16.099999999999973, -36.700000000000045, -138.8, -4.599999999999897, -28.299999999999933, -197.49999999999997, 50.300000000000104, 47.000000000000234, 25.400000000000034, -10.59999999999991, 20.000000000000014, 7.399999999999965, -19.899999999999785, -26.199999999999996, -134.5000000000007, 31.099999999999966, 20.000000000000014, -57.999999999999886, 46.39999999999998, 111.7999999999996], "policy_predator_policy_reward": [96.0, 113.0, 42.0, 49.0, 25.0, 58.0, 12.0, 13.0, 4.0, 75.0, 13.0, 6.0, 47.0, 5.0, 2.0, 0.0, 82.0, 65.0, 16.0, 2.0, 0.0, 1.0, 67.0, 40.0, 111.0, 0.0, 3.0, 64.0, 45.0, 1.0, 100.0, 0.0, 146.0, 0.0, 49.0, 48.0, 42.0, 50.0, 101.0, 35.0, 12.0, 39.0, 0.0, 57.0, 92.0, 114.0, 106.0, 0.0, 34.0, 0.0, 1.0, 64.0, 27.0, 4.0, 13.0, 89.0, 34.0, 83.0, 0.0, 10.0, 24.0, 0.0, 6.0, 0.0, 20.0, 21.0, 0.0, 74.0, 24.0, 38.0, 0.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2372153395207317, "mean_inference_ms": 3.2478887933065486, "mean_action_processing_ms": 0.52146146318002, "mean_env_wait_ms": 0.7947887337027074, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008470813433329264, "StateBufferConnector_ms": 0.006266766124301487, "ViewRequirementAgentConnector_ms": 0.20646552244822183}, "num_episodes": 18, "episode_return_max": 204.09999999999937, "episode_return_min": -203.10000000000042, "episode_return_mean": 22.972222222222026, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 180.33764335862642, "num_env_steps_trained_throughput_per_sec": 180.33764335862642, "timesteps_total": 8000, "num_env_steps_sampled_lifetime": 8000, "num_agent_steps_sampled_lifetime": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 19115.467, "restore_workers_time_ms": 0.128, "training_step_time_ms": 19114.804, "sample_time_ms": 3133.68, "learn_time_ms": 15949.976, "learn_throughput": 250.784, "synch_weights_time_ms": 24.809}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "training_iteration": 2, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-52-45", "timestamp": 1723521165, "time_this_iter_s": 22.24655795097351, "time_total_s": 38.420231103897095, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28415e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 38.420231103897095, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 89.9891891891892, "ram_util_percent": 83.68108108108109}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2178000716581231, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.461155902077912, "policy_loss": -0.004107404737018798, "vf_loss": 2.464559397747908, "vf_explained_var": 0.007498641020406491, "kl": 0.007039128991336545, "entropy": 1.6001425266896605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.929132692255671, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.218727075612104, "policy_loss": -0.005535375652034033, "vf_loss": 5.221803325572342, "vf_explained_var": 0.02269191959547618, "kl": 0.012295683309877532, "entropy": 1.5855415916947462, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 4725.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "env_runners": {"episode_reward_max": 237.09999999999934, "episode_reward_min": -203.10000000000042, "episode_reward_mean": 35.79814814814791, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 10800, "policy_reward_min": {"prey_policy": -266.1999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.79999999999984, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -12.406481481481576, "predator_policy": 30.305555555555557}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.10000000000073, -52.8999999999996, 56.70000000000038, 144.79999999999933, 43.10000000000002, 58.69999999999966, 93.49999999999983, 116.99999999999983, 41.500000000000064, 204.09999999999937, 103.69999999999854, -42.299999999999955, -16.399999999999842, 50.29999999999951, 9.500000000000014, -32.19999999999974, -203.10000000000042, -60.399999999999686, 116.69999999999983, -43.90000000000037, 161.20000000000016, 71.79999999999912, -188.10000000000036, 42.2000000000002, 76.39999999999884, 31.800000000000153, 10.400000000000183, -41.40000000000002, -108.80000000000018, 107.29999999999926, 38.80000000000024, 33.400000000000205, -5.10000000000006, -29.400000000000908, 24.00000000000022, 184.19999999999965, -6.100000000000055, 96.29999999999836, 60.60000000000026, -74.49999999999983, 40.9000000000003, 66.90000000000008, 73.60000000000007, -13.899999999999888, 104.49999999999926, 90.8999999999987, 25.20000000000011, -55.600000000000364, 8.799999999999924, 114.79999999999868, 99.09999999999961, 226.0999999999994, 237.09999999999934, 11.399999999999972], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-242.80000000000018, -136.30000000000055, -164.50000000000054, 20.599999999999994, -91.0000000000008, 64.69999999999942, 114.49999999999986, 5.299999999999967, 40.70000000000008, -76.60000000000069, 8.000000000000004, 31.70000000000021, 27.500000000000036, 13.999999999999961, 18.50000000000006, 96.50000000000003, -97.60000000000002, -7.900000000000006, 20.29999999999999, 165.79999999999984, 20.000000000000014, 82.69999999999928, -89.50000000000009, -59.79999999999999, 67.70000000000007, -195.10000000000036, -24.400000000000066, 7.700000000000072, 25.400000000000006, -61.900000000000006, -112.3000000000004, -19.900000000000013, -82.90000000000033, -266.1999999999994, 20.000000000000014, -177.40000000000038, 34.70000000000016, -10.0, 32.90000000000002, -212.80000000000047, 90.80000000000005, 19.400000000000162, 114.49999999999953, -99.70000000000019, -211.0000000000002, -183.1000000000002, -32.2, -31.599999999999902, 34.999999999999545, 7.399999999999949, -36.7, 3.5000000000000706, 16.099999999999973, -36.700000000000045, -138.8, -4.599999999999897, -28.299999999999933, -197.49999999999997, 50.300000000000104, 47.000000000000234, 25.400000000000034, -10.59999999999991, 20.000000000000014, 7.399999999999965, -19.899999999999785, -26.199999999999996, -134.5000000000007, 31.099999999999966, 20.000000000000014, -57.999999999999886, 46.39999999999998, 111.7999999999996, -3.6999999999999993, -57.39999999999988, 18.199999999999992, 64.10000000000021, 74.8999999999995, -79.30000000000055, -103.60000000000008, -55.90000000000001, 20.90000000000003, 20.000000000000014, -49.90000000000035, 54.80000000000014, 51.499999999999964, 19.1, -82.90000000000038, 20.000000000000014, 14.29999999999995, 57.20000000000008, 44.90000000000017, 20.000000000000014, -27.09999999999993, 8.300000000000008, -83.50000000000048, -66.10000000000078, -13.900000000000025, -7.299999999999894, 20.000000000000014, 90.79999999999939, 30.800000000000097, 62.30000000000012, 125.89999999999998, 81.19999999999965, 124.39999999999952, 112.6999999999999, 1.0999999999999528, -33.69999999999981], "policy_predator_policy_reward": [96.0, 113.0, 42.0, 49.0, 25.0, 58.0, 12.0, 13.0, 4.0, 75.0, 13.0, 6.0, 47.0, 5.0, 2.0, 0.0, 82.0, 65.0, 16.0, 2.0, 0.0, 1.0, 67.0, 40.0, 111.0, 0.0, 3.0, 64.0, 45.0, 1.0, 100.0, 0.0, 146.0, 0.0, 49.0, 48.0, 42.0, 50.0, 101.0, 35.0, 12.0, 39.0, 0.0, 57.0, 92.0, 114.0, 106.0, 0.0, 34.0, 0.0, 1.0, 64.0, 27.0, 4.0, 13.0, 89.0, 34.0, 83.0, 0.0, 10.0, 24.0, 0.0, 6.0, 0.0, 20.0, 21.0, 0.0, 74.0, 24.0, 38.0, 0.0, 26.0, 30.0, 25.0, 5.0, 9.0, 20.0, 45.0, 22.0, 63.0, 0.0, 0.0, 36.0, 26.0, 0.0, 3.0, 49.0, 0.0, 0.0, 33.0, 16.0, 10.0, 43.0, 1.0, 0.0, 94.0, 30.0, 0.0, 4.0, 0.0, 5.0, 1.0, 2.0, 17.0, 0.0, 0.0, 27.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2634216780906427, "mean_inference_ms": 3.3315828789702686, "mean_action_processing_ms": 0.522517591368679, "mean_env_wait_ms": 0.8115793838252704, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00800137166623716, "StateBufferConnector_ms": 0.005659129884507921, "ViewRequirementAgentConnector_ms": 0.20550621880425346}, "num_episodes": 18, "episode_return_max": 237.09999999999934, "episode_return_min": -203.10000000000042, "episode_return_mean": 35.79814814814791, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 214.0423551668779, "num_env_steps_trained_throughput_per_sec": 214.0423551668779, "timesteps_total": 12000, "num_env_steps_sampled_lifetime": 12000, "num_agent_steps_sampled_lifetime": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 18972.944, "restore_workers_time_ms": 0.091, "training_step_time_ms": 18972.484, "sample_time_ms": 3027.781, "learn_time_ms": 15906.662, "learn_throughput": 251.467, "synch_weights_time_ms": 31.761}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "training_iteration": 3, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-53-03", "timestamp": 1723521183, "time_this_iter_s": 18.807301998138428, "time_total_s": 57.22753310203552, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2841430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 57.22753310203552, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 88.34814814814816, "ram_util_percent": 83.78888888888889}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2029197235764177, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.635651917432351, "policy_loss": -0.003704667711265819, "vf_loss": 3.638549630604093, "vf_explained_var": 0.002107488856744514, "kl": 0.008069576362018138, "entropy": 1.6017608101405794, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6843403322356088, "cur_kl_coeff": 0.2, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.41487739187069, "policy_loss": -0.0007055063510840887, "vf_loss": 5.414900912431182, "vf_explained_var": -0.006411765839056994, "kl": 0.0034099165774816517, "entropy": 1.595031842352852, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 6615.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "env_runners": {"episode_reward_max": 237.09999999999934, "episode_reward_min": -203.10000000000042, "episode_reward_mean": 35.356944444444224, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 14400, "policy_reward_min": {"prey_policy": -266.1999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.79999999999984, "predator_policy": 146.0}, "policy_reward_mean": {"prey_policy": -10.967361111111186, "predator_policy": 28.645833333333332}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.10000000000073, -52.8999999999996, 56.70000000000038, 144.79999999999933, 43.10000000000002, 58.69999999999966, 93.49999999999983, 116.99999999999983, 41.500000000000064, 204.09999999999937, 103.69999999999854, -42.299999999999955, -16.399999999999842, 50.29999999999951, 9.500000000000014, -32.19999999999974, -203.10000000000042, -60.399999999999686, 116.69999999999983, -43.90000000000037, 161.20000000000016, 71.79999999999912, -188.10000000000036, 42.2000000000002, 76.39999999999884, 31.800000000000153, 10.400000000000183, -41.40000000000002, -108.80000000000018, 107.29999999999926, 38.80000000000024, 33.400000000000205, -5.10000000000006, -29.400000000000908, 24.00000000000022, 184.19999999999965, -6.100000000000055, 96.29999999999836, 60.60000000000026, -74.49999999999983, 40.9000000000003, 66.90000000000008, 73.60000000000007, -13.899999999999888, 104.49999999999926, 90.8999999999987, 25.20000000000011, -55.600000000000364, 8.799999999999924, 114.79999999999868, 99.09999999999961, 226.0999999999994, 237.09999999999934, 11.399999999999972, -21.799999999999535, -89.4000000000002, 114.09999999999934, -69.10000000000053, 96.69999999999905, 18.80000000000025, 18.00000000000015, 116.99999999999983, 46.80000000000018, 60.89999999999934, -10.599999999999978, 62.300000000000395, 81.29999999999916, -29.29999999999984, 58.000000000000504, 39.60000000000044, 79.29999999999927, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-242.80000000000018, -136.30000000000055, -164.50000000000054, 20.599999999999994, -91.0000000000008, 64.69999999999942, 114.49999999999986, 5.299999999999967, 40.70000000000008, -76.60000000000069, 8.000000000000004, 31.70000000000021, 27.500000000000036, 13.999999999999961, 18.50000000000006, 96.50000000000003, -97.60000000000002, -7.900000000000006, 20.29999999999999, 165.79999999999984, 20.000000000000014, 82.69999999999928, -89.50000000000009, -59.79999999999999, 67.70000000000007, -195.10000000000036, -24.400000000000066, 7.700000000000072, 25.400000000000006, -61.900000000000006, -112.3000000000004, -19.900000000000013, -82.90000000000033, -266.1999999999994, 20.000000000000014, -177.40000000000038, 34.70000000000016, -10.0, 32.90000000000002, -212.80000000000047, 90.80000000000005, 19.400000000000162, 114.49999999999953, -99.70000000000019, -211.0000000000002, -183.1000000000002, -32.2, -31.599999999999902, 34.999999999999545, 7.399999999999949, -36.7, 3.5000000000000706, 16.099999999999973, -36.700000000000045, -138.8, -4.599999999999897, -28.299999999999933, -197.49999999999997, 50.300000000000104, 47.000000000000234, 25.400000000000034, -10.59999999999991, 20.000000000000014, 7.399999999999965, -19.899999999999785, -26.199999999999996, -134.5000000000007, 31.099999999999966, 20.000000000000014, -57.999999999999886, 46.39999999999998, 111.7999999999996, -3.6999999999999993, -57.39999999999988, 18.199999999999992, 64.10000000000021, 74.8999999999995, -79.30000000000055, -103.60000000000008, -55.90000000000001, 20.90000000000003, 20.000000000000014, -49.90000000000035, 54.80000000000014, 51.499999999999964, 19.1, -82.90000000000038, 20.000000000000014, 14.29999999999995, 57.20000000000008, 44.90000000000017, 20.000000000000014, -27.09999999999993, 8.300000000000008, -83.50000000000048, -66.10000000000078, -13.900000000000025, -7.299999999999894, 20.000000000000014, 90.79999999999939, 30.800000000000097, 62.30000000000012, 125.89999999999998, 81.19999999999965, 124.39999999999952, 112.6999999999999, 1.0999999999999528, -33.69999999999981, -7.299999999999898, -95.50000000000081, 20.000000000000014, -252.40000000000003, 13.69999999999997, 79.40000000000003, -243.10000000000002, 20.000000000000014, 39.80000000000025, 56.90000000000013, -5.200000000000051, -1.0000000000000329, 24.200000000000017, -89.19999999999985, 5.000000000000021, 74.00000000000009, -5.499999999999938, 5.299999999999969, 82.39999999999941, -101.50000000000009, 20.000000000000014, -76.60000000000022, 25.100000000000097, 36.20000000000018, 47.30000000000011, 20.000000000000014, -152.2000000000005, 29.900000000000055, 20.000000000000014, 38.00000000000022, 23.30000000000019, 5.299999999999981, 20.000000000000014, 44.300000000000125, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [96.0, 113.0, 42.0, 49.0, 25.0, 58.0, 12.0, 13.0, 4.0, 75.0, 13.0, 6.0, 47.0, 5.0, 2.0, 0.0, 82.0, 65.0, 16.0, 2.0, 0.0, 1.0, 67.0, 40.0, 111.0, 0.0, 3.0, 64.0, 45.0, 1.0, 100.0, 0.0, 146.0, 0.0, 49.0, 48.0, 42.0, 50.0, 101.0, 35.0, 12.0, 39.0, 0.0, 57.0, 92.0, 114.0, 106.0, 0.0, 34.0, 0.0, 1.0, 64.0, 27.0, 4.0, 13.0, 89.0, 34.0, 83.0, 0.0, 10.0, 24.0, 0.0, 6.0, 0.0, 20.0, 21.0, 0.0, 74.0, 24.0, 38.0, 0.0, 26.0, 30.0, 25.0, 5.0, 9.0, 20.0, 45.0, 22.0, 63.0, 0.0, 0.0, 36.0, 26.0, 0.0, 3.0, 49.0, 0.0, 0.0, 33.0, 16.0, 10.0, 43.0, 1.0, 0.0, 94.0, 30.0, 0.0, 4.0, 0.0, 5.0, 1.0, 2.0, 17.0, 0.0, 0.0, 27.0, 17.0, 33.0, 48.0, 143.0, 0.0, 15.0, 6.0, 38.0, 116.0, 0.0, 0.0, 25.0, 0.0, 52.0, 31.0, 0.0, 38.0, 31.0, 16.0, 9.0, 71.0, 46.0, 0.0, 1.0, 0.0, 14.0, 0.0, 93.0, 0.0, 0.0, 0.0, 11.0, 0.0, 11.0, 4.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2650097779471854, "mean_inference_ms": 3.348217877685786, "mean_action_processing_ms": 0.5182922593212553, "mean_env_wait_ms": 0.812947444531515, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009472833739386665, "StateBufferConnector_ms": 0.005280971527099609, "ViewRequirementAgentConnector_ms": 0.18812335199779934}, "num_episodes": 18, "episode_return_max": 237.09999999999934, "episode_return_min": -203.10000000000042, "episode_return_mean": 35.356944444444224, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 247.0918043147061, "num_env_steps_trained_throughput_per_sec": 247.0918043147061, "timesteps_total": 16000, "num_env_steps_sampled_lifetime": 16000, "num_agent_steps_sampled_lifetime": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 18276.79, "restore_workers_time_ms": 0.078, "training_step_time_ms": 18276.423, "sample_time_ms": 2894.745, "learn_time_ms": 15349.049, "learn_throughput": 260.602, "synch_weights_time_ms": 27.295}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "training_iteration": 4, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-53-20", "timestamp": 1723521200, "time_this_iter_s": 16.240535974502563, "time_total_s": 73.46806907653809, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2863a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 73.46806907653809, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 86.14782608695651, "ram_util_percent": 83.79565217391304}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.37550803707745023, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.420946670966174, "policy_loss": -0.0017807432514413324, "vf_loss": 4.42232170079751, "vf_explained_var": 0.004858011795730187, "kl": 0.004057070643383693, "entropy": 1.5929731731692318, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6918388355345952, "cur_kl_coeff": 0.1, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.21213873290511, "policy_loss": -0.00725337378532877, "vf_loss": 5.217082767764096, "vf_explained_var": 0.00011647633774570688, "kl": 0.023093532760713763, "entropy": 1.5865131533335126, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 8505.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "env_runners": {"episode_reward_max": 237.09999999999934, "episode_reward_min": -203.10000000000042, "episode_reward_mean": 23.0171717171715, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 19800, "policy_reward_min": {"prey_policy": -328.6000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 165.79999999999984, "predator_policy": 159.0}, "policy_reward_mean": {"prey_policy": -21.046969696969775, "predator_policy": 32.55555555555556}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.10000000000073, -52.8999999999996, 56.70000000000038, 144.79999999999933, 43.10000000000002, 58.69999999999966, 93.49999999999983, 116.99999999999983, 41.500000000000064, 204.09999999999937, 103.69999999999854, -42.299999999999955, -16.399999999999842, 50.29999999999951, 9.500000000000014, -32.19999999999974, -203.10000000000042, -60.399999999999686, 116.69999999999983, -43.90000000000037, 161.20000000000016, 71.79999999999912, -188.10000000000036, 42.2000000000002, 76.39999999999884, 31.800000000000153, 10.400000000000183, -41.40000000000002, -108.80000000000018, 107.29999999999926, 38.80000000000024, 33.400000000000205, -5.10000000000006, -29.400000000000908, 24.00000000000022, 184.19999999999965, -6.100000000000055, 96.29999999999836, 60.60000000000026, -74.49999999999983, 40.9000000000003, 66.90000000000008, 73.60000000000007, -13.899999999999888, 104.49999999999926, 90.8999999999987, 25.20000000000011, -55.600000000000364, 8.799999999999924, 114.79999999999868, 99.09999999999961, 226.0999999999994, 237.09999999999934, 11.399999999999972, -21.799999999999535, -89.4000000000002, 114.09999999999934, -69.10000000000053, 96.69999999999905, 18.80000000000025, 18.00000000000015, 116.99999999999983, 46.80000000000018, 60.89999999999934, -10.599999999999978, 62.300000000000395, 81.29999999999916, -29.29999999999984, 58.000000000000504, 39.60000000000044, 79.29999999999927, 40.0000000000003, -118.80000000000044, 84.49999999999896, -21.299999999999862, 49.900000000000354, 34.5000000000002, 165.29999999999922, 40.0000000000003, -136.00000000000077, 69.40000000000009, -82.40000000000046, -37.4, 38.69999999999932, 102.19999999999948, -45.19999999999979, 14.300000000000024, -104.3000000000001, 1.4999999999999976, -79.3999999999998, -103.000000000001, -107.7000000000005, -62.1000000000002, -85.20000000000007, -19.19999999999979, 106.5999999999992, 20.100000000000133, 97.79999999999953, -89.80000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-242.80000000000018, -136.30000000000055, -164.50000000000054, 20.599999999999994, -91.0000000000008, 64.69999999999942, 114.49999999999986, 5.299999999999967, 40.70000000000008, -76.60000000000069, 8.000000000000004, 31.70000000000021, 27.500000000000036, 13.999999999999961, 18.50000000000006, 96.50000000000003, -97.60000000000002, -7.900000000000006, 20.29999999999999, 165.79999999999984, 20.000000000000014, 82.69999999999928, -89.50000000000009, -59.79999999999999, 67.70000000000007, -195.10000000000036, -24.400000000000066, 7.700000000000072, 25.400000000000006, -61.900000000000006, -112.3000000000004, -19.900000000000013, -82.90000000000033, -266.1999999999994, 20.000000000000014, -177.40000000000038, 34.70000000000016, -10.0, 32.90000000000002, -212.80000000000047, 90.80000000000005, 19.400000000000162, 114.49999999999953, -99.70000000000019, -211.0000000000002, -183.1000000000002, -32.2, -31.599999999999902, 34.999999999999545, 7.399999999999949, -36.7, 3.5000000000000706, 16.099999999999973, -36.700000000000045, -138.8, -4.599999999999897, -28.299999999999933, -197.49999999999997, 50.300000000000104, 47.000000000000234, 25.400000000000034, -10.59999999999991, 20.000000000000014, 7.399999999999965, -19.899999999999785, -26.199999999999996, -134.5000000000007, 31.099999999999966, 20.000000000000014, -57.999999999999886, 46.39999999999998, 111.7999999999996, -3.6999999999999993, -57.39999999999988, 18.199999999999992, 64.10000000000021, 74.8999999999995, -79.30000000000055, -103.60000000000008, -55.90000000000001, 20.90000000000003, 20.000000000000014, -49.90000000000035, 54.80000000000014, 51.499999999999964, 19.1, -82.90000000000038, 20.000000000000014, 14.29999999999995, 57.20000000000008, 44.90000000000017, 20.000000000000014, -27.09999999999993, 8.300000000000008, -83.50000000000048, -66.10000000000078, -13.900000000000025, -7.299999999999894, 20.000000000000014, 90.79999999999939, 30.800000000000097, 62.30000000000012, 125.89999999999998, 81.19999999999965, 124.39999999999952, 112.6999999999999, 1.0999999999999528, -33.69999999999981, -7.299999999999898, -95.50000000000081, 20.000000000000014, -252.40000000000003, 13.69999999999997, 79.40000000000003, -243.10000000000002, 20.000000000000014, 39.80000000000025, 56.90000000000013, -5.200000000000051, -1.0000000000000329, 24.200000000000017, -89.19999999999985, 5.000000000000021, 74.00000000000009, -5.499999999999938, 5.299999999999969, 82.39999999999941, -101.50000000000009, 20.000000000000014, -76.60000000000022, 25.100000000000097, 36.20000000000018, 47.30000000000011, 20.000000000000014, -152.2000000000005, 29.900000000000055, 20.000000000000014, 38.00000000000022, 23.30000000000019, 5.299999999999981, 20.000000000000014, 44.300000000000125, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -277.0, 57.50000000000019, 20.000000000000014, 20.000000000000014, -103.30000000000004, 29.90000000000018, 20.000000000000014, 20.000000000000014, 9.499999999999977, 20.000000000000014, 137.29999999999998, 20.000000000000014, 20.000000000000014, -205.00000000000009, -127.00000000000074, 48.80000000000024, 14.599999999999953, -1.000000000000012, -327.39999999999986, 20.000000000000014, -282.40000000000003, -51.699999999999875, 34.40000000000019, 74.89999999999998, -48.70000000000028, 13.699999999999953, -148.9000000000003, -64.60000000000025, 17.899999999999977, -89.19999999999996, -87.10000000000005, 20.000000000000014, -80.50000000000051, -80.50000000000065, -132.8999999999999, -89.2000000000007, -143.80000000000038, -137.5000000000001, -68.20000000000039, 0.7999999999999765, -205.90000000000035, 70.39999999999998, -328.6000000000002, 20.000000000000014, -128.2000000000001, 24.500000000000096, 82.09999999999971, 35.300000000000026, -47.19999999999976, -11.800000000000008, 50.60000000000008, 9.499999999999964, -235.30000000000013], "policy_predator_policy_reward": [96.0, 113.0, 42.0, 49.0, 25.0, 58.0, 12.0, 13.0, 4.0, 75.0, 13.0, 6.0, 47.0, 5.0, 2.0, 0.0, 82.0, 65.0, 16.0, 2.0, 0.0, 1.0, 67.0, 40.0, 111.0, 0.0, 3.0, 64.0, 45.0, 1.0, 100.0, 0.0, 146.0, 0.0, 49.0, 48.0, 42.0, 50.0, 101.0, 35.0, 12.0, 39.0, 0.0, 57.0, 92.0, 114.0, 106.0, 0.0, 34.0, 0.0, 1.0, 64.0, 27.0, 4.0, 13.0, 89.0, 34.0, 83.0, 0.0, 10.0, 24.0, 0.0, 6.0, 0.0, 20.0, 21.0, 0.0, 74.0, 24.0, 38.0, 0.0, 26.0, 30.0, 25.0, 5.0, 9.0, 20.0, 45.0, 22.0, 63.0, 0.0, 0.0, 36.0, 26.0, 0.0, 3.0, 49.0, 0.0, 0.0, 33.0, 16.0, 10.0, 43.0, 1.0, 0.0, 94.0, 30.0, 0.0, 4.0, 0.0, 5.0, 1.0, 2.0, 17.0, 0.0, 0.0, 27.0, 17.0, 33.0, 48.0, 143.0, 0.0, 15.0, 6.0, 38.0, 116.0, 0.0, 0.0, 25.0, 0.0, 52.0, 31.0, 0.0, 38.0, 31.0, 16.0, 9.0, 71.0, 46.0, 0.0, 1.0, 0.0, 14.0, 0.0, 93.0, 0.0, 0.0, 0.0, 11.0, 0.0, 11.0, 4.0, 0.0, 0.0, 8.0, 147.0, 7.0, 0.0, 60.0, 2.0, 0.0, 0.0, 5.0, 0.0, 2.0, 6.0, 0.0, 0.0, 106.0, 90.0, 6.0, 0.0, 159.0, 87.0, 98.0, 127.0, 53.0, 3.0, 55.0, 21.0, 34.0, 56.0, 0.0, 61.0, 19.0, 53.0, 34.0, 28.0, 131.0, 3.0, 78.0, 52.0, 98.0, 0.0, 86.0, 57.0, 105.0, 68.0, 89.0, 0.0, 0.0, 0.0, 0.0, 32.0, 39.0, 20.0, 131.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2543474198538898, "mean_inference_ms": 3.332621240290937, "mean_action_processing_ms": 0.5123806436954619, "mean_env_wait_ms": 0.805097271864003, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009047262596361565, "StateBufferConnector_ms": 0.004920333322852549, "ViewRequirementAgentConnector_ms": 0.20830330222544044}, "num_episodes": 27, "episode_return_max": 237.09999999999934, "episode_return_min": -203.10000000000042, "episode_return_mean": 23.0171717171715, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 230.79292657744355, "num_env_steps_trained_throughput_per_sec": 230.79292657744355, "timesteps_total": 20000, "num_env_steps_sampled_lifetime": 20000, "num_agent_steps_sampled_lifetime": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 18087.745, "restore_workers_time_ms": 0.066, "training_step_time_ms": 18087.439, "sample_time_ms": 2781.179, "learn_time_ms": 15269.34, "learn_throughput": 261.963, "synch_weights_time_ms": 31.672}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "training_iteration": 5, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-53-37", "timestamp": 1723521217, "time_this_iter_s": 17.442139863967896, "time_total_s": 90.91020894050598, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28db670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 90.91020894050598, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 85.53200000000001, "ram_util_percent": 83.704}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.283722842053052, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4061416078496864, "policy_loss": -0.0008922881626637366, "vf_loss": 3.4067224612311713, "vf_explained_var": 0.0012125815348650413, "kl": 0.006228529606297718, "entropy": 1.5796394203705761, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4779579531421105, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.616773735783087, "policy_loss": -0.0017225051251925016, "vf_loss": 4.617356509506387, "vf_explained_var": 0.007415345579228073, "kl": 0.007598147949834793, "entropy": 1.5698951915458397, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 10395.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "env_runners": {"episode_reward_max": 237.09999999999934, "episode_reward_min": -188.10000000000036, "episode_reward_mean": 27.45599999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -328.6000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 149.3, "predator_policy": 159.0}, "policy_reward_mean": {"prey_policy": -17.422000000000054, "predator_policy": 31.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-60.399999999999686, 116.69999999999983, -43.90000000000037, 161.20000000000016, 71.79999999999912, -188.10000000000036, 42.2000000000002, 76.39999999999884, 31.800000000000153, 10.400000000000183, -41.40000000000002, -108.80000000000018, 107.29999999999926, 38.80000000000024, 33.400000000000205, -5.10000000000006, -29.400000000000908, 24.00000000000022, 184.19999999999965, -6.100000000000055, 96.29999999999836, 60.60000000000026, -74.49999999999983, 40.9000000000003, 66.90000000000008, 73.60000000000007, -13.899999999999888, 104.49999999999926, 90.8999999999987, 25.20000000000011, -55.600000000000364, 8.799999999999924, 114.79999999999868, 99.09999999999961, 226.0999999999994, 237.09999999999934, 11.399999999999972, -21.799999999999535, -89.4000000000002, 114.09999999999934, -69.10000000000053, 96.69999999999905, 18.80000000000025, 18.00000000000015, 116.99999999999983, 46.80000000000018, 60.89999999999934, -10.599999999999978, 62.300000000000395, 81.29999999999916, -29.29999999999984, 58.000000000000504, 39.60000000000044, 79.29999999999927, 40.0000000000003, -118.80000000000044, 84.49999999999896, -21.299999999999862, 49.900000000000354, 34.5000000000002, 165.29999999999922, 40.0000000000003, -136.00000000000077, 69.40000000000009, -82.40000000000046, -37.4, 38.69999999999932, 102.19999999999948, -45.19999999999979, 14.300000000000024, -104.3000000000001, 1.4999999999999976, -79.3999999999998, -103.000000000001, -107.7000000000005, -62.1000000000002, -85.20000000000007, -19.19999999999979, 106.5999999999992, 20.100000000000133, 97.79999999999953, -89.80000000000004, -67.2999999999999, 64.70000000000019, 34.40000000000034, 213.19999999999928, 29.80000000000013, -1.2000000000000064, 44.80000000000034, 143.4999999999988, 59.100000000000286, -97.2000000000005, 135.79999999999922, 27.00000000000026, -28.299999999999784, 142.89999999999955, 40.0000000000003, -18.499999999999773, 56.3000000000001, 93.79999999999951], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -177.40000000000038, 34.70000000000016, -10.0, 32.90000000000002, -212.80000000000047, 90.80000000000005, 19.400000000000162, 114.49999999999953, -99.70000000000019, -211.0000000000002, -183.1000000000002, -32.2, -31.599999999999902, 34.999999999999545, 7.399999999999949, -36.7, 3.5000000000000706, 16.099999999999973, -36.700000000000045, -138.8, -4.599999999999897, -28.299999999999933, -197.49999999999997, 50.300000000000104, 47.000000000000234, 25.400000000000034, -10.59999999999991, 20.000000000000014, 7.399999999999965, -19.899999999999785, -26.199999999999996, -134.5000000000007, 31.099999999999966, 20.000000000000014, -57.999999999999886, 46.39999999999998, 111.7999999999996, -3.6999999999999993, -57.39999999999988, 18.199999999999992, 64.10000000000021, 74.8999999999995, -79.30000000000055, -103.60000000000008, -55.90000000000001, 20.90000000000003, 20.000000000000014, -49.90000000000035, 54.80000000000014, 51.499999999999964, 19.1, -82.90000000000038, 20.000000000000014, 14.29999999999995, 57.20000000000008, 44.90000000000017, 20.000000000000014, -27.09999999999993, 8.300000000000008, -83.50000000000048, -66.10000000000078, -13.900000000000025, -7.299999999999894, 20.000000000000014, 90.79999999999939, 30.800000000000097, 62.30000000000012, 125.89999999999998, 81.19999999999965, 124.39999999999952, 112.6999999999999, 1.0999999999999528, -33.69999999999981, -7.299999999999898, -95.50000000000081, 20.000000000000014, -252.40000000000003, 13.69999999999997, 79.40000000000003, -243.10000000000002, 20.000000000000014, 39.80000000000025, 56.90000000000013, -5.200000000000051, -1.0000000000000329, 24.200000000000017, -89.19999999999985, 5.000000000000021, 74.00000000000009, -5.499999999999938, 5.299999999999969, 82.39999999999941, -101.50000000000009, 20.000000000000014, -76.60000000000022, 25.100000000000097, 36.20000000000018, 47.30000000000011, 20.000000000000014, -152.2000000000005, 29.900000000000055, 20.000000000000014, 38.00000000000022, 23.30000000000019, 5.299999999999981, 20.000000000000014, 44.300000000000125, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -277.0, 57.50000000000019, 20.000000000000014, 20.000000000000014, -103.30000000000004, 29.90000000000018, 20.000000000000014, 20.000000000000014, 9.499999999999977, 20.000000000000014, 137.29999999999998, 20.000000000000014, 20.000000000000014, -205.00000000000009, -127.00000000000074, 48.80000000000024, 14.599999999999953, -1.000000000000012, -327.39999999999986, 20.000000000000014, -282.40000000000003, -51.699999999999875, 34.40000000000019, 74.89999999999998, -48.70000000000028, 13.699999999999953, -148.9000000000003, -64.60000000000025, 17.899999999999977, -89.19999999999996, -87.10000000000005, 20.000000000000014, -80.50000000000051, -80.50000000000065, -132.8999999999999, -89.2000000000007, -143.80000000000038, -137.5000000000001, -68.20000000000039, 0.7999999999999765, -205.90000000000035, 70.39999999999998, -328.6000000000002, 20.000000000000014, -128.2000000000001, 24.500000000000096, 82.09999999999971, 35.300000000000026, -47.19999999999976, -11.800000000000008, 50.60000000000008, 9.499999999999964, -235.30000000000013, -129.10000000000025, -74.19999999999999, -11.499999999999819, 33.20000000000009, -36.99999999999989, 34.40000000000022, 149.3, 47.90000000000024, 53.30000000000008, -74.50000000000068, 50.6000000000002, -248.80000000000027, 39.80000000000025, -42.99999999999985, 43.10000000000022, 73.39999999999972, 20.000000000000014, 31.100000000000122, -187.30000000000004, -97.90000000000046, 50.30000000000001, 42.50000000000019, -15.999999999999803, -12.999999999999977, -83.50000000000045, -38.79999999999995, 17.900000000000013, 113.00000000000003, 20.000000000000014, 20.000000000000014, 20.900000000000013, -93.40000000000046, 53.900000000000034, -55.599999999999994, 19.70000000000002, 55.100000000000065], "policy_predator_policy_reward": [49.0, 48.0, 42.0, 50.0, 101.0, 35.0, 12.0, 39.0, 0.0, 57.0, 92.0, 114.0, 106.0, 0.0, 34.0, 0.0, 1.0, 64.0, 27.0, 4.0, 13.0, 89.0, 34.0, 83.0, 0.0, 10.0, 24.0, 0.0, 6.0, 0.0, 20.0, 21.0, 0.0, 74.0, 24.0, 38.0, 0.0, 26.0, 30.0, 25.0, 5.0, 9.0, 20.0, 45.0, 22.0, 63.0, 0.0, 0.0, 36.0, 26.0, 0.0, 3.0, 49.0, 0.0, 0.0, 33.0, 16.0, 10.0, 43.0, 1.0, 0.0, 94.0, 30.0, 0.0, 4.0, 0.0, 5.0, 1.0, 2.0, 17.0, 0.0, 0.0, 27.0, 17.0, 33.0, 48.0, 143.0, 0.0, 15.0, 6.0, 38.0, 116.0, 0.0, 0.0, 25.0, 0.0, 52.0, 31.0, 0.0, 38.0, 31.0, 16.0, 9.0, 71.0, 46.0, 0.0, 1.0, 0.0, 14.0, 0.0, 93.0, 0.0, 0.0, 0.0, 11.0, 0.0, 11.0, 4.0, 0.0, 0.0, 8.0, 147.0, 7.0, 0.0, 60.0, 2.0, 0.0, 0.0, 5.0, 0.0, 2.0, 6.0, 0.0, 0.0, 106.0, 90.0, 6.0, 0.0, 159.0, 87.0, 98.0, 127.0, 53.0, 3.0, 55.0, 21.0, 34.0, 56.0, 0.0, 61.0, 19.0, 53.0, 34.0, 28.0, 131.0, 3.0, 78.0, 52.0, 98.0, 0.0, 86.0, 57.0, 105.0, 68.0, 89.0, 0.0, 0.0, 0.0, 0.0, 32.0, 39.0, 20.0, 131.0, 5.0, 65.0, 71.0, 2.0, 41.0, 6.0, 31.0, 0.0, 16.0, 45.0, 6.0, 87.0, 110.0, 48.0, 0.0, 25.0, 2.0, 0.0, 8.0, 63.0, 125.0, 0.0, 43.0, 53.0, 3.0, 27.0, 67.0, 0.0, 12.0, 0.0, 0.0, 39.0, 15.0, 32.0, 26.0, 0.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2741747940510022, "mean_inference_ms": 3.4481080695110347, "mean_action_processing_ms": 0.5192743528894517, "mean_env_wait_ms": 0.8272744141817628, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008739829063415527, "StateBufferConnector_ms": 0.004980802536010742, "ViewRequirementAgentConnector_ms": 0.23787331581115723}, "num_episodes": 18, "episode_return_max": 237.09999999999934, "episode_return_min": -188.10000000000036, "episode_return_mean": 27.45599999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 158.36072659236163, "num_env_steps_trained_throughput_per_sec": 158.36072659236163, "timesteps_total": 24000, "num_env_steps_sampled_lifetime": 24000, "num_agent_steps_sampled_lifetime": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 19282.922, "restore_workers_time_ms": 0.107, "training_step_time_ms": 19282.603, "sample_time_ms": 2942.912, "learn_time_ms": 16303.296, "learn_throughput": 245.349, "synch_weights_time_ms": 30.484}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "training_iteration": 6, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-54-03", "timestamp": 1723521243, "time_this_iter_s": 25.326524257659912, "time_total_s": 116.2367331981659, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28cd8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 116.2367331981659, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 94.23611111111111, "ram_util_percent": 83.09166666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.20403718407901505, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7079118649795573, "policy_loss": -0.005792191741303122, "vf_loss": 1.7130501004438552, "vf_explained_var": 0.0014305339288459254, "kl": 0.013079147175539482, "entropy": 1.6025220905662214, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3706439146052594, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.87355918127393, "policy_loss": -0.005519455983106382, "vf_loss": 3.8763724740850862, "vf_explained_var": 0.03376684873192399, "kl": 0.01804114912915071, "entropy": 1.5709389084861392, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 12285.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "env_runners": {"episode_reward_max": 237.09999999999934, "episode_reward_min": -136.00000000000077, "episode_reward_mean": 36.56099999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -328.6000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.29999999999984, "predator_policy": 159.0}, "policy_reward_mean": {"prey_policy": -8.454500000000046, "predator_policy": 26.735}, "custom_metrics": {}, "hist_stats": {"episode_reward": [184.19999999999965, -6.100000000000055, 96.29999999999836, 60.60000000000026, -74.49999999999983, 40.9000000000003, 66.90000000000008, 73.60000000000007, -13.899999999999888, 104.49999999999926, 90.8999999999987, 25.20000000000011, -55.600000000000364, 8.799999999999924, 114.79999999999868, 99.09999999999961, 226.0999999999994, 237.09999999999934, 11.399999999999972, -21.799999999999535, -89.4000000000002, 114.09999999999934, -69.10000000000053, 96.69999999999905, 18.80000000000025, 18.00000000000015, 116.99999999999983, 46.80000000000018, 60.89999999999934, -10.599999999999978, 62.300000000000395, 81.29999999999916, -29.29999999999984, 58.000000000000504, 39.60000000000044, 79.29999999999927, 40.0000000000003, -118.80000000000044, 84.49999999999896, -21.299999999999862, 49.900000000000354, 34.5000000000002, 165.29999999999922, 40.0000000000003, -136.00000000000077, 69.40000000000009, -82.40000000000046, -37.4, 38.69999999999932, 102.19999999999948, -45.19999999999979, 14.300000000000024, -104.3000000000001, 1.4999999999999976, -79.3999999999998, -103.000000000001, -107.7000000000005, -62.1000000000002, -85.20000000000007, -19.19999999999979, 106.5999999999992, 20.100000000000133, 97.79999999999953, -89.80000000000004, -67.2999999999999, 64.70000000000019, 34.40000000000034, 213.19999999999928, 29.80000000000013, -1.2000000000000064, 44.80000000000034, 143.4999999999988, 59.100000000000286, -97.2000000000005, 135.79999999999922, 27.00000000000026, -28.299999999999784, 142.89999999999955, 40.0000000000003, -18.499999999999773, 56.3000000000001, 93.79999999999951, 58.90000000000052, 55.500000000000476, 131.79999999999973, 30.000000000000234, -51.70000000000045, 224.09999999999908, 40.0000000000003, -7.599999999999762, 75.99999999999956, 155.19999999999877, 102.09999999999935, 28.400000000000375, 13.599999999999937, 75.09999999999982, 2.99999999999994, -36.19999999999981, 62.50000000000051, 186.6999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [46.39999999999998, 111.7999999999996, -3.6999999999999993, -57.39999999999988, 18.199999999999992, 64.10000000000021, 74.8999999999995, -79.30000000000055, -103.60000000000008, -55.90000000000001, 20.90000000000003, 20.000000000000014, -49.90000000000035, 54.80000000000014, 51.499999999999964, 19.1, -82.90000000000038, 20.000000000000014, 14.29999999999995, 57.20000000000008, 44.90000000000017, 20.000000000000014, -27.09999999999993, 8.300000000000008, -83.50000000000048, -66.10000000000078, -13.900000000000025, -7.299999999999894, 20.000000000000014, 90.79999999999939, 30.800000000000097, 62.30000000000012, 125.89999999999998, 81.19999999999965, 124.39999999999952, 112.6999999999999, 1.0999999999999528, -33.69999999999981, -7.299999999999898, -95.50000000000081, 20.000000000000014, -252.40000000000003, 13.69999999999997, 79.40000000000003, -243.10000000000002, 20.000000000000014, 39.80000000000025, 56.90000000000013, -5.200000000000051, -1.0000000000000329, 24.200000000000017, -89.19999999999985, 5.000000000000021, 74.00000000000009, -5.499999999999938, 5.299999999999969, 82.39999999999941, -101.50000000000009, 20.000000000000014, -76.60000000000022, 25.100000000000097, 36.20000000000018, 47.30000000000011, 20.000000000000014, -152.2000000000005, 29.900000000000055, 20.000000000000014, 38.00000000000022, 23.30000000000019, 5.299999999999981, 20.000000000000014, 44.300000000000125, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -277.0, 57.50000000000019, 20.000000000000014, 20.000000000000014, -103.30000000000004, 29.90000000000018, 20.000000000000014, 20.000000000000014, 9.499999999999977, 20.000000000000014, 137.29999999999998, 20.000000000000014, 20.000000000000014, -205.00000000000009, -127.00000000000074, 48.80000000000024, 14.599999999999953, -1.000000000000012, -327.39999999999986, 20.000000000000014, -282.40000000000003, -51.699999999999875, 34.40000000000019, 74.89999999999998, -48.70000000000028, 13.699999999999953, -148.9000000000003, -64.60000000000025, 17.899999999999977, -89.19999999999996, -87.10000000000005, 20.000000000000014, -80.50000000000051, -80.50000000000065, -132.8999999999999, -89.2000000000007, -143.80000000000038, -137.5000000000001, -68.20000000000039, 0.7999999999999765, -205.90000000000035, 70.39999999999998, -328.6000000000002, 20.000000000000014, -128.2000000000001, 24.500000000000096, 82.09999999999971, 35.300000000000026, -47.19999999999976, -11.800000000000008, 50.60000000000008, 9.499999999999964, -235.30000000000013, -129.10000000000025, -74.19999999999999, -11.499999999999819, 33.20000000000009, -36.99999999999989, 34.40000000000022, 149.3, 47.90000000000024, 53.30000000000008, -74.50000000000068, 50.6000000000002, -248.80000000000027, 39.80000000000025, -42.99999999999985, 43.10000000000022, 73.39999999999972, 20.000000000000014, 31.100000000000122, -187.30000000000004, -97.90000000000046, 50.30000000000001, 42.50000000000019, -15.999999999999803, -12.999999999999977, -83.50000000000045, -38.79999999999995, 17.900000000000013, 113.00000000000003, 20.000000000000014, 20.000000000000014, 20.900000000000013, -93.40000000000046, 53.900000000000034, -55.599999999999994, 19.70000000000002, 55.100000000000065, 38.90000000000025, 20.000000000000014, 13.699999999999969, 33.80000000000024, 111.79999999999998, 20.000000000000014, -27.699999999999925, 13.699999999999967, -16.899999999999757, -113.80000000000064, 54.20000000000023, 158.89999999999995, 20.000000000000014, 20.000000000000014, -101.80000000000055, 36.20000000000003, 56.00000000000018, 20.000000000000014, 28.100000000000147, 127.09999999999954, 82.09999999999974, 20.000000000000014, -45.09999999999995, 15.49999999999996, -30.399999999999856, 20.000000000000014, 55.10000000000006, 20.000000000000014, -15.6999999999998, -7.3000000000000345, -108.10000000000025, -48.0999999999998, 42.50000000000025, 20.000000000000014, 25.400000000000006, 161.29999999999984], "policy_predator_policy_reward": [0.0, 26.0, 30.0, 25.0, 5.0, 9.0, 20.0, 45.0, 22.0, 63.0, 0.0, 0.0, 36.0, 26.0, 0.0, 3.0, 49.0, 0.0, 0.0, 33.0, 16.0, 10.0, 43.0, 1.0, 0.0, 94.0, 30.0, 0.0, 4.0, 0.0, 5.0, 1.0, 2.0, 17.0, 0.0, 0.0, 27.0, 17.0, 33.0, 48.0, 143.0, 0.0, 15.0, 6.0, 38.0, 116.0, 0.0, 0.0, 25.0, 0.0, 52.0, 31.0, 0.0, 38.0, 31.0, 16.0, 9.0, 71.0, 46.0, 0.0, 1.0, 0.0, 14.0, 0.0, 93.0, 0.0, 0.0, 0.0, 11.0, 0.0, 11.0, 4.0, 0.0, 0.0, 8.0, 147.0, 7.0, 0.0, 60.0, 2.0, 0.0, 0.0, 5.0, 0.0, 2.0, 6.0, 0.0, 0.0, 106.0, 90.0, 6.0, 0.0, 159.0, 87.0, 98.0, 127.0, 53.0, 3.0, 55.0, 21.0, 34.0, 56.0, 0.0, 61.0, 19.0, 53.0, 34.0, 28.0, 131.0, 3.0, 78.0, 52.0, 98.0, 0.0, 86.0, 57.0, 105.0, 68.0, 89.0, 0.0, 0.0, 0.0, 0.0, 32.0, 39.0, 20.0, 131.0, 5.0, 65.0, 71.0, 2.0, 41.0, 6.0, 31.0, 0.0, 16.0, 45.0, 6.0, 87.0, 110.0, 48.0, 0.0, 25.0, 2.0, 0.0, 8.0, 63.0, 125.0, 0.0, 43.0, 53.0, 3.0, 27.0, 67.0, 0.0, 12.0, 0.0, 0.0, 39.0, 15.0, 32.0, 26.0, 0.0, 19.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 42.0, 2.0, 68.0, 11.0, 11.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 21.0, 3.0, 0.0, 0.0, 0.0, 26.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2910036001770329, "mean_inference_ms": 3.465556734166461, "mean_action_processing_ms": 0.515348536434406, "mean_env_wait_ms": 0.8257287367889338, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01341712474822998, "StateBufferConnector_ms": 0.004343748092651367, "ViewRequirementAgentConnector_ms": 0.27078700065612793}, "num_episodes": 18, "episode_return_max": 237.09999999999934, "episode_return_min": -136.00000000000077, "episode_return_mean": 36.56099999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 247.6371122852685, "num_env_steps_trained_throughput_per_sec": 247.6371122852685, "timesteps_total": 28000, "num_env_steps_sampled_lifetime": 28000, "num_agent_steps_sampled_lifetime": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 18835.744, "restore_workers_time_ms": 0.094, "training_step_time_ms": 18835.463, "sample_time_ms": 3074.951, "learn_time_ms": 15725.919, "learn_throughput": 254.357, "synch_weights_time_ms": 28.407}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "training_iteration": 7, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-54-19", "timestamp": 1723521259, "time_this_iter_s": 16.208493947982788, "time_total_s": 132.44522714614868, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28411f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 132.44522714614868, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 80.33913043478262, "ram_util_percent": 83.07826086956521}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.20397067143133393, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.974204999492282, "policy_loss": -0.002963200280511821, "vf_loss": 1.9768515184442832, "vf_explained_var": 0.0032717262941693503, "kl": 0.0063336554964949715, "entropy": 1.5980189580135244, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2971019364854015, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.5071652281221257, "policy_loss": -0.0009151602062894396, "vf_loss": 3.507282935626923, "vf_explained_var": -0.011208768811806168, "kl": 0.0053163997986812, "entropy": 1.5661320148321687, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 14175.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "env_runners": {"episode_reward_max": 224.09999999999908, "episode_reward_min": -136.00000000000077, "episode_reward_mean": 29.881999999999866, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -328.6000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.29999999999984, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -12.464000000000032, "predator_policy": 27.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.399999999999972, -21.799999999999535, -89.4000000000002, 114.09999999999934, -69.10000000000053, 96.69999999999905, 18.80000000000025, 18.00000000000015, 116.99999999999983, 46.80000000000018, 60.89999999999934, -10.599999999999978, 62.300000000000395, 81.29999999999916, -29.29999999999984, 58.000000000000504, 39.60000000000044, 79.29999999999927, 40.0000000000003, -118.80000000000044, 84.49999999999896, -21.299999999999862, 49.900000000000354, 34.5000000000002, 165.29999999999922, 40.0000000000003, -136.00000000000077, 69.40000000000009, -82.40000000000046, -37.4, 38.69999999999932, 102.19999999999948, -45.19999999999979, 14.300000000000024, -104.3000000000001, 1.4999999999999976, -79.3999999999998, -103.000000000001, -107.7000000000005, -62.1000000000002, -85.20000000000007, -19.19999999999979, 106.5999999999992, 20.100000000000133, 97.79999999999953, -89.80000000000004, -67.2999999999999, 64.70000000000019, 34.40000000000034, 213.19999999999928, 29.80000000000013, -1.2000000000000064, 44.80000000000034, 143.4999999999988, 59.100000000000286, -97.2000000000005, 135.79999999999922, 27.00000000000026, -28.299999999999784, 142.89999999999955, 40.0000000000003, -18.499999999999773, 56.3000000000001, 93.79999999999951, 58.90000000000052, 55.500000000000476, 131.79999999999973, 30.000000000000234, -51.70000000000045, 224.09999999999908, 40.0000000000003, -7.599999999999762, 75.99999999999956, 155.19999999999877, 102.09999999999935, 28.400000000000375, 13.599999999999937, 75.09999999999982, 2.99999999999994, -36.19999999999981, 62.50000000000051, 186.6999999999992, 56.200000000000514, -77.50000000000004, -9.299999999999962, 40.0000000000003, 46.300000000000274, 21.300000000000175, 44.700000000000486, -88.50000000000057, 133.59999999999872, 82.2999999999992, 61.80000000000042, 31.200000000000276, 62.400000000000496, 61.10000000000005, 154.29999999999885, 40.0000000000003, -64.50000000000097, 15.600000000000039], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999528, -33.69999999999981, -7.299999999999898, -95.50000000000081, 20.000000000000014, -252.40000000000003, 13.69999999999997, 79.40000000000003, -243.10000000000002, 20.000000000000014, 39.80000000000025, 56.90000000000013, -5.200000000000051, -1.0000000000000329, 24.200000000000017, -89.19999999999985, 5.000000000000021, 74.00000000000009, -5.499999999999938, 5.299999999999969, 82.39999999999941, -101.50000000000009, 20.000000000000014, -76.60000000000022, 25.100000000000097, 36.20000000000018, 47.30000000000011, 20.000000000000014, -152.2000000000005, 29.900000000000055, 20.000000000000014, 38.00000000000022, 23.30000000000019, 5.299999999999981, 20.000000000000014, 44.300000000000125, 20.000000000000014, 20.000000000000014, 3.1999999999999615, -277.0, 57.50000000000019, 20.000000000000014, 20.000000000000014, -103.30000000000004, 29.90000000000018, 20.000000000000014, 20.000000000000014, 9.499999999999977, 20.000000000000014, 137.29999999999998, 20.000000000000014, 20.000000000000014, -205.00000000000009, -127.00000000000074, 48.80000000000024, 14.599999999999953, -1.000000000000012, -327.39999999999986, 20.000000000000014, -282.40000000000003, -51.699999999999875, 34.40000000000019, 74.89999999999998, -48.70000000000028, 13.699999999999953, -148.9000000000003, -64.60000000000025, 17.899999999999977, -89.19999999999996, -87.10000000000005, 20.000000000000014, -80.50000000000051, -80.50000000000065, -132.8999999999999, -89.2000000000007, -143.80000000000038, -137.5000000000001, -68.20000000000039, 0.7999999999999765, -205.90000000000035, 70.39999999999998, -328.6000000000002, 20.000000000000014, -128.2000000000001, 24.500000000000096, 82.09999999999971, 35.300000000000026, -47.19999999999976, -11.800000000000008, 50.60000000000008, 9.499999999999964, -235.30000000000013, -129.10000000000025, -74.19999999999999, -11.499999999999819, 33.20000000000009, -36.99999999999989, 34.40000000000022, 149.3, 47.90000000000024, 53.30000000000008, -74.50000000000068, 50.6000000000002, -248.80000000000027, 39.80000000000025, -42.99999999999985, 43.10000000000022, 73.39999999999972, 20.000000000000014, 31.100000000000122, -187.30000000000004, -97.90000000000046, 50.30000000000001, 42.50000000000019, -15.999999999999803, -12.999999999999977, -83.50000000000045, -38.79999999999995, 17.900000000000013, 113.00000000000003, 20.000000000000014, 20.000000000000014, 20.900000000000013, -93.40000000000046, 53.900000000000034, -55.599999999999994, 19.70000000000002, 55.100000000000065, 38.90000000000025, 20.000000000000014, 13.699999999999969, 33.80000000000024, 111.79999999999998, 20.000000000000014, -27.699999999999925, 13.699999999999967, -16.899999999999757, -113.80000000000064, 54.20000000000023, 158.89999999999995, 20.000000000000014, 20.000000000000014, -101.80000000000055, 36.20000000000003, 56.00000000000018, 20.000000000000014, 28.100000000000147, 127.09999999999954, 82.09999999999974, 20.000000000000014, -45.09999999999995, 15.49999999999996, -30.399999999999856, 20.000000000000014, 55.10000000000006, 20.000000000000014, -15.6999999999998, -7.3000000000000345, -108.10000000000025, -48.0999999999998, 42.50000000000025, 20.000000000000014, 25.400000000000006, 161.29999999999984, 36.20000000000025, 20.000000000000014, -55.000000000000014, -101.50000000000001, -66.10000000000066, -17.19999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.299999999999976, -48.70000000000002, 20.000000000000014, 1.6999999999999924, 26.000000000000117, -223.60000000000045, -25.89999999999999, 113.59999999999945, 20.000000000000014, 29.000000000000163, 53.30000000000023, -32.499999999999766, 68.2999999999999, 20.000000000000014, -23.79999999999984, 20.000000000000014, 37.40000000000023, -106.30000000000038, 61.40000000000004, 20.000000000000014, 134.29999999999959, 20.000000000000014, 20.000000000000014, -194.50000000000043, 20.000000000000014, 29.000000000000163, -90.40000000000038], "policy_predator_policy_reward": [27.0, 17.0, 33.0, 48.0, 143.0, 0.0, 15.0, 6.0, 38.0, 116.0, 0.0, 0.0, 25.0, 0.0, 52.0, 31.0, 0.0, 38.0, 31.0, 16.0, 9.0, 71.0, 46.0, 0.0, 1.0, 0.0, 14.0, 0.0, 93.0, 0.0, 0.0, 0.0, 11.0, 0.0, 11.0, 4.0, 0.0, 0.0, 8.0, 147.0, 7.0, 0.0, 60.0, 2.0, 0.0, 0.0, 5.0, 0.0, 2.0, 6.0, 0.0, 0.0, 106.0, 90.0, 6.0, 0.0, 159.0, 87.0, 98.0, 127.0, 53.0, 3.0, 55.0, 21.0, 34.0, 56.0, 0.0, 61.0, 19.0, 53.0, 34.0, 28.0, 131.0, 3.0, 78.0, 52.0, 98.0, 0.0, 86.0, 57.0, 105.0, 68.0, 89.0, 0.0, 0.0, 0.0, 0.0, 32.0, 39.0, 20.0, 131.0, 5.0, 65.0, 71.0, 2.0, 41.0, 6.0, 31.0, 0.0, 16.0, 45.0, 6.0, 87.0, 110.0, 48.0, 0.0, 25.0, 2.0, 0.0, 8.0, 63.0, 125.0, 0.0, 43.0, 53.0, 3.0, 27.0, 67.0, 0.0, 12.0, 0.0, 0.0, 39.0, 15.0, 32.0, 26.0, 0.0, 19.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 42.0, 2.0, 68.0, 11.0, 11.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 21.0, 3.0, 0.0, 0.0, 0.0, 26.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 79.0, 19.0, 55.0, 0.0, 0.0, 0.0, 9.0, 24.0, 26.0, 17.0, 0.0, 161.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 25.0, 35.0, 0.0, 5.0, 0.0, 4.0, 102.0, 0.0, 0.0, 0.0, 0.0, 1.0, 109.0, 0.0, 77.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2927137488707086, "mean_inference_ms": 3.4660466469376003, "mean_action_processing_ms": 0.5138215485170141, "mean_env_wait_ms": 0.8197786135774336, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.012884378433227539, "StateBufferConnector_ms": 0.004439115524291992, "ViewRequirementAgentConnector_ms": 0.2577860355377197}, "num_episodes": 18, "episode_return_max": 224.09999999999908, "episode_return_min": -136.00000000000077, "episode_return_mean": 29.881999999999866, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 304.9359695417655, "num_env_steps_trained_throughput_per_sec": 304.9359695417655, "timesteps_total": 32000, "num_env_steps_sampled_lifetime": 32000, "num_agent_steps_sampled_lifetime": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 18120.966, "restore_workers_time_ms": 0.084, "training_step_time_ms": 18120.713, "sample_time_ms": 2924.363, "learn_time_ms": 15164.313, "learn_throughput": 263.777, "synch_weights_time_ms": 26.473}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "training_iteration": 8, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-54-32", "timestamp": 1723521272, "time_this_iter_s": 13.158403158187866, "time_total_s": 145.60363030433655, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28db670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 145.60363030433655, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 72.15555555555555, "ram_util_percent": 82.71111111111111}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3635755529026033, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8229514891508396, "policy_loss": -0.004957803070949262, "vf_loss": 3.8272878452583594, "vf_explained_var": 0.0076611437810161125, "kl": 0.012428936503756715, "entropy": 1.5869512158726888, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3100710403509241, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.241498307702402, "policy_loss": -0.0021894760341161774, "vf_loss": 4.2424839982280025, "vf_explained_var": -0.00953095107482224, "kl": 0.008025252865761794, "entropy": 1.5728876856899765, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 16065.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "env_runners": {"episode_reward_max": 224.09999999999908, "episode_reward_min": -136.00000000000077, "episode_reward_mean": 28.640999999999835, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -328.6000000000002, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.29999999999984, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -13.619500000000048, "predator_policy": 27.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [49.900000000000354, 34.5000000000002, 165.29999999999922, 40.0000000000003, -136.00000000000077, 69.40000000000009, -82.40000000000046, -37.4, 38.69999999999932, 102.19999999999948, -45.19999999999979, 14.300000000000024, -104.3000000000001, 1.4999999999999976, -79.3999999999998, -103.000000000001, -107.7000000000005, -62.1000000000002, -85.20000000000007, -19.19999999999979, 106.5999999999992, 20.100000000000133, 97.79999999999953, -89.80000000000004, -67.2999999999999, 64.70000000000019, 34.40000000000034, 213.19999999999928, 29.80000000000013, -1.2000000000000064, 44.80000000000034, 143.4999999999988, 59.100000000000286, -97.2000000000005, 135.79999999999922, 27.00000000000026, -28.299999999999784, 142.89999999999955, 40.0000000000003, -18.499999999999773, 56.3000000000001, 93.79999999999951, 58.90000000000052, 55.500000000000476, 131.79999999999973, 30.000000000000234, -51.70000000000045, 224.09999999999908, 40.0000000000003, -7.599999999999762, 75.99999999999956, 155.19999999999877, 102.09999999999935, 28.400000000000375, 13.599999999999937, 75.09999999999982, 2.99999999999994, -36.19999999999981, 62.50000000000051, 186.6999999999992, 56.200000000000514, -77.50000000000004, -9.299999999999962, 40.0000000000003, 46.300000000000274, 21.300000000000175, 44.700000000000486, -88.50000000000057, 133.59999999999872, 82.2999999999992, 61.80000000000042, 31.200000000000276, 62.400000000000496, 61.10000000000005, 154.29999999999885, 40.0000000000003, -64.50000000000097, 15.600000000000039, 135.39999999999836, 57.10000000000052, -19.10000000000007, 51.70000000000049, -32.79999999999999, 74.99999999999963, 89.59999999999887, 8.099999999999975, 63.4000000000005, 13.200000000000124, 8.599999999999568, -95.20000000000141, 108.19999999999851, -1.399999999999975, 38.90000000000028, -59.00000000000084, 31.700000000000163, -82.80000000000007, -4.899999999999714, -15.099999999999977, 143.49999999999878, -69.79999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [29.90000000000018, 20.000000000000014, 20.000000000000014, 9.499999999999977, 20.000000000000014, 137.29999999999998, 20.000000000000014, 20.000000000000014, -205.00000000000009, -127.00000000000074, 48.80000000000024, 14.599999999999953, -1.000000000000012, -327.39999999999986, 20.000000000000014, -282.40000000000003, -51.699999999999875, 34.40000000000019, 74.89999999999998, -48.70000000000028, 13.699999999999953, -148.9000000000003, -64.60000000000025, 17.899999999999977, -89.19999999999996, -87.10000000000005, 20.000000000000014, -80.50000000000051, -80.50000000000065, -132.8999999999999, -89.2000000000007, -143.80000000000038, -137.5000000000001, -68.20000000000039, 0.7999999999999765, -205.90000000000035, 70.39999999999998, -328.6000000000002, 20.000000000000014, -128.2000000000001, 24.500000000000096, 82.09999999999971, 35.300000000000026, -47.19999999999976, -11.800000000000008, 50.60000000000008, 9.499999999999964, -235.30000000000013, -129.10000000000025, -74.19999999999999, -11.499999999999819, 33.20000000000009, -36.99999999999989, 34.40000000000022, 149.3, 47.90000000000024, 53.30000000000008, -74.50000000000068, 50.6000000000002, -248.80000000000027, 39.80000000000025, -42.99999999999985, 43.10000000000022, 73.39999999999972, 20.000000000000014, 31.100000000000122, -187.30000000000004, -97.90000000000046, 50.30000000000001, 42.50000000000019, -15.999999999999803, -12.999999999999977, -83.50000000000045, -38.79999999999995, 17.900000000000013, 113.00000000000003, 20.000000000000014, 20.000000000000014, 20.900000000000013, -93.40000000000046, 53.900000000000034, -55.599999999999994, 19.70000000000002, 55.100000000000065, 38.90000000000025, 20.000000000000014, 13.699999999999969, 33.80000000000024, 111.79999999999998, 20.000000000000014, -27.699999999999925, 13.699999999999967, -16.899999999999757, -113.80000000000064, 54.20000000000023, 158.89999999999995, 20.000000000000014, 20.000000000000014, -101.80000000000055, 36.20000000000003, 56.00000000000018, 20.000000000000014, 28.100000000000147, 127.09999999999954, 82.09999999999974, 20.000000000000014, -45.09999999999995, 15.49999999999996, -30.399999999999856, 20.000000000000014, 55.10000000000006, 20.000000000000014, -15.6999999999998, -7.3000000000000345, -108.10000000000025, -48.0999999999998, 42.50000000000025, 20.000000000000014, 25.400000000000006, 161.29999999999984, 36.20000000000025, 20.000000000000014, -55.000000000000014, -101.50000000000001, -66.10000000000066, -17.19999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.299999999999976, -48.70000000000002, 20.000000000000014, 1.6999999999999924, 26.000000000000117, -223.60000000000045, -25.89999999999999, 113.59999999999945, 20.000000000000014, 29.000000000000163, 53.30000000000023, -32.499999999999766, 68.2999999999999, 20.000000000000014, -23.79999999999984, 20.000000000000014, 37.40000000000023, -106.30000000000038, 61.40000000000004, 20.000000000000014, 134.29999999999959, 20.000000000000014, 20.000000000000014, -194.50000000000043, 20.000000000000014, 29.000000000000163, -90.40000000000038, 82.09999999999926, 53.30000000000023, 37.10000000000026, 20.000000000000014, -36.699999999999775, -30.400000000000013, 20.900000000000027, 30.800000000000196, 20.000000000000014, -138.79999999999995, 20.000000000000014, 32.00000000000015, 65.00000000000007, -15.399999999999862, -74.50000000000087, 29.60000000000025, 20.000000000000014, 43.40000000000025, 66.19999999999993, -160.00000000000057, -28.299999999999837, -48.09999999999996, -137.50000000000063, -78.70000000000077, 28.400000000000176, 57.800000000000196, -91.30000000000004, 14.899999999999983, 20.000000000000014, 17.899999999999977, -93.40000000000057, -55.60000000000002, 11.900000000000004, -5.199999999999983, 20.000000000000014, -248.79999999999998, 15.799999999999962, -57.70000000000048, -63.09999999999998, -85.00000000000077, 118.0999999999995, 25.40000000000004, 20.000000000000014, -224.8000000000001], "policy_predator_policy_reward": [0.0, 0.0, 5.0, 0.0, 2.0, 6.0, 0.0, 0.0, 106.0, 90.0, 6.0, 0.0, 159.0, 87.0, 98.0, 127.0, 53.0, 3.0, 55.0, 21.0, 34.0, 56.0, 0.0, 61.0, 19.0, 53.0, 34.0, 28.0, 131.0, 3.0, 78.0, 52.0, 98.0, 0.0, 86.0, 57.0, 105.0, 68.0, 89.0, 0.0, 0.0, 0.0, 0.0, 32.0, 39.0, 20.0, 131.0, 5.0, 65.0, 71.0, 2.0, 41.0, 6.0, 31.0, 0.0, 16.0, 45.0, 6.0, 87.0, 110.0, 48.0, 0.0, 25.0, 2.0, 0.0, 8.0, 63.0, 125.0, 0.0, 43.0, 53.0, 3.0, 27.0, 67.0, 0.0, 12.0, 0.0, 0.0, 39.0, 15.0, 32.0, 26.0, 0.0, 19.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 42.0, 2.0, 68.0, 11.0, 11.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 21.0, 3.0, 0.0, 0.0, 0.0, 26.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 79.0, 19.0, 55.0, 0.0, 0.0, 0.0, 9.0, 24.0, 26.0, 17.0, 0.0, 161.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 25.0, 35.0, 0.0, 5.0, 0.0, 4.0, 102.0, 0.0, 0.0, 0.0, 0.0, 1.0, 109.0, 0.0, 77.0, 0.0, 0.0, 0.0, 0.0, 17.0, 31.0, 0.0, 0.0, 0.0, 86.0, 0.0, 23.0, 0.0, 40.0, 49.0, 4.0, 0.0, 0.0, 17.0, 90.0, 33.0, 52.0, 46.0, 75.0, 0.0, 22.0, 57.0, 18.0, 1.0, 0.0, 54.0, 36.0, 0.0, 25.0, 32.0, 114.0, 0.0, 37.0, 104.0, 29.0, 0.0, 0.0, 119.0, 16.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2914295788430568, "mean_inference_ms": 3.465715423604014, "mean_action_processing_ms": 0.5123492960229308, "mean_env_wait_ms": 0.814425478499023, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010817527770996094, "StateBufferConnector_ms": 0.004120469093322754, "ViewRequirementAgentConnector_ms": 0.24937963485717773}, "num_episodes": 22, "episode_return_max": 224.09999999999908, "episode_return_min": -136.00000000000077, "episode_return_mean": 28.640999999999835, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 270.8917288262904, "num_env_steps_trained_throughput_per_sec": 270.8917288262904, "timesteps_total": 36000, "num_env_steps_sampled_lifetime": 36000, "num_agent_steps_sampled_lifetime": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 17748.198, "restore_workers_time_ms": 0.077, "training_step_time_ms": 17747.959, "sample_time_ms": 2802.328, "learn_time_ms": 14914.423, "learn_throughput": 268.197, "synch_weights_time_ms": 25.217}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "training_iteration": 9, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-54-47", "timestamp": 1723521287, "time_this_iter_s": 14.813262939453125, "time_total_s": 160.41689324378967, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28c7ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 160.41689324378967, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 77.16818181818182, "ram_util_percent": 83.16818181818182}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.29822522480848923, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.584858579484243, "policy_loss": -0.004226644206841393, "vf_loss": 5.588720456759135, "vf_explained_var": 0.0034769559663439553, "kl": 0.007295583276745686, "entropy": 1.5762757128508633, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1317710227594173, "cur_kl_coeff": 0.14999999999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.710749464186411, "policy_loss": -0.000992099988574862, "vf_loss": 6.711069616691145, "vf_explained_var": 0.008279598358446959, "kl": 0.004479700368047664, "entropy": 1.5562506917292478, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 17955.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "env_runners": {"episode_reward_max": 224.09999999999908, "episode_reward_min": -267.6999999999997, "episode_reward_mean": 29.668999999999855, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -326.50000000000006, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.29999999999984, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": -14.015500000000054, "predator_policy": 28.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-89.80000000000004, -67.2999999999999, 64.70000000000019, 34.40000000000034, 213.19999999999928, 29.80000000000013, -1.2000000000000064, 44.80000000000034, 143.4999999999988, 59.100000000000286, -97.2000000000005, 135.79999999999922, 27.00000000000026, -28.299999999999784, 142.89999999999955, 40.0000000000003, -18.499999999999773, 56.3000000000001, 93.79999999999951, 58.90000000000052, 55.500000000000476, 131.79999999999973, 30.000000000000234, -51.70000000000045, 224.09999999999908, 40.0000000000003, -7.599999999999762, 75.99999999999956, 155.19999999999877, 102.09999999999935, 28.400000000000375, 13.599999999999937, 75.09999999999982, 2.99999999999994, -36.19999999999981, 62.50000000000051, 186.6999999999992, 56.200000000000514, -77.50000000000004, -9.299999999999962, 40.0000000000003, 46.300000000000274, 21.300000000000175, 44.700000000000486, -88.50000000000057, 133.59999999999872, 82.2999999999992, 61.80000000000042, 31.200000000000276, 62.400000000000496, 61.10000000000005, 154.29999999999885, 40.0000000000003, -64.50000000000097, 15.600000000000039, 135.39999999999836, 57.10000000000052, -19.10000000000007, 51.70000000000049, -32.79999999999999, 74.99999999999963, 89.59999999999887, 8.099999999999975, 63.4000000000005, 13.200000000000124, 8.599999999999568, -95.20000000000141, 108.19999999999851, -1.399999999999975, 38.90000000000028, -59.00000000000084, 31.700000000000163, -82.80000000000007, -4.899999999999714, -15.099999999999977, 143.49999999999878, -69.79999999999993, -35.60000000000001, 53.800000000000324, -63.60000000000011, 7.500000000000075, -267.6999999999997, -111.29999999999995, -6.999999999999945, 177.69999999999905, 82.29999999999917, -2.6000000000003842, -105.20000000000105, 14.800000000000045, 8.700000000000122, 81.99999999999918, 40.0000000000003, 55.699999999999555, -21.29999999999989, 47.700000000000394, 73.89999999999974, 50.10000000000005, 19.000000000000004, -34.29999999999994, -83.40000000000009], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [9.499999999999964, -235.30000000000013, -129.10000000000025, -74.19999999999999, -11.499999999999819, 33.20000000000009, -36.99999999999989, 34.40000000000022, 149.3, 47.90000000000024, 53.30000000000008, -74.50000000000068, 50.6000000000002, -248.80000000000027, 39.80000000000025, -42.99999999999985, 43.10000000000022, 73.39999999999972, 20.000000000000014, 31.100000000000122, -187.30000000000004, -97.90000000000046, 50.30000000000001, 42.50000000000019, -15.999999999999803, -12.999999999999977, -83.50000000000045, -38.79999999999995, 17.900000000000013, 113.00000000000003, 20.000000000000014, 20.000000000000014, 20.900000000000013, -93.40000000000046, 53.900000000000034, -55.599999999999994, 19.70000000000002, 55.100000000000065, 38.90000000000025, 20.000000000000014, 13.699999999999969, 33.80000000000024, 111.79999999999998, 20.000000000000014, -27.699999999999925, 13.699999999999967, -16.899999999999757, -113.80000000000064, 54.20000000000023, 158.89999999999995, 20.000000000000014, 20.000000000000014, -101.80000000000055, 36.20000000000003, 56.00000000000018, 20.000000000000014, 28.100000000000147, 127.09999999999954, 82.09999999999974, 20.000000000000014, -45.09999999999995, 15.49999999999996, -30.399999999999856, 20.000000000000014, 55.10000000000006, 20.000000000000014, -15.6999999999998, -7.3000000000000345, -108.10000000000025, -48.0999999999998, 42.50000000000025, 20.000000000000014, 25.400000000000006, 161.29999999999984, 36.20000000000025, 20.000000000000014, -55.000000000000014, -101.50000000000001, -66.10000000000066, -17.19999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.299999999999976, -48.70000000000002, 20.000000000000014, 1.6999999999999924, 26.000000000000117, -223.60000000000045, -25.89999999999999, 113.59999999999945, 20.000000000000014, 29.000000000000163, 53.30000000000023, -32.499999999999766, 68.2999999999999, 20.000000000000014, -23.79999999999984, 20.000000000000014, 37.40000000000023, -106.30000000000038, 61.40000000000004, 20.000000000000014, 134.29999999999959, 20.000000000000014, 20.000000000000014, -194.50000000000043, 20.000000000000014, 29.000000000000163, -90.40000000000038, 82.09999999999926, 53.30000000000023, 37.10000000000026, 20.000000000000014, -36.699999999999775, -30.400000000000013, 20.900000000000027, 30.800000000000196, 20.000000000000014, -138.79999999999995, 20.000000000000014, 32.00000000000015, 65.00000000000007, -15.399999999999862, -74.50000000000087, 29.60000000000025, 20.000000000000014, 43.40000000000025, 66.19999999999993, -160.00000000000057, -28.299999999999837, -48.09999999999996, -137.50000000000063, -78.70000000000077, 28.400000000000176, 57.800000000000196, -91.30000000000004, 14.899999999999983, 20.000000000000014, 17.899999999999977, -93.40000000000057, -55.60000000000002, 11.900000000000004, -5.199999999999983, 20.000000000000014, -248.79999999999998, 15.799999999999962, -57.70000000000048, -63.09999999999998, -85.00000000000077, 118.0999999999995, 25.40000000000004, 20.000000000000014, -224.8000000000001, 20.000000000000014, -265.6, 20.90000000000003, -6.100000000000023, -66.1000000000005, -125.50000000000009, -122.80000000000047, 17.300000000000047, -230.20000000000007, -326.50000000000006, -1.0, -274.30000000000007, -34.60000000000004, -27.399999999999835, 78.49999999999957, 99.19999999999942, 20.000000000000014, 62.30000000000022, -57.40000000000042, 15.80000000000006, -135.40000000000035, -101.80000000000062, 54.20000000000008, -93.40000000000046, 26.899999999999856, -110.20000000000019, 36.20000000000024, 39.80000000000021, 20.000000000000014, 20.000000000000014, -19.299999999999905, -6.999999999999922, -44.19999999999986, -108.10000000000016, 20.000000000000014, 16.699999999999974, 36.20000000000014, 13.699999999999958, -212.70000000000002, 111.79999999999963, 88.09999999999948, -150.10000000000062, -108.10000000000052, -137.2, 20.000000000000014, -234.40000000000015], "policy_predator_policy_reward": [131.0, 5.0, 65.0, 71.0, 2.0, 41.0, 6.0, 31.0, 0.0, 16.0, 45.0, 6.0, 87.0, 110.0, 48.0, 0.0, 25.0, 2.0, 0.0, 8.0, 63.0, 125.0, 0.0, 43.0, 53.0, 3.0, 27.0, 67.0, 0.0, 12.0, 0.0, 0.0, 39.0, 15.0, 32.0, 26.0, 0.0, 19.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 42.0, 2.0, 68.0, 11.0, 11.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 21.0, 3.0, 0.0, 0.0, 0.0, 26.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 79.0, 19.0, 55.0, 0.0, 0.0, 0.0, 9.0, 24.0, 26.0, 17.0, 0.0, 161.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 25.0, 35.0, 0.0, 5.0, 0.0, 4.0, 102.0, 0.0, 0.0, 0.0, 0.0, 1.0, 109.0, 0.0, 77.0, 0.0, 0.0, 0.0, 0.0, 17.0, 31.0, 0.0, 0.0, 0.0, 86.0, 0.0, 23.0, 0.0, 40.0, 49.0, 4.0, 0.0, 0.0, 17.0, 90.0, 33.0, 52.0, 46.0, 75.0, 0.0, 22.0, 57.0, 18.0, 1.0, 0.0, 54.0, 36.0, 0.0, 25.0, 32.0, 114.0, 0.0, 37.0, 104.0, 29.0, 0.0, 0.0, 119.0, 16.0, 116.0, 94.0, 0.0, 39.0, 50.0, 78.0, 80.0, 33.0, 129.0, 160.0, 11.0, 153.0, 45.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 31.0, 101.0, 9.0, 45.0, 0.0, 92.0, 0.0, 6.0, 0.0, 0.0, 57.0, 25.0, 51.0, 80.0, 0.0, 11.0, 0.0, 24.0, 79.0, 72.0, 0.0, 81.0, 148.0, 63.0, 0.0, 131.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2959375159288442, "mean_inference_ms": 3.4621158821516946, "mean_action_processing_ms": 0.5082382870781571, "mean_env_wait_ms": 0.8082288636246995, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011980772018432617, "StateBufferConnector_ms": 0.004278779029846191, "ViewRequirementAgentConnector_ms": 0.22946858406066895}, "num_episodes": 23, "episode_return_max": 224.09999999999908, "episode_return_min": -267.6999999999997, "episode_return_mean": 29.668999999999855, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 249.50420656118462, "num_env_steps_trained_throughput_per_sec": 249.50420656118462, "timesteps_total": 40000, "num_env_steps_sampled_lifetime": 40000, "num_agent_steps_sampled_lifetime": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 17576.558, "restore_workers_time_ms": 0.071, "training_step_time_ms": 17576.338, "sample_time_ms": 2734.391, "learn_time_ms": 14811.728, "learn_throughput": 270.056, "synch_weights_time_ms": 24.631}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "training_iteration": 10, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-55-03", "timestamp": 1723521303, "time_this_iter_s": 16.08777689933777, "time_total_s": 176.50467014312744, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28ea160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 176.50467014312744, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 83.45454545454547, "ram_util_percent": 83.81363636363638}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3107159130925697, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.699156098643308, "policy_loss": -0.004893986625035131, "vf_loss": 5.703319191049647, "vf_explained_var": 0.00044423783266985857, "kl": 0.014618128752241747, "entropy": 1.5309666691003023, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1662550961135556, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.0405221535415246, "policy_loss": -0.007908205977744526, "vf_loss": 7.046985728147799, "vf_explained_var": 0.008076195584403143, "kl": 0.01926159014594365, "entropy": 1.5210461646160751, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 19845.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "env_runners": {"episode_reward_max": 224.09999999999908, "episode_reward_min": -267.6999999999997, "episode_reward_mean": 12.046999999999844, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -328.00000000000034, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 161.29999999999984, "predator_policy": 269.0}, "policy_reward_mean": {"prey_policy": -28.41650000000006, "predator_policy": 34.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [93.79999999999951, 58.90000000000052, 55.500000000000476, 131.79999999999973, 30.000000000000234, -51.70000000000045, 224.09999999999908, 40.0000000000003, -7.599999999999762, 75.99999999999956, 155.19999999999877, 102.09999999999935, 28.400000000000375, 13.599999999999937, 75.09999999999982, 2.99999999999994, -36.19999999999981, 62.50000000000051, 186.6999999999992, 56.200000000000514, -77.50000000000004, -9.299999999999962, 40.0000000000003, 46.300000000000274, 21.300000000000175, 44.700000000000486, -88.50000000000057, 133.59999999999872, 82.2999999999992, 61.80000000000042, 31.200000000000276, 62.400000000000496, 61.10000000000005, 154.29999999999885, 40.0000000000003, -64.50000000000097, 15.600000000000039, 135.39999999999836, 57.10000000000052, -19.10000000000007, 51.70000000000049, -32.79999999999999, 74.99999999999963, 89.59999999999887, 8.099999999999975, 63.4000000000005, 13.200000000000124, 8.599999999999568, -95.20000000000141, 108.19999999999851, -1.399999999999975, 38.90000000000028, -59.00000000000084, 31.700000000000163, -82.80000000000007, -4.899999999999714, -15.099999999999977, 143.49999999999878, -69.79999999999993, -35.60000000000001, 53.800000000000324, -63.60000000000011, 7.500000000000075, -267.6999999999997, -111.29999999999995, -6.999999999999945, 177.69999999999905, 82.29999999999917, -2.6000000000003842, -105.20000000000105, 14.800000000000045, 8.700000000000122, 81.99999999999918, 40.0000000000003, 55.699999999999555, -21.29999999999989, 47.700000000000394, 73.89999999999974, 50.10000000000005, 19.000000000000004, -34.29999999999994, -83.40000000000009, -49.40000000000008, -87.4, -54.39999999999986, -5.299999999999612, -71.70000000000005, -200.60000000000036, -0.7000000000000277, -261.50000000000017, 92.0999999999986, -80.20000000000059, -62.700000000000124, -30.59999999999988, -36.500000000000014, 33.00000000000024, 63.600000000000435, -137.80000000000007, 33.099999999999724, -216.0000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [19.70000000000002, 55.100000000000065, 38.90000000000025, 20.000000000000014, 13.699999999999969, 33.80000000000024, 111.79999999999998, 20.000000000000014, -27.699999999999925, 13.699999999999967, -16.899999999999757, -113.80000000000064, 54.20000000000023, 158.89999999999995, 20.000000000000014, 20.000000000000014, -101.80000000000055, 36.20000000000003, 56.00000000000018, 20.000000000000014, 28.100000000000147, 127.09999999999954, 82.09999999999974, 20.000000000000014, -45.09999999999995, 15.49999999999996, -30.399999999999856, 20.000000000000014, 55.10000000000006, 20.000000000000014, -15.6999999999998, -7.3000000000000345, -108.10000000000025, -48.0999999999998, 42.50000000000025, 20.000000000000014, 25.400000000000006, 161.29999999999984, 36.20000000000025, 20.000000000000014, -55.000000000000014, -101.50000000000001, -66.10000000000066, -17.19999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.299999999999976, -48.70000000000002, 20.000000000000014, 1.6999999999999924, 26.000000000000117, -223.60000000000045, -25.89999999999999, 113.59999999999945, 20.000000000000014, 29.000000000000163, 53.30000000000023, -32.499999999999766, 68.2999999999999, 20.000000000000014, -23.79999999999984, 20.000000000000014, 37.40000000000023, -106.30000000000038, 61.40000000000004, 20.000000000000014, 134.29999999999959, 20.000000000000014, 20.000000000000014, -194.50000000000043, 20.000000000000014, 29.000000000000163, -90.40000000000038, 82.09999999999926, 53.30000000000023, 37.10000000000026, 20.000000000000014, -36.699999999999775, -30.400000000000013, 20.900000000000027, 30.800000000000196, 20.000000000000014, -138.79999999999995, 20.000000000000014, 32.00000000000015, 65.00000000000007, -15.399999999999862, -74.50000000000087, 29.60000000000025, 20.000000000000014, 43.40000000000025, 66.19999999999993, -160.00000000000057, -28.299999999999837, -48.09999999999996, -137.50000000000063, -78.70000000000077, 28.400000000000176, 57.800000000000196, -91.30000000000004, 14.899999999999983, 20.000000000000014, 17.899999999999977, -93.40000000000057, -55.60000000000002, 11.900000000000004, -5.199999999999983, 20.000000000000014, -248.79999999999998, 15.799999999999962, -57.70000000000048, -63.09999999999998, -85.00000000000077, 118.0999999999995, 25.40000000000004, 20.000000000000014, -224.8000000000001, 20.000000000000014, -265.6, 20.90000000000003, -6.100000000000023, -66.1000000000005, -125.50000000000009, -122.80000000000047, 17.300000000000047, -230.20000000000007, -326.50000000000006, -1.0, -274.30000000000007, -34.60000000000004, -27.399999999999835, 78.49999999999957, 99.19999999999942, 20.000000000000014, 62.30000000000022, -57.40000000000042, 15.80000000000006, -135.40000000000035, -101.80000000000062, 54.20000000000008, -93.40000000000046, 26.899999999999856, -110.20000000000019, 36.20000000000024, 39.80000000000021, 20.000000000000014, 20.000000000000014, -19.299999999999905, -6.999999999999922, -44.19999999999986, -108.10000000000016, 20.000000000000014, 16.699999999999974, 36.20000000000014, 13.699999999999958, -212.70000000000002, 111.79999999999963, 88.09999999999948, -150.10000000000062, -108.10000000000052, -137.2, 20.000000000000014, -234.40000000000015, -97.60000000000082, -50.79999999999987, -30.399999999999977, -180.0000000000002, -41.49999999999989, -184.90000000000003, -90.69999999999982, 22.40000000000008, -210.99999999999997, 5.299999999999967, -204.70000000000007, -172.90000000000052, -36.699999999999754, -45.99999999999989, -230.50000000000003, -328.00000000000034, 29.300000000000175, 45.80000000000018, 1.0999999999999865, -175.3000000000003, 74.59999999999937, -280.29999999999956, 28.100000000000147, -189.7, 42.800000000000054, -183.29999999999987, 79.39999999999975, -126.4000000000003, 11.59999999999998, 20.000000000000014, -158.50000000000006, -215.30000000000004, -19.299999999999937, -13.599999999999882, -269.0, -219.00000000000003], "policy_predator_policy_reward": [0.0, 19.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 42.0, 2.0, 68.0, 11.0, 11.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 58.0, 0.0, 21.0, 3.0, 0.0, 0.0, 0.0, 26.0, 60.0, 60.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 79.0, 19.0, 55.0, 0.0, 0.0, 0.0, 9.0, 24.0, 26.0, 17.0, 0.0, 161.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 25.0, 35.0, 0.0, 5.0, 0.0, 4.0, 102.0, 0.0, 0.0, 0.0, 0.0, 1.0, 109.0, 0.0, 77.0, 0.0, 0.0, 0.0, 0.0, 17.0, 31.0, 0.0, 0.0, 0.0, 86.0, 0.0, 23.0, 0.0, 40.0, 49.0, 4.0, 0.0, 0.0, 17.0, 90.0, 33.0, 52.0, 46.0, 75.0, 0.0, 22.0, 57.0, 18.0, 1.0, 0.0, 54.0, 36.0, 0.0, 25.0, 32.0, 114.0, 0.0, 37.0, 104.0, 29.0, 0.0, 0.0, 119.0, 16.0, 116.0, 94.0, 0.0, 39.0, 50.0, 78.0, 80.0, 33.0, 129.0, 160.0, 11.0, 153.0, 45.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 31.0, 101.0, 9.0, 45.0, 0.0, 92.0, 0.0, 6.0, 0.0, 0.0, 57.0, 25.0, 51.0, 80.0, 0.0, 11.0, 0.0, 24.0, 79.0, 72.0, 0.0, 81.0, 148.0, 63.0, 0.0, 131.0, 38.0, 61.0, 123.0, 0.0, 0.0, 172.0, 22.0, 41.0, 54.0, 80.0, 157.0, 20.0, 39.0, 43.0, 28.0, 269.0, 0.0, 17.0, 0.0, 94.0, 143.0, 0.0, 131.0, 0.0, 81.0, 23.0, 68.0, 12.0, 13.0, 19.0, 148.0, 88.0, 41.0, 25.0, 129.0, 143.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2842099289381537, "mean_inference_ms": 3.4084983931603476, "mean_action_processing_ms": 0.5006468924940194, "mean_env_wait_ms": 0.7943116173630657, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011838912963867188, "StateBufferConnector_ms": 0.004137873649597168, "ViewRequirementAgentConnector_ms": 0.19816017150878906}, "num_episodes": 18, "episode_return_max": 224.09999999999908, "episode_return_min": -267.6999999999997, "episode_return_mean": 12.046999999999844, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 293.10721920407764, "num_env_steps_trained_throughput_per_sec": 293.10721920407764, "timesteps_total": 44000, "num_env_steps_sampled_lifetime": 44000, "num_agent_steps_sampled_lifetime": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 17336.23, "restore_workers_time_ms": 0.07, "training_step_time_ms": 17336.091, "sample_time_ms": 2695.99, "learn_time_ms": 14613.29, "learn_throughput": 273.723, "synch_weights_time_ms": 22.052}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "training_iteration": 11, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-55-17", "timestamp": 1723521317, "time_this_iter_s": 13.706944942474365, "time_total_s": 190.2116150856018, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28dbdc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 190.2116150856018, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 73.57499999999999, "ram_util_percent": 83.675}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3933867926024413, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.8073117864195005, "policy_loss": -0.004475375043139571, "vf_loss": 5.810840346068932, "vf_explained_var": 0.0003445519341362847, "kl": 0.018936160438976873, "entropy": 1.4989338935367644, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.033429035970143, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.744646444774809, "policy_loss": -0.004980198435101008, "vf_loss": 6.748689758714545, "vf_explained_var": 0.0169261581683285, "kl": 0.012491713764947319, "entropy": 1.5140467699873383, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 21735.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "env_runners": {"episode_reward_max": 186.6999999999992, "episode_reward_min": -267.6999999999997, "episode_reward_mean": 2.826999999999873, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -469.6000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 174.8, "predator_policy": 269.0}, "policy_reward_mean": {"prey_policy": -43.45150000000006, "predator_policy": 44.865}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.6999999999992, 56.200000000000514, -77.50000000000004, -9.299999999999962, 40.0000000000003, 46.300000000000274, 21.300000000000175, 44.700000000000486, -88.50000000000057, 133.59999999999872, 82.2999999999992, 61.80000000000042, 31.200000000000276, 62.400000000000496, 61.10000000000005, 154.29999999999885, 40.0000000000003, -64.50000000000097, 15.600000000000039, 135.39999999999836, 57.10000000000052, -19.10000000000007, 51.70000000000049, -32.79999999999999, 74.99999999999963, 89.59999999999887, 8.099999999999975, 63.4000000000005, 13.200000000000124, 8.599999999999568, -95.20000000000141, 108.19999999999851, -1.399999999999975, 38.90000000000028, -59.00000000000084, 31.700000000000163, -82.80000000000007, -4.899999999999714, -15.099999999999977, 143.49999999999878, -69.79999999999993, -35.60000000000001, 53.800000000000324, -63.60000000000011, 7.500000000000075, -267.6999999999997, -111.29999999999995, -6.999999999999945, 177.69999999999905, 82.29999999999917, -2.6000000000003842, -105.20000000000105, 14.800000000000045, 8.700000000000122, 81.99999999999918, 40.0000000000003, 55.699999999999555, -21.29999999999989, 47.700000000000394, 73.89999999999974, 50.10000000000005, 19.000000000000004, -34.29999999999994, -83.40000000000009, -49.40000000000008, -87.4, -54.39999999999986, -5.299999999999612, -71.70000000000005, -200.60000000000036, -0.7000000000000277, -261.50000000000017, 92.0999999999986, -80.20000000000059, -62.700000000000124, -30.59999999999988, -36.500000000000014, 33.00000000000024, 63.600000000000435, -137.80000000000007, 33.099999999999724, -216.0000000000001, 14.30000000000036, -69.30000000000004, -243.80000000000004, 62.80000000000037, -14.099999999999904, 79.89999999999984, 82.59999999999971, 2.200000000000022, -163.99999999999983, -55.699999999999875, 50.00000000000022, 134.59999999999977, 92.80000000000017, -27.59999999999983, 41.30000000000026, 167.2999999999995, -72.10000000000011, 51.300000000000274], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [25.400000000000006, 161.29999999999984, 36.20000000000025, 20.000000000000014, -55.000000000000014, -101.50000000000001, -66.10000000000066, -17.19999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.299999999999976, -48.70000000000002, 20.000000000000014, 1.6999999999999924, 26.000000000000117, -223.60000000000045, -25.89999999999999, 113.59999999999945, 20.000000000000014, 29.000000000000163, 53.30000000000023, -32.499999999999766, 68.2999999999999, 20.000000000000014, -23.79999999999984, 20.000000000000014, 37.40000000000023, -106.30000000000038, 61.40000000000004, 20.000000000000014, 134.29999999999959, 20.000000000000014, 20.000000000000014, -194.50000000000043, 20.000000000000014, 29.000000000000163, -90.40000000000038, 82.09999999999926, 53.30000000000023, 37.10000000000026, 20.000000000000014, -36.699999999999775, -30.400000000000013, 20.900000000000027, 30.800000000000196, 20.000000000000014, -138.79999999999995, 20.000000000000014, 32.00000000000015, 65.00000000000007, -15.399999999999862, -74.50000000000087, 29.60000000000025, 20.000000000000014, 43.40000000000025, 66.19999999999993, -160.00000000000057, -28.299999999999837, -48.09999999999996, -137.50000000000063, -78.70000000000077, 28.400000000000176, 57.800000000000196, -91.30000000000004, 14.899999999999983, 20.000000000000014, 17.899999999999977, -93.40000000000057, -55.60000000000002, 11.900000000000004, -5.199999999999983, 20.000000000000014, -248.79999999999998, 15.799999999999962, -57.70000000000048, -63.09999999999998, -85.00000000000077, 118.0999999999995, 25.40000000000004, 20.000000000000014, -224.8000000000001, 20.000000000000014, -265.6, 20.90000000000003, -6.100000000000023, -66.1000000000005, -125.50000000000009, -122.80000000000047, 17.300000000000047, -230.20000000000007, -326.50000000000006, -1.0, -274.30000000000007, -34.60000000000004, -27.399999999999835, 78.49999999999957, 99.19999999999942, 20.000000000000014, 62.30000000000022, -57.40000000000042, 15.80000000000006, -135.40000000000035, -101.80000000000062, 54.20000000000008, -93.40000000000046, 26.899999999999856, -110.20000000000019, 36.20000000000024, 39.80000000000021, 20.000000000000014, 20.000000000000014, -19.299999999999905, -6.999999999999922, -44.19999999999986, -108.10000000000016, 20.000000000000014, 16.699999999999974, 36.20000000000014, 13.699999999999958, -212.70000000000002, 111.79999999999963, 88.09999999999948, -150.10000000000062, -108.10000000000052, -137.2, 20.000000000000014, -234.40000000000015, -97.60000000000082, -50.79999999999987, -30.399999999999977, -180.0000000000002, -41.49999999999989, -184.90000000000003, -90.69999999999982, 22.40000000000008, -210.99999999999997, 5.299999999999967, -204.70000000000007, -172.90000000000052, -36.699999999999754, -45.99999999999989, -230.50000000000003, -328.00000000000034, 29.300000000000175, 45.80000000000018, 1.0999999999999865, -175.3000000000003, 74.59999999999937, -280.29999999999956, 28.100000000000147, -189.7, 42.800000000000054, -183.29999999999987, 79.39999999999975, -126.4000000000003, 11.59999999999998, 20.000000000000014, -158.50000000000006, -215.30000000000004, -19.299999999999937, -13.599999999999882, -269.0, -219.00000000000003, -5.200000000000035, -77.49999999999989, 20.000000000000014, -190.30000000000055, -276.6, -276.19999999999993, 52.400000000000205, -97.60000000000024, -249.10000000000002, 29.0, -53.49999999999989, 91.39999999999992, 29.900000000000038, -158.29999999999995, -143.8000000000007, 20.000000000000014, -215.79999999999995, -131.19999999999996, -162.70000000000016, 20.000000000000014, 50.600000000000186, -331.5999999999999, -114.40000000000003, 145.99999999999994, 16.100000000000154, 67.69999999999995, -469.6000000000001, 20.000000000000014, -29.199999999999832, 12.500000000000068, 174.8, -32.49999999999975, -94.59999999999992, -53.49999999999997, 7.399999999999988, 5.899999999999998], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 79.0, 19.0, 55.0, 0.0, 0.0, 0.0, 9.0, 24.0, 26.0, 17.0, 0.0, 161.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 25.0, 35.0, 0.0, 5.0, 0.0, 4.0, 102.0, 0.0, 0.0, 0.0, 0.0, 1.0, 109.0, 0.0, 77.0, 0.0, 0.0, 0.0, 0.0, 17.0, 31.0, 0.0, 0.0, 0.0, 86.0, 0.0, 23.0, 0.0, 40.0, 49.0, 4.0, 0.0, 0.0, 17.0, 90.0, 33.0, 52.0, 46.0, 75.0, 0.0, 22.0, 57.0, 18.0, 1.0, 0.0, 54.0, 36.0, 0.0, 25.0, 32.0, 114.0, 0.0, 37.0, 104.0, 29.0, 0.0, 0.0, 119.0, 16.0, 116.0, 94.0, 0.0, 39.0, 50.0, 78.0, 80.0, 33.0, 129.0, 160.0, 11.0, 153.0, 45.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 31.0, 101.0, 9.0, 45.0, 0.0, 92.0, 0.0, 6.0, 0.0, 0.0, 57.0, 25.0, 51.0, 80.0, 0.0, 11.0, 0.0, 24.0, 79.0, 72.0, 0.0, 81.0, 148.0, 63.0, 0.0, 131.0, 38.0, 61.0, 123.0, 0.0, 0.0, 172.0, 22.0, 41.0, 54.0, 80.0, 157.0, 20.0, 39.0, 43.0, 28.0, 269.0, 0.0, 17.0, 0.0, 94.0, 143.0, 0.0, 131.0, 0.0, 81.0, 23.0, 68.0, 12.0, 13.0, 19.0, 148.0, 88.0, 41.0, 25.0, 129.0, 143.0, 56.0, 41.0, 67.0, 34.0, 224.0, 85.0, 56.0, 52.0, 206.0, 0.0, 35.0, 7.0, 98.0, 113.0, 51.0, 75.0, 53.0, 130.0, 16.0, 71.0, 179.0, 152.0, 59.0, 44.0, 7.0, 2.0, 158.0, 264.0, 48.0, 10.0, 0.0, 25.0, 76.0, 0.0, 26.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.245889590863098, "mean_inference_ms": 3.306749069302027, "mean_action_processing_ms": 0.48640928501697656, "mean_env_wait_ms": 0.7705426480059191, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00618135929107666, "StateBufferConnector_ms": 0.004220366477966309, "ViewRequirementAgentConnector_ms": 0.13879287242889404}, "num_episodes": 18, "episode_return_max": 186.6999999999992, "episode_return_min": -267.6999999999997, "episode_return_mean": 2.826999999999873, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 308.39827713885524, "num_env_steps_trained_throughput_per_sec": 308.39827713885524, "timesteps_total": 48000, "num_env_steps_sampled_lifetime": 48000, "num_agent_steps_sampled_lifetime": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 16415.179, "restore_workers_time_ms": 0.048, "training_step_time_ms": 16415.081, "sample_time_ms": 2484.335, "learn_time_ms": 13903.114, "learn_throughput": 287.705, "synch_weights_time_ms": 22.156}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "training_iteration": 12, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-55-30", "timestamp": 1723521330, "time_this_iter_s": 13.022348880767822, "time_total_s": 203.23396396636963, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28cd8b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 203.23396396636963, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 71.24736842105264, "ram_util_percent": 83.1842105263158}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3236781522651356, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9473374261427179, "policy_loss": -0.006559306962868918, "vf_loss": 1.9532329759269795, "vf_explained_var": 0.0021637030064113557, "kl": 0.01327514160467087, "entropy": 1.5254173962527482, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4306657921857935, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.123662173937237, "policy_loss": -0.00604492562561833, "vf_loss": 5.128637755737103, "vf_explained_var": 0.04844566444871287, "kl": 0.014257703379410893, "entropy": 1.4683556894776681, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 23625.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "env_runners": {"episode_reward_max": 221.79999999999927, "episode_reward_min": -267.6999999999997, "episode_reward_mean": 10.583999999999849, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -469.6000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 174.8, "predator_policy": 269.0}, "policy_reward_mean": {"prey_policy": -40.85300000000006, "predator_policy": 46.145}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.600000000000039, 135.39999999999836, 57.10000000000052, -19.10000000000007, 51.70000000000049, -32.79999999999999, 74.99999999999963, 89.59999999999887, 8.099999999999975, 63.4000000000005, 13.200000000000124, 8.599999999999568, -95.20000000000141, 108.19999999999851, -1.399999999999975, 38.90000000000028, -59.00000000000084, 31.700000000000163, -82.80000000000007, -4.899999999999714, -15.099999999999977, 143.49999999999878, -69.79999999999993, -35.60000000000001, 53.800000000000324, -63.60000000000011, 7.500000000000075, -267.6999999999997, -111.29999999999995, -6.999999999999945, 177.69999999999905, 82.29999999999917, -2.6000000000003842, -105.20000000000105, 14.800000000000045, 8.700000000000122, 81.99999999999918, 40.0000000000003, 55.699999999999555, -21.29999999999989, 47.700000000000394, 73.89999999999974, 50.10000000000005, 19.000000000000004, -34.29999999999994, -83.40000000000009, -49.40000000000008, -87.4, -54.39999999999986, -5.299999999999612, -71.70000000000005, -200.60000000000036, -0.7000000000000277, -261.50000000000017, 92.0999999999986, -80.20000000000059, -62.700000000000124, -30.59999999999988, -36.500000000000014, 33.00000000000024, 63.600000000000435, -137.80000000000007, 33.099999999999724, -216.0000000000001, 14.30000000000036, -69.30000000000004, -243.80000000000004, 62.80000000000037, -14.099999999999904, 79.89999999999984, 82.59999999999971, 2.200000000000022, -163.99999999999983, -55.699999999999875, 50.00000000000022, 134.59999999999977, 92.80000000000017, -27.59999999999983, 41.30000000000026, 167.2999999999995, -72.10000000000011, 51.300000000000274, 44.70000000000007, 69.70000000000009, 133.8999999999993, 111.99999999999851, 155.19999999999922, 217.69999999999962, 65.20000000000039, 62.500000000000504, -71.6000000000005, -32.79999999999967, 17.39999999999994, 56.200000000000045, 166.49999999999955, 125.39999999999912, 69.80000000000004, 127.99999999999972, 221.79999999999927, 16.199999999999953], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [29.000000000000163, -90.40000000000038, 82.09999999999926, 53.30000000000023, 37.10000000000026, 20.000000000000014, -36.699999999999775, -30.400000000000013, 20.900000000000027, 30.800000000000196, 20.000000000000014, -138.79999999999995, 20.000000000000014, 32.00000000000015, 65.00000000000007, -15.399999999999862, -74.50000000000087, 29.60000000000025, 20.000000000000014, 43.40000000000025, 66.19999999999993, -160.00000000000057, -28.299999999999837, -48.09999999999996, -137.50000000000063, -78.70000000000077, 28.400000000000176, 57.800000000000196, -91.30000000000004, 14.899999999999983, 20.000000000000014, 17.899999999999977, -93.40000000000057, -55.60000000000002, 11.900000000000004, -5.199999999999983, 20.000000000000014, -248.79999999999998, 15.799999999999962, -57.70000000000048, -63.09999999999998, -85.00000000000077, 118.0999999999995, 25.40000000000004, 20.000000000000014, -224.8000000000001, 20.000000000000014, -265.6, 20.90000000000003, -6.100000000000023, -66.1000000000005, -125.50000000000009, -122.80000000000047, 17.300000000000047, -230.20000000000007, -326.50000000000006, -1.0, -274.30000000000007, -34.60000000000004, -27.399999999999835, 78.49999999999957, 99.19999999999942, 20.000000000000014, 62.30000000000022, -57.40000000000042, 15.80000000000006, -135.40000000000035, -101.80000000000062, 54.20000000000008, -93.40000000000046, 26.899999999999856, -110.20000000000019, 36.20000000000024, 39.80000000000021, 20.000000000000014, 20.000000000000014, -19.299999999999905, -6.999999999999922, -44.19999999999986, -108.10000000000016, 20.000000000000014, 16.699999999999974, 36.20000000000014, 13.699999999999958, -212.70000000000002, 111.79999999999963, 88.09999999999948, -150.10000000000062, -108.10000000000052, -137.2, 20.000000000000014, -234.40000000000015, -97.60000000000082, -50.79999999999987, -30.399999999999977, -180.0000000000002, -41.49999999999989, -184.90000000000003, -90.69999999999982, 22.40000000000008, -210.99999999999997, 5.299999999999967, -204.70000000000007, -172.90000000000052, -36.699999999999754, -45.99999999999989, -230.50000000000003, -328.00000000000034, 29.300000000000175, 45.80000000000018, 1.0999999999999865, -175.3000000000003, 74.59999999999937, -280.29999999999956, 28.100000000000147, -189.7, 42.800000000000054, -183.29999999999987, 79.39999999999975, -126.4000000000003, 11.59999999999998, 20.000000000000014, -158.50000000000006, -215.30000000000004, -19.299999999999937, -13.599999999999882, -269.0, -219.00000000000003, -5.200000000000035, -77.49999999999989, 20.000000000000014, -190.30000000000055, -276.6, -276.19999999999993, 52.400000000000205, -97.60000000000024, -249.10000000000002, 29.0, -53.49999999999989, 91.39999999999992, 29.900000000000038, -158.29999999999995, -143.8000000000007, 20.000000000000014, -215.79999999999995, -131.19999999999996, -162.70000000000016, 20.000000000000014, 50.600000000000186, -331.5999999999999, -114.40000000000003, 145.99999999999994, 16.100000000000154, 67.69999999999995, -469.6000000000001, 20.000000000000014, -29.199999999999832, 12.500000000000068, 174.8, -32.49999999999975, -94.59999999999992, -53.49999999999997, 7.399999999999988, 5.899999999999998, 103.39999999999992, -170.70000000000005, 20.000000000000014, 49.70000000000024, -39.40000000000012, 116.29999999999961, 87.49999999999929, 24.50000000000009, 132.4999999999998, 22.70000000000001, 96.49999999999986, 105.19999999999999, 20.000000000000014, 45.2000000000001, 28.10000000000016, 34.40000000000026, -328.59999999999985, 20.000000000000014, 20.000000000000014, -125.80000000000052, -25.59999999999976, 20.000000000000014, 50.59999999999999, -24.39999999999975, 105.8, 31.700000000000088, 62.300000000000196, 40.09999999999998, -225.70000000000005, 30.499999999999982, 133.39999999999998, -30.399999999999814, 154.0999999999997, 67.69999999999997, -41.79999999999982, 20.000000000000014], "policy_predator_policy_reward": [0.0, 77.0, 0.0, 0.0, 0.0, 0.0, 17.0, 31.0, 0.0, 0.0, 0.0, 86.0, 0.0, 23.0, 0.0, 40.0, 49.0, 4.0, 0.0, 0.0, 17.0, 90.0, 33.0, 52.0, 46.0, 75.0, 0.0, 22.0, 57.0, 18.0, 1.0, 0.0, 54.0, 36.0, 0.0, 25.0, 32.0, 114.0, 0.0, 37.0, 104.0, 29.0, 0.0, 0.0, 119.0, 16.0, 116.0, 94.0, 0.0, 39.0, 50.0, 78.0, 80.0, 33.0, 129.0, 160.0, 11.0, 153.0, 45.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 31.0, 101.0, 9.0, 45.0, 0.0, 92.0, 0.0, 6.0, 0.0, 0.0, 57.0, 25.0, 51.0, 80.0, 0.0, 11.0, 0.0, 24.0, 79.0, 72.0, 0.0, 81.0, 148.0, 63.0, 0.0, 131.0, 38.0, 61.0, 123.0, 0.0, 0.0, 172.0, 22.0, 41.0, 54.0, 80.0, 157.0, 20.0, 39.0, 43.0, 28.0, 269.0, 0.0, 17.0, 0.0, 94.0, 143.0, 0.0, 131.0, 0.0, 81.0, 23.0, 68.0, 12.0, 13.0, 19.0, 148.0, 88.0, 41.0, 25.0, 129.0, 143.0, 56.0, 41.0, 67.0, 34.0, 224.0, 85.0, 56.0, 52.0, 206.0, 0.0, 35.0, 7.0, 98.0, 113.0, 51.0, 75.0, 53.0, 130.0, 16.0, 71.0, 179.0, 152.0, 59.0, 44.0, 7.0, 2.0, 158.0, 264.0, 48.0, 10.0, 0.0, 25.0, 76.0, 0.0, 26.0, 12.0, 16.0, 96.0, 0.0, 0.0, 20.0, 37.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 166.0, 71.0, 53.0, 20.0, 0.0, 23.0, 22.0, 8.0, 29.0, 0.0, 3.0, 20.0, 131.0, 134.0, 0.0, 25.0, 0.0, 0.0, 0.0, 38.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2235977518548833, "mean_inference_ms": 3.2526374458386966, "mean_action_processing_ms": 0.47809721145450107, "mean_env_wait_ms": 0.7565073283772168, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0061991214752197266, "StateBufferConnector_ms": 0.008826255798339844, "ViewRequirementAgentConnector_ms": 0.1480083465576172}, "num_episodes": 18, "episode_return_max": 221.79999999999927, "episode_return_min": -267.6999999999997, "episode_return_mean": 10.583999999999849, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 245.611052726921, "num_env_steps_trained_throughput_per_sec": 245.611052726921, "timesteps_total": 52000, "num_env_steps_sampled_lifetime": 52000, "num_agent_steps_sampled_lifetime": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 16174.981, "restore_workers_time_ms": 0.048, "training_step_time_ms": 16174.883, "sample_time_ms": 2553.918, "learn_time_ms": 13596.513, "learn_throughput": 294.193, "synch_weights_time_ms": 19.092}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "training_iteration": 13, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-55-46", "timestamp": 1723521346, "time_this_iter_s": 16.333855152130127, "time_total_s": 219.56781911849976, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28360d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 219.56781911849976, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 79.33043478260869, "ram_util_percent": 83.5086956521739}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.28430660054600115, "cur_kl_coeff": 0.05, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.4651324181960375, "policy_loss": -0.0010943694167065794, "vf_loss": 2.4659814790443138, "vf_explained_var": 0.0020011447094104907, "kl": 0.004906187750399478, "entropy": 1.5358970698856171, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2974656569106238, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.215184780908009, "policy_loss": -0.0056668885763015145, "vf_loss": 5.21969250636126, "vf_explained_var": 0.043069874041925665, "kl": 0.015455401109021508, "entropy": 1.4201773075830368, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 25515.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "env_runners": {"episode_reward_max": 293.8000000000005, "episode_reward_min": -267.6999999999997, "episode_reward_mean": 27.939999999999863, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -469.6000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 174.8, "predator_policy": 269.0}, "policy_reward_mean": {"prey_policy": -29.115000000000045, "predator_policy": 43.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-267.6999999999997, -111.29999999999995, -6.999999999999945, 177.69999999999905, 82.29999999999917, -2.6000000000003842, -105.20000000000105, 14.800000000000045, 8.700000000000122, 81.99999999999918, 40.0000000000003, 55.699999999999555, -21.29999999999989, 47.700000000000394, 73.89999999999974, 50.10000000000005, 19.000000000000004, -34.29999999999994, -83.40000000000009, -49.40000000000008, -87.4, -54.39999999999986, -5.299999999999612, -71.70000000000005, -200.60000000000036, -0.7000000000000277, -261.50000000000017, 92.0999999999986, -80.20000000000059, -62.700000000000124, -30.59999999999988, -36.500000000000014, 33.00000000000024, 63.600000000000435, -137.80000000000007, 33.099999999999724, -216.0000000000001, 14.30000000000036, -69.30000000000004, -243.80000000000004, 62.80000000000037, -14.099999999999904, 79.89999999999984, 82.59999999999971, 2.200000000000022, -163.99999999999983, -55.699999999999875, 50.00000000000022, 134.59999999999977, 92.80000000000017, -27.59999999999983, 41.30000000000026, 167.2999999999995, -72.10000000000011, 51.300000000000274, 44.70000000000007, 69.70000000000009, 133.8999999999993, 111.99999999999851, 155.19999999999922, 217.69999999999962, 65.20000000000039, 62.500000000000504, -71.6000000000005, -32.79999999999967, 17.39999999999994, 56.200000000000045, 166.49999999999955, 125.39999999999912, 69.80000000000004, 127.99999999999972, 221.79999999999927, 16.199999999999953, 87.70000000000005, 37.40000000000029, 55.49999999999953, 135.99999999999937, 1.0000000000001823, 125.29999999999981, 40.0000000000003, 127.39999999999947, 56.20000000000027, 108.49999999999918, 172.3999999999995, 29.700000000000106, 52.600000000000264, 69.39999999999993, -89.80000000000038, 100.79999999999947, 120.29999999999986, 103.29999999999899, 151.29999999999998, 9.900000000000192, -30.899999999999814, 111.89999999999966, 293.8000000000005, 96.49999999999989, 9.699999999999957, 176.19999999999922, 5.500000000000105], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-230.20000000000007, -326.50000000000006, -1.0, -274.30000000000007, -34.60000000000004, -27.399999999999835, 78.49999999999957, 99.19999999999942, 20.000000000000014, 62.30000000000022, -57.40000000000042, 15.80000000000006, -135.40000000000035, -101.80000000000062, 54.20000000000008, -93.40000000000046, 26.899999999999856, -110.20000000000019, 36.20000000000024, 39.80000000000021, 20.000000000000014, 20.000000000000014, -19.299999999999905, -6.999999999999922, -44.19999999999986, -108.10000000000016, 20.000000000000014, 16.699999999999974, 36.20000000000014, 13.699999999999958, -212.70000000000002, 111.79999999999963, 88.09999999999948, -150.10000000000062, -108.10000000000052, -137.2, 20.000000000000014, -234.40000000000015, -97.60000000000082, -50.79999999999987, -30.399999999999977, -180.0000000000002, -41.49999999999989, -184.90000000000003, -90.69999999999982, 22.40000000000008, -210.99999999999997, 5.299999999999967, -204.70000000000007, -172.90000000000052, -36.699999999999754, -45.99999999999989, -230.50000000000003, -328.00000000000034, 29.300000000000175, 45.80000000000018, 1.0999999999999865, -175.3000000000003, 74.59999999999937, -280.29999999999956, 28.100000000000147, -189.7, 42.800000000000054, -183.29999999999987, 79.39999999999975, -126.4000000000003, 11.59999999999998, 20.000000000000014, -158.50000000000006, -215.30000000000004, -19.299999999999937, -13.599999999999882, -269.0, -219.00000000000003, -5.200000000000035, -77.49999999999989, 20.000000000000014, -190.30000000000055, -276.6, -276.19999999999993, 52.400000000000205, -97.60000000000024, -249.10000000000002, 29.0, -53.49999999999989, 91.39999999999992, 29.900000000000038, -158.29999999999995, -143.8000000000007, 20.000000000000014, -215.79999999999995, -131.19999999999996, -162.70000000000016, 20.000000000000014, 50.600000000000186, -331.5999999999999, -114.40000000000003, 145.99999999999994, 16.100000000000154, 67.69999999999995, -469.6000000000001, 20.000000000000014, -29.199999999999832, 12.500000000000068, 174.8, -32.49999999999975, -94.59999999999992, -53.49999999999997, 7.399999999999988, 5.899999999999998, 103.39999999999992, -170.70000000000005, 20.000000000000014, 49.70000000000024, -39.40000000000012, 116.29999999999961, 87.49999999999929, 24.50000000000009, 132.4999999999998, 22.70000000000001, 96.49999999999986, 105.19999999999999, 20.000000000000014, 45.2000000000001, 28.10000000000016, 34.40000000000026, -328.59999999999985, 20.000000000000014, 20.000000000000014, -125.80000000000052, -25.59999999999976, 20.000000000000014, 50.59999999999999, -24.39999999999975, 105.8, 31.700000000000088, 62.300000000000196, 40.09999999999998, -225.70000000000005, 30.499999999999982, 133.39999999999998, -30.399999999999814, 154.0999999999997, 67.69999999999997, -41.79999999999982, 20.000000000000014, 20.000000000000014, 67.7000000000001, 11.599999999999953, 21.80000000000001, -53.50000000000004, 47.000000000000114, 89.29999999999978, 40.70000000000023, 20.000000000000014, -91.00000000000068, 30.20000000000015, 40.099999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 76.39999999999984, 20.000000000000014, 36.200000000000024, 67.40000000000013, 28.10000000000015, 126.5, 20.90000000000003, -3.0999999999999615, 21.80000000000002, 42.50000000000002, -52.8999999999999, 7.100000000000037, 23.300000000000097, 20.000000000000014, -227.80000000000015, 51.800000000000075, 20.000000000000014, 20.000000000000014, 32.29999999999994, 62.30000000000012, 20.000000000000014, -13.600000000000009, 113.89999999999998, -84.10000000000011, 20.000000000000014, -223.9000000000003, 26.00000000000013, -103.9000000000008, 156.79999999999984, 150.49999999999974, 143.29999999999995, 89.60000000000002, -87.10000000000079, -28.29999999999975, -10.0, 72.20000000000009, 91.99999999999955, 51.500000000000014, -106.0], "policy_predator_policy_reward": [129.0, 160.0, 11.0, 153.0, 45.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 31.0, 101.0, 9.0, 45.0, 0.0, 92.0, 0.0, 6.0, 0.0, 0.0, 57.0, 25.0, 51.0, 80.0, 0.0, 11.0, 0.0, 24.0, 79.0, 72.0, 0.0, 81.0, 148.0, 63.0, 0.0, 131.0, 38.0, 61.0, 123.0, 0.0, 0.0, 172.0, 22.0, 41.0, 54.0, 80.0, 157.0, 20.0, 39.0, 43.0, 28.0, 269.0, 0.0, 17.0, 0.0, 94.0, 143.0, 0.0, 131.0, 0.0, 81.0, 23.0, 68.0, 12.0, 13.0, 19.0, 148.0, 88.0, 41.0, 25.0, 129.0, 143.0, 56.0, 41.0, 67.0, 34.0, 224.0, 85.0, 56.0, 52.0, 206.0, 0.0, 35.0, 7.0, 98.0, 113.0, 51.0, 75.0, 53.0, 130.0, 16.0, 71.0, 179.0, 152.0, 59.0, 44.0, 7.0, 2.0, 158.0, 264.0, 48.0, 10.0, 0.0, 25.0, 76.0, 0.0, 26.0, 12.0, 16.0, 96.0, 0.0, 0.0, 20.0, 37.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 166.0, 71.0, 53.0, 20.0, 0.0, 23.0, 22.0, 8.0, 29.0, 0.0, 3.0, 20.0, 131.0, 134.0, 0.0, 25.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 4.0, 0.0, 62.0, 0.0, 6.0, 0.0, 34.0, 38.0, 43.0, 12.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 13.0, 0.0, 4.0, 21.0, 11.0, 0.0, 44.0, 19.0, 39.0, 0.0, 118.0, 0.0, 0.0, 29.0, 41.0, 27.0, 21.0, 0.0, 51.0, 0.0, 74.0, 0.0, 81.0, 86.0, 0.0, 59.0, 0.0, 0.0, 51.0, 43.0, 39.0, 9.0, 12.0, 0.0, 0.0, 60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1998673409390685, "mean_inference_ms": 3.201254678510091, "mean_action_processing_ms": 0.47415738541821467, "mean_env_wait_ms": 0.7435246313642933, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007205843925476074, "StateBufferConnector_ms": 0.008948087692260742, "ViewRequirementAgentConnector_ms": 0.14875924587249756}, "num_episodes": 27, "episode_return_max": 293.8000000000005, "episode_return_min": -267.6999999999997, "episode_return_mean": 27.939999999999863, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 277.3083194763603, "num_env_steps_trained_throughput_per_sec": 277.3083194763603, "timesteps_total": 56000, "num_env_steps_sampled_lifetime": 56000, "num_agent_steps_sampled_lifetime": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 15998.587, "restore_workers_time_ms": 0.045, "training_step_time_ms": 15998.491, "sample_time_ms": 2511.324, "learn_time_ms": 13462.925, "learn_throughput": 297.112, "synch_weights_time_ms": 19.01}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "training_iteration": 14, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-56-01", "timestamp": 1723521361, "time_this_iter_s": 14.471098899841309, "time_total_s": 234.03891801834106, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x330dc5f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 234.03891801834106, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 77.94, "ram_util_percent": 83.59}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.23345347726076998, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2169736613987614, "policy_loss": -0.003154013825521346, "vf_loss": 1.219836831597424, "vf_explained_var": 0.0008924040529463026, "kl": 0.011633889192875774, "entropy": 1.5714787302824555, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2101157376769358, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.878182695530079, "policy_loss": -0.0021737661110434346, "vf_loss": 3.879811400080484, "vf_explained_var": 0.0821430209452513, "kl": 0.007267556755610945, "entropy": 1.4253306198372413, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 27405.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "env_runners": {"episode_reward_max": 293.8000000000005, "episode_reward_min": -261.50000000000017, "episode_reward_mean": 42.20499999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -469.6000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 174.8, "predator_policy": 269.0}, "policy_reward_mean": {"prey_policy": -16.25750000000004, "predator_policy": 37.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-83.40000000000009, -49.40000000000008, -87.4, -54.39999999999986, -5.299999999999612, -71.70000000000005, -200.60000000000036, -0.7000000000000277, -261.50000000000017, 92.0999999999986, -80.20000000000059, -62.700000000000124, -30.59999999999988, -36.500000000000014, 33.00000000000024, 63.600000000000435, -137.80000000000007, 33.099999999999724, -216.0000000000001, 14.30000000000036, -69.30000000000004, -243.80000000000004, 62.80000000000037, -14.099999999999904, 79.89999999999984, 82.59999999999971, 2.200000000000022, -163.99999999999983, -55.699999999999875, 50.00000000000022, 134.59999999999977, 92.80000000000017, -27.59999999999983, 41.30000000000026, 167.2999999999995, -72.10000000000011, 51.300000000000274, 44.70000000000007, 69.70000000000009, 133.8999999999993, 111.99999999999851, 155.19999999999922, 217.69999999999962, 65.20000000000039, 62.500000000000504, -71.6000000000005, -32.79999999999967, 17.39999999999994, 56.200000000000045, 166.49999999999955, 125.39999999999912, 69.80000000000004, 127.99999999999972, 221.79999999999927, 16.199999999999953, 87.70000000000005, 37.40000000000029, 55.49999999999953, 135.99999999999937, 1.0000000000001823, 125.29999999999981, 40.0000000000003, 127.39999999999947, 56.20000000000027, 108.49999999999918, 172.3999999999995, 29.700000000000106, 52.600000000000264, 69.39999999999993, -89.80000000000038, 100.79999999999947, 120.29999999999986, 103.29999999999899, 151.29999999999998, 9.900000000000192, -30.899999999999814, 111.89999999999966, 293.8000000000005, 96.49999999999989, 9.699999999999957, 176.19999999999922, 5.500000000000105, 40.0000000000003, 143.599999999999, 13.100000000000176, 210.89999999999964, 31.00000000000007, 78.0999999999993, 201.29999999999902, 34.50000000000022, 41.800000000000324, 92.3999999999989, 52.10000000000036, 62.20000000000044, 64.20000000000024, 66.10000000000035, 106.59999999999948, 120.99999999999878, 104.80000000000014, 65.30000000000037], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -234.40000000000015, -97.60000000000082, -50.79999999999987, -30.399999999999977, -180.0000000000002, -41.49999999999989, -184.90000000000003, -90.69999999999982, 22.40000000000008, -210.99999999999997, 5.299999999999967, -204.70000000000007, -172.90000000000052, -36.699999999999754, -45.99999999999989, -230.50000000000003, -328.00000000000034, 29.300000000000175, 45.80000000000018, 1.0999999999999865, -175.3000000000003, 74.59999999999937, -280.29999999999956, 28.100000000000147, -189.7, 42.800000000000054, -183.29999999999987, 79.39999999999975, -126.4000000000003, 11.59999999999998, 20.000000000000014, -158.50000000000006, -215.30000000000004, -19.299999999999937, -13.599999999999882, -269.0, -219.00000000000003, -5.200000000000035, -77.49999999999989, 20.000000000000014, -190.30000000000055, -276.6, -276.19999999999993, 52.400000000000205, -97.60000000000024, -249.10000000000002, 29.0, -53.49999999999989, 91.39999999999992, 29.900000000000038, -158.29999999999995, -143.8000000000007, 20.000000000000014, -215.79999999999995, -131.19999999999996, -162.70000000000016, 20.000000000000014, 50.600000000000186, -331.5999999999999, -114.40000000000003, 145.99999999999994, 16.100000000000154, 67.69999999999995, -469.6000000000001, 20.000000000000014, -29.199999999999832, 12.500000000000068, 174.8, -32.49999999999975, -94.59999999999992, -53.49999999999997, 7.399999999999988, 5.899999999999998, 103.39999999999992, -170.70000000000005, 20.000000000000014, 49.70000000000024, -39.40000000000012, 116.29999999999961, 87.49999999999929, 24.50000000000009, 132.4999999999998, 22.70000000000001, 96.49999999999986, 105.19999999999999, 20.000000000000014, 45.2000000000001, 28.10000000000016, 34.40000000000026, -328.59999999999985, 20.000000000000014, 20.000000000000014, -125.80000000000052, -25.59999999999976, 20.000000000000014, 50.59999999999999, -24.39999999999975, 105.8, 31.700000000000088, 62.300000000000196, 40.09999999999998, -225.70000000000005, 30.499999999999982, 133.39999999999998, -30.399999999999814, 154.0999999999997, 67.69999999999997, -41.79999999999982, 20.000000000000014, 20.000000000000014, 67.7000000000001, 11.599999999999953, 21.80000000000001, -53.50000000000004, 47.000000000000114, 89.29999999999978, 40.70000000000023, 20.000000000000014, -91.00000000000068, 30.20000000000015, 40.099999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 76.39999999999984, 20.000000000000014, 36.200000000000024, 67.40000000000013, 28.10000000000015, 126.5, 20.90000000000003, -3.0999999999999615, 21.80000000000002, 42.50000000000002, -52.8999999999999, 7.100000000000037, 23.300000000000097, 20.000000000000014, -227.80000000000015, 51.800000000000075, 20.000000000000014, 20.000000000000014, 32.29999999999994, 62.30000000000012, 20.000000000000014, -13.600000000000009, 113.89999999999998, -84.10000000000011, 20.000000000000014, -223.9000000000003, 26.00000000000013, -103.9000000000008, 156.79999999999984, 150.49999999999974, 143.29999999999995, 89.60000000000002, -87.10000000000079, -28.29999999999975, -10.0, 72.20000000000009, 91.99999999999955, 51.500000000000014, -106.0, 20.000000000000014, 20.000000000000014, 130.69999999999965, -9.099999999999905, 20.000000000000014, -46.90000000000057, 122.29999999999988, 65.60000000000002, -42.99999999999995, 20.000000000000014, 20.000000000000014, 46.100000000000186, 133.39999999999975, 59.900000000000176, 20.000000000000014, 9.499999999999964, 20.000000000000014, 21.80000000000004, 43.400000000000134, 20.00000000000003, -89.20000000000076, 89.2999999999993, 20.000000000000014, 36.20000000000014, 8.599999999999987, 14.600000000000009, 46.100000000000236, 20.000000000000014, 52.700000000000045, 17.899999999999988, 100.99999999999946, 20.000000000000014, 57.79999999999996, 10.999999999999607, 20.000000000000014, 32.3000000000002], "policy_predator_policy_reward": [0.0, 131.0, 38.0, 61.0, 123.0, 0.0, 0.0, 172.0, 22.0, 41.0, 54.0, 80.0, 157.0, 20.0, 39.0, 43.0, 28.0, 269.0, 0.0, 17.0, 0.0, 94.0, 143.0, 0.0, 131.0, 0.0, 81.0, 23.0, 68.0, 12.0, 13.0, 19.0, 148.0, 88.0, 41.0, 25.0, 129.0, 143.0, 56.0, 41.0, 67.0, 34.0, 224.0, 85.0, 56.0, 52.0, 206.0, 0.0, 35.0, 7.0, 98.0, 113.0, 51.0, 75.0, 53.0, 130.0, 16.0, 71.0, 179.0, 152.0, 59.0, 44.0, 7.0, 2.0, 158.0, 264.0, 48.0, 10.0, 0.0, 25.0, 76.0, 0.0, 26.0, 12.0, 16.0, 96.0, 0.0, 0.0, 20.0, 37.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 166.0, 71.0, 53.0, 20.0, 0.0, 23.0, 22.0, 8.0, 29.0, 0.0, 3.0, 20.0, 131.0, 134.0, 0.0, 25.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 4.0, 0.0, 62.0, 0.0, 6.0, 0.0, 34.0, 38.0, 43.0, 12.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 13.0, 0.0, 4.0, 21.0, 11.0, 0.0, 44.0, 19.0, 39.0, 0.0, 118.0, 0.0, 0.0, 29.0, 41.0, 27.0, 21.0, 0.0, 51.0, 0.0, 74.0, 0.0, 81.0, 86.0, 0.0, 59.0, 0.0, 0.0, 51.0, 43.0, 39.0, 9.0, 12.0, 0.0, 0.0, 60.0, 0.0, 0.0, 3.0, 19.0, 38.0, 2.0, 0.0, 23.0, 16.0, 38.0, 0.0, 12.0, 0.0, 8.0, 0.0, 5.0, 0.0, 0.0, 29.0, 0.0, 0.0, 52.0, 0.0, 6.0, 10.0, 31.0, 0.0, 0.0, 13.0, 23.0, 0.0, 0.0, 36.0, 0.0, 12.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1900652459780583, "mean_inference_ms": 3.167961956426032, "mean_action_processing_ms": 0.46693818019203337, "mean_env_wait_ms": 0.7345689191829325, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007352709770202637, "StateBufferConnector_ms": 0.009267687797546387, "ViewRequirementAgentConnector_ms": 0.15094983577728271}, "num_episodes": 18, "episode_return_max": 293.8000000000005, "episode_return_min": -261.50000000000017, "episode_return_mean": 42.20499999999986, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 290.1060382104694, "num_env_steps_trained_throughput_per_sec": 290.1060382104694, "timesteps_total": 60000, "num_env_steps_sampled_lifetime": 60000, "num_agent_steps_sampled_lifetime": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 15644.237, "restore_workers_time_ms": 0.045, "training_step_time_ms": 15644.143, "sample_time_ms": 2475.221, "learn_time_ms": 13148.735, "learn_throughput": 304.212, "synch_weights_time_ms": 15.333}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "training_iteration": 15, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-56-15", "timestamp": 1723521375, "time_this_iter_s": 13.844912767410278, "time_total_s": 247.88383078575134, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28ea9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 247.88383078575134, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 76.30999999999999, "ram_util_percent": 83.05999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.17293112846140665, "cur_kl_coeff": 0.025, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.021620291676471, "policy_loss": -0.0012016788723745516, "vf_loss": 1.0227286837797946, "vf_explained_var": 0.0007738899616968064, "kl": 0.003731504877261646, "entropy": 1.5909247995684386, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3089830948719903, "cur_kl_coeff": 0.07499999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.83244582515545, "policy_loss": -0.00014684004031575073, "vf_loss": 2.832303556247994, "vf_explained_var": 0.07090030867586691, "kl": 0.0038548659411353384, "entropy": 1.413499321697881, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 29295.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "env_runners": {"episode_reward_max": 293.8000000000005, "episode_reward_min": -243.80000000000004, "episode_reward_mean": 64.31299999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -469.6000000000001, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 174.8, "predator_policy": 264.0}, "policy_reward_mean": {"prey_policy": 3.276499999999962, "predator_policy": 28.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-216.0000000000001, 14.30000000000036, -69.30000000000004, -243.80000000000004, 62.80000000000037, -14.099999999999904, 79.89999999999984, 82.59999999999971, 2.200000000000022, -163.99999999999983, -55.699999999999875, 50.00000000000022, 134.59999999999977, 92.80000000000017, -27.59999999999983, 41.30000000000026, 167.2999999999995, -72.10000000000011, 51.300000000000274, 44.70000000000007, 69.70000000000009, 133.8999999999993, 111.99999999999851, 155.19999999999922, 217.69999999999962, 65.20000000000039, 62.500000000000504, -71.6000000000005, -32.79999999999967, 17.39999999999994, 56.200000000000045, 166.49999999999955, 125.39999999999912, 69.80000000000004, 127.99999999999972, 221.79999999999927, 16.199999999999953, 87.70000000000005, 37.40000000000029, 55.49999999999953, 135.99999999999937, 1.0000000000001823, 125.29999999999981, 40.0000000000003, 127.39999999999947, 56.20000000000027, 108.49999999999918, 172.3999999999995, 29.700000000000106, 52.600000000000264, 69.39999999999993, -89.80000000000038, 100.79999999999947, 120.29999999999986, 103.29999999999899, 151.29999999999998, 9.900000000000192, -30.899999999999814, 111.89999999999966, 293.8000000000005, 96.49999999999989, 9.699999999999957, 176.19999999999922, 5.500000000000105, 40.0000000000003, 143.599999999999, 13.100000000000176, 210.89999999999964, 31.00000000000007, 78.0999999999993, 201.29999999999902, 34.50000000000022, 41.800000000000324, 92.3999999999989, 52.10000000000036, 62.20000000000044, 64.20000000000024, 66.10000000000035, 106.59999999999948, 120.99999999999878, 104.80000000000014, 65.30000000000037, 18.69999999999998, 74.49999999999973, 124.80000000000007, 143.49999999999952, 167.59999999999874, 70.8999999999998, -3.9999999999997526, 87.79999999999885, 40.0000000000003, -29.899999999999743, -39.6999999999998, 54.2000000000003, 184.99999999999903, 41.40000000000032, 122.79999999999887, 40.9000000000003, 162.69999999999854, 9.200000000000099], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-269.0, -219.00000000000003, -5.200000000000035, -77.49999999999989, 20.000000000000014, -190.30000000000055, -276.6, -276.19999999999993, 52.400000000000205, -97.60000000000024, -249.10000000000002, 29.0, -53.49999999999989, 91.39999999999992, 29.900000000000038, -158.29999999999995, -143.8000000000007, 20.000000000000014, -215.79999999999995, -131.19999999999996, -162.70000000000016, 20.000000000000014, 50.600000000000186, -331.5999999999999, -114.40000000000003, 145.99999999999994, 16.100000000000154, 67.69999999999995, -469.6000000000001, 20.000000000000014, -29.199999999999832, 12.500000000000068, 174.8, -32.49999999999975, -94.59999999999992, -53.49999999999997, 7.399999999999988, 5.899999999999998, 103.39999999999992, -170.70000000000005, 20.000000000000014, 49.70000000000024, -39.40000000000012, 116.29999999999961, 87.49999999999929, 24.50000000000009, 132.4999999999998, 22.70000000000001, 96.49999999999986, 105.19999999999999, 20.000000000000014, 45.2000000000001, 28.10000000000016, 34.40000000000026, -328.59999999999985, 20.000000000000014, 20.000000000000014, -125.80000000000052, -25.59999999999976, 20.000000000000014, 50.59999999999999, -24.39999999999975, 105.8, 31.700000000000088, 62.300000000000196, 40.09999999999998, -225.70000000000005, 30.499999999999982, 133.39999999999998, -30.399999999999814, 154.0999999999997, 67.69999999999997, -41.79999999999982, 20.000000000000014, 20.000000000000014, 67.7000000000001, 11.599999999999953, 21.80000000000001, -53.50000000000004, 47.000000000000114, 89.29999999999978, 40.70000000000023, 20.000000000000014, -91.00000000000068, 30.20000000000015, 40.099999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 76.39999999999984, 20.000000000000014, 36.200000000000024, 67.40000000000013, 28.10000000000015, 126.5, 20.90000000000003, -3.0999999999999615, 21.80000000000002, 42.50000000000002, -52.8999999999999, 7.100000000000037, 23.300000000000097, 20.000000000000014, -227.80000000000015, 51.800000000000075, 20.000000000000014, 20.000000000000014, 32.29999999999994, 62.30000000000012, 20.000000000000014, -13.600000000000009, 113.89999999999998, -84.10000000000011, 20.000000000000014, -223.9000000000003, 26.00000000000013, -103.9000000000008, 156.79999999999984, 150.49999999999974, 143.29999999999995, 89.60000000000002, -87.10000000000079, -28.29999999999975, -10.0, 72.20000000000009, 91.99999999999955, 51.500000000000014, -106.0, 20.000000000000014, 20.000000000000014, 130.69999999999965, -9.099999999999905, 20.000000000000014, -46.90000000000057, 122.29999999999988, 65.60000000000002, -42.99999999999995, 20.000000000000014, 20.000000000000014, 46.100000000000186, 133.39999999999975, 59.900000000000176, 20.000000000000014, 9.499999999999964, 20.000000000000014, 21.80000000000004, 43.400000000000134, 20.00000000000003, -89.20000000000076, 89.2999999999993, 20.000000000000014, 36.20000000000014, 8.599999999999987, 14.600000000000009, 46.100000000000236, 20.000000000000014, 52.700000000000045, 17.899999999999988, 100.99999999999946, 20.000000000000014, 57.79999999999996, 10.999999999999607, 20.000000000000014, 32.3000000000002, 13.699999999999964, -15.999999999999806, 37.10000000000026, 25.400000000000112, 40.69999999999998, 58.1000000000001, 23.90000000000002, 68.59999999999988, 90.19999999999936, 67.3999999999999, -30.399999999999764, 53.30000000000012, -28.299999999999763, -15.699999999999783, 44.3000000000002, 30.50000000000019, 20.000000000000014, 20.000000000000014, -7.899999999999988, -106.0000000000008, -55.600000000000335, -63.1000000000007, -24.099999999999767, 23.3000000000001, 102.79999999999973, 63.20000000000017, 20.000000000000014, 19.400000000000006, 20.000000000000014, 102.79999999999951, 20.90000000000003, 20.000000000000014, 87.49999999999929, 72.1999999999996, -19.899999999999757, 7.099999999999973], "policy_predator_policy_reward": [129.0, 143.0, 56.0, 41.0, 67.0, 34.0, 224.0, 85.0, 56.0, 52.0, 206.0, 0.0, 35.0, 7.0, 98.0, 113.0, 51.0, 75.0, 53.0, 130.0, 16.0, 71.0, 179.0, 152.0, 59.0, 44.0, 7.0, 2.0, 158.0, 264.0, 48.0, 10.0, 0.0, 25.0, 76.0, 0.0, 26.0, 12.0, 16.0, 96.0, 0.0, 0.0, 20.0, 37.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 166.0, 71.0, 53.0, 20.0, 0.0, 23.0, 22.0, 8.0, 29.0, 0.0, 3.0, 20.0, 131.0, 134.0, 0.0, 25.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 4.0, 0.0, 62.0, 0.0, 6.0, 0.0, 34.0, 38.0, 43.0, 12.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 13.0, 0.0, 4.0, 21.0, 11.0, 0.0, 44.0, 19.0, 39.0, 0.0, 118.0, 0.0, 0.0, 29.0, 41.0, 27.0, 21.0, 0.0, 51.0, 0.0, 74.0, 0.0, 81.0, 86.0, 0.0, 59.0, 0.0, 0.0, 51.0, 43.0, 39.0, 9.0, 12.0, 0.0, 0.0, 60.0, 0.0, 0.0, 3.0, 19.0, 38.0, 2.0, 0.0, 23.0, 16.0, 38.0, 0.0, 12.0, 0.0, 8.0, 0.0, 5.0, 0.0, 0.0, 29.0, 0.0, 0.0, 52.0, 0.0, 6.0, 10.0, 31.0, 0.0, 0.0, 13.0, 23.0, 0.0, 0.0, 36.0, 0.0, 12.0, 1.0, 0.0, 21.0, 0.0, 12.0, 0.0, 26.0, 47.0, 4.0, 10.0, 0.0, 24.0, 24.0, 17.0, 23.0, 13.0, 0.0, 0.0, 0.0, 60.0, 24.0, 61.0, 18.0, 0.0, 55.0, 0.0, 19.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 22.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1786492988579962, "mean_inference_ms": 3.134415257514002, "mean_action_processing_ms": 0.46240986875018014, "mean_env_wait_ms": 0.7258825791536772, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007277846336364746, "StateBufferConnector_ms": 0.009231209754943848, "ViewRequirementAgentConnector_ms": 0.16570031642913818}, "num_episodes": 18, "episode_return_max": 293.8000000000005, "episode_return_min": -243.80000000000004, "episode_return_mean": 64.31299999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 260.8945312486029, "num_env_steps_trained_throughput_per_sec": 260.8945312486029, "timesteps_total": 64000, "num_env_steps_sampled_lifetime": 64000, "num_agent_steps_sampled_lifetime": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 14651.544, "restore_workers_time_ms": 0.016, "training_step_time_ms": 14651.483, "sample_time_ms": 2268.568, "learn_time_ms": 12364.256, "learn_throughput": 323.513, "synch_weights_time_ms": 14.394}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "training_iteration": 16, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-56-30", "timestamp": 1723521390, "time_this_iter_s": 15.382286071777344, "time_total_s": 263.2661168575287, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d07f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 263.2661168575287, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 79.50454545454545, "ram_util_percent": 83.21818181818183}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.16529181131689005, "cur_kl_coeff": 0.0125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9332473293341026, "policy_loss": -0.0009132530774290442, "vf_loss": 0.934117833473695, "vf_explained_var": 0.00024302576584790748, "kl": 0.003420007719613329, "entropy": 1.5849179681646761, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0377938715120156, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9766607683802409, "policy_loss": -0.002413562895907533, "vf_loss": 1.9787093972402905, "vf_explained_var": 0.031454369031563005, "kl": 0.00973150834493619, "entropy": 1.3808843265765558, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 31185.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "env_runners": {"episode_reward_max": 293.8000000000005, "episode_reward_min": -89.80000000000038, "episode_reward_mean": 76.09599999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -328.59999999999985, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 156.79999999999984, "predator_policy": 166.0}, "policy_reward_mean": {"prey_policy": 21.25299999999997, "predator_policy": 16.795}, "custom_metrics": {}, "hist_stats": {"episode_reward": [51.300000000000274, 44.70000000000007, 69.70000000000009, 133.8999999999993, 111.99999999999851, 155.19999999999922, 217.69999999999962, 65.20000000000039, 62.500000000000504, -71.6000000000005, -32.79999999999967, 17.39999999999994, 56.200000000000045, 166.49999999999955, 125.39999999999912, 69.80000000000004, 127.99999999999972, 221.79999999999927, 16.199999999999953, 87.70000000000005, 37.40000000000029, 55.49999999999953, 135.99999999999937, 1.0000000000001823, 125.29999999999981, 40.0000000000003, 127.39999999999947, 56.20000000000027, 108.49999999999918, 172.3999999999995, 29.700000000000106, 52.600000000000264, 69.39999999999993, -89.80000000000038, 100.79999999999947, 120.29999999999986, 103.29999999999899, 151.29999999999998, 9.900000000000192, -30.899999999999814, 111.89999999999966, 293.8000000000005, 96.49999999999989, 9.699999999999957, 176.19999999999922, 5.500000000000105, 40.0000000000003, 143.599999999999, 13.100000000000176, 210.89999999999964, 31.00000000000007, 78.0999999999993, 201.29999999999902, 34.50000000000022, 41.800000000000324, 92.3999999999989, 52.10000000000036, 62.20000000000044, 64.20000000000024, 66.10000000000035, 106.59999999999948, 120.99999999999878, 104.80000000000014, 65.30000000000037, 18.69999999999998, 74.49999999999973, 124.80000000000007, 143.49999999999952, 167.59999999999874, 70.8999999999998, -3.9999999999997526, 87.79999999999885, 40.0000000000003, -29.899999999999743, -39.6999999999998, 54.2000000000003, 184.99999999999903, 41.40000000000032, 122.79999999999887, 40.9000000000003, 162.69999999999854, 9.200000000000099, 77.79999999999937, 124.69999999999973, 40.0000000000003, 57.10000000000051, -27.500000000000064, 86.79999999999883, 48.10000000000048, 22.300000000000153, 33.30000000000019, 95.79999999999845, 40.0000000000003, 35.40000000000023, 131.79999999999967, 60.700000000000514, 62.50000000000044, 40.0000000000003, 93.099999999999, 21.60000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999988, 5.899999999999998, 103.39999999999992, -170.70000000000005, 20.000000000000014, 49.70000000000024, -39.40000000000012, 116.29999999999961, 87.49999999999929, 24.50000000000009, 132.4999999999998, 22.70000000000001, 96.49999999999986, 105.19999999999999, 20.000000000000014, 45.2000000000001, 28.10000000000016, 34.40000000000026, -328.59999999999985, 20.000000000000014, 20.000000000000014, -125.80000000000052, -25.59999999999976, 20.000000000000014, 50.59999999999999, -24.39999999999975, 105.8, 31.700000000000088, 62.300000000000196, 40.09999999999998, -225.70000000000005, 30.499999999999982, 133.39999999999998, -30.399999999999814, 154.0999999999997, 67.69999999999997, -41.79999999999982, 20.000000000000014, 20.000000000000014, 67.7000000000001, 11.599999999999953, 21.80000000000001, -53.50000000000004, 47.000000000000114, 89.29999999999978, 40.70000000000023, 20.000000000000014, -91.00000000000068, 30.20000000000015, 40.099999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 76.39999999999984, 20.000000000000014, 36.200000000000024, 67.40000000000013, 28.10000000000015, 126.5, 20.90000000000003, -3.0999999999999615, 21.80000000000002, 42.50000000000002, -52.8999999999999, 7.100000000000037, 23.300000000000097, 20.000000000000014, -227.80000000000015, 51.800000000000075, 20.000000000000014, 20.000000000000014, 32.29999999999994, 62.30000000000012, 20.000000000000014, -13.600000000000009, 113.89999999999998, -84.10000000000011, 20.000000000000014, -223.9000000000003, 26.00000000000013, -103.9000000000008, 156.79999999999984, 150.49999999999974, 143.29999999999995, 89.60000000000002, -87.10000000000079, -28.29999999999975, -10.0, 72.20000000000009, 91.99999999999955, 51.500000000000014, -106.0, 20.000000000000014, 20.000000000000014, 130.69999999999965, -9.099999999999905, 20.000000000000014, -46.90000000000057, 122.29999999999988, 65.60000000000002, -42.99999999999995, 20.000000000000014, 20.000000000000014, 46.100000000000186, 133.39999999999975, 59.900000000000176, 20.000000000000014, 9.499999999999964, 20.000000000000014, 21.80000000000004, 43.400000000000134, 20.00000000000003, -89.20000000000076, 89.2999999999993, 20.000000000000014, 36.20000000000014, 8.599999999999987, 14.600000000000009, 46.100000000000236, 20.000000000000014, 52.700000000000045, 17.899999999999988, 100.99999999999946, 20.000000000000014, 57.79999999999996, 10.999999999999607, 20.000000000000014, 32.3000000000002, 13.699999999999964, -15.999999999999806, 37.10000000000026, 25.400000000000112, 40.69999999999998, 58.1000000000001, 23.90000000000002, 68.59999999999988, 90.19999999999936, 67.3999999999999, -30.399999999999764, 53.30000000000012, -28.299999999999763, -15.699999999999783, 44.3000000000002, 30.50000000000019, 20.000000000000014, 20.000000000000014, -7.899999999999988, -106.0000000000008, -55.600000000000335, -63.1000000000007, -24.099999999999767, 23.3000000000001, 102.79999999999973, 63.20000000000017, 20.000000000000014, 19.400000000000006, 20.000000000000014, 102.79999999999951, 20.90000000000003, 20.000000000000014, 87.49999999999929, 72.1999999999996, -19.899999999999757, 7.099999999999973, 57.80000000000016, 20.000000000000014, -15.699999999999747, 115.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 37.10000000000026, -108.10000000000062, -30.39999999999995, 20.000000000000014, 66.8, 44.300000000000246, -26.19999999999977, 29.90000000000018, -55.60000000000002, -2.5000000000000164, -32.199999999999875, 74.89999999999942, 20.90000000000003, 20.000000000000014, 20.000000000000014, 30.800000000000196, -9.399999999999855, 20.000000000000014, 84.79999999999998, 40.70000000000025, 20.000000000000014, 20.000000000000014, 42.50000000000021, 20.000000000000014, 20.000000000000014, 20.000000000000014, 73.09999999999951, -13.599999999999804, 9.199999999999973], "policy_predator_policy_reward": [26.0, 12.0, 16.0, 96.0, 0.0, 0.0, 20.0, 37.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0, 166.0, 71.0, 53.0, 20.0, 0.0, 23.0, 22.0, 8.0, 29.0, 0.0, 3.0, 20.0, 131.0, 134.0, 0.0, 25.0, 0.0, 0.0, 0.0, 38.0, 0.0, 0.0, 4.0, 0.0, 62.0, 0.0, 6.0, 0.0, 34.0, 38.0, 43.0, 12.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 13.0, 0.0, 4.0, 21.0, 11.0, 0.0, 44.0, 19.0, 39.0, 0.0, 118.0, 0.0, 0.0, 29.0, 41.0, 27.0, 21.0, 0.0, 51.0, 0.0, 74.0, 0.0, 81.0, 86.0, 0.0, 59.0, 0.0, 0.0, 51.0, 43.0, 39.0, 9.0, 12.0, 0.0, 0.0, 60.0, 0.0, 0.0, 3.0, 19.0, 38.0, 2.0, 0.0, 23.0, 16.0, 38.0, 0.0, 12.0, 0.0, 8.0, 0.0, 5.0, 0.0, 0.0, 29.0, 0.0, 0.0, 52.0, 0.0, 6.0, 10.0, 31.0, 0.0, 0.0, 13.0, 23.0, 0.0, 0.0, 36.0, 0.0, 12.0, 1.0, 0.0, 21.0, 0.0, 12.0, 0.0, 26.0, 47.0, 4.0, 10.0, 0.0, 24.0, 24.0, 17.0, 23.0, 13.0, 0.0, 0.0, 0.0, 60.0, 24.0, 61.0, 18.0, 0.0, 55.0, 0.0, 19.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 22.0, 0.0, 0.0, 0.0, 17.0, 8.0, 0.0, 0.0, 0.0, 0.0, 95.0, 16.0, 0.0, 0.0, 8.0, 22.0, 48.0, 0.0, 52.0, 16.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 1.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1701528842454272, "mean_inference_ms": 3.1092054379058447, "mean_action_processing_ms": 0.4590142497859962, "mean_env_wait_ms": 0.7189440771804317, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006940722465515137, "StateBufferConnector_ms": 0.008899092674255371, "ViewRequirementAgentConnector_ms": 0.19760286808013916}, "num_episodes": 18, "episode_return_max": 293.8000000000005, "episode_return_min": -89.80000000000038, "episode_return_mean": 76.09599999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 297.38074165699294, "num_env_steps_trained_throughput_per_sec": 297.38074165699294, "timesteps_total": 68000, "num_env_steps_sampled_lifetime": 68000, "num_agent_steps_sampled_lifetime": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 14381.354, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14381.294, "sample_time_ms": 2054.475, "learn_time_ms": 12308.768, "learn_throughput": 324.972, "synch_weights_time_ms": 14.25}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "training_iteration": 17, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-56-44", "timestamp": 1723521404, "time_this_iter_s": 13.511591911315918, "time_total_s": 276.7777087688446, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28ea280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 276.7777087688446, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 73.15789473684211, "ram_util_percent": 82.94736842105262}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.20937369029239689, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5830756455186814, "policy_loss": -0.005946658260716254, "vf_loss": 1.5889046801776483, "vf_explained_var": 0.00022028791841375764, "kl": 0.018820232632510526, "entropy": 1.539722412351578, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0392994232357495, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.0900748807917195, "policy_loss": -0.0028501566908465175, "vf_loss": 3.092456013878817, "vf_explained_var": 0.04975126174391893, "kl": 0.01250711629817507, "entropy": 1.3718636358225786, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 33075.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "env_runners": {"episode_reward_max": 293.8000000000005, "episode_reward_min": -89.80000000000038, "episode_reward_mean": 71.17199999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -227.80000000000015, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 156.79999999999984, "predator_policy": 118.0}, "policy_reward_mean": {"prey_policy": 20.425999999999974, "predator_policy": 15.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [135.99999999999937, 1.0000000000001823, 125.29999999999981, 40.0000000000003, 127.39999999999947, 56.20000000000027, 108.49999999999918, 172.3999999999995, 29.700000000000106, 52.600000000000264, 69.39999999999993, -89.80000000000038, 100.79999999999947, 120.29999999999986, 103.29999999999899, 151.29999999999998, 9.900000000000192, -30.899999999999814, 111.89999999999966, 293.8000000000005, 96.49999999999989, 9.699999999999957, 176.19999999999922, 5.500000000000105, 40.0000000000003, 143.599999999999, 13.100000000000176, 210.89999999999964, 31.00000000000007, 78.0999999999993, 201.29999999999902, 34.50000000000022, 41.800000000000324, 92.3999999999989, 52.10000000000036, 62.20000000000044, 64.20000000000024, 66.10000000000035, 106.59999999999948, 120.99999999999878, 104.80000000000014, 65.30000000000037, 18.69999999999998, 74.49999999999973, 124.80000000000007, 143.49999999999952, 167.59999999999874, 70.8999999999998, -3.9999999999997526, 87.79999999999885, 40.0000000000003, -29.899999999999743, -39.6999999999998, 54.2000000000003, 184.99999999999903, 41.40000000000032, 122.79999999999887, 40.9000000000003, 162.69999999999854, 9.200000000000099, 77.79999999999937, 124.69999999999973, 40.0000000000003, 57.10000000000051, -27.500000000000064, 86.79999999999883, 48.10000000000048, 22.300000000000153, 33.30000000000019, 95.79999999999845, 40.0000000000003, 35.40000000000023, 131.79999999999967, 60.700000000000514, 62.50000000000044, 40.0000000000003, 93.099999999999, 21.60000000000003, 71.09999999999998, 7.500000000000243, 137.29999999999973, 38.700000000000344, 131.69999999999888, 96.09999999999862, 71.49999999999996, 87.89999999999901, 156.09999999999886, -23.999999999999936, 40.0000000000003, 40.0000000000003, 7.000000000000085, 90.79999999999853, 118.89999999999975, 84.99999999999923, 25.80000000000019, 56.2000000000005, 75.99999999999963, -62.50000000000057, 42.70000000000034, 3.5000000000001523], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [89.29999999999978, 40.70000000000023, 20.000000000000014, -91.00000000000068, 30.20000000000015, 40.099999999999994, 20.000000000000014, 20.000000000000014, 20.000000000000014, 76.39999999999984, 20.000000000000014, 36.200000000000024, 67.40000000000013, 28.10000000000015, 126.5, 20.90000000000003, -3.0999999999999615, 21.80000000000002, 42.50000000000002, -52.8999999999999, 7.100000000000037, 23.300000000000097, 20.000000000000014, -227.80000000000015, 51.800000000000075, 20.000000000000014, 20.000000000000014, 32.29999999999994, 62.30000000000012, 20.000000000000014, -13.600000000000009, 113.89999999999998, -84.10000000000011, 20.000000000000014, -223.9000000000003, 26.00000000000013, -103.9000000000008, 156.79999999999984, 150.49999999999974, 143.29999999999995, 89.60000000000002, -87.10000000000079, -28.29999999999975, -10.0, 72.20000000000009, 91.99999999999955, 51.500000000000014, -106.0, 20.000000000000014, 20.000000000000014, 130.69999999999965, -9.099999999999905, 20.000000000000014, -46.90000000000057, 122.29999999999988, 65.60000000000002, -42.99999999999995, 20.000000000000014, 20.000000000000014, 46.100000000000186, 133.39999999999975, 59.900000000000176, 20.000000000000014, 9.499999999999964, 20.000000000000014, 21.80000000000004, 43.400000000000134, 20.00000000000003, -89.20000000000076, 89.2999999999993, 20.000000000000014, 36.20000000000014, 8.599999999999987, 14.600000000000009, 46.100000000000236, 20.000000000000014, 52.700000000000045, 17.899999999999988, 100.99999999999946, 20.000000000000014, 57.79999999999996, 10.999999999999607, 20.000000000000014, 32.3000000000002, 13.699999999999964, -15.999999999999806, 37.10000000000026, 25.400000000000112, 40.69999999999998, 58.1000000000001, 23.90000000000002, 68.59999999999988, 90.19999999999936, 67.3999999999999, -30.399999999999764, 53.30000000000012, -28.299999999999763, -15.699999999999783, 44.3000000000002, 30.50000000000019, 20.000000000000014, 20.000000000000014, -7.899999999999988, -106.0000000000008, -55.600000000000335, -63.1000000000007, -24.099999999999767, 23.3000000000001, 102.79999999999973, 63.20000000000017, 20.000000000000014, 19.400000000000006, 20.000000000000014, 102.79999999999951, 20.90000000000003, 20.000000000000014, 87.49999999999929, 72.1999999999996, -19.899999999999757, 7.099999999999973, 57.80000000000016, 20.000000000000014, -15.699999999999747, 115.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 37.10000000000026, -108.10000000000062, -30.39999999999995, 20.000000000000014, 66.8, 44.300000000000246, -26.19999999999977, 29.90000000000018, -55.60000000000002, -2.5000000000000164, -32.199999999999875, 74.89999999999942, 20.90000000000003, 20.000000000000014, 20.000000000000014, 30.800000000000196, -9.399999999999855, 20.000000000000014, 84.79999999999998, 40.70000000000025, 20.000000000000014, 20.000000000000014, 42.50000000000021, 20.000000000000014, 20.000000000000014, 20.000000000000014, 73.09999999999951, -13.599999999999804, 9.199999999999973, 20.000000000000014, 49.10000000000023, 49.10000000000016, -118.59999999999998, 11.599999999999973, 121.70000000000002, 50.60000000000023, -40.89999999999981, 106.7, 20.000000000000014, 34.40000000000022, 49.70000000000018, 51.500000000000234, 20.000000000000014, 41.90000000000013, 20.000000000000014, 20.000000000000014, 136.0999999999996, -13.599999999999953, -177.40000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -52.0, 20.000000000000014, 5.299999999999965, 78.49999999999923, 20.000000000000014, 83.90000000000002, 85.99999999999962, -27.99999999999976, -68.20000000000054, 4.9999999999999964, 20.000000000000014, 36.20000000000025, 20.000000000000014, 56.00000000000023, -205.60000000000025, -28.89999999999997, 22.700000000000053, 20.000000000000014, -50.49999999999995, 20.000000000000014], "policy_predator_policy_reward": [6.0, 0.0, 34.0, 38.0, 43.0, 12.0, 0.0, 0.0, 0.0, 31.0, 0.0, 0.0, 13.0, 0.0, 4.0, 21.0, 11.0, 0.0, 44.0, 19.0, 39.0, 0.0, 118.0, 0.0, 0.0, 29.0, 41.0, 27.0, 21.0, 0.0, 51.0, 0.0, 74.0, 0.0, 81.0, 86.0, 0.0, 59.0, 0.0, 0.0, 51.0, 43.0, 39.0, 9.0, 12.0, 0.0, 0.0, 60.0, 0.0, 0.0, 3.0, 19.0, 38.0, 2.0, 0.0, 23.0, 16.0, 38.0, 0.0, 12.0, 0.0, 8.0, 0.0, 5.0, 0.0, 0.0, 29.0, 0.0, 0.0, 52.0, 0.0, 6.0, 10.0, 31.0, 0.0, 0.0, 13.0, 23.0, 0.0, 0.0, 36.0, 0.0, 12.0, 1.0, 0.0, 21.0, 0.0, 12.0, 0.0, 26.0, 47.0, 4.0, 10.0, 0.0, 24.0, 24.0, 17.0, 23.0, 13.0, 0.0, 0.0, 0.0, 60.0, 24.0, 61.0, 18.0, 0.0, 55.0, 0.0, 19.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 22.0, 0.0, 0.0, 0.0, 17.0, 8.0, 0.0, 0.0, 0.0, 0.0, 95.0, 16.0, 0.0, 0.0, 8.0, 22.0, 48.0, 0.0, 52.0, 16.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 1.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 2.0, 26.0, 51.0, 0.0, 4.0, 29.0, 0.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 6.0, 20.0, 0.0, 0.0, 76.0, 91.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 7.0, 0.0, 15.0, 0.0, 27.0, 0.0, 42.0, 47.0, 0.0, 0.0, 0.0, 0.0, 74.0, 98.0, 0.0, 0.0, 0.0, 34.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.154125355218076, "mean_inference_ms": 3.0569609260351878, "mean_action_processing_ms": 0.4536958220130559, "mean_env_wait_ms": 0.7072740818072893, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006875514984130859, "StateBufferConnector_ms": 0.004084348678588867, "ViewRequirementAgentConnector_ms": 0.21604883670806885}, "num_episodes": 22, "episode_return_max": 293.8000000000005, "episode_return_min": -89.80000000000038, "episode_return_mean": 71.17199999999981, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 229.0207378427073, "num_env_steps_trained_throughput_per_sec": 229.0207378427073, "timesteps_total": 72000, "num_env_steps_sampled_lifetime": 72000, "num_agent_steps_sampled_lifetime": 288000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 14816.17, "restore_workers_time_ms": 0.015, "training_step_time_ms": 14816.107, "sample_time_ms": 2094.19, "learn_time_ms": 12702.416, "learn_throughput": 314.901, "synch_weights_time_ms": 15.303}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "training_iteration": 18, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-57-01", "timestamp": 1723521421, "time_this_iter_s": 17.608365058898926, "time_total_s": 294.38607382774353, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x330dc5670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 294.38607382774353, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 84.296, "ram_util_percent": 83.62}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2371762607936506, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7466928848671535, "policy_loss": -0.0020441947531980023, "vf_loss": 0.7486548095626175, "vf_explained_var": 0.0021211440285677633, "kl": 0.013162837743650561, "entropy": 1.4843092406868303, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1368190576948185, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.856590673406288, "policy_loss": -0.003448990099846568, "vf_loss": 1.8593656332404525, "vf_explained_var": 0.056419378298300286, "kl": 0.01797417190972025, "entropy": 1.3284019209089732, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 34965.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "env_runners": {"episode_reward_max": 210.89999999999964, "episode_reward_min": -77.40000000000106, "episode_reward_mean": 63.1419999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -205.60000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 136.0999999999996, "predator_policy": 98.0}, "policy_reward_mean": {"prey_policy": 19.721000000000004, "predator_policy": 11.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.500000000000105, 40.0000000000003, 143.599999999999, 13.100000000000176, 210.89999999999964, 31.00000000000007, 78.0999999999993, 201.29999999999902, 34.50000000000022, 41.800000000000324, 92.3999999999989, 52.10000000000036, 62.20000000000044, 64.20000000000024, 66.10000000000035, 106.59999999999948, 120.99999999999878, 104.80000000000014, 65.30000000000037, 18.69999999999998, 74.49999999999973, 124.80000000000007, 143.49999999999952, 167.59999999999874, 70.8999999999998, -3.9999999999997526, 87.79999999999885, 40.0000000000003, -29.899999999999743, -39.6999999999998, 54.2000000000003, 184.99999999999903, 41.40000000000032, 122.79999999999887, 40.9000000000003, 162.69999999999854, 9.200000000000099, 77.79999999999937, 124.69999999999973, 40.0000000000003, 57.10000000000051, -27.500000000000064, 86.79999999999883, 48.10000000000048, 22.300000000000153, 33.30000000000019, 95.79999999999845, 40.0000000000003, 35.40000000000023, 131.79999999999967, 60.700000000000514, 62.50000000000044, 40.0000000000003, 93.099999999999, 21.60000000000003, 71.09999999999998, 7.500000000000243, 137.29999999999973, 38.700000000000344, 131.69999999999888, 96.09999999999862, 71.49999999999996, 87.89999999999901, 156.09999999999886, -23.999999999999936, 40.0000000000003, 40.0000000000003, 7.000000000000085, 90.79999999999853, 118.89999999999975, 84.99999999999923, 25.80000000000019, 56.2000000000005, 75.99999999999963, -62.50000000000057, 42.70000000000034, 3.5000000000001523, 58.3000000000004, 31.300000000000168, 165.0999999999989, 22.300000000000043, 49.0000000000003, 10.800000000000015, 40.0000000000003, 45.40000000000038, 112.29999999999919, 79.39999999999927, 59.80000000000037, 83.59999999999917, 82.29999999999917, 37.700000000000266, 54.40000000000052, 90.39999999999858, 29.80000000000015, 81.79999999999912, 30.100000000000158, 40.0000000000003, -77.40000000000106, 22.400000000000013, 19.69999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [51.500000000000014, -106.0, 20.000000000000014, 20.000000000000014, 130.69999999999965, -9.099999999999905, 20.000000000000014, -46.90000000000057, 122.29999999999988, 65.60000000000002, -42.99999999999995, 20.000000000000014, 20.000000000000014, 46.100000000000186, 133.39999999999975, 59.900000000000176, 20.000000000000014, 9.499999999999964, 20.000000000000014, 21.80000000000004, 43.400000000000134, 20.00000000000003, -89.20000000000076, 89.2999999999993, 20.000000000000014, 36.20000000000014, 8.599999999999987, 14.600000000000009, 46.100000000000236, 20.000000000000014, 52.700000000000045, 17.899999999999988, 100.99999999999946, 20.000000000000014, 57.79999999999996, 10.999999999999607, 20.000000000000014, 32.3000000000002, 13.699999999999964, -15.999999999999806, 37.10000000000026, 25.400000000000112, 40.69999999999998, 58.1000000000001, 23.90000000000002, 68.59999999999988, 90.19999999999936, 67.3999999999999, -30.399999999999764, 53.30000000000012, -28.299999999999763, -15.699999999999783, 44.3000000000002, 30.50000000000019, 20.000000000000014, 20.000000000000014, -7.899999999999988, -106.0000000000008, -55.600000000000335, -63.1000000000007, -24.099999999999767, 23.3000000000001, 102.79999999999973, 63.20000000000017, 20.000000000000014, 19.400000000000006, 20.000000000000014, 102.79999999999951, 20.90000000000003, 20.000000000000014, 87.49999999999929, 72.1999999999996, -19.899999999999757, 7.099999999999973, 57.80000000000016, 20.000000000000014, -15.699999999999747, 115.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 37.10000000000026, -108.10000000000062, -30.39999999999995, 20.000000000000014, 66.8, 44.300000000000246, -26.19999999999977, 29.90000000000018, -55.60000000000002, -2.5000000000000164, -32.199999999999875, 74.89999999999942, 20.90000000000003, 20.000000000000014, 20.000000000000014, 30.800000000000196, -9.399999999999855, 20.000000000000014, 84.79999999999998, 40.70000000000025, 20.000000000000014, 20.000000000000014, 42.50000000000021, 20.000000000000014, 20.000000000000014, 20.000000000000014, 73.09999999999951, -13.599999999999804, 9.199999999999973, 20.000000000000014, 49.10000000000023, 49.10000000000016, -118.59999999999998, 11.599999999999973, 121.70000000000002, 50.60000000000023, -40.89999999999981, 106.7, 20.000000000000014, 34.40000000000022, 49.70000000000018, 51.500000000000234, 20.000000000000014, 41.90000000000013, 20.000000000000014, 20.000000000000014, 136.0999999999996, -13.599999999999953, -177.40000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -52.0, 20.000000000000014, 5.299999999999965, 78.49999999999923, 20.000000000000014, 83.90000000000002, 85.99999999999962, -27.99999999999976, -68.20000000000054, 4.9999999999999964, 20.000000000000014, 36.20000000000025, 20.000000000000014, 56.00000000000023, -205.60000000000025, -28.89999999999997, 22.700000000000053, 20.000000000000014, -50.49999999999995, 20.000000000000014, -17.79999999999974, 58.1000000000002, -24.099999999999767, 34.40000000000025, 64.1000000000002, 100.99999999999966, 35.30000000000026, -42.99999999999979, 28.100000000000147, -6.099999999999994, -26.499999999999766, 5.299999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.89999999999998, 70.39999999999975, 35.90000000000016, 33.50000000000021, 20.000000000000014, 39.80000000000018, 28.70000000000011, 20.900000000000027, 62.30000000000022, 20.000000000000014, 1.0999999999999936, 20.600000000000026, 20.000000000000014, 34.40000000000026, 53.30000000000021, 37.10000000000026, -49.299999999999834, 46.10000000000024, 45.80000000000017, 20.000000000000014, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 20.000000000000014, -21.699999999999775, -141.70000000000053, -13.59999999999979, 20.000000000000014, 20.900000000000027, -26.199999999999747], "policy_predator_policy_reward": [0.0, 60.0, 0.0, 0.0, 3.0, 19.0, 38.0, 2.0, 0.0, 23.0, 16.0, 38.0, 0.0, 12.0, 0.0, 8.0, 0.0, 5.0, 0.0, 0.0, 29.0, 0.0, 0.0, 52.0, 0.0, 6.0, 10.0, 31.0, 0.0, 0.0, 13.0, 23.0, 0.0, 0.0, 36.0, 0.0, 12.0, 1.0, 0.0, 21.0, 0.0, 12.0, 0.0, 26.0, 47.0, 4.0, 10.0, 0.0, 24.0, 24.0, 17.0, 23.0, 13.0, 0.0, 0.0, 0.0, 60.0, 24.0, 61.0, 18.0, 0.0, 55.0, 0.0, 19.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 22.0, 0.0, 0.0, 0.0, 17.0, 8.0, 0.0, 0.0, 0.0, 0.0, 95.0, 16.0, 0.0, 0.0, 8.0, 22.0, 48.0, 0.0, 52.0, 16.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 1.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 2.0, 26.0, 51.0, 0.0, 4.0, 29.0, 0.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 6.0, 20.0, 0.0, 0.0, 76.0, 91.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 7.0, 0.0, 15.0, 0.0, 27.0, 0.0, 42.0, 47.0, 0.0, 0.0, 0.0, 0.0, 74.0, 98.0, 0.0, 0.0, 0.0, 34.0, 18.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 27.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 15.0, 1.0, 0.0, 0.0, 0.0, 0.0, 33.0, 0.0, 0.0, 16.0, 9.0, 0.0, 0.0, 0.0, 0.0, 86.0, 0.0, 16.0, 3.0, 22.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1616444913440351, "mean_inference_ms": 3.0769790581908647, "mean_action_processing_ms": 0.45674561058631624, "mean_env_wait_ms": 0.7089954157954298, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009901642799377441, "StateBufferConnector_ms": 0.005533695220947266, "ViewRequirementAgentConnector_ms": 0.37422239780426025}, "num_episodes": 23, "episode_return_max": 210.89999999999964, "episode_return_min": -77.40000000000106, "episode_return_mean": 63.1419999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 166.44682383626724, "num_env_steps_trained_throughput_per_sec": 166.44682383626724, "timesteps_total": 76000, "num_env_steps_sampled_lifetime": 76000, "num_agent_steps_sampled_lifetime": 304000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 15742.735, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15742.679, "sample_time_ms": 2638.101, "learn_time_ms": 13085.954, "learn_throughput": 305.671, "synch_weights_time_ms": 15.185}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "training_iteration": 19, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-57-26", "timestamp": 1723521446, "time_this_iter_s": 24.077982902526855, "time_total_s": 318.4640567302704, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28cd790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 318.4640567302704, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 87.79705882352941, "ram_util_percent": 83.54117647058824}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.23694451529355276, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3762052159933817, "policy_loss": -0.003159439754450605, "vf_loss": 0.3793210449692591, "vf_explained_var": 0.005038341391023504, "kl": 0.006977911629262664, "entropy": 1.5092741322895837, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0585531822982288, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7164430474162733, "policy_loss": -0.002346541377267352, "vf_loss": 1.7181156499991341, "vf_explained_var": 0.15280109129885516, "kl": 0.01797156561682256, "entropy": 1.257102366730019, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 36855.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "env_runners": {"episode_reward_max": 184.99999999999903, "episode_reward_min": -77.40000000000106, "episode_reward_mean": 58.720999999999805, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -205.60000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 136.0999999999996, "predator_policy": 98.0}, "policy_reward_mean": {"prey_policy": 18.465500000000016, "predator_policy": 10.895}, "custom_metrics": {}, "hist_stats": {"episode_reward": [65.30000000000037, 18.69999999999998, 74.49999999999973, 124.80000000000007, 143.49999999999952, 167.59999999999874, 70.8999999999998, -3.9999999999997526, 87.79999999999885, 40.0000000000003, -29.899999999999743, -39.6999999999998, 54.2000000000003, 184.99999999999903, 41.40000000000032, 122.79999999999887, 40.9000000000003, 162.69999999999854, 9.200000000000099, 77.79999999999937, 124.69999999999973, 40.0000000000003, 57.10000000000051, -27.500000000000064, 86.79999999999883, 48.10000000000048, 22.300000000000153, 33.30000000000019, 95.79999999999845, 40.0000000000003, 35.40000000000023, 131.79999999999967, 60.700000000000514, 62.50000000000044, 40.0000000000003, 93.099999999999, 21.60000000000003, 71.09999999999998, 7.500000000000243, 137.29999999999973, 38.700000000000344, 131.69999999999888, 96.09999999999862, 71.49999999999996, 87.89999999999901, 156.09999999999886, -23.999999999999936, 40.0000000000003, 40.0000000000003, 7.000000000000085, 90.79999999999853, 118.89999999999975, 84.99999999999923, 25.80000000000019, 56.2000000000005, 75.99999999999963, -62.50000000000057, 42.70000000000034, 3.5000000000001523, 58.3000000000004, 31.300000000000168, 165.0999999999989, 22.300000000000043, 49.0000000000003, 10.800000000000015, 40.0000000000003, 45.40000000000038, 112.29999999999919, 79.39999999999927, 59.80000000000037, 83.59999999999917, 82.29999999999917, 37.700000000000266, 54.40000000000052, 90.39999999999858, 29.80000000000015, 81.79999999999912, 30.100000000000158, 40.0000000000003, -77.40000000000106, 22.400000000000013, 19.69999999999997, -5.5999999999998185, 27.300000000000182, 55.60000000000034, 65.60000000000021, 95.59999999999896, 86.79999999999887, 114.6999999999988, 25.400000000000087, 38.900000000000276, 168.69999999999902, 43.40000000000035, 49.00000000000045, 21.800000000000026, 124.59999999999849, 51.40000000000042, 48.10000000000043, -24.199999999999505, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 32.3000000000002, 13.699999999999964, -15.999999999999806, 37.10000000000026, 25.400000000000112, 40.69999999999998, 58.1000000000001, 23.90000000000002, 68.59999999999988, 90.19999999999936, 67.3999999999999, -30.399999999999764, 53.30000000000012, -28.299999999999763, -15.699999999999783, 44.3000000000002, 30.50000000000019, 20.000000000000014, 20.000000000000014, -7.899999999999988, -106.0000000000008, -55.600000000000335, -63.1000000000007, -24.099999999999767, 23.3000000000001, 102.79999999999973, 63.20000000000017, 20.000000000000014, 19.400000000000006, 20.000000000000014, 102.79999999999951, 20.90000000000003, 20.000000000000014, 87.49999999999929, 72.1999999999996, -19.899999999999757, 7.099999999999973, 57.80000000000016, 20.000000000000014, -15.699999999999747, 115.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 37.10000000000026, -108.10000000000062, -30.39999999999995, 20.000000000000014, 66.8, 44.300000000000246, -26.19999999999977, 29.90000000000018, -55.60000000000002, -2.5000000000000164, -32.199999999999875, 74.89999999999942, 20.90000000000003, 20.000000000000014, 20.000000000000014, 30.800000000000196, -9.399999999999855, 20.000000000000014, 84.79999999999998, 40.70000000000025, 20.000000000000014, 20.000000000000014, 42.50000000000021, 20.000000000000014, 20.000000000000014, 20.000000000000014, 73.09999999999951, -13.599999999999804, 9.199999999999973, 20.000000000000014, 49.10000000000023, 49.10000000000016, -118.59999999999998, 11.599999999999973, 121.70000000000002, 50.60000000000023, -40.89999999999981, 106.7, 20.000000000000014, 34.40000000000022, 49.70000000000018, 51.500000000000234, 20.000000000000014, 41.90000000000013, 20.000000000000014, 20.000000000000014, 136.0999999999996, -13.599999999999953, -177.40000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -52.0, 20.000000000000014, 5.299999999999965, 78.49999999999923, 20.000000000000014, 83.90000000000002, 85.99999999999962, -27.99999999999976, -68.20000000000054, 4.9999999999999964, 20.000000000000014, 36.20000000000025, 20.000000000000014, 56.00000000000023, -205.60000000000025, -28.89999999999997, 22.700000000000053, 20.000000000000014, -50.49999999999995, 20.000000000000014, -17.79999999999974, 58.1000000000002, -24.099999999999767, 34.40000000000025, 64.1000000000002, 100.99999999999966, 35.30000000000026, -42.99999999999979, 28.100000000000147, -6.099999999999994, -26.499999999999766, 5.299999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.89999999999998, 70.39999999999975, 35.90000000000016, 33.50000000000021, 20.000000000000014, 39.80000000000018, 28.70000000000011, 20.900000000000027, 62.30000000000022, 20.000000000000014, 1.0999999999999936, 20.600000000000026, 20.000000000000014, 34.40000000000026, 53.30000000000021, 37.10000000000026, -49.299999999999834, 46.10000000000024, 45.80000000000017, 20.000000000000014, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 20.000000000000014, -21.699999999999775, -141.70000000000053, -13.59999999999979, 20.000000000000014, 20.900000000000027, -26.199999999999747, -30.099999999999795, -23.499999999999794, 7.4000000000000075, -3.099999999999958, 48.80000000000019, -5.199999999999955, -13.599999999999808, 63.200000000000166, 20.000000000000014, 56.600000000000136, 33.50000000000024, 53.30000000000023, 20.000000000000014, 94.69999999999945, 20.000000000000014, -13.599999999999833, 17.899999999999988, 20.000000000000014, 95.5999999999994, 73.0999999999997, 22.40000000000005, 20.000000000000014, 29.000000000000163, 20.000000000000014, -20.199999999999775, 7.999999999999984, 91.99999999999932, 32.60000000000023, 18.5, 17.899999999999988, 20.000000000000014, 28.100000000000147, -66.1000000000009, -3.099999999999958, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [12.0, 1.0, 0.0, 21.0, 0.0, 12.0, 0.0, 26.0, 47.0, 4.0, 10.0, 0.0, 24.0, 24.0, 17.0, 23.0, 13.0, 0.0, 0.0, 0.0, 60.0, 24.0, 61.0, 18.0, 0.0, 55.0, 0.0, 19.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 22.0, 0.0, 0.0, 0.0, 17.0, 8.0, 0.0, 0.0, 0.0, 0.0, 95.0, 16.0, 0.0, 0.0, 8.0, 22.0, 48.0, 0.0, 52.0, 16.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 1.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 2.0, 26.0, 51.0, 0.0, 4.0, 29.0, 0.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 6.0, 20.0, 0.0, 0.0, 76.0, 91.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 7.0, 0.0, 15.0, 0.0, 27.0, 0.0, 42.0, 47.0, 0.0, 0.0, 0.0, 0.0, 74.0, 98.0, 0.0, 0.0, 0.0, 34.0, 18.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 27.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 15.0, 1.0, 0.0, 0.0, 0.0, 0.0, 33.0, 0.0, 0.0, 16.0, 9.0, 0.0, 0.0, 0.0, 0.0, 86.0, 0.0, 16.0, 3.0, 22.0, 17.0, 31.0, 12.0, 11.0, 0.0, 12.0, 0.0, 16.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 14.0, 1.0, 0.0, 0.0, 40.0, 5.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1672413327820979, "mean_inference_ms": 3.092917190812496, "mean_action_processing_ms": 0.46086242145994716, "mean_env_wait_ms": 0.7115203231383853, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00826418399810791, "StateBufferConnector_ms": 0.0049637556076049805, "ViewRequirementAgentConnector_ms": 0.36305689811706543}, "num_episodes": 18, "episode_return_max": 184.99999999999903, "episode_return_min": -77.40000000000106, "episode_return_mean": 58.720999999999805, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 251.81161467732574, "num_env_steps_trained_throughput_per_sec": 251.81161467732574, "timesteps_total": 80000, "num_env_steps_sampled_lifetime": 80000, "num_agent_steps_sampled_lifetime": 320000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 15728.045, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15727.989, "sample_time_ms": 2653.73, "learn_time_ms": 13056.41, "learn_throughput": 306.363, "synch_weights_time_ms": 14.506}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "training_iteration": 20, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-57-42", "timestamp": 1723521462, "time_this_iter_s": 15.954672813415527, "time_total_s": 334.4187295436859, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28c7ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 334.4187295436859, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 78.87727272727274, "ram_util_percent": 83.57272727272728}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.32765974811421184, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8926008141545392, "policy_loss": -0.0032272196093958523, "vf_loss": 0.8957658427023383, "vf_explained_var": 0.00947615311890052, "kl": 0.009950388159666729, "entropy": 1.4680584206152214, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3156514683018916, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1096231353346, "policy_loss": -0.0018780073053055694, "vf_loss": 3.111163632327287, "vf_explained_var": 0.05990997423570623, "kl": 0.009000120862919085, "entropy": 1.1722707792564675, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 38745.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "env_runners": {"episode_reward_max": 168.69999999999902, "episode_reward_min": -77.40000000000106, "episode_reward_mean": 60.09899999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -205.60000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 136.0999999999996, "predator_policy": 106.0}, "policy_reward_mean": {"prey_policy": 20.03450000000002, "predator_policy": 10.015}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.200000000000099, 77.79999999999937, 124.69999999999973, 40.0000000000003, 57.10000000000051, -27.500000000000064, 86.79999999999883, 48.10000000000048, 22.300000000000153, 33.30000000000019, 95.79999999999845, 40.0000000000003, 35.40000000000023, 131.79999999999967, 60.700000000000514, 62.50000000000044, 40.0000000000003, 93.099999999999, 21.60000000000003, 71.09999999999998, 7.500000000000243, 137.29999999999973, 38.700000000000344, 131.69999999999888, 96.09999999999862, 71.49999999999996, 87.89999999999901, 156.09999999999886, -23.999999999999936, 40.0000000000003, 40.0000000000003, 7.000000000000085, 90.79999999999853, 118.89999999999975, 84.99999999999923, 25.80000000000019, 56.2000000000005, 75.99999999999963, -62.50000000000057, 42.70000000000034, 3.5000000000001523, 58.3000000000004, 31.300000000000168, 165.0999999999989, 22.300000000000043, 49.0000000000003, 10.800000000000015, 40.0000000000003, 45.40000000000038, 112.29999999999919, 79.39999999999927, 59.80000000000037, 83.59999999999917, 82.29999999999917, 37.700000000000266, 54.40000000000052, 90.39999999999858, 29.80000000000015, 81.79999999999912, 30.100000000000158, 40.0000000000003, -77.40000000000106, 22.400000000000013, 19.69999999999997, -5.5999999999998185, 27.300000000000182, 55.60000000000034, 65.60000000000021, 95.59999999999896, 86.79999999999887, 114.6999999999988, 25.400000000000087, 38.900000000000276, 168.69999999999902, 43.40000000000035, 49.00000000000045, 21.800000000000026, 124.59999999999849, 51.40000000000042, 48.10000000000043, -24.199999999999505, 40.0000000000003, 76.89999999999944, 148.8999999999988, 79.59999999999937, 78.29999999999922, 159.69999999999865, 113.09999999999914, 40.90000000000031, 109.80000000000013, 35.00000000000023, 147.09999999999914, 134.899999999999, 50.8000000000004, 36.80000000000027, 69.99999999999997, 40.0000000000003, -52.300000000000075, 73.79999999999976, 120.9999999999986], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-19.899999999999757, 7.099999999999973, 57.80000000000016, 20.000000000000014, -15.699999999999747, 115.39999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 37.10000000000026, -108.10000000000062, -30.39999999999995, 20.000000000000014, 66.8, 44.300000000000246, -26.19999999999977, 29.90000000000018, -55.60000000000002, -2.5000000000000164, -32.199999999999875, 74.89999999999942, 20.90000000000003, 20.000000000000014, 20.000000000000014, 30.800000000000196, -9.399999999999855, 20.000000000000014, 84.79999999999998, 40.70000000000025, 20.000000000000014, 20.000000000000014, 42.50000000000021, 20.000000000000014, 20.000000000000014, 20.000000000000014, 73.09999999999951, -13.599999999999804, 9.199999999999973, 20.000000000000014, 49.10000000000023, 49.10000000000016, -118.59999999999998, 11.599999999999973, 121.70000000000002, 50.60000000000023, -40.89999999999981, 106.7, 20.000000000000014, 34.40000000000022, 49.70000000000018, 51.500000000000234, 20.000000000000014, 41.90000000000013, 20.000000000000014, 20.000000000000014, 136.0999999999996, -13.599999999999953, -177.40000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -52.0, 20.000000000000014, 5.299999999999965, 78.49999999999923, 20.000000000000014, 83.90000000000002, 85.99999999999962, -27.99999999999976, -68.20000000000054, 4.9999999999999964, 20.000000000000014, 36.20000000000025, 20.000000000000014, 56.00000000000023, -205.60000000000025, -28.89999999999997, 22.700000000000053, 20.000000000000014, -50.49999999999995, 20.000000000000014, -17.79999999999974, 58.1000000000002, -24.099999999999767, 34.40000000000025, 64.1000000000002, 100.99999999999966, 35.30000000000026, -42.99999999999979, 28.100000000000147, -6.099999999999994, -26.499999999999766, 5.299999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.89999999999998, 70.39999999999975, 35.90000000000016, 33.50000000000021, 20.000000000000014, 39.80000000000018, 28.70000000000011, 20.900000000000027, 62.30000000000022, 20.000000000000014, 1.0999999999999936, 20.600000000000026, 20.000000000000014, 34.40000000000026, 53.30000000000021, 37.10000000000026, -49.299999999999834, 46.10000000000024, 45.80000000000017, 20.000000000000014, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 20.000000000000014, -21.699999999999775, -141.70000000000053, -13.59999999999979, 20.000000000000014, 20.900000000000027, -26.199999999999747, -30.099999999999795, -23.499999999999794, 7.4000000000000075, -3.099999999999958, 48.80000000000019, -5.199999999999955, -13.599999999999808, 63.200000000000166, 20.000000000000014, 56.600000000000136, 33.50000000000024, 53.30000000000023, 20.000000000000014, 94.69999999999945, 20.000000000000014, -13.599999999999833, 17.899999999999988, 20.000000000000014, 95.5999999999994, 73.0999999999997, 22.40000000000005, 20.000000000000014, 29.000000000000163, 20.000000000000014, -20.199999999999775, 7.999999999999984, 91.99999999999932, 32.60000000000023, 18.5, 17.899999999999988, 20.000000000000014, 28.100000000000147, -66.1000000000009, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.900000000000155, 107.29999999999941, 41.60000000000009, 59.60000000000022, 20.000000000000014, 20.000000000000014, 47.300000000000104, 65.90000000000003, 93.79999999999934, 76.09999999999962, 20.000000000000014, 20.90000000000003, 20.000000000000014, 72.19999999999996, 35.60000000000025, 7.999999999999966, 20.000000000000014, 114.49999999999946, 5.600000000000097, 45.200000000000244, 64.70000000000005, 7.999999999999987, 15.799999999999962, -40.899999999999785, 40.70000000000017, 7.399999999999965, 50.60000000000018, 20.000000000000014, 20.000000000000014, 44.30000000000022, -202.60000000000048, 65.90000000000008, -3.099999999999958, 94.69999999999933, 26.300000000000047], "policy_predator_policy_reward": [22.0, 0.0, 0.0, 0.0, 17.0, 8.0, 0.0, 0.0, 0.0, 0.0, 95.0, 16.0, 0.0, 0.0, 8.0, 22.0, 48.0, 0.0, 52.0, 16.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 1.0, 26.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 26.0, 0.0, 2.0, 26.0, 51.0, 0.0, 4.0, 29.0, 0.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 6.0, 20.0, 0.0, 0.0, 76.0, 91.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 7.0, 0.0, 15.0, 0.0, 27.0, 0.0, 42.0, 47.0, 0.0, 0.0, 0.0, 0.0, 74.0, 98.0, 0.0, 0.0, 0.0, 34.0, 18.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 27.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 15.0, 1.0, 0.0, 0.0, 0.0, 0.0, 33.0, 0.0, 0.0, 16.0, 9.0, 0.0, 0.0, 0.0, 0.0, 86.0, 0.0, 16.0, 3.0, 22.0, 17.0, 31.0, 12.0, 11.0, 0.0, 12.0, 0.0, 16.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 14.0, 1.0, 0.0, 0.0, 40.0, 5.0, 0.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 23.0, 4.0, 23.0, 2.0, 0.0, 27.0, 37.0, 0.0, 1.0, 11.0, 0.0, 0.0, 106.0, 0.0, 0.0, 11.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1755388024537659, "mean_inference_ms": 3.116403687373446, "mean_action_processing_ms": 0.4657773375917023, "mean_env_wait_ms": 0.71558667663856, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008785247802734375, "StateBufferConnector_ms": 0.005012631416320801, "ViewRequirementAgentConnector_ms": 0.3568533658981323}, "num_episodes": 18, "episode_return_max": 168.69999999999902, "episode_return_min": -77.40000000000106, "episode_return_mean": 60.09899999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 279.8104071653491, "num_env_steps_trained_throughput_per_sec": 279.8104071653491, "timesteps_total": 84000, "num_env_steps_sampled_lifetime": 84000, "num_agent_steps_sampled_lifetime": 336000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 15792.896, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15792.84, "sample_time_ms": 2665.404, "learn_time_ms": 13109.544, "learn_throughput": 305.121, "synch_weights_time_ms": 14.73}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "training_iteration": 21, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-57-56", "timestamp": 1723521476, "time_this_iter_s": 14.366878986358643, "time_total_s": 348.78560853004456, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29010d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 348.78560853004456, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 76.97142857142856, "ram_util_percent": 83.64285714285714}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2788821218998502, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.569431261678852, "policy_loss": -0.0014189746171709091, "vf_loss": 0.5708016441681634, "vf_explained_var": 0.003963650881298005, "kl": 0.007774511723597935, "entropy": 1.4367875417073568, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.03662629712511, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.289020444476415, "policy_loss": -0.0032280901597231313, "vf_loss": 2.291658156700235, "vf_explained_var": 0.11363125610603857, "kl": 0.0157434600780842, "entropy": 1.1465607794504318, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 40635.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "env_runners": {"episode_reward_max": 233.49999999999895, "episode_reward_min": -77.40000000000106, "episode_reward_mean": 63.27199999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -205.60000000000025, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 136.0999999999996, "predator_policy": 106.0}, "policy_reward_mean": {"prey_policy": 22.196000000000012, "predator_policy": 9.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.60000000000003, 71.09999999999998, 7.500000000000243, 137.29999999999973, 38.700000000000344, 131.69999999999888, 96.09999999999862, 71.49999999999996, 87.89999999999901, 156.09999999999886, -23.999999999999936, 40.0000000000003, 40.0000000000003, 7.000000000000085, 90.79999999999853, 118.89999999999975, 84.99999999999923, 25.80000000000019, 56.2000000000005, 75.99999999999963, -62.50000000000057, 42.70000000000034, 3.5000000000001523, 58.3000000000004, 31.300000000000168, 165.0999999999989, 22.300000000000043, 49.0000000000003, 10.800000000000015, 40.0000000000003, 45.40000000000038, 112.29999999999919, 79.39999999999927, 59.80000000000037, 83.59999999999917, 82.29999999999917, 37.700000000000266, 54.40000000000052, 90.39999999999858, 29.80000000000015, 81.79999999999912, 30.100000000000158, 40.0000000000003, -77.40000000000106, 22.400000000000013, 19.69999999999997, -5.5999999999998185, 27.300000000000182, 55.60000000000034, 65.60000000000021, 95.59999999999896, 86.79999999999887, 114.6999999999988, 25.400000000000087, 38.900000000000276, 168.69999999999902, 43.40000000000035, 49.00000000000045, 21.800000000000026, 124.59999999999849, 51.40000000000042, 48.10000000000043, -24.199999999999505, 40.0000000000003, 76.89999999999944, 148.8999999999988, 79.59999999999937, 78.29999999999922, 159.69999999999865, 113.09999999999914, 40.90000000000031, 109.80000000000013, 35.00000000000023, 147.09999999999914, 134.899999999999, 50.8000000000004, 36.80000000000027, 69.99999999999997, 40.0000000000003, -52.300000000000075, 73.79999999999976, 120.9999999999986, 168.69999999999925, 192.99999999999903, 34.50000000000024, 51.70000000000028, 7.900000000000004, -17.499999999999602, 25.300000000000075, 40.0000000000003, 140.99999999999966, 233.49999999999895, 121.89999999999833, 44.50000000000036, 81.79999999999993, 31.20000000000017, 55.20000000000049, 60.50000000000041, 61.700000000000486, 13.49999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-13.599999999999804, 9.199999999999973, 20.000000000000014, 49.10000000000023, 49.10000000000016, -118.59999999999998, 11.599999999999973, 121.70000000000002, 50.60000000000023, -40.89999999999981, 106.7, 20.000000000000014, 34.40000000000022, 49.70000000000018, 51.500000000000234, 20.000000000000014, 41.90000000000013, 20.000000000000014, 20.000000000000014, 136.0999999999996, -13.599999999999953, -177.40000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -52.0, 20.000000000000014, 5.299999999999965, 78.49999999999923, 20.000000000000014, 83.90000000000002, 85.99999999999962, -27.99999999999976, -68.20000000000054, 4.9999999999999964, 20.000000000000014, 36.20000000000025, 20.000000000000014, 56.00000000000023, -205.60000000000025, -28.89999999999997, 22.700000000000053, 20.000000000000014, -50.49999999999995, 20.000000000000014, -17.79999999999974, 58.1000000000002, -24.099999999999767, 34.40000000000025, 64.1000000000002, 100.99999999999966, 35.30000000000026, -42.99999999999979, 28.100000000000147, -6.099999999999994, -26.499999999999766, 5.299999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.89999999999998, 70.39999999999975, 35.90000000000016, 33.50000000000021, 20.000000000000014, 39.80000000000018, 28.70000000000011, 20.900000000000027, 62.30000000000022, 20.000000000000014, 1.0999999999999936, 20.600000000000026, 20.000000000000014, 34.40000000000026, 53.30000000000021, 37.10000000000026, -49.299999999999834, 46.10000000000024, 45.80000000000017, 20.000000000000014, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 20.000000000000014, -21.699999999999775, -141.70000000000053, -13.59999999999979, 20.000000000000014, 20.900000000000027, -26.199999999999747, -30.099999999999795, -23.499999999999794, 7.4000000000000075, -3.099999999999958, 48.80000000000019, -5.199999999999955, -13.599999999999808, 63.200000000000166, 20.000000000000014, 56.600000000000136, 33.50000000000024, 53.30000000000023, 20.000000000000014, 94.69999999999945, 20.000000000000014, -13.599999999999833, 17.899999999999988, 20.000000000000014, 95.5999999999994, 73.0999999999997, 22.40000000000005, 20.000000000000014, 29.000000000000163, 20.000000000000014, -20.199999999999775, 7.999999999999984, 91.99999999999932, 32.60000000000023, 18.5, 17.899999999999988, 20.000000000000014, 28.100000000000147, -66.1000000000009, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.900000000000155, 107.29999999999941, 41.60000000000009, 59.60000000000022, 20.000000000000014, 20.000000000000014, 47.300000000000104, 65.90000000000003, 93.79999999999934, 76.09999999999962, 20.000000000000014, 20.90000000000003, 20.000000000000014, 72.19999999999996, 35.60000000000025, 7.999999999999966, 20.000000000000014, 114.49999999999946, 5.600000000000097, 45.200000000000244, 64.70000000000005, 7.999999999999987, 15.799999999999962, -40.899999999999785, 40.70000000000017, 7.399999999999965, 50.60000000000018, 20.000000000000014, 20.000000000000014, 44.30000000000022, -202.60000000000048, 65.90000000000008, -3.099999999999958, 94.69999999999933, 26.300000000000047, 58.70000000000022, 109.9999999999998, 104.5999999999994, 88.39999999999961, 9.499999999999966, 20.000000000000014, 31.699999999999996, 20.000000000000014, 20.000000000000014, -60.10000000000044, -40.89999999999978, -13.599999999999847, 29.600000000000176, -28.299999999999777, 20.000000000000014, 20.000000000000014, 132.19999999999993, -5.1999999999999265, 119.89999999999962, 113.59999999999945, 52.10000000000023, 66.8, 20.000000000000014, 24.50000000000008, 61.69999999999996, -4.899999999999949, 13.699999999999966, 9.499999999999968, 20.000000000000014, 30.20000000000019, 30.5000000000002, 20.000000000000014, 20.900000000000027, 36.80000000000024, 20.000000000000014, -53.499999999999794], "policy_predator_policy_reward": [0.0, 26.0, 0.0, 2.0, 26.0, 51.0, 0.0, 4.0, 29.0, 0.0, 0.0, 5.0, 12.0, 0.0, 0.0, 0.0, 6.0, 20.0, 0.0, 0.0, 76.0, 91.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 7.0, 0.0, 15.0, 0.0, 27.0, 0.0, 42.0, 47.0, 0.0, 0.0, 0.0, 0.0, 74.0, 98.0, 0.0, 0.0, 0.0, 34.0, 18.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 30.0, 0.0, 27.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 15.0, 1.0, 0.0, 0.0, 0.0, 0.0, 33.0, 0.0, 0.0, 16.0, 9.0, 0.0, 0.0, 0.0, 0.0, 86.0, 0.0, 16.0, 3.0, 22.0, 17.0, 31.0, 12.0, 11.0, 0.0, 12.0, 0.0, 16.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 14.0, 1.0, 0.0, 0.0, 40.0, 5.0, 0.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 23.0, 4.0, 23.0, 2.0, 0.0, 27.0, 37.0, 0.0, 1.0, 11.0, 0.0, 0.0, 106.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 48.0, 0.0, 37.0, 0.0, 1.0, 23.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 8.0, 17.0, 0.0, 8.0, 0.0, 5.0, 10.0, 0.0, 4.0, 0.0, 27.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1864981909972345, "mean_inference_ms": 3.145764890072727, "mean_action_processing_ms": 0.4712909092540292, "mean_env_wait_ms": 0.7228176361529964, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00880587100982666, "StateBufferConnector_ms": 0.004992127418518066, "ViewRequirementAgentConnector_ms": 0.3429830074310303}, "num_episodes": 18, "episode_return_max": 233.49999999999895, "episode_return_min": -77.40000000000106, "episode_return_mean": 63.27199999999979, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 298.359601723069, "num_env_steps_trained_throughput_per_sec": 298.359601723069, "timesteps_total": 88000, "num_env_steps_sampled_lifetime": 88000, "num_agent_steps_sampled_lifetime": 352000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 15836.536, "restore_workers_time_ms": 0.015, "training_step_time_ms": 15836.48, "sample_time_ms": 2733.94, "learn_time_ms": 13085.549, "learn_throughput": 305.681, "synch_weights_time_ms": 14.591}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "training_iteration": 22, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-58-10", "timestamp": 1723521490, "time_this_iter_s": 13.447357892990112, "time_total_s": 362.23296642303467, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28cdaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 362.23296642303467, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 72.21578947368421, "ram_util_percent": 83.64736842105263}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31245627058522096, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9261107254280616, "policy_loss": -0.0033376938601827654, "vf_loss": 1.9293837387095052, "vf_explained_var": 0.001683011666807548, "kl": 0.010349275592150207, "entropy": 1.4521470206755178, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1045341663969257, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.677642871589257, "policy_loss": -0.004017956626093971, "vf_loss": 4.681140403772788, "vf_explained_var": 0.06370015481792429, "kl": 0.013877845021874063, "entropy": 1.057730200870958, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 42525.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "env_runners": {"episode_reward_max": 385.0000000000002, "episode_reward_min": -77.40000000000106, "episode_reward_mean": 72.4259999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.5999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 26.297999999999984, "predator_policy": 9.915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [49.0000000000003, 10.800000000000015, 40.0000000000003, 45.40000000000038, 112.29999999999919, 79.39999999999927, 59.80000000000037, 83.59999999999917, 82.29999999999917, 37.700000000000266, 54.40000000000052, 90.39999999999858, 29.80000000000015, 81.79999999999912, 30.100000000000158, 40.0000000000003, -77.40000000000106, 22.400000000000013, 19.69999999999997, -5.5999999999998185, 27.300000000000182, 55.60000000000034, 65.60000000000021, 95.59999999999896, 86.79999999999887, 114.6999999999988, 25.400000000000087, 38.900000000000276, 168.69999999999902, 43.40000000000035, 49.00000000000045, 21.800000000000026, 124.59999999999849, 51.40000000000042, 48.10000000000043, -24.199999999999505, 40.0000000000003, 76.89999999999944, 148.8999999999988, 79.59999999999937, 78.29999999999922, 159.69999999999865, 113.09999999999914, 40.90000000000031, 109.80000000000013, 35.00000000000023, 147.09999999999914, 134.899999999999, 50.8000000000004, 36.80000000000027, 69.99999999999997, 40.0000000000003, -52.300000000000075, 73.79999999999976, 120.9999999999986, 168.69999999999925, 192.99999999999903, 34.50000000000024, 51.70000000000028, 7.900000000000004, -17.499999999999602, 25.300000000000075, 40.0000000000003, 140.99999999999966, 233.49999999999895, 121.89999999999833, 44.50000000000036, 81.79999999999993, 31.20000000000017, 55.20000000000049, 60.50000000000041, 61.700000000000486, 13.49999999999992, 159.99999999999886, -46.19999999999989, 141.39999999999966, 40.0000000000003, 171.39999999999984, 27.8000000000002, 29.00000000000014, 115.39999999999955, 67.00000000000028, 77.29999999999946, 120.99999999999976, 110.5999999999992, 142.4999999999989, 164.59999999999926, -32.79999999999964, 69.69999999999987, 60.800000000000175, 385.0000000000002, 41.300000000000324, 200.09999999999954, 111.29999999999886, 21.299999999999994, 40.0000000000003, 40.0000000000003, -6.199999999999731, 218.9999999999997, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [28.100000000000147, -6.099999999999994, -26.499999999999766, 5.299999999999981, 20.000000000000014, 20.000000000000014, 20.000000000000014, 25.400000000000098, 20.89999999999998, 70.39999999999975, 35.90000000000016, 33.50000000000021, 20.000000000000014, 39.80000000000018, 28.70000000000011, 20.900000000000027, 62.30000000000022, 20.000000000000014, 1.0999999999999936, 20.600000000000026, 20.000000000000014, 34.40000000000026, 53.30000000000021, 37.10000000000026, -49.299999999999834, 46.10000000000024, 45.80000000000017, 20.000000000000014, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 20.000000000000014, -21.699999999999775, -141.70000000000053, -13.59999999999979, 20.000000000000014, 20.900000000000027, -26.199999999999747, -30.099999999999795, -23.499999999999794, 7.4000000000000075, -3.099999999999958, 48.80000000000019, -5.199999999999955, -13.599999999999808, 63.200000000000166, 20.000000000000014, 56.600000000000136, 33.50000000000024, 53.30000000000023, 20.000000000000014, 94.69999999999945, 20.000000000000014, -13.599999999999833, 17.899999999999988, 20.000000000000014, 95.5999999999994, 73.0999999999997, 22.40000000000005, 20.000000000000014, 29.000000000000163, 20.000000000000014, -20.199999999999775, 7.999999999999984, 91.99999999999932, 32.60000000000023, 18.5, 17.899999999999988, 20.000000000000014, 28.100000000000147, -66.1000000000009, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.900000000000155, 107.29999999999941, 41.60000000000009, 59.60000000000022, 20.000000000000014, 20.000000000000014, 47.300000000000104, 65.90000000000003, 93.79999999999934, 76.09999999999962, 20.000000000000014, 20.90000000000003, 20.000000000000014, 72.19999999999996, 35.60000000000025, 7.999999999999966, 20.000000000000014, 114.49999999999946, 5.600000000000097, 45.200000000000244, 64.70000000000005, 7.999999999999987, 15.799999999999962, -40.899999999999785, 40.70000000000017, 7.399999999999965, 50.60000000000018, 20.000000000000014, 20.000000000000014, 44.30000000000022, -202.60000000000048, 65.90000000000008, -3.099999999999958, 94.69999999999933, 26.300000000000047, 58.70000000000022, 109.9999999999998, 104.5999999999994, 88.39999999999961, 9.499999999999966, 20.000000000000014, 31.699999999999996, 20.000000000000014, 20.000000000000014, -60.10000000000044, -40.89999999999978, -13.599999999999847, 29.600000000000176, -28.299999999999777, 20.000000000000014, 20.000000000000014, 132.19999999999993, -5.1999999999999265, 119.89999999999962, 113.59999999999945, 52.10000000000023, 66.8, 20.000000000000014, 24.50000000000008, 61.69999999999996, -4.899999999999949, 13.699999999999966, 9.499999999999968, 20.000000000000014, 30.20000000000019, 30.5000000000002, 20.000000000000014, 20.900000000000027, 36.80000000000024, 20.000000000000014, -53.499999999999794, 96.49999999999935, 42.50000000000014, -389.5999999999999, 7.399999999999967, -0.7000000000000134, 127.1, 20.000000000000014, 20.000000000000014, 49.69999999999997, 121.69999999999999, 20.000000000000014, -47.20000000000002, 20.000000000000014, -9.999999999999867, 104.89999999999985, -11.499999999999819, 39.80000000000025, 27.200000000000003, -32.49999999999979, 84.79999999999927, 100.99999999999997, 20.000000000000014, 20.60000000000002, 56.000000000000085, 117.49999999999957, 20.000000000000014, 125.59999999999985, 20.000000000000014, -53.50000000000072, -133.3000000000004, 20.000000000000014, 49.70000000000013, 55.100000000000065, -7.299999999999894, 181.99999999999994, 200.0, -2.2000000000000055, 6.499999999999979, 96.49999999999991, 74.59999999999964, -13.599999999999783, 107.89999999999944, -15.699999999999747, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -68.20000000000083, 103.0999999999998, 83.89999999999992, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 27.0, 0.0, 32.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 15.0, 1.0, 0.0, 0.0, 0.0, 0.0, 33.0, 0.0, 0.0, 16.0, 9.0, 0.0, 0.0, 0.0, 0.0, 86.0, 0.0, 16.0, 3.0, 22.0, 17.0, 31.0, 12.0, 11.0, 0.0, 12.0, 0.0, 16.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 14.0, 1.0, 0.0, 0.0, 40.0, 5.0, 0.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 23.0, 4.0, 23.0, 2.0, 0.0, 27.0, 37.0, 0.0, 1.0, 11.0, 0.0, 0.0, 106.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 48.0, 0.0, 37.0, 0.0, 1.0, 23.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 8.0, 17.0, 0.0, 8.0, 0.0, 5.0, 10.0, 0.0, 4.0, 0.0, 27.0, 20.0, 21.0, 0.0, 139.0, 197.0, 12.0, 3.0, 0.0, 0.0, 0.0, 0.0, 31.0, 24.0, 19.0, 0.0, 3.0, 19.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 22.0, 12.0, 0.0, 5.0, 15.0, 4.0, 73.0, 81.0, 0.0, 0.0, 0.0, 13.0, 3.0, 0.0, 37.0, 0.0, 19.0, 10.0, 17.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 18.0, 14.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.194603990914412, "mean_inference_ms": 3.1707652110133697, "mean_action_processing_ms": 0.4771623967167913, "mean_env_wait_ms": 0.7298559393515903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009132742881774902, "StateBufferConnector_ms": 0.004950046539306641, "ViewRequirementAgentConnector_ms": 0.2855677604675293}, "num_episodes": 27, "episode_return_max": 385.0000000000002, "episode_return_min": -77.40000000000106, "episode_return_mean": 72.4259999999998, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 231.1527415523661, "num_env_steps_trained_throughput_per_sec": 231.1527415523661, "timesteps_total": 92000, "num_env_steps_sampled_lifetime": 92000, "num_agent_steps_sampled_lifetime": 368000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 15938.402, "restore_workers_time_ms": 0.016, "training_step_time_ms": 15938.344, "sample_time_ms": 2565.712, "learn_time_ms": 13351.97, "learn_throughput": 299.581, "synch_weights_time_ms": 17.822}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "training_iteration": 23, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-58-27", "timestamp": 1723521507, "time_this_iter_s": 17.405676126480103, "time_total_s": 379.63864254951477, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2836040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 379.63864254951477, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 86.14999999999999, "ram_util_percent": 83.58333333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2874220373532759, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.46794303139996907, "policy_loss": -0.0028557076404689165, "vf_loss": 0.4707401415909685, "vf_explained_var": 0.006846480867850086, "kl": 0.009375491686990907, "entropy": 1.4378199983526159, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8924574699785028, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4976290395966283, "policy_loss": -0.0008892079137719025, "vf_loss": 1.4981754040276563, "vf_explained_var": 0.10515900068182163, "kl": 0.009142323843426985, "entropy": 1.042591848386028, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 44415.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "env_runners": {"episode_reward_max": 385.0000000000002, "episode_reward_min": -52.300000000000075, "episode_reward_mean": 75.68699999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.5999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 28.48349999999997, "predator_policy": 9.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.69999999999997, -5.5999999999998185, 27.300000000000182, 55.60000000000034, 65.60000000000021, 95.59999999999896, 86.79999999999887, 114.6999999999988, 25.400000000000087, 38.900000000000276, 168.69999999999902, 43.40000000000035, 49.00000000000045, 21.800000000000026, 124.59999999999849, 51.40000000000042, 48.10000000000043, -24.199999999999505, 40.0000000000003, 76.89999999999944, 148.8999999999988, 79.59999999999937, 78.29999999999922, 159.69999999999865, 113.09999999999914, 40.90000000000031, 109.80000000000013, 35.00000000000023, 147.09999999999914, 134.899999999999, 50.8000000000004, 36.80000000000027, 69.99999999999997, 40.0000000000003, -52.300000000000075, 73.79999999999976, 120.9999999999986, 168.69999999999925, 192.99999999999903, 34.50000000000024, 51.70000000000028, 7.900000000000004, -17.499999999999602, 25.300000000000075, 40.0000000000003, 140.99999999999966, 233.49999999999895, 121.89999999999833, 44.50000000000036, 81.79999999999993, 31.20000000000017, 55.20000000000049, 60.50000000000041, 61.700000000000486, 13.49999999999992, 159.99999999999886, -46.19999999999989, 141.39999999999966, 40.0000000000003, 171.39999999999984, 27.8000000000002, 29.00000000000014, 115.39999999999955, 67.00000000000028, 77.29999999999946, 120.99999999999976, 110.5999999999992, 142.4999999999989, 164.59999999999926, -32.79999999999964, 69.69999999999987, 60.800000000000175, 385.0000000000002, 41.300000000000324, 200.09999999999954, 111.29999999999886, 21.299999999999994, 40.0000000000003, 40.0000000000003, -6.199999999999731, 218.9999999999997, 40.0000000000003, 40.0000000000003, 49.100000000000364, 72.19999999999982, -2.8999999999997446, 91.89999999999903, 132.99999999999878, 41.80000000000033, 139.49999999999878, 68.20000000000016, 46.30000000000041, 50.80000000000046, 61.70000000000049, 3.700000000000174, 26.8000000000001, 128.6999999999989, 174.7999999999994, 32.30000000000018, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.900000000000027, -26.199999999999747, -30.099999999999795, -23.499999999999794, 7.4000000000000075, -3.099999999999958, 48.80000000000019, -5.199999999999955, -13.599999999999808, 63.200000000000166, 20.000000000000014, 56.600000000000136, 33.50000000000024, 53.30000000000023, 20.000000000000014, 94.69999999999945, 20.000000000000014, -13.599999999999833, 17.899999999999988, 20.000000000000014, 95.5999999999994, 73.0999999999997, 22.40000000000005, 20.000000000000014, 29.000000000000163, 20.000000000000014, -20.199999999999775, 7.999999999999984, 91.99999999999932, 32.60000000000023, 18.5, 17.899999999999988, 20.000000000000014, 28.100000000000147, -66.1000000000009, -3.099999999999958, 20.000000000000014, 20.000000000000014, 20.000000000000014, 38.900000000000155, 107.29999999999941, 41.60000000000009, 59.60000000000022, 20.000000000000014, 20.000000000000014, 47.300000000000104, 65.90000000000003, 93.79999999999934, 76.09999999999962, 20.000000000000014, 20.90000000000003, 20.000000000000014, 72.19999999999996, 35.60000000000025, 7.999999999999966, 20.000000000000014, 114.49999999999946, 5.600000000000097, 45.200000000000244, 64.70000000000005, 7.999999999999987, 15.799999999999962, -40.899999999999785, 40.70000000000017, 7.399999999999965, 50.60000000000018, 20.000000000000014, 20.000000000000014, 44.30000000000022, -202.60000000000048, 65.90000000000008, -3.099999999999958, 94.69999999999933, 26.300000000000047, 58.70000000000022, 109.9999999999998, 104.5999999999994, 88.39999999999961, 9.499999999999966, 20.000000000000014, 31.699999999999996, 20.000000000000014, 20.000000000000014, -60.10000000000044, -40.89999999999978, -13.599999999999847, 29.600000000000176, -28.299999999999777, 20.000000000000014, 20.000000000000014, 132.19999999999993, -5.1999999999999265, 119.89999999999962, 113.59999999999945, 52.10000000000023, 66.8, 20.000000000000014, 24.50000000000008, 61.69999999999996, -4.899999999999949, 13.699999999999966, 9.499999999999968, 20.000000000000014, 30.20000000000019, 30.5000000000002, 20.000000000000014, 20.900000000000027, 36.80000000000024, 20.000000000000014, -53.499999999999794, 96.49999999999935, 42.50000000000014, -389.5999999999999, 7.399999999999967, -0.7000000000000134, 127.1, 20.000000000000014, 20.000000000000014, 49.69999999999997, 121.69999999999999, 20.000000000000014, -47.20000000000002, 20.000000000000014, -9.999999999999867, 104.89999999999985, -11.499999999999819, 39.80000000000025, 27.200000000000003, -32.49999999999979, 84.79999999999927, 100.99999999999997, 20.000000000000014, 20.60000000000002, 56.000000000000085, 117.49999999999957, 20.000000000000014, 125.59999999999985, 20.000000000000014, -53.50000000000072, -133.3000000000004, 20.000000000000014, 49.70000000000013, 55.100000000000065, -7.299999999999894, 181.99999999999994, 200.0, -2.2000000000000055, 6.499999999999979, 96.49999999999991, 74.59999999999964, -13.599999999999783, 107.89999999999944, -15.699999999999747, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -68.20000000000083, 103.0999999999998, 83.89999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.099999999999984, 49.70000000000018, 9.49999999999997, -61.900000000000766, 20.000000000000014, -40.899999999999764, 102.79999999999951, 20.000000000000014, 109.99999999999949, 20.000000000000014, 21.80000000000004, 117.49999999999952, 20.000000000000014, 22.700000000000063, 33.50000000000023, 26.300000000000118, 20.000000000000014, 20.000000000000014, 30.800000000000203, 20.000000000000014, 37.70000000000024, -49.299999999999905, 20.000000000000014, 20.000000000000014, -5.199999999999976, 47.000000000000234, 61.70000000000012, 20.000000000000014, 153.79999999999995, 7.399999999999965, 17.899999999999988, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [3.0, 22.0, 17.0, 31.0, 12.0, 11.0, 0.0, 12.0, 0.0, 16.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 8.0, 11.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 14.0, 1.0, 0.0, 0.0, 40.0, 5.0, 0.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 23.0, 4.0, 23.0, 2.0, 0.0, 27.0, 37.0, 0.0, 1.0, 11.0, 0.0, 0.0, 106.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 48.0, 0.0, 37.0, 0.0, 1.0, 23.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 8.0, 17.0, 0.0, 8.0, 0.0, 5.0, 10.0, 0.0, 4.0, 0.0, 27.0, 20.0, 21.0, 0.0, 139.0, 197.0, 12.0, 3.0, 0.0, 0.0, 0.0, 0.0, 31.0, 24.0, 19.0, 0.0, 3.0, 19.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 22.0, 12.0, 0.0, 5.0, 15.0, 4.0, 73.0, 81.0, 0.0, 0.0, 0.0, 13.0, 3.0, 0.0, 37.0, 0.0, 19.0, 10.0, 17.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 18.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 13.0, 39.0, 0.0, 13.0, 17.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 33.0, 0.0, 12.0, 0.0, 20.0, 0.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1904462094421455, "mean_inference_ms": 3.152083042705156, "mean_action_processing_ms": 0.4739583541387451, "mean_env_wait_ms": 0.7273873707386878, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02095794677734375, "StateBufferConnector_ms": 0.004014372825622559, "ViewRequirementAgentConnector_ms": 0.16497278213500977}, "num_episodes": 18, "episode_return_max": 385.0000000000002, "episode_return_min": -52.300000000000075, "episode_return_mean": 75.68699999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 210.98217963604137, "num_env_steps_trained_throughput_per_sec": 210.98217963604137, "timesteps_total": 96000, "num_env_steps_sampled_lifetime": 96000, "num_agent_steps_sampled_lifetime": 384000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 16391.859, "restore_workers_time_ms": 0.016, "training_step_time_ms": 16391.793, "sample_time_ms": 2732.924, "learn_time_ms": 13636.159, "learn_throughput": 293.338, "synch_weights_time_ms": 19.239}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "training_iteration": 24, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-58-46", "timestamp": 1723521526, "time_this_iter_s": 19.01922297477722, "time_total_s": 398.657865524292, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28eaaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 398.657865524292, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 85.96296296296298, "ram_util_percent": 83.35925925925925}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31864362968496546, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7672971268810292, "policy_loss": -0.005054566258485749, "vf_loss": 0.7722563938015983, "vf_explained_var": 0.011234298963395376, "kl": 0.015247922184655685, "entropy": 1.4719389662540778, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1506870479061806, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7152936552567457, "policy_loss": -0.0019045610921999449, "vf_loss": 2.7168294299216496, "vf_explained_var": 0.0820068131994318, "kl": 0.009834281405262789, "entropy": 0.9418059897801233, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 46305.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "env_runners": {"episode_reward_max": 385.0000000000002, "episode_reward_min": -52.300000000000075, "episode_reward_mean": 75.87499999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.5999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 197.0}, "policy_reward_mean": {"prey_policy": 28.34249999999997, "predator_policy": 9.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 76.89999999999944, 148.8999999999988, 79.59999999999937, 78.29999999999922, 159.69999999999865, 113.09999999999914, 40.90000000000031, 109.80000000000013, 35.00000000000023, 147.09999999999914, 134.899999999999, 50.8000000000004, 36.80000000000027, 69.99999999999997, 40.0000000000003, -52.300000000000075, 73.79999999999976, 120.9999999999986, 168.69999999999925, 192.99999999999903, 34.50000000000024, 51.70000000000028, 7.900000000000004, -17.499999999999602, 25.300000000000075, 40.0000000000003, 140.99999999999966, 233.49999999999895, 121.89999999999833, 44.50000000000036, 81.79999999999993, 31.20000000000017, 55.20000000000049, 60.50000000000041, 61.700000000000486, 13.49999999999992, 159.99999999999886, -46.19999999999989, 141.39999999999966, 40.0000000000003, 171.39999999999984, 27.8000000000002, 29.00000000000014, 115.39999999999955, 67.00000000000028, 77.29999999999946, 120.99999999999976, 110.5999999999992, 142.4999999999989, 164.59999999999926, -32.79999999999964, 69.69999999999987, 60.800000000000175, 385.0000000000002, 41.300000000000324, 200.09999999999954, 111.29999999999886, 21.299999999999994, 40.0000000000003, 40.0000000000003, -6.199999999999731, 218.9999999999997, 40.0000000000003, 40.0000000000003, 49.100000000000364, 72.19999999999982, -2.8999999999997446, 91.89999999999903, 132.99999999999878, 41.80000000000033, 139.49999999999878, 68.20000000000016, 46.30000000000041, 50.80000000000046, 61.70000000000049, 3.700000000000174, 26.8000000000001, 128.6999999999989, 174.7999999999994, 32.30000000000018, 40.0000000000003, 6.999999999999952, 166.09999999999934, 40.0000000000003, 38.900000000000276, 33.4000000000002, 112.3999999999997, 40.0000000000003, 103.49999999999841, 36.40000000000025, 154.99999999999946, -6.599999999999751, -1.799999999999772, 7.000000000000107, 40.0000000000003, 40.0000000000003, 115.89999999999986, 33.2000000000002, 65.20000000000041], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 38.900000000000155, 107.29999999999941, 41.60000000000009, 59.60000000000022, 20.000000000000014, 20.000000000000014, 47.300000000000104, 65.90000000000003, 93.79999999999934, 76.09999999999962, 20.000000000000014, 20.90000000000003, 20.000000000000014, 72.19999999999996, 35.60000000000025, 7.999999999999966, 20.000000000000014, 114.49999999999946, 5.600000000000097, 45.200000000000244, 64.70000000000005, 7.999999999999987, 15.799999999999962, -40.899999999999785, 40.70000000000017, 7.399999999999965, 50.60000000000018, 20.000000000000014, 20.000000000000014, 44.30000000000022, -202.60000000000048, 65.90000000000008, -3.099999999999958, 94.69999999999933, 26.300000000000047, 58.70000000000022, 109.9999999999998, 104.5999999999994, 88.39999999999961, 9.499999999999966, 20.000000000000014, 31.699999999999996, 20.000000000000014, 20.000000000000014, -60.10000000000044, -40.89999999999978, -13.599999999999847, 29.600000000000176, -28.299999999999777, 20.000000000000014, 20.000000000000014, 132.19999999999993, -5.1999999999999265, 119.89999999999962, 113.59999999999945, 52.10000000000023, 66.8, 20.000000000000014, 24.50000000000008, 61.69999999999996, -4.899999999999949, 13.699999999999966, 9.499999999999968, 20.000000000000014, 30.20000000000019, 30.5000000000002, 20.000000000000014, 20.900000000000027, 36.80000000000024, 20.000000000000014, -53.499999999999794, 96.49999999999935, 42.50000000000014, -389.5999999999999, 7.399999999999967, -0.7000000000000134, 127.1, 20.000000000000014, 20.000000000000014, 49.69999999999997, 121.69999999999999, 20.000000000000014, -47.20000000000002, 20.000000000000014, -9.999999999999867, 104.89999999999985, -11.499999999999819, 39.80000000000025, 27.200000000000003, -32.49999999999979, 84.79999999999927, 100.99999999999997, 20.000000000000014, 20.60000000000002, 56.000000000000085, 117.49999999999957, 20.000000000000014, 125.59999999999985, 20.000000000000014, -53.50000000000072, -133.3000000000004, 20.000000000000014, 49.70000000000013, 55.100000000000065, -7.299999999999894, 181.99999999999994, 200.0, -2.2000000000000055, 6.499999999999979, 96.49999999999991, 74.59999999999964, -13.599999999999783, 107.89999999999944, -15.699999999999747, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -68.20000000000083, 103.0999999999998, 83.89999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.099999999999984, 49.70000000000018, 9.49999999999997, -61.900000000000766, 20.000000000000014, -40.899999999999764, 102.79999999999951, 20.000000000000014, 109.99999999999949, 20.000000000000014, 21.80000000000004, 117.49999999999952, 20.000000000000014, 22.700000000000063, 33.50000000000023, 26.300000000000118, 20.000000000000014, 20.000000000000014, 30.800000000000203, 20.000000000000014, 37.70000000000024, -49.299999999999905, 20.000000000000014, 20.000000000000014, -5.199999999999976, 47.000000000000234, 61.70000000000012, 20.000000000000014, 153.79999999999995, 7.399999999999965, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999964, -34.59999999999982, 100.09999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 13.699999999999964, 13.699999999999964, 3.199999999999967, 75.19999999999992, 20.000000000000014, 20.000000000000014, 74.89999999999942, 26.600000000000122, 9.499999999999964, 20.900000000000027, 2.599999999999975, 124.39999999999992, -13.59999999999984, -21.999999999999787, 20.000000000000014, -59.800000000000594, 17.899999999999988, -40.899999999999764, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 125.60000000000004, -57.70000000000041, 20.000000000000014, 6.1999999999999655, 45.200000000000244, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 11.0, 7.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 2.0, 0.0, 7.0, 23.0, 4.0, 23.0, 2.0, 0.0, 27.0, 37.0, 0.0, 1.0, 11.0, 0.0, 0.0, 106.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 48.0, 0.0, 37.0, 0.0, 1.0, 23.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 8.0, 17.0, 0.0, 8.0, 0.0, 5.0, 10.0, 0.0, 4.0, 0.0, 27.0, 20.0, 21.0, 0.0, 139.0, 197.0, 12.0, 3.0, 0.0, 0.0, 0.0, 0.0, 31.0, 24.0, 19.0, 0.0, 3.0, 19.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 22.0, 12.0, 0.0, 5.0, 15.0, 4.0, 73.0, 81.0, 0.0, 0.0, 0.0, 13.0, 3.0, 0.0, 37.0, 0.0, 19.0, 10.0, 17.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 18.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 13.0, 39.0, 0.0, 13.0, 17.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 33.0, 0.0, 12.0, 0.0, 20.0, 0.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 4.0, 26.0, 20.0, 26.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, 34.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 22.0, 6.0, 7.0, 22.0, 0.0, 38.0, 1.0, 29.0, 0.0, 0.0, 0.0, 0.0, 11.0, 37.0, 7.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1912366310498153, "mean_inference_ms": 3.1524249959501844, "mean_action_processing_ms": 0.47456936793996896, "mean_env_wait_ms": 0.7291974860606237, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022623300552368164, "StateBufferConnector_ms": 0.004032492637634277, "ViewRequirementAgentConnector_ms": 0.19478368759155273}, "num_episodes": 18, "episode_return_max": 385.0000000000002, "episode_return_min": -52.300000000000075, "episode_return_mean": 75.87499999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 254.94887662327608, "num_env_steps_trained_throughput_per_sec": 254.94887662327608, "timesteps_total": 100000, "num_env_steps_sampled_lifetime": 100000, "num_agent_steps_sampled_lifetime": 400000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 16581.995, "restore_workers_time_ms": 0.016, "training_step_time_ms": 16581.924, "sample_time_ms": 2960.694, "learn_time_ms": 13598.108, "learn_throughput": 294.159, "synch_weights_time_ms": 19.506}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "training_iteration": 25, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-59-02", "timestamp": 1723521542, "time_this_iter_s": 15.737154960632324, "time_total_s": 414.3950204849243, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29011f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 414.3950204849243, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 76.7695652173913, "ram_util_percent": 83.30434782608695}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.35830957567092603, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.7123714451436642, "policy_loss": -0.0024305973720623467, "vf_loss": 2.7146812714596904, "vf_explained_var": 0.0008995230866487695, "kl": 0.019323103148083554, "entropy": 1.3775302391203623, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.113048251584251, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.529223470208506, "policy_loss": -0.0013769294805430546, "vf_loss": 4.5303557090658355, "vf_explained_var": 0.03699100001779183, "kl": 0.006525070806377104, "entropy": 0.9046141676171117, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 48195.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "env_runners": {"episode_reward_max": 385.0000000000002, "episode_reward_min": -125.60000000000042, "episode_reward_mean": 72.42999999999988, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.5999999999999, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 231.0}, "policy_reward_mean": {"prey_policy": 23.07999999999997, "predator_policy": 13.135}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.9999999999986, 168.69999999999925, 192.99999999999903, 34.50000000000024, 51.70000000000028, 7.900000000000004, -17.499999999999602, 25.300000000000075, 40.0000000000003, 140.99999999999966, 233.49999999999895, 121.89999999999833, 44.50000000000036, 81.79999999999993, 31.20000000000017, 55.20000000000049, 60.50000000000041, 61.700000000000486, 13.49999999999992, 159.99999999999886, -46.19999999999989, 141.39999999999966, 40.0000000000003, 171.39999999999984, 27.8000000000002, 29.00000000000014, 115.39999999999955, 67.00000000000028, 77.29999999999946, 120.99999999999976, 110.5999999999992, 142.4999999999989, 164.59999999999926, -32.79999999999964, 69.69999999999987, 60.800000000000175, 385.0000000000002, 41.300000000000324, 200.09999999999954, 111.29999999999886, 21.299999999999994, 40.0000000000003, 40.0000000000003, -6.199999999999731, 218.9999999999997, 40.0000000000003, 40.0000000000003, 49.100000000000364, 72.19999999999982, -2.8999999999997446, 91.89999999999903, 132.99999999999878, 41.80000000000033, 139.49999999999878, 68.20000000000016, 46.30000000000041, 50.80000000000046, 61.70000000000049, 3.700000000000174, 26.8000000000001, 128.6999999999989, 174.7999999999994, 32.30000000000018, 40.0000000000003, 6.999999999999952, 166.09999999999934, 40.0000000000003, 38.900000000000276, 33.4000000000002, 112.3999999999997, 40.0000000000003, 103.49999999999841, 36.40000000000025, 154.99999999999946, -6.599999999999751, -1.799999999999772, 7.000000000000107, 40.0000000000003, 40.0000000000003, 115.89999999999986, 33.2000000000002, 65.20000000000041, 184.89999999999944, 132.09999999999957, 196.59999999999943, 98.39999999999958, 45.400000000000276, -86.40000000000003, 76.30000000000024, -125.60000000000042, 31.40000000000017, 40.0000000000003, 66.10000000000011, 84.1999999999993, 109.39999999999924, 129.99999999999858, 25.500000000000068, 117.6999999999993, -57.899999999999686, -29.299999999999578], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [94.69999999999933, 26.300000000000047, 58.70000000000022, 109.9999999999998, 104.5999999999994, 88.39999999999961, 9.499999999999966, 20.000000000000014, 31.699999999999996, 20.000000000000014, 20.000000000000014, -60.10000000000044, -40.89999999999978, -13.599999999999847, 29.600000000000176, -28.299999999999777, 20.000000000000014, 20.000000000000014, 132.19999999999993, -5.1999999999999265, 119.89999999999962, 113.59999999999945, 52.10000000000023, 66.8, 20.000000000000014, 24.50000000000008, 61.69999999999996, -4.899999999999949, 13.699999999999966, 9.499999999999968, 20.000000000000014, 30.20000000000019, 30.5000000000002, 20.000000000000014, 20.900000000000027, 36.80000000000024, 20.000000000000014, -53.499999999999794, 96.49999999999935, 42.50000000000014, -389.5999999999999, 7.399999999999967, -0.7000000000000134, 127.1, 20.000000000000014, 20.000000000000014, 49.69999999999997, 121.69999999999999, 20.000000000000014, -47.20000000000002, 20.000000000000014, -9.999999999999867, 104.89999999999985, -11.499999999999819, 39.80000000000025, 27.200000000000003, -32.49999999999979, 84.79999999999927, 100.99999999999997, 20.000000000000014, 20.60000000000002, 56.000000000000085, 117.49999999999957, 20.000000000000014, 125.59999999999985, 20.000000000000014, -53.50000000000072, -133.3000000000004, 20.000000000000014, 49.70000000000013, 55.100000000000065, -7.299999999999894, 181.99999999999994, 200.0, -2.2000000000000055, 6.499999999999979, 96.49999999999991, 74.59999999999964, -13.599999999999783, 107.89999999999944, -15.699999999999747, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -68.20000000000083, 103.0999999999998, 83.89999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.099999999999984, 49.70000000000018, 9.49999999999997, -61.900000000000766, 20.000000000000014, -40.899999999999764, 102.79999999999951, 20.000000000000014, 109.99999999999949, 20.000000000000014, 21.80000000000004, 117.49999999999952, 20.000000000000014, 22.700000000000063, 33.50000000000023, 26.300000000000118, 20.000000000000014, 20.000000000000014, 30.800000000000203, 20.000000000000014, 37.70000000000024, -49.299999999999905, 20.000000000000014, 20.000000000000014, -5.199999999999976, 47.000000000000234, 61.70000000000012, 20.000000000000014, 153.79999999999995, 7.399999999999965, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999964, -34.59999999999982, 100.09999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 13.699999999999964, 13.699999999999964, 3.199999999999967, 75.19999999999992, 20.000000000000014, 20.000000000000014, 74.89999999999942, 26.600000000000122, 9.499999999999964, 20.900000000000027, 2.599999999999975, 124.39999999999992, -13.59999999999984, -21.999999999999787, 20.000000000000014, -59.800000000000594, 17.899999999999988, -40.899999999999764, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 125.60000000000004, -57.70000000000041, 20.000000000000014, 6.1999999999999655, 45.200000000000244, 20.000000000000014, 149.0, 17.899999999999988, 91.10000000000005, 20.000000000000014, 79.39999999999996, 108.19999999999976, -160.60000000000022, 172.99999999999983, 65.0, -55.59999999999984, 60.500000000000185, -377.9, -0.9999999999999846, 44.30000000000013, 20.000000000000014, -349.60000000000014, -7.899999999999814, 5.299999999999965, 20.000000000000014, 20.000000000000014, 46.10000000000009, 20.000000000000014, -139.60000000000005, 135.7999999999996, -38.799999999999784, 117.19999999999953, 100.99999999999943, 29.000000000000163, 20.000000000000014, -8.499999999999872, 67.6999999999998, 20.000000000000014, -139.59999999999997, -28.299999999999777, -26.199999999999747, -66.10000000000007], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 48.0, 0.0, 37.0, 0.0, 1.0, 23.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 8.0, 17.0, 0.0, 8.0, 0.0, 5.0, 10.0, 0.0, 4.0, 0.0, 27.0, 20.0, 21.0, 0.0, 139.0, 197.0, 12.0, 3.0, 0.0, 0.0, 0.0, 0.0, 31.0, 24.0, 19.0, 0.0, 3.0, 19.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 22.0, 12.0, 0.0, 5.0, 15.0, 4.0, 73.0, 81.0, 0.0, 0.0, 0.0, 13.0, 3.0, 0.0, 37.0, 0.0, 19.0, 10.0, 17.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 18.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 13.0, 39.0, 0.0, 13.0, 17.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 33.0, 0.0, 12.0, 0.0, 20.0, 0.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 4.0, 26.0, 20.0, 26.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, 34.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 22.0, 6.0, 7.0, 22.0, 0.0, 38.0, 1.0, 29.0, 0.0, 0.0, 0.0, 0.0, 11.0, 37.0, 7.0, 0.0, 0.0, 0.0, 1.0, 17.0, 1.0, 20.0, 9.0, 0.0, 22.0, 64.0, 35.0, 1.0, 231.0, 0.0, 24.0, 9.0, 131.0, 73.0, 7.0, 27.0, 0.0, 0.0, 0.0, 0.0, 45.0, 43.0, 3.0, 28.0, 0.0, 0.0, 14.0, 0.0, 30.0, 0.0, 36.0, 74.0, 13.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1947105377778906, "mean_inference_ms": 3.159242828109793, "mean_action_processing_ms": 0.476394095825851, "mean_env_wait_ms": 0.7318951838315462, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022629141807556152, "StateBufferConnector_ms": 0.005013227462768555, "ViewRequirementAgentConnector_ms": 0.1960902214050293}, "num_episodes": 18, "episode_return_max": 385.0000000000002, "episode_return_min": -125.60000000000042, "episode_return_mean": 72.42999999999988, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 298.0738497992216, "num_env_steps_trained_throughput_per_sec": 298.0738497992216, "timesteps_total": 104000, "num_env_steps_sampled_lifetime": 104000, "num_agent_steps_sampled_lifetime": 416000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 16390.758, "restore_workers_time_ms": 0.016, "training_step_time_ms": 16390.687, "sample_time_ms": 3105.315, "learn_time_ms": 13262.407, "learn_throughput": 301.604, "synch_weights_time_ms": 19.469}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "training_iteration": 26, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-59-15", "timestamp": 1723521555, "time_this_iter_s": 13.480004072189331, "time_total_s": 427.87502455711365, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2901c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 427.87502455711365, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 72.8578947368421, "ram_util_percent": 83.21578947368421}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.34022155901978884, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.7877239177151332, "policy_loss": -0.001752628520052269, "vf_loss": 1.78941700754973, "vf_explained_var": 0.0018140256404876709, "kl": 0.00952636464596976, "entropy": 1.315542715693277, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9504220402824185, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4284596205388427, "policy_loss": -0.002015176560808584, "vf_loss": 3.4301908276699207, "vf_explained_var": 0.051438832787609606, "kl": 0.007572728373326171, "entropy": 0.8301575826589392, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 50085.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "env_runners": {"episode_reward_max": 385.0000000000002, "episode_reward_min": -156.2000000000013, "episode_reward_mean": 69.66399999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -377.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 231.0}, "policy_reward_mean": {"prey_policy": 19.951999999999963, "predator_policy": 14.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 171.39999999999984, 27.8000000000002, 29.00000000000014, 115.39999999999955, 67.00000000000028, 77.29999999999946, 120.99999999999976, 110.5999999999992, 142.4999999999989, 164.59999999999926, -32.79999999999964, 69.69999999999987, 60.800000000000175, 385.0000000000002, 41.300000000000324, 200.09999999999954, 111.29999999999886, 21.299999999999994, 40.0000000000003, 40.0000000000003, -6.199999999999731, 218.9999999999997, 40.0000000000003, 40.0000000000003, 49.100000000000364, 72.19999999999982, -2.8999999999997446, 91.89999999999903, 132.99999999999878, 41.80000000000033, 139.49999999999878, 68.20000000000016, 46.30000000000041, 50.80000000000046, 61.70000000000049, 3.700000000000174, 26.8000000000001, 128.6999999999989, 174.7999999999994, 32.30000000000018, 40.0000000000003, 6.999999999999952, 166.09999999999934, 40.0000000000003, 38.900000000000276, 33.4000000000002, 112.3999999999997, 40.0000000000003, 103.49999999999841, 36.40000000000025, 154.99999999999946, -6.599999999999751, -1.799999999999772, 7.000000000000107, 40.0000000000003, 40.0000000000003, 115.89999999999986, 33.2000000000002, 65.20000000000041, 184.89999999999944, 132.09999999999957, 196.59999999999943, 98.39999999999958, 45.400000000000276, -86.40000000000003, 76.30000000000024, -125.60000000000042, 31.40000000000017, 40.0000000000003, 66.10000000000011, 84.1999999999993, 109.39999999999924, 129.99999999999858, 25.500000000000068, 117.6999999999993, -57.899999999999686, -29.299999999999578, -51.300000000000246, 183.89999999999944, 32.30000000000018, 40.0000000000003, 123.69999999999978, 86.29999999999953, 200.19999999999948, 132.0999999999998, 78.79999999999937, 8.900000000000079, -156.2000000000013, 183.09999999999943, 33.400000000000205, -41.099999999999575, 66.40000000000013, 19.200000000000024, 4.200000000000211, 99.19999999999999, 193.99999999999937, -38.09999999999965, 208.9999999999996, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 49.69999999999997, 121.69999999999999, 20.000000000000014, -47.20000000000002, 20.000000000000014, -9.999999999999867, 104.89999999999985, -11.499999999999819, 39.80000000000025, 27.200000000000003, -32.49999999999979, 84.79999999999927, 100.99999999999997, 20.000000000000014, 20.60000000000002, 56.000000000000085, 117.49999999999957, 20.000000000000014, 125.59999999999985, 20.000000000000014, -53.50000000000072, -133.3000000000004, 20.000000000000014, 49.70000000000013, 55.100000000000065, -7.299999999999894, 181.99999999999994, 200.0, -2.2000000000000055, 6.499999999999979, 96.49999999999991, 74.59999999999964, -13.599999999999783, 107.89999999999944, -15.699999999999747, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -68.20000000000083, 103.0999999999998, 83.89999999999992, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.099999999999984, 49.70000000000018, 9.49999999999997, -61.900000000000766, 20.000000000000014, -40.899999999999764, 102.79999999999951, 20.000000000000014, 109.99999999999949, 20.000000000000014, 21.80000000000004, 117.49999999999952, 20.000000000000014, 22.700000000000063, 33.50000000000023, 26.300000000000118, 20.000000000000014, 20.000000000000014, 30.800000000000203, 20.000000000000014, 37.70000000000024, -49.299999999999905, 20.000000000000014, 20.000000000000014, -5.199999999999976, 47.000000000000234, 61.70000000000012, 20.000000000000014, 153.79999999999995, 7.399999999999965, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999964, -34.59999999999982, 100.09999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 13.699999999999964, 13.699999999999964, 3.199999999999967, 75.19999999999992, 20.000000000000014, 20.000000000000014, 74.89999999999942, 26.600000000000122, 9.499999999999964, 20.900000000000027, 2.599999999999975, 124.39999999999992, -13.59999999999984, -21.999999999999787, 20.000000000000014, -59.800000000000594, 17.899999999999988, -40.899999999999764, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 125.60000000000004, -57.70000000000041, 20.000000000000014, 6.1999999999999655, 45.200000000000244, 20.000000000000014, 149.0, 17.899999999999988, 91.10000000000005, 20.000000000000014, 79.39999999999996, 108.19999999999976, -160.60000000000022, 172.99999999999983, 65.0, -55.59999999999984, 60.500000000000185, -377.9, -0.9999999999999846, 44.30000000000013, 20.000000000000014, -349.60000000000014, -7.899999999999814, 5.299999999999965, 20.000000000000014, 20.000000000000014, 46.10000000000009, 20.000000000000014, -139.60000000000005, 135.7999999999996, -38.799999999999784, 117.19999999999953, 100.99999999999943, 29.000000000000163, 20.000000000000014, -8.499999999999872, 67.6999999999998, 20.000000000000014, -139.59999999999997, -28.299999999999777, -26.199999999999747, -66.10000000000007, -154.3000000000006, 20.000000000000014, 20.000000000000014, 149.9, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 103.69999999999999, 20.000000000000014, -30.399999999999793, 91.69999999999979, 197.0, -23.799999999999784, -49.29999999999985, 139.40000000000003, 60.50000000000019, 5.299999999999965, 20.000000000000014, -45.09999999999976, -131.20000000000073, -230.00000000000057, 154.10000000000002, 20.000000000000014, 7.399999999999965, 20.000000000000014, -214.10000000000068, 20.000000000000014, -169.0000000000005, 124.39999999999999, 19.099999999999998, -19.899999999999743, 20.000000000000014, -59.80000000000004, -47.49999999999978, 91.70000000000005, 20.000000000000014, 161.0, -64.00000000000034, -45.099999999999795, 94.40000000000009, 95.5999999999996, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 31.0, 24.0, 19.0, 0.0, 3.0, 19.0, 0.0, 0.0, 25.0, 0.0, 0.0, 0.0, 22.0, 12.0, 0.0, 5.0, 15.0, 4.0, 73.0, 81.0, 0.0, 0.0, 0.0, 13.0, 3.0, 0.0, 37.0, 0.0, 19.0, 10.0, 17.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 18.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 13.0, 39.0, 0.0, 13.0, 17.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 33.0, 0.0, 12.0, 0.0, 20.0, 0.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 4.0, 26.0, 20.0, 26.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, 34.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 22.0, 6.0, 7.0, 22.0, 0.0, 38.0, 1.0, 29.0, 0.0, 0.0, 0.0, 0.0, 11.0, 37.0, 7.0, 0.0, 0.0, 0.0, 1.0, 17.0, 1.0, 20.0, 9.0, 0.0, 22.0, 64.0, 35.0, 1.0, 231.0, 0.0, 24.0, 9.0, 131.0, 73.0, 7.0, 27.0, 0.0, 0.0, 0.0, 0.0, 45.0, 43.0, 3.0, 28.0, 0.0, 0.0, 14.0, 0.0, 30.0, 0.0, 36.0, 74.0, 13.0, 50.0, 83.0, 0.0, 14.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 1.0, 27.0, 0.0, 33.0, 9.0, 7.0, 6.0, 14.0, 20.0, 134.0, 71.0, 9.0, 0.0, 6.0, 0.0, 70.0, 83.0, 40.0, 71.0, 0.0, 20.0, 10.0, 34.0, 36.0, 19.0, 13.0, 0.0, 69.0, 2.0, 13.0, 6.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2004834468676413, "mean_inference_ms": 3.171630752687702, "mean_action_processing_ms": 0.47974689726481456, "mean_env_wait_ms": 0.733257086097361, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02501976490020752, "StateBufferConnector_ms": 0.00503993034362793, "ViewRequirementAgentConnector_ms": 0.23088300228118896}, "num_episodes": 22, "episode_return_max": 385.0000000000002, "episode_return_min": -156.2000000000013, "episode_return_mean": 69.66399999999987, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 224.92785227354662, "num_env_steps_trained_throughput_per_sec": 224.92785227354662, "timesteps_total": 108000, "num_env_steps_sampled_lifetime": 108000, "num_agent_steps_sampled_lifetime": 432000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 16824.029, "restore_workers_time_ms": 0.016, "training_step_time_ms": 16823.958, "sample_time_ms": 3269.482, "learn_time_ms": 13527.157, "learn_throughput": 295.701, "synch_weights_time_ms": 23.808}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "training_iteration": 27, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-59-33", "timestamp": 1723521573, "time_this_iter_s": 17.830225229263306, "time_total_s": 445.70524978637695, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d075e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 445.70524978637695, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 85.012, "ram_util_percent": 83.11599999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.326473617183153, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7899938343220918, "policy_loss": -0.0029948539959227362, "vf_loss": 0.7929249600364418, "vf_explained_var": 0.0056871494603535485, "kl": 0.010197180757610488, "entropy": 1.378948550627976, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1348343836488548, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4203780768409606, "policy_loss": -0.0012399317888868234, "vf_loss": 3.4213693138152834, "vf_explained_var": 0.10377939059620812, "kl": 0.006632014134596593, "entropy": 0.7232760247730073, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 51975.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "env_runners": {"episode_reward_max": 247.89999999999958, "episode_reward_min": -156.2000000000013, "episode_reward_mean": 69.07799999999986, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -377.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 231.0}, "policy_reward_mean": {"prey_policy": 19.54399999999997, "predator_policy": 14.995}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 40.0000000000003, 49.100000000000364, 72.19999999999982, -2.8999999999997446, 91.89999999999903, 132.99999999999878, 41.80000000000033, 139.49999999999878, 68.20000000000016, 46.30000000000041, 50.80000000000046, 61.70000000000049, 3.700000000000174, 26.8000000000001, 128.6999999999989, 174.7999999999994, 32.30000000000018, 40.0000000000003, 6.999999999999952, 166.09999999999934, 40.0000000000003, 38.900000000000276, 33.4000000000002, 112.3999999999997, 40.0000000000003, 103.49999999999841, 36.40000000000025, 154.99999999999946, -6.599999999999751, -1.799999999999772, 7.000000000000107, 40.0000000000003, 40.0000000000003, 115.89999999999986, 33.2000000000002, 65.20000000000041, 184.89999999999944, 132.09999999999957, 196.59999999999943, 98.39999999999958, 45.400000000000276, -86.40000000000003, 76.30000000000024, -125.60000000000042, 31.40000000000017, 40.0000000000003, 66.10000000000011, 84.1999999999993, 109.39999999999924, 129.99999999999858, 25.500000000000068, 117.6999999999993, -57.899999999999686, -29.299999999999578, -51.300000000000246, 183.89999999999944, 32.30000000000018, 40.0000000000003, 123.69999999999978, 86.29999999999953, 200.19999999999948, 132.0999999999998, 78.79999999999937, 8.900000000000079, -156.2000000000013, 183.09999999999943, 33.400000000000205, -41.099999999999575, 66.40000000000013, 19.200000000000024, 4.200000000000211, 99.19999999999999, 193.99999999999937, -38.09999999999965, 208.9999999999996, 40.0000000000003, 12.50000000000003, 177.49999999999957, 183.09999999999943, 27.90000000000011, 207.19999999999908, 247.89999999999958, 113.79999999999859, 36.70000000000025, 63.800000000000345, 151.09999999999965, 86.79999999999902, 42.200000000000344, 160.5999999999989, 58.90000000000052, 32.30000000000018, 31.200000000000202, 129.49999999999972, -27.299999999999855, 50.10000000000042, 210.0999999999993, -55.200000000000784, 42.70000000000034, 174.09999999999877], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 16.099999999999984, 49.70000000000018, 9.49999999999997, -61.900000000000766, 20.000000000000014, -40.899999999999764, 102.79999999999951, 20.000000000000014, 109.99999999999949, 20.000000000000014, 21.80000000000004, 117.49999999999952, 20.000000000000014, 22.700000000000063, 33.50000000000023, 26.300000000000118, 20.000000000000014, 20.000000000000014, 30.800000000000203, 20.000000000000014, 37.70000000000024, -49.299999999999905, 20.000000000000014, 20.000000000000014, -5.199999999999976, 47.000000000000234, 61.70000000000012, 20.000000000000014, 153.79999999999995, 7.399999999999965, 17.899999999999988, 20.000000000000014, 20.000000000000014, 11.599999999999964, -34.59999999999982, 100.09999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 13.699999999999964, 13.699999999999964, 3.199999999999967, 75.19999999999992, 20.000000000000014, 20.000000000000014, 74.89999999999942, 26.600000000000122, 9.499999999999964, 20.900000000000027, 2.599999999999975, 124.39999999999992, -13.59999999999984, -21.999999999999787, 20.000000000000014, -59.800000000000594, 17.899999999999988, -40.899999999999764, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 125.60000000000004, -57.70000000000041, 20.000000000000014, 6.1999999999999655, 45.200000000000244, 20.000000000000014, 149.0, 17.899999999999988, 91.10000000000005, 20.000000000000014, 79.39999999999996, 108.19999999999976, -160.60000000000022, 172.99999999999983, 65.0, -55.59999999999984, 60.500000000000185, -377.9, -0.9999999999999846, 44.30000000000013, 20.000000000000014, -349.60000000000014, -7.899999999999814, 5.299999999999965, 20.000000000000014, 20.000000000000014, 46.10000000000009, 20.000000000000014, -139.60000000000005, 135.7999999999996, -38.799999999999784, 117.19999999999953, 100.99999999999943, 29.000000000000163, 20.000000000000014, -8.499999999999872, 67.6999999999998, 20.000000000000014, -139.59999999999997, -28.299999999999777, -26.199999999999747, -66.10000000000007, -154.3000000000006, 20.000000000000014, 20.000000000000014, 149.9, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 103.69999999999999, 20.000000000000014, -30.399999999999793, 91.69999999999979, 197.0, -23.799999999999784, -49.29999999999985, 139.40000000000003, 60.50000000000019, 5.299999999999965, 20.000000000000014, -45.09999999999976, -131.20000000000073, -230.00000000000057, 154.10000000000002, 20.000000000000014, 7.399999999999965, 20.000000000000014, -214.10000000000068, 20.000000000000014, -169.0000000000005, 124.39999999999999, 19.099999999999998, -19.899999999999743, 20.000000000000014, -59.80000000000004, -47.49999999999978, 91.70000000000005, 20.000000000000014, 161.0, -64.00000000000034, -45.099999999999795, 94.40000000000009, 95.5999999999996, 20.000000000000014, 20.000000000000014, -32.49999999999975, 20.000000000000014, 60.50000000000022, 107.00000000000004, 163.1, 20.000000000000014, 20.000000000000014, -3.099999999999958, 28.700000000000202, 168.4999999999999, 155.8999999999998, 91.99999999999997, 93.79999999999933, 20.000000000000014, 20.000000000000014, 13.699999999999964, 47.000000000000156, -26.19999999999976, 158.6, -32.49999999999975, 75.49999999999949, -15.699999999999747, -3.0999999999999863, 32.300000000000225, 20.000000000000014, 140.59999999999962, 35.30000000000026, 23.60000000000007, 5.299999999999965, 20.000000000000014, 26.300000000000118, -66.10000000000088, 164.9, -135.4000000000007, -120.70000000000026, 7.399999999999965, 13.099999999999971, 20.000000000000014, 190.1, 20.000000000000014, -36.69999999999976, -116.50000000000068, 20.000000000000014, 22.700000000000053, 138.7999999999996, 35.30000000000026], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, 13.0, 39.0, 0.0, 13.0, 17.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 33.0, 0.0, 12.0, 0.0, 20.0, 0.0, 1.0, 0.0, 1.0, 6.0, 0.0, 0.0, 4.0, 26.0, 20.0, 26.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, 34.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 22.0, 6.0, 7.0, 22.0, 0.0, 38.0, 1.0, 29.0, 0.0, 0.0, 0.0, 0.0, 11.0, 37.0, 7.0, 0.0, 0.0, 0.0, 1.0, 17.0, 1.0, 20.0, 9.0, 0.0, 22.0, 64.0, 35.0, 1.0, 231.0, 0.0, 24.0, 9.0, 131.0, 73.0, 7.0, 27.0, 0.0, 0.0, 0.0, 0.0, 45.0, 43.0, 3.0, 28.0, 0.0, 0.0, 14.0, 0.0, 30.0, 0.0, 36.0, 74.0, 13.0, 50.0, 83.0, 0.0, 14.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 1.0, 27.0, 0.0, 33.0, 9.0, 7.0, 6.0, 14.0, 20.0, 134.0, 71.0, 9.0, 0.0, 6.0, 0.0, 70.0, 83.0, 40.0, 71.0, 0.0, 20.0, 10.0, 34.0, 36.0, 19.0, 13.0, 0.0, 69.0, 2.0, 13.0, 6.0, 0.0, 0.0, 25.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 11.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 43.0, 25.0, 0.0, 17.0, 10.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 38.0, 33.0, 26.0, 74.0, 57.0, 29.0, 11.0, 6.0, 0.0, 0.0, 30.0, 68.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2283568581308149, "mean_inference_ms": 3.243421981143391, "mean_action_processing_ms": 0.5800816585295465, "mean_env_wait_ms": 0.7482617398440418, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.026656508445739746, "StateBufferConnector_ms": 0.006075143814086914, "ViewRequirementAgentConnector_ms": 0.3703800439834595}, "num_episodes": 23, "episode_return_max": 247.89999999999958, "episode_return_min": -156.2000000000013, "episode_return_mean": 69.07799999999986, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 159.93968796537553, "num_env_steps_trained_throughput_per_sec": 159.93968796537553, "timesteps_total": 112000, "num_env_steps_sampled_lifetime": 112000, "num_agent_steps_sampled_lifetime": 448000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 17578.405, "restore_workers_time_ms": 0.016, "training_step_time_ms": 17578.336, "sample_time_ms": 4257.445, "learn_time_ms": 13294.36, "learn_throughput": 300.879, "synch_weights_time_ms": 23.184}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "training_iteration": 28, "trial_id": "5b7e3_00000", "date": "2024-08-12_23-59-58", "timestamp": 1723521598, "time_this_iter_s": 25.101130962371826, "time_total_s": 470.8063807487488, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28639d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 470.8063807487488, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 87.96857142857142, "ram_util_percent": 83.64}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.45340553297015723, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9939847793528642, "policy_loss": -0.002303201120800127, "vf_loss": 1.9962241849886677, "vf_explained_var": 0.004214561048638884, "kl": 0.010206200581861495, "entropy": 1.4469743123130192, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8672030837033634, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.827933574605871, "policy_loss": -0.0019622963329619437, "vf_loss": 3.8297054252927265, "vf_explained_var": 0.07458659088800824, "kl": 0.005078954969402361, "entropy": 0.7015162429796955, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 53865.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "env_runners": {"episode_reward_max": 247.89999999999958, "episode_reward_min": -156.2000000000013, "episode_reward_mean": 68.26299999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -377.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 197.0, "predator_policy": 231.0}, "policy_reward_mean": {"prey_policy": 15.981499999999958, "predator_policy": 18.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 6.999999999999952, 166.09999999999934, 40.0000000000003, 38.900000000000276, 33.4000000000002, 112.3999999999997, 40.0000000000003, 103.49999999999841, 36.40000000000025, 154.99999999999946, -6.599999999999751, -1.799999999999772, 7.000000000000107, 40.0000000000003, 40.0000000000003, 115.89999999999986, 33.2000000000002, 65.20000000000041, 184.89999999999944, 132.09999999999957, 196.59999999999943, 98.39999999999958, 45.400000000000276, -86.40000000000003, 76.30000000000024, -125.60000000000042, 31.40000000000017, 40.0000000000003, 66.10000000000011, 84.1999999999993, 109.39999999999924, 129.99999999999858, 25.500000000000068, 117.6999999999993, -57.899999999999686, -29.299999999999578, -51.300000000000246, 183.89999999999944, 32.30000000000018, 40.0000000000003, 123.69999999999978, 86.29999999999953, 200.19999999999948, 132.0999999999998, 78.79999999999937, 8.900000000000079, -156.2000000000013, 183.09999999999943, 33.400000000000205, -41.099999999999575, 66.40000000000013, 19.200000000000024, 4.200000000000211, 99.19999999999999, 193.99999999999937, -38.09999999999965, 208.9999999999996, 40.0000000000003, 12.50000000000003, 177.49999999999957, 183.09999999999943, 27.90000000000011, 207.19999999999908, 247.89999999999958, 113.79999999999859, 36.70000000000025, 63.800000000000345, 151.09999999999965, 86.79999999999902, 42.200000000000344, 160.5999999999989, 58.90000000000052, 32.30000000000018, 31.200000000000202, 129.49999999999972, -27.299999999999855, 50.10000000000042, 210.0999999999993, -55.200000000000784, 42.70000000000034, 174.09999999999877, 76.70000000000003, 42.500000000000334, 217.09999999999926, -19.899999999999572, -23.099999999999973, -59.40000000000039, 32.30000000000018, -12.800000000000052, 131.79999999999905, 32.30000000000018, 202.39999999999972, 111.19999999999987, 132.6999999999997, 202.89999999999998, -70.00000000000071, 40.0000000000003, 134.29999999999927, -54.60000000000062], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 11.599999999999964, -34.59999999999982, 100.09999999999991, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 13.699999999999964, 13.699999999999964, 3.199999999999967, 75.19999999999992, 20.000000000000014, 20.000000000000014, 74.89999999999942, 26.600000000000122, 9.499999999999964, 20.900000000000027, 2.599999999999975, 124.39999999999992, -13.59999999999984, -21.999999999999787, 20.000000000000014, -59.800000000000594, 17.899999999999988, -40.899999999999764, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 125.60000000000004, -57.70000000000041, 20.000000000000014, 6.1999999999999655, 45.200000000000244, 20.000000000000014, 149.0, 17.899999999999988, 91.10000000000005, 20.000000000000014, 79.39999999999996, 108.19999999999976, -160.60000000000022, 172.99999999999983, 65.0, -55.59999999999984, 60.500000000000185, -377.9, -0.9999999999999846, 44.30000000000013, 20.000000000000014, -349.60000000000014, -7.899999999999814, 5.299999999999965, 20.000000000000014, 20.000000000000014, 46.10000000000009, 20.000000000000014, -139.60000000000005, 135.7999999999996, -38.799999999999784, 117.19999999999953, 100.99999999999943, 29.000000000000163, 20.000000000000014, -8.499999999999872, 67.6999999999998, 20.000000000000014, -139.59999999999997, -28.299999999999777, -26.199999999999747, -66.10000000000007, -154.3000000000006, 20.000000000000014, 20.000000000000014, 149.9, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 103.69999999999999, 20.000000000000014, -30.399999999999793, 91.69999999999979, 197.0, -23.799999999999784, -49.29999999999985, 139.40000000000003, 60.50000000000019, 5.299999999999965, 20.000000000000014, -45.09999999999976, -131.20000000000073, -230.00000000000057, 154.10000000000002, 20.000000000000014, 7.399999999999965, 20.000000000000014, -214.10000000000068, 20.000000000000014, -169.0000000000005, 124.39999999999999, 19.099999999999998, -19.899999999999743, 20.000000000000014, -59.80000000000004, -47.49999999999978, 91.70000000000005, 20.000000000000014, 161.0, -64.00000000000034, -45.099999999999795, 94.40000000000009, 95.5999999999996, 20.000000000000014, 20.000000000000014, -32.49999999999975, 20.000000000000014, 60.50000000000022, 107.00000000000004, 163.1, 20.000000000000014, 20.000000000000014, -3.099999999999958, 28.700000000000202, 168.4999999999999, 155.8999999999998, 91.99999999999997, 93.79999999999933, 20.000000000000014, 20.000000000000014, 13.699999999999964, 47.000000000000156, -26.19999999999976, 158.6, -32.49999999999975, 75.49999999999949, -15.699999999999747, -3.0999999999999863, 32.300000000000225, 20.000000000000014, 140.59999999999962, 35.30000000000026, 23.60000000000007, 5.299999999999965, 20.000000000000014, 26.300000000000118, -66.10000000000088, 164.9, -135.4000000000007, -120.70000000000026, 7.399999999999965, 13.099999999999971, 20.000000000000014, 190.1, 20.000000000000014, -36.69999999999976, -116.50000000000068, 20.000000000000014, 22.700000000000053, 138.7999999999996, 35.30000000000026, -1.0000000000000204, 67.7000000000001, 23.600000000000065, 17.899999999999988, 38.00000000000024, 178.1, -124.90000000000072, 20.000000000000014, 20.000000000000014, -213.1000000000004, -198.40000000000055, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, -80.7999999999999, -36.6999999999999, 141.49999999999963, 5.299999999999965, 20.000000000000014, 152.0, 16.40000000000012, -68.20000000000078, 133.39999999999998, 20.000000000000014, 112.69999999999999, 122.6, 80.29999999999998, 20.000000000000014, -232.00000000000028, 20.000000000000014, 20.000000000000014, 133.99999999999977, -36.69999999999982, -160.60000000000065, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 4.0, 26.0, 20.0, 26.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, 34.0, 0.0, 0.0, 0.0, 2.0, 5.0, 1.0, 22.0, 6.0, 7.0, 22.0, 0.0, 38.0, 1.0, 29.0, 0.0, 0.0, 0.0, 0.0, 11.0, 37.0, 7.0, 0.0, 0.0, 0.0, 1.0, 17.0, 1.0, 20.0, 9.0, 0.0, 22.0, 64.0, 35.0, 1.0, 231.0, 0.0, 24.0, 9.0, 131.0, 73.0, 7.0, 27.0, 0.0, 0.0, 0.0, 0.0, 45.0, 43.0, 3.0, 28.0, 0.0, 0.0, 14.0, 0.0, 30.0, 0.0, 36.0, 74.0, 13.0, 50.0, 83.0, 0.0, 14.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 1.0, 27.0, 0.0, 33.0, 9.0, 7.0, 6.0, 14.0, 20.0, 134.0, 71.0, 9.0, 0.0, 6.0, 0.0, 70.0, 83.0, 40.0, 71.0, 0.0, 20.0, 10.0, 34.0, 36.0, 19.0, 13.0, 0.0, 69.0, 2.0, 13.0, 6.0, 0.0, 0.0, 25.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 11.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 43.0, 25.0, 0.0, 17.0, 10.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 38.0, 33.0, 26.0, 74.0, 57.0, 29.0, 11.0, 6.0, 0.0, 0.0, 30.0, 68.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 1.0, 0.0, 69.0, 16.0, 87.0, 83.0, 63.0, 56.0, 7.0, 0.0, 37.0, 11.0, 3.0, 24.0, 7.0, 0.0, 16.0, 18.0, 42.0, 4.0, 0.0, 0.0, 0.0, 0.0, 61.0, 81.0, 0.0, 0.0, 27.0, 10.0, 65.0, 21.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.254926664414492, "mean_inference_ms": 3.317289765985704, "mean_action_processing_ms": 0.652772419618978, "mean_env_wait_ms": 0.7630145136513967, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014123678207397461, "StateBufferConnector_ms": 0.008502364158630371, "ViewRequirementAgentConnector_ms": 0.363314151763916}, "num_episodes": 18, "episode_return_max": 247.89999999999958, "episode_return_min": -156.2000000000013, "episode_return_mean": 68.26299999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 203.5753644631008, "num_env_steps_trained_throughput_per_sec": 203.5753644631008, "timesteps_total": 116000, "num_env_steps_sampled_lifetime": 116000, "num_agent_steps_sampled_lifetime": 464000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 17140.11, "restore_workers_time_ms": 0.016, "training_step_time_ms": 17140.041, "sample_time_ms": 4197.692, "learn_time_ms": 12916.133, "learn_throughput": 309.69, "synch_weights_time_ms": 22.908}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "training_iteration": 29, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-00-18", "timestamp": 1723521618, "time_this_iter_s": 19.705897092819214, "time_total_s": 490.512277841568, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28c7ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 490.512277841568, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 86.92500000000003, "ram_util_percent": 83.91071428571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4109259533385436, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.265235888721451, "policy_loss": -0.0021037430161235746, "vf_loss": 1.2672831824532262, "vf_explained_var": 0.005002539939981289, "kl": 0.009031692131917988, "entropy": 1.4027188680159353, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1069804892022774, "cur_kl_coeff": 0.03749999999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.4251351559603656, "policy_loss": -0.00180457852578786, "vf_loss": 4.4267814492422435, "vf_explained_var": 0.10994200056822842, "kl": 0.004220886441278605, "entropy": 0.679611117341531, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 55755.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "env_runners": {"episode_reward_max": 302.6000000000008, "episode_reward_min": -156.2000000000013, "episode_reward_mean": 80.31199999999981, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -377.9, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 231.0}, "policy_reward_mean": {"prey_policy": 21.475999999999953, "predator_policy": 18.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [65.20000000000041, 184.89999999999944, 132.09999999999957, 196.59999999999943, 98.39999999999958, 45.400000000000276, -86.40000000000003, 76.30000000000024, -125.60000000000042, 31.40000000000017, 40.0000000000003, 66.10000000000011, 84.1999999999993, 109.39999999999924, 129.99999999999858, 25.500000000000068, 117.6999999999993, -57.899999999999686, -29.299999999999578, -51.300000000000246, 183.89999999999944, 32.30000000000018, 40.0000000000003, 123.69999999999978, 86.29999999999953, 200.19999999999948, 132.0999999999998, 78.79999999999937, 8.900000000000079, -156.2000000000013, 183.09999999999943, 33.400000000000205, -41.099999999999575, 66.40000000000013, 19.200000000000024, 4.200000000000211, 99.19999999999999, 193.99999999999937, -38.09999999999965, 208.9999999999996, 40.0000000000003, 12.50000000000003, 177.49999999999957, 183.09999999999943, 27.90000000000011, 207.19999999999908, 247.89999999999958, 113.79999999999859, 36.70000000000025, 63.800000000000345, 151.09999999999965, 86.79999999999902, 42.200000000000344, 160.5999999999989, 58.90000000000052, 32.30000000000018, 31.200000000000202, 129.49999999999972, -27.299999999999855, 50.10000000000042, 210.0999999999993, -55.200000000000784, 42.70000000000034, 174.09999999999877, 76.70000000000003, 42.500000000000334, 217.09999999999926, -19.899999999999572, -23.099999999999973, -59.40000000000039, 32.30000000000018, -12.800000000000052, 131.79999999999905, 32.30000000000018, 202.39999999999972, 111.19999999999987, 132.6999999999997, 202.89999999999998, -70.00000000000071, 40.0000000000003, 134.29999999999927, -54.60000000000062, 25.200000000000063, 189.6999999999993, 40.0000000000003, -18.599999999999575, 195.19999999999936, -19.90000000000003, 20.199999999999978, 197.49999999999937, 136.69999999999888, 302.6000000000008, 23.500000000000032, 40.0000000000003, 59.80000000000027, 116.29999999999976, 282.00000000000057, 185.89999999999944, 237.09999999999903, 192.0999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [45.200000000000244, 20.000000000000014, 149.0, 17.899999999999988, 91.10000000000005, 20.000000000000014, 79.39999999999996, 108.19999999999976, -160.60000000000022, 172.99999999999983, 65.0, -55.59999999999984, 60.500000000000185, -377.9, -0.9999999999999846, 44.30000000000013, 20.000000000000014, -349.60000000000014, -7.899999999999814, 5.299999999999965, 20.000000000000014, 20.000000000000014, 46.10000000000009, 20.000000000000014, -139.60000000000005, 135.7999999999996, -38.799999999999784, 117.19999999999953, 100.99999999999943, 29.000000000000163, 20.000000000000014, -8.499999999999872, 67.6999999999998, 20.000000000000014, -139.59999999999997, -28.299999999999777, -26.199999999999747, -66.10000000000007, -154.3000000000006, 20.000000000000014, 20.000000000000014, 149.9, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 103.69999999999999, 20.000000000000014, -30.399999999999793, 91.69999999999979, 197.0, -23.799999999999784, -49.29999999999985, 139.40000000000003, 60.50000000000019, 5.299999999999965, 20.000000000000014, -45.09999999999976, -131.20000000000073, -230.00000000000057, 154.10000000000002, 20.000000000000014, 7.399999999999965, 20.000000000000014, -214.10000000000068, 20.000000000000014, -169.0000000000005, 124.39999999999999, 19.099999999999998, -19.899999999999743, 20.000000000000014, -59.80000000000004, -47.49999999999978, 91.70000000000005, 20.000000000000014, 161.0, -64.00000000000034, -45.099999999999795, 94.40000000000009, 95.5999999999996, 20.000000000000014, 20.000000000000014, -32.49999999999975, 20.000000000000014, 60.50000000000022, 107.00000000000004, 163.1, 20.000000000000014, 20.000000000000014, -3.099999999999958, 28.700000000000202, 168.4999999999999, 155.8999999999998, 91.99999999999997, 93.79999999999933, 20.000000000000014, 20.000000000000014, 13.699999999999964, 47.000000000000156, -26.19999999999976, 158.6, -32.49999999999975, 75.49999999999949, -15.699999999999747, -3.0999999999999863, 32.300000000000225, 20.000000000000014, 140.59999999999962, 35.30000000000026, 23.60000000000007, 5.299999999999965, 20.000000000000014, 26.300000000000118, -66.10000000000088, 164.9, -135.4000000000007, -120.70000000000026, 7.399999999999965, 13.099999999999971, 20.000000000000014, 190.1, 20.000000000000014, -36.69999999999976, -116.50000000000068, 20.000000000000014, 22.700000000000053, 138.7999999999996, 35.30000000000026, -1.0000000000000204, 67.7000000000001, 23.600000000000065, 17.899999999999988, 38.00000000000024, 178.1, -124.90000000000072, 20.000000000000014, 20.000000000000014, -213.1000000000004, -198.40000000000055, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, -80.7999999999999, -36.6999999999999, 141.49999999999963, 5.299999999999965, 20.000000000000014, 152.0, 16.40000000000012, -68.20000000000078, 133.39999999999998, 20.000000000000014, 112.69999999999999, 122.6, 80.29999999999998, 20.000000000000014, -232.00000000000028, 20.000000000000014, 20.000000000000014, 133.99999999999977, -36.69999999999982, -160.60000000000065, 20.000000000000014, -17.79999999999974, 20.000000000000014, 11.599999999999966, 166.09999999999994, 20.000000000000014, 20.000000000000014, -5.199999999999941, -72.40000000000065, 170.0, -17.79999999999974, -240.40000000000043, 78.4999999999994, -17.79999999999974, 20.000000000000014, 1.0999999999999617, 187.4, 20.000000000000014, 109.69999999999956, 200.0, 83.59999999999962, 20.000000000000014, -11.499999999999819, 20.000000000000014, 20.000000000000014, 39.79999999999998, 20.000000000000014, 20.000000000000014, 86.30000000000004, 152.59999999999985, 124.39999999999998, 200.0, -45.09999999999976, 56.00000000000023, 181.09999999999994, 1.0999999999999865, 173.0], "policy_predator_policy_reward": [0.0, 0.0, 1.0, 17.0, 1.0, 20.0, 9.0, 0.0, 22.0, 64.0, 35.0, 1.0, 231.0, 0.0, 24.0, 9.0, 131.0, 73.0, 7.0, 27.0, 0.0, 0.0, 0.0, 0.0, 45.0, 43.0, 3.0, 28.0, 0.0, 0.0, 14.0, 0.0, 30.0, 0.0, 36.0, 74.0, 13.0, 50.0, 83.0, 0.0, 14.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 1.0, 27.0, 0.0, 33.0, 9.0, 7.0, 6.0, 14.0, 20.0, 134.0, 71.0, 9.0, 0.0, 6.0, 0.0, 70.0, 83.0, 40.0, 71.0, 0.0, 20.0, 10.0, 34.0, 36.0, 19.0, 13.0, 0.0, 69.0, 2.0, 13.0, 6.0, 0.0, 0.0, 25.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 11.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 43.0, 25.0, 0.0, 17.0, 10.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 38.0, 33.0, 26.0, 74.0, 57.0, 29.0, 11.0, 6.0, 0.0, 0.0, 30.0, 68.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 1.0, 0.0, 69.0, 16.0, 87.0, 83.0, 63.0, 56.0, 7.0, 0.0, 37.0, 11.0, 3.0, 24.0, 7.0, 0.0, 16.0, 18.0, 42.0, 4.0, 0.0, 0.0, 0.0, 0.0, 61.0, 81.0, 0.0, 0.0, 27.0, 10.0, 65.0, 21.0, 18.0, 5.0, 4.0, 8.0, 0.0, 0.0, 3.0, 56.0, 16.0, 27.0, 32.0, 110.0, 18.0, 0.0, 2.0, 7.0, 0.0, 7.0, 0.0, 19.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 4.0, 1.0, 31.0, 0.0, 0.0, 0.0, 9.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2769758004547869, "mean_inference_ms": 3.3774714312327485, "mean_action_processing_ms": 0.7208057195625251, "mean_env_wait_ms": 0.7743693922881684, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014035224914550781, "StateBufferConnector_ms": 0.01018679141998291, "ViewRequirementAgentConnector_ms": 0.3450409173965454}, "num_episodes": 18, "episode_return_max": 302.6000000000008, "episode_return_min": -156.2000000000013, "episode_return_mean": 80.31199999999981, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 282.17036725219, "num_env_steps_trained_throughput_per_sec": 282.17036725219, "timesteps_total": 120000, "num_env_steps_sampled_lifetime": 120000, "num_agent_steps_sampled_lifetime": 480000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 16969.204, "restore_workers_time_ms": 0.016, "training_step_time_ms": 16969.134, "sample_time_ms": 4270.509, "learn_time_ms": 12671.136, "learn_throughput": 315.678, "synch_weights_time_ms": 23.069}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "training_iteration": 30, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-00-32", "timestamp": 1723521632, "time_this_iter_s": 14.219265222549438, "time_total_s": 504.73154306411743, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28c73a0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 504.73154306411743, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 75.74999999999999, "ram_util_percent": 83.465}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5021970274823683, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1564821137637689, "policy_loss": -0.0019516427971659198, "vf_loss": 1.1583878760773039, "vf_explained_var": 0.004489240349915923, "kl": 0.007340875448142768, "entropy": 1.3446540597885375, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2380210438654535, "cur_kl_coeff": 0.018749999999999996, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.109631930898737, "policy_loss": -0.0005867301394039439, "vf_loss": 3.1101654757898323, "vf_explained_var": 0.11281811276440898, "kl": 0.002836524482432277, "entropy": 0.7140625311584069, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 57645.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "env_runners": {"episode_reward_max": 302.6000000000008, "episode_reward_min": -156.2000000000013, "episode_reward_mean": 87.40899999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -302.59999999999917, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 142.0}, "policy_reward_mean": {"prey_policy": 27.204499999999953, "predator_policy": 16.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-29.299999999999578, -51.300000000000246, 183.89999999999944, 32.30000000000018, 40.0000000000003, 123.69999999999978, 86.29999999999953, 200.19999999999948, 132.0999999999998, 78.79999999999937, 8.900000000000079, -156.2000000000013, 183.09999999999943, 33.400000000000205, -41.099999999999575, 66.40000000000013, 19.200000000000024, 4.200000000000211, 99.19999999999999, 193.99999999999937, -38.09999999999965, 208.9999999999996, 40.0000000000003, 12.50000000000003, 177.49999999999957, 183.09999999999943, 27.90000000000011, 207.19999999999908, 247.89999999999958, 113.79999999999859, 36.70000000000025, 63.800000000000345, 151.09999999999965, 86.79999999999902, 42.200000000000344, 160.5999999999989, 58.90000000000052, 32.30000000000018, 31.200000000000202, 129.49999999999972, -27.299999999999855, 50.10000000000042, 210.0999999999993, -55.200000000000784, 42.70000000000034, 174.09999999999877, 76.70000000000003, 42.500000000000334, 217.09999999999926, -19.899999999999572, -23.099999999999973, -59.40000000000039, 32.30000000000018, -12.800000000000052, 131.79999999999905, 32.30000000000018, 202.39999999999972, 111.19999999999987, 132.6999999999997, 202.89999999999998, -70.00000000000071, 40.0000000000003, 134.29999999999927, -54.60000000000062, 25.200000000000063, 189.6999999999993, 40.0000000000003, -18.599999999999575, 195.19999999999936, -19.90000000000003, 20.199999999999978, 197.49999999999937, 136.69999999999888, 302.6000000000008, 23.500000000000032, 40.0000000000003, 59.80000000000027, 116.29999999999976, 282.00000000000057, 185.89999999999944, 237.09999999999903, 192.0999999999994, 169.59999999999954, 225.3999999999992, 125.59999999999894, 40.0000000000003, 93.8999999999992, 26.20000000000008, 167.59999999999906, 122.89999999999975, 26.80000000000009, 230.4999999999994, 120.99999999999875, 30.100000000000147, 291.10000000000025, 9.200000000000085, -67.40000000000035, 225.29999999999936, 26.80000000000011, -21.599999999999675], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-26.199999999999747, -66.10000000000007, -154.3000000000006, 20.000000000000014, 20.000000000000014, 149.9, 5.299999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 103.69999999999999, 20.000000000000014, -30.399999999999793, 91.69999999999979, 197.0, -23.799999999999784, -49.29999999999985, 139.40000000000003, 60.50000000000019, 5.299999999999965, 20.000000000000014, -45.09999999999976, -131.20000000000073, -230.00000000000057, 154.10000000000002, 20.000000000000014, 7.399999999999965, 20.000000000000014, -214.10000000000068, 20.000000000000014, -169.0000000000005, 124.39999999999999, 19.099999999999998, -19.899999999999743, 20.000000000000014, -59.80000000000004, -47.49999999999978, 91.70000000000005, 20.000000000000014, 161.0, -64.00000000000034, -45.099999999999795, 94.40000000000009, 95.5999999999996, 20.000000000000014, 20.000000000000014, -32.49999999999975, 20.000000000000014, 60.50000000000022, 107.00000000000004, 163.1, 20.000000000000014, 20.000000000000014, -3.099999999999958, 28.700000000000202, 168.4999999999999, 155.8999999999998, 91.99999999999997, 93.79999999999933, 20.000000000000014, 20.000000000000014, 13.699999999999964, 47.000000000000156, -26.19999999999976, 158.6, -32.49999999999975, 75.49999999999949, -15.699999999999747, -3.0999999999999863, 32.300000000000225, 20.000000000000014, 140.59999999999962, 35.30000000000026, 23.60000000000007, 5.299999999999965, 20.000000000000014, 26.300000000000118, -66.10000000000088, 164.9, -135.4000000000007, -120.70000000000026, 7.399999999999965, 13.099999999999971, 20.000000000000014, 190.1, 20.000000000000014, -36.69999999999976, -116.50000000000068, 20.000000000000014, 22.700000000000053, 138.7999999999996, 35.30000000000026, -1.0000000000000204, 67.7000000000001, 23.600000000000065, 17.899999999999988, 38.00000000000024, 178.1, -124.90000000000072, 20.000000000000014, 20.000000000000014, -213.1000000000004, -198.40000000000055, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, -80.7999999999999, -36.6999999999999, 141.49999999999963, 5.299999999999965, 20.000000000000014, 152.0, 16.40000000000012, -68.20000000000078, 133.39999999999998, 20.000000000000014, 112.69999999999999, 122.6, 80.29999999999998, 20.000000000000014, -232.00000000000028, 20.000000000000014, 20.000000000000014, 133.99999999999977, -36.69999999999982, -160.60000000000065, 20.000000000000014, -17.79999999999974, 20.000000000000014, 11.599999999999966, 166.09999999999994, 20.000000000000014, 20.000000000000014, -5.199999999999941, -72.40000000000065, 170.0, -17.79999999999974, -240.40000000000043, 78.4999999999994, -17.79999999999974, 20.000000000000014, 1.0999999999999617, 187.4, 20.000000000000014, 109.69999999999956, 200.0, 83.59999999999962, 20.000000000000014, -11.499999999999819, 20.000000000000014, 20.000000000000014, 39.79999999999998, 20.000000000000014, 20.000000000000014, 86.30000000000004, 152.59999999999985, 124.39999999999998, 200.0, -45.09999999999976, 56.00000000000023, 181.09999999999994, 1.0999999999999865, 173.0, 20.000000000000014, 149.60000000000002, 200.0, 25.400000000000098, 20.000000000000014, 92.59999999999957, 20.000000000000014, 20.000000000000014, 38.9000000000001, 20.000000000000014, -2.4999999999999716, 13.699999999999966, -24.399999999999807, 157.99999999999977, -108.1000000000007, 155.0, -5.199999999999934, 20.000000000000014, 24.50000000000003, 200.0, 74.8999999999994, 46.10000000000014, 7.399999999999965, 13.699999999999958, 200.0, 91.09999999999931, -38.799999999999756, 20.000000000000014, 27.20000000000013, -302.59999999999917, 20.30000000000004, 200.0, 20.000000000000014, -5.1999999999999975, 5.299999999999965, -82.9000000000006], "policy_predator_policy_reward": [13.0, 50.0, 83.0, 0.0, 14.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.0, 1.0, 27.0, 0.0, 33.0, 9.0, 7.0, 6.0, 14.0, 20.0, 134.0, 71.0, 9.0, 0.0, 6.0, 0.0, 70.0, 83.0, 40.0, 71.0, 0.0, 20.0, 10.0, 34.0, 36.0, 19.0, 13.0, 0.0, 69.0, 2.0, 13.0, 6.0, 0.0, 0.0, 25.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 11.0, 3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 43.0, 25.0, 0.0, 17.0, 10.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 38.0, 33.0, 26.0, 74.0, 57.0, 29.0, 11.0, 6.0, 0.0, 0.0, 30.0, 68.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 1.0, 0.0, 69.0, 16.0, 87.0, 83.0, 63.0, 56.0, 7.0, 0.0, 37.0, 11.0, 3.0, 24.0, 7.0, 0.0, 16.0, 18.0, 42.0, 4.0, 0.0, 0.0, 0.0, 0.0, 61.0, 81.0, 0.0, 0.0, 27.0, 10.0, 65.0, 21.0, 18.0, 5.0, 4.0, 8.0, 0.0, 0.0, 3.0, 56.0, 16.0, 27.0, 32.0, 110.0, 18.0, 0.0, 2.0, 7.0, 0.0, 7.0, 0.0, 19.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 4.0, 1.0, 31.0, 0.0, 0.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 17.0, 18.0, 12.0, 3.0, 34.0, 0.0, 15.0, 61.0, 0.0, 12.0, 3.0, 3.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 28.0, 0.0, 142.0, 66.0, 0.0, 5.0, 0.0, 12.0, 49.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2958106364892652, "mean_inference_ms": 3.428895860551787, "mean_action_processing_ms": 0.7855666310018009, "mean_env_wait_ms": 0.7843700189083894, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011623859405517578, "StateBufferConnector_ms": 0.009073138236999512, "ViewRequirementAgentConnector_ms": 0.3267320394515991}, "num_episodes": 18, "episode_return_max": 302.6000000000008, "episode_return_min": -156.2000000000013, "episode_return_mean": 87.40899999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 269.54942398269094, "num_env_steps_trained_throughput_per_sec": 269.54942398269094, "timesteps_total": 124000, "num_env_steps_sampled_lifetime": 124000, "num_agent_steps_sampled_lifetime": 496000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 17023.622, "restore_workers_time_ms": 0.016, "training_step_time_ms": 17023.552, "sample_time_ms": 4271.941, "learn_time_ms": 12717.245, "learn_throughput": 314.534, "synch_weights_time_ms": 29.632}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "training_iteration": 31, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-00-47", "timestamp": 1723521647, "time_this_iter_s": 14.888654947280884, "time_total_s": 519.6201980113983, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d3aaf0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 519.6201980113983, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 76.85, "ram_util_percent": 83.19500000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4117823870606208, "cur_kl_coeff": 0.00625, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.582322390653469, "policy_loss": -0.0008727572111797238, "vf_loss": 1.5831818350408442, "vf_explained_var": 0.0028119780714549714, "kl": 0.002130427365815351, "entropy": 1.322665342704329, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0806570240981364, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.8514034373419626, "policy_loss": -0.0023374054096786984, "vf_loss": 3.8536833778260244, "vf_explained_var": 0.08868643824385587, "kl": 0.006129440767297616, "entropy": 0.7440400668237576, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 59535.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "env_runners": {"episode_reward_max": 302.6000000000008, "episode_reward_min": -103.50000000000003, "episode_reward_mean": 89.26999999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -302.59999999999917, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": 28.334999999999944, "predator_policy": 16.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [207.19999999999908, 247.89999999999958, 113.79999999999859, 36.70000000000025, 63.800000000000345, 151.09999999999965, 86.79999999999902, 42.200000000000344, 160.5999999999989, 58.90000000000052, 32.30000000000018, 31.200000000000202, 129.49999999999972, -27.299999999999855, 50.10000000000042, 210.0999999999993, -55.200000000000784, 42.70000000000034, 174.09999999999877, 76.70000000000003, 42.500000000000334, 217.09999999999926, -19.899999999999572, -23.099999999999973, -59.40000000000039, 32.30000000000018, -12.800000000000052, 131.79999999999905, 32.30000000000018, 202.39999999999972, 111.19999999999987, 132.6999999999997, 202.89999999999998, -70.00000000000071, 40.0000000000003, 134.29999999999927, -54.60000000000062, 25.200000000000063, 189.6999999999993, 40.0000000000003, -18.599999999999575, 195.19999999999936, -19.90000000000003, 20.199999999999978, 197.49999999999937, 136.69999999999888, 302.6000000000008, 23.500000000000032, 40.0000000000003, 59.80000000000027, 116.29999999999976, 282.00000000000057, 185.89999999999944, 237.09999999999903, 192.0999999999994, 169.59999999999954, 225.3999999999992, 125.59999999999894, 40.0000000000003, 93.8999999999992, 26.20000000000008, 167.59999999999906, 122.89999999999975, 26.80000000000009, 230.4999999999994, 120.99999999999875, 30.100000000000147, 291.10000000000025, 9.200000000000085, -67.40000000000035, 225.29999999999936, 26.80000000000011, -21.599999999999675, 67.60000000000015, 191.0999999999994, 151.799999999999, 69.90000000000005, 235.59999999999945, 192.59999999999937, 121.89999999999864, 111.9999999999992, -64.50000000000016, 155.1999999999989, 16.19999999999999, 261.40000000000066, 27.900000000000112, -74.40000000000012, 10.30000000000006, 129.099999999999, 40.0000000000003, 40.0000000000003, -79.30000000000032, -103.50000000000003, 68.4000000000001, -7.299999999999983, 40.0000000000003, 114.49999999999989, 25.70000000000007, 131.79999999999973, 131.7999999999987], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [28.700000000000202, 168.4999999999999, 155.8999999999998, 91.99999999999997, 93.79999999999933, 20.000000000000014, 20.000000000000014, 13.699999999999964, 47.000000000000156, -26.19999999999976, 158.6, -32.49999999999975, 75.49999999999949, -15.699999999999747, -3.0999999999999863, 32.300000000000225, 20.000000000000014, 140.59999999999962, 35.30000000000026, 23.60000000000007, 5.299999999999965, 20.000000000000014, 26.300000000000118, -66.10000000000088, 164.9, -135.4000000000007, -120.70000000000026, 7.399999999999965, 13.099999999999971, 20.000000000000014, 190.1, 20.000000000000014, -36.69999999999976, -116.50000000000068, 20.000000000000014, 22.700000000000053, 138.7999999999996, 35.30000000000026, -1.0000000000000204, 67.7000000000001, 23.600000000000065, 17.899999999999988, 38.00000000000024, 178.1, -124.90000000000072, 20.000000000000014, 20.000000000000014, -213.1000000000004, -198.40000000000055, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, -80.7999999999999, -36.6999999999999, 141.49999999999963, 5.299999999999965, 20.000000000000014, 152.0, 16.40000000000012, -68.20000000000078, 133.39999999999998, 20.000000000000014, 112.69999999999999, 122.6, 80.29999999999998, 20.000000000000014, -232.00000000000028, 20.000000000000014, 20.000000000000014, 133.99999999999977, -36.69999999999982, -160.60000000000065, 20.000000000000014, -17.79999999999974, 20.000000000000014, 11.599999999999966, 166.09999999999994, 20.000000000000014, 20.000000000000014, -5.199999999999941, -72.40000000000065, 170.0, -17.79999999999974, -240.40000000000043, 78.4999999999994, -17.79999999999974, 20.000000000000014, 1.0999999999999617, 187.4, 20.000000000000014, 109.69999999999956, 200.0, 83.59999999999962, 20.000000000000014, -11.499999999999819, 20.000000000000014, 20.000000000000014, 39.79999999999998, 20.000000000000014, 20.000000000000014, 86.30000000000004, 152.59999999999985, 124.39999999999998, 200.0, -45.09999999999976, 56.00000000000023, 181.09999999999994, 1.0999999999999865, 173.0, 20.000000000000014, 149.60000000000002, 200.0, 25.400000000000098, 20.000000000000014, 92.59999999999957, 20.000000000000014, 20.000000000000014, 38.9000000000001, 20.000000000000014, -2.4999999999999716, 13.699999999999966, -24.399999999999807, 157.99999999999977, -108.1000000000007, 155.0, -5.199999999999934, 20.000000000000014, 24.50000000000003, 200.0, 74.8999999999994, 46.10000000000014, 7.399999999999965, 13.699999999999958, 200.0, 91.09999999999931, -38.799999999999756, 20.000000000000014, 27.20000000000013, -302.59999999999917, 20.30000000000004, 200.0, 20.000000000000014, -5.1999999999999975, 5.299999999999965, -82.9000000000006, 32.60000000000019, 20.000000000000014, 166.1, 20.000000000000014, 123.79999999999967, 20.000000000000014, 41.90000000000018, 20.000000000000014, 82.99999999999943, 143.59999999999997, 157.10000000000002, 24.500000000000096, 101.89999999999938, 20.000000000000014, 20.000000000000014, 91.99999999999967, -145.90000000000018, -13.599999999999833, 20.000000000000014, 135.19999999999962, -257.7999999999988, 20.000000000000014, 132.49999999999957, 128.89999999999955, 7.39999999999997, 9.499999999999964, 13.699999999999964, -192.10000000000053, -19.899999999999757, 3.1999999999999615, -0.9999999999999846, 112.0999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -217.30000000000013, 20.000000000000014, -36.700000000000045, -290.7999999999994, 50.6000000000002, 15.799999999999963, 20.000000000000014, -70.30000000000044, 20.000000000000014, 20.000000000000014, 75.19999999999996, -15.699999999999747, 20.000000000000014, -7.299999999999891, 111.79999999999998, 20.000000000000014, 111.79999999999944, 20.000000000000014], "policy_predator_policy_reward": [3.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 43.0, 25.0, 0.0, 17.0, 10.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 38.0, 33.0, 26.0, 74.0, 57.0, 29.0, 11.0, 6.0, 0.0, 0.0, 30.0, 68.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 1.0, 0.0, 69.0, 16.0, 87.0, 83.0, 63.0, 56.0, 7.0, 0.0, 37.0, 11.0, 3.0, 24.0, 7.0, 0.0, 16.0, 18.0, 42.0, 4.0, 0.0, 0.0, 0.0, 0.0, 61.0, 81.0, 0.0, 0.0, 27.0, 10.0, 65.0, 21.0, 18.0, 5.0, 4.0, 8.0, 0.0, 0.0, 3.0, 56.0, 16.0, 27.0, 32.0, 110.0, 18.0, 0.0, 2.0, 7.0, 0.0, 7.0, 0.0, 19.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 4.0, 1.0, 31.0, 0.0, 0.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 17.0, 18.0, 12.0, 3.0, 34.0, 0.0, 15.0, 61.0, 0.0, 12.0, 3.0, 3.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 28.0, 0.0, 142.0, 66.0, 0.0, 5.0, 0.0, 12.0, 49.0, 7.0, 0.0, 15.0, 2.0, 3.0, 0.0, 8.0, 0.0, 8.0, 9.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 94.0, 1.0, 0.0, 0.0, 120.0, 134.0, 0.0, 0.0, 11.0, 0.0, 53.0, 51.0, 0.0, 27.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 111.0, 7.0, 169.0, 55.0, 0.0, 2.0, 0.0, 43.0, 0.0, 0.0, 17.0, 38.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3197056559659024, "mean_inference_ms": 3.504556316916299, "mean_action_processing_ms": 0.8766642712291105, "mean_env_wait_ms": 0.7985252505098945, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009445905685424805, "StateBufferConnector_ms": 0.008288145065307617, "ViewRequirementAgentConnector_ms": 0.29691898822784424}, "num_episodes": 27, "episode_return_max": 302.6000000000008, "episode_return_min": -103.50000000000003, "episode_return_mean": 89.26999999999977, "episodes_this_iter": 27}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 213.40623421328405, "num_env_steps_trained_throughput_per_sec": 213.40623421328405, "timesteps_total": 128000, "num_env_steps_sampled_lifetime": 128000, "num_agent_steps_sampled_lifetime": 512000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 17557.318, "restore_workers_time_ms": 0.016, "training_step_time_ms": 17557.247, "sample_time_ms": 4484.501, "learn_time_ms": 13032.685, "learn_throughput": 306.921, "synch_weights_time_ms": 33.353}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "training_iteration": 32, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-01-06", "timestamp": 1723521666, "time_this_iter_s": 18.854924201965332, "time_total_s": 538.4751222133636, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28dbee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 538.4751222133636, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 85.07777777777777, "ram_util_percent": 83.57037037037036}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4025848474136736, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0032980502755553, "policy_loss": -0.0033015640132208032, "vf_loss": 1.0065629390024005, "vf_explained_var": 0.01147020765082546, "kl": 0.011736806326666956, "entropy": 1.2946694188017063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.308270914178519, "cur_kl_coeff": 0.009374999999999998, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.308120477893365, "policy_loss": -0.00042906879088915295, "vf_loss": 3.308522549255815, "vf_explained_var": 0.1746552581509585, "kl": 0.002879485204128958, "entropy": 0.7515668435071511, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 61425.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "env_runners": {"episode_reward_max": 302.6000000000008, "episode_reward_min": -103.50000000000003, "episode_reward_mean": 90.94899999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -302.59999999999917, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": 29.539499999999954, "predator_policy": 15.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [174.09999999999877, 76.70000000000003, 42.500000000000334, 217.09999999999926, -19.899999999999572, -23.099999999999973, -59.40000000000039, 32.30000000000018, -12.800000000000052, 131.79999999999905, 32.30000000000018, 202.39999999999972, 111.19999999999987, 132.6999999999997, 202.89999999999998, -70.00000000000071, 40.0000000000003, 134.29999999999927, -54.60000000000062, 25.200000000000063, 189.6999999999993, 40.0000000000003, -18.599999999999575, 195.19999999999936, -19.90000000000003, 20.199999999999978, 197.49999999999937, 136.69999999999888, 302.6000000000008, 23.500000000000032, 40.0000000000003, 59.80000000000027, 116.29999999999976, 282.00000000000057, 185.89999999999944, 237.09999999999903, 192.0999999999994, 169.59999999999954, 225.3999999999992, 125.59999999999894, 40.0000000000003, 93.8999999999992, 26.20000000000008, 167.59999999999906, 122.89999999999975, 26.80000000000009, 230.4999999999994, 120.99999999999875, 30.100000000000147, 291.10000000000025, 9.200000000000085, -67.40000000000035, 225.29999999999936, 26.80000000000011, -21.599999999999675, 67.60000000000015, 191.0999999999994, 151.799999999999, 69.90000000000005, 235.59999999999945, 192.59999999999937, 121.89999999999864, 111.9999999999992, -64.50000000000016, 155.1999999999989, 16.19999999999999, 261.40000000000066, 27.900000000000112, -74.40000000000012, 10.30000000000006, 129.099999999999, 40.0000000000003, 40.0000000000003, -79.30000000000032, -103.50000000000003, 68.4000000000001, -7.299999999999983, 40.0000000000003, 114.49999999999989, 25.70000000000007, 131.79999999999973, 131.7999999999987, 68.89999999999996, 40.0000000000003, 129.19999999999877, 221.1999999999992, -13.09999999999982, -14.999999999999607, 54.400000000000524, 191.1999999999994, 40.0000000000003, 157.79999999999956, 102.09999999999812, 166.29999999999922, 162.79999999999924, 124.99999999999972, 19.09999999999997, 74.69999999999948, 57.900000000000404, 167.79999999999893], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [138.7999999999996, 35.30000000000026, -1.0000000000000204, 67.7000000000001, 23.600000000000065, 17.899999999999988, 38.00000000000024, 178.1, -124.90000000000072, 20.000000000000014, 20.000000000000014, -213.1000000000004, -198.40000000000055, 20.000000000000014, 20.000000000000014, 5.299999999999965, 20.000000000000014, -80.7999999999999, -36.6999999999999, 141.49999999999963, 5.299999999999965, 20.000000000000014, 152.0, 16.40000000000012, -68.20000000000078, 133.39999999999998, 20.000000000000014, 112.69999999999999, 122.6, 80.29999999999998, 20.000000000000014, -232.00000000000028, 20.000000000000014, 20.000000000000014, 133.99999999999977, -36.69999999999982, -160.60000000000065, 20.000000000000014, -17.79999999999974, 20.000000000000014, 11.599999999999966, 166.09999999999994, 20.000000000000014, 20.000000000000014, -5.199999999999941, -72.40000000000065, 170.0, -17.79999999999974, -240.40000000000043, 78.4999999999994, -17.79999999999974, 20.000000000000014, 1.0999999999999617, 187.4, 20.000000000000014, 109.69999999999956, 200.0, 83.59999999999962, 20.000000000000014, -11.499999999999819, 20.000000000000014, 20.000000000000014, 39.79999999999998, 20.000000000000014, 20.000000000000014, 86.30000000000004, 152.59999999999985, 124.39999999999998, 200.0, -45.09999999999976, 56.00000000000023, 181.09999999999994, 1.0999999999999865, 173.0, 20.000000000000014, 149.60000000000002, 200.0, 25.400000000000098, 20.000000000000014, 92.59999999999957, 20.000000000000014, 20.000000000000014, 38.9000000000001, 20.000000000000014, -2.4999999999999716, 13.699999999999966, -24.399999999999807, 157.99999999999977, -108.1000000000007, 155.0, -5.199999999999934, 20.000000000000014, 24.50000000000003, 200.0, 74.8999999999994, 46.10000000000014, 7.399999999999965, 13.699999999999958, 200.0, 91.09999999999931, -38.799999999999756, 20.000000000000014, 27.20000000000013, -302.59999999999917, 20.30000000000004, 200.0, 20.000000000000014, -5.1999999999999975, 5.299999999999965, -82.9000000000006, 32.60000000000019, 20.000000000000014, 166.1, 20.000000000000014, 123.79999999999967, 20.000000000000014, 41.90000000000018, 20.000000000000014, 82.99999999999943, 143.59999999999997, 157.10000000000002, 24.500000000000096, 101.89999999999938, 20.000000000000014, 20.000000000000014, 91.99999999999967, -145.90000000000018, -13.599999999999833, 20.000000000000014, 135.19999999999962, -257.7999999999988, 20.000000000000014, 132.49999999999957, 128.89999999999955, 7.39999999999997, 9.499999999999964, 13.699999999999964, -192.10000000000053, -19.899999999999757, 3.1999999999999615, -0.9999999999999846, 112.0999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -217.30000000000013, 20.000000000000014, -36.700000000000045, -290.7999999999994, 50.6000000000002, 15.799999999999963, 20.000000000000014, -70.30000000000044, 20.000000000000014, 20.000000000000014, 75.19999999999996, -15.699999999999747, 20.000000000000014, -7.299999999999891, 111.79999999999998, 20.000000000000014, 111.79999999999944, 20.000000000000014, -40.8999999999998, 63.80000000000014, 20.000000000000014, 20.000000000000014, 105.19999999999948, 20.000000000000014, 28.100000000000154, 190.1, -184.6000000000004, 33.50000000000025, -66.10000000000076, 1.0999999999999865, 34.40000000000026, 20.000000000000014, 171.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 97.40000000000003, 25.400000000000098, 49.70000000000024, 52.40000000000023, 9.199999999999973, 145.09999999999982, 174.79999999999984, -64.00000000000072, -34.599999999999774, 116.6, -19.899999999999743, 20.000000000000014, 15.799999999999963, 56.90000000000005, 14.899999999999965, 20.000000000000014, 147.79999999999967, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 10.0, 0.0, 0.0, 1.0, 1.0, 0.0, 69.0, 16.0, 87.0, 83.0, 63.0, 56.0, 7.0, 0.0, 37.0, 11.0, 3.0, 24.0, 7.0, 0.0, 16.0, 18.0, 42.0, 4.0, 0.0, 0.0, 0.0, 0.0, 61.0, 81.0, 0.0, 0.0, 27.0, 10.0, 65.0, 21.0, 18.0, 5.0, 4.0, 8.0, 0.0, 0.0, 3.0, 56.0, 16.0, 27.0, 32.0, 110.0, 18.0, 0.0, 2.0, 7.0, 0.0, 7.0, 0.0, 19.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 4.0, 1.0, 31.0, 0.0, 0.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 17.0, 18.0, 12.0, 3.0, 34.0, 0.0, 15.0, 61.0, 0.0, 12.0, 3.0, 3.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 28.0, 0.0, 142.0, 66.0, 0.0, 5.0, 0.0, 12.0, 49.0, 7.0, 0.0, 15.0, 2.0, 3.0, 0.0, 8.0, 0.0, 8.0, 9.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 94.0, 1.0, 0.0, 0.0, 120.0, 134.0, 0.0, 0.0, 11.0, 0.0, 53.0, 51.0, 0.0, 27.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 111.0, 7.0, 169.0, 55.0, 0.0, 2.0, 0.0, 43.0, 0.0, 0.0, 17.0, 38.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 38.0, 0.0, 0.0, 4.0, 0.0, 0.0, 3.0, 32.0, 106.0, 41.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 13.0, 0.0, 0.0, 0.0, 12.0, 30.0, 22.0, 26.0, 17.0, 0.0, 19.0, 2.0, 0.0, 10.0, 13.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3359049505144958, "mean_inference_ms": 3.545098382790793, "mean_action_processing_ms": 0.855158577246008, "mean_env_wait_ms": 0.8071909735221225, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008983373641967773, "StateBufferConnector_ms": 0.024950623512268066, "ViewRequirementAgentConnector_ms": 0.24639999866485596}, "num_episodes": 18, "episode_return_max": 302.6000000000008, "episode_return_min": -103.50000000000003, "episode_return_mean": 90.94899999999973, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 248.21017498895333, "num_env_steps_trained_throughput_per_sec": 248.21017498895333, "timesteps_total": 132000, "num_env_steps_sampled_lifetime": 132000, "num_agent_steps_sampled_lifetime": 528000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 17438.398, "restore_workers_time_ms": 0.037, "training_step_time_ms": 17438.307, "sample_time_ms": 4728.538, "learn_time_ms": 12673.289, "learn_throughput": 315.624, "synch_weights_time_ms": 30.432}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "training_iteration": 33, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-01-23", "timestamp": 1723521683, "time_this_iter_s": 16.20905613899231, "time_total_s": 554.684178352356, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28eaee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 554.684178352356, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 85.03478260869564, "ram_util_percent": 83.39565217391304}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3471035568171708, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5403635748479733, "policy_loss": -0.003368782959188576, "vf_loss": 0.5436945005338492, "vf_explained_var": 0.009799004641790239, "kl": 0.012114490383317985, "entropy": 1.3096581746030738, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.51671031508102, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.3754894787672334, "policy_loss": -0.002768961887402588, "vf_loss": 3.378194981781894, "vf_explained_var": 0.26699083989890166, "kl": 0.013537085220762787, "entropy": 0.7201092218595838, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 63315.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "env_runners": {"episode_reward_max": 302.6000000000008, "episode_reward_min": -103.50000000000003, "episode_reward_mean": 98.67499999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -302.59999999999917, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": 35.97749999999997, "predator_policy": 13.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-54.60000000000062, 25.200000000000063, 189.6999999999993, 40.0000000000003, -18.599999999999575, 195.19999999999936, -19.90000000000003, 20.199999999999978, 197.49999999999937, 136.69999999999888, 302.6000000000008, 23.500000000000032, 40.0000000000003, 59.80000000000027, 116.29999999999976, 282.00000000000057, 185.89999999999944, 237.09999999999903, 192.0999999999994, 169.59999999999954, 225.3999999999992, 125.59999999999894, 40.0000000000003, 93.8999999999992, 26.20000000000008, 167.59999999999906, 122.89999999999975, 26.80000000000009, 230.4999999999994, 120.99999999999875, 30.100000000000147, 291.10000000000025, 9.200000000000085, -67.40000000000035, 225.29999999999936, 26.80000000000011, -21.599999999999675, 67.60000000000015, 191.0999999999994, 151.799999999999, 69.90000000000005, 235.59999999999945, 192.59999999999937, 121.89999999999864, 111.9999999999992, -64.50000000000016, 155.1999999999989, 16.19999999999999, 261.40000000000066, 27.900000000000112, -74.40000000000012, 10.30000000000006, 129.099999999999, 40.0000000000003, 40.0000000000003, -79.30000000000032, -103.50000000000003, 68.4000000000001, -7.299999999999983, 40.0000000000003, 114.49999999999989, 25.70000000000007, 131.79999999999973, 131.7999999999987, 68.89999999999996, 40.0000000000003, 129.19999999999877, 221.1999999999992, -13.09999999999982, -14.999999999999607, 54.400000000000524, 191.1999999999994, 40.0000000000003, 157.79999999999956, 102.09999999999812, 166.29999999999922, 162.79999999999924, 124.99999999999972, 19.09999999999997, 74.69999999999948, 57.900000000000404, 167.79999999999893, 168.19999999999953, 118.29999999999941, 100.19999999999891, 20.199999999999978, 28.10000000000011, 40.0000000000003, 150.19999999999905, 37.80000000000027, 219.99999999999926, 148.99999999999932, 143.0999999999997, 199.99999999999935, 8.100000000000074, 244.3, 195.99999999999937, 40.0000000000003, 40.0000000000003, 214.19999999999945], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-160.60000000000065, 20.000000000000014, -17.79999999999974, 20.000000000000014, 11.599999999999966, 166.09999999999994, 20.000000000000014, 20.000000000000014, -5.199999999999941, -72.40000000000065, 170.0, -17.79999999999974, -240.40000000000043, 78.4999999999994, -17.79999999999974, 20.000000000000014, 1.0999999999999617, 187.4, 20.000000000000014, 109.69999999999956, 200.0, 83.59999999999962, 20.000000000000014, -11.499999999999819, 20.000000000000014, 20.000000000000014, 39.79999999999998, 20.000000000000014, 20.000000000000014, 86.30000000000004, 152.59999999999985, 124.39999999999998, 200.0, -45.09999999999976, 56.00000000000023, 181.09999999999994, 1.0999999999999865, 173.0, 20.000000000000014, 149.60000000000002, 200.0, 25.400000000000098, 20.000000000000014, 92.59999999999957, 20.000000000000014, 20.000000000000014, 38.9000000000001, 20.000000000000014, -2.4999999999999716, 13.699999999999966, -24.399999999999807, 157.99999999999977, -108.1000000000007, 155.0, -5.199999999999934, 20.000000000000014, 24.50000000000003, 200.0, 74.8999999999994, 46.10000000000014, 7.399999999999965, 13.699999999999958, 200.0, 91.09999999999931, -38.799999999999756, 20.000000000000014, 27.20000000000013, -302.59999999999917, 20.30000000000004, 200.0, 20.000000000000014, -5.1999999999999975, 5.299999999999965, -82.9000000000006, 32.60000000000019, 20.000000000000014, 166.1, 20.000000000000014, 123.79999999999967, 20.000000000000014, 41.90000000000018, 20.000000000000014, 82.99999999999943, 143.59999999999997, 157.10000000000002, 24.500000000000096, 101.89999999999938, 20.000000000000014, 20.000000000000014, 91.99999999999967, -145.90000000000018, -13.599999999999833, 20.000000000000014, 135.19999999999962, -257.7999999999988, 20.000000000000014, 132.49999999999957, 128.89999999999955, 7.39999999999997, 9.499999999999964, 13.699999999999964, -192.10000000000053, -19.899999999999757, 3.1999999999999615, -0.9999999999999846, 112.0999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -217.30000000000013, 20.000000000000014, -36.700000000000045, -290.7999999999994, 50.6000000000002, 15.799999999999963, 20.000000000000014, -70.30000000000044, 20.000000000000014, 20.000000000000014, 75.19999999999996, -15.699999999999747, 20.000000000000014, -7.299999999999891, 111.79999999999998, 20.000000000000014, 111.79999999999944, 20.000000000000014, -40.8999999999998, 63.80000000000014, 20.000000000000014, 20.000000000000014, 105.19999999999948, 20.000000000000014, 28.100000000000154, 190.1, -184.6000000000004, 33.50000000000025, -66.10000000000076, 1.0999999999999865, 34.40000000000026, 20.000000000000014, 171.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 97.40000000000003, 25.400000000000098, 49.70000000000024, 52.40000000000023, 9.199999999999973, 145.09999999999982, 174.79999999999984, -64.00000000000072, -34.599999999999774, 116.6, -19.899999999999743, 20.000000000000014, 15.799999999999963, 56.90000000000005, 14.899999999999965, 20.000000000000014, 147.79999999999967, 20.000000000000014, 17.899999999999988, 134.3, 45.50000000000007, 42.80000000000017, 74.29999999999947, 11.899999999999974, 20.000000000000014, -17.79999999999974, -10.899999999999856, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999855, 143.59999999999968, 20.000000000000014, 15.799999999999963, 200.0, 20.000000000000014, 85.39999999999985, 59.600000000000115, 20.000000000000014, 94.10000000000002, 20.000000000000014, 170.0, 20.000000000000014, -40.89999999999977, 109.09999999999998, 135.2, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.200000000000003, 170.0], "policy_predator_policy_reward": [65.0, 21.0, 18.0, 5.0, 4.0, 8.0, 0.0, 0.0, 3.0, 56.0, 16.0, 27.0, 32.0, 110.0, 18.0, 0.0, 2.0, 7.0, 0.0, 7.0, 0.0, 19.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 4.0, 1.0, 31.0, 0.0, 0.0, 0.0, 9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 17.0, 18.0, 12.0, 3.0, 34.0, 0.0, 15.0, 61.0, 0.0, 12.0, 3.0, 3.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 28.0, 0.0, 142.0, 66.0, 0.0, 5.0, 0.0, 12.0, 49.0, 7.0, 0.0, 15.0, 2.0, 3.0, 0.0, 8.0, 0.0, 8.0, 9.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 94.0, 1.0, 0.0, 0.0, 120.0, 134.0, 0.0, 0.0, 11.0, 0.0, 53.0, 51.0, 0.0, 27.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 111.0, 7.0, 169.0, 55.0, 0.0, 2.0, 0.0, 43.0, 0.0, 0.0, 17.0, 38.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 38.0, 0.0, 0.0, 4.0, 0.0, 0.0, 3.0, 32.0, 106.0, 41.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 13.0, 0.0, 0.0, 0.0, 12.0, 30.0, 22.0, 26.0, 17.0, 0.0, 19.0, 2.0, 0.0, 10.0, 13.0, 0.0, 0.0, 16.0, 0.0, 30.0, 0.0, 14.0, 0.0, 18.0, 0.0, 19.0, 0.0, 0.0, 0.0, 14.0, 2.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 19.0, 10.0, 10.0, 0.0, 27.0, 2.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3435595807689822, "mean_inference_ms": 3.5687770041560447, "mean_action_processing_ms": 0.8491532922323094, "mean_env_wait_ms": 0.8127469829151553, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0056612491607666016, "StateBufferConnector_ms": 0.022334575653076172, "ViewRequirementAgentConnector_ms": 0.24546968936920166}, "num_episodes": 18, "episode_return_max": 302.6000000000008, "episode_return_min": -103.50000000000003, "episode_return_mean": 98.67499999999973, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 221.9715447442209, "num_env_steps_trained_throughput_per_sec": 221.9715447442209, "timesteps_total": 136000, "num_env_steps_sampled_lifetime": 136000, "num_agent_steps_sampled_lifetime": 544000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 17344.536, "restore_workers_time_ms": 0.038, "training_step_time_ms": 17344.454, "sample_time_ms": 4944.569, "learn_time_ms": 12363.414, "learn_throughput": 323.535, "synch_weights_time_ms": 30.287}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "training_iteration": 34, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-01-41", "timestamp": 1723521701, "time_this_iter_s": 18.091866970062256, "time_total_s": 572.7760453224182, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29011f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 572.7760453224182, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 83.744, "ram_util_percent": 83.712}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3814007518546922, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.580463176650345, "policy_loss": -0.004325285134960223, "vf_loss": 0.5847573889981187, "vf_explained_var": 0.013570661771865118, "kl": 0.009943269934074636, "entropy": 1.3771616765430996, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8911233073898723, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.1570416186221695, "policy_loss": -0.0007050422229680907, "vf_loss": 3.1577304565086566, "vf_explained_var": 0.2785629653741443, "kl": 0.0034563055514710166, "entropy": 0.724746444647905, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 65205.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "env_runners": {"episode_reward_max": 291.10000000000025, "episode_reward_min": -103.50000000000003, "episode_reward_mean": 92.10199999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -302.59999999999917, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": 33.39599999999997, "predator_policy": 12.655}, "custom_metrics": {}, "hist_stats": {"episode_reward": [192.0999999999994, 169.59999999999954, 225.3999999999992, 125.59999999999894, 40.0000000000003, 93.8999999999992, 26.20000000000008, 167.59999999999906, 122.89999999999975, 26.80000000000009, 230.4999999999994, 120.99999999999875, 30.100000000000147, 291.10000000000025, 9.200000000000085, -67.40000000000035, 225.29999999999936, 26.80000000000011, -21.599999999999675, 67.60000000000015, 191.0999999999994, 151.799999999999, 69.90000000000005, 235.59999999999945, 192.59999999999937, 121.89999999999864, 111.9999999999992, -64.50000000000016, 155.1999999999989, 16.19999999999999, 261.40000000000066, 27.900000000000112, -74.40000000000012, 10.30000000000006, 129.099999999999, 40.0000000000003, 40.0000000000003, -79.30000000000032, -103.50000000000003, 68.4000000000001, -7.299999999999983, 40.0000000000003, 114.49999999999989, 25.70000000000007, 131.79999999999973, 131.7999999999987, 68.89999999999996, 40.0000000000003, 129.19999999999877, 221.1999999999992, -13.09999999999982, -14.999999999999607, 54.400000000000524, 191.1999999999994, 40.0000000000003, 157.79999999999956, 102.09999999999812, 166.29999999999922, 162.79999999999924, 124.99999999999972, 19.09999999999997, 74.69999999999948, 57.900000000000404, 167.79999999999893, 168.19999999999953, 118.29999999999941, 100.19999999999891, 20.199999999999978, 28.10000000000011, 40.0000000000003, 150.19999999999905, 37.80000000000027, 219.99999999999926, 148.99999999999932, 143.0999999999997, 199.99999999999935, 8.100000000000074, 244.3, 195.99999999999937, 40.0000000000003, 40.0000000000003, 214.19999999999945, 36.10000000000024, 29.80000000000012, 23.500000000000036, 174.09999999999945, 40.0000000000003, 47.2000000000004, 32.30000000000019, 24.60000000000005, 167.7999999999995, 261.7999999999996, 19.099999999999955, 50.80000000000048, 139.79999999999976, 21.300000000000058, 55.50000000000047, 17.99999999999992, 119.59999999999977, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [1.0999999999999865, 173.0, 20.000000000000014, 149.60000000000002, 200.0, 25.400000000000098, 20.000000000000014, 92.59999999999957, 20.000000000000014, 20.000000000000014, 38.9000000000001, 20.000000000000014, -2.4999999999999716, 13.699999999999966, -24.399999999999807, 157.99999999999977, -108.1000000000007, 155.0, -5.199999999999934, 20.000000000000014, 24.50000000000003, 200.0, 74.8999999999994, 46.10000000000014, 7.399999999999965, 13.699999999999958, 200.0, 91.09999999999931, -38.799999999999756, 20.000000000000014, 27.20000000000013, -302.59999999999917, 20.30000000000004, 200.0, 20.000000000000014, -5.1999999999999975, 5.299999999999965, -82.9000000000006, 32.60000000000019, 20.000000000000014, 166.1, 20.000000000000014, 123.79999999999967, 20.000000000000014, 41.90000000000018, 20.000000000000014, 82.99999999999943, 143.59999999999997, 157.10000000000002, 24.500000000000096, 101.89999999999938, 20.000000000000014, 20.000000000000014, 91.99999999999967, -145.90000000000018, -13.599999999999833, 20.000000000000014, 135.19999999999962, -257.7999999999988, 20.000000000000014, 132.49999999999957, 128.89999999999955, 7.39999999999997, 9.499999999999964, 13.699999999999964, -192.10000000000053, -19.899999999999757, 3.1999999999999615, -0.9999999999999846, 112.0999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -217.30000000000013, 20.000000000000014, -36.700000000000045, -290.7999999999994, 50.6000000000002, 15.799999999999963, 20.000000000000014, -70.30000000000044, 20.000000000000014, 20.000000000000014, 75.19999999999996, -15.699999999999747, 20.000000000000014, -7.299999999999891, 111.79999999999998, 20.000000000000014, 111.79999999999944, 20.000000000000014, -40.8999999999998, 63.80000000000014, 20.000000000000014, 20.000000000000014, 105.19999999999948, 20.000000000000014, 28.100000000000154, 190.1, -184.6000000000004, 33.50000000000025, -66.10000000000076, 1.0999999999999865, 34.40000000000026, 20.000000000000014, 171.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 97.40000000000003, 25.400000000000098, 49.70000000000024, 52.40000000000023, 9.199999999999973, 145.09999999999982, 174.79999999999984, -64.00000000000072, -34.599999999999774, 116.6, -19.899999999999743, 20.000000000000014, 15.799999999999963, 56.90000000000005, 14.899999999999965, 20.000000000000014, 147.79999999999967, 20.000000000000014, 17.899999999999988, 134.3, 45.50000000000007, 42.80000000000017, 74.29999999999947, 11.899999999999974, 20.000000000000014, -17.79999999999974, -10.899999999999856, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999855, 143.59999999999968, 20.000000000000014, 15.799999999999963, 200.0, 20.000000000000014, 85.39999999999985, 59.600000000000115, 20.000000000000014, 94.10000000000002, 20.000000000000014, 170.0, 20.000000000000014, -40.89999999999977, 109.09999999999998, 135.2, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.200000000000003, 170.0, 20.000000000000014, 1.099999999999983, 5.299999999999965, 9.499999999999961, -11.499999999999826, 20.000000000000014, 154.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 37.10000000000021, 20.000000000000014, 5.299999999999965, -9.399999999999855, 20.000000000000014, 20.000000000000014, 135.79999999999998, 81.79999999999944, 140.0, -7.299999999999891, 7.399999999999974, 30.800000000000196, 20.000000000000014, 56.00000000000023, 51.80000000000004, -74.50000000000085, 48.80000000000013, 21.50000000000004, 20.000000000000014, 20.000000000000014, -21.999999999999915, 155.0, -114.40000000000055, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [9.0, 9.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 0.0, 0.0, 17.0, 18.0, 12.0, 3.0, 34.0, 0.0, 15.0, 61.0, 0.0, 12.0, 3.0, 3.0, 0.0, 0.0, 6.0, 3.0, 0.0, 0.0, 28.0, 0.0, 142.0, 66.0, 0.0, 5.0, 0.0, 12.0, 49.0, 7.0, 0.0, 15.0, 2.0, 3.0, 0.0, 8.0, 0.0, 8.0, 9.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 94.0, 1.0, 0.0, 0.0, 120.0, 134.0, 0.0, 0.0, 11.0, 0.0, 53.0, 51.0, 0.0, 27.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 111.0, 7.0, 169.0, 55.0, 0.0, 2.0, 0.0, 43.0, 0.0, 0.0, 17.0, 38.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 38.0, 0.0, 0.0, 4.0, 0.0, 0.0, 3.0, 32.0, 106.0, 41.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 13.0, 0.0, 0.0, 0.0, 12.0, 30.0, 22.0, 26.0, 17.0, 0.0, 19.0, 2.0, 0.0, 10.0, 13.0, 0.0, 0.0, 16.0, 0.0, 30.0, 0.0, 14.0, 0.0, 18.0, 0.0, 19.0, 0.0, 0.0, 0.0, 14.0, 2.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 19.0, 10.0, 10.0, 0.0, 27.0, 2.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 7.0, 8.0, 8.0, 7.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 7.0, 0.0, 0.0, 14.0, 7.0, 5.0, 18.0, 22.0, 6.0, 13.0, 0.0, 0.0, 32.0, 0.0, 45.0, 2.0, 9.0, 5.0, 17.0, 3.0, 64.0, 15.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.351839763028368, "mean_inference_ms": 3.5955660621111316, "mean_action_processing_ms": 0.84420029738376, "mean_env_wait_ms": 0.8191336925229262, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005508899688720703, "StateBufferConnector_ms": 0.020794034004211426, "ViewRequirementAgentConnector_ms": 0.2657963037490845}, "num_episodes": 18, "episode_return_max": 291.10000000000025, "episode_return_min": -103.50000000000003, "episode_return_mean": 92.10199999999973, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 253.02100735027346, "num_env_steps_trained_throughput_per_sec": 253.02100735027346, "timesteps_total": 140000, "num_env_steps_sampled_lifetime": 140000, "num_agent_steps_sampled_lifetime": 560000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 17356.49, "restore_workers_time_ms": 0.038, "training_step_time_ms": 17356.412, "sample_time_ms": 4893.033, "learn_time_ms": 12427.038, "learn_throughput": 321.879, "synch_weights_time_ms": 30.27}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "training_iteration": 35, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-01-57", "timestamp": 1723521717, "time_this_iter_s": 15.847701072692871, "time_total_s": 588.6237463951111, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b29018b0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 588.6237463951111, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 83.62173913043479, "ram_util_percent": 83.73913043478261}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3371291553926846, "cur_kl_coeff": 0.003125, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3377080099686744, "policy_loss": -0.004313628853756994, "vf_loss": 0.3419494262149942, "vf_explained_var": 0.017120135082769647, "kl": 0.0231081230763708, "entropy": 1.2714619229710291, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8261762035941635, "cur_kl_coeff": 0.0023437499999999995, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.533613867103738, "policy_loss": -0.0005963561637573457, "vf_loss": 3.5341993661153883, "vf_explained_var": 0.25378645106598186, "kl": 0.004634775576535883, "entropy": 0.5881507110658777, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 67095.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "env_runners": {"episode_reward_max": 261.7999999999996, "episode_reward_min": -103.50000000000003, "episode_reward_mean": 95.62999999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -290.7999999999994, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": 37.05499999999998, "predator_policy": 10.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [69.90000000000005, 235.59999999999945, 192.59999999999937, 121.89999999999864, 111.9999999999992, -64.50000000000016, 155.1999999999989, 16.19999999999999, 261.40000000000066, 27.900000000000112, -74.40000000000012, 10.30000000000006, 129.099999999999, 40.0000000000003, 40.0000000000003, -79.30000000000032, -103.50000000000003, 68.4000000000001, -7.299999999999983, 40.0000000000003, 114.49999999999989, 25.70000000000007, 131.79999999999973, 131.7999999999987, 68.89999999999996, 40.0000000000003, 129.19999999999877, 221.1999999999992, -13.09999999999982, -14.999999999999607, 54.400000000000524, 191.1999999999994, 40.0000000000003, 157.79999999999956, 102.09999999999812, 166.29999999999922, 162.79999999999924, 124.99999999999972, 19.09999999999997, 74.69999999999948, 57.900000000000404, 167.79999999999893, 168.19999999999953, 118.29999999999941, 100.19999999999891, 20.199999999999978, 28.10000000000011, 40.0000000000003, 150.19999999999905, 37.80000000000027, 219.99999999999926, 148.99999999999932, 143.0999999999997, 199.99999999999935, 8.100000000000074, 244.3, 195.99999999999937, 40.0000000000003, 40.0000000000003, 214.19999999999945, 36.10000000000024, 29.80000000000012, 23.500000000000036, 174.09999999999945, 40.0000000000003, 47.2000000000004, 32.30000000000019, 24.60000000000005, 167.7999999999995, 261.7999999999996, 19.099999999999955, 50.80000000000048, 139.79999999999976, 21.300000000000058, 55.50000000000047, 17.99999999999992, 119.59999999999977, 40.0000000000003, 219.99999999999926, 169.5999999999995, 40.0000000000003, 40.0000000000003, 15.799999999999969, 52.80000000000041, 217.79999999999927, 48.10000000000043, 40.0000000000003, 40.0000000000003, 204.49999999999935, 201.69999999999936, 140.49999999999963, 164.69999999999897, 47.200000000000415, 211.9999999999993, 207.39999999999932, 199.99999999999935, 185.39999999999944, 189.3999999999994, 131.39999999999938, 30.100000000000154], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [41.90000000000018, 20.000000000000014, 82.99999999999943, 143.59999999999997, 157.10000000000002, 24.500000000000096, 101.89999999999938, 20.000000000000014, 20.000000000000014, 91.99999999999967, -145.90000000000018, -13.599999999999833, 20.000000000000014, 135.19999999999962, -257.7999999999988, 20.000000000000014, 132.49999999999957, 128.89999999999955, 7.39999999999997, 9.499999999999964, 13.699999999999964, -192.10000000000053, -19.899999999999757, 3.1999999999999615, -0.9999999999999846, 112.0999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -217.30000000000013, 20.000000000000014, -36.700000000000045, -290.7999999999994, 50.6000000000002, 15.799999999999963, 20.000000000000014, -70.30000000000044, 20.000000000000014, 20.000000000000014, 75.19999999999996, -15.699999999999747, 20.000000000000014, -7.299999999999891, 111.79999999999998, 20.000000000000014, 111.79999999999944, 20.000000000000014, -40.8999999999998, 63.80000000000014, 20.000000000000014, 20.000000000000014, 105.19999999999948, 20.000000000000014, 28.100000000000154, 190.1, -184.6000000000004, 33.50000000000025, -66.10000000000076, 1.0999999999999865, 34.40000000000026, 20.000000000000014, 171.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 97.40000000000003, 25.400000000000098, 49.70000000000024, 52.40000000000023, 9.199999999999973, 145.09999999999982, 174.79999999999984, -64.00000000000072, -34.599999999999774, 116.6, -19.899999999999743, 20.000000000000014, 15.799999999999963, 56.90000000000005, 14.899999999999965, 20.000000000000014, 147.79999999999967, 20.000000000000014, 17.899999999999988, 134.3, 45.50000000000007, 42.80000000000017, 74.29999999999947, 11.899999999999974, 20.000000000000014, -17.79999999999974, -10.899999999999856, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999855, 143.59999999999968, 20.000000000000014, 15.799999999999963, 200.0, 20.000000000000014, 85.39999999999985, 59.600000000000115, 20.000000000000014, 94.10000000000002, 20.000000000000014, 170.0, 20.000000000000014, -40.89999999999977, 109.09999999999998, 135.2, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.200000000000003, 170.0, 20.000000000000014, 1.099999999999983, 5.299999999999965, 9.499999999999961, -11.499999999999826, 20.000000000000014, 154.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 37.10000000000021, 20.000000000000014, 5.299999999999965, -9.399999999999855, 20.000000000000014, 20.000000000000014, 135.79999999999998, 81.79999999999944, 140.0, -7.299999999999891, 7.399999999999974, 30.800000000000196, 20.000000000000014, 56.00000000000023, 51.80000000000004, -74.50000000000085, 48.80000000000013, 21.50000000000004, 20.000000000000014, 20.000000000000014, -21.999999999999915, 155.0, -114.40000000000055, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 133.7, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, 15.799999999999967, 20.000000000000014, 6.7999999999999705, 200.0, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 170.0, -7.299999999999891, 194.0, 105.50000000000006, 20.000000000000014, 121.09999999999954, 41.59999999999998, 27.20000000000013, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 187.4, 20.000000000000014, 170.0, 170.3, 1.0999999999999652, 20.000000000000014, 169.4, 90.19999999999976, 21.20000000000004, 20.000000000000014, 1.0999999999999723], "policy_predator_policy_reward": [0.0, 8.0, 9.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 94.0, 1.0, 0.0, 0.0, 120.0, 134.0, 0.0, 0.0, 11.0, 0.0, 53.0, 51.0, 0.0, 27.0, 10.0, 8.0, 0.0, 0.0, 0.0, 0.0, 111.0, 7.0, 169.0, 55.0, 0.0, 2.0, 0.0, 43.0, 0.0, 0.0, 17.0, 38.0, 13.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 38.0, 0.0, 0.0, 4.0, 0.0, 0.0, 3.0, 32.0, 106.0, 41.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 13.0, 0.0, 0.0, 0.0, 12.0, 30.0, 22.0, 26.0, 17.0, 0.0, 19.0, 2.0, 0.0, 10.0, 13.0, 0.0, 0.0, 16.0, 0.0, 30.0, 0.0, 14.0, 0.0, 18.0, 0.0, 19.0, 0.0, 0.0, 0.0, 14.0, 2.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 19.0, 10.0, 10.0, 0.0, 27.0, 2.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 7.0, 8.0, 8.0, 7.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 7.0, 0.0, 0.0, 14.0, 7.0, 5.0, 18.0, 22.0, 6.0, 13.0, 0.0, 0.0, 32.0, 0.0, 45.0, 2.0, 9.0, 5.0, 17.0, 3.0, 64.0, 15.0, 0.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 17.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 2.0, 13.0, 15.0, 0.0, 2.0, 0.0, 0.0, 0.0, 7.0, 6.0, 0.0, 0.0, 10.0, 0.0, 9.0, 5.0, 0.0, 0.0, 14.0, 6.0, 0.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.358217067687756, "mean_inference_ms": 3.623594468483264, "mean_action_processing_ms": 0.8367507001526983, "mean_env_wait_ms": 0.8247749625758578, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055692195892333984, "StateBufferConnector_ms": 0.020825862884521484, "ViewRequirementAgentConnector_ms": 0.2574115991592407}, "num_episodes": 22, "episode_return_max": 261.7999999999996, "episode_return_min": -103.50000000000003, "episode_return_mean": 95.62999999999978, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.0190929890119, "num_env_steps_trained_throughput_per_sec": 199.0190929890119, "timesteps_total": 144000, "num_env_steps_sampled_lifetime": 144000, "num_agent_steps_sampled_lifetime": 576000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 576000, "timers": {"training_iteration_time_ms": 18024.398, "restore_workers_time_ms": 0.038, "training_step_time_ms": 18024.319, "sample_time_ms": 4956.724, "learn_time_ms": 13031.475, "learn_throughput": 306.949, "synch_weights_time_ms": 30.034}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 576000, "num_agent_steps_trained": 576000}, "done": false, "training_iteration": 36, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-02-17", "timestamp": 1723521737, "time_this_iter_s": 20.189121961593628, "time_total_s": 608.8128683567047, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4cfd430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 608.8128683567047, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 86.46785714285714, "ram_util_percent": 83.59642857142856}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4104853139056888, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.575743838521854, "policy_loss": -0.0013212401949598519, "vf_loss": 0.5770213994912055, "vf_explained_var": 0.01116819630854975, "kl": 0.009318271322288891, "entropy": 1.1901359863382168, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5126908516126967, "cur_kl_coeff": 0.0011718749999999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7356765585601646, "policy_loss": 0.0004364893546268817, "vf_loss": 3.73523919822047, "vf_explained_var": 0.19454953408745862, "kl": 0.000740306904037842, "entropy": 0.600421299947002, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 68985.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "env_runners": {"episode_reward_max": 382.9, "episode_reward_min": -25.700000000000024, "episode_reward_mean": 111.89299999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -184.6000000000004, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 106.0}, "policy_reward_mean": {"prey_policy": 48.861499999999985, "predator_policy": 7.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.7999999999987, 68.89999999999996, 40.0000000000003, 129.19999999999877, 221.1999999999992, -13.09999999999982, -14.999999999999607, 54.400000000000524, 191.1999999999994, 40.0000000000003, 157.79999999999956, 102.09999999999812, 166.29999999999922, 162.79999999999924, 124.99999999999972, 19.09999999999997, 74.69999999999948, 57.900000000000404, 167.79999999999893, 168.19999999999953, 118.29999999999941, 100.19999999999891, 20.199999999999978, 28.10000000000011, 40.0000000000003, 150.19999999999905, 37.80000000000027, 219.99999999999926, 148.99999999999932, 143.0999999999997, 199.99999999999935, 8.100000000000074, 244.3, 195.99999999999937, 40.0000000000003, 40.0000000000003, 214.19999999999945, 36.10000000000024, 29.80000000000012, 23.500000000000036, 174.09999999999945, 40.0000000000003, 47.2000000000004, 32.30000000000019, 24.60000000000005, 167.7999999999995, 261.7999999999996, 19.099999999999955, 50.80000000000048, 139.79999999999976, 21.300000000000058, 55.50000000000047, 17.99999999999992, 119.59999999999977, 40.0000000000003, 219.99999999999926, 169.5999999999995, 40.0000000000003, 40.0000000000003, 15.799999999999969, 52.80000000000041, 217.79999999999927, 48.10000000000043, 40.0000000000003, 40.0000000000003, 204.49999999999935, 201.69999999999936, 140.49999999999963, 164.69999999999897, 47.200000000000415, 211.9999999999993, 207.39999999999932, 199.99999999999935, 185.39999999999944, 189.3999999999994, 131.39999999999938, 30.100000000000154, 40.0000000000003, 183.69999999999945, 70.79999999999998, -25.700000000000024, 219.99999999999926, 219.99999999999926, 382.9, 61.2000000000005, 90.8999999999992, 74.69999999999972, 38.90000000000028, 349.5, 209.9999999999993, -7.299999999999713, 101.19999999999837, 190.89999999999938, 56.200000000000514, 40.0000000000003, 219.99999999999926, 217.99999999999926, 208.99999999999932, 40.0000000000003, 104.90000000000012], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [111.79999999999944, 20.000000000000014, -40.8999999999998, 63.80000000000014, 20.000000000000014, 20.000000000000014, 105.19999999999948, 20.000000000000014, 28.100000000000154, 190.1, -184.6000000000004, 33.50000000000025, -66.10000000000076, 1.0999999999999865, 34.40000000000026, 20.000000000000014, 171.2, 20.000000000000014, 20.000000000000014, 20.000000000000014, 97.40000000000003, 25.400000000000098, 49.70000000000024, 52.40000000000023, 9.199999999999973, 145.09999999999982, 174.79999999999984, -64.00000000000072, -34.599999999999774, 116.6, -19.899999999999743, 20.000000000000014, 15.799999999999963, 56.90000000000005, 14.899999999999965, 20.000000000000014, 147.79999999999967, 20.000000000000014, 17.899999999999988, 134.3, 45.50000000000007, 42.80000000000017, 74.29999999999947, 11.899999999999974, 20.000000000000014, -17.79999999999974, -10.899999999999856, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999855, 143.59999999999968, 20.000000000000014, 15.799999999999963, 200.0, 20.000000000000014, 85.39999999999985, 59.600000000000115, 20.000000000000014, 94.10000000000002, 20.000000000000014, 170.0, 20.000000000000014, -40.89999999999977, 109.09999999999998, 135.2, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.200000000000003, 170.0, 20.000000000000014, 1.099999999999983, 5.299999999999965, 9.499999999999961, -11.499999999999826, 20.000000000000014, 154.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 37.10000000000021, 20.000000000000014, 5.299999999999965, -9.399999999999855, 20.000000000000014, 20.000000000000014, 135.79999999999998, 81.79999999999944, 140.0, -7.299999999999891, 7.399999999999974, 30.800000000000196, 20.000000000000014, 56.00000000000023, 51.80000000000004, -74.50000000000085, 48.80000000000013, 21.50000000000004, 20.000000000000014, 20.000000000000014, -21.999999999999915, 155.0, -114.40000000000055, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 133.7, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, 15.799999999999967, 20.000000000000014, 6.7999999999999705, 200.0, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 170.0, -7.299999999999891, 194.0, 105.50000000000006, 20.000000000000014, 121.09999999999954, 41.59999999999998, 27.20000000000013, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 187.4, 20.000000000000014, 170.0, 170.3, 1.0999999999999652, 20.000000000000014, 169.4, 90.19999999999976, 21.20000000000004, 20.000000000000014, 1.0999999999999723, 20.000000000000014, 20.000000000000014, -7.299999999999894, 167.0, 20.000000000000014, 42.80000000000021, 17.899999999999988, -124.60000000000048, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 182.9, 200.0, 20.000000000000014, 39.200000000000244, 41.9000000000001, 20.000000000000014, 56.900000000000226, 15.799999999999963, 17.899999999999988, 20.000000000000014, 135.5, 200.0, 185.0, 20.000000000000014, 20.000000000000014, -70.30000000000084, 29.00000000000017, 72.19999999999962, 158.0, 17.899999999999988, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 197.0, 20.000000000000014, -0.9999999999999846, 200.0, 20.000000000000014, 20.000000000000014, 29.900000000000198, 53.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 8.0, 38.0, 0.0, 0.0, 4.0, 0.0, 0.0, 3.0, 32.0, 106.0, 41.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 22.0, 13.0, 0.0, 0.0, 0.0, 12.0, 30.0, 22.0, 26.0, 17.0, 0.0, 19.0, 2.0, 0.0, 10.0, 13.0, 0.0, 0.0, 16.0, 0.0, 30.0, 0.0, 14.0, 0.0, 18.0, 0.0, 19.0, 0.0, 0.0, 0.0, 14.0, 2.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 19.0, 10.0, 10.0, 0.0, 27.0, 2.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 7.0, 8.0, 8.0, 7.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 7.0, 0.0, 0.0, 14.0, 7.0, 5.0, 18.0, 22.0, 6.0, 13.0, 0.0, 0.0, 32.0, 0.0, 45.0, 2.0, 9.0, 5.0, 17.0, 3.0, 64.0, 15.0, 0.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 17.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 2.0, 13.0, 15.0, 0.0, 2.0, 0.0, 0.0, 0.0, 7.0, 6.0, 0.0, 0.0, 10.0, 0.0, 9.0, 5.0, 0.0, 0.0, 14.0, 6.0, 0.0, 9.0, 0.0, 0.0, 21.0, 3.0, 0.0, 8.0, 35.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 29.0, 0.0, 2.0, 0.0, 1.0, 14.0, 0.0, 0.0, 5.0, 0.0, 43.0, 0.0, 0.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 15.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3778692156532673, "mean_inference_ms": 3.686622462384126, "mean_action_processing_ms": 0.836003530718622, "mean_env_wait_ms": 0.8386801896219374, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0053588151931762695, "StateBufferConnector_ms": 0.02238774299621582, "ViewRequirementAgentConnector_ms": 0.30897343158721924}, "num_episodes": 23, "episode_return_max": 382.9, "episode_return_min": -25.700000000000024, "episode_return_mean": 111.89299999999977, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 228.7099470505869, "num_env_steps_trained_throughput_per_sec": 228.7099470505869, "timesteps_total": 148000, "num_env_steps_sampled_lifetime": 148000, "num_agent_steps_sampled_lifetime": 592000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 592000, "timers": {"training_iteration_time_ms": 17994.991, "restore_workers_time_ms": 0.038, "training_step_time_ms": 17994.912, "sample_time_ms": 5126.436, "learn_time_ms": 12836.587, "learn_throughput": 311.609, "synch_weights_time_ms": 25.959}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 592000, "num_agent_steps_trained": 592000}, "done": false, "training_iteration": 37, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-02-35", "timestamp": 1723521755, "time_this_iter_s": 17.56197190284729, "time_total_s": 626.374840259552, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2901ca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 626.374840259552, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 79.79599999999999, "ram_util_percent": 83.35600000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4385990781679986, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.47704371176068744, "policy_loss": -0.002018542935647977, "vf_loss": 0.4790053616061058, "vf_explained_var": 0.010300989977266422, "kl": 0.012137411893634622, "entropy": 1.2710678508672764, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3505364300830969, "cur_kl_coeff": 0.0005859374999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.244170223278974, "policy_loss": -0.001773057946141947, "vf_loss": 3.245939219880987, "vf_explained_var": 0.19560693672725132, "kl": 0.006939987392224133, "entropy": 0.5333108694780441, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 70875.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "env_runners": {"episode_reward_max": 382.9, "episode_reward_min": -25.700000000000024, "episode_reward_mean": 114.78199999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -124.60000000000048, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 64.0}, "policy_reward_mean": {"prey_policy": 51.58099999999999, "predator_policy": 5.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [167.79999999999893, 168.19999999999953, 118.29999999999941, 100.19999999999891, 20.199999999999978, 28.10000000000011, 40.0000000000003, 150.19999999999905, 37.80000000000027, 219.99999999999926, 148.99999999999932, 143.0999999999997, 199.99999999999935, 8.100000000000074, 244.3, 195.99999999999937, 40.0000000000003, 40.0000000000003, 214.19999999999945, 36.10000000000024, 29.80000000000012, 23.500000000000036, 174.09999999999945, 40.0000000000003, 47.2000000000004, 32.30000000000019, 24.60000000000005, 167.7999999999995, 261.7999999999996, 19.099999999999955, 50.80000000000048, 139.79999999999976, 21.300000000000058, 55.50000000000047, 17.99999999999992, 119.59999999999977, 40.0000000000003, 219.99999999999926, 169.5999999999995, 40.0000000000003, 40.0000000000003, 15.799999999999969, 52.80000000000041, 217.79999999999927, 48.10000000000043, 40.0000000000003, 40.0000000000003, 204.49999999999935, 201.69999999999936, 140.49999999999963, 164.69999999999897, 47.200000000000415, 211.9999999999993, 207.39999999999932, 199.99999999999935, 185.39999999999944, 189.3999999999994, 131.39999999999938, 30.100000000000154, 40.0000000000003, 183.69999999999945, 70.79999999999998, -25.700000000000024, 219.99999999999926, 219.99999999999926, 382.9, 61.2000000000005, 90.8999999999992, 74.69999999999972, 38.90000000000028, 349.5, 209.9999999999993, -7.299999999999713, 101.19999999999837, 190.89999999999938, 56.200000000000514, 40.0000000000003, 219.99999999999926, 217.99999999999926, 208.99999999999932, 40.0000000000003, 104.90000000000012, 37.80000000000027, 36.70000000000025, 168.6999999999991, 40.0000000000003, 52.90000000000031, 187.49999999999912, 52.50000000000036, 219.99999999999926, 192.5999999999991, 123.69999999999979, 139.3999999999997, 189.19999999999942, 195.6999999999994, 180.89999999999904, 62.00000000000048, 43.60000000000035, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [147.79999999999967, 20.000000000000014, 17.899999999999988, 134.3, 45.50000000000007, 42.80000000000017, 74.29999999999947, 11.899999999999974, 20.000000000000014, -17.79999999999974, -10.899999999999856, 20.000000000000014, 20.000000000000014, 20.000000000000014, -9.399999999999855, 143.59999999999968, 20.000000000000014, 15.799999999999963, 200.0, 20.000000000000014, 85.39999999999985, 59.600000000000115, 20.000000000000014, 94.10000000000002, 20.000000000000014, 170.0, 20.000000000000014, -40.89999999999977, 109.09999999999998, 135.2, 164.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.200000000000003, 170.0, 20.000000000000014, 1.099999999999983, 5.299999999999965, 9.499999999999961, -11.499999999999826, 20.000000000000014, 154.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 37.10000000000021, 20.000000000000014, 5.299999999999965, -9.399999999999855, 20.000000000000014, 20.000000000000014, 135.79999999999998, 81.79999999999944, 140.0, -7.299999999999891, 7.399999999999974, 30.800000000000196, 20.000000000000014, 56.00000000000023, 51.80000000000004, -74.50000000000085, 48.80000000000013, 21.50000000000004, 20.000000000000014, 20.000000000000014, -21.999999999999915, 155.0, -114.40000000000055, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 133.7, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, 15.799999999999967, 20.000000000000014, 6.7999999999999705, 200.0, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 170.0, -7.299999999999891, 194.0, 105.50000000000006, 20.000000000000014, 121.09999999999954, 41.59999999999998, 27.20000000000013, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 187.4, 20.000000000000014, 170.0, 170.3, 1.0999999999999652, 20.000000000000014, 169.4, 90.19999999999976, 21.20000000000004, 20.000000000000014, 1.0999999999999723, 20.000000000000014, 20.000000000000014, -7.299999999999894, 167.0, 20.000000000000014, 42.80000000000021, 17.899999999999988, -124.60000000000048, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 182.9, 200.0, 20.000000000000014, 39.200000000000244, 41.9000000000001, 20.000000000000014, 56.900000000000226, 15.799999999999963, 17.899999999999988, 20.000000000000014, 135.5, 200.0, 185.0, 20.000000000000014, 20.000000000000014, -70.30000000000084, 29.00000000000017, 72.19999999999962, 158.0, 17.899999999999988, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 197.0, 20.000000000000014, -0.9999999999999846, 200.0, 20.000000000000014, 20.000000000000014, 29.900000000000198, 53.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 13.699999999999964, 148.69999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999773, 35.900000000000155, 90.5, 91.99999999999932, 83.2999999999993, -80.80000000000044, 20.000000000000014, 200.0, 174.79999999999984, 15.799999999999963, 20.000000000000014, 103.69999999999997, 94.40000000000002, 20.000000000000014, 167.0, 3.1999999999999615, 22.700000000000056, 155.0, 163.09999999999977, 15.799999999999963, 5.299999999999967, 49.70000000000023, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 16.0, 0.0, 30.0, 0.0, 14.0, 0.0, 18.0, 0.0, 19.0, 0.0, 0.0, 0.0, 14.0, 2.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 19.0, 10.0, 10.0, 0.0, 27.0, 2.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 1.0, 19.0, 7.0, 8.0, 8.0, 7.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 7.0, 0.0, 0.0, 14.0, 7.0, 5.0, 18.0, 22.0, 6.0, 13.0, 0.0, 0.0, 32.0, 0.0, 45.0, 2.0, 9.0, 5.0, 17.0, 3.0, 64.0, 15.0, 0.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 17.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 2.0, 13.0, 15.0, 0.0, 2.0, 0.0, 0.0, 0.0, 7.0, 6.0, 0.0, 0.0, 10.0, 0.0, 9.0, 5.0, 0.0, 0.0, 14.0, 6.0, 0.0, 9.0, 0.0, 0.0, 21.0, 3.0, 0.0, 8.0, 35.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 29.0, 0.0, 2.0, 0.0, 1.0, 14.0, 0.0, 0.0, 5.0, 0.0, 43.0, 0.0, 0.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 15.0, 7.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 27.0, 3.0, 2.0, 24.0, 26.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 25.0, 0.0, 8.0, 11.0, 18.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.38651934399245, "mean_inference_ms": 3.719919852976281, "mean_action_processing_ms": 0.8330519440778376, "mean_env_wait_ms": 0.8454198456654306, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0051451921463012695, "StateBufferConnector_ms": 0.00564730167388916, "ViewRequirementAgentConnector_ms": 0.3251302242279053}, "num_episodes": 18, "episode_return_max": 382.9, "episode_return_min": -25.700000000000024, "episode_return_mean": 114.78199999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 233.58246665728748, "num_env_steps_trained_throughput_per_sec": 233.58246665728748, "timesteps_total": 152000, "num_env_steps_sampled_lifetime": 152000, "num_agent_steps_sampled_lifetime": 608000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 608000, "timers": {"training_iteration_time_ms": 17206.505, "restore_workers_time_ms": 0.038, "training_step_time_ms": 17206.427, "sample_time_ms": 4274.014, "learn_time_ms": 12899.297, "learn_throughput": 310.094, "synch_weights_time_ms": 26.429}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 608000, "num_agent_steps_trained": 608000}, "done": false, "training_iteration": 38, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-02-52", "timestamp": 1723521772, "time_this_iter_s": 17.265991926193237, "time_total_s": 643.6408321857452, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x330dc5ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 643.6408321857452, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 79.4, "ram_util_percent": 82.668}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.42885824537900075, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4838747651094482, "policy_loss": -0.003367862085166274, "vf_loss": 0.4871780179726778, "vf_explained_var": 0.016159283767932308, "kl": 0.013783325857636081, "entropy": 1.3505885136190545, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.519238603119024, "cur_kl_coeff": 0.0005859374999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.810856326799544, "policy_loss": -0.0006456540042544326, "vf_loss": 3.811500411437302, "vf_explained_var": 0.2172367031927462, "kl": 0.002676224881889557, "entropy": 0.5229742155977027, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 72765.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "env_runners": {"episode_reward_max": 382.9, "episode_reward_min": -25.700000000000024, "episode_reward_mean": 119.58999999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -124.60000000000048, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 64.0}, "policy_reward_mean": {"prey_policy": 54.01999999999998, "predator_policy": 5.775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [214.19999999999945, 36.10000000000024, 29.80000000000012, 23.500000000000036, 174.09999999999945, 40.0000000000003, 47.2000000000004, 32.30000000000019, 24.60000000000005, 167.7999999999995, 261.7999999999996, 19.099999999999955, 50.80000000000048, 139.79999999999976, 21.300000000000058, 55.50000000000047, 17.99999999999992, 119.59999999999977, 40.0000000000003, 219.99999999999926, 169.5999999999995, 40.0000000000003, 40.0000000000003, 15.799999999999969, 52.80000000000041, 217.79999999999927, 48.10000000000043, 40.0000000000003, 40.0000000000003, 204.49999999999935, 201.69999999999936, 140.49999999999963, 164.69999999999897, 47.200000000000415, 211.9999999999993, 207.39999999999932, 199.99999999999935, 185.39999999999944, 189.3999999999994, 131.39999999999938, 30.100000000000154, 40.0000000000003, 183.69999999999945, 70.79999999999998, -25.700000000000024, 219.99999999999926, 219.99999999999926, 382.9, 61.2000000000005, 90.8999999999992, 74.69999999999972, 38.90000000000028, 349.5, 209.9999999999993, -7.299999999999713, 101.19999999999837, 190.89999999999938, 56.200000000000514, 40.0000000000003, 219.99999999999926, 217.99999999999926, 208.99999999999932, 40.0000000000003, 104.90000000000012, 37.80000000000027, 36.70000000000025, 168.6999999999991, 40.0000000000003, 52.90000000000031, 187.49999999999912, 52.50000000000036, 219.99999999999926, 192.5999999999991, 123.69999999999979, 139.3999999999997, 189.19999999999942, 195.6999999999994, 180.89999999999904, 62.00000000000048, 43.60000000000035, 40.0000000000003, 40.0000000000003, -1.799999999999772, 215.99999999999926, 376.0, 207.99999999999932, 82.89999999999992, 34.40000000000021, 348.70000000000005, 148.9999999999996, 37.80000000000027, 219.99999999999926, 29.000000000000128, 178.29999999999913, 40.0000000000003, 219.99999999999926, 169.59999999999962, 164.19999999999874, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [24.200000000000003, 170.0, 20.000000000000014, 1.099999999999983, 5.299999999999965, 9.499999999999961, -11.499999999999826, 20.000000000000014, 154.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 37.10000000000021, 20.000000000000014, 5.299999999999965, -9.399999999999855, 20.000000000000014, 20.000000000000014, 135.79999999999998, 81.79999999999944, 140.0, -7.299999999999891, 7.399999999999974, 30.800000000000196, 20.000000000000014, 56.00000000000023, 51.80000000000004, -74.50000000000085, 48.80000000000013, 21.50000000000004, 20.000000000000014, 20.000000000000014, -21.999999999999915, 155.0, -114.40000000000055, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 133.7, 17.899999999999988, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, 15.799999999999967, 20.000000000000014, 6.7999999999999705, 200.0, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 170.0, -7.299999999999891, 194.0, 105.50000000000006, 20.000000000000014, 121.09999999999954, 41.59999999999998, 27.20000000000013, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 187.4, 20.000000000000014, 170.0, 170.3, 1.0999999999999652, 20.000000000000014, 169.4, 90.19999999999976, 21.20000000000004, 20.000000000000014, 1.0999999999999723, 20.000000000000014, 20.000000000000014, -7.299999999999894, 167.0, 20.000000000000014, 42.80000000000021, 17.899999999999988, -124.60000000000048, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 182.9, 200.0, 20.000000000000014, 39.200000000000244, 41.9000000000001, 20.000000000000014, 56.900000000000226, 15.799999999999963, 17.899999999999988, 20.000000000000014, 135.5, 200.0, 185.0, 20.000000000000014, 20.000000000000014, -70.30000000000084, 29.00000000000017, 72.19999999999962, 158.0, 17.899999999999988, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 197.0, 20.000000000000014, -0.9999999999999846, 200.0, 20.000000000000014, 20.000000000000014, 29.900000000000198, 53.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 13.699999999999964, 148.69999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999773, 35.900000000000155, 90.5, 91.99999999999932, 83.2999999999993, -80.80000000000044, 20.000000000000014, 200.0, 174.79999999999984, 15.799999999999963, 20.000000000000014, 103.69999999999997, 94.40000000000002, 20.000000000000014, 167.0, 3.1999999999999615, 22.700000000000056, 155.0, 163.09999999999977, 15.799999999999963, 5.299999999999967, 49.70000000000023, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, -47.199999999999775, 194.0, 20.000000000000014, 182.0, 188.0, 20.000000000000014, 182.0, 31.700000000000212, 6.200000000000003, 1.699999999999964, 13.699999999999967, 200.0, 148.7, 138.2, -5.199999999999951, 20.000000000000014, 15.799999999999963, 200.0, 20.000000000000014, -0.9999999999999881, 20.000000000000014, 20.000000000000014, 152.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 46.99999999999996, 80.60000000000004, 38.000000000000234, 126.19999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [1.0, 19.0, 7.0, 8.0, 8.0, 7.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 7.0, 0.0, 0.0, 14.0, 7.0, 5.0, 18.0, 22.0, 6.0, 13.0, 0.0, 0.0, 32.0, 0.0, 45.0, 2.0, 9.0, 5.0, 17.0, 3.0, 64.0, 15.0, 0.0, 0.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 0.0, 0.0, 22.0, 0.0, 0.0, 17.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 2.0, 13.0, 15.0, 0.0, 2.0, 0.0, 0.0, 0.0, 7.0, 6.0, 0.0, 0.0, 10.0, 0.0, 9.0, 5.0, 0.0, 0.0, 14.0, 6.0, 0.0, 9.0, 0.0, 0.0, 21.0, 3.0, 0.0, 8.0, 35.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 29.0, 0.0, 2.0, 0.0, 1.0, 14.0, 0.0, 0.0, 5.0, 0.0, 43.0, 0.0, 0.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 15.0, 7.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 27.0, 3.0, 2.0, 24.0, 26.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 25.0, 0.0, 8.0, 11.0, 18.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 32.0, 2.0, 0.0, 6.0, 0.0, 0.0, 6.0, 27.0, 18.0, 16.0, 3.0, 0.0, 0.0, 4.0, 12.0, 2.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3924110124577316, "mean_inference_ms": 3.7441334309746552, "mean_action_processing_ms": 0.8285268784665143, "mean_env_wait_ms": 0.8491982974657409, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004877924919128418, "StateBufferConnector_ms": 0.005980730056762695, "ViewRequirementAgentConnector_ms": 0.30021822452545166}, "num_episodes": 18, "episode_return_max": 382.9, "episode_return_min": -25.700000000000024, "episode_return_mean": 119.58999999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 234.25998625232594, "num_env_steps_trained_throughput_per_sec": 234.25998625232594, "timesteps_total": 156000, "num_env_steps_sampled_lifetime": 156000, "num_agent_steps_sampled_lifetime": 624000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 624000, "timers": {"training_iteration_time_ms": 16949.135, "restore_workers_time_ms": 0.04, "training_step_time_ms": 16949.056, "sample_time_ms": 4028.747, "learn_time_ms": 12886.638, "learn_throughput": 310.399, "synch_weights_time_ms": 26.95}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 624000, "num_agent_steps_trained": 624000}, "done": false, "training_iteration": 39, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-03-09", "timestamp": 1723521789, "time_this_iter_s": 17.122664213180542, "time_total_s": 660.7634963989258, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d3aca0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 660.7634963989258, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 78.18333333333334, "ram_util_percent": 83.59583333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4138820533221834, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4889307095654427, "policy_loss": -0.0024464711891832177, "vf_loss": 0.4913157216196254, "vf_explained_var": 0.005310083160955439, "kl": 0.013111017540017643, "entropy": 1.285490396729222, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4454693689626992, "cur_kl_coeff": 0.00029296874999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.983151380851786, "policy_loss": -0.0013030875957122556, "vf_loss": 3.9844529582079127, "vf_explained_var": 0.23519178490159373, "kl": 0.005239657675002199, "entropy": 0.5202206689844686, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 74655.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "env_runners": {"episode_reward_max": 382.9, "episode_reward_min": -25.700000000000024, "episode_reward_mean": 127.83599999999979, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -124.60000000000048, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 46.0}, "policy_reward_mean": {"prey_policy": 58.642999999999994, "predator_policy": 5.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 15.799999999999969, 52.80000000000041, 217.79999999999927, 48.10000000000043, 40.0000000000003, 40.0000000000003, 204.49999999999935, 201.69999999999936, 140.49999999999963, 164.69999999999897, 47.200000000000415, 211.9999999999993, 207.39999999999932, 199.99999999999935, 185.39999999999944, 189.3999999999994, 131.39999999999938, 30.100000000000154, 40.0000000000003, 183.69999999999945, 70.79999999999998, -25.700000000000024, 219.99999999999926, 219.99999999999926, 382.9, 61.2000000000005, 90.8999999999992, 74.69999999999972, 38.90000000000028, 349.5, 209.9999999999993, -7.299999999999713, 101.19999999999837, 190.89999999999938, 56.200000000000514, 40.0000000000003, 219.99999999999926, 217.99999999999926, 208.99999999999932, 40.0000000000003, 104.90000000000012, 37.80000000000027, 36.70000000000025, 168.6999999999991, 40.0000000000003, 52.90000000000031, 187.49999999999912, 52.50000000000036, 219.99999999999926, 192.5999999999991, 123.69999999999979, 139.3999999999997, 189.19999999999942, 195.6999999999994, 180.89999999999904, 62.00000000000048, 43.60000000000035, 40.0000000000003, 40.0000000000003, -1.799999999999772, 215.99999999999926, 376.0, 207.99999999999932, 82.89999999999992, 34.40000000000021, 348.70000000000005, 148.9999999999996, 37.80000000000027, 219.99999999999926, 29.000000000000128, 178.29999999999913, 40.0000000000003, 219.99999999999926, 169.59999999999962, 164.19999999999874, 40.0000000000003, 40.0000000000003, 246.99999999999966, 178.89999999999947, 197.99999999999937, 34.50000000000022, 51.39999999999999, 77.49999999999949, 22.400000000000013, 40.0000000000003, 158.79999999999953, 23.500000000000057, 197.99999999999937, 120.0999999999997, 211.4999999999993, 219.99999999999926, 219.99999999999926, 38.90000000000028, 158.0999999999996, 321.5000000000006, 45.700000000000315, 40.0000000000003, 170.2999999999995, -6.3999999999997375], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, -26.199999999999747, 20.000000000000014, 15.799999999999967, 20.000000000000014, 6.7999999999999705, 200.0, 28.100000000000147, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000008, 170.0, -7.299999999999891, 194.0, 105.50000000000006, 20.000000000000014, 121.09999999999954, 41.59999999999998, 27.20000000000013, 20.000000000000014, 179.0, 20.000000000000014, 20.000000000000014, 187.4, 20.000000000000014, 170.0, 170.3, 1.0999999999999652, 20.000000000000014, 169.4, 90.19999999999976, 21.20000000000004, 20.000000000000014, 1.0999999999999723, 20.000000000000014, 20.000000000000014, -7.299999999999894, 167.0, 20.000000000000014, 42.80000000000021, 17.899999999999988, -124.60000000000048, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 182.9, 200.0, 20.000000000000014, 39.200000000000244, 41.9000000000001, 20.000000000000014, 56.900000000000226, 15.799999999999963, 17.899999999999988, 20.000000000000014, 135.5, 200.0, 185.0, 20.000000000000014, 20.000000000000014, -70.30000000000084, 29.00000000000017, 72.19999999999962, 158.0, 17.899999999999988, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 197.0, 20.000000000000014, -0.9999999999999846, 200.0, 20.000000000000014, 20.000000000000014, 29.900000000000198, 53.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 13.699999999999964, 148.69999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999773, 35.900000000000155, 90.5, 91.99999999999932, 83.2999999999993, -80.80000000000044, 20.000000000000014, 200.0, 174.79999999999984, 15.799999999999963, 20.000000000000014, 103.69999999999997, 94.40000000000002, 20.000000000000014, 167.0, 3.1999999999999615, 22.700000000000056, 155.0, 163.09999999999977, 15.799999999999963, 5.299999999999967, 49.70000000000023, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, -47.199999999999775, 194.0, 20.000000000000014, 182.0, 188.0, 20.000000000000014, 182.0, 31.700000000000212, 6.200000000000003, 1.699999999999964, 13.699999999999967, 200.0, 148.7, 138.2, -5.199999999999951, 20.000000000000014, 15.799999999999963, 200.0, 20.000000000000014, -0.9999999999999881, 20.000000000000014, 20.000000000000014, 152.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 46.99999999999996, 80.60000000000004, 38.000000000000234, 126.19999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 29.000000000000142, -21.99999999999975, 179.9, 167.0, 20.000000000000014, 20.000000000000014, 9.499999999999964, -30.39999999999978, 57.79999999999996, 7.399999999999967, 64.1000000000002, 20.000000000000014, -13.599999999999783, 20.000000000000014, 20.000000000000014, 20.000000000000014, 138.79999999999998, 20.000000000000014, -11.499999999999872, 167.0, 20.000000000000014, 100.09999999999988, 20.000000000000014, 200.0, -11.499999999999819, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 128.60000000000002, 9.499999999999964, 127.09999999999977, 193.4, 57.79999999999996, -60.10000000000065, 20.000000000000014, 20.000000000000014, 139.40000000000003, 20.90000000000003, 7.399999999999965, -59.80000000000017], "policy_predator_policy_reward": [0.0, 0.0, 22.0, 0.0, 0.0, 17.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 2.0, 13.0, 15.0, 0.0, 2.0, 0.0, 0.0, 0.0, 7.0, 6.0, 0.0, 0.0, 10.0, 0.0, 9.0, 5.0, 0.0, 0.0, 14.0, 6.0, 0.0, 9.0, 0.0, 0.0, 21.0, 3.0, 0.0, 8.0, 35.0, 46.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 29.0, 0.0, 2.0, 0.0, 1.0, 14.0, 0.0, 0.0, 5.0, 0.0, 43.0, 0.0, 0.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 15.0, 7.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 27.0, 3.0, 2.0, 24.0, 26.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 25.0, 0.0, 8.0, 11.0, 18.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 32.0, 2.0, 0.0, 6.0, 0.0, 0.0, 6.0, 27.0, 18.0, 16.0, 3.0, 0.0, 0.0, 4.0, 12.0, 2.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 21.0, 0.0, 11.0, 5.0, 0.0, 8.0, 16.0, 6.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 11.0, 0.0, 0.0, 15.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 15.0, 1.0, 0.0, 30.0, 18.0, 0.0, 0.0, 10.0, 0.0, 29.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.390419306881274, "mean_inference_ms": 3.748311272797638, "mean_action_processing_ms": 0.8186898181621216, "mean_env_wait_ms": 0.847214848874959, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004750967025756836, "StateBufferConnector_ms": 0.005855560302734375, "ViewRequirementAgentConnector_ms": 0.26302778720855713}, "num_episodes": 22, "episode_return_max": 382.9, "episode_return_min": -25.700000000000024, "episode_return_mean": 127.83599999999979, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 192.65115744340312, "num_env_steps_trained_throughput_per_sec": 192.65115744340312, "timesteps_total": 160000, "num_env_steps_sampled_lifetime": 160000, "num_agent_steps_sampled_lifetime": 640000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 640000, "timers": {"training_iteration_time_ms": 17607.844, "restore_workers_time_ms": 0.04, "training_step_time_ms": 17607.764, "sample_time_ms": 3967.369, "learn_time_ms": 13606.506, "learn_throughput": 293.977, "synch_weights_time_ms": 27.869}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 640000, "num_agent_steps_trained": 640000}, "done": false, "training_iteration": 40, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-03-30", "timestamp": 1723521810, "time_this_iter_s": 20.822545289993286, "time_total_s": 681.5860416889191, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4da25e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 681.5860416889191, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 87.58, "ram_util_percent": 83.36999999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.379653741890397, "cur_kl_coeff": 0.004687499999999999, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4003451371003711, "policy_loss": -0.002485609799869871, "vf_loss": 0.4028077828675686, "vf_explained_var": 0.017748255546761568, "kl": 0.004899152087866708, "entropy": 1.2338267340231195, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8346880457152135, "cur_kl_coeff": 0.00029296874999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.4787975755318135, "policy_loss": -0.00018180791589199867, "vf_loss": 4.478978213305195, "vf_explained_var": 0.15223830553589673, "kl": 0.004044608404064473, "entropy": 0.42110875824456495, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 76545.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -7.299999999999713, "episode_reward_mean": 133.12999999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -93.4000000000007, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 53.0}, "policy_reward_mean": {"prey_policy": 61.75999999999999, "predator_policy": 4.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 219.99999999999926, 382.9, 61.2000000000005, 90.8999999999992, 74.69999999999972, 38.90000000000028, 349.5, 209.9999999999993, -7.299999999999713, 101.19999999999837, 190.89999999999938, 56.200000000000514, 40.0000000000003, 219.99999999999926, 217.99999999999926, 208.99999999999932, 40.0000000000003, 104.90000000000012, 37.80000000000027, 36.70000000000025, 168.6999999999991, 40.0000000000003, 52.90000000000031, 187.49999999999912, 52.50000000000036, 219.99999999999926, 192.5999999999991, 123.69999999999979, 139.3999999999997, 189.19999999999942, 195.6999999999994, 180.89999999999904, 62.00000000000048, 43.60000000000035, 40.0000000000003, 40.0000000000003, -1.799999999999772, 215.99999999999926, 376.0, 207.99999999999932, 82.89999999999992, 34.40000000000021, 348.70000000000005, 148.9999999999996, 37.80000000000027, 219.99999999999926, 29.000000000000128, 178.29999999999913, 40.0000000000003, 219.99999999999926, 169.59999999999962, 164.19999999999874, 40.0000000000003, 40.0000000000003, 246.99999999999966, 178.89999999999947, 197.99999999999937, 34.50000000000022, 51.39999999999999, 77.49999999999949, 22.400000000000013, 40.0000000000003, 158.79999999999953, 23.500000000000057, 197.99999999999937, 120.0999999999997, 211.4999999999993, 219.99999999999926, 219.99999999999926, 38.90000000000028, 158.0999999999996, 321.5000000000006, 45.700000000000315, 40.0000000000003, 170.2999999999995, -6.3999999999997375, 306.0, 35.600000000000236, 63.50000000000021, 110.29999999999981, 203.49999999999986, 40.0000000000003, 400.0, 378.0, 40.0000000000003, 50.50000000000044, 187.59999999999923, 221.79999999999927, 80.29999999999927, 4.500000000000194, 128.19999999999973, 147.3999999999996, 204.69999999999933, 102.99999999999994, 38.90000000000028, 130.8999999999989, 40.0000000000003, 219.99999999999926, 32.30000000000018], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 200.0, 200.0, 20.000000000000014, 182.9, 200.0, 20.000000000000014, 39.200000000000244, 41.9000000000001, 20.000000000000014, 56.900000000000226, 15.799999999999963, 17.899999999999988, 20.000000000000014, 135.5, 200.0, 185.0, 20.000000000000014, 20.000000000000014, -70.30000000000084, 29.00000000000017, 72.19999999999962, 158.0, 17.899999999999988, 20.000000000000014, 36.20000000000026, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 197.0, 20.000000000000014, -0.9999999999999846, 200.0, 20.000000000000014, 20.000000000000014, 29.900000000000198, 53.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 13.699999999999964, 148.69999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999773, 35.900000000000155, 90.5, 91.99999999999932, 83.2999999999993, -80.80000000000044, 20.000000000000014, 200.0, 174.79999999999984, 15.799999999999963, 20.000000000000014, 103.69999999999997, 94.40000000000002, 20.000000000000014, 167.0, 3.1999999999999615, 22.700000000000056, 155.0, 163.09999999999977, 15.799999999999963, 5.299999999999967, 49.70000000000023, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, -47.199999999999775, 194.0, 20.000000000000014, 182.0, 188.0, 20.000000000000014, 182.0, 31.700000000000212, 6.200000000000003, 1.699999999999964, 13.699999999999967, 200.0, 148.7, 138.2, -5.199999999999951, 20.000000000000014, 15.799999999999963, 200.0, 20.000000000000014, -0.9999999999999881, 20.000000000000014, 20.000000000000014, 152.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 46.99999999999996, 80.60000000000004, 38.000000000000234, 126.19999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 29.000000000000142, -21.99999999999975, 179.9, 167.0, 20.000000000000014, 20.000000000000014, 9.499999999999964, -30.39999999999978, 57.79999999999996, 7.399999999999967, 64.1000000000002, 20.000000000000014, -13.599999999999783, 20.000000000000014, 20.000000000000014, 20.000000000000014, 138.79999999999998, 20.000000000000014, -11.499999999999872, 167.0, 20.000000000000014, 100.09999999999988, 20.000000000000014, 200.0, -11.499999999999819, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 128.60000000000002, 9.499999999999964, 127.09999999999977, 193.4, 57.79999999999996, -60.10000000000065, 20.000000000000014, 20.000000000000014, 139.40000000000003, 20.90000000000003, 7.399999999999965, -59.80000000000017, 148.70000000000007, 146.3, 20.000000000000014, 11.599999999999964, -93.4000000000007, 98.89999999999984, 20.000000000000014, 86.29999999999998, 122.60000000000002, 62.89999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000009, 20.000000000000014, 167.5999999999999, 21.800000000000047, 200.0, 5.299999999999969, 65.00000000000013, -15.699999999999747, 3.1999999999999633, 1.09999999999996, 118.09999999999998, 20.000000000000014, 115.40000000000008, 173.0, 22.700000000000053, 82.99999999999997, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 101.89999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 7.399999999999965, 17.899999999999984], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 29.0, 0.0, 2.0, 0.0, 1.0, 14.0, 0.0, 0.0, 5.0, 0.0, 43.0, 0.0, 0.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 15.0, 7.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 27.0, 3.0, 2.0, 24.0, 26.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 25.0, 0.0, 8.0, 11.0, 18.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 32.0, 2.0, 0.0, 6.0, 0.0, 0.0, 6.0, 27.0, 18.0, 16.0, 3.0, 0.0, 0.0, 4.0, 12.0, 2.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 21.0, 0.0, 11.0, 5.0, 0.0, 8.0, 16.0, 6.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 11.0, 0.0, 0.0, 15.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 15.0, 1.0, 0.0, 30.0, 18.0, 0.0, 0.0, 10.0, 0.0, 29.0, 17.0, 11.0, 0.0, 4.0, 0.0, 5.0, 53.0, 0.0, 4.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 17.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4025155168738865, "mean_inference_ms": 3.8004119571634103, "mean_action_processing_ms": 0.8306322527038885, "mean_env_wait_ms": 0.8550177129613552, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007417559623718262, "StateBufferConnector_ms": 0.007451176643371582, "ViewRequirementAgentConnector_ms": 0.42211830615997314}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -7.299999999999713, "episode_return_mean": 133.12999999999982, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 195.75950718012288, "num_env_steps_trained_throughput_per_sec": 195.75950718012288, "timesteps_total": 164000, "num_env_steps_sampled_lifetime": 164000, "num_agent_steps_sampled_lifetime": 656000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 656000, "timers": {"training_iteration_time_ms": 18167.21, "restore_workers_time_ms": 0.04, "training_step_time_ms": 18167.13, "sample_time_ms": 4448.968, "learn_time_ms": 13690.754, "learn_throughput": 292.168, "synch_weights_time_ms": 21.641}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 656000, "num_agent_steps_trained": 656000}, "done": false, "training_iteration": 41, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-03-51", "timestamp": 1723521831, "time_this_iter_s": 20.510547876358032, "time_total_s": 702.0965895652771, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d0d1f0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 702.0965895652771, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 86.2344827586207, "ram_util_percent": 83.64482758620689}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5252020661241164, "cur_kl_coeff": 0.0023437499999999995, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.5242360643924229, "policy_loss": -0.003842172877143615, "vf_loss": 1.528040530773067, "vf_explained_var": 0.00829227194584236, "kl": 0.016087357903622635, "entropy": 1.2500428084343198, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5514975808363742, "cur_kl_coeff": 0.00014648437499999997, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.921291447821117, "policy_loss": -0.00041037693499001087, "vf_loss": 4.921701322283064, "vf_explained_var": 0.15783750380157793, "kl": 0.0034841317797964133, "entropy": 0.4639070783500318, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 78435.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -25.099999999999532, "episode_reward_mean": 130.36499999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -93.4000000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 63.0}, "policy_reward_mean": {"prey_policy": 58.227499999999985, "predator_policy": 6.955}, "custom_metrics": {}, "hist_stats": {"episode_reward": [104.90000000000012, 37.80000000000027, 36.70000000000025, 168.6999999999991, 40.0000000000003, 52.90000000000031, 187.49999999999912, 52.50000000000036, 219.99999999999926, 192.5999999999991, 123.69999999999979, 139.3999999999997, 189.19999999999942, 195.6999999999994, 180.89999999999904, 62.00000000000048, 43.60000000000035, 40.0000000000003, 40.0000000000003, -1.799999999999772, 215.99999999999926, 376.0, 207.99999999999932, 82.89999999999992, 34.40000000000021, 348.70000000000005, 148.9999999999996, 37.80000000000027, 219.99999999999926, 29.000000000000128, 178.29999999999913, 40.0000000000003, 219.99999999999926, 169.59999999999962, 164.19999999999874, 40.0000000000003, 40.0000000000003, 246.99999999999966, 178.89999999999947, 197.99999999999937, 34.50000000000022, 51.39999999999999, 77.49999999999949, 22.400000000000013, 40.0000000000003, 158.79999999999953, 23.500000000000057, 197.99999999999937, 120.0999999999997, 211.4999999999993, 219.99999999999926, 219.99999999999926, 38.90000000000028, 158.0999999999996, 321.5000000000006, 45.700000000000315, 40.0000000000003, 170.2999999999995, -6.3999999999997375, 306.0, 35.600000000000236, 63.50000000000021, 110.29999999999981, 203.49999999999986, 40.0000000000003, 400.0, 378.0, 40.0000000000003, 50.50000000000044, 187.59999999999923, 221.79999999999927, 80.29999999999927, 4.500000000000194, 128.19999999999973, 147.3999999999996, 204.69999999999933, 102.99999999999994, 38.90000000000028, 130.8999999999989, 40.0000000000003, 219.99999999999926, 32.30000000000018, 16.899999999999945, 84.99999999999889, 329.3, -25.099999999999532, 146.1999999999996, 340.6, 17.99999999999996, 75.50000000000031, 26.300000000000338, 35.600000000000236, 211.1999999999993, 40.0000000000003, 318.3, 65.00000000000006, 374.0, 168.49999999999952, 26.600000000000108, 187.69999999999942], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [29.900000000000198, 53.000000000000014, 15.799999999999963, 20.000000000000014, 20.000000000000014, 13.699999999999964, 148.69999999999976, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.999999999999773, 35.900000000000155, 90.5, 91.99999999999932, 83.2999999999993, -80.80000000000044, 20.000000000000014, 200.0, 174.79999999999984, 15.799999999999963, 20.000000000000014, 103.69999999999997, 94.40000000000002, 20.000000000000014, 167.0, 3.1999999999999615, 22.700000000000056, 155.0, 163.09999999999977, 15.799999999999963, 5.299999999999967, 49.70000000000023, 20.000000000000014, 23.600000000000065, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, -47.199999999999775, 194.0, 20.000000000000014, 182.0, 188.0, 20.000000000000014, 182.0, 31.700000000000212, 6.200000000000003, 1.699999999999964, 13.699999999999967, 200.0, 148.7, 138.2, -5.199999999999951, 20.000000000000014, 15.799999999999963, 200.0, 20.000000000000014, -0.9999999999999881, 20.000000000000014, 20.000000000000014, 152.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 46.99999999999996, 80.60000000000004, 38.000000000000234, 126.19999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 29.000000000000142, -21.99999999999975, 179.9, 167.0, 20.000000000000014, 20.000000000000014, 9.499999999999964, -30.39999999999978, 57.79999999999996, 7.399999999999967, 64.1000000000002, 20.000000000000014, -13.599999999999783, 20.000000000000014, 20.000000000000014, 20.000000000000014, 138.79999999999998, 20.000000000000014, -11.499999999999872, 167.0, 20.000000000000014, 100.09999999999988, 20.000000000000014, 200.0, -11.499999999999819, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 128.60000000000002, 9.499999999999964, 127.09999999999977, 193.4, 57.79999999999996, -60.10000000000065, 20.000000000000014, 20.000000000000014, 139.40000000000003, 20.90000000000003, 7.399999999999965, -59.80000000000017, 148.70000000000007, 146.3, 20.000000000000014, 11.599999999999964, -93.4000000000007, 98.89999999999984, 20.000000000000014, 86.29999999999998, 122.60000000000002, 62.89999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000009, 20.000000000000014, 167.5999999999999, 21.800000000000047, 200.0, 5.299999999999969, 65.00000000000013, -15.699999999999747, 3.1999999999999633, 1.09999999999996, 118.09999999999998, 20.000000000000014, 115.40000000000008, 173.0, 22.700000000000053, 82.99999999999997, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 101.89999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 7.399999999999965, 17.899999999999984, 3.1999999999999686, -7.299999999999901, -36.69999999999981, 94.69999999999933, 134.3, 170.0, 5.299999999999965, -93.4000000000008, 126.19999999999999, 20.000000000000014, 140.6, 200.0, 20.000000000000014, -21.99999999999975, 20.000000000000014, 39.50000000000018, 27.800000000000168, -74.50000000000027, 20.000000000000014, 11.599999999999964, 3.1999999999999615, 200.0, 20.000000000000014, 20.000000000000014, 126.80000000000004, 168.5, -67.00000000000023, 20.000000000000014, 161.0, 200.0, -74.50000000000081, 146.0, -30.399999999999814, 20.000000000000014, 154.7, 20.000000000000014], "policy_predator_policy_reward": [15.0, 7.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 27.0, 3.0, 2.0, 24.0, 26.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 25.0, 0.0, 8.0, 11.0, 18.0, 0.0, 2.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 32.0, 2.0, 0.0, 6.0, 0.0, 0.0, 6.0, 27.0, 18.0, 16.0, 3.0, 0.0, 0.0, 4.0, 12.0, 2.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 21.0, 0.0, 11.0, 5.0, 0.0, 8.0, 16.0, 6.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 11.0, 0.0, 0.0, 15.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 15.0, 1.0, 0.0, 30.0, 18.0, 0.0, 0.0, 10.0, 0.0, 29.0, 17.0, 11.0, 0.0, 4.0, 0.0, 5.0, 53.0, 0.0, 4.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 17.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 1.0, 8.0, 13.0, 0.0, 27.0, 10.0, 15.0, 43.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 3.0, 13.0, 28.0, 45.0, 0.0, 4.0, 0.0, 8.0, 0.0, 0.0, 13.0, 10.0, 63.0, 49.0, 0.0, 13.0, 46.0, 51.0, 19.0, 18.0, 13.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.411896646735151, "mean_inference_ms": 3.8179048183426705, "mean_action_processing_ms": 0.8144979034964007, "mean_env_wait_ms": 0.860131552865428, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007094264030456543, "StateBufferConnector_ms": 0.005685925483703613, "ViewRequirementAgentConnector_ms": 0.3374892473220825}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -25.099999999999532, "episode_return_mean": 130.36499999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 244.13077633707826, "num_env_steps_trained_throughput_per_sec": 244.13077633707826, "timesteps_total": 168000, "num_env_steps_sampled_lifetime": 168000, "num_agent_steps_sampled_lifetime": 672000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 672000, "timers": {"training_iteration_time_ms": 17931.316, "restore_workers_time_ms": 0.041, "training_step_time_ms": 17931.236, "sample_time_ms": 4241.928, "learn_time_ms": 13667.471, "learn_throughput": 292.666, "synch_weights_time_ms": 17.997}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 672000, "num_agent_steps_trained": 672000}, "done": false, "training_iteration": 42, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-04-07", "timestamp": 1723521847, "time_this_iter_s": 16.450292825698853, "time_total_s": 718.546882390976, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d3a550>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 718.546882390976, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 82.84347826086957, "ram_util_percent": 83.25652173913043}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4423746293046014, "cur_kl_coeff": 0.0023437499999999995, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.29773691817723885, "policy_loss": -0.0068076622053961115, "vf_loss": 0.30448814441693856, "vf_explained_var": -0.0018523981331517456, "kl": 0.02407939371641506, "entropy": 1.2492368565034615, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9631779276898929, "cur_kl_coeff": 7.324218749999998e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.80420717183875, "policy_loss": -0.001829992282258534, "vf_loss": 4.8060368672880545, "vf_explained_var": 0.25150589637024695, "kl": 0.003948767314211709, "entropy": 0.4713325410292893, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 80325.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -25.099999999999532, "episode_reward_mean": 140.54099999999983, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -200.50000000000043, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 93.0}, "policy_reward_mean": {"prey_policy": 63.25549999999998, "predator_policy": 7.015}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, -1.799999999999772, 215.99999999999926, 376.0, 207.99999999999932, 82.89999999999992, 34.40000000000021, 348.70000000000005, 148.9999999999996, 37.80000000000027, 219.99999999999926, 29.000000000000128, 178.29999999999913, 40.0000000000003, 219.99999999999926, 169.59999999999962, 164.19999999999874, 40.0000000000003, 40.0000000000003, 246.99999999999966, 178.89999999999947, 197.99999999999937, 34.50000000000022, 51.39999999999999, 77.49999999999949, 22.400000000000013, 40.0000000000003, 158.79999999999953, 23.500000000000057, 197.99999999999937, 120.0999999999997, 211.4999999999993, 219.99999999999926, 219.99999999999926, 38.90000000000028, 158.0999999999996, 321.5000000000006, 45.700000000000315, 40.0000000000003, 170.2999999999995, -6.3999999999997375, 306.0, 35.600000000000236, 63.50000000000021, 110.29999999999981, 203.49999999999986, 40.0000000000003, 400.0, 378.0, 40.0000000000003, 50.50000000000044, 187.59999999999923, 221.79999999999927, 80.29999999999927, 4.500000000000194, 128.19999999999973, 147.3999999999996, 204.69999999999933, 102.99999999999994, 38.90000000000028, 130.8999999999989, 40.0000000000003, 219.99999999999926, 32.30000000000018, 16.899999999999945, 84.99999999999889, 329.3, -25.099999999999532, 146.1999999999996, 340.6, 17.99999999999996, 75.50000000000031, 26.300000000000338, 35.600000000000236, 211.1999999999993, 40.0000000000003, 318.3, 65.00000000000006, 374.0, 168.49999999999952, 26.600000000000108, 187.69999999999942, 146.19999999999965, 40.0000000000003, 64.60000000000011, 202.89999999999972, 40.0000000000003, 131.79999999999973, 219.99999999999926, 393.7, 183.89999999999944, 201.09999999999926, 205.99999999999932, 105.6999999999997, 36.70000000000025, 346.00000000000136, 196.2999999999994, 246.09999999999908, 300.0999999999998, 24.60000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 7.399999999999965, -47.199999999999775, 194.0, 20.000000000000014, 182.0, 188.0, 20.000000000000014, 182.0, 31.700000000000212, 6.200000000000003, 1.699999999999964, 13.699999999999967, 200.0, 148.7, 138.2, -5.199999999999951, 20.000000000000014, 15.799999999999963, 200.0, 20.000000000000014, -0.9999999999999881, 20.000000000000014, 20.000000000000014, 152.2999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 46.99999999999996, 80.60000000000004, 38.000000000000234, 126.19999999999953, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 29.000000000000142, -21.99999999999975, 179.9, 167.0, 20.000000000000014, 20.000000000000014, 9.499999999999964, -30.39999999999978, 57.79999999999996, 7.399999999999967, 64.1000000000002, 20.000000000000014, -13.599999999999783, 20.000000000000014, 20.000000000000014, 20.000000000000014, 138.79999999999998, 20.000000000000014, -11.499999999999872, 167.0, 20.000000000000014, 100.09999999999988, 20.000000000000014, 200.0, -11.499999999999819, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 128.60000000000002, 9.499999999999964, 127.09999999999977, 193.4, 57.79999999999996, -60.10000000000065, 20.000000000000014, 20.000000000000014, 139.40000000000003, 20.90000000000003, 7.399999999999965, -59.80000000000017, 148.70000000000007, 146.3, 20.000000000000014, 11.599999999999964, -93.4000000000007, 98.89999999999984, 20.000000000000014, 86.29999999999998, 122.60000000000002, 62.89999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000009, 20.000000000000014, 167.5999999999999, 21.800000000000047, 200.0, 5.299999999999969, 65.00000000000013, -15.699999999999747, 3.1999999999999633, 1.09999999999996, 118.09999999999998, 20.000000000000014, 115.40000000000008, 173.0, 22.700000000000053, 82.99999999999997, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 101.89999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 7.399999999999965, 17.899999999999984, 3.1999999999999686, -7.299999999999901, -36.69999999999981, 94.69999999999933, 134.3, 170.0, 5.299999999999965, -93.4000000000008, 126.19999999999999, 20.000000000000014, 140.6, 200.0, 20.000000000000014, -21.99999999999975, 20.000000000000014, 39.50000000000018, 27.800000000000168, -74.50000000000027, 20.000000000000014, 11.599999999999964, 3.1999999999999615, 200.0, 20.000000000000014, 20.000000000000014, 126.80000000000004, 168.5, -67.00000000000023, 20.000000000000014, 161.0, 200.0, -74.50000000000081, 146.0, -30.399999999999814, 20.000000000000014, 154.7, 20.000000000000014, 3.1999999999999686, 134.0, 20.000000000000014, 20.000000000000014, 130.09999999999997, -200.50000000000043, 70.39999999999996, 132.4999999999999, 20.000000000000014, 20.000000000000014, 111.79999999999998, 20.000000000000014, 20.000000000000014, 200.0, 193.7, 200.0, 149.9, 20.000000000000014, 1.0999999999999865, 190.99999999999994, 179.0, 20.000000000000014, 20.000000000000014, 85.69999999999987, 13.699999999999964, 20.000000000000014, 145.99999999999966, 200.0, 5.299999999999965, 176.0, 46.10000000000022, 200.0, 100.09999999999998, 200.0, 20.000000000000014, -9.399999999999855], "policy_predator_policy_reward": [0.0, 0.0, 6.0, 32.0, 2.0, 0.0, 6.0, 0.0, 0.0, 6.0, 27.0, 18.0, 16.0, 3.0, 0.0, 0.0, 4.0, 12.0, 2.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 21.0, 0.0, 11.0, 5.0, 0.0, 8.0, 16.0, 6.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 11.0, 0.0, 0.0, 15.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 15.0, 1.0, 0.0, 30.0, 18.0, 0.0, 0.0, 10.0, 0.0, 29.0, 17.0, 11.0, 0.0, 4.0, 0.0, 5.0, 53.0, 0.0, 4.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 17.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 1.0, 8.0, 13.0, 0.0, 27.0, 10.0, 15.0, 43.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 3.0, 13.0, 28.0, 45.0, 0.0, 4.0, 0.0, 8.0, 0.0, 0.0, 13.0, 10.0, 63.0, 49.0, 0.0, 13.0, 46.0, 51.0, 19.0, 18.0, 13.0, 0.0, 1.0, 8.0, 0.0, 0.0, 93.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 9.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.416238416804132, "mean_inference_ms": 3.834893650909846, "mean_action_processing_ms": 0.8101636078029734, "mean_env_wait_ms": 0.8627690707577549, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007451772689819336, "StateBufferConnector_ms": 0.005876779556274414, "ViewRequirementAgentConnector_ms": 0.35522282123565674}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -25.099999999999532, "episode_return_mean": 140.54099999999983, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 214.24082041238088, "num_env_steps_trained_throughput_per_sec": 214.24082041238088, "timesteps_total": 172000, "num_env_steps_sampled_lifetime": 172000, "num_agent_steps_sampled_lifetime": 688000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 688000, "timers": {"training_iteration_time_ms": 18186.837, "restore_workers_time_ms": 0.02, "training_step_time_ms": 18186.776, "sample_time_ms": 4187.102, "learn_time_ms": 13977.901, "learn_throughput": 286.166, "synch_weights_time_ms": 17.706}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 688000, "num_agent_steps_trained": 688000}, "done": false, "training_iteration": 43, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-04-26", "timestamp": 1723521866, "time_this_iter_s": 18.748713970184326, "time_total_s": 737.2955963611603, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28cd0d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 737.2955963611603, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 86.08148148148148, "ram_util_percent": 83.52222222222223}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4094488005651526, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.21424266940386838, "policy_loss": -0.003537853700527675, "vf_loss": 0.21772562754525257, "vf_explained_var": 0.00613416004433203, "kl": 0.015614635688392492, "entropy": 1.1734925726103405, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9923085384543926, "cur_kl_coeff": 3.662109374999999e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7412756873186304, "policy_loss": -0.0004060488997431344, "vf_loss": 3.741681708608355, "vf_explained_var": 0.2924656991920774, "kl": 0.0019339733606619776, "entropy": 0.5739696086556824, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 82215.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -25.099999999999532, "episode_reward_mean": 137.33599999999987, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -200.50000000000043, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 93.0}, "policy_reward_mean": {"prey_policy": 61.867999999999995, "predator_policy": 6.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 246.99999999999966, 178.89999999999947, 197.99999999999937, 34.50000000000022, 51.39999999999999, 77.49999999999949, 22.400000000000013, 40.0000000000003, 158.79999999999953, 23.500000000000057, 197.99999999999937, 120.0999999999997, 211.4999999999993, 219.99999999999926, 219.99999999999926, 38.90000000000028, 158.0999999999996, 321.5000000000006, 45.700000000000315, 40.0000000000003, 170.2999999999995, -6.3999999999997375, 306.0, 35.600000000000236, 63.50000000000021, 110.29999999999981, 203.49999999999986, 40.0000000000003, 400.0, 378.0, 40.0000000000003, 50.50000000000044, 187.59999999999923, 221.79999999999927, 80.29999999999927, 4.500000000000194, 128.19999999999973, 147.3999999999996, 204.69999999999933, 102.99999999999994, 38.90000000000028, 130.8999999999989, 40.0000000000003, 219.99999999999926, 32.30000000000018, 16.899999999999945, 84.99999999999889, 329.3, -25.099999999999532, 146.1999999999996, 340.6, 17.99999999999996, 75.50000000000031, 26.300000000000338, 35.600000000000236, 211.1999999999993, 40.0000000000003, 318.3, 65.00000000000006, 374.0, 168.49999999999952, 26.600000000000108, 187.69999999999942, 146.19999999999965, 40.0000000000003, 64.60000000000011, 202.89999999999972, 40.0000000000003, 131.79999999999973, 219.99999999999926, 393.7, 183.89999999999944, 201.09999999999926, 205.99999999999932, 105.6999999999997, 36.70000000000025, 346.00000000000136, 196.2999999999994, 246.09999999999908, 300.0999999999998, 24.60000000000005, 127.49999999999972, 138.5999999999999, 10.200000000000086, 191.3999999999994, 219.99999999999926, 40.0000000000003, 161.5999999999994, 35.600000000000236, 27.90000000000011, 118.49999999999974, 81.40000000000012, 201.99999999999935, 221.29999999999922, 161.49999999999952, 66.10000000000025, 184.89999999999944, 218.89999999999927, 24.200000000000045], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 200.0, 29.000000000000142, -21.99999999999975, 179.9, 167.0, 20.000000000000014, 20.000000000000014, 9.499999999999964, -30.39999999999978, 57.79999999999996, 7.399999999999967, 64.1000000000002, 20.000000000000014, -13.599999999999783, 20.000000000000014, 20.000000000000014, 20.000000000000014, 138.79999999999998, 20.000000000000014, -11.499999999999872, 167.0, 20.000000000000014, 100.09999999999988, 20.000000000000014, 200.0, -11.499999999999819, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 17.899999999999988, 128.60000000000002, 9.499999999999964, 127.09999999999977, 193.4, 57.79999999999996, -60.10000000000065, 20.000000000000014, 20.000000000000014, 139.40000000000003, 20.90000000000003, 7.399999999999965, -59.80000000000017, 148.70000000000007, 146.3, 20.000000000000014, 11.599999999999964, -93.4000000000007, 98.89999999999984, 20.000000000000014, 86.29999999999998, 122.60000000000002, 62.89999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000009, 20.000000000000014, 167.5999999999999, 21.800000000000047, 200.0, 5.299999999999969, 65.00000000000013, -15.699999999999747, 3.1999999999999633, 1.09999999999996, 118.09999999999998, 20.000000000000014, 115.40000000000008, 173.0, 22.700000000000053, 82.99999999999997, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 101.89999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 7.399999999999965, 17.899999999999984, 3.1999999999999686, -7.299999999999901, -36.69999999999981, 94.69999999999933, 134.3, 170.0, 5.299999999999965, -93.4000000000008, 126.19999999999999, 20.000000000000014, 140.6, 200.0, 20.000000000000014, -21.99999999999975, 20.000000000000014, 39.50000000000018, 27.800000000000168, -74.50000000000027, 20.000000000000014, 11.599999999999964, 3.1999999999999615, 200.0, 20.000000000000014, 20.000000000000014, 126.80000000000004, 168.5, -67.00000000000023, 20.000000000000014, 161.0, 200.0, -74.50000000000081, 146.0, -30.399999999999814, 20.000000000000014, 154.7, 20.000000000000014, 3.1999999999999686, 134.0, 20.000000000000014, 20.000000000000014, 130.09999999999997, -200.50000000000043, 70.39999999999996, 132.4999999999999, 20.000000000000014, 20.000000000000014, 111.79999999999998, 20.000000000000014, 20.000000000000014, 200.0, 193.7, 200.0, 149.9, 20.000000000000014, 1.0999999999999865, 190.99999999999994, 179.0, 20.000000000000014, 20.000000000000014, 85.69999999999987, 13.699999999999964, 20.000000000000014, 145.99999999999966, 200.0, 5.299999999999965, 176.0, 46.10000000000022, 200.0, 100.09999999999998, 200.0, 20.000000000000014, -9.399999999999855, 20.000000000000014, 99.49999999999997, 36.50000000000025, 100.09999999999998, 20.000000000000014, -41.79999999999978, 167.0, 7.399999999999965, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.59999999999998, 29.00000000000018, 11.599999999999966, 20.000000000000014, -3.099999999999958, 20.000000000000014, 90.49999999999997, 20.000000000000014, 20.000000000000014, 61.39999999999996, 173.0, 20.000000000000014, 26.30000000000013, 185.0, 20.000000000000014, 141.5, 46.09999999999997, 20.000000000000014, 164.9, 20.000000000000014, 200.0, 17.899999999999988, -11.799999999999818, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 18.0, 0.0, 0.0, 21.0, 0.0, 11.0, 5.0, 0.0, 8.0, 16.0, 6.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 11.0, 0.0, 0.0, 15.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 5.0, 15.0, 1.0, 0.0, 30.0, 18.0, 0.0, 0.0, 10.0, 0.0, 29.0, 17.0, 11.0, 0.0, 4.0, 0.0, 5.0, 53.0, 0.0, 4.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 17.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 1.0, 8.0, 13.0, 0.0, 27.0, 10.0, 15.0, 43.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 3.0, 13.0, 28.0, 45.0, 0.0, 4.0, 0.0, 8.0, 0.0, 0.0, 13.0, 10.0, 63.0, 49.0, 0.0, 13.0, 46.0, 51.0, 19.0, 18.0, 13.0, 0.0, 1.0, 8.0, 0.0, 0.0, 93.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 9.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 8.0, 0.0, 0.0, 2.0, 9.0, 23.0, 11.0, 6.0, 0.0, 0.0, 0.0, 0.0, 16.0, 15.0, 0.0, 4.0, 11.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 9.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 16.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4223454005528857, "mean_inference_ms": 3.856486482817537, "mean_action_processing_ms": 0.8064599183840664, "mean_env_wait_ms": 0.8662253683668051, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007623910903930664, "StateBufferConnector_ms": 0.005631208419799805, "ViewRequirementAgentConnector_ms": 0.466713547706604}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -25.099999999999532, "episode_return_mean": 137.33599999999987, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 175.2556022572823, "num_env_steps_trained_throughput_per_sec": 175.2556022572823, "timesteps_total": 176000, "num_env_steps_sampled_lifetime": 176000, "num_agent_steps_sampled_lifetime": 704000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 704000, "timers": {"training_iteration_time_ms": 18667.184, "restore_workers_time_ms": 0.019, "training_step_time_ms": 18667.126, "sample_time_ms": 4110.759, "learn_time_ms": 14536.429, "learn_throughput": 275.171, "synch_weights_time_ms": 16.649}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 704000, "num_agent_steps_trained": 704000}, "done": false, "training_iteration": 44, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-04-49", "timestamp": 1723521889, "time_this_iter_s": 22.922462224960327, "time_total_s": 760.2180585861206, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2901c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 760.2180585861206, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 89.58125000000001, "ram_util_percent": 83.64375000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4650292251239378, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.1200878051222947, "policy_loss": -0.0015871365655647227, "vf_loss": 1.121633940493619, "vf_explained_var": 0.0022916825360091275, "kl": 0.011662656595916747, "entropy": 1.132047104078626, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4930155870657433, "cur_kl_coeff": 1.8310546874999996e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.35534150814884, "policy_loss": -0.0019094579277816352, "vf_loss": 5.3572509548651475, "vf_explained_var": 0.21325046571474227, "kl": 0.004379039203006258, "entropy": 0.47152901900508415, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 84105.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -47.60000000000028, "episode_reward_mean": 141.96899999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -244.60000000000022, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 122.0}, "policy_reward_mean": {"prey_policy": 62.90449999999997, "predator_policy": 8.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-6.3999999999997375, 306.0, 35.600000000000236, 63.50000000000021, 110.29999999999981, 203.49999999999986, 40.0000000000003, 400.0, 378.0, 40.0000000000003, 50.50000000000044, 187.59999999999923, 221.79999999999927, 80.29999999999927, 4.500000000000194, 128.19999999999973, 147.3999999999996, 204.69999999999933, 102.99999999999994, 38.90000000000028, 130.8999999999989, 40.0000000000003, 219.99999999999926, 32.30000000000018, 16.899999999999945, 84.99999999999889, 329.3, -25.099999999999532, 146.1999999999996, 340.6, 17.99999999999996, 75.50000000000031, 26.300000000000338, 35.600000000000236, 211.1999999999993, 40.0000000000003, 318.3, 65.00000000000006, 374.0, 168.49999999999952, 26.600000000000108, 187.69999999999942, 146.19999999999965, 40.0000000000003, 64.60000000000011, 202.89999999999972, 40.0000000000003, 131.79999999999973, 219.99999999999926, 393.7, 183.89999999999944, 201.09999999999926, 205.99999999999932, 105.6999999999997, 36.70000000000025, 346.00000000000136, 196.2999999999994, 246.09999999999908, 300.0999999999998, 24.60000000000005, 127.49999999999972, 138.5999999999999, 10.200000000000086, 191.3999999999994, 219.99999999999926, 40.0000000000003, 161.5999999999994, 35.600000000000236, 27.90000000000011, 118.49999999999974, 81.40000000000012, 201.99999999999935, 221.29999999999922, 161.49999999999952, 66.10000000000025, 184.89999999999944, 218.89999999999927, 24.200000000000045, 31.20000000000017, 220.5999999999994, 345.0000000000006, 189.19999999999942, 40.0000000000003, -11.699999999999626, 325.29999999999995, 330.70000000000016, 351.0999999999999, 25.70000000000007, -12.599999999999833, 236.99999999999923, 27.900000000000116, 112.89999999999986, 219.99999999999926, 138.09999999999903, 87.30000000000004, -47.60000000000028, 198.49999999999918, 78.79999999999994, 199.99999999999935, 191.9999999999994], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, -59.80000000000017, 148.70000000000007, 146.3, 20.000000000000014, 11.599999999999964, -93.4000000000007, 98.89999999999984, 20.000000000000014, 86.29999999999998, 122.60000000000002, 62.89999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 200.0, 176.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 24.50000000000009, 20.000000000000014, 167.5999999999999, 21.800000000000047, 200.0, 5.299999999999969, 65.00000000000013, -15.699999999999747, 3.1999999999999633, 1.09999999999996, 118.09999999999998, 20.000000000000014, 115.40000000000008, 173.0, 22.700000000000053, 82.99999999999997, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 101.89999999999955, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 7.399999999999965, 17.899999999999984, 3.1999999999999686, -7.299999999999901, -36.69999999999981, 94.69999999999933, 134.3, 170.0, 5.299999999999965, -93.4000000000008, 126.19999999999999, 20.000000000000014, 140.6, 200.0, 20.000000000000014, -21.99999999999975, 20.000000000000014, 39.50000000000018, 27.800000000000168, -74.50000000000027, 20.000000000000014, 11.599999999999964, 3.1999999999999615, 200.0, 20.000000000000014, 20.000000000000014, 126.80000000000004, 168.5, -67.00000000000023, 20.000000000000014, 161.0, 200.0, -74.50000000000081, 146.0, -30.399999999999814, 20.000000000000014, 154.7, 20.000000000000014, 3.1999999999999686, 134.0, 20.000000000000014, 20.000000000000014, 130.09999999999997, -200.50000000000043, 70.39999999999996, 132.4999999999999, 20.000000000000014, 20.000000000000014, 111.79999999999998, 20.000000000000014, 20.000000000000014, 200.0, 193.7, 200.0, 149.9, 20.000000000000014, 1.0999999999999865, 190.99999999999994, 179.0, 20.000000000000014, 20.000000000000014, 85.69999999999987, 13.699999999999964, 20.000000000000014, 145.99999999999966, 200.0, 5.299999999999965, 176.0, 46.10000000000022, 200.0, 100.09999999999998, 200.0, 20.000000000000014, -9.399999999999855, 20.000000000000014, 99.49999999999997, 36.50000000000025, 100.09999999999998, 20.000000000000014, -41.79999999999978, 167.0, 7.399999999999965, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.59999999999998, 29.00000000000018, 11.599999999999966, 20.000000000000014, -3.099999999999958, 20.000000000000014, 90.49999999999997, 20.000000000000014, 20.000000000000014, 61.39999999999996, 173.0, 20.000000000000014, 26.30000000000013, 185.0, 20.000000000000014, 141.5, 46.09999999999997, 20.000000000000014, 164.9, 20.000000000000014, 200.0, 17.899999999999988, -11.799999999999818, 20.000000000000014, 20.000000000000014, 3.1999999999999633, 182.0, 32.599999999999994, 172.99999999999983, 158.0, 167.0, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -78.70000000000083, 20.000000000000014, 125.29999999999998, 200.0, 130.69999999999996, 200.0, 158.6, 186.49999999999991, -0.9999999999999881, 13.699999999999964, -244.60000000000022, 20.000000000000014, 185.0, 47.00000000000019, 20.000000000000014, -3.099999999999972, 20.000000000000014, 92.89999999999998, 20.000000000000014, 200.0, 109.9999999999996, 28.100000000000144, 65.29999999999998, 20.000000000000014, -19.899999999999743, -120.7000000000007, 182.8999999999999, 11.599999999999971, 20.000000000000014, 45.80000000000011, 170.0, 20.000000000000014, -21.999999999999744, 191.0], "policy_predator_policy_reward": [29.0, 17.0, 11.0, 0.0, 4.0, 0.0, 5.0, 53.0, 0.0, 4.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 17.0, 0.0, 0.0, 9.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 6.0, 1.0, 8.0, 13.0, 0.0, 27.0, 10.0, 15.0, 43.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 3.0, 13.0, 28.0, 45.0, 0.0, 4.0, 0.0, 8.0, 0.0, 0.0, 13.0, 10.0, 63.0, 49.0, 0.0, 13.0, 46.0, 51.0, 19.0, 18.0, 13.0, 0.0, 1.0, 8.0, 0.0, 0.0, 93.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 9.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 8.0, 0.0, 0.0, 2.0, 9.0, 23.0, 11.0, 6.0, 0.0, 0.0, 0.0, 0.0, 16.0, 15.0, 0.0, 4.0, 11.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 9.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 16.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 14.0, 8.0, 11.0, 0.0, 0.0, 39.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 10.0, 3.0, 122.0, 90.0, 0.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 26.0, 67.0, 4.0, 0.0, 13.0, 0.0, 10.0, 0.0, 10.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4311539530359159, "mean_inference_ms": 3.886276266848637, "mean_action_processing_ms": 0.8031399428557137, "mean_env_wait_ms": 0.8711897848506709, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007821917533874512, "StateBufferConnector_ms": 0.005798935890197754, "ViewRequirementAgentConnector_ms": 0.5075898170471191}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -47.60000000000028, "episode_return_mean": 141.96899999999982, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 217.50110612738894, "num_env_steps_trained_throughput_per_sec": 217.50110612738894, "timesteps_total": 180000, "num_env_steps_sampled_lifetime": 180000, "num_agent_steps_sampled_lifetime": 720000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 720000, "timers": {"training_iteration_time_ms": 18925.36, "restore_workers_time_ms": 0.021, "training_step_time_ms": 18925.298, "sample_time_ms": 4050.186, "learn_time_ms": 14854.958, "learn_throughput": 269.27, "synch_weights_time_ms": 16.632}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 720000, "num_agent_steps_trained": 720000}, "done": false, "training_iteration": 45, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-05-07", "timestamp": 1723521907, "time_this_iter_s": 18.52618384361267, "time_total_s": 778.7442424297333, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2836040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 778.7442424297333, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 84.6074074074074, "ram_util_percent": 83.54074074074073}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43877656205936716, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.6572626547523277, "policy_loss": -0.0013722456468111546, "vf_loss": 1.6585891476383916, "vf_explained_var": 4.4167924810338904e-05, "kl": 0.01301228500963507, "entropy": 1.0598780042279965, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.9355158786373163, "cur_kl_coeff": 9.155273437499998e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.575436049415952, "policy_loss": -0.0015484782785827678, "vf_loss": 4.576984532295712, "vf_explained_var": 0.1008215811832872, "kl": 0.0070101569387585215, "entropy": 0.5866375498197697, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 85995.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "env_runners": {"episode_reward_max": 393.7, "episode_reward_min": -47.60000000000028, "episode_reward_mean": 141.90199999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -603.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 389.0}, "policy_reward_mean": {"prey_policy": 56.34599999999998, "predator_policy": 14.605}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.30000000000018, 16.899999999999945, 84.99999999999889, 329.3, -25.099999999999532, 146.1999999999996, 340.6, 17.99999999999996, 75.50000000000031, 26.300000000000338, 35.600000000000236, 211.1999999999993, 40.0000000000003, 318.3, 65.00000000000006, 374.0, 168.49999999999952, 26.600000000000108, 187.69999999999942, 146.19999999999965, 40.0000000000003, 64.60000000000011, 202.89999999999972, 40.0000000000003, 131.79999999999973, 219.99999999999926, 393.7, 183.89999999999944, 201.09999999999926, 205.99999999999932, 105.6999999999997, 36.70000000000025, 346.00000000000136, 196.2999999999994, 246.09999999999908, 300.0999999999998, 24.60000000000005, 127.49999999999972, 138.5999999999999, 10.200000000000086, 191.3999999999994, 219.99999999999926, 40.0000000000003, 161.5999999999994, 35.600000000000236, 27.90000000000011, 118.49999999999974, 81.40000000000012, 201.99999999999935, 221.29999999999922, 161.49999999999952, 66.10000000000025, 184.89999999999944, 218.89999999999927, 24.200000000000045, 31.20000000000017, 220.5999999999994, 345.0000000000006, 189.19999999999942, 40.0000000000003, -11.699999999999626, 325.29999999999995, 330.70000000000016, 351.0999999999999, 25.70000000000007, -12.599999999999833, 236.99999999999923, 27.900000000000116, 112.89999999999986, 219.99999999999926, 138.09999999999903, 87.30000000000004, -47.60000000000028, 198.49999999999918, 78.79999999999994, 199.99999999999935, 191.9999999999994, 63.10000000000036, 136.39999999999975, 69.50000000000007, 194.6999999999994, 195.0999999999994, 40.0000000000003, 15.099999999999962, 196.69999999999936, 166.69999999999953, 360.40000000000003, 29.000000000000128, 14.300000000000038, 332.80000000000075, 328.0, 123.69999999999978, 219.99999999999926, 51.60000000000032, 40.0000000000003, 35.600000000000236, 37.500000000000206, 258.7999999999997, 159.0999999999996, 53.50000000000052], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, 17.899999999999984, 3.1999999999999686, -7.299999999999901, -36.69999999999981, 94.69999999999933, 134.3, 170.0, 5.299999999999965, -93.4000000000008, 126.19999999999999, 20.000000000000014, 140.6, 200.0, 20.000000000000014, -21.99999999999975, 20.000000000000014, 39.50000000000018, 27.800000000000168, -74.50000000000027, 20.000000000000014, 11.599999999999964, 3.1999999999999615, 200.0, 20.000000000000014, 20.000000000000014, 126.80000000000004, 168.5, -67.00000000000023, 20.000000000000014, 161.0, 200.0, -74.50000000000081, 146.0, -30.399999999999814, 20.000000000000014, 154.7, 20.000000000000014, 3.1999999999999686, 134.0, 20.000000000000014, 20.000000000000014, 130.09999999999997, -200.50000000000043, 70.39999999999996, 132.4999999999999, 20.000000000000014, 20.000000000000014, 111.79999999999998, 20.000000000000014, 20.000000000000014, 200.0, 193.7, 200.0, 149.9, 20.000000000000014, 1.0999999999999865, 190.99999999999994, 179.0, 20.000000000000014, 20.000000000000014, 85.69999999999987, 13.699999999999964, 20.000000000000014, 145.99999999999966, 200.0, 5.299999999999965, 176.0, 46.10000000000022, 200.0, 100.09999999999998, 200.0, 20.000000000000014, -9.399999999999855, 20.000000000000014, 99.49999999999997, 36.50000000000025, 100.09999999999998, 20.000000000000014, -41.79999999999978, 167.0, 7.399999999999965, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.59999999999998, 29.00000000000018, 11.599999999999966, 20.000000000000014, -3.099999999999958, 20.000000000000014, 90.49999999999997, 20.000000000000014, 20.000000000000014, 61.39999999999996, 173.0, 20.000000000000014, 26.30000000000013, 185.0, 20.000000000000014, 141.5, 46.09999999999997, 20.000000000000014, 164.9, 20.000000000000014, 200.0, 17.899999999999988, -11.799999999999818, 20.000000000000014, 20.000000000000014, 3.1999999999999633, 182.0, 32.599999999999994, 172.99999999999983, 158.0, 167.0, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -78.70000000000083, 20.000000000000014, 125.29999999999998, 200.0, 130.69999999999996, 200.0, 158.6, 186.49999999999991, -0.9999999999999881, 13.699999999999964, -244.60000000000022, 20.000000000000014, 185.0, 47.00000000000019, 20.000000000000014, -3.099999999999972, 20.000000000000014, 92.89999999999998, 20.000000000000014, 200.0, 109.9999999999996, 28.100000000000144, 65.29999999999998, 20.000000000000014, -19.899999999999743, -120.7000000000007, 182.8999999999999, 11.599999999999971, 20.000000000000014, 45.80000000000011, 170.0, 20.000000000000014, -21.999999999999744, 191.0, 20.000000000000014, 37.10000000000015, 114.20000000000007, 3.1999999999999615, 20.000000000000014, 39.500000000000206, -28.29999999999979, 200.0, -19.899999999999743, 194.0, 20.000000000000014, 20.000000000000014, -353.7999999999999, 38.90000000000021, 11.599999999999964, 178.1, 191.0, -70.30000000000078, 200.0, 160.4, 20.000000000000014, -0.9999999999999881, -0.9999999999999846, 5.299999999999965, 191.0, 138.7999999999998, -603.5, 159.49999999999974, 103.69999999999997, 20.000000000000014, 20.000000000000014, 200.0, 9.499999999999964, 37.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999966, -261.3999999999999, 50.90000000000017, 173.6, 81.19999999999996, 21.80000000000004, 134.29999999999998, 20.000000000000014, 33.50000000000024], "policy_predator_policy_reward": [6.0, 1.0, 8.0, 13.0, 0.0, 27.0, 10.0, 15.0, 43.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 20.0, 3.0, 13.0, 28.0, 45.0, 0.0, 4.0, 0.0, 8.0, 0.0, 0.0, 13.0, 10.0, 63.0, 49.0, 0.0, 13.0, 46.0, 51.0, 19.0, 18.0, 13.0, 0.0, 1.0, 8.0, 0.0, 0.0, 93.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 9.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 8.0, 0.0, 0.0, 2.0, 9.0, 23.0, 11.0, 6.0, 0.0, 0.0, 0.0, 0.0, 16.0, 15.0, 0.0, 4.0, 11.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 9.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 16.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 14.0, 8.0, 11.0, 0.0, 0.0, 39.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 10.0, 3.0, 122.0, 90.0, 0.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 26.0, 67.0, 4.0, 0.0, 13.0, 0.0, 10.0, 0.0, 10.0, 13.0, 6.0, 0.0, 19.0, 0.0, 10.0, 0.0, 23.0, 0.0, 2.0, 19.0, 0.0, 0.0, 153.0, 177.0, 0.0, 7.0, 24.0, 22.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 3.0, 389.0, 383.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 0.0, 133.0, 115.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4360691595808905, "mean_inference_ms": 3.9011081107400365, "mean_action_processing_ms": 0.7960021221100964, "mean_env_wait_ms": 0.871687298456495, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0060242414474487305, "StateBufferConnector_ms": 0.005199313163757324, "ViewRequirementAgentConnector_ms": 0.3676968812942505}, "num_episodes": 23, "episode_return_max": 393.7, "episode_return_min": -47.60000000000028, "episode_return_mean": 141.90199999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 187.58131106858934, "num_env_steps_trained_throughput_per_sec": 187.58131106858934, "timesteps_total": 184000, "num_env_steps_sampled_lifetime": 184000, "num_agent_steps_sampled_lifetime": 736000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 736000, "timers": {"training_iteration_time_ms": 19047.911, "restore_workers_time_ms": 0.023, "training_step_time_ms": 19047.846, "sample_time_ms": 4100.979, "learn_time_ms": 14924.527, "learn_throughput": 268.015, "synch_weights_time_ms": 18.87}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 736000, "num_agent_steps_trained": 736000}, "done": false, "training_iteration": 46, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-05-29", "timestamp": 1723521929, "time_this_iter_s": 21.443310022354126, "time_total_s": 800.1875524520874, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28e0af0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 800.1875524520874, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 89.54999999999998, "ram_util_percent": 83.65666666666665}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3426804001507147, "cur_kl_coeff": 0.003515625000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.403717259857705, "policy_loss": 8.468468865704914e-05, "vf_loss": 0.4036170592791494, "vf_explained_var": 0.002735764986623532, "kl": 0.004413307993079425, "entropy": 0.9961447388091416, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2837593065131276, "cur_kl_coeff": 9.155273437499998e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.431272088409101, "policy_loss": -0.0016020253432480983, "vf_loss": 3.4328741047117446, "vf_explained_var": 0.3048184078206461, "kl": 0.0076810830901407655, "entropy": 0.5231734296474507, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 87885.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -47.60000000000028, "episode_reward_mean": 143.15099999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -603.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 389.0}, "policy_reward_mean": {"prey_policy": 58.72049999999997, "predator_policy": 12.855}, "custom_metrics": {}, "hist_stats": {"episode_reward": [187.69999999999942, 146.19999999999965, 40.0000000000003, 64.60000000000011, 202.89999999999972, 40.0000000000003, 131.79999999999973, 219.99999999999926, 393.7, 183.89999999999944, 201.09999999999926, 205.99999999999932, 105.6999999999997, 36.70000000000025, 346.00000000000136, 196.2999999999994, 246.09999999999908, 300.0999999999998, 24.60000000000005, 127.49999999999972, 138.5999999999999, 10.200000000000086, 191.3999999999994, 219.99999999999926, 40.0000000000003, 161.5999999999994, 35.600000000000236, 27.90000000000011, 118.49999999999974, 81.40000000000012, 201.99999999999935, 221.29999999999922, 161.49999999999952, 66.10000000000025, 184.89999999999944, 218.89999999999927, 24.200000000000045, 31.20000000000017, 220.5999999999994, 345.0000000000006, 189.19999999999942, 40.0000000000003, -11.699999999999626, 325.29999999999995, 330.70000000000016, 351.0999999999999, 25.70000000000007, -12.599999999999833, 236.99999999999923, 27.900000000000116, 112.89999999999986, 219.99999999999926, 138.09999999999903, 87.30000000000004, -47.60000000000028, 198.49999999999918, 78.79999999999994, 199.99999999999935, 191.9999999999994, 63.10000000000036, 136.39999999999975, 69.50000000000007, 194.6999999999994, 195.0999999999994, 40.0000000000003, 15.099999999999962, 196.69999999999936, 166.69999999999953, 360.40000000000003, 29.000000000000128, 14.300000000000038, 332.80000000000075, 328.0, 123.69999999999978, 219.99999999999926, 51.60000000000032, 40.0000000000003, 35.600000000000236, 37.500000000000206, 258.7999999999997, 159.0999999999996, 53.50000000000052, 54.40000000000052, 27.90000000000011, 104.39999999999856, 184.09999999999943, 400.0, 219.99999999999926, 179.89999999999947, 201.99999999999935, 173.7999999999995, 203.99999999999935, 130.6999999999987, 91.29999999999852, 155.19999999999956, -8.399999999999709, 26.900000000000087, 40.0000000000003, 2.90000000000018, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [154.7, 20.000000000000014, 3.1999999999999686, 134.0, 20.000000000000014, 20.000000000000014, 130.09999999999997, -200.50000000000043, 70.39999999999996, 132.4999999999999, 20.000000000000014, 20.000000000000014, 111.79999999999998, 20.000000000000014, 20.000000000000014, 200.0, 193.7, 200.0, 149.9, 20.000000000000014, 1.0999999999999865, 190.99999999999994, 179.0, 20.000000000000014, 20.000000000000014, 85.69999999999987, 13.699999999999964, 20.000000000000014, 145.99999999999966, 200.0, 5.299999999999965, 176.0, 46.10000000000022, 200.0, 100.09999999999998, 200.0, 20.000000000000014, -9.399999999999855, 20.000000000000014, 99.49999999999997, 36.50000000000025, 100.09999999999998, 20.000000000000014, -41.79999999999978, 167.0, 7.399999999999965, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.59999999999998, 29.00000000000018, 11.599999999999966, 20.000000000000014, -3.099999999999958, 20.000000000000014, 90.49999999999997, 20.000000000000014, 20.000000000000014, 61.39999999999996, 173.0, 20.000000000000014, 26.30000000000013, 185.0, 20.000000000000014, 141.5, 46.09999999999997, 20.000000000000014, 164.9, 20.000000000000014, 200.0, 17.899999999999988, -11.799999999999818, 20.000000000000014, 20.000000000000014, 3.1999999999999633, 182.0, 32.599999999999994, 172.99999999999983, 158.0, 167.0, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -78.70000000000083, 20.000000000000014, 125.29999999999998, 200.0, 130.69999999999996, 200.0, 158.6, 186.49999999999991, -0.9999999999999881, 13.699999999999964, -244.60000000000022, 20.000000000000014, 185.0, 47.00000000000019, 20.000000000000014, -3.099999999999972, 20.000000000000014, 92.89999999999998, 20.000000000000014, 200.0, 109.9999999999996, 28.100000000000144, 65.29999999999998, 20.000000000000014, -19.899999999999743, -120.7000000000007, 182.8999999999999, 11.599999999999971, 20.000000000000014, 45.80000000000011, 170.0, 20.000000000000014, -21.999999999999744, 191.0, 20.000000000000014, 37.10000000000015, 114.20000000000007, 3.1999999999999615, 20.000000000000014, 39.500000000000206, -28.29999999999979, 200.0, -19.899999999999743, 194.0, 20.000000000000014, 20.000000000000014, -353.7999999999999, 38.90000000000021, 11.599999999999964, 178.1, 191.0, -70.30000000000078, 200.0, 160.4, 20.000000000000014, -0.9999999999999881, -0.9999999999999846, 5.299999999999965, 191.0, 138.7999999999998, -603.5, 159.49999999999974, 103.69999999999997, 20.000000000000014, 20.000000000000014, 200.0, 9.499999999999964, 37.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999966, -261.3999999999999, 50.90000000000017, 173.6, 81.19999999999996, 21.80000000000004, 134.29999999999998, 20.000000000000014, 33.50000000000024, 20.000000000000014, 34.40000000000026, 20.000000000000014, -3.0999999999999615, 82.3999999999993, 20.000000000000014, 160.1, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, 21.80000000000004, 142.1, 173.0, 20.000000000000014, 200.0, -68.20000000000086, 20.000000000000014, 176.0, 20.000000000000014, 109.69999999999945, 71.29999999999968, 20.000000000000014, 20.000000000000014, 135.2, 20.000000000000014, -72.4000000000008, 17.899999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -55.600000000000136, 9.499999999999968, 20.000000000000014, 200.0], "policy_predator_policy_reward": [13.0, 0.0, 1.0, 8.0, 0.0, 0.0, 93.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 9.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 8.0, 0.0, 0.0, 2.0, 9.0, 23.0, 11.0, 6.0, 0.0, 0.0, 0.0, 0.0, 16.0, 15.0, 0.0, 4.0, 11.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 9.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 16.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 14.0, 8.0, 11.0, 0.0, 0.0, 39.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 10.0, 3.0, 122.0, 90.0, 0.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 26.0, 67.0, 4.0, 0.0, 13.0, 0.0, 10.0, 0.0, 10.0, 13.0, 6.0, 0.0, 19.0, 0.0, 10.0, 0.0, 23.0, 0.0, 2.0, 19.0, 0.0, 0.0, 153.0, 177.0, 0.0, 7.0, 24.0, 22.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 3.0, 389.0, 383.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 0.0, 133.0, 115.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 9.0, 37.0, 5.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 10.0, 0.0, 0.0, 0.0, 31.0, 18.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.441046470136061, "mean_inference_ms": 3.9167110404527876, "mean_action_processing_ms": 0.7918740031546853, "mean_env_wait_ms": 0.8731180884392552, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007709026336669922, "StateBufferConnector_ms": 0.007513523101806641, "ViewRequirementAgentConnector_ms": 0.43324124813079834}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -47.60000000000028, "episode_return_mean": 143.15099999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 167.35314788245782, "num_env_steps_trained_throughput_per_sec": 167.35314788245782, "timesteps_total": 188000, "num_env_steps_sampled_lifetime": 188000, "num_agent_steps_sampled_lifetime": 752000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 752000, "timers": {"training_iteration_time_ms": 19689.127, "restore_workers_time_ms": 0.028, "training_step_time_ms": 19689.057, "sample_time_ms": 4006.144, "learn_time_ms": 15660.929, "learn_throughput": 255.413, "synch_weights_time_ms": 18.546}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 752000, "num_agent_steps_trained": 752000}, "done": false, "training_iteration": 47, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-05-53", "timestamp": 1723521953, "time_this_iter_s": 24.011737823486328, "time_total_s": 824.1992902755737, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x330dc5670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 824.1992902755737, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 89.58787878787881, "ram_util_percent": 83.6818181818182}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3956645770451773, "cur_kl_coeff": 0.0017578125000000005, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2857149102503345, "policy_loss": -0.0008263133128700906, "vf_loss": 0.28653088512389413, "vf_explained_var": 0.038762475195385164, "kl": 0.005881183586550169, "entropy": 1.02018957623729, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7197670060372543, "cur_kl_coeff": 9.155273437499998e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.241134904301355, "policy_loss": -0.0010739364021916, "vf_loss": 4.242208841742662, "vf_explained_var": 0.338078575537949, "kl": 0.00263480149871722, "entropy": 0.47267127989461183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 89775.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -47.60000000000028, "episode_reward_mean": 137.6839999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -603.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 389.0}, "policy_reward_mean": {"prey_policy": 56.35199999999998, "predator_policy": 12.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.60000000000005, 127.49999999999972, 138.5999999999999, 10.200000000000086, 191.3999999999994, 219.99999999999926, 40.0000000000003, 161.5999999999994, 35.600000000000236, 27.90000000000011, 118.49999999999974, 81.40000000000012, 201.99999999999935, 221.29999999999922, 161.49999999999952, 66.10000000000025, 184.89999999999944, 218.89999999999927, 24.200000000000045, 31.20000000000017, 220.5999999999994, 345.0000000000006, 189.19999999999942, 40.0000000000003, -11.699999999999626, 325.29999999999995, 330.70000000000016, 351.0999999999999, 25.70000000000007, -12.599999999999833, 236.99999999999923, 27.900000000000116, 112.89999999999986, 219.99999999999926, 138.09999999999903, 87.30000000000004, -47.60000000000028, 198.49999999999918, 78.79999999999994, 199.99999999999935, 191.9999999999994, 63.10000000000036, 136.39999999999975, 69.50000000000007, 194.6999999999994, 195.0999999999994, 40.0000000000003, 15.099999999999962, 196.69999999999936, 166.69999999999953, 360.40000000000003, 29.000000000000128, 14.300000000000038, 332.80000000000075, 328.0, 123.69999999999978, 219.99999999999926, 51.60000000000032, 40.0000000000003, 35.600000000000236, 37.500000000000206, 258.7999999999997, 159.0999999999996, 53.50000000000052, 54.40000000000052, 27.90000000000011, 104.39999999999856, 184.09999999999943, 400.0, 219.99999999999926, 179.89999999999947, 201.99999999999935, 173.7999999999995, 203.99999999999935, 130.6999999999987, 91.29999999999852, 155.19999999999956, -8.399999999999709, 26.900000000000087, 40.0000000000003, 2.90000000000018, 219.99999999999926, 14.699999999999937, 205.99999999999932, 219.99999999999926, 161.39999999999955, 48.700000000000024, 84.59999999999893, 40.0000000000003, 24.600000000000055, 235.29999999999916, 233.09999999999914, 263.49999999999955, 33.400000000000205, 335.20000000000164, 25.70000000000007, 175.49999999999946, 219.99999999999926, 180.39999999999944, 199.99999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, -9.399999999999855, 20.000000000000014, 99.49999999999997, 36.50000000000025, 100.09999999999998, 20.000000000000014, -41.79999999999978, 167.0, 7.399999999999965, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 101.59999999999998, 29.00000000000018, 11.599999999999966, 20.000000000000014, -3.099999999999958, 20.000000000000014, 90.49999999999997, 20.000000000000014, 20.000000000000014, 61.39999999999996, 173.0, 20.000000000000014, 26.30000000000013, 185.0, 20.000000000000014, 141.5, 46.09999999999997, 20.000000000000014, 164.9, 20.000000000000014, 200.0, 17.899999999999988, -11.799999999999818, 20.000000000000014, 20.000000000000014, 3.1999999999999633, 182.0, 32.599999999999994, 172.99999999999983, 158.0, 167.0, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -78.70000000000083, 20.000000000000014, 125.29999999999998, 200.0, 130.69999999999996, 200.0, 158.6, 186.49999999999991, -0.9999999999999881, 13.699999999999964, -244.60000000000022, 20.000000000000014, 185.0, 47.00000000000019, 20.000000000000014, -3.099999999999972, 20.000000000000014, 92.89999999999998, 20.000000000000014, 200.0, 109.9999999999996, 28.100000000000144, 65.29999999999998, 20.000000000000014, -19.899999999999743, -120.7000000000007, 182.8999999999999, 11.599999999999971, 20.000000000000014, 45.80000000000011, 170.0, 20.000000000000014, -21.999999999999744, 191.0, 20.000000000000014, 37.10000000000015, 114.20000000000007, 3.1999999999999615, 20.000000000000014, 39.500000000000206, -28.29999999999979, 200.0, -19.899999999999743, 194.0, 20.000000000000014, 20.000000000000014, -353.7999999999999, 38.90000000000021, 11.599999999999964, 178.1, 191.0, -70.30000000000078, 200.0, 160.4, 20.000000000000014, -0.9999999999999881, -0.9999999999999846, 5.299999999999965, 191.0, 138.7999999999998, -603.5, 159.49999999999974, 103.69999999999997, 20.000000000000014, 20.000000000000014, 200.0, 9.499999999999964, 37.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999966, -261.3999999999999, 50.90000000000017, 173.6, 81.19999999999996, 21.80000000000004, 134.29999999999998, 20.000000000000014, 33.50000000000024, 20.000000000000014, 34.40000000000026, 20.000000000000014, -3.0999999999999615, 82.3999999999993, 20.000000000000014, 160.1, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, 21.80000000000004, 142.1, 173.0, 20.000000000000014, 200.0, -68.20000000000086, 20.000000000000014, 176.0, 20.000000000000014, 109.69999999999945, 71.29999999999968, 20.000000000000014, 20.000000000000014, 135.2, 20.000000000000014, -72.4000000000008, 17.899999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -55.600000000000136, 9.499999999999968, 20.000000000000014, 200.0, 20.000000000000014, -28.299999999999777, 179.0, 20.000000000000014, 20.000000000000014, 200.0, -1.0000000000000346, 151.4, 20.000000000000014, 4.700000000000195, 66.79999999999997, 15.799999999999963, 20.000000000000014, 20.000000000000014, -5.199999999999937, 15.799999999999963, 200.0, 35.30000000000026, 49.10000000000023, 176.0, 96.49999999999935, 164.0, 20.000000000000014, 7.399999999999965, 159.49999999999974, 175.69999999999985, -7.299999999999891, 20.000000000000014, 144.50000000000003, 20.000000000000014, 20.000000000000014, 200.0, 160.4, 20.000000000000014, 170.0, 20.000000000000014], "policy_predator_policy_reward": [14.0, 0.0, 8.0, 0.0, 0.0, 2.0, 9.0, 23.0, 11.0, 6.0, 0.0, 0.0, 0.0, 0.0, 16.0, 15.0, 0.0, 4.0, 11.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 9.0, 5.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 16.0, 0.0, 8.0, 0.0, 6.0, 0.0, 0.0, 14.0, 8.0, 11.0, 0.0, 0.0, 39.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 10.0, 3.0, 122.0, 90.0, 0.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 26.0, 67.0, 4.0, 0.0, 13.0, 0.0, 10.0, 0.0, 10.0, 13.0, 6.0, 0.0, 19.0, 0.0, 10.0, 0.0, 23.0, 0.0, 2.0, 19.0, 0.0, 0.0, 153.0, 177.0, 0.0, 7.0, 24.0, 22.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 3.0, 389.0, 383.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 0.0, 133.0, 115.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 9.0, 37.0, 5.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 10.0, 0.0, 0.0, 0.0, 31.0, 18.0, 0.0, 0.0, 23.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 9.0, 12.0, 12.0, 0.0, 2.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 13.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4458176202843327, "mean_inference_ms": 3.934145264867871, "mean_action_processing_ms": 0.788596975052349, "mean_env_wait_ms": 0.874805755896025, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01076197624206543, "StateBufferConnector_ms": 0.01433098316192627, "ViewRequirementAgentConnector_ms": 0.40843796730041504}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -47.60000000000028, "episode_return_mean": 137.6839999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 207.94165264821012, "num_env_steps_trained_throughput_per_sec": 207.94165264821012, "timesteps_total": 192000, "num_env_steps_sampled_lifetime": 192000, "num_agent_steps_sampled_lifetime": 768000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 768000, "timers": {"training_iteration_time_ms": 19900.286, "restore_workers_time_ms": 0.029, "training_step_time_ms": 19900.216, "sample_time_ms": 4116.947, "learn_time_ms": 15763.038, "learn_throughput": 253.758, "synch_weights_time_ms": 17.627}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 768000, "num_agent_steps_trained": 768000}, "done": false, "training_iteration": 48, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-06-12", "timestamp": 1723521972, "time_this_iter_s": 19.286525011062622, "time_total_s": 843.4858152866364, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28dbf70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 843.4858152866364, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 87.73703703703706, "ram_util_percent": 83.55185185185185}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3890642366396687, "cur_kl_coeff": 0.0017578125000000005, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2880026510547078, "policy_loss": -0.0019195472195783936, "vf_loss": 0.28989885485468975, "vf_explained_var": -0.003615378261243225, "kl": 0.013279342886598502, "entropy": 0.974307068220522, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.352790754252956, "cur_kl_coeff": 4.577636718749999e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.049365769618403, "policy_loss": -0.0012253096070948732, "vf_loss": 4.050591070059116, "vf_explained_var": 0.3919226593126065, "kl": 0.006153594118674389, "entropy": 0.579802346781448, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 91665.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -47.60000000000028, "episode_reward_mean": 145.16999999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -603.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 389.0}, "policy_reward_mean": {"prey_policy": 60.28499999999996, "predator_policy": 12.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [189.19999999999942, 40.0000000000003, -11.699999999999626, 325.29999999999995, 330.70000000000016, 351.0999999999999, 25.70000000000007, -12.599999999999833, 236.99999999999923, 27.900000000000116, 112.89999999999986, 219.99999999999926, 138.09999999999903, 87.30000000000004, -47.60000000000028, 198.49999999999918, 78.79999999999994, 199.99999999999935, 191.9999999999994, 63.10000000000036, 136.39999999999975, 69.50000000000007, 194.6999999999994, 195.0999999999994, 40.0000000000003, 15.099999999999962, 196.69999999999936, 166.69999999999953, 360.40000000000003, 29.000000000000128, 14.300000000000038, 332.80000000000075, 328.0, 123.69999999999978, 219.99999999999926, 51.60000000000032, 40.0000000000003, 35.600000000000236, 37.500000000000206, 258.7999999999997, 159.0999999999996, 53.50000000000052, 54.40000000000052, 27.90000000000011, 104.39999999999856, 184.09999999999943, 400.0, 219.99999999999926, 179.89999999999947, 201.99999999999935, 173.7999999999995, 203.99999999999935, 130.6999999999987, 91.29999999999852, 155.19999999999956, -8.399999999999709, 26.900000000000087, 40.0000000000003, 2.90000000000018, 219.99999999999926, 14.699999999999937, 205.99999999999932, 219.99999999999926, 161.39999999999955, 48.700000000000024, 84.59999999999893, 40.0000000000003, 24.600000000000055, 235.29999999999916, 233.09999999999914, 263.49999999999955, 33.400000000000205, 335.20000000000164, 25.70000000000007, 175.49999999999946, 219.99999999999926, 180.39999999999944, 199.99999999999935, 40.0000000000003, 219.99999999999926, 40.0000000000003, 106.59999999999854, 198.29999999999936, 195.99999999999937, 275.7999999999996, 162.3999999999989, 78.70000000000014, 315.1, 218.89999999999927, 34.50000000000022, 201.99999999999935, 191.9999999999994, 329.30000000000143, 205.99999999999932, 174.8999999999995, 249.49999999999906, 76.9, 27.900000000000098, 36.80000000000031, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [167.0, 3.1999999999999615, 20.000000000000014, 20.000000000000014, -78.70000000000083, 20.000000000000014, 125.29999999999998, 200.0, 130.69999999999996, 200.0, 158.6, 186.49999999999991, -0.9999999999999881, 13.699999999999964, -244.60000000000022, 20.000000000000014, 185.0, 47.00000000000019, 20.000000000000014, -3.099999999999972, 20.000000000000014, 92.89999999999998, 20.000000000000014, 200.0, 109.9999999999996, 28.100000000000144, 65.29999999999998, 20.000000000000014, -19.899999999999743, -120.7000000000007, 182.8999999999999, 11.599999999999971, 20.000000000000014, 45.80000000000011, 170.0, 20.000000000000014, -21.999999999999744, 191.0, 20.000000000000014, 37.10000000000015, 114.20000000000007, 3.1999999999999615, 20.000000000000014, 39.500000000000206, -28.29999999999979, 200.0, -19.899999999999743, 194.0, 20.000000000000014, 20.000000000000014, -353.7999999999999, 38.90000000000021, 11.599999999999964, 178.1, 191.0, -70.30000000000078, 200.0, 160.4, 20.000000000000014, -0.9999999999999881, -0.9999999999999846, 5.299999999999965, 191.0, 138.7999999999998, -603.5, 159.49999999999974, 103.69999999999997, 20.000000000000014, 20.000000000000014, 200.0, 9.499999999999964, 37.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999966, -261.3999999999999, 50.90000000000017, 173.6, 81.19999999999996, 21.80000000000004, 134.29999999999998, 20.000000000000014, 33.50000000000024, 20.000000000000014, 34.40000000000026, 20.000000000000014, -3.0999999999999615, 82.3999999999993, 20.000000000000014, 160.1, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, 21.80000000000004, 142.1, 173.0, 20.000000000000014, 200.0, -68.20000000000086, 20.000000000000014, 176.0, 20.000000000000014, 109.69999999999945, 71.29999999999968, 20.000000000000014, 20.000000000000014, 135.2, 20.000000000000014, -72.4000000000008, 17.899999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -55.600000000000136, 9.499999999999968, 20.000000000000014, 200.0, 20.000000000000014, -28.299999999999777, 179.0, 20.000000000000014, 20.000000000000014, 200.0, -1.0000000000000346, 151.4, 20.000000000000014, 4.700000000000195, 66.79999999999997, 15.799999999999963, 20.000000000000014, 20.000000000000014, -5.199999999999937, 15.799999999999963, 200.0, 35.30000000000026, 49.10000000000023, 176.0, 96.49999999999935, 164.0, 20.000000000000014, 7.399999999999965, 159.49999999999974, 175.69999999999985, -7.299999999999891, 20.000000000000014, 144.50000000000003, 20.000000000000014, 20.000000000000014, 200.0, 160.4, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 86.59999999999928, 7.399999999999965, 182.9, 20.000000000000014, 164.0, 200.0, 75.79999999999997, 142.39999999999964, 20.000000000000014, 20.000000000000014, 58.69999999999996, 136.10000000000002, 158.0, 17.899999999999988, 200.0, 9.499999999999964, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 158.0, 200.0, 122.29999999999964, 20.000000000000014, 179.0, 9.499999999999964, 160.4, 51.500000000000234, 197.0, 47.89999999999997, 20.000000000000014, 20.000000000000014, -3.100000000000047, -26.20000000000053, 20.000000000000014, 200.0, 20.000000000000014], "policy_predator_policy_reward": [8.0, 11.0, 0.0, 0.0, 39.0, 8.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 10.0, 3.0, 122.0, 90.0, 0.0, 5.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 26.0, 67.0, 4.0, 0.0, 13.0, 0.0, 10.0, 0.0, 10.0, 13.0, 6.0, 0.0, 19.0, 0.0, 10.0, 0.0, 23.0, 0.0, 2.0, 19.0, 0.0, 0.0, 153.0, 177.0, 0.0, 7.0, 24.0, 22.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 3.0, 389.0, 383.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 0.0, 133.0, 115.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 9.0, 37.0, 5.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 10.0, 0.0, 0.0, 0.0, 31.0, 18.0, 0.0, 0.0, 23.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 9.0, 12.0, 12.0, 0.0, 2.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 13.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 12.0, 0.0, 1.0, 5.0, 0.0, 0.0, 9.0, 14.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 5.0, 1.0, 0.0, 7.0, 2.0, 0.0, 11.0, 43.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4402936492179441, "mean_inference_ms": 3.931773922614548, "mean_action_processing_ms": 0.7803398550276702, "mean_env_wait_ms": 0.8705418909639263, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01167905330657959, "StateBufferConnector_ms": 0.014316797256469727, "ViewRequirementAgentConnector_ms": 0.2952307462692261}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -47.60000000000028, "episode_return_mean": 145.16999999999976, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 236.23479061864964, "num_env_steps_trained_throughput_per_sec": 236.23479061864964, "timesteps_total": 196000, "num_env_steps_sampled_lifetime": 196000, "num_agent_steps_sampled_lifetime": 784000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 784000, "timers": {"training_iteration_time_ms": 19886.012, "restore_workers_time_ms": 0.027, "training_step_time_ms": 19885.944, "sample_time_ms": 4088.814, "learn_time_ms": 15777.017, "learn_throughput": 253.533, "synch_weights_time_ms": 17.558}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 784000, "num_agent_steps_trained": 784000}, "done": false, "training_iteration": 49, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-06-29", "timestamp": 1723521989, "time_this_iter_s": 17.003439903259277, "time_total_s": 860.4892551898956, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4da2790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 860.4892551898956, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 80.87083333333334, "ram_util_percent": 83.44583333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.43210710163016325, "cur_kl_coeff": 0.0017578125000000005, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2325334458794228, "policy_loss": -0.0013087805836072201, "vf_loss": 0.2338347212363342, "vf_explained_var": -0.021772940669740948, "kl": 0.004269485761909739, "entropy": 0.979666253561696, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.149699496718311, "cur_kl_coeff": 4.577636718749999e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.678926206518103, "policy_loss": 0.00021150738577402773, "vf_loss": 4.678714697323148, "vf_explained_var": 0.4172768086037308, "kl": 0.0018085007032917178, "entropy": 0.588626479613718, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 93555.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -8.399999999999709, "episode_reward_mean": 150.4749999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -603.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 389.0}, "policy_reward_mean": {"prey_policy": 64.77749999999997, "predator_policy": 10.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [195.0999999999994, 40.0000000000003, 15.099999999999962, 196.69999999999936, 166.69999999999953, 360.40000000000003, 29.000000000000128, 14.300000000000038, 332.80000000000075, 328.0, 123.69999999999978, 219.99999999999926, 51.60000000000032, 40.0000000000003, 35.600000000000236, 37.500000000000206, 258.7999999999997, 159.0999999999996, 53.50000000000052, 54.40000000000052, 27.90000000000011, 104.39999999999856, 184.09999999999943, 400.0, 219.99999999999926, 179.89999999999947, 201.99999999999935, 173.7999999999995, 203.99999999999935, 130.6999999999987, 91.29999999999852, 155.19999999999956, -8.399999999999709, 26.900000000000087, 40.0000000000003, 2.90000000000018, 219.99999999999926, 14.699999999999937, 205.99999999999932, 219.99999999999926, 161.39999999999955, 48.700000000000024, 84.59999999999893, 40.0000000000003, 24.600000000000055, 235.29999999999916, 233.09999999999914, 263.49999999999955, 33.400000000000205, 335.20000000000164, 25.70000000000007, 175.49999999999946, 219.99999999999926, 180.39999999999944, 199.99999999999935, 40.0000000000003, 219.99999999999926, 40.0000000000003, 106.59999999999854, 198.29999999999936, 195.99999999999937, 275.7999999999996, 162.3999999999989, 78.70000000000014, 315.1, 218.89999999999927, 34.50000000000022, 201.99999999999935, 191.9999999999994, 329.30000000000143, 205.99999999999932, 174.8999999999995, 249.49999999999906, 76.9, 27.900000000000098, 36.80000000000031, 219.99999999999926, 97.6, 86.7999999999999, 199.99999999999937, 302.7000000000006, 140.99999999999966, 282.1, 219.99999999999926, 334.29999999999995, 19.099999999999973, 302.8000000000006, 40.0000000000003, 207.39999999999918, 366.0, 40.0000000000003, 197.99999999999937, 22.400000000000038, 168.6999999999995, 10.000000000000039, 67.90000000000019, 137.19999999999982, 209.9999999999993, 179.39999999999947, 43.40000000000035], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-19.899999999999743, 194.0, 20.000000000000014, 20.000000000000014, -353.7999999999999, 38.90000000000021, 11.599999999999964, 178.1, 191.0, -70.30000000000078, 200.0, 160.4, 20.000000000000014, -0.9999999999999881, -0.9999999999999846, 5.299999999999965, 191.0, 138.7999999999998, -603.5, 159.49999999999974, 103.69999999999997, 20.000000000000014, 20.000000000000014, 200.0, 9.499999999999964, 37.10000000000015, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999966, -261.3999999999999, 50.90000000000017, 173.6, 81.19999999999996, 21.80000000000004, 134.29999999999998, 20.000000000000014, 33.50000000000024, 20.000000000000014, 34.40000000000026, 20.000000000000014, -3.0999999999999615, 82.3999999999993, 20.000000000000014, 160.1, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, 21.80000000000004, 142.1, 173.0, 20.000000000000014, 200.0, -68.20000000000086, 20.000000000000014, 176.0, 20.000000000000014, 109.69999999999945, 71.29999999999968, 20.000000000000014, 20.000000000000014, 135.2, 20.000000000000014, -72.4000000000008, 17.899999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -55.600000000000136, 9.499999999999968, 20.000000000000014, 200.0, 20.000000000000014, -28.299999999999777, 179.0, 20.000000000000014, 20.000000000000014, 200.0, -1.0000000000000346, 151.4, 20.000000000000014, 4.700000000000195, 66.79999999999997, 15.799999999999963, 20.000000000000014, 20.000000000000014, -5.199999999999937, 15.799999999999963, 200.0, 35.30000000000026, 49.10000000000023, 176.0, 96.49999999999935, 164.0, 20.000000000000014, 7.399999999999965, 159.49999999999974, 175.69999999999985, -7.299999999999891, 20.000000000000014, 144.50000000000003, 20.000000000000014, 20.000000000000014, 200.0, 160.4, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 86.59999999999928, 7.399999999999965, 182.9, 20.000000000000014, 164.0, 200.0, 75.79999999999997, 142.39999999999964, 20.000000000000014, 20.000000000000014, 58.69999999999996, 136.10000000000002, 158.0, 17.899999999999988, 200.0, 9.499999999999964, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 158.0, 200.0, 122.29999999999964, 20.000000000000014, 179.0, 9.499999999999964, 160.4, 51.500000000000234, 197.0, 47.89999999999997, 20.000000000000014, 20.000000000000014, -3.100000000000047, -26.20000000000053, 20.000000000000014, 200.0, 20.000000000000014, 77.59999999999997, 20.000000000000014, -17.79999999999975, 86.59999999999997, 170.0, 20.000000000000014, 97.69999999999945, 200.0, 112.99999999999997, 20.000000000000014, 181.1, 100.99999999999943, 20.000000000000014, 200.0, 200.0, 134.29999999999998, 20.000000000000014, -19.899999999999785, 102.79999999999939, 200.0, 20.000000000000014, 20.000000000000014, 187.39999999999992, 20.000000000000014, 200.0, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, -13.599999999999818, 20.000000000000014, 148.7, 20.000000000000014, -42.999999999999766, 20.000000000000014, 47.900000000000226, 28.100000000000147, 109.09999999999998, 185.0, 20.000000000000014, -9.399999999999855, 174.8, 22.40000000000005, 20.000000000000014], "policy_predator_policy_reward": [2.0, 19.0, 0.0, 0.0, 153.0, 177.0, 0.0, 7.0, 24.0, 22.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 3.0, 389.0, 383.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 4.0, 0.0, 133.0, 115.0, 4.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 9.0, 37.0, 5.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 10.0, 0.0, 0.0, 0.0, 31.0, 18.0, 0.0, 0.0, 23.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 9.0, 12.0, 12.0, 0.0, 2.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 13.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 12.0, 0.0, 1.0, 5.0, 0.0, 0.0, 9.0, 14.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 5.0, 1.0, 0.0, 7.0, 2.0, 0.0, 11.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 10.0, 0.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 16.0, 0.0, 0.0, 12.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 14.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.442363185691754, "mean_inference_ms": 3.953866876309165, "mean_action_processing_ms": 0.7880275037759386, "mean_env_wait_ms": 0.8713781351614632, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011765122413635254, "StateBufferConnector_ms": 0.013300538063049316, "ViewRequirementAgentConnector_ms": 0.2485278844833374}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -8.399999999999709, "episode_return_mean": 150.4749999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 257.1488198864998, "num_env_steps_trained_throughput_per_sec": 257.1488198864998, "timesteps_total": 200000, "num_env_steps_sampled_lifetime": 200000, "num_agent_steps_sampled_lifetime": 800000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 800000, "timers": {"training_iteration_time_ms": 19365.24, "restore_workers_time_ms": 0.027, "training_step_time_ms": 19365.154, "sample_time_ms": 4121.186, "learn_time_ms": 15223.306, "learn_throughput": 262.755, "synch_weights_time_ms": 18.291}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 800000, "num_agent_steps_trained": 800000}, "done": false, "training_iteration": 50, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-06-45", "timestamp": 1723522005, "time_this_iter_s": 15.608277082443237, "time_total_s": 876.0975322723389, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28e0dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 876.0975322723389, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 77.68695652173912, "ram_util_percent": 83.44782608695652}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5792198108893538, "cur_kl_coeff": 0.0008789062500000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9104121401196434, "policy_loss": -0.0036967467260423793, "vf_loss": 0.9140932367986472, "vf_explained_var": 0.00711465528402379, "kl": 0.017805973120923257, "entropy": 0.9662119941736655, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.454850008405706, "cur_kl_coeff": 2.2888183593749995e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.7697964369304597, "policy_loss": 0.00042626528493153355, "vf_loss": 3.769370174029517, "vf_explained_var": 0.3924182675818287, "kl": 0.0014473286989284142, "entropy": 0.66259392897288, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 95445.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -8.399999999999709, "episode_reward_mean": 142.17799999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -72.4000000000008, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 44.0}, "policy_reward_mean": {"prey_policy": 66.61399999999998, "predator_policy": 4.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [53.50000000000052, 54.40000000000052, 27.90000000000011, 104.39999999999856, 184.09999999999943, 400.0, 219.99999999999926, 179.89999999999947, 201.99999999999935, 173.7999999999995, 203.99999999999935, 130.6999999999987, 91.29999999999852, 155.19999999999956, -8.399999999999709, 26.900000000000087, 40.0000000000003, 2.90000000000018, 219.99999999999926, 14.699999999999937, 205.99999999999932, 219.99999999999926, 161.39999999999955, 48.700000000000024, 84.59999999999893, 40.0000000000003, 24.600000000000055, 235.29999999999916, 233.09999999999914, 263.49999999999955, 33.400000000000205, 335.20000000000164, 25.70000000000007, 175.49999999999946, 219.99999999999926, 180.39999999999944, 199.99999999999935, 40.0000000000003, 219.99999999999926, 40.0000000000003, 106.59999999999854, 198.29999999999936, 195.99999999999937, 275.7999999999996, 162.3999999999989, 78.70000000000014, 315.1, 218.89999999999927, 34.50000000000022, 201.99999999999935, 191.9999999999994, 329.30000000000143, 205.99999999999932, 174.8999999999995, 249.49999999999906, 76.9, 27.900000000000098, 36.80000000000031, 219.99999999999926, 97.6, 86.7999999999999, 199.99999999999937, 302.7000000000006, 140.99999999999966, 282.1, 219.99999999999926, 334.29999999999995, 19.099999999999973, 302.8000000000006, 40.0000000000003, 207.39999999999918, 366.0, 40.0000000000003, 197.99999999999937, 22.400000000000038, 168.6999999999995, 10.000000000000039, 67.90000000000019, 137.19999999999982, 209.9999999999993, 179.39999999999947, 43.40000000000035, 12.499999999999988, 40.0000000000003, 40.0000000000003, 325.29999999999995, 104.89999999999881, 35.30000000000023, 40.0000000000003, 30.10000000000016, 219.99999999999926, 40.0000000000003, 219.99999999999926, 40.0000000000003, 193.5999999999994, 105.89999999999998, 51.50000000000021, 33.8000000000002, 38.90000000000028, 202.89999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 33.50000000000024, 20.000000000000014, 34.40000000000026, 20.000000000000014, -3.0999999999999615, 82.3999999999993, 20.000000000000014, 160.1, 20.000000000000014, 200.0, 200.0, 200.0, 20.000000000000014, 21.80000000000004, 142.1, 173.0, 20.000000000000014, 200.0, -68.20000000000086, 20.000000000000014, 176.0, 20.000000000000014, 109.69999999999945, 71.29999999999968, 20.000000000000014, 20.000000000000014, 135.2, 20.000000000000014, -72.4000000000008, 17.899999999999988, -0.9999999999999846, 20.000000000000014, 20.000000000000014, -55.600000000000136, 9.499999999999968, 20.000000000000014, 200.0, 20.000000000000014, -28.299999999999777, 179.0, 20.000000000000014, 20.000000000000014, 200.0, -1.0000000000000346, 151.4, 20.000000000000014, 4.700000000000195, 66.79999999999997, 15.799999999999963, 20.000000000000014, 20.000000000000014, -5.199999999999937, 15.799999999999963, 200.0, 35.30000000000026, 49.10000000000023, 176.0, 96.49999999999935, 164.0, 20.000000000000014, 7.399999999999965, 159.49999999999974, 175.69999999999985, -7.299999999999891, 20.000000000000014, 144.50000000000003, 20.000000000000014, 20.000000000000014, 200.0, 160.4, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 86.59999999999928, 7.399999999999965, 182.9, 20.000000000000014, 164.0, 200.0, 75.79999999999997, 142.39999999999964, 20.000000000000014, 20.000000000000014, 58.69999999999996, 136.10000000000002, 158.0, 17.899999999999988, 200.0, 9.499999999999964, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 158.0, 200.0, 122.29999999999964, 20.000000000000014, 179.0, 9.499999999999964, 160.4, 51.500000000000234, 197.0, 47.89999999999997, 20.000000000000014, 20.000000000000014, -3.100000000000047, -26.20000000000053, 20.000000000000014, 200.0, 20.000000000000014, 77.59999999999997, 20.000000000000014, -17.79999999999975, 86.59999999999997, 170.0, 20.000000000000014, 97.69999999999945, 200.0, 112.99999999999997, 20.000000000000014, 181.1, 100.99999999999943, 20.000000000000014, 200.0, 200.0, 134.29999999999998, 20.000000000000014, -19.899999999999785, 102.79999999999939, 200.0, 20.000000000000014, 20.000000000000014, 187.39999999999992, 20.000000000000014, 200.0, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, -13.599999999999818, 20.000000000000014, 148.7, 20.000000000000014, -42.999999999999766, 20.000000000000014, 47.900000000000226, 28.100000000000147, 109.09999999999998, 185.0, 20.000000000000014, -9.399999999999855, 174.8, 22.40000000000005, 20.000000000000014, 20.000000000000014, -32.49999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 125.29999999999998, 200.0, 20.000000000000014, 71.89999999999958, 41.60000000000025, -70.30000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 167.0, -68.20000000000024, 127.1, 36.19999999999999, -15.699999999999768, -47.199999999999804, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 182.9], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 12.0, 0.0, 9.0, 37.0, 5.0, 8.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 10.0, 0.0, 0.0, 0.0, 31.0, 18.0, 0.0, 0.0, 23.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 9.0, 12.0, 12.0, 0.0, 2.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 13.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 12.0, 0.0, 1.0, 5.0, 0.0, 0.0, 9.0, 14.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 5.0, 1.0, 0.0, 7.0, 2.0, 0.0, 11.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 10.0, 0.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 16.0, 0.0, 0.0, 12.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 14.0, 0.0, 1.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 36.0, 28.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 5.0, 42.0, 17.0, 14.0, 29.0, 32.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4432812897886818, "mean_inference_ms": 3.9580302093453117, "mean_action_processing_ms": 0.7748447785887584, "mean_env_wait_ms": 0.8719352906913121, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011126041412353516, "StateBufferConnector_ms": 0.01303720474243164, "ViewRequirementAgentConnector_ms": 0.21871280670166016}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -8.399999999999709, "episode_return_mean": 142.17799999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 240.54491575430342, "num_env_steps_trained_throughput_per_sec": 240.54491575430342, "timesteps_total": 204000, "num_env_steps_sampled_lifetime": 204000, "num_agent_steps_sampled_lifetime": 816000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 816000, "timers": {"training_iteration_time_ms": 18984.807, "restore_workers_time_ms": 0.027, "training_step_time_ms": 18984.721, "sample_time_ms": 3727.446, "learn_time_ms": 15235.124, "learn_throughput": 262.551, "synch_weights_time_ms": 18.903}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 816000, "num_agent_steps_trained": 816000}, "done": false, "training_iteration": 51, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-07-02", "timestamp": 1723522022, "time_this_iter_s": 16.678066730499268, "time_total_s": 892.7755990028381, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d1a940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 892.7755990028381, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 78.88260869565218, "ram_util_percent": 83.50869565217394}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.48216356363088364, "cur_kl_coeff": 0.0008789062500000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.8023617600164716, "policy_loss": -0.002205396042249742, "vf_loss": 0.8045548399762502, "vf_explained_var": 0.0002071319749115636, "kl": 0.014014537086988967, "entropy": 0.9320358174818534, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.4627601415786162, "cur_kl_coeff": 1.1444091796874997e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.535274989895089, "policy_loss": -0.0021510788806216427, "vf_loss": 4.537426059712809, "vf_explained_var": 0.3188327380273708, "kl": 0.0046681591269175345, "entropy": 0.6060140529795298, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 97335.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 10.000000000000039, "episode_reward_mean": 151.41899999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.4999999999982, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 234.0}, "policy_reward_mean": {"prey_policy": 69.60949999999998, "predator_policy": 6.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 14.699999999999937, 205.99999999999932, 219.99999999999926, 161.39999999999955, 48.700000000000024, 84.59999999999893, 40.0000000000003, 24.600000000000055, 235.29999999999916, 233.09999999999914, 263.49999999999955, 33.400000000000205, 335.20000000000164, 25.70000000000007, 175.49999999999946, 219.99999999999926, 180.39999999999944, 199.99999999999935, 40.0000000000003, 219.99999999999926, 40.0000000000003, 106.59999999999854, 198.29999999999936, 195.99999999999937, 275.7999999999996, 162.3999999999989, 78.70000000000014, 315.1, 218.89999999999927, 34.50000000000022, 201.99999999999935, 191.9999999999994, 329.30000000000143, 205.99999999999932, 174.8999999999995, 249.49999999999906, 76.9, 27.900000000000098, 36.80000000000031, 219.99999999999926, 97.6, 86.7999999999999, 199.99999999999937, 302.7000000000006, 140.99999999999966, 282.1, 219.99999999999926, 334.29999999999995, 19.099999999999973, 302.8000000000006, 40.0000000000003, 207.39999999999918, 366.0, 40.0000000000003, 197.99999999999937, 22.400000000000038, 168.6999999999995, 10.000000000000039, 67.90000000000019, 137.19999999999982, 209.9999999999993, 179.39999999999947, 43.40000000000035, 12.499999999999988, 40.0000000000003, 40.0000000000003, 325.29999999999995, 104.89999999999881, 35.30000000000023, 40.0000000000003, 30.10000000000016, 219.99999999999926, 40.0000000000003, 219.99999999999926, 40.0000000000003, 193.5999999999994, 105.89999999999998, 51.50000000000021, 33.8000000000002, 38.90000000000028, 202.89999999999935, 198.19999999999936, 227.1999999999993, 248.09999999999957, 40.0000000000003, 171.49999999999918, 40.0000000000003, 154.29999999999956, 40.0000000000003, 315.20000000000005, 325.29999999999995, 26.80000000000009, 52.60000000000035, 137.49999999999883, 400.0, 189.3999999999994, 160.5999999999989, 40.0000000000003, 400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 200.0, 20.000000000000014, -28.299999999999777, 179.0, 20.000000000000014, 20.000000000000014, 200.0, -1.0000000000000346, 151.4, 20.000000000000014, 4.700000000000195, 66.79999999999997, 15.799999999999963, 20.000000000000014, 20.000000000000014, -5.199999999999937, 15.799999999999963, 200.0, 35.30000000000026, 49.10000000000023, 176.0, 96.49999999999935, 164.0, 20.000000000000014, 7.399999999999965, 159.49999999999974, 175.69999999999985, -7.299999999999891, 20.000000000000014, 144.50000000000003, 20.000000000000014, 20.000000000000014, 200.0, 160.4, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 86.59999999999928, 7.399999999999965, 182.9, 20.000000000000014, 164.0, 200.0, 75.79999999999997, 142.39999999999964, 20.000000000000014, 20.000000000000014, 58.69999999999996, 136.10000000000002, 158.0, 17.899999999999988, 200.0, 9.499999999999964, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 158.0, 200.0, 122.29999999999964, 20.000000000000014, 179.0, 9.499999999999964, 160.4, 51.500000000000234, 197.0, 47.89999999999997, 20.000000000000014, 20.000000000000014, -3.100000000000047, -26.20000000000053, 20.000000000000014, 200.0, 20.000000000000014, 77.59999999999997, 20.000000000000014, -17.79999999999975, 86.59999999999997, 170.0, 20.000000000000014, 97.69999999999945, 200.0, 112.99999999999997, 20.000000000000014, 181.1, 100.99999999999943, 20.000000000000014, 200.0, 200.0, 134.29999999999998, 20.000000000000014, -19.899999999999785, 102.79999999999939, 200.0, 20.000000000000014, 20.000000000000014, 187.39999999999992, 20.000000000000014, 200.0, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, -13.599999999999818, 20.000000000000014, 148.7, 20.000000000000014, -42.999999999999766, 20.000000000000014, 47.900000000000226, 28.100000000000147, 109.09999999999998, 185.0, 20.000000000000014, -9.399999999999855, 174.8, 22.40000000000005, 20.000000000000014, 20.000000000000014, -32.49999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 125.29999999999998, 200.0, 20.000000000000014, 71.89999999999958, 41.60000000000025, -70.30000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 167.0, -68.20000000000024, 127.1, 36.19999999999999, -15.699999999999768, -47.199999999999804, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 182.9, 189.2, -1.0000000000000062, 200.0, 27.200000000000003, 99.79999999999998, 140.2999999999997, 20.000000000000014, 20.000000000000014, -15.699999999999754, 165.19999999999982, 20.000000000000014, 20.000000000000014, 134.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 120.20000000000007, 182.0, 125.29999999999998, 200.0, 1.0999999999999865, 13.69999999999997, 20.000000000000014, 32.60000000000017, 20.000000000000014, -320.4999999999982, 200.0, 200.0, 25.400000000000098, 146.0, 20.000000000000014, 140.59999999999962, 20.000000000000014, 20.000000000000014, 200.0, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 23.0, 0.0, 0.0, 7.0, 0.0, 0.0, 2.0, 9.0, 12.0, 12.0, 0.0, 2.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 13.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 12.0, 0.0, 1.0, 5.0, 0.0, 0.0, 9.0, 14.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 5.0, 1.0, 0.0, 7.0, 2.0, 0.0, 11.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 10.0, 0.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 16.0, 0.0, 0.0, 12.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 14.0, 0.0, 1.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 36.0, 28.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 5.0, 42.0, 17.0, 14.0, 29.0, 32.0, 0.0, 1.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 4.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 204.0, 234.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.439377179651834, "mean_inference_ms": 3.958859417897676, "mean_action_processing_ms": 0.7705347724640927, "mean_env_wait_ms": 0.8704202047256976, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009438157081604004, "StateBufferConnector_ms": 0.010606050491333008, "ViewRequirementAgentConnector_ms": 0.14392876625061035}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 10.000000000000039, "episode_return_mean": 151.41899999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 224.58619151513932, "num_env_steps_trained_throughput_per_sec": 224.58619151513932, "timesteps_total": 208000, "num_env_steps_sampled_lifetime": 208000, "num_agent_steps_sampled_lifetime": 832000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 832000, "timers": {"training_iteration_time_ms": 19127.394, "restore_workers_time_ms": 0.026, "training_step_time_ms": 19127.31, "sample_time_ms": 3844.376, "learn_time_ms": 15259.727, "learn_throughput": 262.128, "synch_weights_time_ms": 19.048}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 832000, "num_agent_steps_trained": 832000}, "done": false, "training_iteration": 52, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-07-20", "timestamp": 1723522040, "time_this_iter_s": 17.879956007003784, "time_total_s": 910.6555550098419, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4da2a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 910.6555550098419, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 84.69230769230768, "ram_util_percent": 83.41923076923078}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5280048308647657, "cur_kl_coeff": 0.0008789062500000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.3377808926755158, "policy_loss": -0.0011043849499728629, "vf_loss": 0.3388829351755145, "vf_explained_var": 0.024712488575587197, "kl": 0.0026651846774012923, "entropy": 0.9077754297899822, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.722363805755106, "cur_kl_coeff": 5.722045898437499e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.255335389369379, "policy_loss": -0.0012926688548374587, "vf_loss": 4.256628045077046, "vf_explained_var": 0.4789107947437852, "kl": 0.002765600600840938, "entropy": 0.6668572257435511, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 99225.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": 10.000000000000039, "episode_reward_mean": 149.2579999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.4999999999982, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 234.0}, "policy_reward_mean": {"prey_policy": 67.01899999999999, "predator_policy": 7.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [199.99999999999935, 40.0000000000003, 219.99999999999926, 40.0000000000003, 106.59999999999854, 198.29999999999936, 195.99999999999937, 275.7999999999996, 162.3999999999989, 78.70000000000014, 315.1, 218.89999999999927, 34.50000000000022, 201.99999999999935, 191.9999999999994, 329.30000000000143, 205.99999999999932, 174.8999999999995, 249.49999999999906, 76.9, 27.900000000000098, 36.80000000000031, 219.99999999999926, 97.6, 86.7999999999999, 199.99999999999937, 302.7000000000006, 140.99999999999966, 282.1, 219.99999999999926, 334.29999999999995, 19.099999999999973, 302.8000000000006, 40.0000000000003, 207.39999999999918, 366.0, 40.0000000000003, 197.99999999999937, 22.400000000000038, 168.6999999999995, 10.000000000000039, 67.90000000000019, 137.19999999999982, 209.9999999999993, 179.39999999999947, 43.40000000000035, 12.499999999999988, 40.0000000000003, 40.0000000000003, 325.29999999999995, 104.89999999999881, 35.30000000000023, 40.0000000000003, 30.10000000000016, 219.99999999999926, 40.0000000000003, 219.99999999999926, 40.0000000000003, 193.5999999999994, 105.89999999999998, 51.50000000000021, 33.8000000000002, 38.90000000000028, 202.89999999999935, 198.19999999999936, 227.1999999999993, 248.09999999999957, 40.0000000000003, 171.49999999999918, 40.0000000000003, 154.29999999999956, 40.0000000000003, 315.20000000000005, 325.29999999999995, 26.80000000000009, 52.60000000000035, 137.49999999999883, 400.0, 189.3999999999994, 160.5999999999989, 40.0000000000003, 400.0, 36.70000000000025, 213.3999999999993, 40.0000000000003, 217.79999999999927, 40.0000000000003, 156.09999999999886, 101.39999999999995, 209.5999999999993, 373.0, 17.89999999999995, 88.20000000000003, 71.5000000000002, 171.69999999999945, 81.39999999999911, 214.4999999999993, 281.2, 151.59999999999957, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 86.59999999999928, 7.399999999999965, 182.9, 20.000000000000014, 164.0, 200.0, 75.79999999999997, 142.39999999999964, 20.000000000000014, 20.000000000000014, 58.69999999999996, 136.10000000000002, 158.0, 17.899999999999988, 200.0, 9.499999999999964, 20.000000000000014, 173.0, 20.000000000000014, 20.000000000000014, 158.0, 200.0, 122.29999999999964, 20.000000000000014, 179.0, 9.499999999999964, 160.4, 51.500000000000234, 197.0, 47.89999999999997, 20.000000000000014, 20.000000000000014, -3.100000000000047, -26.20000000000053, 20.000000000000014, 200.0, 20.000000000000014, 77.59999999999997, 20.000000000000014, -17.79999999999975, 86.59999999999997, 170.0, 20.000000000000014, 97.69999999999945, 200.0, 112.99999999999997, 20.000000000000014, 181.1, 100.99999999999943, 20.000000000000014, 200.0, 200.0, 134.29999999999998, 20.000000000000014, -19.899999999999785, 102.79999999999939, 200.0, 20.000000000000014, 20.000000000000014, 187.39999999999992, 20.000000000000014, 200.0, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, -13.599999999999818, 20.000000000000014, 148.7, 20.000000000000014, -42.999999999999766, 20.000000000000014, 47.900000000000226, 28.100000000000147, 109.09999999999998, 185.0, 20.000000000000014, -9.399999999999855, 174.8, 22.40000000000005, 20.000000000000014, 20.000000000000014, -32.49999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 125.29999999999998, 200.0, 20.000000000000014, 71.89999999999958, 41.60000000000025, -70.30000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 167.0, -68.20000000000024, 127.1, 36.19999999999999, -15.699999999999768, -47.199999999999804, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 182.9, 189.2, -1.0000000000000062, 200.0, 27.200000000000003, 99.79999999999998, 140.2999999999997, 20.000000000000014, 20.000000000000014, -15.699999999999754, 165.19999999999982, 20.000000000000014, 20.000000000000014, 134.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 120.20000000000007, 182.0, 125.29999999999998, 200.0, 1.0999999999999865, 13.69999999999997, 20.000000000000014, 32.60000000000017, 20.000000000000014, -320.4999999999982, 200.0, 200.0, 25.400000000000098, 146.0, 20.000000000000014, 140.59999999999962, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 13.699999999999966, 200.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 200.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 136.09999999999968, 20.000000000000014, 141.5, -192.10000000000048, 167.0, 26.600000000000126, 197.0, 164.0, -45.09999999999977, 20.000000000000014, 100.09999999999998, -40.89999999999977, 51.499999999999964, 20.000000000000014, 200.0, -175.3000000000006, 54.50000000000014, 17.899999999999984, 200.0, 9.499999999999964, 149.6, 131.6, 20.000000000000014, 131.6, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 12.0, 0.0, 1.0, 5.0, 0.0, 0.0, 9.0, 14.0, 0.0, 0.0, 7.0, 7.0, 0.0, 0.0, 5.0, 1.0, 0.0, 7.0, 2.0, 0.0, 11.0, 43.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 10.0, 0.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 16.0, 0.0, 0.0, 12.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 14.0, 0.0, 1.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 36.0, 28.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 5.0, 42.0, 17.0, 14.0, 29.0, 32.0, 0.0, 1.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 4.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 204.0, 234.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 82.0, 70.0, 5.0, 11.0, 0.0, 12.0, 28.0, 15.0, 29.0, 0.0, 0.0, 0.0, 54.0, 93.0, 1.0, 8.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.433644423510819, "mean_inference_ms": 3.9526204020241096, "mean_action_processing_ms": 0.7651073506843116, "mean_env_wait_ms": 0.8673909452586378, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006302475929260254, "StateBufferConnector_ms": 0.0036725997924804688, "ViewRequirementAgentConnector_ms": 0.1914808750152588}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": 10.000000000000039, "episode_return_mean": 149.2579999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 252.89848959878097, "num_env_steps_trained_throughput_per_sec": 252.89848959878097, "timesteps_total": 212000, "num_env_steps_sampled_lifetime": 212000, "num_agent_steps_sampled_lifetime": 848000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 848000, "timers": {"training_iteration_time_ms": 18841.999, "restore_workers_time_ms": 0.026, "training_step_time_ms": 18841.916, "sample_time_ms": 3732.489, "learn_time_ms": 15085.626, "learn_throughput": 265.153, "synch_weights_time_ms": 19.958}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 848000, "num_agent_steps_trained": 848000}, "done": false, "training_iteration": 53, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-07-36", "timestamp": 1723522056, "time_this_iter_s": 15.918320178985596, "time_total_s": 926.5738751888275, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x330dafb80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 926.5738751888275, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 76.85454545454546, "ram_util_percent": 83.5909090909091}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5501438777519282, "cur_kl_coeff": 0.0004394531250000001, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6294515106570784, "policy_loss": -0.0005447298539654603, "vf_loss": 0.629994974610588, "vf_explained_var": 0.01050765561679053, "kl": 0.0028761484565151462, "entropy": 0.8929647600840008, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.269813803303494, "cur_kl_coeff": 2.8610229492187494e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.0787699449630015, "policy_loss": -0.0014066398417251925, "vf_loss": 4.080176587079568, "vf_explained_var": 0.3812402699674879, "kl": 0.006038755383090252, "entropy": 0.6463383803607294, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 101115.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -27.599999999999525, "episode_reward_mean": 141.11099999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.4999999999982, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 234.0}, "policy_reward_mean": {"prey_policy": 62.085499999999996, "predator_policy": 8.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 97.6, 86.7999999999999, 199.99999999999937, 302.7000000000006, 140.99999999999966, 282.1, 219.99999999999926, 334.29999999999995, 19.099999999999973, 302.8000000000006, 40.0000000000003, 207.39999999999918, 366.0, 40.0000000000003, 197.99999999999937, 22.400000000000038, 168.6999999999995, 10.000000000000039, 67.90000000000019, 137.19999999999982, 209.9999999999993, 179.39999999999947, 43.40000000000035, 12.499999999999988, 40.0000000000003, 40.0000000000003, 325.29999999999995, 104.89999999999881, 35.30000000000023, 40.0000000000003, 30.10000000000016, 219.99999999999926, 40.0000000000003, 219.99999999999926, 40.0000000000003, 193.5999999999994, 105.89999999999998, 51.50000000000021, 33.8000000000002, 38.90000000000028, 202.89999999999935, 198.19999999999936, 227.1999999999993, 248.09999999999957, 40.0000000000003, 171.49999999999918, 40.0000000000003, 154.29999999999956, 40.0000000000003, 315.20000000000005, 325.29999999999995, 26.80000000000009, 52.60000000000035, 137.49999999999883, 400.0, 189.3999999999994, 160.5999999999989, 40.0000000000003, 400.0, 36.70000000000025, 213.3999999999993, 40.0000000000003, 217.79999999999927, 40.0000000000003, 156.09999999999886, 101.39999999999995, 209.5999999999993, 373.0, 17.89999999999995, 88.20000000000003, 71.5000000000002, 171.69999999999945, 81.39999999999911, 214.4999999999993, 281.2, 151.59999999999957, 40.0000000000003, 40.0000000000003, 12.899999999999922, 40.0000000000003, 215.59999999999928, 46.60000000000039, 40.0000000000003, 347.80000000000007, 204.49999999999932, 196.59999999999982, 12.50000000000003, 199.99999999999935, 219.99999999999926, -27.599999999999525, 40.0000000000003, 171.89999999999918, 40.0000000000003, 176.19999999999948, 201.99999999999935, 38.900000000000276, 350.3, 15.799999999999976, 182.89999999999898], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 20.000000000000014, 77.59999999999997, 20.000000000000014, -17.79999999999975, 86.59999999999997, 170.0, 20.000000000000014, 97.69999999999945, 200.0, 112.99999999999997, 20.000000000000014, 181.1, 100.99999999999943, 20.000000000000014, 200.0, 200.0, 134.29999999999998, 20.000000000000014, -19.899999999999785, 102.79999999999939, 200.0, 20.000000000000014, 20.000000000000014, 187.39999999999992, 20.000000000000014, 200.0, 149.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 176.0, 20.000000000000014, -13.599999999999818, 20.000000000000014, 148.7, 20.000000000000014, -42.999999999999766, 20.000000000000014, 47.900000000000226, 28.100000000000147, 109.09999999999998, 185.0, 20.000000000000014, -9.399999999999855, 174.8, 22.40000000000005, 20.000000000000014, 20.000000000000014, -32.49999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 125.29999999999998, 200.0, 20.000000000000014, 71.89999999999958, 41.60000000000025, -70.30000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 167.0, -68.20000000000024, 127.1, 36.19999999999999, -15.699999999999768, -47.199999999999804, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 182.9, 189.2, -1.0000000000000062, 200.0, 27.200000000000003, 99.79999999999998, 140.2999999999997, 20.000000000000014, 20.000000000000014, -15.699999999999754, 165.19999999999982, 20.000000000000014, 20.000000000000014, 134.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 120.20000000000007, 182.0, 125.29999999999998, 200.0, 1.0999999999999865, 13.69999999999997, 20.000000000000014, 32.60000000000017, 20.000000000000014, -320.4999999999982, 200.0, 200.0, 25.400000000000098, 146.0, 20.000000000000014, 140.59999999999962, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 13.699999999999966, 200.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 200.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 136.09999999999968, 20.000000000000014, 141.5, -192.10000000000048, 167.0, 26.600000000000126, 197.0, 164.0, -45.09999999999977, 20.000000000000014, 100.09999999999998, -40.89999999999977, 51.499999999999964, 20.000000000000014, 200.0, -175.3000000000006, 54.50000000000014, 17.899999999999984, 200.0, 9.499999999999964, 149.6, 131.6, 20.000000000000014, 131.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -87.10000000000049, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 200.0, -74.50000000000077, 73.09999999999955, 20.000000000000014, 20.000000000000014, 200.0, 147.8, 200.0, -14.499999999999794, 135.2, 61.39999999999996, 11.599999999999975, -24.099999999999746, 170.0, 20.000000000000014, 20.000000000000014, 200.0, -21.999999999999766, -34.59999999999976, 20.000000000000014, 20.000000000000014, 148.09999999999982, 15.799999999999963, 20.000000000000014, 20.000000000000014, -17.799999999999763, 164.0, 20.000000000000014, 173.0, 17.899999999999988, 20.000000000000014, 143.0, 188.3, 20.000000000000014, -26.199999999999747, 66.49999999999996, 85.39999999999952], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 18.0, 0.0, 10.0, 0.0, 5.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.0, 3.0, 0.0, 0.0, 0.0, 2.0, 0.0, 16.0, 0.0, 0.0, 12.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 14.0, 0.0, 1.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 36.0, 28.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 5.0, 42.0, 17.0, 14.0, 29.0, 32.0, 0.0, 1.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 4.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 204.0, 234.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 82.0, 70.0, 5.0, 11.0, 0.0, 12.0, 28.0, 15.0, 29.0, 0.0, 0.0, 0.0, 54.0, 93.0, 1.0, 8.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 41.0, 0.0, 0.0, 0.0, 4.0, 29.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 21.0, 4.0, 0.0, 10.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 16.0, 14.0, 9.0, 0.0, 1.0, 0.0, 8.0, 11.0, 22.0, 0.0, 16.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4273238924203993, "mean_inference_ms": 3.94489356930021, "mean_action_processing_ms": 0.7595107256871231, "mean_env_wait_ms": 0.8644560475078759, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00494837760925293, "StateBufferConnector_ms": 0.0039021968841552734, "ViewRequirementAgentConnector_ms": 0.18955636024475098}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -27.599999999999525, "episode_return_mean": 141.11099999999982, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 217.00615376619828, "num_env_steps_trained_throughput_per_sec": 217.00615376619828, "timesteps_total": 216000, "num_env_steps_sampled_lifetime": 216000, "num_agent_steps_sampled_lifetime": 864000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 864000, "timers": {"training_iteration_time_ms": 18402.884, "restore_workers_time_ms": 0.026, "training_step_time_ms": 18402.792, "sample_time_ms": 3610.146, "learn_time_ms": 14767.955, "learn_throughput": 270.857, "synch_weights_time_ms": 20.197}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 864000, "num_agent_steps_trained": 864000}, "done": false, "training_iteration": 54, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-07-54", "timestamp": 1723522074, "time_this_iter_s": 18.47795009613037, "time_total_s": 945.0518252849579, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2901040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 945.0518252849579, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 82.96296296296296, "ram_util_percent": 83.67777777777776}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5070869151946334, "cur_kl_coeff": 0.00021972656250000006, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.5878059923333466, "policy_loss": -0.0011005707883409092, "vf_loss": 0.5889057911858554, "vf_explained_var": 0.020738052407269756, "kl": 0.0035202169664279846, "entropy": 0.8735505105957152, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.739152711945236, "cur_kl_coeff": 2.8610229492187494e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.5672116036137576, "policy_loss": -0.001997951522380823, "vf_loss": 4.569209540710247, "vf_explained_var": 0.357824718100684, "kl": 0.004043368294934698, "entropy": 0.5960141532477878, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 103005.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -27.599999999999525, "episode_reward_mean": 136.4589999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.4999999999982, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 234.0}, "policy_reward_mean": {"prey_policy": 59.169500000000006, "predator_policy": 9.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [43.40000000000035, 12.499999999999988, 40.0000000000003, 40.0000000000003, 325.29999999999995, 104.89999999999881, 35.30000000000023, 40.0000000000003, 30.10000000000016, 219.99999999999926, 40.0000000000003, 219.99999999999926, 40.0000000000003, 193.5999999999994, 105.89999999999998, 51.50000000000021, 33.8000000000002, 38.90000000000028, 202.89999999999935, 198.19999999999936, 227.1999999999993, 248.09999999999957, 40.0000000000003, 171.49999999999918, 40.0000000000003, 154.29999999999956, 40.0000000000003, 315.20000000000005, 325.29999999999995, 26.80000000000009, 52.60000000000035, 137.49999999999883, 400.0, 189.3999999999994, 160.5999999999989, 40.0000000000003, 400.0, 36.70000000000025, 213.3999999999993, 40.0000000000003, 217.79999999999927, 40.0000000000003, 156.09999999999886, 101.39999999999995, 209.5999999999993, 373.0, 17.89999999999995, 88.20000000000003, 71.5000000000002, 171.69999999999945, 81.39999999999911, 214.4999999999993, 281.2, 151.59999999999957, 40.0000000000003, 40.0000000000003, 12.899999999999922, 40.0000000000003, 215.59999999999928, 46.60000000000039, 40.0000000000003, 347.80000000000007, 204.49999999999932, 196.59999999999982, 12.50000000000003, 199.99999999999935, 219.99999999999926, -27.599999999999525, 40.0000000000003, 171.89999999999918, 40.0000000000003, 176.19999999999948, 201.99999999999935, 38.900000000000276, 350.3, 15.799999999999976, 182.89999999999898, 15.699999999999928, 168.0999999999995, 327.20000000000005, 25.70000000000007, 198.29999999999936, 40.0000000000003, 209.99999999999932, 196.09999999999937, 143.39999999999873, 223.49999999999997, 209.9999999999993, 29.000000000000128, 282.99999999999966, -8.79999999999965, 211.9999999999993, 120.19999999999993, 312.6999999999998, 99.99999999999987, 168.5999999999995, 207.99999999999932, 104.79999999999993, 40.0000000000003, 60.700000000000514], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [22.40000000000005, 20.000000000000014, 20.000000000000014, -32.49999999999977, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 125.29999999999998, 200.0, 20.000000000000014, 71.89999999999958, 41.60000000000025, -70.30000000000089, 20.000000000000014, 20.000000000000014, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 167.0, -68.20000000000024, 127.1, 36.19999999999999, -15.699999999999768, -47.199999999999804, 20.000000000000014, 17.899999999999988, 20.000000000000014, 20.000000000000014, 182.9, 189.2, -1.0000000000000062, 200.0, 27.200000000000003, 99.79999999999998, 140.2999999999997, 20.000000000000014, 20.000000000000014, -15.699999999999754, 165.19999999999982, 20.000000000000014, 20.000000000000014, 134.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 120.20000000000007, 182.0, 125.29999999999998, 200.0, 1.0999999999999865, 13.69999999999997, 20.000000000000014, 32.60000000000017, 20.000000000000014, -320.4999999999982, 200.0, 200.0, 25.400000000000098, 146.0, 20.000000000000014, 140.59999999999962, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 13.699999999999966, 200.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 200.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 136.09999999999968, 20.000000000000014, 141.5, -192.10000000000048, 167.0, 26.600000000000126, 197.0, 164.0, -45.09999999999977, 20.000000000000014, 100.09999999999998, -40.89999999999977, 51.499999999999964, 20.000000000000014, 200.0, -175.3000000000006, 54.50000000000014, 17.899999999999984, 200.0, 9.499999999999964, 149.6, 131.6, 20.000000000000014, 131.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -87.10000000000049, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 200.0, -74.50000000000077, 73.09999999999955, 20.000000000000014, 20.000000000000014, 200.0, 147.8, 200.0, -14.499999999999794, 135.2, 61.39999999999996, 11.599999999999975, -24.099999999999746, 170.0, 20.000000000000014, 20.000000000000014, 200.0, -21.999999999999766, -34.59999999999976, 20.000000000000014, 20.000000000000014, 148.09999999999982, 15.799999999999963, 20.000000000000014, 20.000000000000014, -17.799999999999763, 164.0, 20.000000000000014, 173.0, 17.899999999999988, 20.000000000000014, 143.0, 188.3, 20.000000000000014, -26.199999999999747, 66.49999999999996, 85.39999999999952, -21.999999999999787, 13.699999999999969, 13.699999999999964, 151.4, 135.2, 188.0, -7.299999999999891, 20.000000000000014, 161.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, -2.7999999999999896, 182.9, 63.80000000000017, 65.60000000000004, 9.49999999999978, 170.0, 185.0, 20.000000000000014, 3.1999999999999615, 15.799999999999962, 200.0, 82.99999999999997, 3.199999999999967, -42.99999999999978, 179.0, 20.000000000000014, -7.299999999999891, 96.50000000000007, 200.0, 112.69999999999999, 20.000000000000014, 73.99999999999997, 15.799999999999963, 129.8, 20.000000000000014, 182.0, 20.000000000000014, 84.79999999999997, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014], "policy_predator_policy_reward": [1.0, 0.0, 25.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 36.0, 28.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 5.0, 42.0, 17.0, 14.0, 29.0, 32.0, 0.0, 1.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 4.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 204.0, 234.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 82.0, 70.0, 5.0, 11.0, 0.0, 12.0, 28.0, 15.0, 29.0, 0.0, 0.0, 0.0, 54.0, 93.0, 1.0, 8.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 41.0, 0.0, 0.0, 0.0, 4.0, 29.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 21.0, 4.0, 0.0, 10.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 16.0, 14.0, 9.0, 0.0, 1.0, 0.0, 8.0, 11.0, 22.0, 0.0, 16.0, 15.0, 4.0, 20.0, 3.0, 0.0, 4.0, 0.0, 0.0, 13.0, 8.0, 9.0, 0.0, 0.0, 5.0, 0.0, 3.0, 13.0, 14.0, 0.0, 15.0, 29.0, 1.0, 4.0, 2.0, 8.0, 0.0, 0.0, 0.0, 31.0, 6.0, 7.0, 18.0, 13.0, 0.0, 0.0, 6.0, 0.0, 6.0, 17.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4222154904779918, "mean_inference_ms": 3.9444217397044103, "mean_action_processing_ms": 0.7544129011632983, "mean_env_wait_ms": 0.8623897139100953, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004468560218811035, "StateBufferConnector_ms": 0.004734992980957031, "ViewRequirementAgentConnector_ms": 0.23714697360992432}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -27.599999999999525, "episode_return_mean": 136.4589999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.54162274406957, "num_env_steps_trained_throughput_per_sec": 199.54162274406957, "timesteps_total": 220000, "num_env_steps_sampled_lifetime": 220000, "num_agent_steps_sampled_lifetime": 880000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 880000, "timers": {"training_iteration_time_ms": 18568.406, "restore_workers_time_ms": 0.024, "training_step_time_ms": 18568.316, "sample_time_ms": 3810.904, "learn_time_ms": 14708.416, "learn_throughput": 271.953, "synch_weights_time_ms": 44.155}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 880000, "num_agent_steps_trained": 880000}, "done": false, "training_iteration": 55, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-08-15", "timestamp": 1723522095, "time_this_iter_s": 20.351351022720337, "time_total_s": 965.4031763076782, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d1aa60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 965.4031763076782, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 82.06785714285714, "ram_util_percent": 83.35000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.47174134244008986, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.24933305508481762, "policy_loss": -0.0020885595428466637, "vf_loss": 0.25141996561628754, "vf_explained_var": -0.025968284487093568, "kl": 0.015013937242337919, "entropy": 0.9667720025809353, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.170302040926205, "cur_kl_coeff": 1.4305114746093747e-07, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.0171072254735956, "policy_loss": -0.0005011234333906225, "vf_loss": 4.017608349285428, "vf_explained_var": 0.39272145102263756, "kl": 0.002041513765392686, "entropy": 0.6342505543004899, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 104895.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -27.599999999999525, "episode_reward_mean": 141.6939999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.4999999999982, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 234.0}, "policy_reward_mean": {"prey_policy": 62.04200000000001, "predator_policy": 8.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [202.89999999999935, 198.19999999999936, 227.1999999999993, 248.09999999999957, 40.0000000000003, 171.49999999999918, 40.0000000000003, 154.29999999999956, 40.0000000000003, 315.20000000000005, 325.29999999999995, 26.80000000000009, 52.60000000000035, 137.49999999999883, 400.0, 189.3999999999994, 160.5999999999989, 40.0000000000003, 400.0, 36.70000000000025, 213.3999999999993, 40.0000000000003, 217.79999999999927, 40.0000000000003, 156.09999999999886, 101.39999999999995, 209.5999999999993, 373.0, 17.89999999999995, 88.20000000000003, 71.5000000000002, 171.69999999999945, 81.39999999999911, 214.4999999999993, 281.2, 151.59999999999957, 40.0000000000003, 40.0000000000003, 12.899999999999922, 40.0000000000003, 215.59999999999928, 46.60000000000039, 40.0000000000003, 347.80000000000007, 204.49999999999932, 196.59999999999982, 12.50000000000003, 199.99999999999935, 219.99999999999926, -27.599999999999525, 40.0000000000003, 171.89999999999918, 40.0000000000003, 176.19999999999948, 201.99999999999935, 38.900000000000276, 350.3, 15.799999999999976, 182.89999999999898, 15.699999999999928, 168.0999999999995, 327.20000000000005, 25.70000000000007, 198.29999999999936, 40.0000000000003, 209.99999999999932, 196.09999999999937, 143.39999999999873, 223.49999999999997, 209.9999999999993, 29.000000000000128, 282.99999999999966, -8.79999999999965, 211.9999999999993, 120.19999999999993, 312.6999999999998, 99.99999999999987, 168.5999999999995, 207.99999999999932, 104.79999999999993, 40.0000000000003, 60.700000000000514, 13.0, 45.000000000000405, 20.199999999999992, 121.89999999999941, 54.10000000000011, 151.59999999999957, 127.09999999999985, 165.09999999999891, 85.00000000000009, 188.8999999999994, 214.4999999999993, 85.7999999999999, 223.40000000000003, 196.89999999999938, 40.0000000000003, 44.50000000000036, 143.69999999999968, 217.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 182.9, 189.2, -1.0000000000000062, 200.0, 27.200000000000003, 99.79999999999998, 140.2999999999997, 20.000000000000014, 20.000000000000014, -15.699999999999754, 165.19999999999982, 20.000000000000014, 20.000000000000014, 134.29999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 120.20000000000007, 182.0, 125.29999999999998, 200.0, 1.0999999999999865, 13.69999999999997, 20.000000000000014, 32.60000000000017, 20.000000000000014, -320.4999999999982, 200.0, 200.0, 25.400000000000098, 146.0, 20.000000000000014, 140.59999999999962, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 13.699999999999966, 200.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 200.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 136.09999999999968, 20.000000000000014, 141.5, -192.10000000000048, 167.0, 26.600000000000126, 197.0, 164.0, -45.09999999999977, 20.000000000000014, 100.09999999999998, -40.89999999999977, 51.499999999999964, 20.000000000000014, 200.0, -175.3000000000006, 54.50000000000014, 17.899999999999984, 200.0, 9.499999999999964, 149.6, 131.6, 20.000000000000014, 131.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -87.10000000000049, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 200.0, -74.50000000000077, 73.09999999999955, 20.000000000000014, 20.000000000000014, 200.0, 147.8, 200.0, -14.499999999999794, 135.2, 61.39999999999996, 11.599999999999975, -24.099999999999746, 170.0, 20.000000000000014, 20.000000000000014, 200.0, -21.999999999999766, -34.59999999999976, 20.000000000000014, 20.000000000000014, 148.09999999999982, 15.799999999999963, 20.000000000000014, 20.000000000000014, -17.799999999999763, 164.0, 20.000000000000014, 173.0, 17.899999999999988, 20.000000000000014, 143.0, 188.3, 20.000000000000014, -26.199999999999747, 66.49999999999996, 85.39999999999952, -21.999999999999787, 13.699999999999969, 13.699999999999964, 151.4, 135.2, 188.0, -7.299999999999891, 20.000000000000014, 161.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, -2.7999999999999896, 182.9, 63.80000000000017, 65.60000000000004, 9.49999999999978, 170.0, 185.0, 20.000000000000014, 3.1999999999999615, 15.799999999999962, 200.0, 82.99999999999997, 3.199999999999967, -42.99999999999978, 179.0, 20.000000000000014, -7.299999999999891, 96.50000000000007, 200.0, 112.69999999999999, 20.000000000000014, 73.99999999999997, 15.799999999999963, 129.8, 20.000000000000014, 182.0, 20.000000000000014, 84.79999999999997, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, -7.299999999999919, 5.299999999999972, -21.99999999999978, 47.00000000000023, -17.79999999999977, 20.000000000000014, 20.000000000000014, 101.89999999999982, 10.999999999999963, -1.8999999999998138, 131.6, 20.000000000000014, 20.000000000000014, 79.10000000000005, 145.09999999999965, 20.000000000000014, 20.000000000000014, 64.99999999999997, 155.0, 17.899999999999988, 9.499999999999964, 200.0, -9.399999999999855, 81.19999999999996, 82.69999999999996, 133.7, 200.0, -24.099999999999767, 20.000000000000014, 20.000000000000014, 24.50000000000008, 20.000000000000014, 118.70000000000002, -0.9999999999999846, 197.0, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 4.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 204.0, 234.0, 0.0, 0.0, 0.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 82.0, 70.0, 5.0, 11.0, 0.0, 12.0, 28.0, 15.0, 29.0, 0.0, 0.0, 0.0, 54.0, 93.0, 1.0, 8.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 41.0, 0.0, 0.0, 0.0, 4.0, 29.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 21.0, 4.0, 0.0, 10.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 16.0, 14.0, 9.0, 0.0, 1.0, 0.0, 8.0, 11.0, 22.0, 0.0, 16.0, 15.0, 4.0, 20.0, 3.0, 0.0, 4.0, 0.0, 0.0, 13.0, 8.0, 9.0, 0.0, 0.0, 5.0, 0.0, 3.0, 13.0, 14.0, 0.0, 15.0, 29.0, 1.0, 4.0, 2.0, 8.0, 0.0, 0.0, 0.0, 31.0, 6.0, 7.0, 18.0, 13.0, 0.0, 0.0, 6.0, 0.0, 6.0, 17.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 20.0, 18.0, 0.0, 0.0, 0.0, 25.0, 20.0, 0.0, 0.0, 13.0, 15.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 5.0, 0.0, 14.0, 0.0, 0.0, 7.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 10.0, 16.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4191933437674624, "mean_inference_ms": 3.946725107664371, "mean_action_processing_ms": 0.7509014313815342, "mean_env_wait_ms": 0.8617139392351817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0046083927154541016, "StateBufferConnector_ms": 0.005100369453430176, "ViewRequirementAgentConnector_ms": 0.24411725997924805}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -27.599999999999525, "episode_return_mean": 141.6939999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 227.13420140253055, "num_env_steps_trained_throughput_per_sec": 227.13420140253055, "timesteps_total": 224000, "num_env_steps_sampled_lifetime": 224000, "num_agent_steps_sampled_lifetime": 896000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 896000, "timers": {"training_iteration_time_ms": 18197.073, "restore_workers_time_ms": 0.025, "training_step_time_ms": 18196.981, "sample_time_ms": 3707.125, "learn_time_ms": 14442.731, "learn_throughput": 276.956, "synch_weights_time_ms": 42.356}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 896000, "num_agent_steps_trained": 896000}, "done": false, "training_iteration": 56, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-08-33", "timestamp": 1723522113, "time_this_iter_s": 17.639756202697754, "time_total_s": 983.042932510376, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4dcc4c0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 983.042932510376, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 87.69615384615386, "ram_util_percent": 82.77692307692308}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.46910681697347806, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.32983037255822667, "policy_loss": -0.002387363190649363, "vf_loss": 0.3322170807192812, "vf_explained_var": 0.009272973531137698, "kl": 0.005947854513206968, "entropy": 0.9956852946647261, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.8684208489993894, "cur_kl_coeff": 7.152557373046873e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.7600452839382115, "policy_loss": -0.0010380644543421646, "vf_loss": 4.761083355530229, "vf_explained_var": 0.38942293556278973, "kl": 0.0018237756792484979, "entropy": 0.5435345739441574, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 106785.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -27.599999999999525, "episode_reward_mean": 139.09099999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -192.10000000000048, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 93.0}, "policy_reward_mean": {"prey_policy": 62.4605, "predator_policy": 7.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [400.0, 36.70000000000025, 213.3999999999993, 40.0000000000003, 217.79999999999927, 40.0000000000003, 156.09999999999886, 101.39999999999995, 209.5999999999993, 373.0, 17.89999999999995, 88.20000000000003, 71.5000000000002, 171.69999999999945, 81.39999999999911, 214.4999999999993, 281.2, 151.59999999999957, 40.0000000000003, 40.0000000000003, 12.899999999999922, 40.0000000000003, 215.59999999999928, 46.60000000000039, 40.0000000000003, 347.80000000000007, 204.49999999999932, 196.59999999999982, 12.50000000000003, 199.99999999999935, 219.99999999999926, -27.599999999999525, 40.0000000000003, 171.89999999999918, 40.0000000000003, 176.19999999999948, 201.99999999999935, 38.900000000000276, 350.3, 15.799999999999976, 182.89999999999898, 15.699999999999928, 168.0999999999995, 327.20000000000005, 25.70000000000007, 198.29999999999936, 40.0000000000003, 209.99999999999932, 196.09999999999937, 143.39999999999873, 223.49999999999997, 209.9999999999993, 29.000000000000128, 282.99999999999966, -8.79999999999965, 211.9999999999993, 120.19999999999993, 312.6999999999998, 99.99999999999987, 168.5999999999995, 207.99999999999932, 104.79999999999993, 40.0000000000003, 60.700000000000514, 13.0, 45.000000000000405, 20.199999999999992, 121.89999999999941, 54.10000000000011, 151.59999999999957, 127.09999999999985, 165.09999999999891, 85.00000000000009, 188.8999999999994, 214.4999999999993, 85.7999999999999, 223.40000000000003, 196.89999999999938, 40.0000000000003, 44.50000000000036, 143.69999999999968, 217.99999999999926, 197.29999999999916, 254.59999999999997, 40.0000000000003, 33.400000000000205, 40.0000000000003, 38.90000000000028, 199.99999999999935, 190.29999999999927, 50.80000000000035, 221.89999999999998, 40.0000000000003, 76.00000000000016, 28.500000000000124, 38.90000000000028, 218.89999999999927, 335.1, 304.70000000000005, 400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 200.0, 20.000000000000014, 13.699999999999966, 200.0, 7.399999999999965, 20.000000000000014, 20.000000000000014, 200.0, 15.799999999999963, 20.000000000000014, 20.000000000000014, 136.09999999999968, 20.000000000000014, 141.5, -192.10000000000048, 167.0, 26.600000000000126, 197.0, 164.0, -45.09999999999977, 20.000000000000014, 100.09999999999998, -40.89999999999977, 51.499999999999964, 20.000000000000014, 200.0, -175.3000000000006, 54.50000000000014, 17.899999999999984, 200.0, 9.499999999999964, 149.6, 131.6, 20.000000000000014, 131.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -87.10000000000049, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999964, 200.0, -74.50000000000077, 73.09999999999955, 20.000000000000014, 20.000000000000014, 200.0, 147.8, 200.0, -14.499999999999794, 135.2, 61.39999999999996, 11.599999999999975, -24.099999999999746, 170.0, 20.000000000000014, 20.000000000000014, 200.0, -21.999999999999766, -34.59999999999976, 20.000000000000014, 20.000000000000014, 148.09999999999982, 15.799999999999963, 20.000000000000014, 20.000000000000014, -17.799999999999763, 164.0, 20.000000000000014, 173.0, 17.899999999999988, 20.000000000000014, 143.0, 188.3, 20.000000000000014, -26.199999999999747, 66.49999999999996, 85.39999999999952, -21.999999999999787, 13.699999999999969, 13.699999999999964, 151.4, 135.2, 188.0, -7.299999999999891, 20.000000000000014, 161.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, -2.7999999999999896, 182.9, 63.80000000000017, 65.60000000000004, 9.49999999999978, 170.0, 185.0, 20.000000000000014, 3.1999999999999615, 15.799999999999962, 200.0, 82.99999999999997, 3.199999999999967, -42.99999999999978, 179.0, 20.000000000000014, -7.299999999999891, 96.50000000000007, 200.0, 112.69999999999999, 20.000000000000014, 73.99999999999997, 15.799999999999963, 129.8, 20.000000000000014, 182.0, 20.000000000000014, 84.79999999999997, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, -7.299999999999919, 5.299999999999972, -21.99999999999978, 47.00000000000023, -17.79999999999977, 20.000000000000014, 20.000000000000014, 101.89999999999982, 10.999999999999963, -1.8999999999998138, 131.6, 20.000000000000014, 20.000000000000014, 79.10000000000005, 145.09999999999965, 20.000000000000014, 20.000000000000014, 64.99999999999997, 155.0, 17.899999999999988, 9.499999999999964, 200.0, -9.399999999999855, 81.19999999999996, 82.69999999999996, 133.7, 200.0, -24.099999999999767, 20.000000000000014, 20.000000000000014, 24.50000000000008, 20.000000000000014, 118.70000000000002, -0.9999999999999846, 197.0, 20.000000000000014, 37.10000000000026, 150.20000000000005, 96.49999999999997, 151.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 170.0, 161.29999999999993, 20.000000000000014, 20.000000000000014, 30.80000000000012, 164.0, 2.8999999999995225, 20.000000000000014, 20.000000000000014, -5.200000000000415, 45.2000000000001, 27.20000000000013, -15.699999999999747, 17.899999999999988, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 130.1, 185.0, 100.70000000000007, 200.0, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 82.0, 70.0, 5.0, 11.0, 0.0, 12.0, 28.0, 15.0, 29.0, 0.0, 0.0, 0.0, 54.0, 93.0, 1.0, 8.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 41.0, 0.0, 0.0, 0.0, 4.0, 29.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 21.0, 4.0, 0.0, 10.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 16.0, 14.0, 9.0, 0.0, 1.0, 0.0, 8.0, 11.0, 22.0, 0.0, 16.0, 15.0, 4.0, 20.0, 3.0, 0.0, 4.0, 0.0, 0.0, 13.0, 8.0, 9.0, 0.0, 0.0, 5.0, 0.0, 3.0, 13.0, 14.0, 0.0, 15.0, 29.0, 1.0, 4.0, 2.0, 8.0, 0.0, 0.0, 0.0, 31.0, 6.0, 7.0, 18.0, 13.0, 0.0, 0.0, 6.0, 0.0, 6.0, 17.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 20.0, 18.0, 0.0, 0.0, 0.0, 25.0, 20.0, 0.0, 0.0, 13.0, 15.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 5.0, 0.0, 14.0, 0.0, 0.0, 7.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 10.0, 16.0, 1.0, 0.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 31.0, 24.0, 0.0, 0.0, 36.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 19.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4152141837192511, "mean_inference_ms": 3.944200396085227, "mean_action_processing_ms": 0.7469295546836261, "mean_env_wait_ms": 0.859701747495169, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009631514549255371, "StateBufferConnector_ms": 0.005036592483520508, "ViewRequirementAgentConnector_ms": 0.24621844291687012}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -27.599999999999525, "episode_return_mean": 139.09099999999984, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 260.16687807053285, "num_env_steps_trained_throughput_per_sec": 260.16687807053285, "timesteps_total": 228000, "num_env_steps_sampled_lifetime": 228000, "num_agent_steps_sampled_lifetime": 912000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 912000, "timers": {"training_iteration_time_ms": 17344.392, "restore_workers_time_ms": 0.02, "training_step_time_ms": 17344.304, "sample_time_ms": 3523.748, "learn_time_ms": 13773.257, "learn_throughput": 290.418, "synch_weights_time_ms": 42.521}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 912000, "num_agent_steps_trained": 912000}, "done": false, "training_iteration": 57, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-08-48", "timestamp": 1723522128, "time_this_iter_s": 15.411295890808105, "time_total_s": 998.4542284011841, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d55820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 998.4542284011841, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 78.54090909090911, "ram_util_percent": 83.35909090909091}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5467711044702107, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.43542816755632874, "policy_loss": -0.0021404085212717297, "vf_loss": 0.4375674369641476, "vf_explained_var": 0.04509264167654451, "kl": 0.010366131465863593, "entropy": 1.016105071924351, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.244376360542244, "cur_kl_coeff": 3.576278686523437e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.195984177488499, "policy_loss": -0.001140021402684469, "vf_loss": 5.1971242074613215, "vf_explained_var": 0.4211445084009221, "kl": 0.004884424492221055, "entropy": 0.5265274183775382, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 108675.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -27.599999999999525, "episode_reward_mean": 147.3789999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -74.50000000000077, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 36.0}, "policy_reward_mean": {"prey_policy": 68.0645, "predator_policy": 5.625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [215.59999999999928, 46.60000000000039, 40.0000000000003, 347.80000000000007, 204.49999999999932, 196.59999999999982, 12.50000000000003, 199.99999999999935, 219.99999999999926, -27.599999999999525, 40.0000000000003, 171.89999999999918, 40.0000000000003, 176.19999999999948, 201.99999999999935, 38.900000000000276, 350.3, 15.799999999999976, 182.89999999999898, 15.699999999999928, 168.0999999999995, 327.20000000000005, 25.70000000000007, 198.29999999999936, 40.0000000000003, 209.99999999999932, 196.09999999999937, 143.39999999999873, 223.49999999999997, 209.9999999999993, 29.000000000000128, 282.99999999999966, -8.79999999999965, 211.9999999999993, 120.19999999999993, 312.6999999999998, 99.99999999999987, 168.5999999999995, 207.99999999999932, 104.79999999999993, 40.0000000000003, 60.700000000000514, 13.0, 45.000000000000405, 20.199999999999992, 121.89999999999941, 54.10000000000011, 151.59999999999957, 127.09999999999985, 165.09999999999891, 85.00000000000009, 188.8999999999994, 214.4999999999993, 85.7999999999999, 223.40000000000003, 196.89999999999938, 40.0000000000003, 44.50000000000036, 143.69999999999968, 217.99999999999926, 197.29999999999916, 254.59999999999997, 40.0000000000003, 33.400000000000205, 40.0000000000003, 38.90000000000028, 199.99999999999935, 190.29999999999927, 50.80000000000035, 221.89999999999998, 40.0000000000003, 76.00000000000016, 28.500000000000124, 38.90000000000028, 218.89999999999927, 335.1, 304.70000000000005, 400.0, 16.49999999999994, 105.29999999999981, 59.200000000000045, 206.79999999999933, 305.3, 215.59999999999928, 400.0, 322.59999999999997, 212.69999999999928, 127.79999999999971, 382.0, 240.6999999999991, 54.50000000000036, 219.99999999999926, 30.100000000000147, 203.99999999999932, 37.80000000000027, 173.0999999999995, 40.0000000000003, 219.99999999999926, 105.29999999999882, 148.3999999999997], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [11.599999999999964, 200.0, -74.50000000000077, 73.09999999999955, 20.000000000000014, 20.000000000000014, 200.0, 147.8, 200.0, -14.499999999999794, 135.2, 61.39999999999996, 11.599999999999975, -24.099999999999746, 170.0, 20.000000000000014, 20.000000000000014, 200.0, -21.999999999999766, -34.59999999999976, 20.000000000000014, 20.000000000000014, 148.09999999999982, 15.799999999999963, 20.000000000000014, 20.000000000000014, -17.799999999999763, 164.0, 20.000000000000014, 173.0, 17.899999999999988, 20.000000000000014, 143.0, 188.3, 20.000000000000014, -26.199999999999747, 66.49999999999996, 85.39999999999952, -21.999999999999787, 13.699999999999969, 13.699999999999964, 151.4, 135.2, 188.0, -7.299999999999891, 20.000000000000014, 161.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, -2.7999999999999896, 182.9, 63.80000000000017, 65.60000000000004, 9.49999999999978, 170.0, 185.0, 20.000000000000014, 3.1999999999999615, 15.799999999999962, 200.0, 82.99999999999997, 3.199999999999967, -42.99999999999978, 179.0, 20.000000000000014, -7.299999999999891, 96.50000000000007, 200.0, 112.69999999999999, 20.000000000000014, 73.99999999999997, 15.799999999999963, 129.8, 20.000000000000014, 182.0, 20.000000000000014, 84.79999999999997, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, -7.299999999999919, 5.299999999999972, -21.99999999999978, 47.00000000000023, -17.79999999999977, 20.000000000000014, 20.000000000000014, 101.89999999999982, 10.999999999999963, -1.8999999999998138, 131.6, 20.000000000000014, 20.000000000000014, 79.10000000000005, 145.09999999999965, 20.000000000000014, 20.000000000000014, 64.99999999999997, 155.0, 17.899999999999988, 9.499999999999964, 200.0, -9.399999999999855, 81.19999999999996, 82.69999999999996, 133.7, 200.0, -24.099999999999767, 20.000000000000014, 20.000000000000014, 24.50000000000008, 20.000000000000014, 118.70000000000002, -0.9999999999999846, 197.0, 20.000000000000014, 37.10000000000026, 150.20000000000005, 96.49999999999997, 151.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 170.0, 161.29999999999993, 20.000000000000014, 20.000000000000014, 30.80000000000012, 164.0, 2.8999999999995225, 20.000000000000014, 20.000000000000014, -5.200000000000415, 45.2000000000001, 27.20000000000013, -15.699999999999747, 17.899999999999988, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 130.1, 185.0, 100.70000000000007, 200.0, 200.0, 20.000000000000014, -32.49999999999976, -3.099999999999958, 97.39999999999998, 27.200000000000074, 20.000000000000014, -5.199999999999962, 200.0, 167.0, 116.30000000000004, 200.0, 11.599999999999964, 200.0, 200.0, 200.0, 101.6000000000001, 194.0, 13.699999999999964, 105.8, 20.000000000000014, 200.0, 173.0, 40.70000000000025, 200.0, 20.000000000000014, 21.50000000000008, 20.000000000000014, 200.0, 1.0999999999999865, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 15.799999999999962, 9.499999999999966, 149.6, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 83.89999999999944, 7.399999999999965, 130.70000000000005, -7.299999999999901], "policy_predator_policy_reward": [0.0, 4.0, 29.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.0, 0.0, 21.0, 4.0, 0.0, 10.0, 0.0, 0.0, 0.0, 29.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 16.0, 14.0, 9.0, 0.0, 1.0, 0.0, 8.0, 11.0, 22.0, 0.0, 16.0, 15.0, 4.0, 20.0, 3.0, 0.0, 4.0, 0.0, 0.0, 13.0, 8.0, 9.0, 0.0, 0.0, 5.0, 0.0, 3.0, 13.0, 14.0, 0.0, 15.0, 29.0, 1.0, 4.0, 2.0, 8.0, 0.0, 0.0, 0.0, 31.0, 6.0, 7.0, 18.0, 13.0, 0.0, 0.0, 6.0, 0.0, 6.0, 17.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 20.0, 18.0, 0.0, 0.0, 0.0, 25.0, 20.0, 0.0, 0.0, 13.0, 15.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 5.0, 0.0, 14.0, 0.0, 0.0, 7.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 10.0, 16.0, 1.0, 0.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 31.0, 24.0, 0.0, 0.0, 36.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 19.0, 0.0, 0.0, 14.0, 15.0, 11.0, 0.0, 0.0, 12.0, 12.0, 0.0, 22.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 10.0, 3.0, 2.0, 0.0, 2.0, 0.0, 9.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 2.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 12.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4038641325841, "mean_inference_ms": 3.9242040392075968, "mean_action_processing_ms": 0.7382618098551259, "mean_env_wait_ms": 0.8535698441171398, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009900927543640137, "StateBufferConnector_ms": 0.00555729866027832, "ViewRequirementAgentConnector_ms": 0.19473624229431152}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -27.599999999999525, "episode_return_mean": 147.3789999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 258.7024090917992, "num_env_steps_trained_throughput_per_sec": 258.7024090917992, "timesteps_total": 232000, "num_env_steps_sampled_lifetime": 232000, "num_agent_steps_sampled_lifetime": 928000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 928000, "timers": {"training_iteration_time_ms": 16966.954, "restore_workers_time_ms": 0.019, "training_step_time_ms": 16966.846, "sample_time_ms": 3311.317, "learn_time_ms": 13607.261, "learn_throughput": 293.961, "synch_weights_time_ms": 43.228}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 928000, "num_agent_steps_trained": 928000}, "done": false, "training_iteration": 58, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-09-04", "timestamp": 1723522144, "time_this_iter_s": 15.531044960021973, "time_total_s": 1013.985273361206, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28cd9d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1013.985273361206, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 77.05000000000001, "ram_util_percent": 83.33636363636363}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5542243584103528, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.405317094709192, "policy_loss": -0.0025176416570074343, "vf_loss": 0.4078338785337841, "vf_explained_var": 0.011203975084597471, "kl": 0.007819741447402188, "entropy": 0.9881097031964197, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.685188017288843, "cur_kl_coeff": 1.7881393432617184e-08, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.153811298350178, "policy_loss": -0.0004823059894430338, "vf_loss": 5.154293614594394, "vf_explained_var": 0.4639188790762866, "kl": 0.0018510362243664375, "entropy": 0.5602929080131823, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 110565.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -8.79999999999965, "episode_reward_mean": 151.51799999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -42.99999999999978, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 36.0}, "policy_reward_mean": {"prey_policy": 70.37900000000002, "predator_policy": 5.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [182.89999999999898, 15.699999999999928, 168.0999999999995, 327.20000000000005, 25.70000000000007, 198.29999999999936, 40.0000000000003, 209.99999999999932, 196.09999999999937, 143.39999999999873, 223.49999999999997, 209.9999999999993, 29.000000000000128, 282.99999999999966, -8.79999999999965, 211.9999999999993, 120.19999999999993, 312.6999999999998, 99.99999999999987, 168.5999999999995, 207.99999999999932, 104.79999999999993, 40.0000000000003, 60.700000000000514, 13.0, 45.000000000000405, 20.199999999999992, 121.89999999999941, 54.10000000000011, 151.59999999999957, 127.09999999999985, 165.09999999999891, 85.00000000000009, 188.8999999999994, 214.4999999999993, 85.7999999999999, 223.40000000000003, 196.89999999999938, 40.0000000000003, 44.50000000000036, 143.69999999999968, 217.99999999999926, 197.29999999999916, 254.59999999999997, 40.0000000000003, 33.400000000000205, 40.0000000000003, 38.90000000000028, 199.99999999999935, 190.29999999999927, 50.80000000000035, 221.89999999999998, 40.0000000000003, 76.00000000000016, 28.500000000000124, 38.90000000000028, 218.89999999999927, 335.1, 304.70000000000005, 400.0, 16.49999999999994, 105.29999999999981, 59.200000000000045, 206.79999999999933, 305.3, 215.59999999999928, 400.0, 322.59999999999997, 212.69999999999928, 127.79999999999971, 382.0, 240.6999999999991, 54.50000000000036, 219.99999999999926, 30.100000000000147, 203.99999999999932, 37.80000000000027, 173.0999999999995, 40.0000000000003, 219.99999999999926, 105.29999999999882, 148.3999999999997, 367.3, 219.99999999999926, 178.29999999999944, 40.0000000000003, 27.90000000000011, 81.39999999999914, 103.09999999999891, 142.09999999999977, 193.5999999999994, 139.39999999999975, 28.69999999999998, 368.0, 70.89999999999999, 157.89999999999952, 207.39999999999932, 138.9999999999991, 219.99999999999926, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [66.49999999999996, 85.39999999999952, -21.999999999999787, 13.699999999999969, 13.699999999999964, 151.4, 135.2, 188.0, -7.299999999999891, 20.000000000000014, 161.3, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, -2.7999999999999896, 182.9, 63.80000000000017, 65.60000000000004, 9.49999999999978, 170.0, 185.0, 20.000000000000014, 3.1999999999999615, 15.799999999999962, 200.0, 82.99999999999997, 3.199999999999967, -42.99999999999978, 179.0, 20.000000000000014, -7.299999999999891, 96.50000000000007, 200.0, 112.69999999999999, 20.000000000000014, 73.99999999999997, 15.799999999999963, 129.8, 20.000000000000014, 182.0, 20.000000000000014, 84.79999999999997, 20.000000000000014, 20.000000000000014, 40.70000000000025, 20.000000000000014, -7.299999999999919, 5.299999999999972, -21.99999999999978, 47.00000000000023, -17.79999999999977, 20.000000000000014, 20.000000000000014, 101.89999999999982, 10.999999999999963, -1.8999999999998138, 131.6, 20.000000000000014, 20.000000000000014, 79.10000000000005, 145.09999999999965, 20.000000000000014, 20.000000000000014, 64.99999999999997, 155.0, 17.899999999999988, 9.499999999999964, 200.0, -9.399999999999855, 81.19999999999996, 82.69999999999996, 133.7, 200.0, -24.099999999999767, 20.000000000000014, 20.000000000000014, 24.50000000000008, 20.000000000000014, 118.70000000000002, -0.9999999999999846, 197.0, 20.000000000000014, 37.10000000000026, 150.20000000000005, 96.49999999999997, 151.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 170.0, 161.29999999999993, 20.000000000000014, 20.000000000000014, 30.80000000000012, 164.0, 2.8999999999995225, 20.000000000000014, 20.000000000000014, -5.200000000000415, 45.2000000000001, 27.20000000000013, -15.699999999999747, 17.899999999999988, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 130.1, 185.0, 100.70000000000007, 200.0, 200.0, 20.000000000000014, -32.49999999999976, -3.099999999999958, 97.39999999999998, 27.200000000000074, 20.000000000000014, -5.199999999999962, 200.0, 167.0, 116.30000000000004, 200.0, 11.599999999999964, 200.0, 200.0, 200.0, 101.6000000000001, 194.0, 13.699999999999964, 105.8, 20.000000000000014, 200.0, 173.0, 40.70000000000025, 200.0, 20.000000000000014, 21.50000000000008, 20.000000000000014, 200.0, 1.0999999999999865, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 15.799999999999962, 9.499999999999966, 149.6, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 83.89999999999944, 7.399999999999965, 130.70000000000005, -7.299999999999901, 161.0, 188.3, 200.0, 20.000000000000014, 162.2, 1.099999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 61.4000000000001, 20.000000000000014, 79.09999999999948, 20.000000000000014, 13.100000000000119, 98.00000000000001, 200.0, -30.3999999999998, 140.6, -26.19999999999976, 36.19999999999999, -32.49999999999978, 200.0, 149.0, 54.20000000000023, 13.699999999999967, 137.89999999999998, 20.000000000000014, 187.4, 20.000000000000014, 118.99999999999967, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0], "policy_predator_policy_reward": [16.0, 15.0, 4.0, 20.0, 3.0, 0.0, 4.0, 0.0, 0.0, 13.0, 8.0, 9.0, 0.0, 0.0, 5.0, 0.0, 3.0, 13.0, 14.0, 0.0, 15.0, 29.0, 1.0, 4.0, 2.0, 8.0, 0.0, 0.0, 0.0, 31.0, 6.0, 7.0, 18.0, 13.0, 0.0, 0.0, 6.0, 0.0, 6.0, 17.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 15.0, 0.0, 0.0, 20.0, 18.0, 0.0, 0.0, 0.0, 25.0, 20.0, 0.0, 0.0, 13.0, 15.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 5.0, 0.0, 14.0, 0.0, 0.0, 7.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 10.0, 16.0, 1.0, 0.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 31.0, 24.0, 0.0, 0.0, 36.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 19.0, 0.0, 0.0, 14.0, 15.0, 11.0, 0.0, 0.0, 12.0, 12.0, 0.0, 22.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 10.0, 3.0, 2.0, 0.0, 2.0, 0.0, 9.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 2.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 12.0, 13.0, 8.0, 10.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 15.0, 16.0, 3.0, 21.0, 3.0, 22.0, 18.0, 7.0, 11.0, 8.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4072499874494009, "mean_inference_ms": 3.938461551621342, "mean_action_processing_ms": 0.7385712718347537, "mean_env_wait_ms": 0.8556928599832412, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009717702865600586, "StateBufferConnector_ms": 0.005165457725524902, "ViewRequirementAgentConnector_ms": 0.18515467643737793}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -8.79999999999965, "episode_return_mean": 151.51799999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 215.58785355352043, "num_env_steps_trained_throughput_per_sec": 215.58785355352043, "timesteps_total": 236000, "num_env_steps_sampled_lifetime": 236000, "num_agent_steps_sampled_lifetime": 944000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 944000, "timers": {"training_iteration_time_ms": 17129.115, "restore_workers_time_ms": 0.019, "training_step_time_ms": 17129.007, "sample_time_ms": 3254.921, "learn_time_ms": 13822.545, "learn_throughput": 289.382, "synch_weights_time_ms": 45.382}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 944000, "num_agent_steps_trained": 944000}, "done": false, "training_iteration": 59, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-09-22", "timestamp": 1723522162, "time_this_iter_s": 18.591039896011353, "time_total_s": 1032.5763132572174, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28e0dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1032.5763132572174, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 84.22307692307692, "ram_util_percent": 83.0}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7829452768204704, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9824945227809684, "policy_loss": -0.005887588732949798, "vf_loss": 0.9883802783709985, "vf_explained_var": 0.006839257321029744, "kl": 0.01668354670049938, "entropy": 0.9079440716713194, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.142193939122889, "cur_kl_coeff": 8.940696716308592e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.64392910735317, "policy_loss": -0.0005745425290630135, "vf_loss": 4.644503652103364, "vf_explained_var": 0.5042520253115861, "kl": 0.00202380142002629, "entropy": 0.6161298520192898, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 112455.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -4.499999999999808, "episode_reward_mean": 153.31699999999972, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -133.3000000000006, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 74.0}, "policy_reward_mean": {"prey_policy": 70.8485, "predator_policy": 5.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.700000000000514, 13.0, 45.000000000000405, 20.199999999999992, 121.89999999999941, 54.10000000000011, 151.59999999999957, 127.09999999999985, 165.09999999999891, 85.00000000000009, 188.8999999999994, 214.4999999999993, 85.7999999999999, 223.40000000000003, 196.89999999999938, 40.0000000000003, 44.50000000000036, 143.69999999999968, 217.99999999999926, 197.29999999999916, 254.59999999999997, 40.0000000000003, 33.400000000000205, 40.0000000000003, 38.90000000000028, 199.99999999999935, 190.29999999999927, 50.80000000000035, 221.89999999999998, 40.0000000000003, 76.00000000000016, 28.500000000000124, 38.90000000000028, 218.89999999999927, 335.1, 304.70000000000005, 400.0, 16.49999999999994, 105.29999999999981, 59.200000000000045, 206.79999999999933, 305.3, 215.59999999999928, 400.0, 322.59999999999997, 212.69999999999928, 127.79999999999971, 382.0, 240.6999999999991, 54.50000000000036, 219.99999999999926, 30.100000000000147, 203.99999999999932, 37.80000000000027, 173.0999999999995, 40.0000000000003, 219.99999999999926, 105.29999999999882, 148.3999999999997, 367.3, 219.99999999999926, 178.29999999999944, 40.0000000000003, 27.90000000000011, 81.39999999999914, 103.09999999999891, 142.09999999999977, 193.5999999999994, 139.39999999999975, 28.69999999999998, 368.0, 70.89999999999999, 157.89999999999952, 207.39999999999932, 138.9999999999991, 219.99999999999926, 219.99999999999926, 171.69999999999945, 35.600000000000236, 156.29999999999927, 296.30000000000007, 219.99999999999926, 40.0000000000003, 213.9999999999993, 104.79999999999993, 127.29999999999976, 184.09999999999943, 210.99999999999932, 258.6999999999995, 197.79999999999936, 209.99999999999932, 160.09999999999954, 299.99999999999983, 40.0000000000003, 177.19999999999914, 237.89999999999975, -4.499999999999808, 111.99999999999989, 40.0000000000003, 199.99999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [40.70000000000025, 20.000000000000014, -7.299999999999919, 5.299999999999972, -21.99999999999978, 47.00000000000023, -17.79999999999977, 20.000000000000014, 20.000000000000014, 101.89999999999982, 10.999999999999963, -1.8999999999998138, 131.6, 20.000000000000014, 20.000000000000014, 79.10000000000005, 145.09999999999965, 20.000000000000014, 20.000000000000014, 64.99999999999997, 155.0, 17.899999999999988, 9.499999999999964, 200.0, -9.399999999999855, 81.19999999999996, 82.69999999999996, 133.7, 200.0, -24.099999999999767, 20.000000000000014, 20.000000000000014, 24.50000000000008, 20.000000000000014, 118.70000000000002, -0.9999999999999846, 197.0, 20.000000000000014, 37.10000000000026, 150.20000000000005, 96.49999999999997, 151.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 170.0, 161.29999999999993, 20.000000000000014, 20.000000000000014, 30.80000000000012, 164.0, 2.8999999999995225, 20.000000000000014, 20.000000000000014, -5.200000000000415, 45.2000000000001, 27.20000000000013, -15.699999999999747, 17.899999999999988, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 130.1, 185.0, 100.70000000000007, 200.0, 200.0, 20.000000000000014, -32.49999999999976, -3.099999999999958, 97.39999999999998, 27.200000000000074, 20.000000000000014, -5.199999999999962, 200.0, 167.0, 116.30000000000004, 200.0, 11.599999999999964, 200.0, 200.0, 200.0, 101.6000000000001, 194.0, 13.699999999999964, 105.8, 20.000000000000014, 200.0, 173.0, 40.70000000000025, 200.0, 20.000000000000014, 21.50000000000008, 20.000000000000014, 200.0, 1.0999999999999865, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 15.799999999999962, 9.499999999999966, 149.6, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 83.89999999999944, 7.399999999999965, 130.70000000000005, -7.299999999999901, 161.0, 188.3, 200.0, 20.000000000000014, 162.2, 1.099999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 61.4000000000001, 20.000000000000014, 79.09999999999948, 20.000000000000014, 13.100000000000119, 98.00000000000001, 200.0, -30.3999999999998, 140.6, -26.19999999999976, 36.19999999999999, -32.49999999999978, 200.0, 149.0, 54.20000000000023, 13.699999999999967, 137.89999999999998, 20.000000000000014, 187.4, 20.000000000000014, 118.99999999999967, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, -133.3000000000006, 158.0, 20.000000000000014, 11.599999999999971, 143.89999999999984, -13.599999999999783, 167.0, 107.3000000000001, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 84.79999999999997, 107.29999999999998, 20.000000000000014, 151.1, 20.000000000000014, -1.0000000000000346, 200.0, 200.0, 58.69999999999996, 170.0, 15.799999999999963, 20.000000000000014, 185.0, 20.000000000000014, 115.10000000000001, 97.99999999999999, 197.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 150.19999999999982, 23.900000000000148, 170.0, -42.09999999999982, -9.399999999999872, 20.000000000000014, 91.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0], "policy_predator_policy_reward": [0.0, 0.0, 15.0, 0.0, 0.0, 20.0, 18.0, 0.0, 0.0, 0.0, 25.0, 20.0, 0.0, 0.0, 13.0, 15.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 5.0, 0.0, 14.0, 0.0, 0.0, 7.0, 0.0, 21.0, 0.0, 0.0, 0.0, 0.0, 10.0, 16.0, 1.0, 0.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 31.0, 24.0, 0.0, 0.0, 36.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 19.0, 0.0, 0.0, 14.0, 15.0, 11.0, 0.0, 0.0, 12.0, 12.0, 0.0, 22.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 10.0, 3.0, 2.0, 0.0, 2.0, 0.0, 9.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 2.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 12.0, 13.0, 8.0, 10.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 15.0, 16.0, 3.0, 21.0, 3.0, 22.0, 18.0, 7.0, 11.0, 8.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 74.0, 0.0, 4.0, 0.0, 26.0, 12.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 4.0, 8.0, 0.0, 0.0, 10.0, 2.0, 0.0, 5.0, 11.0, 14.0, 0.0, 5.0, 0.0, 0.0, 0.0, 7.0, 28.0, 16.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3999075078587282, "mean_inference_ms": 3.9229977831397878, "mean_action_processing_ms": 0.7314144483971464, "mean_env_wait_ms": 0.8517411783806645, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009808182716369629, "StateBufferConnector_ms": 0.004442811012268066, "ViewRequirementAgentConnector_ms": 0.15224623680114746}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -4.499999999999808, "episode_return_mean": 153.31699999999972, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 253.1225998019221, "num_env_steps_trained_throughput_per_sec": 253.1225998019221, "timesteps_total": 240000, "num_env_steps_sampled_lifetime": 240000, "num_agent_steps_sampled_lifetime": 960000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 960000, "timers": {"training_iteration_time_ms": 17153.857, "restore_workers_time_ms": 0.019, "training_step_time_ms": 17153.766, "sample_time_ms": 3251.735, "learn_time_ms": 13851.593, "learn_throughput": 288.775, "synch_weights_time_ms": 44.378}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 960000, "num_agent_steps_trained": 960000}, "done": false, "training_iteration": 60, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-09-38", "timestamp": 1723522178, "time_this_iter_s": 15.881184101104736, "time_total_s": 1048.4574973583221, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28e0160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1048.4574973583221, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 81.04545454545453, "ram_util_percent": 83.39090909090909}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8201373397495854, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7989490474658038, "policy_loss": -0.002260526715378676, "vf_loss": 0.8012087567694604, "vf_explained_var": 0.004522878436184434, "kl": 0.007433392793175232, "entropy": 0.9667610236891994, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.642316219147551, "cur_kl_coeff": 4.470348358154296e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.2990760500468905, "policy_loss": -0.0014001637505042174, "vf_loss": 4.30047621083638, "vf_explained_var": 0.4852064212794026, "kl": 0.0037116384582537303, "entropy": 0.6551158767213267, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 114345.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -23.299999999999656, "episode_reward_mean": 158.21999999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -175.3000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 74.0}, "policy_reward_mean": {"prey_policy": 73.01, "predator_policy": 6.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [217.99999999999926, 197.29999999999916, 254.59999999999997, 40.0000000000003, 33.400000000000205, 40.0000000000003, 38.90000000000028, 199.99999999999935, 190.29999999999927, 50.80000000000035, 221.89999999999998, 40.0000000000003, 76.00000000000016, 28.500000000000124, 38.90000000000028, 218.89999999999927, 335.1, 304.70000000000005, 400.0, 16.49999999999994, 105.29999999999981, 59.200000000000045, 206.79999999999933, 305.3, 215.59999999999928, 400.0, 322.59999999999997, 212.69999999999928, 127.79999999999971, 382.0, 240.6999999999991, 54.50000000000036, 219.99999999999926, 30.100000000000147, 203.99999999999932, 37.80000000000027, 173.0999999999995, 40.0000000000003, 219.99999999999926, 105.29999999999882, 148.3999999999997, 367.3, 219.99999999999926, 178.29999999999944, 40.0000000000003, 27.90000000000011, 81.39999999999914, 103.09999999999891, 142.09999999999977, 193.5999999999994, 139.39999999999975, 28.69999999999998, 368.0, 70.89999999999999, 157.89999999999952, 207.39999999999932, 138.9999999999991, 219.99999999999926, 219.99999999999926, 171.69999999999945, 35.600000000000236, 156.29999999999927, 296.30000000000007, 219.99999999999926, 40.0000000000003, 213.9999999999993, 104.79999999999993, 127.29999999999976, 184.09999999999943, 210.99999999999932, 258.6999999999995, 197.79999999999936, 209.99999999999932, 160.09999999999954, 299.99999999999983, 40.0000000000003, 177.19999999999914, 237.89999999999975, -4.499999999999808, 111.99999999999989, 40.0000000000003, 199.99999999999935, 230.79999999999933, 187.09999999999943, -23.299999999999656, 272.1999999999996, 74.69999999999966, 134.59999999999965, 21.70000000000005, 203.99999999999932, 30.100000000000165, 290.20000000000005, 164.1999999999995, 30.100000000000158, 39.9000000000003, 400.0, 40.0000000000003, 301.9999999999999, 35.600000000000236, 37.80000000000027], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [197.0, 20.000000000000014, 37.10000000000026, 150.20000000000005, 96.49999999999997, 151.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 17.899999999999988, 20.000000000000014, 170.0, 161.29999999999993, 20.000000000000014, 20.000000000000014, 30.80000000000012, 164.0, 2.8999999999995225, 20.000000000000014, 20.000000000000014, -5.200000000000415, 45.2000000000001, 27.20000000000013, -15.699999999999747, 17.899999999999988, 20.000000000000014, 200.0, 17.899999999999988, 200.0, 130.1, 185.0, 100.70000000000007, 200.0, 200.0, 20.000000000000014, -32.49999999999976, -3.099999999999958, 97.39999999999998, 27.200000000000074, 20.000000000000014, -5.199999999999962, 200.0, 167.0, 116.30000000000004, 200.0, 11.599999999999964, 200.0, 200.0, 200.0, 101.6000000000001, 194.0, 13.699999999999964, 105.8, 20.000000000000014, 200.0, 173.0, 40.70000000000025, 200.0, 20.000000000000014, 21.50000000000008, 20.000000000000014, 200.0, 1.0999999999999865, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 15.799999999999962, 9.499999999999966, 149.6, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 83.89999999999944, 7.399999999999965, 130.70000000000005, -7.299999999999901, 161.0, 188.3, 200.0, 20.000000000000014, 162.2, 1.099999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 61.4000000000001, 20.000000000000014, 79.09999999999948, 20.000000000000014, 13.100000000000119, 98.00000000000001, 200.0, -30.3999999999998, 140.6, -26.19999999999976, 36.19999999999999, -32.49999999999978, 200.0, 149.0, 54.20000000000023, 13.699999999999967, 137.89999999999998, 20.000000000000014, 187.4, 20.000000000000014, 118.99999999999967, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, -133.3000000000006, 158.0, 20.000000000000014, 11.599999999999971, 143.89999999999984, -13.599999999999783, 167.0, 107.3000000000001, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 84.79999999999997, 107.29999999999998, 20.000000000000014, 151.1, 20.000000000000014, -1.0000000000000346, 200.0, 200.0, 58.69999999999996, 170.0, 15.799999999999963, 20.000000000000014, 185.0, 20.000000000000014, 115.10000000000001, 97.99999999999999, 197.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 150.19999999999982, 23.900000000000148, 170.0, -42.09999999999982, -9.399999999999872, 20.000000000000014, 91.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 30.800000000000153, 200.0, -13.599999999999826, 184.7, -175.3000000000005, 20.000000000000014, 72.19999999999996, 200.0, 17.899999999999988, 45.800000000000196, 20.000000000000014, 110.6, 31.700000000000212, -64.00000000000074, 176.0, 20.000000000000014, 20.000000000000014, 1.0999999999999617, 102.19999999999997, 170.0, 144.2, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 17.899999999999977, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 109.99999999999997, 188.0, 20.000000000000014, 11.599999999999964, 15.799999999999963, 20.000000000000014], "policy_predator_policy_reward": [1.0, 0.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 0.0, 31.0, 24.0, 0.0, 0.0, 36.0, 0.0, 0.0, 17.0, 1.0, 0.0, 0.0, 1.0, 0.0, 5.0, 0.0, 19.0, 0.0, 0.0, 14.0, 15.0, 11.0, 0.0, 0.0, 12.0, 12.0, 0.0, 22.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 10.0, 3.0, 2.0, 0.0, 2.0, 0.0, 9.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 2.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 12.0, 13.0, 8.0, 10.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 15.0, 16.0, 3.0, 21.0, 3.0, 22.0, 18.0, 7.0, 11.0, 8.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 74.0, 0.0, 4.0, 0.0, 26.0, 12.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 4.0, 8.0, 0.0, 0.0, 10.0, 2.0, 0.0, 5.0, 11.0, 14.0, 0.0, 5.0, 0.0, 0.0, 0.0, 7.0, 28.0, 16.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 16.0, 0.0, 71.0, 61.0, 0.0, 0.0, 11.0, 0.0, 0.0, 4.0, 35.0, 19.0, 8.0, 0.0, 9.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 9.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3986163087877577, "mean_inference_ms": 3.921466379702143, "mean_action_processing_ms": 0.7272715463063996, "mean_env_wait_ms": 0.850712998869351, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010273456573486328, "StateBufferConnector_ms": 0.005004763603210449, "ViewRequirementAgentConnector_ms": 0.2091541290283203}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -23.299999999999656, "episode_return_mean": 158.21999999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 184.09482250319715, "num_env_steps_trained_throughput_per_sec": 184.09482250319715, "timesteps_total": 244000, "num_env_steps_sampled_lifetime": 244000, "num_agent_steps_sampled_lifetime": 976000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 976000, "timers": {"training_iteration_time_ms": 17663.759, "restore_workers_time_ms": 0.019, "training_step_time_ms": 17663.669, "sample_time_ms": 3638.553, "learn_time_ms": 13973.731, "learn_throughput": 286.251, "synch_weights_time_ms": 46.181}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 976000, "num_agent_steps_trained": 976000}, "done": false, "training_iteration": 61, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-10-00", "timestamp": 1723522200, "time_this_iter_s": 22.02246594429016, "time_total_s": 1070.4799633026123, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d240d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1070.4799633026123, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 90.19677419354838, "ram_util_percent": 83.64516129032259}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5142633921235169, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.14865150016254533, "policy_loss": -0.0006515733756016566, "vf_loss": 0.14930217493078782, "vf_explained_var": -0.10191075145882904, "kl": 0.008174094506249377, "entropy": 1.0313077876176784, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.178191466661042, "cur_kl_coeff": 2.235174179077148e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.061376039187113, "policy_loss": -0.0022668631418445518, "vf_loss": 4.063642904367397, "vf_explained_var": 0.6147984670898902, "kl": 0.006305091317087041, "entropy": 0.6551573492231824, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 116235.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -23.299999999999656, "episode_reward_mean": 151.01699999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -175.3000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 74.0}, "policy_reward_mean": {"prey_policy": 68.62849999999999, "predator_policy": 6.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [400.0, 16.49999999999994, 105.29999999999981, 59.200000000000045, 206.79999999999933, 305.3, 215.59999999999928, 400.0, 322.59999999999997, 212.69999999999928, 127.79999999999971, 382.0, 240.6999999999991, 54.50000000000036, 219.99999999999926, 30.100000000000147, 203.99999999999932, 37.80000000000027, 173.0999999999995, 40.0000000000003, 219.99999999999926, 105.29999999999882, 148.3999999999997, 367.3, 219.99999999999926, 178.29999999999944, 40.0000000000003, 27.90000000000011, 81.39999999999914, 103.09999999999891, 142.09999999999977, 193.5999999999994, 139.39999999999975, 28.69999999999998, 368.0, 70.89999999999999, 157.89999999999952, 207.39999999999932, 138.9999999999991, 219.99999999999926, 219.99999999999926, 171.69999999999945, 35.600000000000236, 156.29999999999927, 296.30000000000007, 219.99999999999926, 40.0000000000003, 213.9999999999993, 104.79999999999993, 127.29999999999976, 184.09999999999943, 210.99999999999932, 258.6999999999995, 197.79999999999936, 209.99999999999932, 160.09999999999954, 299.99999999999983, 40.0000000000003, 177.19999999999914, 237.89999999999975, -4.499999999999808, 111.99999999999989, 40.0000000000003, 199.99999999999935, 230.79999999999933, 187.09999999999943, -23.299999999999656, 272.1999999999996, 74.69999999999966, 134.59999999999965, 21.70000000000005, 203.99999999999932, 30.100000000000165, 290.20000000000005, 164.1999999999995, 30.100000000000158, 39.9000000000003, 400.0, 40.0000000000003, 301.9999999999999, 35.600000000000236, 37.80000000000027, 149.09999999999965, 144.9999999999997, -19.099999999999532, 40.0000000000003, 39.80000000000011, 31.200000000000166, 13.599999999999936, 183.19999999999945, 40.0000000000003, 40.0000000000003, 101.19999999999996, 112.89999999999986, 40.0000000000003, 219.99999999999926, 219.99999999999926, 29.000000000000128, 196.5999999999991, 224.4999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 200.0, 20.000000000000014, -32.49999999999976, -3.099999999999958, 97.39999999999998, 27.200000000000074, 20.000000000000014, -5.199999999999962, 200.0, 167.0, 116.30000000000004, 200.0, 11.599999999999964, 200.0, 200.0, 200.0, 101.6000000000001, 194.0, 13.699999999999964, 105.8, 20.000000000000014, 200.0, 173.0, 40.70000000000025, 200.0, 20.000000000000014, 21.50000000000008, 20.000000000000014, 200.0, 1.0999999999999865, 20.000000000000014, 176.0, 20.000000000000014, 20.000000000000014, 15.799999999999962, 9.499999999999966, 149.6, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 83.89999999999944, 7.399999999999965, 130.70000000000005, -7.299999999999901, 161.0, 188.3, 200.0, 20.000000000000014, 162.2, 1.099999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 61.4000000000001, 20.000000000000014, 79.09999999999948, 20.000000000000014, 13.100000000000119, 98.00000000000001, 200.0, -30.3999999999998, 140.6, -26.19999999999976, 36.19999999999999, -32.49999999999978, 200.0, 149.0, 54.20000000000023, 13.699999999999967, 137.89999999999998, 20.000000000000014, 187.4, 20.000000000000014, 118.99999999999967, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, -133.3000000000006, 158.0, 20.000000000000014, 11.599999999999971, 143.89999999999984, -13.599999999999783, 167.0, 107.3000000000001, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 84.79999999999997, 107.29999999999998, 20.000000000000014, 151.1, 20.000000000000014, -1.0000000000000346, 200.0, 200.0, 58.69999999999996, 170.0, 15.799999999999963, 20.000000000000014, 185.0, 20.000000000000014, 115.10000000000001, 97.99999999999999, 197.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 150.19999999999982, 23.900000000000148, 170.0, -42.09999999999982, -9.399999999999872, 20.000000000000014, 91.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 30.800000000000153, 200.0, -13.599999999999826, 184.7, -175.3000000000005, 20.000000000000014, 72.19999999999996, 200.0, 17.899999999999988, 45.800000000000196, 20.000000000000014, 110.6, 31.700000000000212, -64.00000000000074, 176.0, 20.000000000000014, 20.000000000000014, 1.0999999999999617, 102.19999999999997, 170.0, 144.2, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 17.899999999999977, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 109.99999999999997, 188.0, 20.000000000000014, 11.599999999999964, 15.799999999999963, 20.000000000000014, -99.70000000000076, 144.79999999999998, 3.1999999999999615, 117.80000000000004, -51.40000000000005, -15.699999999999779, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 30.799999999999997, 3.1999999999999615, 20.000000000000014, -114.40000000000049, 20.000000000000014, -13.89999999999976, 175.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 81.19999999999996, 20.000000000000014, 20.000000000000014, 92.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 17.899999999999988, 1.099999999999983, 20.000000000000014, 176.59999999999985, 200.0, 24.500000000000007], "policy_predator_policy_reward": [0.0, 0.0, 14.0, 15.0, 11.0, 0.0, 0.0, 12.0, 12.0, 0.0, 22.0, 0.0, 0.0, 4.0, 0.0, 0.0, 11.0, 10.0, 3.0, 2.0, 0.0, 2.0, 0.0, 9.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 0.0, 9.0, 8.0, 0.0, 2.0, 0.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 5.0, 9.0, 12.0, 13.0, 8.0, 10.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 15.0, 16.0, 3.0, 21.0, 3.0, 22.0, 18.0, 7.0, 11.0, 8.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 74.0, 0.0, 4.0, 0.0, 26.0, 12.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 4.0, 8.0, 0.0, 0.0, 10.0, 2.0, 0.0, 5.0, 11.0, 14.0, 0.0, 5.0, 0.0, 0.0, 0.0, 7.0, 28.0, 16.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 16.0, 0.0, 71.0, 61.0, 0.0, 0.0, 11.0, 0.0, 0.0, 4.0, 35.0, 19.0, 8.0, 0.0, 9.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 9.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 2.0, 0.0, 48.0, 56.0, 8.0, 16.0, 18.0, 30.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 44.0, 64.0, 18.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4022279808730942, "mean_inference_ms": 3.9314942626318103, "mean_action_processing_ms": 0.7246244019067666, "mean_env_wait_ms": 0.8519182145933193, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005252957344055176, "StateBufferConnector_ms": 0.00534665584564209, "ViewRequirementAgentConnector_ms": 0.2904466390609741}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -23.299999999999656, "episode_return_mean": 151.01699999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 151.13261341794944, "num_env_steps_trained_throughput_per_sec": 151.13261341794944, "timesteps_total": 248000, "num_env_steps_sampled_lifetime": 248000, "num_agent_steps_sampled_lifetime": 992000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 992000, "timers": {"training_iteration_time_ms": 18529.389, "restore_workers_time_ms": 0.02, "training_step_time_ms": 18529.296, "sample_time_ms": 3992.908, "learn_time_ms": 14484.185, "learn_throughput": 276.163, "synch_weights_time_ms": 47.892}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 992000, "num_agent_steps_trained": 992000}, "done": false, "training_iteration": 62, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-10-27", "timestamp": 1723522227, "time_this_iter_s": 26.547075986862183, "time_total_s": 1097.0270392894745, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28e00d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1097.0270392894745, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 99.15263157894738, "ram_util_percent": 83.67105263157893}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7540626432194754, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4564464607882121, "policy_loss": -0.0016570089535206242, "vf_loss": 0.4581019408857972, "vf_explained_var": 0.0031792146503609956, "kl": 0.013922281140524493, "entropy": 0.9898630076930637, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.748897299091652, "cur_kl_coeff": 2.235174179077148e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.4061087144114985, "policy_loss": -0.00022205757112710406, "vf_loss": 5.40633076940264, "vf_explained_var": 0.5541599506738956, "kl": 0.0012772212161759348, "entropy": 0.6075573617503757, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 118125.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -23.299999999999656, "episode_reward_mean": 147.50099999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -175.3000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 74.0}, "policy_reward_mean": {"prey_policy": 66.9155, "predator_policy": 6.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [148.3999999999997, 367.3, 219.99999999999926, 178.29999999999944, 40.0000000000003, 27.90000000000011, 81.39999999999914, 103.09999999999891, 142.09999999999977, 193.5999999999994, 139.39999999999975, 28.69999999999998, 368.0, 70.89999999999999, 157.89999999999952, 207.39999999999932, 138.9999999999991, 219.99999999999926, 219.99999999999926, 171.69999999999945, 35.600000000000236, 156.29999999999927, 296.30000000000007, 219.99999999999926, 40.0000000000003, 213.9999999999993, 104.79999999999993, 127.29999999999976, 184.09999999999943, 210.99999999999932, 258.6999999999995, 197.79999999999936, 209.99999999999932, 160.09999999999954, 299.99999999999983, 40.0000000000003, 177.19999999999914, 237.89999999999975, -4.499999999999808, 111.99999999999989, 40.0000000000003, 199.99999999999935, 230.79999999999933, 187.09999999999943, -23.299999999999656, 272.1999999999996, 74.69999999999966, 134.59999999999965, 21.70000000000005, 203.99999999999932, 30.100000000000165, 290.20000000000005, 164.1999999999995, 30.100000000000158, 39.9000000000003, 400.0, 40.0000000000003, 301.9999999999999, 35.600000000000236, 37.80000000000027, 149.09999999999965, 144.9999999999997, -19.099999999999532, 40.0000000000003, 39.80000000000011, 31.200000000000166, 13.599999999999936, 183.19999999999945, 40.0000000000003, 40.0000000000003, 101.19999999999996, 112.89999999999986, 40.0000000000003, 219.99999999999926, 219.99999999999926, 29.000000000000128, 196.5999999999991, 224.4999999999993, 29.000000000000128, 209.19999999999922, 36.70000000000025, 40.0000000000003, 188.4999999999994, 38.30000000000034, 214.4999999999993, 40.0000000000003, 190.99999999999946, 219.99999999999926, 157.39999999999955, 305.5000000000007, 340.6, 40.0000000000003, 400.0, 268.5999999999998, 216.69999999999928, 219.99999999999926, 178.49999999999943, 19.099999999999977, 29.00000000000013, 345.1], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [130.70000000000005, -7.299999999999901, 161.0, 188.3, 200.0, 20.000000000000014, 162.2, 1.099999999999967, 20.000000000000014, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 61.4000000000001, 20.000000000000014, 79.09999999999948, 20.000000000000014, 13.100000000000119, 98.00000000000001, 200.0, -30.3999999999998, 140.6, -26.19999999999976, 36.19999999999999, -32.49999999999978, 200.0, 149.0, 54.20000000000023, 13.699999999999967, 137.89999999999998, 20.000000000000014, 187.4, 20.000000000000014, 118.99999999999967, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 200.0, -133.3000000000006, 158.0, 20.000000000000014, 11.599999999999971, 143.89999999999984, -13.599999999999783, 167.0, 107.3000000000001, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 84.79999999999997, 107.29999999999998, 20.000000000000014, 151.1, 20.000000000000014, -1.0000000000000346, 200.0, 200.0, 58.69999999999996, 170.0, 15.799999999999963, 20.000000000000014, 185.0, 20.000000000000014, 115.10000000000001, 97.99999999999999, 197.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 150.19999999999982, 23.900000000000148, 170.0, -42.09999999999982, -9.399999999999872, 20.000000000000014, 91.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 30.800000000000153, 200.0, -13.599999999999826, 184.7, -175.3000000000005, 20.000000000000014, 72.19999999999996, 200.0, 17.899999999999988, 45.800000000000196, 20.000000000000014, 110.6, 31.700000000000212, -64.00000000000074, 176.0, 20.000000000000014, 20.000000000000014, 1.0999999999999617, 102.19999999999997, 170.0, 144.2, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 17.899999999999977, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 109.99999999999997, 188.0, 20.000000000000014, 11.599999999999964, 15.799999999999963, 20.000000000000014, -99.70000000000076, 144.79999999999998, 3.1999999999999615, 117.80000000000004, -51.40000000000005, -15.699999999999779, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 30.799999999999997, 3.1999999999999615, 20.000000000000014, -114.40000000000049, 20.000000000000014, -13.89999999999976, 175.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 81.19999999999996, 20.000000000000014, 20.000000000000014, 92.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 17.899999999999988, 1.099999999999983, 20.000000000000014, 176.59999999999985, 200.0, 24.500000000000007, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 189.19999999999996, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 168.5, 9.200000000000026, 1.0999999999999759, 9.499999999999964, 200.0, 20.000000000000014, 20.000000000000014, 185.0, -64.00000000000045, 200.0, 20.000000000000014, -13.59999999999979, 155.0, 105.4999999999994, 200.0, 140.6, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 68.59999999999975, 200.0, 200.0, 13.699999999999964, 200.0, 20.000000000000014, 144.50000000000003, 20.000000000000014, -19.899999999999743, 20.000000000000014, -0.9999999999999917, 20.000000000000014, 200.0, 145.1], "policy_predator_policy_reward": [12.0, 13.0, 8.0, 10.0, 0.0, 0.0, 15.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 4.0, 0.0, 15.0, 16.0, 3.0, 21.0, 3.0, 22.0, 18.0, 7.0, 11.0, 8.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 74.0, 0.0, 4.0, 0.0, 26.0, 12.0, 10.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 4.0, 8.0, 0.0, 0.0, 10.0, 2.0, 0.0, 5.0, 11.0, 14.0, 0.0, 5.0, 0.0, 0.0, 0.0, 7.0, 28.0, 16.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 16.0, 0.0, 71.0, 61.0, 0.0, 0.0, 11.0, 0.0, 0.0, 4.0, 35.0, 19.0, 8.0, 0.0, 9.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 9.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 2.0, 0.0, 48.0, 56.0, 8.0, 16.0, 18.0, 30.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 44.0, 64.0, 18.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 11.0, 5.0, 0.0, 0.0, 0.0, 34.0, 36.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 19.0, 10.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4114217634783575, "mean_inference_ms": 3.956020002640618, "mean_action_processing_ms": 0.7235408119837239, "mean_env_wait_ms": 0.8555291664635409, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.014580845832824707, "StateBufferConnector_ms": 0.007638812065124512, "ViewRequirementAgentConnector_ms": 0.34035563468933105}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -23.299999999999656, "episode_return_mean": 147.50099999999978, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 182.1373115480647, "num_env_steps_trained_throughput_per_sec": 182.1373115480647, "timesteps_total": 252000, "num_env_steps_sampled_lifetime": 252000, "num_agent_steps_sampled_lifetime": 1008000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1008000, "timers": {"training_iteration_time_ms": 19143.872, "restore_workers_time_ms": 0.021, "training_step_time_ms": 19143.777, "sample_time_ms": 4376.422, "learn_time_ms": 14715.667, "learn_throughput": 271.819, "synch_weights_time_ms": 47.385}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 1008000, "num_agent_steps_trained": 1008000}, "done": false, "training_iteration": 63, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-10-49", "timestamp": 1723522249, "time_this_iter_s": 22.044553995132446, "time_total_s": 1119.071593284607, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x330dc5ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1119.071593284607, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 88.86774193548388, "ram_util_percent": 83.73870967741935}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8424560408940707, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.9973429526916887, "policy_loss": -0.00022162935085515812, "vf_loss": 0.9975638942704315, "vf_explained_var": 0.0005092333548914188, "kl": 0.0062342254423633165, "entropy": 0.9694584605555056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.201610086148694, "cur_kl_coeff": 1.117587089538574e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.607914177324406, "policy_loss": -0.0016121379333848833, "vf_loss": 6.609526315315691, "vf_explained_var": 0.39574473869232907, "kl": 0.007075032800568884, "entropy": 0.5411007826763486, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 120015.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -23.299999999999656, "episode_reward_mean": 157.74899999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -443.49999999999875, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 319.0}, "policy_reward_mean": {"prey_policy": 69.68449999999999, "predator_policy": 9.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 40.0000000000003, 213.9999999999993, 104.79999999999993, 127.29999999999976, 184.09999999999943, 210.99999999999932, 258.6999999999995, 197.79999999999936, 209.99999999999932, 160.09999999999954, 299.99999999999983, 40.0000000000003, 177.19999999999914, 237.89999999999975, -4.499999999999808, 111.99999999999989, 40.0000000000003, 199.99999999999935, 230.79999999999933, 187.09999999999943, -23.299999999999656, 272.1999999999996, 74.69999999999966, 134.59999999999965, 21.70000000000005, 203.99999999999932, 30.100000000000165, 290.20000000000005, 164.1999999999995, 30.100000000000158, 39.9000000000003, 400.0, 40.0000000000003, 301.9999999999999, 35.600000000000236, 37.80000000000027, 149.09999999999965, 144.9999999999997, -19.099999999999532, 40.0000000000003, 39.80000000000011, 31.200000000000166, 13.599999999999936, 183.19999999999945, 40.0000000000003, 40.0000000000003, 101.19999999999996, 112.89999999999986, 40.0000000000003, 219.99999999999926, 219.99999999999926, 29.000000000000128, 196.5999999999991, 224.4999999999993, 29.000000000000128, 209.19999999999922, 36.70000000000025, 40.0000000000003, 188.4999999999994, 38.30000000000034, 214.4999999999993, 40.0000000000003, 190.99999999999946, 219.99999999999926, 157.39999999999955, 305.5000000000007, 340.6, 40.0000000000003, 400.0, 268.5999999999998, 216.69999999999928, 219.99999999999926, 178.49999999999943, 19.099999999999977, 29.00000000000013, 345.1, 370.90000000000003, 241.5999999999994, 36.70000000000024, 40.0000000000003, 254.49999999999966, 380.0, 384.7, 3.700000000000131, 264.09999999999957, 219.99999999999926, 204.69999999999933, 243.19999999999962, 400.0, 219.99999999999926, 40.0000000000003, 121.99999999999922, 217.4999999999995, 215.79999999999927, 204.49999999999972, 181.49999999999912, 392.6, 40.0000000000003, 60.10000000000047], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 191.0, 20.000000000000014, 84.79999999999997, 107.29999999999998, 20.000000000000014, 151.1, 20.000000000000014, -1.0000000000000346, 200.0, 200.0, 58.69999999999996, 170.0, 15.799999999999963, 20.000000000000014, 185.0, 20.000000000000014, 115.10000000000001, 97.99999999999999, 197.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 150.19999999999982, 23.900000000000148, 170.0, -42.09999999999982, -9.399999999999872, 20.000000000000014, 91.99999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 30.800000000000153, 200.0, -13.599999999999826, 184.7, -175.3000000000005, 20.000000000000014, 72.19999999999996, 200.0, 17.899999999999988, 45.800000000000196, 20.000000000000014, 110.6, 31.700000000000212, -64.00000000000074, 176.0, 20.000000000000014, 20.000000000000014, 1.0999999999999617, 102.19999999999997, 170.0, 144.2, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 17.899999999999977, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 109.99999999999997, 188.0, 20.000000000000014, 11.599999999999964, 15.799999999999963, 20.000000000000014, -99.70000000000076, 144.79999999999998, 3.1999999999999615, 117.80000000000004, -51.40000000000005, -15.699999999999779, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 30.799999999999997, 3.1999999999999615, 20.000000000000014, -114.40000000000049, 20.000000000000014, -13.89999999999976, 175.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 81.19999999999996, 20.000000000000014, 20.000000000000014, 92.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 17.899999999999988, 1.099999999999983, 20.000000000000014, 176.59999999999985, 200.0, 24.500000000000007, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 189.19999999999996, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 168.5, 9.200000000000026, 1.0999999999999759, 9.499999999999964, 200.0, 20.000000000000014, 20.000000000000014, 185.0, -64.00000000000045, 200.0, 20.000000000000014, -13.59999999999979, 155.0, 105.4999999999994, 200.0, 140.6, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 68.59999999999975, 200.0, 200.0, 13.699999999999964, 200.0, 20.000000000000014, 144.50000000000003, 20.000000000000014, -19.899999999999743, 20.000000000000014, -0.9999999999999917, 20.000000000000014, 200.0, 145.1, 182.89999999999995, 182.0, 41.59999999999998, 200.0, 20.000000000000014, 13.69999999999997, 20.000000000000014, 20.000000000000014, -443.49999999999875, 95.00000000000009, 170.0, 200.0, 184.7, 200.0, 20.000000000000014, -49.299999999999834, 200.0, 64.09999999999997, 200.0, 20.000000000000014, -28.299999999999784, 200.0, 170.0, 63.200000000000024, 200.0, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 143.89999999999966, -82.90000000000072, 200.0, -47.49999999999997, 197.0, 15.799999999999963, 12.500000000000178, 170.0, 170.2999999999998, 3.1999999999999615, 200.0, 191.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.10000000000016], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 4.0, 8.0, 0.0, 0.0, 10.0, 2.0, 0.0, 5.0, 11.0, 14.0, 0.0, 5.0, 0.0, 0.0, 0.0, 7.0, 28.0, 16.0, 47.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 16.0, 0.0, 71.0, 61.0, 0.0, 0.0, 11.0, 0.0, 0.0, 4.0, 35.0, 19.0, 8.0, 0.0, 9.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 9.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 2.0, 0.0, 48.0, 56.0, 8.0, 16.0, 18.0, 30.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 44.0, 64.0, 18.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 11.0, 5.0, 0.0, 0.0, 0.0, 34.0, 36.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 19.0, 10.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 319.0, 284.0, 10.0, 0.0, 0.0, 0.0, 14.0, 19.0, 0.0, 0.0, 0.0, 0.0, 10.0, 23.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 26.0, 40.0, 25.0, 1.0, 2.0, 22.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 12.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4196720580789997, "mean_inference_ms": 3.9911172359525358, "mean_action_processing_ms": 0.7308831241300221, "mean_env_wait_ms": 0.8596433900792998, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020642876625061035, "StateBufferConnector_ms": 0.009738564491271973, "ViewRequirementAgentConnector_ms": 0.41760993003845215}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -23.299999999999656, "episode_return_mean": 157.74899999999982, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 151.74501673456362, "num_env_steps_trained_throughput_per_sec": 151.74501673456362, "timesteps_total": 256000, "num_env_steps_sampled_lifetime": 256000, "num_agent_steps_sampled_lifetime": 1024000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1024000, "timers": {"training_iteration_time_ms": 19936.607, "restore_workers_time_ms": 0.021, "training_step_time_ms": 19936.521, "sample_time_ms": 5065.99, "learn_time_ms": 14819.346, "learn_throughput": 269.917, "synch_weights_time_ms": 47.126}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 1024000, "num_agent_steps_trained": 1024000}, "done": false, "training_iteration": 64, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-11-16", "timestamp": 1723522276, "time_this_iter_s": 26.427183866500854, "time_total_s": 1145.4987771511078, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d1a940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1145.4987771511078, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 92.86486486486486, "ram_util_percent": 83.63513513513513}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.777098796780778, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.257728681835548, "policy_loss": -0.0032705369540958337, "vf_loss": 0.26099730809288474, "vf_explained_var": -0.00979353630984271, "kl": 0.017391436474922507, "entropy": 1.0255949680136625, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.7535006490334, "cur_kl_coeff": 1.117587089538574e-09, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.728171396129346, "policy_loss": 0.00031309524186389154, "vf_loss": 4.727858309644871, "vf_explained_var": 0.6576781224636804, "kl": 0.0025638889831621253, "entropy": 0.8778265854038259, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 121905.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -23.299999999999656, "episode_reward_mean": 151.8459999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -443.49999999999875, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 319.0}, "policy_reward_mean": {"prey_policy": 66.87799999999999, "predator_policy": 9.045}, "custom_metrics": {}, "hist_stats": {"episode_reward": [199.99999999999935, 230.79999999999933, 187.09999999999943, -23.299999999999656, 272.1999999999996, 74.69999999999966, 134.59999999999965, 21.70000000000005, 203.99999999999932, 30.100000000000165, 290.20000000000005, 164.1999999999995, 30.100000000000158, 39.9000000000003, 400.0, 40.0000000000003, 301.9999999999999, 35.600000000000236, 37.80000000000027, 149.09999999999965, 144.9999999999997, -19.099999999999532, 40.0000000000003, 39.80000000000011, 31.200000000000166, 13.599999999999936, 183.19999999999945, 40.0000000000003, 40.0000000000003, 101.19999999999996, 112.89999999999986, 40.0000000000003, 219.99999999999926, 219.99999999999926, 29.000000000000128, 196.5999999999991, 224.4999999999993, 29.000000000000128, 209.19999999999922, 36.70000000000025, 40.0000000000003, 188.4999999999994, 38.30000000000034, 214.4999999999993, 40.0000000000003, 190.99999999999946, 219.99999999999926, 157.39999999999955, 305.5000000000007, 340.6, 40.0000000000003, 400.0, 268.5999999999998, 216.69999999999928, 219.99999999999926, 178.49999999999943, 19.099999999999977, 29.00000000000013, 345.1, 370.90000000000003, 241.5999999999994, 36.70000000000024, 40.0000000000003, 254.49999999999966, 380.0, 384.7, 3.700000000000131, 264.09999999999957, 219.99999999999926, 204.69999999999933, 243.19999999999962, 400.0, 219.99999999999926, 40.0000000000003, 121.99999999999922, 217.4999999999995, 215.79999999999927, 204.49999999999972, 181.49999999999912, 392.6, 40.0000000000003, 60.10000000000047, 164.19999999999996, 40.0000000000003, 35.60000000000023, 179.499999999999, 211.9999999999993, 201.99999999999923, 378.0, 40.0000000000003, 40.0000000000003, 73.29999999999983, 193.89999999999938, 45.4000000000004, 219.99999999999926, 40.0000000000003, 140.19999999999965, 195.59999999999937, 7.000000000000007, 33.400000000000205], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 170.0, 30.800000000000153, 200.0, -13.599999999999826, 184.7, -175.3000000000005, 20.000000000000014, 72.19999999999996, 200.0, 17.899999999999988, 45.800000000000196, 20.000000000000014, 110.6, 31.700000000000212, -64.00000000000074, 176.0, 20.000000000000014, 20.000000000000014, 1.0999999999999617, 102.19999999999997, 170.0, 144.2, 20.000000000000014, 1.0999999999999652, 20.000000000000014, 17.899999999999977, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 109.99999999999997, 188.0, 20.000000000000014, 11.599999999999964, 15.799999999999963, 20.000000000000014, -99.70000000000076, 144.79999999999998, 3.1999999999999615, 117.80000000000004, -51.40000000000005, -15.699999999999779, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 30.799999999999997, 3.1999999999999615, 20.000000000000014, -114.40000000000049, 20.000000000000014, -13.89999999999976, 175.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 81.19999999999996, 20.000000000000014, 20.000000000000014, 92.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 17.899999999999988, 1.099999999999983, 20.000000000000014, 176.59999999999985, 200.0, 24.500000000000007, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 189.19999999999996, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 168.5, 9.200000000000026, 1.0999999999999759, 9.499999999999964, 200.0, 20.000000000000014, 20.000000000000014, 185.0, -64.00000000000045, 200.0, 20.000000000000014, -13.59999999999979, 155.0, 105.4999999999994, 200.0, 140.6, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 68.59999999999975, 200.0, 200.0, 13.699999999999964, 200.0, 20.000000000000014, 144.50000000000003, 20.000000000000014, -19.899999999999743, 20.000000000000014, -0.9999999999999917, 20.000000000000014, 200.0, 145.1, 182.89999999999995, 182.0, 41.59999999999998, 200.0, 20.000000000000014, 13.69999999999997, 20.000000000000014, 20.000000000000014, -443.49999999999875, 95.00000000000009, 170.0, 200.0, 184.7, 200.0, 20.000000000000014, -49.299999999999834, 200.0, 64.09999999999997, 200.0, 20.000000000000014, -28.299999999999784, 200.0, 170.0, 63.200000000000024, 200.0, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 143.89999999999966, -82.90000000000072, 200.0, -47.49999999999997, 197.0, 15.799999999999963, 12.500000000000178, 170.0, 170.2999999999998, 3.1999999999999615, 200.0, 191.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.10000000000016, 68.59999999999997, 86.59999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999975, 36.19999999999999, 143.29999999999964, 20.000000000000014, 188.0, 126.19999999999953, 24.80000000000014, 200.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 53.30000000000023, 5.299999999999965, 176.6, 20.000000000000014, 25.400000000000112, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 117.19999999999999, 170.0, 11.599999999999964, 20.000000000000014, -42.99999999999981, 7.399999999999965, 20.000000000000014], "policy_predator_policy_reward": [10.0, 0.0, 0.0, 0.0, 16.0, 0.0, 71.0, 61.0, 0.0, 0.0, 11.0, 0.0, 0.0, 4.0, 35.0, 19.0, 8.0, 0.0, 9.0, 0.0, 8.0, 10.0, 0.0, 0.0, 0.0, 9.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 2.0, 0.0, 48.0, 56.0, 8.0, 16.0, 18.0, 30.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 44.0, 64.0, 18.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 11.0, 5.0, 0.0, 0.0, 0.0, 34.0, 36.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 19.0, 10.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 319.0, 284.0, 10.0, 0.0, 0.0, 0.0, 14.0, 19.0, 0.0, 0.0, 0.0, 0.0, 10.0, 23.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 26.0, 40.0, 25.0, 1.0, 2.0, 22.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 22.0, 29.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 14.0, 0.0, 30.0, 0.0, 6.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.440951056504416, "mean_inference_ms": 4.0452632588963615, "mean_action_processing_ms": 0.7284595656287348, "mean_env_wait_ms": 0.8725328735330087, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020746588706970215, "StateBufferConnector_ms": 0.0162200927734375, "ViewRequirementAgentConnector_ms": 0.4413706064224243}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -23.299999999999656, "episode_return_mean": 151.8459999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 213.2222285753277, "num_env_steps_trained_throughput_per_sec": 213.2222285753277, "timesteps_total": 260000, "num_env_steps_sampled_lifetime": 260000, "num_agent_steps_sampled_lifetime": 1040000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1040000, "timers": {"training_iteration_time_ms": 19807.99, "restore_workers_time_ms": 0.021, "training_step_time_ms": 19807.906, "sample_time_ms": 5186.572, "learn_time_ms": 14593.587, "learn_throughput": 274.093, "synch_weights_time_ms": 24.128}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 1040000, "num_agent_steps_trained": 1040000}, "done": false, "training_iteration": 65, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-11-35", "timestamp": 1723522295, "time_this_iter_s": 18.883253812789917, "time_total_s": 1164.3820309638977, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28e00d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1164.3820309638977, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 83.41851851851852, "ram_util_percent": 83.28148148148148}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5347051455900467, "cur_kl_coeff": 0.00010986328125000003, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2008599015632792, "policy_loss": -0.00531231986664275, "vf_loss": 0.20616857033962752, "vf_explained_var": -0.02498677382393489, "kl": 0.03322880923769863, "entropy": 1.040174231138179, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.47232021043698, "cur_kl_coeff": 5.58793544769287e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.801834717503301, "policy_loss": -0.002262174498127212, "vf_loss": 5.804096905390422, "vf_explained_var": 0.6968908718969457, "kl": 0.0038169547237736448, "entropy": 0.7150050764361386, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 123795.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -19.099999999999532, "episode_reward_mean": 157.3039999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -443.49999999999875, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 319.0}, "policy_reward_mean": {"prey_policy": 70.487, "predator_policy": 8.165}, "custom_metrics": {}, "hist_stats": {"episode_reward": [37.80000000000027, 149.09999999999965, 144.9999999999997, -19.099999999999532, 40.0000000000003, 39.80000000000011, 31.200000000000166, 13.599999999999936, 183.19999999999945, 40.0000000000003, 40.0000000000003, 101.19999999999996, 112.89999999999986, 40.0000000000003, 219.99999999999926, 219.99999999999926, 29.000000000000128, 196.5999999999991, 224.4999999999993, 29.000000000000128, 209.19999999999922, 36.70000000000025, 40.0000000000003, 188.4999999999994, 38.30000000000034, 214.4999999999993, 40.0000000000003, 190.99999999999946, 219.99999999999926, 157.39999999999955, 305.5000000000007, 340.6, 40.0000000000003, 400.0, 268.5999999999998, 216.69999999999928, 219.99999999999926, 178.49999999999943, 19.099999999999977, 29.00000000000013, 345.1, 370.90000000000003, 241.5999999999994, 36.70000000000024, 40.0000000000003, 254.49999999999966, 380.0, 384.7, 3.700000000000131, 264.09999999999957, 219.99999999999926, 204.69999999999933, 243.19999999999962, 400.0, 219.99999999999926, 40.0000000000003, 121.99999999999922, 217.4999999999995, 215.79999999999927, 204.49999999999972, 181.49999999999912, 392.6, 40.0000000000003, 60.10000000000047, 164.19999999999996, 40.0000000000003, 35.60000000000023, 179.499999999999, 211.9999999999993, 201.99999999999923, 378.0, 40.0000000000003, 40.0000000000003, 73.29999999999983, 193.89999999999938, 45.4000000000004, 219.99999999999926, 40.0000000000003, 140.19999999999965, 195.59999999999937, 7.000000000000007, 33.400000000000205, 205.2999999999993, 219.99999999999926, 170.49999999999983, 55.10000000000026, 32.30000000000018, 113.5999999999986, 170.1999999999995, 104.79999999999986, 400.0, 282.9000000000001, 245.69999999999985, 184.89999999999938, 211.69999999999942, 197.99999999999937, 167.0999999999995, 72.4000000000002, 181.39999999999944, 163.79999999999956], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [15.799999999999963, 20.000000000000014, -99.70000000000076, 144.79999999999998, 3.1999999999999615, 117.80000000000004, -51.40000000000005, -15.699999999999779, 20.000000000000014, 20.000000000000014, -0.9999999999999846, 30.799999999999997, 3.1999999999999615, 20.000000000000014, -114.40000000000049, 20.000000000000014, -13.89999999999976, 175.1, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 81.19999999999996, 20.000000000000014, 20.000000000000014, 92.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 17.899999999999988, 1.099999999999983, 20.000000000000014, 176.59999999999985, 200.0, 24.500000000000007, 20.000000000000014, -0.9999999999999846, 20.000000000000014, 189.19999999999996, 20.000000000000014, 13.699999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 168.5, 9.200000000000026, 1.0999999999999759, 9.499999999999964, 200.0, 20.000000000000014, 20.000000000000014, 185.0, -64.00000000000045, 200.0, 20.000000000000014, -13.59999999999979, 155.0, 105.4999999999994, 200.0, 140.6, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 68.59999999999975, 200.0, 200.0, 13.699999999999964, 200.0, 20.000000000000014, 144.50000000000003, 20.000000000000014, -19.899999999999743, 20.000000000000014, -0.9999999999999917, 20.000000000000014, 200.0, 145.1, 182.89999999999995, 182.0, 41.59999999999998, 200.0, 20.000000000000014, 13.69999999999997, 20.000000000000014, 20.000000000000014, -443.49999999999875, 95.00000000000009, 170.0, 200.0, 184.7, 200.0, 20.000000000000014, -49.299999999999834, 200.0, 64.09999999999997, 200.0, 20.000000000000014, -28.299999999999784, 200.0, 170.0, 63.200000000000024, 200.0, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 143.89999999999966, -82.90000000000072, 200.0, -47.49999999999997, 197.0, 15.799999999999963, 12.500000000000178, 170.0, 170.2999999999998, 3.1999999999999615, 200.0, 191.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.10000000000016, 68.59999999999997, 86.59999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999975, 36.19999999999999, 143.29999999999964, 20.000000000000014, 188.0, 126.19999999999953, 24.80000000000014, 200.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 53.30000000000023, 5.299999999999965, 176.6, 20.000000000000014, 25.400000000000112, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 117.19999999999999, 170.0, 11.599999999999964, 20.000000000000014, -42.99999999999981, 7.399999999999965, 20.000000000000014, 20.000000000000014, 179.29999999999998, 200.0, 20.000000000000014, 120.79999999999998, 49.69999999999997, 36.200000000000095, 17.899999999999988, 13.699999999999966, 11.599999999999964, 92.59999999999934, 20.000000000000014, 21.80000000000004, 142.39999999999998, 84.79999999999994, 20.000000000000014, 200.0, 200.0, 93.80000000000007, 175.10000000000002, 151.7, 82.99999999999997, 164.89999999999998, 20.000000000000014, 31.700000000000113, 170.0, 167.0, 20.000000000000014, 139.1, 20.000000000000014, 20.000000000000014, 52.39999999999996, 148.39999999999998, 20.000000000000014, 149.9, -3.0999999999999863], "policy_predator_policy_reward": [2.0, 0.0, 48.0, 56.0, 8.0, 16.0, 18.0, 30.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 44.0, 64.0, 18.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 11.0, 5.0, 0.0, 0.0, 0.0, 34.0, 36.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 19.0, 10.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 319.0, 284.0, 10.0, 0.0, 0.0, 0.0, 14.0, 19.0, 0.0, 0.0, 0.0, 0.0, 10.0, 23.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 26.0, 40.0, 25.0, 1.0, 2.0, 22.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 22.0, 29.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 14.0, 0.0, 30.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 12.0, 0.0, 11.0, 0.0, 0.0, 0.0, 10.0, 11.0, 0.0, 8.0, 0.0, 0.0, 0.0, 3.0, 10.0, 0.0, 17.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4536024843346624, "mean_inference_ms": 4.083296107916379, "mean_action_processing_ms": 0.7312937745701799, "mean_env_wait_ms": 0.8805108098406322, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020181775093078613, "StateBufferConnector_ms": 0.015390396118164062, "ViewRequirementAgentConnector_ms": 0.4146449565887451}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -19.099999999999532, "episode_return_mean": 157.3039999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 222.04554745778327, "num_env_steps_trained_throughput_per_sec": 222.04554745778327, "timesteps_total": 264000, "num_env_steps_sampled_lifetime": 264000, "num_agent_steps_sampled_lifetime": 1056000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1056000, "timers": {"training_iteration_time_ms": 19848.346, "restore_workers_time_ms": 0.018, "training_step_time_ms": 19848.265, "sample_time_ms": 5434.691, "learn_time_ms": 14385.012, "learn_throughput": 278.067, "synch_weights_time_ms": 24.59}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 1056000, "num_agent_steps_trained": 1056000}, "done": false, "training_iteration": 66, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-11-53", "timestamp": 1723522313, "time_this_iter_s": 18.10930895805359, "time_total_s": 1182.4913399219513, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d75a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1182.4913399219513, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 85.55384615384615, "ram_util_percent": 83.2346153846154}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9179226979790699, "cur_kl_coeff": 0.000164794921875, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.619568585261466, "policy_loss": -0.0023557477288204368, "vf_loss": 0.6219224113320547, "vf_explained_var": 0.00401854742140997, "kl": 0.011660961556745722, "entropy": 0.9781250361727659, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 12.325762956262265, "cur_kl_coeff": 2.793967723846435e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.768173885597753, "policy_loss": -0.0016066437716492348, "vf_loss": 5.769780533906644, "vf_explained_var": 0.6706996603932961, "kl": 0.0029741318831596917, "entropy": 0.7280550774443086, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 125685.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -13.69999999999964, "episode_reward_mean": 169.9339999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -443.49999999999875, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 319.0}, "policy_reward_mean": {"prey_policy": 77.05699999999999, "predator_policy": 7.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 188.4999999999994, 38.30000000000034, 214.4999999999993, 40.0000000000003, 190.99999999999946, 219.99999999999926, 157.39999999999955, 305.5000000000007, 340.6, 40.0000000000003, 400.0, 268.5999999999998, 216.69999999999928, 219.99999999999926, 178.49999999999943, 19.099999999999977, 29.00000000000013, 345.1, 370.90000000000003, 241.5999999999994, 36.70000000000024, 40.0000000000003, 254.49999999999966, 380.0, 384.7, 3.700000000000131, 264.09999999999957, 219.99999999999926, 204.69999999999933, 243.19999999999962, 400.0, 219.99999999999926, 40.0000000000003, 121.99999999999922, 217.4999999999995, 215.79999999999927, 204.49999999999972, 181.49999999999912, 392.6, 40.0000000000003, 60.10000000000047, 164.19999999999996, 40.0000000000003, 35.60000000000023, 179.499999999999, 211.9999999999993, 201.99999999999923, 378.0, 40.0000000000003, 40.0000000000003, 73.29999999999983, 193.89999999999938, 45.4000000000004, 219.99999999999926, 40.0000000000003, 140.19999999999965, 195.59999999999937, 7.000000000000007, 33.400000000000205, 205.2999999999993, 219.99999999999926, 170.49999999999983, 55.10000000000026, 32.30000000000018, 113.5999999999986, 170.1999999999995, 104.79999999999986, 400.0, 282.9000000000001, 245.69999999999985, 184.89999999999938, 211.69999999999942, 197.99999999999937, 167.0999999999995, 72.4000000000002, 181.39999999999944, 163.79999999999956, 22.400000000000013, 219.99999999999926, 150.79999999999998, 15.799999999999969, 198.8999999999998, 219.99999999999926, 358.0, 219.99999999999926, 219.99999999999926, 219.99999999999926, 26.80000000000009, 12.400000000000048, 240.49999999999983, 40.0000000000003, 227.69999999999933, 38.90000000000028, 219.99999999999926, -13.69999999999964, 320.3999999999999, 201.09999999999934, 61.60000000000051, 161.09999999999914], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 168.5, 9.200000000000026, 1.0999999999999759, 9.499999999999964, 200.0, 20.000000000000014, 20.000000000000014, 185.0, -64.00000000000045, 200.0, 20.000000000000014, -13.59999999999979, 155.0, 105.4999999999994, 200.0, 140.6, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 68.59999999999975, 200.0, 200.0, 13.699999999999964, 200.0, 20.000000000000014, 144.50000000000003, 20.000000000000014, -19.899999999999743, 20.000000000000014, -0.9999999999999917, 20.000000000000014, 200.0, 145.1, 182.89999999999995, 182.0, 41.59999999999998, 200.0, 20.000000000000014, 13.69999999999997, 20.000000000000014, 20.000000000000014, -443.49999999999875, 95.00000000000009, 170.0, 200.0, 184.7, 200.0, 20.000000000000014, -49.299999999999834, 200.0, 64.09999999999997, 200.0, 20.000000000000014, -28.299999999999784, 200.0, 170.0, 63.200000000000024, 200.0, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 143.89999999999966, -82.90000000000072, 200.0, -47.49999999999997, 197.0, 15.799999999999963, 12.500000000000178, 170.0, 170.2999999999998, 3.1999999999999615, 200.0, 191.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.10000000000016, 68.59999999999997, 86.59999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999975, 36.19999999999999, 143.29999999999964, 20.000000000000014, 188.0, 126.19999999999953, 24.80000000000014, 200.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 53.30000000000023, 5.299999999999965, 176.6, 20.000000000000014, 25.400000000000112, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 117.19999999999999, 170.0, 11.599999999999964, 20.000000000000014, -42.99999999999981, 7.399999999999965, 20.000000000000014, 20.000000000000014, 179.29999999999998, 200.0, 20.000000000000014, 120.79999999999998, 49.69999999999997, 36.200000000000095, 17.899999999999988, 13.699999999999966, 11.599999999999964, 92.59999999999934, 20.000000000000014, 21.80000000000004, 142.39999999999998, 84.79999999999994, 20.000000000000014, 200.0, 200.0, 93.80000000000007, 175.10000000000002, 151.7, 82.99999999999997, 164.89999999999998, 20.000000000000014, 31.700000000000113, 170.0, 167.0, 20.000000000000014, 139.1, 20.000000000000014, 20.000000000000014, 52.39999999999996, 148.39999999999998, 20.000000000000014, 149.9, -3.0999999999999863, -13.599999999999783, 20.000000000000014, 200.0, 20.000000000000014, 74.89999999999996, 62.90000000000013, 11.599999999999964, -17.79999999999975, 15.800000000000104, 163.1, 200.0, 20.000000000000014, 176.0, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 20.000000000000014, -76.60000000000075, 149.3, 81.19999999999996, 20.000000000000014, 20.000000000000014, 194.0, 31.699999999999996, 17.899999999999988, 20.000000000000014, 20.000000000000014, 200.0, -38.799999999999784, -82.90000000000065, 124.39999999999998, 194.0, 181.1, 20.000000000000014, 41.60000000000025, 20.000000000000014, 20.000000000000014, 130.09999999999977], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 17.0, 11.0, 5.0, 0.0, 0.0, 0.0, 34.0, 36.0, 0.0, 0.0, 11.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 14.0, 0.0, 19.0, 10.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 319.0, 284.0, 10.0, 0.0, 0.0, 0.0, 14.0, 19.0, 0.0, 0.0, 0.0, 0.0, 10.0, 23.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 26.0, 40.0, 25.0, 1.0, 2.0, 22.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 22.0, 29.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 14.0, 0.0, 30.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 12.0, 0.0, 11.0, 0.0, 0.0, 0.0, 10.0, 11.0, 0.0, 8.0, 0.0, 0.0, 0.0, 3.0, 10.0, 0.0, 17.0, 9.0, 7.0, 0.0, 0.0, 0.0, 13.0, 20.0, 2.0, 20.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 35.0, 34.0, 10.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 63.0, 45.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4579998501387472, "mean_inference_ms": 4.102114570009087, "mean_action_processing_ms": 0.7299360528077924, "mean_env_wait_ms": 0.8846945646048329, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02065896987915039, "StateBufferConnector_ms": 0.014961957931518555, "ViewRequirementAgentConnector_ms": 0.30660462379455566}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -13.69999999999964, "episode_return_mean": 169.9339999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 193.44674914369466, "num_env_steps_trained_throughput_per_sec": 193.44674914369466, "timesteps_total": 268000, "num_env_steps_sampled_lifetime": 268000, "num_agent_steps_sampled_lifetime": 1072000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1072000, "timers": {"training_iteration_time_ms": 20378.624, "restore_workers_time_ms": 0.018, "training_step_time_ms": 20378.542, "sample_time_ms": 5665.271, "learn_time_ms": 14683.63, "learn_throughput": 272.412, "synch_weights_time_ms": 25.154}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 1072000, "num_agent_steps_trained": 1072000}, "done": false, "training_iteration": 67, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-12-14", "timestamp": 1723522334, "time_this_iter_s": 20.76315188407898, "time_total_s": 1203.2544918060303, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d1a670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1203.2544918060303, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 93.67586206896553, "ram_util_percent": 83.66206896551725}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9142182321775527, "cur_kl_coeff": 0.000164794921875, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6426237767808651, "policy_loss": -0.0012089032531967239, "vf_loss": 0.6438308042311479, "vf_explained_var": 0.006214567593165806, "kl": 0.011369716892222798, "entropy": 1.0078250425833244, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 11.853175482011977, "cur_kl_coeff": 1.3969838619232175e-10, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.754403396384426, "policy_loss": -0.00033621073148592753, "vf_loss": 5.754739616030738, "vf_explained_var": 0.6932054650531244, "kl": 0.0007697853709379474, "entropy": 0.7107048835388567, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 127575.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -13.69999999999964, "episode_reward_mean": 169.52299999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -443.49999999999875, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 319.0}, "policy_reward_mean": {"prey_policy": 76.4615, "predator_policy": 8.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [345.1, 370.90000000000003, 241.5999999999994, 36.70000000000024, 40.0000000000003, 254.49999999999966, 380.0, 384.7, 3.700000000000131, 264.09999999999957, 219.99999999999926, 204.69999999999933, 243.19999999999962, 400.0, 219.99999999999926, 40.0000000000003, 121.99999999999922, 217.4999999999995, 215.79999999999927, 204.49999999999972, 181.49999999999912, 392.6, 40.0000000000003, 60.10000000000047, 164.19999999999996, 40.0000000000003, 35.60000000000023, 179.499999999999, 211.9999999999993, 201.99999999999923, 378.0, 40.0000000000003, 40.0000000000003, 73.29999999999983, 193.89999999999938, 45.4000000000004, 219.99999999999926, 40.0000000000003, 140.19999999999965, 195.59999999999937, 7.000000000000007, 33.400000000000205, 205.2999999999993, 219.99999999999926, 170.49999999999983, 55.10000000000026, 32.30000000000018, 113.5999999999986, 170.1999999999995, 104.79999999999986, 400.0, 282.9000000000001, 245.69999999999985, 184.89999999999938, 211.69999999999942, 197.99999999999937, 167.0999999999995, 72.4000000000002, 181.39999999999944, 163.79999999999956, 22.400000000000013, 219.99999999999926, 150.79999999999998, 15.799999999999969, 198.8999999999998, 219.99999999999926, 358.0, 219.99999999999926, 219.99999999999926, 219.99999999999926, 26.80000000000009, 12.400000000000048, 240.49999999999983, 40.0000000000003, 227.69999999999933, 38.90000000000028, 219.99999999999926, -13.69999999999964, 320.3999999999999, 201.09999999999934, 61.60000000000051, 161.09999999999914, 361.1, 185.99999999999943, 265.8999999999994, 219.99999999999926, 206.99999999999932, 40.0000000000003, 57.60000000000031, 48.80000000000025, 169.3999999999995, 139.69999999999965, 380.0, 73.29999999999974, 100.39999999999856, 219.99999999999926, 69.70000000000022, 130.8999999999997, 356.80000000000007, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 145.1, 182.89999999999995, 182.0, 41.59999999999998, 200.0, 20.000000000000014, 13.69999999999997, 20.000000000000014, 20.000000000000014, -443.49999999999875, 95.00000000000009, 170.0, 200.0, 184.7, 200.0, 20.000000000000014, -49.299999999999834, 200.0, 64.09999999999997, 200.0, 20.000000000000014, -28.299999999999784, 200.0, 170.0, 63.200000000000024, 200.0, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 143.89999999999966, -82.90000000000072, 200.0, -47.49999999999997, 197.0, 15.799999999999963, 12.500000000000178, 170.0, 170.2999999999998, 3.1999999999999615, 200.0, 191.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 28.10000000000016, 68.59999999999997, 86.59999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999975, 36.19999999999999, 143.29999999999964, 20.000000000000014, 188.0, 126.19999999999953, 24.80000000000014, 200.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 53.30000000000023, 5.299999999999965, 176.6, 20.000000000000014, 25.400000000000112, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 117.19999999999999, 170.0, 11.599999999999964, 20.000000000000014, -42.99999999999981, 7.399999999999965, 20.000000000000014, 20.000000000000014, 179.29999999999998, 200.0, 20.000000000000014, 120.79999999999998, 49.69999999999997, 36.200000000000095, 17.899999999999988, 13.699999999999966, 11.599999999999964, 92.59999999999934, 20.000000000000014, 21.80000000000004, 142.39999999999998, 84.79999999999994, 20.000000000000014, 200.0, 200.0, 93.80000000000007, 175.10000000000002, 151.7, 82.99999999999997, 164.89999999999998, 20.000000000000014, 31.700000000000113, 170.0, 167.0, 20.000000000000014, 139.1, 20.000000000000014, 20.000000000000014, 52.39999999999996, 148.39999999999998, 20.000000000000014, 149.9, -3.0999999999999863, -13.599999999999783, 20.000000000000014, 200.0, 20.000000000000014, 74.89999999999996, 62.90000000000013, 11.599999999999964, -17.79999999999975, 15.800000000000104, 163.1, 200.0, 20.000000000000014, 176.0, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 20.000000000000014, -76.60000000000075, 149.3, 81.19999999999996, 20.000000000000014, 20.000000000000014, 194.0, 31.699999999999996, 17.899999999999988, 20.000000000000014, 20.000000000000014, 200.0, -38.799999999999784, -82.90000000000065, 124.39999999999998, 194.0, 181.1, 20.000000000000014, 41.60000000000025, 20.000000000000014, 20.000000000000014, 130.09999999999977, 200.0, 151.10000000000002, 20.000000000000014, 149.0, 200.0, 65.90000000000008, 20.000000000000014, 200.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -36.6999999999998, 47.30000000000014, -34.59999999999975, -22.600000000000236, 139.40000000000003, 20.000000000000014, 22.700000000000053, 107.00000000000004, 200.0, 170.0, 53.30000000000018, 20.000000000000014, 11.599999999999964, 84.79999999999941, 200.0, 20.000000000000014, 49.69999999999997, 20.000000000000014, 20.000000000000014, 101.89999999999999, 200.0, 156.8, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 319.0, 284.0, 10.0, 0.0, 0.0, 0.0, 14.0, 19.0, 0.0, 0.0, 0.0, 0.0, 10.0, 23.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 35.0, 26.0, 40.0, 25.0, 1.0, 2.0, 22.0, 0.0, 0.0, 8.0, 0.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 22.0, 29.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 14.0, 0.0, 30.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 12.0, 0.0, 11.0, 0.0, 0.0, 0.0, 10.0, 11.0, 0.0, 8.0, 0.0, 0.0, 0.0, 3.0, 10.0, 0.0, 17.0, 9.0, 7.0, 0.0, 0.0, 0.0, 13.0, 20.0, 2.0, 20.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 35.0, 34.0, 10.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 63.0, 45.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 10.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 41.0, 6.0, 69.0, 37.0, 10.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4748740415702275, "mean_inference_ms": 4.15196143568171, "mean_action_processing_ms": 0.7365230115160907, "mean_env_wait_ms": 0.8957295397513647, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.011941075325012207, "StateBufferConnector_ms": 0.01339864730834961, "ViewRequirementAgentConnector_ms": 0.3641066551208496}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -13.69999999999964, "episode_return_mean": 169.52299999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 204.3435247029591, "num_env_steps_trained_throughput_per_sec": 204.3435247029591, "timesteps_total": 272000, "num_env_steps_sampled_lifetime": 272000, "num_agent_steps_sampled_lifetime": 1088000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1088000, "timers": {"training_iteration_time_ms": 20789.934, "restore_workers_time_ms": 0.019, "training_step_time_ms": 20789.872, "sample_time_ms": 6061.488, "learn_time_ms": 14699.869, "learn_throughput": 272.111, "synch_weights_time_ms": 24.26}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 1088000, "num_agent_steps_trained": 1088000}, "done": false, "training_iteration": 68, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-12-33", "timestamp": 1723522353, "time_this_iter_s": 19.64589285850525, "time_total_s": 1222.9003846645355, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d1a160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1222.9003846645355, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 89.4285714285714, "ram_util_percent": 83.77142857142857}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8426035780696168, "cur_kl_coeff": 0.000164794921875, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.572643193602562, "policy_loss": -0.002689187260955651, "vf_loss": 0.5753287634560986, "vf_explained_var": 0.006900277087297389, "kl": 0.021941120325330885, "entropy": 0.9706101379066548, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 13.468554622865227, "cur_kl_coeff": 6.984919309616087e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.697011963652555, "policy_loss": -0.0014336407304095923, "vf_loss": 4.69844562023405, "vf_explained_var": 0.6494332128731662, "kl": 0.003920122200924164, "entropy": 0.8473238854496568, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 129465.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -13.69999999999964, "episode_reward_mean": 148.59099999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -82.90000000000065, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 69.0}, "policy_reward_mean": {"prey_policy": 68.4755, "predator_policy": 5.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.10000000000047, 164.19999999999996, 40.0000000000003, 35.60000000000023, 179.499999999999, 211.9999999999993, 201.99999999999923, 378.0, 40.0000000000003, 40.0000000000003, 73.29999999999983, 193.89999999999938, 45.4000000000004, 219.99999999999926, 40.0000000000003, 140.19999999999965, 195.59999999999937, 7.000000000000007, 33.400000000000205, 205.2999999999993, 219.99999999999926, 170.49999999999983, 55.10000000000026, 32.30000000000018, 113.5999999999986, 170.1999999999995, 104.79999999999986, 400.0, 282.9000000000001, 245.69999999999985, 184.89999999999938, 211.69999999999942, 197.99999999999937, 167.0999999999995, 72.4000000000002, 181.39999999999944, 163.79999999999956, 22.400000000000013, 219.99999999999926, 150.79999999999998, 15.799999999999969, 198.8999999999998, 219.99999999999926, 358.0, 219.99999999999926, 219.99999999999926, 219.99999999999926, 26.80000000000009, 12.400000000000048, 240.49999999999983, 40.0000000000003, 227.69999999999933, 38.90000000000028, 219.99999999999926, -13.69999999999964, 320.3999999999999, 201.09999999999934, 61.60000000000051, 161.09999999999914, 361.1, 185.99999999999943, 265.8999999999994, 219.99999999999926, 206.99999999999932, 40.0000000000003, 57.60000000000031, 48.80000000000025, 169.3999999999995, 139.69999999999965, 380.0, 73.29999999999974, 100.39999999999856, 219.99999999999926, 69.70000000000022, 130.8999999999997, 356.80000000000007, 40.0000000000003, 20.499999999999993, 156.79999999999956, 219.99999999999926, 142.59999999999962, 55.200000000000024, 27.90000000000011, 35.60000000000022, 153.59999999999908, 400.0, 40.0000000000003, 66.90000000000006, 86.2999999999999, 378.4, 218.49999999999926, 151.3999999999996, -12.799999999999587, 40.0000000000003, 215.99999999999926, 30.100000000000147, 185.59999999999985, 40.0000000000003, 57.30000000000006, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 28.10000000000016, 68.59999999999997, 86.59999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 11.599999999999975, 36.19999999999999, 143.29999999999964, 20.000000000000014, 188.0, 126.19999999999953, 24.80000000000014, 200.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 53.30000000000023, 5.299999999999965, 176.6, 20.000000000000014, 25.400000000000112, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 117.19999999999999, 170.0, 11.599999999999964, 20.000000000000014, -42.99999999999981, 7.399999999999965, 20.000000000000014, 20.000000000000014, 179.29999999999998, 200.0, 20.000000000000014, 120.79999999999998, 49.69999999999997, 36.200000000000095, 17.899999999999988, 13.699999999999966, 11.599999999999964, 92.59999999999934, 20.000000000000014, 21.80000000000004, 142.39999999999998, 84.79999999999994, 20.000000000000014, 200.0, 200.0, 93.80000000000007, 175.10000000000002, 151.7, 82.99999999999997, 164.89999999999998, 20.000000000000014, 31.700000000000113, 170.0, 167.0, 20.000000000000014, 139.1, 20.000000000000014, 20.000000000000014, 52.39999999999996, 148.39999999999998, 20.000000000000014, 149.9, -3.0999999999999863, -13.599999999999783, 20.000000000000014, 200.0, 20.000000000000014, 74.89999999999996, 62.90000000000013, 11.599999999999964, -17.79999999999975, 15.800000000000104, 163.1, 200.0, 20.000000000000014, 176.0, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 20.000000000000014, -76.60000000000075, 149.3, 81.19999999999996, 20.000000000000014, 20.000000000000014, 194.0, 31.699999999999996, 17.899999999999988, 20.000000000000014, 20.000000000000014, 200.0, -38.799999999999784, -82.90000000000065, 124.39999999999998, 194.0, 181.1, 20.000000000000014, 41.60000000000025, 20.000000000000014, 20.000000000000014, 130.09999999999977, 200.0, 151.10000000000002, 20.000000000000014, 149.0, 200.0, 65.90000000000008, 20.000000000000014, 200.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -36.6999999999998, 47.30000000000014, -34.59999999999975, -22.600000000000236, 139.40000000000003, 20.000000000000014, 22.700000000000053, 107.00000000000004, 200.0, 170.0, 53.30000000000018, 20.000000000000014, 11.599999999999964, 84.79999999999941, 200.0, 20.000000000000014, 49.69999999999997, 20.000000000000014, 20.000000000000014, 101.89999999999999, 200.0, 156.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -53.500000000000135, 20.000000000000014, 126.80000000000005, 20.000000000000014, 200.0, 113.6, 20.000000000000014, 20.000000000000014, 12.20000000000016, 20.000000000000014, -3.099999999999958, 20.000000000000014, 11.599999999999978, 147.79999999999967, -53.200000000000685, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 23.900000000000162, 20.000000000000014, 20.000000000000014, 35.30000000000013, 200.0, 178.4, 33.50000000000024, 173.0, -9.399999999999904, 144.8, -80.80000000000086, 20.000000000000014, 20.000000000000014, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 55.09999999999996, 96.50000000000003, 20.000000000000014, 20.000000000000014, -9.399999999999855, 49.69999999999997, 20.000000000000014, 200.0], "policy_predator_policy_reward": [12.0, 0.0, 0.0, 9.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 22.0, 29.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 14.0, 0.0, 30.0, 0.0, 6.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 12.0, 0.0, 11.0, 0.0, 0.0, 0.0, 10.0, 11.0, 0.0, 8.0, 0.0, 0.0, 0.0, 3.0, 10.0, 0.0, 17.0, 9.0, 7.0, 0.0, 0.0, 0.0, 13.0, 20.0, 2.0, 20.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 35.0, 34.0, 10.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 63.0, 45.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 10.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 41.0, 6.0, 69.0, 37.0, 10.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 35.0, 19.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 19.0, 4.0, 0.0, 11.0, 0.0, 4.0, 37.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 7.0, 24.0, 0.0, 0.0, 9.0, 3.0, 2.0, 14.0, 48.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 16.0, 18.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4803515684022706, "mean_inference_ms": 4.169407228996507, "mean_action_processing_ms": 0.7359116756350491, "mean_env_wait_ms": 0.8998506879024781, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0072307586669921875, "StateBufferConnector_ms": 0.011432886123657227, "ViewRequirementAgentConnector_ms": 0.294147253036499}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -13.69999999999964, "episode_return_mean": 148.59099999999978, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 212.50779414265025, "num_env_steps_trained_throughput_per_sec": 212.50779414265025, "timesteps_total": 276000, "num_env_steps_sampled_lifetime": 276000, "num_agent_steps_sampled_lifetime": 1104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1104000, "timers": {"training_iteration_time_ms": 20816.826, "restore_workers_time_ms": 0.018, "training_step_time_ms": 20816.765, "sample_time_ms": 6101.641, "learn_time_ms": 14688.57, "learn_throughput": 272.321, "synch_weights_time_ms": 22.822}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 1104000, "num_agent_steps_trained": 1104000}, "done": false, "training_iteration": 69, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-12-52", "timestamp": 1723522372, "time_this_iter_s": 18.913347959518433, "time_total_s": 1241.813732624054, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d3a940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1241.813732624054, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 88.85185185185186, "ram_util_percent": 83.76296296296296}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.958187398720513, "cur_kl_coeff": 0.00024719238281249993, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6673473377470617, "policy_loss": -0.00021559697004261787, "vf_loss": 0.6675612025192653, "vf_explained_var": 0.0020297131841144865, "kl": 0.007002021595824713, "entropy": 1.0000358266489846, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.789529063588096, "cur_kl_coeff": 3.4924596548080437e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.050061637636215, "policy_loss": -0.0013523910298115678, "vf_loss": 5.051414034732435, "vf_explained_var": 0.7631757674393831, "kl": 0.002441451825080971, "entropy": 0.7839970881030673, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 131355.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -40.29999999999963, "episode_reward_mean": 155.3579999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -133.3000000000006, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 73.0}, "policy_reward_mean": {"prey_policy": 71.92399999999998, "predator_policy": 5.755}, "custom_metrics": {}, "hist_stats": {"episode_reward": [33.400000000000205, 205.2999999999993, 219.99999999999926, 170.49999999999983, 55.10000000000026, 32.30000000000018, 113.5999999999986, 170.1999999999995, 104.79999999999986, 400.0, 282.9000000000001, 245.69999999999985, 184.89999999999938, 211.69999999999942, 197.99999999999937, 167.0999999999995, 72.4000000000002, 181.39999999999944, 163.79999999999956, 22.400000000000013, 219.99999999999926, 150.79999999999998, 15.799999999999969, 198.8999999999998, 219.99999999999926, 358.0, 219.99999999999926, 219.99999999999926, 219.99999999999926, 26.80000000000009, 12.400000000000048, 240.49999999999983, 40.0000000000003, 227.69999999999933, 38.90000000000028, 219.99999999999926, -13.69999999999964, 320.3999999999999, 201.09999999999934, 61.60000000000051, 161.09999999999914, 361.1, 185.99999999999943, 265.8999999999994, 219.99999999999926, 206.99999999999932, 40.0000000000003, 57.60000000000031, 48.80000000000025, 169.3999999999995, 139.69999999999965, 380.0, 73.29999999999974, 100.39999999999856, 219.99999999999926, 69.70000000000022, 130.8999999999997, 356.80000000000007, 40.0000000000003, 20.499999999999993, 156.79999999999956, 219.99999999999926, 142.59999999999962, 55.200000000000024, 27.90000000000011, 35.60000000000022, 153.59999999999908, 400.0, 40.0000000000003, 66.90000000000006, 86.2999999999999, 378.4, 218.49999999999926, 151.3999999999996, -12.799999999999587, 40.0000000000003, 215.99999999999926, 30.100000000000147, 185.59999999999985, 40.0000000000003, 57.30000000000006, 219.99999999999926, 170.4999999999995, 400.0, 215.59999999999928, 40.0000000000003, 40.0000000000003, 287.50000000000034, -40.29999999999963, 219.99999999999926, 139.19999999999965, 40.0000000000003, 345.90000000000003, 51.70000000000028, 40.0000000000003, 147.39999999999964, 32.30000000000018, 271.89999999999964, 321.8000000000012, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [7.399999999999965, 20.000000000000014, 20.000000000000014, 179.29999999999998, 200.0, 20.000000000000014, 120.79999999999998, 49.69999999999997, 36.200000000000095, 17.899999999999988, 13.699999999999966, 11.599999999999964, 92.59999999999934, 20.000000000000014, 21.80000000000004, 142.39999999999998, 84.79999999999994, 20.000000000000014, 200.0, 200.0, 93.80000000000007, 175.10000000000002, 151.7, 82.99999999999997, 164.89999999999998, 20.000000000000014, 31.700000000000113, 170.0, 167.0, 20.000000000000014, 139.1, 20.000000000000014, 20.000000000000014, 52.39999999999996, 148.39999999999998, 20.000000000000014, 149.9, -3.0999999999999863, -13.599999999999783, 20.000000000000014, 200.0, 20.000000000000014, 74.89999999999996, 62.90000000000013, 11.599999999999964, -17.79999999999975, 15.800000000000104, 163.1, 200.0, 20.000000000000014, 176.0, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 20.000000000000014, -76.60000000000075, 149.3, 81.19999999999996, 20.000000000000014, 20.000000000000014, 194.0, 31.699999999999996, 17.899999999999988, 20.000000000000014, 20.000000000000014, 200.0, -38.799999999999784, -82.90000000000065, 124.39999999999998, 194.0, 181.1, 20.000000000000014, 41.60000000000025, 20.000000000000014, 20.000000000000014, 130.09999999999977, 200.0, 151.10000000000002, 20.000000000000014, 149.0, 200.0, 65.90000000000008, 20.000000000000014, 200.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -36.6999999999998, 47.30000000000014, -34.59999999999975, -22.600000000000236, 139.40000000000003, 20.000000000000014, 22.700000000000053, 107.00000000000004, 200.0, 170.0, 53.30000000000018, 20.000000000000014, 11.599999999999964, 84.79999999999941, 200.0, 20.000000000000014, 49.69999999999997, 20.000000000000014, 20.000000000000014, 101.89999999999999, 200.0, 156.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -53.500000000000135, 20.000000000000014, 126.80000000000005, 20.000000000000014, 200.0, 113.6, 20.000000000000014, 20.000000000000014, 12.20000000000016, 20.000000000000014, -3.099999999999958, 20.000000000000014, 11.599999999999978, 147.79999999999967, -53.200000000000685, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 23.900000000000162, 20.000000000000014, 20.000000000000014, 35.30000000000013, 200.0, 178.4, 33.50000000000024, 173.0, -9.399999999999904, 144.8, -80.80000000000086, 20.000000000000014, 20.000000000000014, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 55.09999999999996, 96.50000000000003, 20.000000000000014, 20.000000000000014, -9.399999999999855, 49.69999999999997, 20.000000000000014, 200.0, 20.000000000000014, 150.5, 200.0, 200.0, 200.0, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 120.79999999999957, 166.7, 20.000000000000014, -133.3000000000006, 20.000000000000014, 200.0, 20.000000000000014, 102.20000000000005, 20.000000000000014, 20.000000000000014, 140.89999999999998, 200.0, 20.000000000000014, 31.699999999999996, 20.000000000000014, 20.000000000000014, 106.40000000000005, 20.000000000000014, 20.000000000000014, 5.299999999999965, 65.89999999999998, 200.0, 129.79999999999956, 188.0, 200.0, 20.000000000000014], "policy_predator_policy_reward": [6.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 0.0, 1.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 12.0, 0.0, 11.0, 0.0, 0.0, 0.0, 10.0, 11.0, 0.0, 8.0, 0.0, 0.0, 0.0, 3.0, 10.0, 0.0, 17.0, 9.0, 7.0, 0.0, 0.0, 0.0, 13.0, 20.0, 2.0, 20.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 35.0, 34.0, 10.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 63.0, 45.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 10.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 41.0, 6.0, 69.0, 37.0, 10.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 35.0, 19.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 19.0, 4.0, 0.0, 11.0, 0.0, 4.0, 37.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 7.0, 24.0, 0.0, 0.0, 9.0, 3.0, 2.0, 14.0, 48.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 16.0, 18.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 7.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4822464954664767, "mean_inference_ms": 4.1759153259115, "mean_action_processing_ms": 0.7347286313136163, "mean_env_wait_ms": 0.9012290154711404, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0073136091232299805, "StateBufferConnector_ms": 0.005110740661621094, "ViewRequirementAgentConnector_ms": 0.2628525495529175}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -40.29999999999963, "episode_return_mean": 155.3579999999998, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 244.8229556776634, "num_env_steps_trained_throughput_per_sec": 244.8229556776634, "timesteps_total": 280000, "num_env_steps_sampled_lifetime": 280000, "num_agent_steps_sampled_lifetime": 1120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1120000, "timers": {"training_iteration_time_ms": 20870.398, "restore_workers_time_ms": 0.02, "training_step_time_ms": 20870.33, "sample_time_ms": 6120.59, "learn_time_ms": 14722.497, "learn_throughput": 271.693, "synch_weights_time_ms": 22.873}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 1120000, "num_agent_steps_trained": 1120000}, "done": false, "training_iteration": 70, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-13-09", "timestamp": 1723522389, "time_this_iter_s": 16.398547887802124, "time_total_s": 1258.212280511856, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4f03280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1258.212280511856, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 87.05217391304349, "ram_util_percent": 83.5391304347826}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.981297595603835, "cur_kl_coeff": 0.00024719238281249993, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2199803755160362, "policy_loss": -0.001370250880373297, "vf_loss": 0.22134560941625817, "vf_explained_var": -0.017324860039211454, "kl": 0.020295067896763212, "entropy": 0.9625402592792713, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 14.612060338337585, "cur_kl_coeff": 1.7462298274040218e-11, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.550729656471777, "policy_loss": -0.0013049617344414984, "vf_loss": 5.552034615713453, "vf_explained_var": 0.7762949056095547, "kl": 0.003460129633349471, "entropy": 0.7100236205512254, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 133245.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -40.29999999999963, "episode_reward_mean": 152.03299999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -133.3000000000006, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 73.0}, "policy_reward_mean": {"prey_policy": 69.48649999999998, "predator_policy": 6.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [163.79999999999956, 22.400000000000013, 219.99999999999926, 150.79999999999998, 15.799999999999969, 198.8999999999998, 219.99999999999926, 358.0, 219.99999999999926, 219.99999999999926, 219.99999999999926, 26.80000000000009, 12.400000000000048, 240.49999999999983, 40.0000000000003, 227.69999999999933, 38.90000000000028, 219.99999999999926, -13.69999999999964, 320.3999999999999, 201.09999999999934, 61.60000000000051, 161.09999999999914, 361.1, 185.99999999999943, 265.8999999999994, 219.99999999999926, 206.99999999999932, 40.0000000000003, 57.60000000000031, 48.80000000000025, 169.3999999999995, 139.69999999999965, 380.0, 73.29999999999974, 100.39999999999856, 219.99999999999926, 69.70000000000022, 130.8999999999997, 356.80000000000007, 40.0000000000003, 20.499999999999993, 156.79999999999956, 219.99999999999926, 142.59999999999962, 55.200000000000024, 27.90000000000011, 35.60000000000022, 153.59999999999908, 400.0, 40.0000000000003, 66.90000000000006, 86.2999999999999, 378.4, 218.49999999999926, 151.3999999999996, -12.799999999999587, 40.0000000000003, 215.99999999999926, 30.100000000000147, 185.59999999999985, 40.0000000000003, 57.30000000000006, 219.99999999999926, 170.4999999999995, 400.0, 215.59999999999928, 40.0000000000003, 40.0000000000003, 287.50000000000034, -40.29999999999963, 219.99999999999926, 139.19999999999965, 40.0000000000003, 345.90000000000003, 51.70000000000028, 40.0000000000003, 147.39999999999964, 32.30000000000018, 271.89999999999964, 321.8000000000012, 219.99999999999926, -10.69999999999975, 210.8999999999993, 40.0000000000003, 174.09999999999945, 96.79999999999993, 153.29999999999959, 219.99999999999926, 217.79999999999927, 245.50000000000009, 369.2, 103.59999999999988, 203.29999999999933, 163.7999999999994, 217.99999999999926, 31.200000000000166, 199.99999999999935, 40.0000000000003, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [149.9, -3.0999999999999863, -13.599999999999783, 20.000000000000014, 200.0, 20.000000000000014, 74.89999999999996, 62.90000000000013, 11.599999999999964, -17.79999999999975, 15.800000000000104, 163.1, 200.0, 20.000000000000014, 176.0, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 200.0, 20.000000000000014, -5.1999999999999265, 20.000000000000014, 20.000000000000014, -76.60000000000075, 149.3, 81.19999999999996, 20.000000000000014, 20.000000000000014, 194.0, 31.699999999999996, 17.899999999999988, 20.000000000000014, 20.000000000000014, 200.0, -38.799999999999784, -82.90000000000065, 124.39999999999998, 194.0, 181.1, 20.000000000000014, 41.60000000000025, 20.000000000000014, 20.000000000000014, 130.09999999999977, 200.0, 151.10000000000002, 20.000000000000014, 149.0, 200.0, 65.90000000000008, 20.000000000000014, 200.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -36.6999999999998, 47.30000000000014, -34.59999999999975, -22.600000000000236, 139.40000000000003, 20.000000000000014, 22.700000000000053, 107.00000000000004, 200.0, 170.0, 53.30000000000018, 20.000000000000014, 11.599999999999964, 84.79999999999941, 200.0, 20.000000000000014, 49.69999999999997, 20.000000000000014, 20.000000000000014, 101.89999999999999, 200.0, 156.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -53.500000000000135, 20.000000000000014, 126.80000000000005, 20.000000000000014, 200.0, 113.6, 20.000000000000014, 20.000000000000014, 12.20000000000016, 20.000000000000014, -3.099999999999958, 20.000000000000014, 11.599999999999978, 147.79999999999967, -53.200000000000685, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 23.900000000000162, 20.000000000000014, 20.000000000000014, 35.30000000000013, 200.0, 178.4, 33.50000000000024, 173.0, -9.399999999999904, 144.8, -80.80000000000086, 20.000000000000014, 20.000000000000014, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 55.09999999999996, 96.50000000000003, 20.000000000000014, 20.000000000000014, -9.399999999999855, 49.69999999999997, 20.000000000000014, 200.0, 20.000000000000014, 150.5, 200.0, 200.0, 200.0, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 120.79999999999957, 166.7, 20.000000000000014, -133.3000000000006, 20.000000000000014, 200.0, 20.000000000000014, 102.20000000000005, 20.000000000000014, 20.000000000000014, 140.89999999999998, 200.0, 20.000000000000014, 31.699999999999996, 20.000000000000014, 20.000000000000014, 106.40000000000005, 20.000000000000014, 20.000000000000014, 5.299999999999965, 65.89999999999998, 200.0, 129.79999999999956, 188.0, 200.0, 20.000000000000014, -85.00000000000017, 5.299999999999965, 17.899999999999988, 188.0, 20.000000000000014, 20.000000000000014, 154.1, 20.000000000000014, 68.90000000000005, -3.099999999999958, 20.000000000000014, 128.29999999999998, 20.000000000000014, 200.0, 15.799999999999962, 200.0, 55.09999999999984, 151.4, 170.0, 189.2, 59.6000000000001, 20.000000000000014, 20.000000000000014, 176.3, 112.69999999999945, 13.099999999999724, 197.0, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 17.0, 9.0, 7.0, 0.0, 0.0, 0.0, 13.0, 20.0, 2.0, 20.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 35.0, 34.0, 10.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 63.0, 45.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 10.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 41.0, 6.0, 69.0, 37.0, 10.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 35.0, 19.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 19.0, 4.0, 0.0, 11.0, 0.0, 4.0, 37.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 7.0, 24.0, 0.0, 0.0, 9.0, 3.0, 2.0, 14.0, 48.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 16.0, 18.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 7.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 0.0, 50.0, 19.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 39.0, 10.0, 0.0, 0.0, 24.0, 7.0, 0.0, 38.0, 0.0, 1.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4815652571184343, "mean_inference_ms": 4.175760081194469, "mean_action_processing_ms": 0.7326614527735787, "mean_env_wait_ms": 0.9008631395943713, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007860779762268066, "StateBufferConnector_ms": 0.005082488059997559, "ViewRequirementAgentConnector_ms": 0.22123503684997559}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -40.29999999999963, "episode_return_mean": 152.03299999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 253.92013004805244, "num_env_steps_trained_throughput_per_sec": 253.92013004805244, "timesteps_total": 284000, "num_env_steps_sampled_lifetime": 284000, "num_agent_steps_sampled_lifetime": 1136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1136000, "timers": {"training_iteration_time_ms": 20272.903, "restore_workers_time_ms": 0.02, "training_step_time_ms": 20272.835, "sample_time_ms": 5687.803, "learn_time_ms": 14560.151, "learn_throughput": 274.722, "synch_weights_time_ms": 20.48}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 1136000, "num_agent_steps_trained": 1136000}, "done": false, "training_iteration": 71, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-13-25", "timestamp": 1723522405, "time_this_iter_s": 15.83539891242981, "time_total_s": 1274.047679424286, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d1a160>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1274.047679424286, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 87.50869565217391, "ram_util_percent": 82.92173913043477}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9154261547362521, "cur_kl_coeff": 0.0003707885742187501, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.467033155364965, "policy_loss": -0.0017918695429606096, "vf_loss": 0.4688220338196809, "vf_explained_var": 0.01327515301250276, "kl": 0.008065556372754048, "entropy": 0.9929773015635354, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 16.010760739256465, "cur_kl_coeff": 8.731149137020109e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.831397522315777, "policy_loss": -0.0011538575408319947, "vf_loss": 5.8325513819538095, "vf_explained_var": 0.8011648679851855, "kl": 0.0018336170762383503, "entropy": 0.657988700869853, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 135135.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -40.29999999999963, "episode_reward_mean": 161.48099999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -133.3000000000006, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 73.0}, "policy_reward_mean": {"prey_policy": 74.55049999999997, "predator_policy": 6.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [161.09999999999914, 361.1, 185.99999999999943, 265.8999999999994, 219.99999999999926, 206.99999999999932, 40.0000000000003, 57.60000000000031, 48.80000000000025, 169.3999999999995, 139.69999999999965, 380.0, 73.29999999999974, 100.39999999999856, 219.99999999999926, 69.70000000000022, 130.8999999999997, 356.80000000000007, 40.0000000000003, 20.499999999999993, 156.79999999999956, 219.99999999999926, 142.59999999999962, 55.200000000000024, 27.90000000000011, 35.60000000000022, 153.59999999999908, 400.0, 40.0000000000003, 66.90000000000006, 86.2999999999999, 378.4, 218.49999999999926, 151.3999999999996, -12.799999999999587, 40.0000000000003, 215.99999999999926, 30.100000000000147, 185.59999999999985, 40.0000000000003, 57.30000000000006, 219.99999999999926, 170.4999999999995, 400.0, 215.59999999999928, 40.0000000000003, 40.0000000000003, 287.50000000000034, -40.29999999999963, 219.99999999999926, 139.19999999999965, 40.0000000000003, 345.90000000000003, 51.70000000000028, 40.0000000000003, 147.39999999999964, 32.30000000000018, 271.89999999999964, 321.8000000000012, 219.99999999999926, -10.69999999999975, 210.8999999999993, 40.0000000000003, 174.09999999999945, 96.79999999999993, 153.29999999999959, 219.99999999999926, 217.79999999999927, 245.50000000000009, 369.2, 103.59999999999988, 203.29999999999933, 163.7999999999994, 217.99999999999926, 31.200000000000166, 199.99999999999935, 40.0000000000003, 40.0000000000003, 169.5999999999995, 176.89999999999947, 298.80000000000047, 79.30000000000004, 26.800000000000118, 149.89999999999992, 291.9999999999997, 195.59999999999937, 249.69999999999956, 180.69999999999945, 219.99999999999926, 95.40000000000003, 208.99999999999932, 260.3999999999994, 196.10000000000002, 123.49999999999972, 219.99999999999926, 19.700000000000014, 186.49999999999872, 369.40000000000003, 233.59999999999917, 377.3], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 130.09999999999977, 200.0, 151.10000000000002, 20.000000000000014, 149.0, 200.0, 65.90000000000008, 20.000000000000014, 200.0, 167.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -36.6999999999998, 47.30000000000014, -34.59999999999975, -22.600000000000236, 139.40000000000003, 20.000000000000014, 22.700000000000053, 107.00000000000004, 200.0, 170.0, 53.30000000000018, 20.000000000000014, 11.599999999999964, 84.79999999999941, 200.0, 20.000000000000014, 49.69999999999997, 20.000000000000014, 20.000000000000014, 101.89999999999999, 200.0, 156.8, 20.000000000000014, 20.000000000000014, 20.000000000000014, -53.500000000000135, 20.000000000000014, 126.80000000000005, 20.000000000000014, 200.0, 113.6, 20.000000000000014, 20.000000000000014, 12.20000000000016, 20.000000000000014, -3.099999999999958, 20.000000000000014, 11.599999999999978, 147.79999999999967, -53.200000000000685, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 23.900000000000162, 20.000000000000014, 20.000000000000014, 35.30000000000013, 200.0, 178.4, 33.50000000000024, 173.0, -9.399999999999904, 144.8, -80.80000000000086, 20.000000000000014, 20.000000000000014, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 55.09999999999996, 96.50000000000003, 20.000000000000014, 20.000000000000014, -9.399999999999855, 49.69999999999997, 20.000000000000014, 200.0, 20.000000000000014, 150.5, 200.0, 200.0, 200.0, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 120.79999999999957, 166.7, 20.000000000000014, -133.3000000000006, 20.000000000000014, 200.0, 20.000000000000014, 102.20000000000005, 20.000000000000014, 20.000000000000014, 140.89999999999998, 200.0, 20.000000000000014, 31.699999999999996, 20.000000000000014, 20.000000000000014, 106.40000000000005, 20.000000000000014, 20.000000000000014, 5.299999999999965, 65.89999999999998, 200.0, 129.79999999999956, 188.0, 200.0, 20.000000000000014, -85.00000000000017, 5.299999999999965, 17.899999999999988, 188.0, 20.000000000000014, 20.000000000000014, 154.1, 20.000000000000014, 68.90000000000005, -3.099999999999958, 20.000000000000014, 128.29999999999998, 20.000000000000014, 200.0, 15.799999999999962, 200.0, 55.09999999999984, 151.4, 170.0, 189.2, 59.6000000000001, 20.000000000000014, 20.000000000000014, 176.3, 112.69999999999945, 13.099999999999724, 197.0, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.6, 20.000000000000014, 11.599999999999964, 161.3, 102.79999999999939, 194.0, 53.299999999999976, 20.000000000000014, 20.000000000000014, -5.199999999999955, 146.89999999999998, -37.000000000000554, 200.0, 91.99999999999997, 11.599999999999964, 170.0, 40.699999999999974, 200.0, 157.7, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 46.400000000000105, 200.0, -1.0000000000000027, 158.0, 88.39999999999931, 137.9, 24.200000000000003, 84.50000000000009, 20.000000000000014, 200.0, 20.000000000000014, 7.399999999999965, 5.299999999999965, 128.89999999999955, 56.60000000000021, 169.4, 200.0, 182.0, 38.6000000000002, 167.3, 200.0], "policy_predator_policy_reward": [11.0, 0.0, 0.0, 10.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 41.0, 6.0, 69.0, 37.0, 10.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 35.0, 19.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 19.0, 4.0, 0.0, 11.0, 0.0, 4.0, 37.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 7.0, 24.0, 0.0, 0.0, 9.0, 3.0, 2.0, 14.0, 48.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 16.0, 18.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 7.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 0.0, 50.0, 19.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 39.0, 10.0, 0.0, 0.0, 24.0, 7.0, 0.0, 38.0, 0.0, 1.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 6.0, 0.0, 12.0, 40.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 0.0, 29.0, 0.0, 10.0, 0.0, 10.0, 4.0, 12.0, 22.0, 0.0, 19.0, 0.0, 0.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 6.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4806938790451596, "mean_inference_ms": 4.174289639550057, "mean_action_processing_ms": 0.7303058955417663, "mean_env_wait_ms": 0.8997940256524163, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00767064094543457, "StateBufferConnector_ms": 0.0051538944244384766, "ViewRequirementAgentConnector_ms": 0.24009239673614502}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -40.29999999999963, "episode_return_mean": 161.48099999999977, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000, "num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 221.30397344407615, "num_env_steps_trained_throughput_per_sec": 221.30397344407615, "timesteps_total": 288000, "num_env_steps_sampled_lifetime": 288000, "num_agent_steps_sampled_lifetime": 1152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1152000, "timers": {"training_iteration_time_ms": 19433.689, "restore_workers_time_ms": 0.019, "training_step_time_ms": 19433.624, "sample_time_ms": 5377.823, "learn_time_ms": 14032.983, "learn_throughput": 285.043, "synch_weights_time_ms": 18.442}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 288000, "num_agent_steps_sampled": 1152000, "num_agent_steps_trained": 1152000}, "done": false, "training_iteration": 72, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-13-43", "timestamp": 1723522423, "time_this_iter_s": 18.15005612373352, "time_total_s": 1292.1977355480194, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4dcc820>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1292.1977355480194, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 90.73199999999999, "ram_util_percent": 83.436}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1553615829261838, "cur_kl_coeff": 0.0003707885742187501, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0524650156497954, "policy_loss": -0.0009693472715163673, "vf_loss": 1.0534299948464625, "vf_explained_var": 0.0008812964908660405, "kl": 0.011785179829167018, "entropy": 0.8999577591028163, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 20.072414637148064, "cur_kl_coeff": 4.3655745685100546e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.3306727068764825, "policy_loss": -0.0014281586573887913, "vf_loss": 5.332100870748046, "vf_explained_var": 0.6208521978880363, "kl": 0.0033530461227286572, "entropy": 0.8396701258641702, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 137025.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -89.80000000000112, "episode_reward_mean": 155.5609999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -317.0999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 211.0}, "policy_reward_mean": {"prey_policy": 69.81549999999997, "predator_policy": 7.965}, "custom_metrics": {}, "hist_stats": {"episode_reward": [55.200000000000024, 27.90000000000011, 35.60000000000022, 153.59999999999908, 400.0, 40.0000000000003, 66.90000000000006, 86.2999999999999, 378.4, 218.49999999999926, 151.3999999999996, -12.799999999999587, 40.0000000000003, 215.99999999999926, 30.100000000000147, 185.59999999999985, 40.0000000000003, 57.30000000000006, 219.99999999999926, 170.4999999999995, 400.0, 215.59999999999928, 40.0000000000003, 40.0000000000003, 287.50000000000034, -40.29999999999963, 219.99999999999926, 139.19999999999965, 40.0000000000003, 345.90000000000003, 51.70000000000028, 40.0000000000003, 147.39999999999964, 32.30000000000018, 271.89999999999964, 321.8000000000012, 219.99999999999926, -10.69999999999975, 210.8999999999993, 40.0000000000003, 174.09999999999945, 96.79999999999993, 153.29999999999959, 219.99999999999926, 217.79999999999927, 245.50000000000009, 369.2, 103.59999999999988, 203.29999999999933, 163.7999999999994, 217.99999999999926, 31.200000000000166, 199.99999999999935, 40.0000000000003, 40.0000000000003, 169.5999999999995, 176.89999999999947, 298.80000000000047, 79.30000000000004, 26.800000000000118, 149.89999999999992, 291.9999999999997, 195.59999999999937, 249.69999999999956, 180.69999999999945, 219.99999999999926, 95.40000000000003, 208.99999999999932, 260.3999999999994, 196.10000000000002, 123.49999999999972, 219.99999999999926, 19.700000000000014, 186.49999999999872, 369.40000000000003, 233.59999999999917, 377.3, 72.50000000000017, 206.99999999999932, 184.09999999999997, 294.60000000000053, 193.6999999999994, 24.300000000000047, 172.89999999999978, 40.0000000000003, 297.49999999999994, 172.09999999999948, 124.29999999999981, 40.0000000000003, 24.600000000000048, 219.99999999999926, 40.0000000000003, 31.000000000000156, -89.80000000000112, 149.79999999999959, 40.0000000000003, 219.99999999999926, 271.8, 187.5999999999994, 257.6], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 12.20000000000016, 20.000000000000014, -3.099999999999958, 20.000000000000014, 11.599999999999978, 147.79999999999967, -53.200000000000685, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 23.900000000000162, 20.000000000000014, 20.000000000000014, 35.30000000000013, 200.0, 178.4, 33.50000000000024, 173.0, -9.399999999999904, 144.8, -80.80000000000086, 20.000000000000014, 20.000000000000014, 20.000000000000014, 194.0, 20.000000000000014, 20.000000000000014, 1.0999999999999865, 55.09999999999996, 96.50000000000003, 20.000000000000014, 20.000000000000014, -9.399999999999855, 49.69999999999997, 20.000000000000014, 200.0, 20.000000000000014, 150.5, 200.0, 200.0, 200.0, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 120.79999999999957, 166.7, 20.000000000000014, -133.3000000000006, 20.000000000000014, 200.0, 20.000000000000014, 102.20000000000005, 20.000000000000014, 20.000000000000014, 140.89999999999998, 200.0, 20.000000000000014, 31.699999999999996, 20.000000000000014, 20.000000000000014, 106.40000000000005, 20.000000000000014, 20.000000000000014, 5.299999999999965, 65.89999999999998, 200.0, 129.79999999999956, 188.0, 200.0, 20.000000000000014, -85.00000000000017, 5.299999999999965, 17.899999999999988, 188.0, 20.000000000000014, 20.000000000000014, 154.1, 20.000000000000014, 68.90000000000005, -3.099999999999958, 20.000000000000014, 128.29999999999998, 20.000000000000014, 200.0, 15.799999999999962, 200.0, 55.09999999999984, 151.4, 170.0, 189.2, 59.6000000000001, 20.000000000000014, 20.000000000000014, 176.3, 112.69999999999945, 13.099999999999724, 197.0, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.6, 20.000000000000014, 11.599999999999964, 161.3, 102.79999999999939, 194.0, 53.299999999999976, 20.000000000000014, 20.000000000000014, -5.199999999999955, 146.89999999999998, -37.000000000000554, 200.0, 91.99999999999997, 11.599999999999964, 170.0, 40.699999999999974, 200.0, 157.7, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 46.400000000000105, 200.0, -1.0000000000000027, 158.0, 88.39999999999931, 137.9, 24.200000000000003, 84.50000000000009, 20.000000000000014, 200.0, 20.000000000000014, 7.399999999999965, 5.299999999999965, 128.89999999999955, 56.60000000000021, 169.4, 200.0, 182.0, 38.6000000000002, 167.3, 200.0, 20.000000000000014, 42.49999999999997, 20.000000000000014, 179.0, 9.199999999999676, 101.89999999999998, 176.0, 110.59999999999954, 13.699999999999964, 167.0, 20.000000000000014, -15.699999999999747, -317.0999999999991, 170.0, 20.000000000000014, 20.000000000000014, 93.50000000000004, 194.0, 20.000000000000014, 142.10000000000002, 107.60000000000008, -7.299999999999908, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.9999999999998, -227.80000000000047, 20.000000000000014, 20.000000000000014, 129.79999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 128.89999999999998, 131.90000000000003, 167.6, 20.000000000000014, 107.29999999999998, 140.3], "policy_predator_policy_reward": [19.0, 4.0, 0.0, 11.0, 0.0, 4.0, 37.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 23.0, 7.0, 24.0, 0.0, 0.0, 9.0, 3.0, 2.0, 14.0, 48.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 9.0, 16.0, 18.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 7.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 0.0, 50.0, 19.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 39.0, 10.0, 0.0, 0.0, 24.0, 7.0, 0.0, 38.0, 0.0, 1.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 6.0, 0.0, 12.0, 40.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 0.0, 29.0, 0.0, 10.0, 0.0, 10.0, 4.0, 12.0, 22.0, 0.0, 19.0, 0.0, 0.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 6.0, 0.0, 10.0, 4.0, 6.0, 7.0, 1.0, 29.0, 44.0, 0.0, 8.0, 2.0, 11.0, 11.0, 9.0, 211.0, 109.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 13.0, 11.0, 0.0, 0.0, 6.0, 8.0, 0.0, 0.0, 0.0, 0.0, 13.0, 20.0, 118.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4641780163600742, "mean_inference_ms": 4.139782266236651, "mean_action_processing_ms": 0.7286351078475325, "mean_env_wait_ms": 0.8892462133048252, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007231593132019043, "StateBufferConnector_ms": 0.004004478454589844, "ViewRequirementAgentConnector_ms": 0.15337872505187988}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -89.80000000000112, "episode_return_mean": 155.5609999999998, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000, "num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 247.31250303019144, "num_env_steps_trained_throughput_per_sec": 247.31250303019144, "timesteps_total": 292000, "num_env_steps_sampled_lifetime": 292000, "num_agent_steps_sampled_lifetime": 1168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1168000, "timers": {"training_iteration_time_ms": 18854.93, "restore_workers_time_ms": 0.019, "training_step_time_ms": 18854.867, "sample_time_ms": 5008.437, "learn_time_ms": 13823.816, "learn_throughput": 289.356, "synch_weights_time_ms": 17.977}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 292000, "num_agent_steps_sampled": 1168000, "num_agent_steps_trained": 1168000}, "done": false, "training_iteration": 73, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-13-59", "timestamp": 1723522439, "time_this_iter_s": 16.24148988723755, "time_total_s": 1308.439225435257, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x330dc5ee0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1308.439225435257, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 87.16521739130435, "ram_util_percent": 83.57391304347826}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6651733321073667, "cur_kl_coeff": 0.0003707885742187501, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.23458885711484723, "policy_loss": -0.003465205702743439, "vf_loss": 0.23804334038718408, "vf_explained_var": -0.012517450915442572, "kl": 0.02891919266543067, "entropy": 0.8043540080703756, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 19.93754155862899, "cur_kl_coeff": 2.1827872842550273e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.789352597635259, "policy_loss": -0.0014451833358083768, "vf_loss": 5.790797792414509, "vf_explained_var": 0.8443377725661747, "kl": 0.0030907870651986817, "entropy": 0.7566316781220612, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 138915.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -89.80000000000112, "episode_reward_mean": 166.37299999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -317.0999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 211.0}, "policy_reward_mean": {"prey_policy": 74.96649999999998, "predator_policy": 8.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 170.4999999999995, 400.0, 215.59999999999928, 40.0000000000003, 40.0000000000003, 287.50000000000034, -40.29999999999963, 219.99999999999926, 139.19999999999965, 40.0000000000003, 345.90000000000003, 51.70000000000028, 40.0000000000003, 147.39999999999964, 32.30000000000018, 271.89999999999964, 321.8000000000012, 219.99999999999926, -10.69999999999975, 210.8999999999993, 40.0000000000003, 174.09999999999945, 96.79999999999993, 153.29999999999959, 219.99999999999926, 217.79999999999927, 245.50000000000009, 369.2, 103.59999999999988, 203.29999999999933, 163.7999999999994, 217.99999999999926, 31.200000000000166, 199.99999999999935, 40.0000000000003, 40.0000000000003, 169.5999999999995, 176.89999999999947, 298.80000000000047, 79.30000000000004, 26.800000000000118, 149.89999999999992, 291.9999999999997, 195.59999999999937, 249.69999999999956, 180.69999999999945, 219.99999999999926, 95.40000000000003, 208.99999999999932, 260.3999999999994, 196.10000000000002, 123.49999999999972, 219.99999999999926, 19.700000000000014, 186.49999999999872, 369.40000000000003, 233.59999999999917, 377.3, 72.50000000000017, 206.99999999999932, 184.09999999999997, 294.60000000000053, 193.6999999999994, 24.300000000000047, 172.89999999999978, 40.0000000000003, 297.49999999999994, 172.09999999999948, 124.29999999999981, 40.0000000000003, 24.600000000000048, 219.99999999999926, 40.0000000000003, 31.000000000000156, -89.80000000000112, 149.79999999999959, 40.0000000000003, 219.99999999999926, 271.8, 187.5999999999994, 257.6, 210.39999999999955, 248.1, 214.19999999999933, 40.0000000000003, 308.90000000000094, 115.79999999999976, 123.69999999999978, 400.0, 190.2999999999994, 68.80000000000015, 121.89999999999979, 219.99999999999926, 32.30000000000018, 376.0, 113.39999999999989, 34.600000000000264, 246.99999999999932, 185.79999999999953], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 200.0, 20.000000000000014, 150.5, 200.0, 200.0, 200.0, 11.599999999999964, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 120.79999999999957, 166.7, 20.000000000000014, -133.3000000000006, 20.000000000000014, 200.0, 20.000000000000014, 102.20000000000005, 20.000000000000014, 20.000000000000014, 140.89999999999998, 200.0, 20.000000000000014, 31.699999999999996, 20.000000000000014, 20.000000000000014, 106.40000000000005, 20.000000000000014, 20.000000000000014, 5.299999999999965, 65.89999999999998, 200.0, 129.79999999999956, 188.0, 200.0, 20.000000000000014, -85.00000000000017, 5.299999999999965, 17.899999999999988, 188.0, 20.000000000000014, 20.000000000000014, 154.1, 20.000000000000014, 68.90000000000005, -3.099999999999958, 20.000000000000014, 128.29999999999998, 20.000000000000014, 200.0, 15.799999999999962, 200.0, 55.09999999999984, 151.4, 170.0, 189.2, 59.6000000000001, 20.000000000000014, 20.000000000000014, 176.3, 112.69999999999945, 13.099999999999724, 197.0, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.6, 20.000000000000014, 11.599999999999964, 161.3, 102.79999999999939, 194.0, 53.299999999999976, 20.000000000000014, 20.000000000000014, -5.199999999999955, 146.89999999999998, -37.000000000000554, 200.0, 91.99999999999997, 11.599999999999964, 170.0, 40.699999999999974, 200.0, 157.7, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 46.400000000000105, 200.0, -1.0000000000000027, 158.0, 88.39999999999931, 137.9, 24.200000000000003, 84.50000000000009, 20.000000000000014, 200.0, 20.000000000000014, 7.399999999999965, 5.299999999999965, 128.89999999999955, 56.60000000000021, 169.4, 200.0, 182.0, 38.6000000000002, 167.3, 200.0, 20.000000000000014, 42.49999999999997, 20.000000000000014, 179.0, 9.199999999999676, 101.89999999999998, 176.0, 110.59999999999954, 13.699999999999964, 167.0, 20.000000000000014, -15.699999999999747, -317.0999999999991, 170.0, 20.000000000000014, 20.000000000000014, 93.50000000000004, 194.0, 20.000000000000014, 142.10000000000002, 107.60000000000008, -7.299999999999908, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.9999999999998, -227.80000000000047, 20.000000000000014, 20.000000000000014, 129.79999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 128.89999999999998, 131.90000000000003, 167.6, 20.000000000000014, 107.29999999999998, 140.3, 19.4, 170.0, 129.79999999999998, 110.29999999999998, -170.80000000000067, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 128.89999999999955, 20.000000000000014, 87.79999999999997, 103.69999999999997, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 170.3, 48.80000000000024, 20.000000000000014, 101.89999999999998, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 194.0, 173.0, 64.40000000000005, 20.000000000000014, 13.699999999999964, -42.10000000000031, 200.0, 47.00000000000018, 136.1, 49.70000000000024], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 73.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.0, 0.0, 7.0, 0.0, 6.0, 0.0, 4.0, 0.0, 0.0, 0.0, 50.0, 19.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 39.0, 10.0, 0.0, 0.0, 24.0, 7.0, 0.0, 38.0, 0.0, 1.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 6.0, 0.0, 12.0, 40.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 0.0, 29.0, 0.0, 10.0, 0.0, 10.0, 4.0, 12.0, 22.0, 0.0, 19.0, 0.0, 0.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 6.0, 0.0, 10.0, 4.0, 6.0, 7.0, 1.0, 29.0, 44.0, 0.0, 8.0, 2.0, 11.0, 11.0, 9.0, 211.0, 109.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 13.0, 11.0, 0.0, 0.0, 6.0, 8.0, 0.0, 0.0, 0.0, 0.0, 13.0, 20.0, 118.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 10.0, 21.0, 0.0, 8.0, 0.0, 122.0, 63.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 0.0, 29.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4700689359129495, "mean_inference_ms": 4.15091181841783, "mean_action_processing_ms": 0.7218768590606345, "mean_env_wait_ms": 0.8937757288540026, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006003618240356445, "StateBufferConnector_ms": 0.00479733943939209, "ViewRequirementAgentConnector_ms": 0.15232813358306885}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -89.80000000000112, "episode_return_mean": 166.37299999999982, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000, "num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 242.8876577611177, "num_env_steps_trained_throughput_per_sec": 242.8876577611177, "timesteps_total": 296000, "num_env_steps_sampled_lifetime": 296000, "num_agent_steps_sampled_lifetime": 1184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1184000, "timers": {"training_iteration_time_ms": 17865.781, "restore_workers_time_ms": 0.018, "training_step_time_ms": 17865.719, "sample_time_ms": 4193.745, "learn_time_ms": 13649.849, "learn_throughput": 293.044, "synch_weights_time_ms": 17.917}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 296000, "num_agent_steps_sampled": 1184000, "num_agent_steps_trained": 1184000}, "done": false, "training_iteration": 74, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-14-16", "timestamp": 1723522456, "time_this_iter_s": 16.551047801971436, "time_total_s": 1324.9902732372284, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4da2790>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1324.9902732372284, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 86.29583333333333, "ram_util_percent": 83.42083333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8493836811255842, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4997365415175125, "policy_loss": -0.0006074432355090582, "vf_loss": 0.5003380829021187, "vf_explained_var": 0.012919770252136958, "kl": 0.010611181294542672, "entropy": 0.9092152361831968, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.62354193150051, "cur_kl_coeff": 1.0913936421275136e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.709211967231105, "policy_loss": -0.001376678163639058, "vf_loss": 4.7105886453043215, "vf_explained_var": 0.9071405690498453, "kl": 0.006832302363710786, "entropy": 0.847729563240021, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 140805.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -89.80000000000112, "episode_reward_mean": 164.46999999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -317.0999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 211.0}, "policy_reward_mean": {"prey_policy": 73.62999999999997, "predator_policy": 8.605}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, -10.69999999999975, 210.8999999999993, 40.0000000000003, 174.09999999999945, 96.79999999999993, 153.29999999999959, 219.99999999999926, 217.79999999999927, 245.50000000000009, 369.2, 103.59999999999988, 203.29999999999933, 163.7999999999994, 217.99999999999926, 31.200000000000166, 199.99999999999935, 40.0000000000003, 40.0000000000003, 169.5999999999995, 176.89999999999947, 298.80000000000047, 79.30000000000004, 26.800000000000118, 149.89999999999992, 291.9999999999997, 195.59999999999937, 249.69999999999956, 180.69999999999945, 219.99999999999926, 95.40000000000003, 208.99999999999932, 260.3999999999994, 196.10000000000002, 123.49999999999972, 219.99999999999926, 19.700000000000014, 186.49999999999872, 369.40000000000003, 233.59999999999917, 377.3, 72.50000000000017, 206.99999999999932, 184.09999999999997, 294.60000000000053, 193.6999999999994, 24.300000000000047, 172.89999999999978, 40.0000000000003, 297.49999999999994, 172.09999999999948, 124.29999999999981, 40.0000000000003, 24.600000000000048, 219.99999999999926, 40.0000000000003, 31.000000000000156, -89.80000000000112, 149.79999999999959, 40.0000000000003, 219.99999999999926, 271.8, 187.5999999999994, 257.6, 210.39999999999955, 248.1, 214.19999999999933, 40.0000000000003, 308.90000000000094, 115.79999999999976, 123.69999999999978, 400.0, 190.2999999999994, 68.80000000000015, 121.89999999999979, 219.99999999999926, 32.30000000000018, 376.0, 113.39999999999989, 34.600000000000264, 246.99999999999932, 185.79999999999953, 211.59999999999994, 111.09999999999988, 198.39999999999935, 165.69999999999953, 199.99999999999935, 185.69999999999942, 24.600000000000062, 265.1999999999998, 40.0000000000003, 214.9999999999993, 207.39999999999932, 195.19999999999933, 64.10000000000025, 169.19999999999948, 219.99999999999926, 40.0000000000003, 40.0000000000003, 199.99999999999935], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 20.000000000000014, -85.00000000000017, 5.299999999999965, 17.899999999999988, 188.0, 20.000000000000014, 20.000000000000014, 154.1, 20.000000000000014, 68.90000000000005, -3.099999999999958, 20.000000000000014, 128.29999999999998, 20.000000000000014, 200.0, 15.799999999999962, 200.0, 55.09999999999984, 151.4, 170.0, 189.2, 59.6000000000001, 20.000000000000014, 20.000000000000014, 176.3, 112.69999999999945, 13.099999999999724, 197.0, 20.000000000000014, 3.1999999999999615, 20.000000000000014, 170.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 140.6, 20.000000000000014, 11.599999999999964, 161.3, 102.79999999999939, 194.0, 53.299999999999976, 20.000000000000014, 20.000000000000014, -5.199999999999955, 146.89999999999998, -37.000000000000554, 200.0, 91.99999999999997, 11.599999999999964, 170.0, 40.699999999999974, 200.0, 157.7, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 46.400000000000105, 200.0, -1.0000000000000027, 158.0, 88.39999999999931, 137.9, 24.200000000000003, 84.50000000000009, 20.000000000000014, 200.0, 20.000000000000014, 7.399999999999965, 5.299999999999965, 128.89999999999955, 56.60000000000021, 169.4, 200.0, 182.0, 38.6000000000002, 167.3, 200.0, 20.000000000000014, 42.49999999999997, 20.000000000000014, 179.0, 9.199999999999676, 101.89999999999998, 176.0, 110.59999999999954, 13.699999999999964, 167.0, 20.000000000000014, -15.699999999999747, -317.0999999999991, 170.0, 20.000000000000014, 20.000000000000014, 93.50000000000004, 194.0, 20.000000000000014, 142.10000000000002, 107.60000000000008, -7.299999999999908, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.9999999999998, -227.80000000000047, 20.000000000000014, 20.000000000000014, 129.79999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 128.89999999999998, 131.90000000000003, 167.6, 20.000000000000014, 107.29999999999998, 140.3, 19.4, 170.0, 129.79999999999998, 110.29999999999998, -170.80000000000067, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 128.89999999999955, 20.000000000000014, 87.79999999999997, 103.69999999999997, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 170.3, 48.80000000000024, 20.000000000000014, 101.89999999999998, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 194.0, 173.0, 64.40000000000005, 20.000000000000014, 13.699999999999964, -42.10000000000031, 200.0, 47.00000000000018, 136.1, 49.70000000000024, 150.20000000000005, 49.40000000000002, 20.000000000000014, 91.09999999999997, 20.000000000000014, 178.4, -5.1999999999999265, 146.89999999999998, 170.0, 20.000000000000014, 13.699999999999964, 158.0, 17.899999999999988, -7.299999999999912, 47.300000000000125, 191.9, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999846, 20.000000000000014, 187.4, 200.0, -80.8000000000008, 17.899999999999988, 45.199999999999974, 138.20000000000005, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0], "policy_predator_policy_reward": [0.0, 0.0, 50.0, 19.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 5.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 39.0, 10.0, 0.0, 0.0, 24.0, 7.0, 0.0, 38.0, 0.0, 1.0, 0.0, 8.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 4.0, 2.0, 0.0, 0.0, 6.0, 0.0, 12.0, 40.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 0.0, 29.0, 0.0, 10.0, 0.0, 10.0, 4.0, 12.0, 22.0, 0.0, 19.0, 0.0, 0.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 6.0, 0.0, 10.0, 4.0, 6.0, 7.0, 1.0, 29.0, 44.0, 0.0, 8.0, 2.0, 11.0, 11.0, 9.0, 211.0, 109.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 13.0, 11.0, 0.0, 0.0, 6.0, 8.0, 0.0, 0.0, 0.0, 0.0, 13.0, 20.0, 118.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 10.0, 21.0, 0.0, 8.0, 0.0, 122.0, 63.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 0.0, 29.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 12.0, 12.0, 0.0, 10.0, 10.0, 4.0, 0.0, 14.0, 12.0, 14.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 37.0, 39.0, 1.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.464883598483353, "mean_inference_ms": 4.13861308211391, "mean_action_processing_ms": 0.7181048853323435, "mean_env_wait_ms": 0.8907325735639773, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005510568618774414, "StateBufferConnector_ms": 0.005029559135437012, "ViewRequirementAgentConnector_ms": 0.14989662170410156}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -89.80000000000112, "episode_return_mean": 164.46999999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000, "num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 250.9520634031043, "num_env_steps_trained_throughput_per_sec": 250.9520634031043, "timesteps_total": 300000, "num_env_steps_sampled_lifetime": 300000, "num_agent_steps_sampled_lifetime": 1200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1200000, "timers": {"training_iteration_time_ms": 17583.734, "restore_workers_time_ms": 0.018, "training_step_time_ms": 17583.672, "sample_time_ms": 3833.224, "learn_time_ms": 13729.372, "learn_throughput": 291.346, "synch_weights_time_ms": 16.995}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 300000, "num_agent_steps_sampled": 1200000, "num_agent_steps_trained": 1200000}, "done": false, "training_iteration": 75, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-14-32", "timestamp": 1723522472, "time_this_iter_s": 16.00666618347168, "time_total_s": 1340.9969394207, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d68040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1340.9969394207, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 85.66956521739131, "ram_util_percent": 83.5608695652174}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5450356897351051, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.26685919423030796, "policy_loss": -0.0015142741849616408, "vf_loss": 0.26836409243652176, "vf_explained_var": 0.012125277235394432, "kl": 0.016857420742135636, "entropy": 0.9175456753168156, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.29649211871561, "cur_kl_coeff": 1.0913936421275136e-12, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.132053523719626, "policy_loss": -0.0006514673121273517, "vf_loss": 5.132704992773672, "vf_explained_var": 0.901140808869922, "kl": 0.0011595345550934613, "entropy": 0.7402452765949189, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 142695.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -89.80000000000112, "episode_reward_mean": 172.4459999999998, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -317.0999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 211.0}, "policy_reward_mean": {"prey_policy": 78.133, "predator_policy": 8.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [79.30000000000004, 26.800000000000118, 149.89999999999992, 291.9999999999997, 195.59999999999937, 249.69999999999956, 180.69999999999945, 219.99999999999926, 95.40000000000003, 208.99999999999932, 260.3999999999994, 196.10000000000002, 123.49999999999972, 219.99999999999926, 19.700000000000014, 186.49999999999872, 369.40000000000003, 233.59999999999917, 377.3, 72.50000000000017, 206.99999999999932, 184.09999999999997, 294.60000000000053, 193.6999999999994, 24.300000000000047, 172.89999999999978, 40.0000000000003, 297.49999999999994, 172.09999999999948, 124.29999999999981, 40.0000000000003, 24.600000000000048, 219.99999999999926, 40.0000000000003, 31.000000000000156, -89.80000000000112, 149.79999999999959, 40.0000000000003, 219.99999999999926, 271.8, 187.5999999999994, 257.6, 210.39999999999955, 248.1, 214.19999999999933, 40.0000000000003, 308.90000000000094, 115.79999999999976, 123.69999999999978, 400.0, 190.2999999999994, 68.80000000000015, 121.89999999999979, 219.99999999999926, 32.30000000000018, 376.0, 113.39999999999989, 34.600000000000264, 246.99999999999932, 185.79999999999953, 211.59999999999994, 111.09999999999988, 198.39999999999935, 165.69999999999953, 199.99999999999935, 185.69999999999942, 24.600000000000062, 265.1999999999998, 40.0000000000003, 214.9999999999993, 207.39999999999932, 195.19999999999933, 64.10000000000025, 169.19999999999948, 219.99999999999926, 40.0000000000003, 40.0000000000003, 199.99999999999935, 219.99999999999926, 40.0000000000003, 376.6, 335.20000000000164, 143.49999999999915, 372.0, 219.99999999999926, 290.80000000000007, 226.2999999999993, 35.30000000000023, 224.99999999999932, 214.59999999999928, 40.0000000000003, 191.1999999999994, 215.99999999999926, 182.69999999999962, 40.0000000000003, 219.99999999999926, 209.49999999999983, 219.99999999999926, 303.9000000000003, 57.100000000000385], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [53.299999999999976, 20.000000000000014, 20.000000000000014, -5.199999999999955, 146.89999999999998, -37.000000000000554, 200.0, 91.99999999999997, 11.599999999999964, 170.0, 40.699999999999974, 200.0, 157.7, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 46.400000000000105, 200.0, -1.0000000000000027, 158.0, 88.39999999999931, 137.9, 24.200000000000003, 84.50000000000009, 20.000000000000014, 200.0, 20.000000000000014, 7.399999999999965, 5.299999999999965, 128.89999999999955, 56.60000000000021, 169.4, 200.0, 182.0, 38.6000000000002, 167.3, 200.0, 20.000000000000014, 42.49999999999997, 20.000000000000014, 179.0, 9.199999999999676, 101.89999999999998, 176.0, 110.59999999999954, 13.699999999999964, 167.0, 20.000000000000014, -15.699999999999747, -317.0999999999991, 170.0, 20.000000000000014, 20.000000000000014, 93.50000000000004, 194.0, 20.000000000000014, 142.10000000000002, 107.60000000000008, -7.299999999999908, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.9999999999998, -227.80000000000047, 20.000000000000014, 20.000000000000014, 129.79999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 128.89999999999998, 131.90000000000003, 167.6, 20.000000000000014, 107.29999999999998, 140.3, 19.4, 170.0, 129.79999999999998, 110.29999999999998, -170.80000000000067, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 128.89999999999955, 20.000000000000014, 87.79999999999997, 103.69999999999997, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 170.3, 48.80000000000024, 20.000000000000014, 101.89999999999998, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 194.0, 173.0, 64.40000000000005, 20.000000000000014, 13.699999999999964, -42.10000000000031, 200.0, 47.00000000000018, 136.1, 49.70000000000024, 150.20000000000005, 49.40000000000002, 20.000000000000014, 91.09999999999997, 20.000000000000014, 178.4, -5.1999999999999265, 146.89999999999998, 170.0, 20.000000000000014, 13.699999999999964, 158.0, 17.899999999999988, -7.299999999999912, 47.300000000000125, 191.9, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999846, 20.000000000000014, 187.4, 200.0, -80.8000000000008, 17.899999999999988, 45.199999999999974, 138.20000000000005, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, 200.0, 135.1999999999996, 200.0, 123.49999999999974, 20.000000000000014, 200.0, 155.0, 20.000000000000014, 200.0, 170.0, 99.80000000000003, 200.0, 26.30000000000009, 20.000000000000014, -15.699999999999747, 56.900000000000176, 157.1, 194.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.199999999999967, 170.0, 194.0, 20.000000000000014, 122.89999999999995, 48.79999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 23.900000000000155, 155.6, 200.0, 20.000000000000014, 179.0, 113.8999999999999, 20.000000000000014, 37.100000000000186], "policy_predator_policy_reward": [0.0, 6.0, 0.0, 12.0, 40.0, 0.0, 0.0, 0.0, 14.0, 0.0, 0.0, 9.0, 0.0, 3.0, 0.0, 0.0, 29.0, 0.0, 10.0, 0.0, 10.0, 4.0, 12.0, 22.0, 0.0, 19.0, 0.0, 0.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 7.0, 6.0, 0.0, 10.0, 4.0, 6.0, 7.0, 1.0, 29.0, 44.0, 0.0, 8.0, 2.0, 11.0, 11.0, 9.0, 211.0, 109.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 13.0, 11.0, 0.0, 0.0, 6.0, 8.0, 0.0, 0.0, 0.0, 0.0, 13.0, 20.0, 118.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 10.0, 21.0, 0.0, 8.0, 0.0, 122.0, 63.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 0.0, 29.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 12.0, 12.0, 0.0, 10.0, 10.0, 4.0, 0.0, 14.0, 12.0, 14.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 37.0, 39.0, 1.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 11.0, 10.0, 0.0, 0.0, 17.0, 14.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 2.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 25.0, 5.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.451435661211626, "mean_inference_ms": 4.100614803342349, "mean_action_processing_ms": 0.709106246773326, "mean_env_wait_ms": 0.881402403168638, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0047283172607421875, "StateBufferConnector_ms": 0.005011320114135742, "ViewRequirementAgentConnector_ms": 0.1498962640762329}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -89.80000000000112, "episode_return_mean": 172.4459999999998, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000, "num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 222.30027726027558, "num_env_steps_trained_throughput_per_sec": 222.30027726027558, "timesteps_total": 304000, "num_env_steps_sampled_lifetime": 304000, "num_agent_steps_sampled_lifetime": 1216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1216000, "timers": {"training_iteration_time_ms": 17581.67, "restore_workers_time_ms": 0.018, "training_step_time_ms": 17581.61, "sample_time_ms": 3523.614, "learn_time_ms": 14036.472, "learn_throughput": 284.972, "synch_weights_time_ms": 17.081}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 304000, "num_agent_steps_sampled": 1216000, "num_agent_steps_trained": 1216000}, "done": false, "training_iteration": 76, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-14-50", "timestamp": 1723522490, "time_this_iter_s": 18.104500770568848, "time_total_s": 1359.101440191269, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d68dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1359.101440191269, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 94.068, "ram_util_percent": 83.684}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8940098421687566, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.276050981682129, "policy_loss": -0.0008071811675098995, "vf_loss": 0.2768502011923822, "vf_explained_var": -0.005429605169901772, "kl": 0.014314215089396195, "entropy": 0.9254187603476186, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 27.110669495725126, "cur_kl_coeff": 5.456968210637568e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.451406694089294, "policy_loss": -0.003178864449789876, "vf_loss": 5.4545855461605015, "vf_explained_var": 0.8333664911449271, "kl": 0.004131248366489881, "entropy": 0.8486500679815888, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 144585.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -89.80000000000112, "episode_reward_mean": 177.41299999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -317.0999999999991, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 211.0}, "policy_reward_mean": {"prey_policy": 81.17649999999999, "predator_policy": 7.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [377.3, 72.50000000000017, 206.99999999999932, 184.09999999999997, 294.60000000000053, 193.6999999999994, 24.300000000000047, 172.89999999999978, 40.0000000000003, 297.49999999999994, 172.09999999999948, 124.29999999999981, 40.0000000000003, 24.600000000000048, 219.99999999999926, 40.0000000000003, 31.000000000000156, -89.80000000000112, 149.79999999999959, 40.0000000000003, 219.99999999999926, 271.8, 187.5999999999994, 257.6, 210.39999999999955, 248.1, 214.19999999999933, 40.0000000000003, 308.90000000000094, 115.79999999999976, 123.69999999999978, 400.0, 190.2999999999994, 68.80000000000015, 121.89999999999979, 219.99999999999926, 32.30000000000018, 376.0, 113.39999999999989, 34.600000000000264, 246.99999999999932, 185.79999999999953, 211.59999999999994, 111.09999999999988, 198.39999999999935, 165.69999999999953, 199.99999999999935, 185.69999999999942, 24.600000000000062, 265.1999999999998, 40.0000000000003, 214.9999999999993, 207.39999999999932, 195.19999999999933, 64.10000000000025, 169.19999999999948, 219.99999999999926, 40.0000000000003, 40.0000000000003, 199.99999999999935, 219.99999999999926, 40.0000000000003, 376.6, 335.20000000000164, 143.49999999999915, 372.0, 219.99999999999926, 290.80000000000007, 226.2999999999993, 35.30000000000023, 224.99999999999932, 214.59999999999928, 40.0000000000003, 191.1999999999994, 215.99999999999926, 182.69999999999962, 40.0000000000003, 219.99999999999926, 209.49999999999983, 219.99999999999926, 303.9000000000003, 57.100000000000385, 40.0000000000003, 373.0, 103.79999999999914, 146.89999999999893, 219.99999999999926, 219.99999999999926, 234.39999999999915, 192.69999999999948, 235.19999999999956, 33.400000000000205, 397.3, 362.20000000000016, 348.6, 245.1999999999998, 35.600000000000236, 35.600000000000236, 219.99999999999926, 360.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [167.3, 200.0, 20.000000000000014, 42.49999999999997, 20.000000000000014, 179.0, 9.199999999999676, 101.89999999999998, 176.0, 110.59999999999954, 13.699999999999964, 167.0, 20.000000000000014, -15.699999999999747, -317.0999999999991, 170.0, 20.000000000000014, 20.000000000000014, 93.50000000000004, 194.0, 20.000000000000014, 142.10000000000002, 107.60000000000008, -7.299999999999908, 20.000000000000014, 20.000000000000014, 3.1999999999999615, 7.399999999999965, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, -21.9999999999998, -227.80000000000047, 20.000000000000014, 20.000000000000014, 129.79999999999998, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 128.89999999999998, 131.90000000000003, 167.6, 20.000000000000014, 107.29999999999998, 140.3, 19.4, 170.0, 129.79999999999998, 110.29999999999998, -170.80000000000067, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 128.89999999999955, 20.000000000000014, 87.79999999999997, 103.69999999999997, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 170.3, 48.80000000000024, 20.000000000000014, 101.89999999999998, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 194.0, 173.0, 64.40000000000005, 20.000000000000014, 13.699999999999964, -42.10000000000031, 200.0, 47.00000000000018, 136.1, 49.70000000000024, 150.20000000000005, 49.40000000000002, 20.000000000000014, 91.09999999999997, 20.000000000000014, 178.4, -5.1999999999999265, 146.89999999999998, 170.0, 20.000000000000014, 13.699999999999964, 158.0, 17.899999999999988, -7.299999999999912, 47.300000000000125, 191.9, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999846, 20.000000000000014, 187.4, 200.0, -80.8000000000008, 17.899999999999988, 45.199999999999974, 138.20000000000005, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, 200.0, 135.1999999999996, 200.0, 123.49999999999974, 20.000000000000014, 200.0, 155.0, 20.000000000000014, 200.0, 170.0, 99.80000000000003, 200.0, 26.30000000000009, 20.000000000000014, -15.699999999999747, 56.900000000000176, 157.1, 194.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.199999999999967, 170.0, 194.0, 20.000000000000014, 122.89999999999995, 48.79999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 23.900000000000155, 155.6, 200.0, 20.000000000000014, 179.0, 113.8999999999999, 20.000000000000014, 37.100000000000186, 20.000000000000014, 20.000000000000014, 191.0, 173.0, -7.5999999999998895, 97.39999999999961, 137.8999999999996, -0.9999999999999992, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 62.30000000000022, 172.1, 170.0, -1.2999999999998693, 170.29999999999984, 50.900000000000155, 7.399999999999965, 20.000000000000014, 200.0, 197.3, 167.59999999999997, 194.6, 143.59999999999997, 200.0, 165.8, 79.39999999999998, 11.599999999999964, 20.000000000000014, 20.000000000000014, 11.599999999999964, 200.0, 20.000000000000014, 181.1, 170.3], "policy_predator_policy_reward": [0.0, 10.0, 4.0, 6.0, 7.0, 1.0, 29.0, 44.0, 0.0, 8.0, 2.0, 11.0, 11.0, 9.0, 211.0, 109.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 13.0, 11.0, 0.0, 0.0, 6.0, 8.0, 0.0, 0.0, 0.0, 0.0, 13.0, 20.0, 118.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 10.0, 21.0, 0.0, 8.0, 0.0, 122.0, 63.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 0.0, 29.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 12.0, 12.0, 0.0, 10.0, 10.0, 4.0, 0.0, 14.0, 12.0, 14.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 37.0, 39.0, 1.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 11.0, 10.0, 0.0, 0.0, 17.0, 14.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 2.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 25.0, 5.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 18.0, 0.0, 14.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4527989211337158, "mean_inference_ms": 4.11135176875568, "mean_action_processing_ms": 0.709951779105336, "mean_env_wait_ms": 0.8838673143268909, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0041522979736328125, "StateBufferConnector_ms": 0.004873991012573242, "ViewRequirementAgentConnector_ms": 0.11407089233398438}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -89.80000000000112, "episode_return_mean": 177.41299999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000, "num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 217.19194023605147, "num_env_steps_trained_throughput_per_sec": 217.19194023605147, "timesteps_total": 308000, "num_env_steps_sampled_lifetime": 308000, "num_agent_steps_sampled_lifetime": 1232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1232000, "timers": {"training_iteration_time_ms": 17355.607, "restore_workers_time_ms": 0.018, "training_step_time_ms": 17355.534, "sample_time_ms": 3365.17, "learn_time_ms": 13968.724, "learn_throughput": 286.354, "synch_weights_time_ms": 17.566}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 308000, "num_agent_steps_sampled": 1232000, "num_agent_steps_trained": 1232000}, "done": false, "training_iteration": 77, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-15-09", "timestamp": 1723522509, "time_this_iter_s": 18.553839206695557, "time_total_s": 1377.6552793979645, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2901940>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1377.6552793979645, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 88.71923076923076, "ram_util_percent": 83.77692307692307}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2696374708126303, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.6838965497950396, "policy_loss": -0.0032892447814995805, "vf_loss": 2.6871787786483763, "vf_explained_var": 0.0007036137833166374, "kl": 0.012613828736702647, "entropy": 0.814982448400013, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.535824950283796, "cur_kl_coeff": 2.728484105318784e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.204715387152616, "policy_loss": -0.002222416458698236, "vf_loss": 6.206937798495015, "vf_explained_var": 0.5827866116844157, "kl": 0.003820388576516323, "entropy": 0.9245369779685187, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 146475.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -52.40000000000015, "episode_reward_mean": 179.16999999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -502.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 310.0}, "policy_reward_mean": {"prey_policy": 78.70999999999998, "predator_policy": 10.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [257.6, 210.39999999999955, 248.1, 214.19999999999933, 40.0000000000003, 308.90000000000094, 115.79999999999976, 123.69999999999978, 400.0, 190.2999999999994, 68.80000000000015, 121.89999999999979, 219.99999999999926, 32.30000000000018, 376.0, 113.39999999999989, 34.600000000000264, 246.99999999999932, 185.79999999999953, 211.59999999999994, 111.09999999999988, 198.39999999999935, 165.69999999999953, 199.99999999999935, 185.69999999999942, 24.600000000000062, 265.1999999999998, 40.0000000000003, 214.9999999999993, 207.39999999999932, 195.19999999999933, 64.10000000000025, 169.19999999999948, 219.99999999999926, 40.0000000000003, 40.0000000000003, 199.99999999999935, 219.99999999999926, 40.0000000000003, 376.6, 335.20000000000164, 143.49999999999915, 372.0, 219.99999999999926, 290.80000000000007, 226.2999999999993, 35.30000000000023, 224.99999999999932, 214.59999999999928, 40.0000000000003, 191.1999999999994, 215.99999999999926, 182.69999999999962, 40.0000000000003, 219.99999999999926, 209.49999999999983, 219.99999999999926, 303.9000000000003, 57.100000000000385, 40.0000000000003, 373.0, 103.79999999999914, 146.89999999999893, 219.99999999999926, 219.99999999999926, 234.39999999999915, 192.69999999999948, 235.19999999999956, 33.400000000000205, 397.3, 362.20000000000016, 348.6, 245.1999999999998, 35.600000000000236, 35.600000000000236, 219.99999999999926, 360.4, 195.7999999999994, 345.5, 101.19999999999996, 184.49999999999974, 40.0000000000003, 177.49999999999946, 72.89999999999998, 21.60000000000004, 197.89999999999935, 208.29999999999936, 252.39999999999918, 40.0000000000003, 177.99999999999972, 50.40000000000045, 165.29999999999953, 185.7999999999996, 204.0, 185.39999999999927, 211.69999999999968, 50.19999999999998, 264.0999999999994, 190.8999999999992, -52.40000000000015], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [107.29999999999998, 140.3, 19.4, 170.0, 129.79999999999998, 110.29999999999998, -170.80000000000067, 200.0, 20.000000000000014, 20.000000000000014, 170.0, 128.89999999999955, 20.000000000000014, 87.79999999999997, 103.69999999999997, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 170.3, 48.80000000000024, 20.000000000000014, 101.89999999999998, 20.000000000000014, 200.0, 20.000000000000014, 5.299999999999965, 20.000000000000014, 194.0, 173.0, 64.40000000000005, 20.000000000000014, 13.699999999999964, -42.10000000000031, 200.0, 47.00000000000018, 136.1, 49.70000000000024, 150.20000000000005, 49.40000000000002, 20.000000000000014, 91.09999999999997, 20.000000000000014, 178.4, -5.1999999999999265, 146.89999999999998, 170.0, 20.000000000000014, 13.699999999999964, 158.0, 17.899999999999988, -7.299999999999912, 47.300000000000125, 191.9, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999846, 20.000000000000014, 187.4, 200.0, -80.8000000000008, 17.899999999999988, 45.199999999999974, 138.20000000000005, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, 200.0, 135.1999999999996, 200.0, 123.49999999999974, 20.000000000000014, 200.0, 155.0, 20.000000000000014, 200.0, 170.0, 99.80000000000003, 200.0, 26.30000000000009, 20.000000000000014, -15.699999999999747, 56.900000000000176, 157.1, 194.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.199999999999967, 170.0, 194.0, 20.000000000000014, 122.89999999999995, 48.79999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 23.900000000000155, 155.6, 200.0, 20.000000000000014, 179.0, 113.8999999999999, 20.000000000000014, 37.100000000000186, 20.000000000000014, 20.000000000000014, 191.0, 173.0, -7.5999999999998895, 97.39999999999961, 137.8999999999996, -0.9999999999999992, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 62.30000000000022, 172.1, 170.0, -1.2999999999998693, 170.29999999999984, 50.900000000000155, 7.399999999999965, 20.000000000000014, 200.0, 197.3, 167.59999999999997, 194.6, 143.59999999999997, 200.0, 165.8, 79.39999999999998, 11.599999999999964, 20.000000000000014, 20.000000000000014, 11.599999999999964, 200.0, 20.000000000000014, 181.1, 170.3, -26.19999999999979, 200.0, 170.0, 165.5, 20.000000000000014, 81.19999999999996, 74.89999999999996, -502.39999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, 147.5, -34.60000000000002, 3.499999999999879, -114.4000000000006, 20.000000000000014, 170.0, 8.89999999999997, 20.000000000000014, 188.3, 200.0, 52.40000000000023, 20.000000000000014, 20.000000000000014, 44.299999999999976, 121.70000000000007, 10.399999999999975, 20.000000000000014, 20.000000000000014, 137.29999999999998, -55.59999999999996, 160.4, 53.600000000000115, 115.39999999999998, 20.000000000000014, 163.39999999999992, -141.30000000000013, 200.0, 20.000000000000014, -26.800000000000665, 64.10000000000012, 200.0, 27.200000000000024, 157.69999999999985, 13.699999999999964, -150.1000000000005], "policy_predator_policy_reward": [0.0, 10.0, 21.0, 0.0, 8.0, 0.0, 122.0, 63.0, 0.0, 0.0, 10.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 9.0, 0.0, 29.0, 0.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 12.0, 12.0, 0.0, 10.0, 10.0, 4.0, 0.0, 14.0, 12.0, 14.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 37.0, 39.0, 1.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 11.0, 10.0, 0.0, 0.0, 17.0, 14.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 2.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 25.0, 5.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 18.0, 0.0, 14.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 22.0, 0.0, 10.0, 0.0, 0.0, 0.0, 310.0, 302.0, 0.0, 0.0, 0.0, 10.0, 44.0, 60.0, 62.0, 54.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 11.0, 0.0, 8.0, 36.0, 45.0, 15.0, 20.0, 2.0, 0.0, 82.0, 71.0, 39.0, 18.0, 0.0, 0.0, 0.0, 6.0, 84.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4470532874687123, "mean_inference_ms": 4.0997931411521185, "mean_action_processing_ms": 0.7060089400674967, "mean_env_wait_ms": 0.8804223829477884, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.003931164741516113, "StateBufferConnector_ms": 0.004839539527893066, "ViewRequirementAgentConnector_ms": 0.2654455900192261}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -52.40000000000015, "episode_return_mean": 179.16999999999973, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000, "num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 239.3882367330691, "num_env_steps_trained_throughput_per_sec": 239.3882367330691, "timesteps_total": 312000, "num_env_steps_sampled_lifetime": 312000, "num_agent_steps_sampled_lifetime": 1248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1248000, "timers": {"training_iteration_time_ms": 17069.046, "restore_workers_time_ms": 0.019, "training_step_time_ms": 17068.97, "sample_time_ms": 3179.568, "learn_time_ms": 13867.728, "learn_throughput": 288.439, "synch_weights_time_ms": 17.619}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 312000, "num_agent_steps_sampled": 1248000, "num_agent_steps_trained": 1248000}, "done": false, "training_iteration": 78, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-15-25", "timestamp": 1723522525, "time_this_iter_s": 16.76942205429077, "time_total_s": 1394.4247014522552, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d689d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1394.4247014522552, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 88.125, "ram_util_percent": 83.22083333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2475587825926524, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.47031477029834473, "policy_loss": -0.0023337453988099854, "vf_loss": 0.4726408866374561, "vf_explained_var": 0.010210865294491804, "kl": 0.013717221962077827, "entropy": 0.9205055859984544, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.532789618628367, "cur_kl_coeff": 1.364242052659392e-13, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.779047091801961, "policy_loss": -0.0016753905072128253, "vf_loss": 5.780722472024342, "vf_explained_var": 0.8454178262009192, "kl": 0.003317276799884096, "entropy": 0.7113979873676148, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 148365.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -52.40000000000015, "episode_reward_mean": 182.47099999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -502.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 310.0}, "policy_reward_mean": {"prey_policy": 80.98549999999999, "predator_policy": 10.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [185.79999999999953, 211.59999999999994, 111.09999999999988, 198.39999999999935, 165.69999999999953, 199.99999999999935, 185.69999999999942, 24.600000000000062, 265.1999999999998, 40.0000000000003, 214.9999999999993, 207.39999999999932, 195.19999999999933, 64.10000000000025, 169.19999999999948, 219.99999999999926, 40.0000000000003, 40.0000000000003, 199.99999999999935, 219.99999999999926, 40.0000000000003, 376.6, 335.20000000000164, 143.49999999999915, 372.0, 219.99999999999926, 290.80000000000007, 226.2999999999993, 35.30000000000023, 224.99999999999932, 214.59999999999928, 40.0000000000003, 191.1999999999994, 215.99999999999926, 182.69999999999962, 40.0000000000003, 219.99999999999926, 209.49999999999983, 219.99999999999926, 303.9000000000003, 57.100000000000385, 40.0000000000003, 373.0, 103.79999999999914, 146.89999999999893, 219.99999999999926, 219.99999999999926, 234.39999999999915, 192.69999999999948, 235.19999999999956, 33.400000000000205, 397.3, 362.20000000000016, 348.6, 245.1999999999998, 35.600000000000236, 35.600000000000236, 219.99999999999926, 360.4, 195.7999999999994, 345.5, 101.19999999999996, 184.49999999999974, 40.0000000000003, 177.49999999999946, 72.89999999999998, 21.60000000000004, 197.89999999999935, 208.29999999999936, 252.39999999999918, 40.0000000000003, 177.99999999999972, 50.40000000000045, 165.29999999999953, 185.7999999999996, 204.0, 185.39999999999927, 211.69999999999968, 50.19999999999998, 264.0999999999994, 190.8999999999992, -52.40000000000015, 316.29999999999984, 222.69999999999928, 247.69999999999982, 48.700000000000244, 40.0000000000003, 400.0, 24.60000000000007, 199.99999999999935, 207.99999999999932, 222.99999999999932, 251.39999999999995, 168.49999999999952, 211.1999999999993, 142.60000000000014, 244.3, 152.49999999999957, 351.40000000000003, 200.19999999999936], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [136.1, 49.70000000000024, 150.20000000000005, 49.40000000000002, 20.000000000000014, 91.09999999999997, 20.000000000000014, 178.4, -5.1999999999999265, 146.89999999999998, 170.0, 20.000000000000014, 13.699999999999964, 158.0, 17.899999999999988, -7.299999999999912, 47.300000000000125, 191.9, 20.000000000000014, 20.000000000000014, 200.0, -0.9999999999999846, 20.000000000000014, 187.4, 200.0, -80.8000000000008, 17.899999999999988, 45.199999999999974, 138.20000000000005, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 170.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 167.6, 200.0, 135.1999999999996, 200.0, 123.49999999999974, 20.000000000000014, 200.0, 155.0, 20.000000000000014, 200.0, 170.0, 99.80000000000003, 200.0, 26.30000000000009, 20.000000000000014, -15.699999999999747, 56.900000000000176, 157.1, 194.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.199999999999967, 170.0, 194.0, 20.000000000000014, 122.89999999999995, 48.79999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 23.900000000000155, 155.6, 200.0, 20.000000000000014, 179.0, 113.8999999999999, 20.000000000000014, 37.100000000000186, 20.000000000000014, 20.000000000000014, 191.0, 173.0, -7.5999999999998895, 97.39999999999961, 137.8999999999996, -0.9999999999999992, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 62.30000000000022, 172.1, 170.0, -1.2999999999998693, 170.29999999999984, 50.900000000000155, 7.399999999999965, 20.000000000000014, 200.0, 197.3, 167.59999999999997, 194.6, 143.59999999999997, 200.0, 165.8, 79.39999999999998, 11.599999999999964, 20.000000000000014, 20.000000000000014, 11.599999999999964, 200.0, 20.000000000000014, 181.1, 170.3, -26.19999999999979, 200.0, 170.0, 165.5, 20.000000000000014, 81.19999999999996, 74.89999999999996, -502.39999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, 147.5, -34.60000000000002, 3.499999999999879, -114.4000000000006, 20.000000000000014, 170.0, 8.89999999999997, 20.000000000000014, 188.3, 200.0, 52.40000000000023, 20.000000000000014, 20.000000000000014, 44.299999999999976, 121.70000000000007, 10.399999999999975, 20.000000000000014, 20.000000000000014, 137.29999999999998, -55.59999999999996, 160.4, 53.600000000000115, 115.39999999999998, 20.000000000000014, 163.39999999999992, -141.30000000000013, 200.0, 20.000000000000014, -26.800000000000665, 64.10000000000012, 200.0, 27.200000000000024, 157.69999999999985, 13.699999999999964, -150.1000000000005, 200.0, 116.29999999999998, 22.70000000000001, 200.0, 70.69999999999999, 149.0, 25.400000000000112, 17.29999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.900000000000027, -70.30000000000004, 20.000000000000014, 170.0, 20.000000000000014, 170.0, 19.99999999999997, 200.0, 109.10000000000001, 137.29999999999998, 159.5, -0.9999999999999846, 3.199999999999995, 200.0, 86.59999999999997, 55.99999999999996, 2.299999999999784, 179.0, 20.000000000000014, 132.5, 151.4, 200.0, 180.2, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 0.0, 12.0, 12.0, 0.0, 10.0, 10.0, 4.0, 0.0, 14.0, 12.0, 14.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 37.0, 39.0, 1.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 11.0, 10.0, 0.0, 0.0, 17.0, 14.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 2.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 25.0, 5.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 18.0, 0.0, 14.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 22.0, 0.0, 10.0, 0.0, 0.0, 0.0, 310.0, 302.0, 0.0, 0.0, 0.0, 10.0, 44.0, 60.0, 62.0, 54.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 11.0, 0.0, 8.0, 36.0, 45.0, 15.0, 20.0, 2.0, 0.0, 82.0, 71.0, 39.0, 18.0, 0.0, 0.0, 0.0, 6.0, 84.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 17.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 43.0, 0.0, 10.0, 8.0, 10.0, 0.0, 3.0, 0.0, 5.0, 10.0, 0.0, 6.0, 2.0, 0.0, 0.0, 10.0, 53.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4436974660199113, "mean_inference_ms": 4.094972248274381, "mean_action_processing_ms": 0.7037319891762153, "mean_env_wait_ms": 0.8785962053857479, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00921165943145752, "StateBufferConnector_ms": 0.008309245109558105, "ViewRequirementAgentConnector_ms": 0.2832437753677368}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -52.40000000000015, "episode_return_mean": 182.47099999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000, "num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 234.48510434278097, "num_env_steps_trained_throughput_per_sec": 234.48510434278097, "timesteps_total": 316000, "num_env_steps_sampled_lifetime": 316000, "num_agent_steps_sampled_lifetime": 1264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1264000, "timers": {"training_iteration_time_ms": 16892.628, "restore_workers_time_ms": 0.019, "training_step_time_ms": 16892.545, "sample_time_ms": 3242.456, "learn_time_ms": 13629.192, "learn_throughput": 293.488, "synch_weights_time_ms": 16.916}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 316000, "num_agent_steps_sampled": 1264000, "num_agent_steps_trained": 1264000}, "done": false, "training_iteration": 79, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-15-43", "timestamp": 1723522543, "time_this_iter_s": 17.124158143997192, "time_total_s": 1411.5488595962524, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28e0040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1411.5488595962524, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 83.51666666666667, "ram_util_percent": 82.91666666666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3604286349383454, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.4044160498828484, "policy_loss": -0.0036467324047985057, "vf_loss": 1.4080543764369198, "vf_explained_var": 0.002577722671801451, "kl": 0.015113990037508282, "entropy": 0.8621202958954706, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 21.58934722911744, "cur_kl_coeff": 6.82121026329696e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.18195917013461, "policy_loss": -0.0009352726774369047, "vf_loss": 6.182894430967866, "vf_explained_var": 0.582450296355303, "kl": 0.002407524924617595, "entropy": 0.7139411191776316, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 150255.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -82.00000000000004, "episode_reward_mean": 183.41199999999972, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -502.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 310.0}, "policy_reward_mean": {"prey_policy": 78.88099999999999, "predator_policy": 12.825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [335.20000000000164, 143.49999999999915, 372.0, 219.99999999999926, 290.80000000000007, 226.2999999999993, 35.30000000000023, 224.99999999999932, 214.59999999999928, 40.0000000000003, 191.1999999999994, 215.99999999999926, 182.69999999999962, 40.0000000000003, 219.99999999999926, 209.49999999999983, 219.99999999999926, 303.9000000000003, 57.100000000000385, 40.0000000000003, 373.0, 103.79999999999914, 146.89999999999893, 219.99999999999926, 219.99999999999926, 234.39999999999915, 192.69999999999948, 235.19999999999956, 33.400000000000205, 397.3, 362.20000000000016, 348.6, 245.1999999999998, 35.600000000000236, 35.600000000000236, 219.99999999999926, 360.4, 195.7999999999994, 345.5, 101.19999999999996, 184.49999999999974, 40.0000000000003, 177.49999999999946, 72.89999999999998, 21.60000000000004, 197.89999999999935, 208.29999999999936, 252.39999999999918, 40.0000000000003, 177.99999999999972, 50.40000000000045, 165.29999999999953, 185.7999999999996, 204.0, 185.39999999999927, 211.69999999999968, 50.19999999999998, 264.0999999999994, 190.8999999999992, -52.40000000000015, 316.29999999999984, 222.69999999999928, 247.69999999999982, 48.700000000000244, 40.0000000000003, 400.0, 24.60000000000007, 199.99999999999935, 207.99999999999932, 222.99999999999932, 251.39999999999995, 168.49999999999952, 211.1999999999993, 142.60000000000014, 244.3, 152.49999999999957, 351.40000000000003, 200.19999999999936, 219.99999999999926, 219.99999999999926, 161.69999999999962, 213.69999999999922, 84.19999999999996, 215.99999999999926, 55.70000000000022, 85.0000000000002, 85.89999999999998, 152.1999999999996, 270.99999999999966, 242.2999999999996, 175.69999999999948, 110.19999999999989, 136.29999999999967, 211.69999999999936, 273.9999999999996, 174.39999999999947, 310.70000000000005, 198.29999999999956, 152.6999999999998, -82.00000000000004], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [135.1999999999996, 200.0, 123.49999999999974, 20.000000000000014, 200.0, 155.0, 20.000000000000014, 200.0, 170.0, 99.80000000000003, 200.0, 26.30000000000009, 20.000000000000014, -15.699999999999747, 56.900000000000176, 157.1, 194.6, 20.000000000000014, 20.000000000000014, 20.000000000000014, 3.199999999999967, 170.0, 194.0, 20.000000000000014, 122.89999999999995, 48.79999999999997, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 23.900000000000155, 155.6, 200.0, 20.000000000000014, 179.0, 113.8999999999999, 20.000000000000014, 37.100000000000186, 20.000000000000014, 20.000000000000014, 191.0, 173.0, -7.5999999999998895, 97.39999999999961, 137.8999999999996, -0.9999999999999992, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 62.30000000000022, 172.1, 170.0, -1.2999999999998693, 170.29999999999984, 50.900000000000155, 7.399999999999965, 20.000000000000014, 200.0, 197.3, 167.59999999999997, 194.6, 143.59999999999997, 200.0, 165.8, 79.39999999999998, 11.599999999999964, 20.000000000000014, 20.000000000000014, 11.599999999999964, 200.0, 20.000000000000014, 181.1, 170.3, -26.19999999999979, 200.0, 170.0, 165.5, 20.000000000000014, 81.19999999999996, 74.89999999999996, -502.39999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, 147.5, -34.60000000000002, 3.499999999999879, -114.4000000000006, 20.000000000000014, 170.0, 8.89999999999997, 20.000000000000014, 188.3, 200.0, 52.40000000000023, 20.000000000000014, 20.000000000000014, 44.299999999999976, 121.70000000000007, 10.399999999999975, 20.000000000000014, 20.000000000000014, 137.29999999999998, -55.59999999999996, 160.4, 53.600000000000115, 115.39999999999998, 20.000000000000014, 163.39999999999992, -141.30000000000013, 200.0, 20.000000000000014, -26.800000000000665, 64.10000000000012, 200.0, 27.200000000000024, 157.69999999999985, 13.699999999999964, -150.1000000000005, 200.0, 116.29999999999998, 22.70000000000001, 200.0, 70.69999999999999, 149.0, 25.400000000000112, 17.29999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.900000000000027, -70.30000000000004, 20.000000000000014, 170.0, 20.000000000000014, 170.0, 19.99999999999997, 200.0, 109.10000000000001, 137.29999999999998, 159.5, -0.9999999999999846, 3.199999999999995, 200.0, 86.59999999999997, 55.99999999999996, 2.299999999999784, 179.0, 20.000000000000014, 132.5, 151.4, 200.0, 180.2, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 154.10000000000002, -9.39999999999975, 193.69999999999996, 20.000000000000014, 155.0, -206.80000000000044, 194.0, 20.000000000000014, 53.300000000000104, -13.599999999999794, -73.6000000000006, 104.59999999999998, 20.000000000000014, 65.89999999999992, 126.19999999999997, 20.000000000000014, 182.0, 82.99999999999993, 170.0, 62.30000000000007, 145.70000000000005, 20.000000000000014, 20.000000000000014, 90.19999999999997, 109.09999999999998, 27.200000000000138, 170.0, 31.700000000000074, 126.80000000000004, 126.19999999999958, 124.39999999999998, 47.000000000000156, 193.7, 107.00000000000004, -194.80000000000047, 199.1, 97.69999999999999, 47.00000000000009, -309.6999999999999, -7.299999999999901], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 7.0, 10.0, 0.0, 0.0, 11.0, 10.0, 0.0, 0.0, 17.0, 14.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 10.0, 0.0, 2.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 25.0, 5.0, 0.0, 0.0, 0.0, 11.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 18.0, 0.0, 14.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 22.0, 0.0, 10.0, 0.0, 0.0, 0.0, 310.0, 302.0, 0.0, 0.0, 0.0, 10.0, 44.0, 60.0, 62.0, 54.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 11.0, 0.0, 8.0, 36.0, 45.0, 15.0, 20.0, 2.0, 0.0, 82.0, 71.0, 39.0, 18.0, 0.0, 0.0, 0.0, 6.0, 84.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 17.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 43.0, 0.0, 10.0, 8.0, 10.0, 0.0, 3.0, 0.0, 5.0, 10.0, 0.0, 6.0, 2.0, 0.0, 0.0, 10.0, 53.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 72.0, 64.0, 0.0, 2.0, 0.0, 16.0, 54.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 15.0, 6.0, 0.0, 3.0, 10.0, 0.0, 92.0, 102.0, 2.0, 6.0, 123.0, 112.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4339201685307916, "mean_inference_ms": 4.070864111250817, "mean_action_processing_ms": 0.6974635828866406, "mean_env_wait_ms": 0.871384953037118, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009376049041748047, "StateBufferConnector_ms": 0.007880926132202148, "ViewRequirementAgentConnector_ms": 0.3032078742980957}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -82.00000000000004, "episode_return_mean": 183.41199999999972, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000, "num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 216.01749141036694, "num_env_steps_trained_throughput_per_sec": 216.01749141036694, "timesteps_total": 320000, "num_env_steps_sampled_lifetime": 320000, "num_agent_steps_sampled_lifetime": 1280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1280000, "timers": {"training_iteration_time_ms": 17110.496, "restore_workers_time_ms": 0.018, "training_step_time_ms": 17110.421, "sample_time_ms": 3371.277, "learn_time_ms": 13718.59, "learn_throughput": 291.575, "synch_weights_time_ms": 17.317}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 320000, "num_agent_steps_sampled": 1280000, "num_agent_steps_trained": 1280000}, "done": false, "training_iteration": 80, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-16-01", "timestamp": 1723522561, "time_this_iter_s": 18.598668098449707, "time_total_s": 1430.1475276947021, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4f039d0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1430.1475276947021, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 89.31851851851852, "ram_util_percent": 83.55925925925925}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2316773036918627, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.2293942450846314, "policy_loss": -9.98855019037528e-05, "vf_loss": 1.2294895057640378, "vf_explained_var": 0.003076030747600333, "kl": 0.00830709696807106, "entropy": 0.7707292014644259, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 27.960706772627653, "cur_kl_coeff": 3.41060513164848e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.749305893882872, "policy_loss": -0.0017980198279791881, "vf_loss": 5.751103901484656, "vf_explained_var": 0.6420178488133446, "kl": 0.0021024982477798396, "entropy": 0.5990826640652601, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 152145.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -82.00000000000004, "episode_reward_mean": 186.06599999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -502.39999999999986, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 310.0}, "policy_reward_mean": {"prey_policy": 78.69799999999998, "predator_policy": 14.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [57.100000000000385, 40.0000000000003, 373.0, 103.79999999999914, 146.89999999999893, 219.99999999999926, 219.99999999999926, 234.39999999999915, 192.69999999999948, 235.19999999999956, 33.400000000000205, 397.3, 362.20000000000016, 348.6, 245.1999999999998, 35.600000000000236, 35.600000000000236, 219.99999999999926, 360.4, 195.7999999999994, 345.5, 101.19999999999996, 184.49999999999974, 40.0000000000003, 177.49999999999946, 72.89999999999998, 21.60000000000004, 197.89999999999935, 208.29999999999936, 252.39999999999918, 40.0000000000003, 177.99999999999972, 50.40000000000045, 165.29999999999953, 185.7999999999996, 204.0, 185.39999999999927, 211.69999999999968, 50.19999999999998, 264.0999999999994, 190.8999999999992, -52.40000000000015, 316.29999999999984, 222.69999999999928, 247.69999999999982, 48.700000000000244, 40.0000000000003, 400.0, 24.60000000000007, 199.99999999999935, 207.99999999999932, 222.99999999999932, 251.39999999999995, 168.49999999999952, 211.1999999999993, 142.60000000000014, 244.3, 152.49999999999957, 351.40000000000003, 200.19999999999936, 219.99999999999926, 219.99999999999926, 161.69999999999962, 213.69999999999922, 84.19999999999996, 215.99999999999926, 55.70000000000022, 85.0000000000002, 85.89999999999998, 152.1999999999996, 270.99999999999966, 242.2999999999996, 175.69999999999948, 110.19999999999989, 136.29999999999967, 211.69999999999936, 273.9999999999996, 174.39999999999947, 310.70000000000005, 198.29999999999956, 152.6999999999998, -82.00000000000004, 101.19999999999995, 311.79999999999995, 135.39999999999986, 40.0000000000003, 331.1999999999999, 169.59999999999948, -8.499999999999787, 325.8000000000012, 265.8999999999995, 309.8000000000003, 272.5999999999999, 110.80000000000004, 15.49999999999992, 353.2000000000012, 310.5, 292.5999999999999, 213.9999999999993, 400.0], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 37.100000000000186, 20.000000000000014, 20.000000000000014, 191.0, 173.0, -7.5999999999998895, 97.39999999999961, 137.8999999999996, -0.9999999999999992, 200.0, 20.000000000000014, 20.000000000000014, 200.0, 62.30000000000022, 172.1, 170.0, -1.2999999999998693, 170.29999999999984, 50.900000000000155, 7.399999999999965, 20.000000000000014, 200.0, 197.3, 167.59999999999997, 194.6, 143.59999999999997, 200.0, 165.8, 79.39999999999998, 11.599999999999964, 20.000000000000014, 20.000000000000014, 11.599999999999964, 200.0, 20.000000000000014, 181.1, 170.3, -26.19999999999979, 200.0, 170.0, 165.5, 20.000000000000014, 81.19999999999996, 74.89999999999996, -502.39999999999986, 20.000000000000014, 20.000000000000014, 20.000000000000014, 147.5, -34.60000000000002, 3.499999999999879, -114.4000000000006, 20.000000000000014, 170.0, 8.89999999999997, 20.000000000000014, 188.3, 200.0, 52.40000000000023, 20.000000000000014, 20.000000000000014, 44.299999999999976, 121.70000000000007, 10.399999999999975, 20.000000000000014, 20.000000000000014, 137.29999999999998, -55.59999999999996, 160.4, 53.600000000000115, 115.39999999999998, 20.000000000000014, 163.39999999999992, -141.30000000000013, 200.0, 20.000000000000014, -26.800000000000665, 64.10000000000012, 200.0, 27.200000000000024, 157.69999999999985, 13.699999999999964, -150.1000000000005, 200.0, 116.29999999999998, 22.70000000000001, 200.0, 70.69999999999999, 149.0, 25.400000000000112, 17.29999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.900000000000027, -70.30000000000004, 20.000000000000014, 170.0, 20.000000000000014, 170.0, 19.99999999999997, 200.0, 109.10000000000001, 137.29999999999998, 159.5, -0.9999999999999846, 3.199999999999995, 200.0, 86.59999999999997, 55.99999999999996, 2.299999999999784, 179.0, 20.000000000000014, 132.5, 151.4, 200.0, 180.2, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 154.10000000000002, -9.39999999999975, 193.69999999999996, 20.000000000000014, 155.0, -206.80000000000044, 194.0, 20.000000000000014, 53.300000000000104, -13.599999999999794, -73.6000000000006, 104.59999999999998, 20.000000000000014, 65.89999999999992, 126.19999999999997, 20.000000000000014, 182.0, 82.99999999999993, 170.0, 62.30000000000007, 145.70000000000005, 20.000000000000014, 20.000000000000014, 90.19999999999997, 109.09999999999998, 27.200000000000138, 170.0, 31.700000000000074, 126.80000000000004, 126.19999999999958, 124.39999999999998, 47.000000000000156, 193.7, 107.00000000000004, -194.80000000000047, 199.1, 97.69999999999999, 47.00000000000009, -309.6999999999999, -7.299999999999901, 131.60000000000002, -93.40000000000039, 118.99999999999999, 192.79999999999995, 31.699999999999996, 103.69999999999997, 20.000000000000014, 20.000000000000014, 141.19999999999993, 170.0, 149.6, 20.000000000000014, 13.699999999999964, -152.20000000000064, 194.0, 129.79999999999967, 200.0, 65.89999999999996, 172.1, 127.69999999999996, 200.0, 47.60000000000012, 140.60000000000002, -89.8000000000007, 20.000000000000014, -137.5000000000007, 200.0, 153.1999999999997, 122.6, 185.9, 98.3, 188.3, 20.000000000000014, 191.0, 200.0, 200.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 14.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 18.0, 0.0, 14.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 9.0, 22.0, 0.0, 10.0, 0.0, 0.0, 0.0, 310.0, 302.0, 0.0, 0.0, 0.0, 10.0, 44.0, 60.0, 62.0, 54.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 11.0, 0.0, 8.0, 36.0, 45.0, 15.0, 20.0, 2.0, 0.0, 82.0, 71.0, 39.0, 18.0, 0.0, 0.0, 0.0, 6.0, 84.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 17.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 43.0, 0.0, 10.0, 8.0, 10.0, 0.0, 3.0, 0.0, 5.0, 10.0, 0.0, 6.0, 2.0, 0.0, 0.0, 10.0, 53.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 72.0, 64.0, 0.0, 2.0, 0.0, 16.0, 54.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 15.0, 6.0, 0.0, 3.0, 10.0, 0.0, 92.0, 102.0, 2.0, 6.0, 123.0, 112.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 82.0, 48.0, 0.0, 2.0, 0.0, 0.0, 10.0, 0.0, 0.0, 25.0, 0.0, 60.0, 64.0, 69.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4422947324881215, "mean_inference_ms": 4.1003010512600495, "mean_action_processing_ms": 0.7013055736003957, "mean_env_wait_ms": 0.877209101096646, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009517669677734375, "StateBufferConnector_ms": 0.007986664772033691, "ViewRequirementAgentConnector_ms": 0.3146042823791504}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -82.00000000000004, "episode_return_mean": 186.06599999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000, "num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 211.56069151322546, "num_env_steps_trained_throughput_per_sec": 211.56069151322546, "timesteps_total": 324000, "num_env_steps_sampled_lifetime": 324000, "num_agent_steps_sampled_lifetime": 1296000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1296000, "timers": {"training_iteration_time_ms": 17425.908, "restore_workers_time_ms": 0.017, "training_step_time_ms": 17425.833, "sample_time_ms": 3754.848, "learn_time_ms": 13650.06, "learn_throughput": 293.039, "synch_weights_time_ms": 17.63}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 324000, "num_agent_steps_sampled": 1296000, "num_agent_steps_trained": 1296000}, "done": false, "training_iteration": 81, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-16-20", "timestamp": 1723522580, "time_this_iter_s": 18.9997079372406, "time_total_s": 1449.1472356319427, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d47c10>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1449.1472356319427, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 87.74814814814815, "ram_util_percent": 83.48148148148148}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9557979801916099, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.4367807478264526, "policy_loss": -0.0013745860701732378, "vf_loss": 0.43814844854524676, "vf_explained_var": 0.0037298919031859704, "kl": 0.012382733356433539, "entropy": 0.6486513725033513, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 33.45334270416744, "cur_kl_coeff": 1.70530256582424e-14, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.456452382556976, "policy_loss": -0.002463315754990887, "vf_loss": 5.458915695185384, "vf_explained_var": 0.7028486104869338, "kl": 0.003549585781285161, "entropy": 0.7642210848117, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 154035.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -82.00000000000004, "episode_reward_mean": 177.05199999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -320.20000000000005, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 169.0}, "policy_reward_mean": {"prey_policy": 75.76599999999996, "predator_policy": 12.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 177.49999999999946, 72.89999999999998, 21.60000000000004, 197.89999999999935, 208.29999999999936, 252.39999999999918, 40.0000000000003, 177.99999999999972, 50.40000000000045, 165.29999999999953, 185.7999999999996, 204.0, 185.39999999999927, 211.69999999999968, 50.19999999999998, 264.0999999999994, 190.8999999999992, -52.40000000000015, 316.29999999999984, 222.69999999999928, 247.69999999999982, 48.700000000000244, 40.0000000000003, 400.0, 24.60000000000007, 199.99999999999935, 207.99999999999932, 222.99999999999932, 251.39999999999995, 168.49999999999952, 211.1999999999993, 142.60000000000014, 244.3, 152.49999999999957, 351.40000000000003, 200.19999999999936, 219.99999999999926, 219.99999999999926, 161.69999999999962, 213.69999999999922, 84.19999999999996, 215.99999999999926, 55.70000000000022, 85.0000000000002, 85.89999999999998, 152.1999999999996, 270.99999999999966, 242.2999999999996, 175.69999999999948, 110.19999999999989, 136.29999999999967, 211.69999999999936, 273.9999999999996, 174.39999999999947, 310.70000000000005, 198.29999999999956, 152.6999999999998, -82.00000000000004, 101.19999999999995, 311.79999999999995, 135.39999999999986, 40.0000000000003, 331.1999999999999, 169.59999999999948, -8.499999999999787, 325.8000000000012, 265.8999999999995, 309.8000000000003, 272.5999999999999, 110.80000000000004, 15.49999999999992, 353.2000000000012, 310.5, 292.5999999999999, 213.9999999999993, 400.0, 219.09999999999937, 86.3999999999999, 326.90000000000003, 183.09999999999977, -37.49999999999955, 40.0000000000003, 59.20000000000004, 219.99999999999926, 380.0, 104.79999999999926, -8.40000000000006, 40.0000000000003, 122.19999999999956, 162.89999999999978, 27.100000000000115, 300.80000000000075, 89.49999999999872, 18.799999999999997, 219.99999999999926, 300.9000000000006, 225.2999999999995, 364.0, 341.90000000000134], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 147.5, -34.60000000000002, 3.499999999999879, -114.4000000000006, 20.000000000000014, 170.0, 8.89999999999997, 20.000000000000014, 188.3, 200.0, 52.40000000000023, 20.000000000000014, 20.000000000000014, 44.299999999999976, 121.70000000000007, 10.399999999999975, 20.000000000000014, 20.000000000000014, 137.29999999999998, -55.59999999999996, 160.4, 53.600000000000115, 115.39999999999998, 20.000000000000014, 163.39999999999992, -141.30000000000013, 200.0, 20.000000000000014, -26.800000000000665, 64.10000000000012, 200.0, 27.200000000000024, 157.69999999999985, 13.699999999999964, -150.1000000000005, 200.0, 116.29999999999998, 22.70000000000001, 200.0, 70.69999999999999, 149.0, 25.400000000000112, 17.29999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.900000000000027, -70.30000000000004, 20.000000000000014, 170.0, 20.000000000000014, 170.0, 19.99999999999997, 200.0, 109.10000000000001, 137.29999999999998, 159.5, -0.9999999999999846, 3.199999999999995, 200.0, 86.59999999999997, 55.99999999999996, 2.299999999999784, 179.0, 20.000000000000014, 132.5, 151.4, 200.0, 180.2, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 154.10000000000002, -9.39999999999975, 193.69999999999996, 20.000000000000014, 155.0, -206.80000000000044, 194.0, 20.000000000000014, 53.300000000000104, -13.599999999999794, -73.6000000000006, 104.59999999999998, 20.000000000000014, 65.89999999999992, 126.19999999999997, 20.000000000000014, 182.0, 82.99999999999993, 170.0, 62.30000000000007, 145.70000000000005, 20.000000000000014, 20.000000000000014, 90.19999999999997, 109.09999999999998, 27.200000000000138, 170.0, 31.700000000000074, 126.80000000000004, 126.19999999999958, 124.39999999999998, 47.000000000000156, 193.7, 107.00000000000004, -194.80000000000047, 199.1, 97.69999999999999, 47.00000000000009, -309.6999999999999, -7.299999999999901, 131.60000000000002, -93.40000000000039, 118.99999999999999, 192.79999999999995, 31.699999999999996, 103.69999999999997, 20.000000000000014, 20.000000000000014, 141.19999999999993, 170.0, 149.6, 20.000000000000014, 13.699999999999964, -152.20000000000064, 194.0, 129.79999999999967, 200.0, 65.89999999999996, 172.1, 127.69999999999996, 200.0, 47.60000000000012, 140.60000000000002, -89.8000000000007, 20.000000000000014, -137.5000000000007, 200.0, 153.1999999999997, 122.6, 185.9, 98.3, 188.3, 20.000000000000014, 191.0, 200.0, 200.0, 10.099999999999971, 200.0, 20.000000000000014, 55.400000000000084, 131.89999999999998, 185.0, 102.79999999999998, 80.29999999999974, -32.49999999999978, -64.00000000000034, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000008, 20.000000000000014, 200.0, 200.0, 170.0, 35.300000000000196, 69.49999999999969, -72.40000000000006, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 99.19999999999987, 3.8000000000002245, 133.1, 20.000000000000014, -40.89999999999988, 99.79999999999984, 200.0, 20.000000000000014, 69.49999999999977, 170.0, -320.20000000000005, 20.000000000000014, 200.0, 185.0, 110.89999999999944, 164.0, 44.299999999999976, 200.0, 164.0, 146.89999999999966, 191.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 10.0, 44.0, 60.0, 62.0, 54.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.0, 9.0, 11.0, 0.0, 8.0, 36.0, 45.0, 15.0, 20.0, 2.0, 0.0, 82.0, 71.0, 39.0, 18.0, 0.0, 0.0, 0.0, 6.0, 84.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 17.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 43.0, 0.0, 10.0, 8.0, 10.0, 0.0, 3.0, 0.0, 5.0, 10.0, 0.0, 6.0, 2.0, 0.0, 0.0, 10.0, 53.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 72.0, 64.0, 0.0, 2.0, 0.0, 16.0, 54.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 15.0, 6.0, 0.0, 3.0, 10.0, 0.0, 92.0, 102.0, 2.0, 6.0, 123.0, 112.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 82.0, 48.0, 0.0, 2.0, 0.0, 0.0, 10.0, 0.0, 0.0, 25.0, 0.0, 60.0, 64.0, 69.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 5.0, 5.0, 0.0, 0.0, 7.0, 52.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 0.0, 0.0, 3.0, 17.0, 9.0, 19.0, 29.0, 1.0, 0.0, 0.0, 0.0, 169.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 10.0, 0.0, 0.0, 3.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4331135364504504, "mean_inference_ms": 4.0844763394007675, "mean_action_processing_ms": 0.7024981937736642, "mean_env_wait_ms": 0.8702804566526514, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.009661674499511719, "StateBufferConnector_ms": 0.008281111717224121, "ViewRequirementAgentConnector_ms": 0.23637127876281738}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -82.00000000000004, "episode_return_mean": 177.05199999999982, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000, "num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 242.8277927470847, "num_env_steps_trained_throughput_per_sec": 242.8277927470847, "timesteps_total": 328000, "num_env_steps_sampled_lifetime": 328000, "num_agent_steps_sampled_lifetime": 1312000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1312000, "timers": {"training_iteration_time_ms": 17265.697, "restore_workers_time_ms": 0.021, "training_step_time_ms": 17265.606, "sample_time_ms": 3759.828, "learn_time_ms": 13484.684, "learn_throughput": 296.633, "synch_weights_time_ms": 17.82}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 328000, "num_agent_steps_sampled": 1312000, "num_agent_steps_trained": 1312000}, "done": false, "training_iteration": 82, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-16-37", "timestamp": 1723522597, "time_this_iter_s": 16.53832507133484, "time_total_s": 1465.6855607032776, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x330dc5dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1465.6855607032776, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 84.72173913043478, "ram_util_percent": 83.27826086956523}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9257390814720008, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.726513736020951, "policy_loss": -0.0012654322371990592, "vf_loss": 1.7277758305350308, "vf_explained_var": 0.001296630265220763, "kl": 0.005998103776925868, "entropy": 0.5211326052745183, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 25.112062122708274, "cur_kl_coeff": 8.5265128291212e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.080121993892408, "policy_loss": -0.0030700520139246706, "vf_loss": 5.083192047997127, "vf_explained_var": 0.49415987543958834, "kl": 0.008576051606487325, "entropy": 0.8687679514367744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 155925.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -232.7000000000004, "episode_reward_mean": 173.95099999999985, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": 72.73049999999995, "predator_policy": 14.245}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-52.40000000000015, 316.29999999999984, 222.69999999999928, 247.69999999999982, 48.700000000000244, 40.0000000000003, 400.0, 24.60000000000007, 199.99999999999935, 207.99999999999932, 222.99999999999932, 251.39999999999995, 168.49999999999952, 211.1999999999993, 142.60000000000014, 244.3, 152.49999999999957, 351.40000000000003, 200.19999999999936, 219.99999999999926, 219.99999999999926, 161.69999999999962, 213.69999999999922, 84.19999999999996, 215.99999999999926, 55.70000000000022, 85.0000000000002, 85.89999999999998, 152.1999999999996, 270.99999999999966, 242.2999999999996, 175.69999999999948, 110.19999999999989, 136.29999999999967, 211.69999999999936, 273.9999999999996, 174.39999999999947, 310.70000000000005, 198.29999999999956, 152.6999999999998, -82.00000000000004, 101.19999999999995, 311.79999999999995, 135.39999999999986, 40.0000000000003, 331.1999999999999, 169.59999999999948, -8.499999999999787, 325.8000000000012, 265.8999999999995, 309.8000000000003, 272.5999999999999, 110.80000000000004, 15.49999999999992, 353.2000000000012, 310.5, 292.5999999999999, 213.9999999999993, 400.0, 219.09999999999937, 86.3999999999999, 326.90000000000003, 183.09999999999977, -37.49999999999955, 40.0000000000003, 59.20000000000004, 219.99999999999926, 380.0, 104.79999999999926, -8.40000000000006, 40.0000000000003, 122.19999999999956, 162.89999999999978, 27.100000000000115, 300.80000000000075, 89.49999999999872, 18.799999999999997, 219.99999999999926, 300.9000000000006, 225.2999999999995, 364.0, 341.90000000000134, 219.99999999999926, 210.0999999999993, 194.7999999999993, 65.60000000000014, 110.19999999999987, 353.90000000000003, 287.59999999999985, 169.5999999999995, 218.89999999999927, -201.20000000000107, 210.99999999999932, 127.29999999999976, 147.99999999999957, 380.0, 59.400000000000055, -232.7000000000004, 91.29999999999923, -27.49999999999985], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [13.699999999999964, -150.1000000000005, 200.0, 116.29999999999998, 22.70000000000001, 200.0, 70.69999999999999, 149.0, 25.400000000000112, 17.29999999999997, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.900000000000027, -70.30000000000004, 20.000000000000014, 170.0, 20.000000000000014, 170.0, 19.99999999999997, 200.0, 109.10000000000001, 137.29999999999998, 159.5, -0.9999999999999846, 3.199999999999995, 200.0, 86.59999999999997, 55.99999999999996, 2.299999999999784, 179.0, 20.000000000000014, 132.5, 151.4, 200.0, 180.2, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 154.10000000000002, -9.39999999999975, 193.69999999999996, 20.000000000000014, 155.0, -206.80000000000044, 194.0, 20.000000000000014, 53.300000000000104, -13.599999999999794, -73.6000000000006, 104.59999999999998, 20.000000000000014, 65.89999999999992, 126.19999999999997, 20.000000000000014, 182.0, 82.99999999999993, 170.0, 62.30000000000007, 145.70000000000005, 20.000000000000014, 20.000000000000014, 90.19999999999997, 109.09999999999998, 27.200000000000138, 170.0, 31.700000000000074, 126.80000000000004, 126.19999999999958, 124.39999999999998, 47.000000000000156, 193.7, 107.00000000000004, -194.80000000000047, 199.1, 97.69999999999999, 47.00000000000009, -309.6999999999999, -7.299999999999901, 131.60000000000002, -93.40000000000039, 118.99999999999999, 192.79999999999995, 31.699999999999996, 103.69999999999997, 20.000000000000014, 20.000000000000014, 141.19999999999993, 170.0, 149.6, 20.000000000000014, 13.699999999999964, -152.20000000000064, 194.0, 129.79999999999967, 200.0, 65.89999999999996, 172.1, 127.69999999999996, 200.0, 47.60000000000012, 140.60000000000002, -89.8000000000007, 20.000000000000014, -137.5000000000007, 200.0, 153.1999999999997, 122.6, 185.9, 98.3, 188.3, 20.000000000000014, 191.0, 200.0, 200.0, 10.099999999999971, 200.0, 20.000000000000014, 55.400000000000084, 131.89999999999998, 185.0, 102.79999999999998, 80.29999999999974, -32.49999999999978, -64.00000000000034, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000008, 20.000000000000014, 200.0, 200.0, 170.0, 35.300000000000196, 69.49999999999969, -72.40000000000006, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 99.19999999999987, 3.8000000000002245, 133.1, 20.000000000000014, -40.89999999999988, 99.79999999999984, 200.0, 20.000000000000014, 69.49999999999977, 170.0, -320.20000000000005, 20.000000000000014, 200.0, 185.0, 110.89999999999944, 164.0, 44.299999999999976, 200.0, 164.0, 146.89999999999966, 191.0, 200.0, 20.000000000000014, 200.0, 1.0999999999999617, 20.000000000000014, 174.79999999999995, 20.000000000000014, 38.59999999999997, 20.000000000000014, 90.19999999999997, 200.0, 143.90000000000003, 194.0, 80.60000000000007, 61.40000000000015, 108.19999999999999, 17.899999999999988, 200.0, -93.4000000000007, -243.80000000000035, 191.0, 20.000000000000014, 20.000000000000014, 107.29999999999998, 127.99999999999999, 20.000000000000014, 170.0, 200.0, 200.0, -286.5999999999999, -179.50000000000026, -320.20000000000016, 20.000000000000014, 71.29999999999963, -368.5, 20.000000000000014], "policy_predator_policy_reward": [84.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.0, 17.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 31.0, 43.0, 0.0, 10.0, 8.0, 10.0, 0.0, 3.0, 0.0, 5.0, 10.0, 0.0, 6.0, 2.0, 0.0, 0.0, 10.0, 53.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 72.0, 64.0, 0.0, 2.0, 0.0, 16.0, 54.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 15.0, 6.0, 0.0, 3.0, 10.0, 0.0, 92.0, 102.0, 2.0, 6.0, 123.0, 112.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 82.0, 48.0, 0.0, 2.0, 0.0, 0.0, 10.0, 0.0, 0.0, 25.0, 0.0, 60.0, 64.0, 69.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 5.0, 5.0, 0.0, 0.0, 7.0, 52.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 0.0, 0.0, 3.0, 17.0, 9.0, 19.0, 29.0, 1.0, 0.0, 0.0, 0.0, 169.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 10.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 136.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 146.0, 176.0, 91.0, 0.0, 0.0, 181.0, 140.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4461932726824478, "mean_inference_ms": 4.116290934867222, "mean_action_processing_ms": 0.70002681200103, "mean_env_wait_ms": 0.8792272168583659, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00965261459350586, "StateBufferConnector_ms": 0.008299112319946289, "ViewRequirementAgentConnector_ms": 0.19796216487884521}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -232.7000000000004, "episode_return_mean": 173.95099999999985, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000, "num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 231.15099312634658, "num_env_steps_trained_throughput_per_sec": 231.15099312634658, "timesteps_total": 332000, "num_env_steps_sampled_lifetime": 332000, "num_agent_steps_sampled_lifetime": 1328000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1328000, "timers": {"training_iteration_time_ms": 17378.781, "restore_workers_time_ms": 0.021, "training_step_time_ms": 17378.69, "sample_time_ms": 3952.167, "learn_time_ms": 13405.725, "learn_throughput": 298.38, "synch_weights_time_ms": 17.808}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 332000, "num_agent_steps_sampled": 1328000, "num_agent_steps_trained": 1328000}, "done": false, "training_iteration": 83, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-16-54", "timestamp": 1723522614, "time_this_iter_s": 17.367151975631714, "time_total_s": 1483.0527126789093, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b28e0dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1483.0527126789093, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 86.54800000000002, "ram_util_percent": 83.38}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.030020753233127, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7883654754076685, "policy_loss": -0.0007835479509873838, "vf_loss": 0.7891461371839609, "vf_explained_var": 0.0008471979035271539, "kl": 0.005190141559236939, "entropy": 0.5721018556406889, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 46.29181024105776, "cur_kl_coeff": 8.5265128291212e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.588123394446398, "policy_loss": -0.001710939721731597, "vf_loss": 3.5898343362505476, "vf_explained_var": 0.8274150915562161, "kl": 0.002371490590227494, "entropy": 0.882332867983157, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 157815.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -232.7000000000004, "episode_reward_mean": 172.60799999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": 71.84399999999997, "predator_policy": 14.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [200.19999999999936, 219.99999999999926, 219.99999999999926, 161.69999999999962, 213.69999999999922, 84.19999999999996, 215.99999999999926, 55.70000000000022, 85.0000000000002, 85.89999999999998, 152.1999999999996, 270.99999999999966, 242.2999999999996, 175.69999999999948, 110.19999999999989, 136.29999999999967, 211.69999999999936, 273.9999999999996, 174.39999999999947, 310.70000000000005, 198.29999999999956, 152.6999999999998, -82.00000000000004, 101.19999999999995, 311.79999999999995, 135.39999999999986, 40.0000000000003, 331.1999999999999, 169.59999999999948, -8.499999999999787, 325.8000000000012, 265.8999999999995, 309.8000000000003, 272.5999999999999, 110.80000000000004, 15.49999999999992, 353.2000000000012, 310.5, 292.5999999999999, 213.9999999999993, 400.0, 219.09999999999937, 86.3999999999999, 326.90000000000003, 183.09999999999977, -37.49999999999955, 40.0000000000003, 59.20000000000004, 219.99999999999926, 380.0, 104.79999999999926, -8.40000000000006, 40.0000000000003, 122.19999999999956, 162.89999999999978, 27.100000000000115, 300.80000000000075, 89.49999999999872, 18.799999999999997, 219.99999999999926, 300.9000000000006, 225.2999999999995, 364.0, 341.90000000000134, 219.99999999999926, 210.0999999999993, 194.7999999999993, 65.60000000000014, 110.19999999999987, 353.90000000000003, 287.59999999999985, 169.5999999999995, 218.89999999999927, -201.20000000000107, 210.99999999999932, 127.29999999999976, 147.99999999999957, 380.0, 59.400000000000055, -232.7000000000004, 91.29999999999923, -27.49999999999985, 219.99999999999926, 217.99999999999926, 247.99999999999972, 360.20000000000005, 217.29999999999956, 199.99999999999935, 300.79999999999995, 40.0000000000003, 242.2999999999996, 328.5, 19.79999999999998, 157.79999999999956, 33.400000000000205, 33.400000000000205, 144.3999999999991, 178.59999999999943, 134.4999999999993, 189.20000000000005], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [180.2, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 20.000000000000014, 154.10000000000002, -9.39999999999975, 193.69999999999996, 20.000000000000014, 155.0, -206.80000000000044, 194.0, 20.000000000000014, 53.300000000000104, -13.599999999999794, -73.6000000000006, 104.59999999999998, 20.000000000000014, 65.89999999999992, 126.19999999999997, 20.000000000000014, 182.0, 82.99999999999993, 170.0, 62.30000000000007, 145.70000000000005, 20.000000000000014, 20.000000000000014, 90.19999999999997, 109.09999999999998, 27.200000000000138, 170.0, 31.700000000000074, 126.80000000000004, 126.19999999999958, 124.39999999999998, 47.000000000000156, 193.7, 107.00000000000004, -194.80000000000047, 199.1, 97.69999999999999, 47.00000000000009, -309.6999999999999, -7.299999999999901, 131.60000000000002, -93.40000000000039, 118.99999999999999, 192.79999999999995, 31.699999999999996, 103.69999999999997, 20.000000000000014, 20.000000000000014, 141.19999999999993, 170.0, 149.6, 20.000000000000014, 13.699999999999964, -152.20000000000064, 194.0, 129.79999999999967, 200.0, 65.89999999999996, 172.1, 127.69999999999996, 200.0, 47.60000000000012, 140.60000000000002, -89.8000000000007, 20.000000000000014, -137.5000000000007, 200.0, 153.1999999999997, 122.6, 185.9, 98.3, 188.3, 20.000000000000014, 191.0, 200.0, 200.0, 10.099999999999971, 200.0, 20.000000000000014, 55.400000000000084, 131.89999999999998, 185.0, 102.79999999999998, 80.29999999999974, -32.49999999999978, -64.00000000000034, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000008, 20.000000000000014, 200.0, 200.0, 170.0, 35.300000000000196, 69.49999999999969, -72.40000000000006, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 99.19999999999987, 3.8000000000002245, 133.1, 20.000000000000014, -40.89999999999988, 99.79999999999984, 200.0, 20.000000000000014, 69.49999999999977, 170.0, -320.20000000000005, 20.000000000000014, 200.0, 185.0, 110.89999999999944, 164.0, 44.299999999999976, 200.0, 164.0, 146.89999999999966, 191.0, 200.0, 20.000000000000014, 200.0, 1.0999999999999617, 20.000000000000014, 174.79999999999995, 20.000000000000014, 38.59999999999997, 20.000000000000014, 90.19999999999997, 200.0, 143.90000000000003, 194.0, 80.60000000000007, 61.40000000000015, 108.19999999999999, 17.899999999999988, 200.0, -93.4000000000007, -243.80000000000035, 191.0, 20.000000000000014, 20.000000000000014, 107.29999999999998, 127.99999999999999, 20.000000000000014, 170.0, 200.0, 200.0, -286.5999999999999, -179.50000000000026, -320.20000000000016, 20.000000000000014, 71.29999999999963, -368.5, 20.000000000000014, 200.0, 20.000000000000014, 197.0, 20.000000000000014, 73.99999999999999, 158.0, 158.3, 191.9, 6.500000000000125, 192.8, 20.000000000000014, 170.0, 173.0, 108.80000000000004, 20.000000000000014, 20.000000000000014, 144.79999999999984, 87.49999999999997, 132.5, 170.0, 74.0000000000001, -194.2, 20.000000000000014, 132.79999999999998, 20.000000000000014, 7.399999999999967, 7.399999999999965, 20.000000000000014, 124.40000000000008, 20.000000000000014, 20.000000000000014, 158.6, 114.49999999999977, 20.000000000000014, 155.9, -51.70000000000016], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.0, 0.0, 0.0, 72.0, 64.0, 0.0, 2.0, 0.0, 16.0, 54.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 6.0, 0.0, 10.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 15.0, 6.0, 0.0, 3.0, 10.0, 0.0, 92.0, 102.0, 2.0, 6.0, 123.0, 112.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 82.0, 48.0, 0.0, 2.0, 0.0, 0.0, 10.0, 0.0, 0.0, 25.0, 0.0, 60.0, 64.0, 69.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 5.0, 5.0, 0.0, 0.0, 7.0, 52.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 0.0, 0.0, 3.0, 17.0, 9.0, 19.0, 29.0, 1.0, 0.0, 0.0, 0.0, 169.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 10.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 136.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 146.0, 176.0, 91.0, 0.0, 0.0, 181.0, 140.0, 0.0, 0.0, 0.0, 1.0, 6.0, 10.0, 10.0, 0.0, 18.0, 0.0, 10.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 16.0, 94.0, 46.0, 5.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 72.0, 13.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4476036093135365, "mean_inference_ms": 4.121598421876843, "mean_action_processing_ms": 0.6992053003336212, "mean_env_wait_ms": 0.8799283918777024, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005440354347229004, "StateBufferConnector_ms": 0.004102230072021484, "ViewRequirementAgentConnector_ms": 0.21891117095947266}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -232.7000000000004, "episode_return_mean": 172.60799999999978, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000, "num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 230.53187058986543, "num_env_steps_trained_throughput_per_sec": 230.53187058986543, "timesteps_total": 336000, "num_env_steps_sampled_lifetime": 336000, "num_agent_steps_sampled_lifetime": 1344000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1344000, "timers": {"training_iteration_time_ms": 17467.047, "restore_workers_time_ms": 0.021, "training_step_time_ms": 17466.956, "sample_time_ms": 4037.456, "learn_time_ms": 13407.553, "learn_throughput": 298.339, "synch_weights_time_ms": 18.199}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 336000, "num_agent_steps_sampled": 1344000, "num_agent_steps_trained": 1344000}, "done": false, "training_iteration": 84, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-17-12", "timestamp": 1723522632, "time_this_iter_s": 17.398944854736328, "time_total_s": 1500.4516575336456, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d68f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1500.4516575336456, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 88.85000000000001, "ram_util_percent": 80.84583333333335}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3263684648813473, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.16902933556564328, "policy_loss": -0.0007338015153195965, "vf_loss": 0.16975769529069243, "vf_explained_var": 0.0048651090374699345, "kl": 0.009784842739641052, "entropy": 0.4588189852458459, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 40.53448824024705, "cur_kl_coeff": 4.2632564145606e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.278849284106461, "policy_loss": -0.0010949166623441867, "vf_loss": 4.2799441948138846, "vf_explained_var": 0.7278850868265465, "kl": 0.001369597824955231, "entropy": 0.9170712671898029, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 159705.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -232.7000000000004, "episode_reward_mean": 165.43299999999982, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": 70.24649999999995, "predator_policy": 12.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-82.00000000000004, 101.19999999999995, 311.79999999999995, 135.39999999999986, 40.0000000000003, 331.1999999999999, 169.59999999999948, -8.499999999999787, 325.8000000000012, 265.8999999999995, 309.8000000000003, 272.5999999999999, 110.80000000000004, 15.49999999999992, 353.2000000000012, 310.5, 292.5999999999999, 213.9999999999993, 400.0, 219.09999999999937, 86.3999999999999, 326.90000000000003, 183.09999999999977, -37.49999999999955, 40.0000000000003, 59.20000000000004, 219.99999999999926, 380.0, 104.79999999999926, -8.40000000000006, 40.0000000000003, 122.19999999999956, 162.89999999999978, 27.100000000000115, 300.80000000000075, 89.49999999999872, 18.799999999999997, 219.99999999999926, 300.9000000000006, 225.2999999999995, 364.0, 341.90000000000134, 219.99999999999926, 210.0999999999993, 194.7999999999993, 65.60000000000014, 110.19999999999987, 353.90000000000003, 287.59999999999985, 169.5999999999995, 218.89999999999927, -201.20000000000107, 210.99999999999932, 127.29999999999976, 147.99999999999957, 380.0, 59.400000000000055, -232.7000000000004, 91.29999999999923, -27.49999999999985, 219.99999999999926, 217.99999999999926, 247.99999999999972, 360.20000000000005, 217.29999999999956, 199.99999999999935, 300.79999999999995, 40.0000000000003, 242.2999999999996, 328.5, 19.79999999999998, 157.79999999999956, 33.400000000000205, 33.400000000000205, 144.3999999999991, 178.59999999999943, 134.4999999999993, 189.20000000000005, 40.9000000000003, 121.99999999999888, 219.99999999999926, 40.0000000000003, 165.99999999999952, 219.99999999999926, 376.6, 40.0000000000003, 108.39999999999921, 40.0000000000003, 298.30000000000075, 40.0000000000003, 143.59999999999948, 90.9, 219.99999999999926, 111.09999999999991, 49.00000000000045, 219.99999999999926, 218.19999999999936, 151.59999999999883, 97.79999999999993, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-309.6999999999999, -7.299999999999901, 131.60000000000002, -93.40000000000039, 118.99999999999999, 192.79999999999995, 31.699999999999996, 103.69999999999997, 20.000000000000014, 20.000000000000014, 141.19999999999993, 170.0, 149.6, 20.000000000000014, 13.699999999999964, -152.20000000000064, 194.0, 129.79999999999967, 200.0, 65.89999999999996, 172.1, 127.69999999999996, 200.0, 47.60000000000012, 140.60000000000002, -89.8000000000007, 20.000000000000014, -137.5000000000007, 200.0, 153.1999999999997, 122.6, 185.9, 98.3, 188.3, 20.000000000000014, 191.0, 200.0, 200.0, 10.099999999999971, 200.0, 20.000000000000014, 55.400000000000084, 131.89999999999998, 185.0, 102.79999999999998, 80.29999999999974, -32.49999999999978, -64.00000000000034, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000008, 20.000000000000014, 200.0, 200.0, 170.0, 35.300000000000196, 69.49999999999969, -72.40000000000006, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 99.19999999999987, 3.8000000000002245, 133.1, 20.000000000000014, -40.89999999999988, 99.79999999999984, 200.0, 20.000000000000014, 69.49999999999977, 170.0, -320.20000000000005, 20.000000000000014, 200.0, 185.0, 110.89999999999944, 164.0, 44.299999999999976, 200.0, 164.0, 146.89999999999966, 191.0, 200.0, 20.000000000000014, 200.0, 1.0999999999999617, 20.000000000000014, 174.79999999999995, 20.000000000000014, 38.59999999999997, 20.000000000000014, 90.19999999999997, 200.0, 143.90000000000003, 194.0, 80.60000000000007, 61.40000000000015, 108.19999999999999, 17.899999999999988, 200.0, -93.4000000000007, -243.80000000000035, 191.0, 20.000000000000014, 20.000000000000014, 107.29999999999998, 127.99999999999999, 20.000000000000014, 170.0, 200.0, 200.0, -286.5999999999999, -179.50000000000026, -320.20000000000016, 20.000000000000014, 71.29999999999963, -368.5, 20.000000000000014, 200.0, 20.000000000000014, 197.0, 20.000000000000014, 73.99999999999999, 158.0, 158.3, 191.9, 6.500000000000125, 192.8, 20.000000000000014, 170.0, 173.0, 108.80000000000004, 20.000000000000014, 20.000000000000014, 144.79999999999984, 87.49999999999997, 132.5, 170.0, 74.0000000000001, -194.2, 20.000000000000014, 132.79999999999998, 20.000000000000014, 7.399999999999967, 7.399999999999965, 20.000000000000014, 124.40000000000008, 20.000000000000014, 20.000000000000014, 158.6, 114.49999999999977, 20.000000000000014, 155.9, -51.70000000000016, 20.90000000000003, 20.000000000000014, 9.499999999999964, 93.49999999999952, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 146.0, 200.0, 20.000000000000014, 200.0, 176.6, 20.000000000000014, 20.000000000000014, 88.39999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 98.29999999999959, 20.000000000000014, 20.000000000000014, 156.49999999999991, -61.90000000000068, 68.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 21.80000000000001, 89.30000000000001, 20.000000000000014, 29.000000000000163, 20.000000000000014, 200.0, 200.0, 9.19999999999998, 20.000000000000014, 131.59999999999957, 5.299999999999965, 66.50000000000009, 20.000000000000014, 200.0], "policy_predator_policy_reward": [123.0, 112.0, 0.0, 63.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 82.0, 48.0, 0.0, 2.0, 0.0, 0.0, 10.0, 0.0, 0.0, 25.0, 0.0, 60.0, 64.0, 69.0, 0.0, 0.0, 0.0, 2.0, 0.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 5.0, 5.0, 0.0, 0.0, 7.0, 52.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 0.0, 0.0, 3.0, 17.0, 9.0, 19.0, 29.0, 1.0, 0.0, 0.0, 0.0, 169.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 10.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 136.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 146.0, 176.0, 91.0, 0.0, 0.0, 181.0, 140.0, 0.0, 0.0, 0.0, 1.0, 6.0, 10.0, 10.0, 0.0, 18.0, 0.0, 10.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 16.0, 94.0, 46.0, 5.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 72.0, 13.0, 0.0, 0.0, 14.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 26.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4477407556090742, "mean_inference_ms": 4.12397209972473, "mean_action_processing_ms": 0.6976384912815083, "mean_env_wait_ms": 0.8802591993652061, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005730032920837402, "StateBufferConnector_ms": 0.004084229469299316, "ViewRequirementAgentConnector_ms": 0.210479736328125}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -232.7000000000004, "episode_return_mean": 165.43299999999982, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000, "num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 273.69901206157436, "num_env_steps_trained_throughput_per_sec": 273.69901206157436, "timesteps_total": 340000, "num_env_steps_sampled_lifetime": 340000, "num_agent_steps_sampled_lifetime": 1360000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1360000, "timers": {"training_iteration_time_ms": 17334.577, "restore_workers_time_ms": 0.021, "training_step_time_ms": 17334.481, "sample_time_ms": 3983.919, "learn_time_ms": 13328.176, "learn_throughput": 300.116, "synch_weights_time_ms": 18.437}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 340000, "num_agent_steps_sampled": 1360000, "num_agent_steps_trained": 1360000}, "done": false, "training_iteration": 85, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-17-27", "timestamp": 1723522647, "time_this_iter_s": 14.665980815887451, "time_total_s": 1515.117638349533, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x330dc5dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1515.117638349533, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 75.85714285714286, "ram_util_percent": 81.23809523809526}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3623684902847917, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.1771621096489961, "policy_loss": -0.0008270478461223541, "vf_loss": 0.17798582696558837, "vf_explained_var": -0.05884429446603886, "kl": 0.005987505546809531, "entropy": 0.3802593034253549, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 53.60160814104257, "cur_kl_coeff": 2.1316282072803e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.51305984996614, "policy_loss": -9.570998588094005e-05, "vf_loss": 4.513155570358196, "vf_explained_var": 0.763593926284679, "kl": 0.000992065757735312, "entropy": 0.9762150364578086, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 161595.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -232.7000000000004, "episode_reward_mean": 155.20399999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": 67.91699999999997, "predator_policy": 9.685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [400.0, 219.09999999999937, 86.3999999999999, 326.90000000000003, 183.09999999999977, -37.49999999999955, 40.0000000000003, 59.20000000000004, 219.99999999999926, 380.0, 104.79999999999926, -8.40000000000006, 40.0000000000003, 122.19999999999956, 162.89999999999978, 27.100000000000115, 300.80000000000075, 89.49999999999872, 18.799999999999997, 219.99999999999926, 300.9000000000006, 225.2999999999995, 364.0, 341.90000000000134, 219.99999999999926, 210.0999999999993, 194.7999999999993, 65.60000000000014, 110.19999999999987, 353.90000000000003, 287.59999999999985, 169.5999999999995, 218.89999999999927, -201.20000000000107, 210.99999999999932, 127.29999999999976, 147.99999999999957, 380.0, 59.400000000000055, -232.7000000000004, 91.29999999999923, -27.49999999999985, 219.99999999999926, 217.99999999999926, 247.99999999999972, 360.20000000000005, 217.29999999999956, 199.99999999999935, 300.79999999999995, 40.0000000000003, 242.2999999999996, 328.5, 19.79999999999998, 157.79999999999956, 33.400000000000205, 33.400000000000205, 144.3999999999991, 178.59999999999943, 134.4999999999993, 189.20000000000005, 40.9000000000003, 121.99999999999888, 219.99999999999926, 40.0000000000003, 165.99999999999952, 219.99999999999926, 376.6, 40.0000000000003, 108.39999999999921, 40.0000000000003, 298.30000000000075, 40.0000000000003, 143.59999999999948, 90.9, 219.99999999999926, 111.09999999999991, 49.00000000000045, 219.99999999999926, 218.19999999999936, 151.59999999999883, 97.79999999999993, 219.99999999999926, 201.99999999999935, 40.0000000000003, 169.2999999999995, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 140.7999999999994, 36.300000000000246, 108.39999999999989, 284.3, 219.99999999999926, 180.19999999999922, 201.99999999999935, 171.8999999999995, 154.29999999999885, 33.3000000000002, 163.6999999999995], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 200.0, 10.099999999999971, 200.0, 20.000000000000014, 55.400000000000084, 131.89999999999998, 185.0, 102.79999999999998, 80.29999999999974, -32.49999999999978, -64.00000000000034, 20.000000000000014, 20.000000000000014, 20.000000000000014, 27.20000000000008, 20.000000000000014, 200.0, 200.0, 170.0, 35.300000000000196, 69.49999999999969, -72.40000000000006, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 99.19999999999987, 3.8000000000002245, 133.1, 20.000000000000014, -40.89999999999988, 99.79999999999984, 200.0, 20.000000000000014, 69.49999999999977, 170.0, -320.20000000000005, 20.000000000000014, 200.0, 185.0, 110.89999999999944, 164.0, 44.299999999999976, 200.0, 164.0, 146.89999999999966, 191.0, 200.0, 20.000000000000014, 200.0, 1.0999999999999617, 20.000000000000014, 174.79999999999995, 20.000000000000014, 38.59999999999997, 20.000000000000014, 90.19999999999997, 200.0, 143.90000000000003, 194.0, 80.60000000000007, 61.40000000000015, 108.19999999999999, 17.899999999999988, 200.0, -93.4000000000007, -243.80000000000035, 191.0, 20.000000000000014, 20.000000000000014, 107.29999999999998, 127.99999999999999, 20.000000000000014, 170.0, 200.0, 200.0, -286.5999999999999, -179.50000000000026, -320.20000000000016, 20.000000000000014, 71.29999999999963, -368.5, 20.000000000000014, 200.0, 20.000000000000014, 197.0, 20.000000000000014, 73.99999999999999, 158.0, 158.3, 191.9, 6.500000000000125, 192.8, 20.000000000000014, 170.0, 173.0, 108.80000000000004, 20.000000000000014, 20.000000000000014, 144.79999999999984, 87.49999999999997, 132.5, 170.0, 74.0000000000001, -194.2, 20.000000000000014, 132.79999999999998, 20.000000000000014, 7.399999999999967, 7.399999999999965, 20.000000000000014, 124.40000000000008, 20.000000000000014, 20.000000000000014, 158.6, 114.49999999999977, 20.000000000000014, 155.9, -51.70000000000016, 20.90000000000003, 20.000000000000014, 9.499999999999964, 93.49999999999952, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 146.0, 200.0, 20.000000000000014, 200.0, 176.6, 20.000000000000014, 20.000000000000014, 88.39999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 98.29999999999959, 20.000000000000014, 20.000000000000014, 156.49999999999991, -61.90000000000068, 68.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 21.80000000000001, 89.30000000000001, 20.000000000000014, 29.000000000000163, 20.000000000000014, 200.0, 200.0, 9.19999999999998, 20.000000000000014, 131.59999999999957, 5.299999999999965, 66.50000000000009, 20.000000000000014, 200.0, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, -57.70000000000035, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 120.79999999999987, 20.000000000000014, 20.000000000000014, 5.299999999999965, 88.39999999999998, 20.000000000000014, 80.30000000000005, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 150.19999999999987, 173.0, 20.000000000000014, 149.9, 20.000000000000014, 20.000000000000014, 134.29999999999959, 20.000000000000014, 5.299999999999965, 136.7, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 9.0, 11.0, 0.0, 5.0, 5.0, 0.0, 0.0, 7.0, 52.0, 0.0, 0.0, 0.0, 12.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 44.0, 0.0, 0.0, 0.0, 3.0, 17.0, 9.0, 19.0, 29.0, 1.0, 0.0, 0.0, 0.0, 169.0, 0.0, 0.0, 0.0, 0.0, 5.0, 7.0, 10.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 136.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 146.0, 176.0, 91.0, 0.0, 0.0, 181.0, 140.0, 0.0, 0.0, 0.0, 1.0, 6.0, 10.0, 10.0, 0.0, 18.0, 0.0, 10.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 16.0, 94.0, 46.0, 5.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 72.0, 13.0, 0.0, 0.0, 14.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 26.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 37.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.445014649943489, "mean_inference_ms": 4.117383116441594, "mean_action_processing_ms": 0.6951779035285639, "mean_env_wait_ms": 0.8788705215500214, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0057991743087768555, "StateBufferConnector_ms": 0.0039327144622802734, "ViewRequirementAgentConnector_ms": 0.20187795162200928}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -232.7000000000004, "episode_return_mean": 155.20399999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000, "num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 280.5966870181524, "num_env_steps_trained_throughput_per_sec": 280.5966870181524, "timesteps_total": 344000, "num_env_steps_sampled_lifetime": 344000, "num_agent_steps_sampled_lifetime": 1376000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1376000, "timers": {"training_iteration_time_ms": 16960.742, "restore_workers_time_ms": 0.02, "training_step_time_ms": 16960.647, "sample_time_ms": 3942.59, "learn_time_ms": 12995.728, "learn_throughput": 307.793, "synch_weights_time_ms": 18.621}, "counters": {"num_env_steps_sampled": 344000, "num_env_steps_trained": 344000, "num_agent_steps_sampled": 1376000, "num_agent_steps_trained": 1376000}, "done": false, "training_iteration": 86, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-17-41", "timestamp": 1723522661, "time_this_iter_s": 14.321928024291992, "time_total_s": 1529.439566373825, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2850670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1529.439566373825, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 68.91428571428573, "ram_util_percent": 83.11904761904762}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.40482498615112883, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.24748366337919991, "policy_loss": -0.0004417424793626187, "vf_loss": 0.24792140983781166, "vf_explained_var": -0.008918806295546275, "kl": 0.007184443529988911, "entropy": 0.45535134507550135, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 42.52255043885695, "cur_kl_coeff": 1.06581410364015e-15, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.122116061367055, "policy_loss": -0.0007741093645414347, "vf_loss": 5.122890156160587, "vf_explained_var": 0.6149214105946678, "kl": 0.0021929461006751864, "entropy": 0.8680513179806805, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 163485.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "env_runners": {"episode_reward_max": 380.0, "episode_reward_min": -232.7000000000004, "episode_reward_mean": 143.32299999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": 63.15149999999996, "predator_policy": 8.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [341.90000000000134, 219.99999999999926, 210.0999999999993, 194.7999999999993, 65.60000000000014, 110.19999999999987, 353.90000000000003, 287.59999999999985, 169.5999999999995, 218.89999999999927, -201.20000000000107, 210.99999999999932, 127.29999999999976, 147.99999999999957, 380.0, 59.400000000000055, -232.7000000000004, 91.29999999999923, -27.49999999999985, 219.99999999999926, 217.99999999999926, 247.99999999999972, 360.20000000000005, 217.29999999999956, 199.99999999999935, 300.79999999999995, 40.0000000000003, 242.2999999999996, 328.5, 19.79999999999998, 157.79999999999956, 33.400000000000205, 33.400000000000205, 144.3999999999991, 178.59999999999943, 134.4999999999993, 189.20000000000005, 40.9000000000003, 121.99999999999888, 219.99999999999926, 40.0000000000003, 165.99999999999952, 219.99999999999926, 376.6, 40.0000000000003, 108.39999999999921, 40.0000000000003, 298.30000000000075, 40.0000000000003, 143.59999999999948, 90.9, 219.99999999999926, 111.09999999999991, 49.00000000000045, 219.99999999999926, 218.19999999999936, 151.59999999999883, 97.79999999999993, 219.99999999999926, 201.99999999999935, 40.0000000000003, 169.2999999999995, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 140.7999999999994, 36.300000000000246, 108.39999999999989, 284.3, 219.99999999999926, 180.19999999999922, 201.99999999999935, 171.8999999999995, 154.29999999999885, 33.3000000000002, 163.6999999999995, 40.0000000000003, 246.49999999999923, 132.19999999999885, 142.89999999999884, 261.39999999999964, 160.5999999999989, 40.0000000000003, 40.0000000000003, 93.79999999999986, 40.0000000000003, 180.69999999999922, 63.10000000000016, 40.0000000000003, 40.0000000000003, 40.0000000000003, 97.79999999999859, 40.0000000000003, 29.600000000000186, -16.099999999999596, 36.70000000000025, 347.0, 340.8, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [146.89999999999966, 191.0, 200.0, 20.000000000000014, 200.0, 1.0999999999999617, 20.000000000000014, 174.79999999999995, 20.000000000000014, 38.59999999999997, 20.000000000000014, 90.19999999999997, 200.0, 143.90000000000003, 194.0, 80.60000000000007, 61.40000000000015, 108.19999999999999, 17.899999999999988, 200.0, -93.4000000000007, -243.80000000000035, 191.0, 20.000000000000014, 20.000000000000014, 107.29999999999998, 127.99999999999999, 20.000000000000014, 170.0, 200.0, 200.0, -286.5999999999999, -179.50000000000026, -320.20000000000016, 20.000000000000014, 71.29999999999963, -368.5, 20.000000000000014, 200.0, 20.000000000000014, 197.0, 20.000000000000014, 73.99999999999999, 158.0, 158.3, 191.9, 6.500000000000125, 192.8, 20.000000000000014, 170.0, 173.0, 108.80000000000004, 20.000000000000014, 20.000000000000014, 144.79999999999984, 87.49999999999997, 132.5, 170.0, 74.0000000000001, -194.2, 20.000000000000014, 132.79999999999998, 20.000000000000014, 7.399999999999967, 7.399999999999965, 20.000000000000014, 124.40000000000008, 20.000000000000014, 20.000000000000014, 158.6, 114.49999999999977, 20.000000000000014, 155.9, -51.70000000000016, 20.90000000000003, 20.000000000000014, 9.499999999999964, 93.49999999999952, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 146.0, 200.0, 20.000000000000014, 200.0, 176.6, 20.000000000000014, 20.000000000000014, 88.39999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 98.29999999999959, 20.000000000000014, 20.000000000000014, 156.49999999999991, -61.90000000000068, 68.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 21.80000000000001, 89.30000000000001, 20.000000000000014, 29.000000000000163, 20.000000000000014, 200.0, 200.0, 9.19999999999998, 20.000000000000014, 131.59999999999957, 5.299999999999965, 66.50000000000009, 20.000000000000014, 200.0, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, -57.70000000000035, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 120.79999999999987, 20.000000000000014, 20.000000000000014, 5.299999999999965, 88.39999999999998, 20.000000000000014, 80.30000000000005, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 150.19999999999987, 173.0, 20.000000000000014, 149.9, 20.000000000000014, 20.000000000000014, 134.29999999999959, 20.000000000000014, 5.299999999999965, 136.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.500000000000192, 200.0, 5.299999999999965, 119.89999999999952, 119.89999999999955, 20.000000000000014, 61.39999999999999, 200.0, 20.000000000000014, 140.59999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 63.800000000000026, 20.000000000000014, 20.000000000000014, 159.19999999999987, 9.49999999999997, 49.69999999999997, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999967, 84.49999999999929, 20.000000000000014, 20.000000000000014, 29.000000000000163, -42.400000000000716, 20.000000000000014, -87.10000000000073, 13.699999999999964, 20.000000000000014, 170.0, 155.0, 176.0, 156.8, 20.000000000000014, 200.0], "policy_predator_policy_reward": [3.0, 1.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 10.0, 0.0, 11.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 136.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 146.0, 176.0, 91.0, 0.0, 0.0, 181.0, 140.0, 0.0, 0.0, 0.0, 1.0, 6.0, 10.0, 10.0, 0.0, 18.0, 0.0, 10.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 16.0, 94.0, 46.0, 5.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 72.0, 13.0, 0.0, 0.0, 14.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 26.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 37.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 7.0, 0.0, 0.0, 6.0, 10.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 5.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 51.0, 0.0, 3.0, 8.0, 14.0, 8.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4399160349903584, "mean_inference_ms": 4.104249292133891, "mean_action_processing_ms": 0.6912650600681636, "mean_env_wait_ms": 0.8757759100133188, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005627274513244629, "StateBufferConnector_ms": 0.0036607980728149414, "ViewRequirementAgentConnector_ms": 0.20880162715911865}, "num_episodes": 23, "episode_return_max": 380.0, "episode_return_min": -232.7000000000004, "episode_return_mean": 143.32299999999975, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000, "num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 287.75359813858734, "num_env_steps_trained_throughput_per_sec": 287.75359813858734, "timesteps_total": 348000, "num_env_steps_sampled_lifetime": 348000, "num_agent_steps_sampled_lifetime": 1392000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1392000, "timers": {"training_iteration_time_ms": 16509.131, "restore_workers_time_ms": 0.021, "training_step_time_ms": 16509.049, "sample_time_ms": 3867.08, "learn_time_ms": 12620.625, "learn_throughput": 316.942, "synch_weights_time_ms": 17.804}, "counters": {"num_env_steps_sampled": 348000, "num_env_steps_trained": 348000, "num_agent_steps_sampled": 1392000, "num_agent_steps_trained": 1392000}, "done": false, "training_iteration": 87, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-17-55", "timestamp": 1723522675, "time_this_iter_s": 13.956234216690063, "time_total_s": 1543.3958005905151, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d47f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1543.3958005905151, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 72.47, "ram_util_percent": 83.35499999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.22986562364788912, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.08620895220058547, "policy_loss": -4.1741652847834365e-05, "vf_loss": 0.08624742132718671, "vf_explained_var": -0.2122961110854275, "kl": 0.0058836067072947085, "entropy": 0.37992581994760605, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 39.89178008957515, "cur_kl_coeff": 5.32907051820075e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.244871314618953, "policy_loss": 0.0005096404995552446, "vf_loss": 4.2443616769931936, "vf_explained_var": 0.7914199083885819, "kl": 0.00208499950211364, "entropy": 0.6854353244973238, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 165375.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "env_runners": {"episode_reward_max": 390.10000000000025, "episode_reward_min": -27.49999999999985, "episode_reward_mean": 155.53399999999976, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -368.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 181.0}, "policy_reward_mean": {"prey_policy": 71.92699999999996, "predator_policy": 5.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-27.49999999999985, 219.99999999999926, 217.99999999999926, 247.99999999999972, 360.20000000000005, 217.29999999999956, 199.99999999999935, 300.79999999999995, 40.0000000000003, 242.2999999999996, 328.5, 19.79999999999998, 157.79999999999956, 33.400000000000205, 33.400000000000205, 144.3999999999991, 178.59999999999943, 134.4999999999993, 189.20000000000005, 40.9000000000003, 121.99999999999888, 219.99999999999926, 40.0000000000003, 165.99999999999952, 219.99999999999926, 376.6, 40.0000000000003, 108.39999999999921, 40.0000000000003, 298.30000000000075, 40.0000000000003, 143.59999999999948, 90.9, 219.99999999999926, 111.09999999999991, 49.00000000000045, 219.99999999999926, 218.19999999999936, 151.59999999999883, 97.79999999999993, 219.99999999999926, 201.99999999999935, 40.0000000000003, 169.2999999999995, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 140.7999999999994, 36.300000000000246, 108.39999999999989, 284.3, 219.99999999999926, 180.19999999999922, 201.99999999999935, 171.8999999999995, 154.29999999999885, 33.3000000000002, 163.6999999999995, 40.0000000000003, 246.49999999999923, 132.19999999999885, 142.89999999999884, 261.39999999999964, 160.5999999999989, 40.0000000000003, 40.0000000000003, 93.79999999999986, 40.0000000000003, 180.69999999999922, 63.10000000000016, 40.0000000000003, 40.0000000000003, 40.0000000000003, 97.79999999999859, 40.0000000000003, 29.600000000000186, -16.099999999999596, 36.70000000000025, 347.0, 340.8, 219.99999999999926, 294.7000000000004, 29.00000000000014, 276.6999999999997, 40.0000000000003, 371.9000000000002, 219.99999999999926, 219.99999999999926, 359.3000000000004, 179.99999999999946, 228.99999999999932, 181.29999999999902, 199.29999999999936, 303.5000000000015, 211.9999999999993, 390.10000000000025, 219.99999999999926, 40.0000000000003, 209.9999999999993], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-368.5, 20.000000000000014, 200.0, 20.000000000000014, 197.0, 20.000000000000014, 73.99999999999999, 158.0, 158.3, 191.9, 6.500000000000125, 192.8, 20.000000000000014, 170.0, 173.0, 108.80000000000004, 20.000000000000014, 20.000000000000014, 144.79999999999984, 87.49999999999997, 132.5, 170.0, 74.0000000000001, -194.2, 20.000000000000014, 132.79999999999998, 20.000000000000014, 7.399999999999967, 7.399999999999965, 20.000000000000014, 124.40000000000008, 20.000000000000014, 20.000000000000014, 158.6, 114.49999999999977, 20.000000000000014, 155.9, -51.70000000000016, 20.90000000000003, 20.000000000000014, 9.499999999999964, 93.49999999999952, 20.000000000000014, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 146.0, 200.0, 20.000000000000014, 200.0, 176.6, 20.000000000000014, 20.000000000000014, 88.39999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 98.29999999999959, 20.000000000000014, 20.000000000000014, 156.49999999999991, -61.90000000000068, 68.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 21.80000000000001, 89.30000000000001, 20.000000000000014, 29.000000000000163, 20.000000000000014, 200.0, 200.0, 9.19999999999998, 20.000000000000014, 131.59999999999957, 5.299999999999965, 66.50000000000009, 20.000000000000014, 200.0, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, -57.70000000000035, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 120.79999999999987, 20.000000000000014, 20.000000000000014, 5.299999999999965, 88.39999999999998, 20.000000000000014, 80.30000000000005, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 150.19999999999987, 173.0, 20.000000000000014, 149.9, 20.000000000000014, 20.000000000000014, 134.29999999999959, 20.000000000000014, 5.299999999999965, 136.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.500000000000192, 200.0, 5.299999999999965, 119.89999999999952, 119.89999999999955, 20.000000000000014, 61.39999999999999, 200.0, 20.000000000000014, 140.59999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 63.800000000000026, 20.000000000000014, 20.000000000000014, 159.19999999999987, 9.49999999999997, 49.69999999999997, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999967, 84.49999999999929, 20.000000000000014, 20.000000000000014, 29.000000000000163, -42.400000000000716, 20.000000000000014, -87.10000000000073, 13.699999999999964, 20.000000000000014, 170.0, 155.0, 176.0, 156.8, 20.000000000000014, 200.0, 200.0, 94.69999999999933, -1.0000000000000062, 20.000000000000014, 200.0, 67.69999999999997, 20.000000000000014, 20.000000000000014, 170.0, 191.89999999999995, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 184.6999999999999, 164.60000000000002, 170.0, -0.9999999999999992, 200.0, 29.0, 161.30000000000007, 20.000000000000014, 179.3, 20.000000000000014, 187.39999999999992, 106.0999999999996, 188.0, 20.000000000000014, 190.09999999999994, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014], "policy_predator_policy_reward": [181.0, 140.0, 0.0, 0.0, 0.0, 1.0, 6.0, 10.0, 10.0, 0.0, 18.0, 0.0, 10.0, 0.0, 19.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 16.0, 94.0, 46.0, 5.0, 0.0, 6.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 72.0, 13.0, 0.0, 0.0, 14.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 26.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 37.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 7.0, 0.0, 0.0, 6.0, 10.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 5.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 51.0, 0.0, 3.0, 8.0, 14.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4344593234946308, "mean_inference_ms": 4.089866206810047, "mean_action_processing_ms": 0.687694209918972, "mean_env_wait_ms": 0.8724664293974358, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005532741546630859, "StateBufferConnector_ms": 0.0035539865493774414, "ViewRequirementAgentConnector_ms": 0.19055306911468506}, "num_episodes": 18, "episode_return_max": 390.10000000000025, "episode_return_min": -27.49999999999985, "episode_return_mean": 155.53399999999976, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000, "num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 276.9237127826551, "num_env_steps_trained_throughput_per_sec": 276.9237127826551, "timesteps_total": 352000, "num_env_steps_sampled_lifetime": 352000, "num_agent_steps_sampled_lifetime": 1408000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1408000, "timers": {"training_iteration_time_ms": 16282.645, "restore_workers_time_ms": 0.047, "training_step_time_ms": 16282.518, "sample_time_ms": 3604.955, "learn_time_ms": 12654.894, "learn_throughput": 316.083, "synch_weights_time_ms": 18.855}, "counters": {"num_env_steps_sampled": 352000, "num_env_steps_trained": 352000, "num_agent_steps_sampled": 1408000, "num_agent_steps_trained": 1408000}, "done": false, "training_iteration": 88, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-18-10", "timestamp": 1723522690, "time_this_iter_s": 14.481590986251831, "time_total_s": 1557.877391576767, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2901a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1557.877391576767, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 77.985, "ram_util_percent": 83.57}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3645318168570243, "cur_kl_coeff": 0.0005561828613281247, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.2480159382143664, "policy_loss": -0.00036358702459702734, "vf_loss": 0.24837750336956035, "vf_explained_var": 0.0412254203248907, "kl": 0.0036361800844267604, "entropy": 0.3559607959455914, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 40.71255916514725, "cur_kl_coeff": 2.664535259100375e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.1135963796938535, "policy_loss": -0.0015511246231783714, "vf_loss": 5.115147506244599, "vf_explained_var": 0.732374524124085, "kl": 0.0028796196466708895, "entropy": 0.754824589705341, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 167265.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "env_runners": {"episode_reward_max": 390.10000000000025, "episode_reward_min": -16.099999999999596, "episode_reward_mean": 161.23499999999973, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -87.10000000000073, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 51.0}, "policy_reward_mean": {"prey_policy": 77.60749999999996, "predator_policy": 3.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [40.0000000000003, 165.99999999999952, 219.99999999999926, 376.6, 40.0000000000003, 108.39999999999921, 40.0000000000003, 298.30000000000075, 40.0000000000003, 143.59999999999948, 90.9, 219.99999999999926, 111.09999999999991, 49.00000000000045, 219.99999999999926, 218.19999999999936, 151.59999999999883, 97.79999999999993, 219.99999999999926, 201.99999999999935, 40.0000000000003, 169.2999999999995, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 140.7999999999994, 36.300000000000246, 108.39999999999989, 284.3, 219.99999999999926, 180.19999999999922, 201.99999999999935, 171.8999999999995, 154.29999999999885, 33.3000000000002, 163.6999999999995, 40.0000000000003, 246.49999999999923, 132.19999999999885, 142.89999999999884, 261.39999999999964, 160.5999999999989, 40.0000000000003, 40.0000000000003, 93.79999999999986, 40.0000000000003, 180.69999999999922, 63.10000000000016, 40.0000000000003, 40.0000000000003, 40.0000000000003, 97.79999999999859, 40.0000000000003, 29.600000000000186, -16.099999999999596, 36.70000000000025, 347.0, 340.8, 219.99999999999926, 294.7000000000004, 29.00000000000014, 276.6999999999997, 40.0000000000003, 371.9000000000002, 219.99999999999926, 219.99999999999926, 359.3000000000004, 179.99999999999946, 228.99999999999932, 181.29999999999902, 199.29999999999936, 303.5000000000015, 211.9999999999993, 390.10000000000025, 219.99999999999926, 40.0000000000003, 209.9999999999993, 292.7999999999998, 298.1000000000006, 163.5999999999995, 162.39999999999947, 236.89999999999958, 40.0000000000003, 195.89999999999938, 334.8999999999999, 140.29999999999907, 211.9999999999993, 126.39999999999878, 280.9999999999998, 219.99999999999926, 156.99999999999955, 216.69999999999928, 199.99999999999935, 190.79999999999941, 215.59999999999928, 61.60000000000039, 35.600000000000236, 338.8, 71.30000000000001], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 20.000000000000014, 20.000000000000014, 146.0, 200.0, 20.000000000000014, 200.0, 176.6, 20.000000000000014, 20.000000000000014, 88.39999999999966, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 98.29999999999959, 20.000000000000014, 20.000000000000014, 156.49999999999991, -61.90000000000068, 68.89999999999998, 20.000000000000014, 20.000000000000014, 200.0, 21.80000000000001, 89.30000000000001, 20.000000000000014, 29.000000000000163, 20.000000000000014, 200.0, 200.0, 9.19999999999998, 20.000000000000014, 131.59999999999957, 5.299999999999965, 66.50000000000009, 20.000000000000014, 200.0, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, -57.70000000000035, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 120.79999999999987, 20.000000000000014, 20.000000000000014, 5.299999999999965, 88.39999999999998, 20.000000000000014, 80.30000000000005, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 150.19999999999987, 173.0, 20.000000000000014, 149.9, 20.000000000000014, 20.000000000000014, 134.29999999999959, 20.000000000000014, 5.299999999999965, 136.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.500000000000192, 200.0, 5.299999999999965, 119.89999999999952, 119.89999999999955, 20.000000000000014, 61.39999999999999, 200.0, 20.000000000000014, 140.59999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 63.800000000000026, 20.000000000000014, 20.000000000000014, 159.19999999999987, 9.49999999999997, 49.69999999999997, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999967, 84.49999999999929, 20.000000000000014, 20.000000000000014, 29.000000000000163, -42.400000000000716, 20.000000000000014, -87.10000000000073, 13.699999999999964, 20.000000000000014, 170.0, 155.0, 176.0, 156.8, 20.000000000000014, 200.0, 200.0, 94.69999999999933, -1.0000000000000062, 20.000000000000014, 200.0, 67.69999999999997, 20.000000000000014, 20.000000000000014, 170.0, 191.89999999999995, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 184.6999999999999, 164.60000000000002, 170.0, -0.9999999999999992, 200.0, 29.0, 161.30000000000007, 20.000000000000014, 179.3, 20.000000000000014, 187.39999999999992, 106.0999999999996, 188.0, 20.000000000000014, 190.09999999999994, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 87.79999999999998, 200.0, 100.09999999999962, 197.0, 131.60000000000005, 20.000000000000014, 142.39999999999995, 20.000000000000014, 56.90000000000005, 170.0, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 182.0, 182.0, 146.90000000000006, 117.79999999999967, 9.499999999999964, 188.0, 20.000000000000014, 106.39999999999947, 20.000000000000014, 101.00000000000006, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 137.0, 13.699999999999964, 200.0, 20.000000000000014, 164.0, 15.799999999999963, 173.0, 200.0, 11.599999999999968, 20.000000000000014, 41.60000000000012, 20.000000000000014, 11.599999999999964, 200.0, 138.79999999999998, 72.19999999999999, -19.899999999999757], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 26.0, 0.0, 0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 37.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 7.0, 0.0, 0.0, 6.0, 10.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 5.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 51.0, 0.0, 3.0, 8.0, 14.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 11.0, 6.0, 6.0, 0.0, 13.0, 0.0, 4.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 10.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 19.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4194247785627447, "mean_inference_ms": 4.0487061773727815, "mean_action_processing_ms": 0.6790802717201132, "mean_env_wait_ms": 0.8623370249499558, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004530668258666992, "StateBufferConnector_ms": 0.0033729076385498047, "ViewRequirementAgentConnector_ms": 0.15749096870422363}, "num_episodes": 22, "episode_return_max": 390.10000000000025, "episode_return_min": -16.099999999999596, "episode_return_mean": 161.23499999999973, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000, "num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 232.50390454494033, "num_env_steps_trained_throughput_per_sec": 232.50390454494033, "timesteps_total": 356000, "num_env_steps_sampled_lifetime": 356000, "num_agent_steps_sampled_lifetime": 1424000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1424000, "timers": {"training_iteration_time_ms": 16297.18, "restore_workers_time_ms": 0.047, "training_step_time_ms": 16297.06, "sample_time_ms": 3470.234, "learn_time_ms": 12804.096, "learn_throughput": 312.4, "synch_weights_time_ms": 19.302}, "counters": {"num_env_steps_sampled": 356000, "num_env_steps_trained": 356000, "num_agent_steps_sampled": 1424000, "num_agent_steps_trained": 1424000}, "done": false, "training_iteration": 89, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-18-27", "timestamp": 1723522707, "time_this_iter_s": 17.27332305908203, "time_total_s": 1575.150714635849, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d68280>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1575.150714635849, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 79.236, "ram_util_percent": 83.30400000000002}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6916687991036466, "cur_kl_coeff": 0.00027809143066406236, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.3339234647296725, "policy_loss": -0.0003067811992926099, "vf_loss": 1.3342298125779186, "vf_explained_var": 0.001892341413195171, "kl": 0.0015549499661764452, "entropy": 0.2887254049144094, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 28.509204468115296, "cur_kl_coeff": 1.3322676295501876e-16, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.934860816329875, "policy_loss": -0.0007641835500382715, "vf_loss": 5.935624996568791, "vf_explained_var": 0.3602341469633516, "kl": 0.0014683219939485776, "entropy": 0.7313574689405936, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 169155.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "env_runners": {"episode_reward_max": 390.10000000000025, "episode_reward_min": -143.90000000000057, "episode_reward_mean": 158.19499999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.8999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 133.0}, "policy_reward_mean": {"prey_policy": 73.64749999999997, "predator_policy": 5.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 201.99999999999935, 40.0000000000003, 169.2999999999995, 40.0000000000003, 40.0000000000003, 40.0000000000003, 219.99999999999926, 140.7999999999994, 36.300000000000246, 108.39999999999989, 284.3, 219.99999999999926, 180.19999999999922, 201.99999999999935, 171.8999999999995, 154.29999999999885, 33.3000000000002, 163.6999999999995, 40.0000000000003, 246.49999999999923, 132.19999999999885, 142.89999999999884, 261.39999999999964, 160.5999999999989, 40.0000000000003, 40.0000000000003, 93.79999999999986, 40.0000000000003, 180.69999999999922, 63.10000000000016, 40.0000000000003, 40.0000000000003, 40.0000000000003, 97.79999999999859, 40.0000000000003, 29.600000000000186, -16.099999999999596, 36.70000000000025, 347.0, 340.8, 219.99999999999926, 294.7000000000004, 29.00000000000014, 276.6999999999997, 40.0000000000003, 371.9000000000002, 219.99999999999926, 219.99999999999926, 359.3000000000004, 179.99999999999946, 228.99999999999932, 181.29999999999902, 199.29999999999936, 303.5000000000015, 211.9999999999993, 390.10000000000025, 219.99999999999926, 40.0000000000003, 209.9999999999993, 292.7999999999998, 298.1000000000006, 163.5999999999995, 162.39999999999947, 236.89999999999958, 40.0000000000003, 195.89999999999938, 334.8999999999999, 140.29999999999907, 211.9999999999993, 126.39999999999878, 280.9999999999998, 219.99999999999926, 156.99999999999955, 216.69999999999928, 199.99999999999935, 190.79999999999941, 215.59999999999928, 61.60000000000039, 35.600000000000236, 338.8, 71.30000000000001, 125.49999999999977, 73.70000000000002, 155.79999999999959, 44.60000000000022, 40.5, -143.90000000000057, 99.89999999999944, 40.0000000000003, 205.99999999999932, 203.79999999999933, 250.39999999999966, 43.00000000000037, 212.59999999999943, 219.99999999999926, -39.19999999999986, 256.69999999999925, 318.09999999999957, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 200.0, 173.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, -57.70000000000035, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 200.0, 20.000000000000014, 120.79999999999987, 20.000000000000014, 20.000000000000014, 5.299999999999965, 88.39999999999998, 20.000000000000014, 80.30000000000005, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 150.19999999999987, 173.0, 20.000000000000014, 149.9, 20.000000000000014, 20.000000000000014, 134.29999999999959, 20.000000000000014, 5.299999999999965, 136.7, 20.000000000000014, 20.000000000000014, 20.000000000000014, 30.500000000000192, 200.0, 5.299999999999965, 119.89999999999952, 119.89999999999955, 20.000000000000014, 61.39999999999999, 200.0, 20.000000000000014, 140.59999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 63.800000000000026, 20.000000000000014, 20.000000000000014, 159.19999999999987, 9.49999999999997, 49.69999999999997, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999967, 84.49999999999929, 20.000000000000014, 20.000000000000014, 29.000000000000163, -42.400000000000716, 20.000000000000014, -87.10000000000073, 13.699999999999964, 20.000000000000014, 170.0, 155.0, 176.0, 156.8, 20.000000000000014, 200.0, 200.0, 94.69999999999933, -1.0000000000000062, 20.000000000000014, 200.0, 67.69999999999997, 20.000000000000014, 20.000000000000014, 170.0, 191.89999999999995, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 184.6999999999999, 164.60000000000002, 170.0, -0.9999999999999992, 200.0, 29.0, 161.30000000000007, 20.000000000000014, 179.3, 20.000000000000014, 187.39999999999992, 106.0999999999996, 188.0, 20.000000000000014, 190.09999999999994, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 87.79999999999998, 200.0, 100.09999999999962, 197.0, 131.60000000000005, 20.000000000000014, 142.39999999999995, 20.000000000000014, 56.90000000000005, 170.0, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 182.0, 182.0, 146.90000000000006, 117.79999999999967, 9.499999999999964, 188.0, 20.000000000000014, 106.39999999999947, 20.000000000000014, 101.00000000000006, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 137.0, 13.699999999999964, 200.0, 20.000000000000014, 164.0, 15.799999999999963, 173.0, 200.0, 11.599999999999968, 20.000000000000014, 41.60000000000012, 20.000000000000014, 11.599999999999964, 200.0, 138.79999999999998, 72.19999999999999, -19.899999999999757, 105.49999999999997, 20.000000000000014, -259.30000000000007, 200.0, -17.799999999999955, 140.59999999999977, 29.0, 11.599999999999968, 19.400000000000034, 1.0999999999999865, -355.8999999999997, 20.000000000000014, 161.29999999999976, -135.40000000000012, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 15.799999999999963, 182.0, 170.0, 70.39999999999996, 26.30000000000013, 13.699999999999964, 167.29999999999998, 35.30000000000006, 200.0, 20.000000000000014, -131.20000000000005, 20.000000000000014, 76.69999999999929, 170.0, 200.0, 118.10000000000011, 200.0, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 9.0, 0.0, 0.0, 37.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 7.0, 0.0, 0.0, 0.0, 34.0, 0.0, 0.0, 10.0, 0.0, 9.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 7.0, 0.0, 7.0, 0.0, 0.0, 6.0, 10.0, 0.0, 7.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 5.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 51.0, 0.0, 3.0, 8.0, 14.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 11.0, 6.0, 6.0, 0.0, 13.0, 0.0, 4.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 10.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 133.0, 0.0, 33.0, 0.0, 4.0, 0.0, 9.0, 11.0, 60.0, 132.0, 0.0, 74.0, 0.0, 0.0, 7.0, 0.0, 0.0, 6.0, 10.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 0.0, 72.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.423360547769782, "mean_inference_ms": 4.063119884993164, "mean_action_processing_ms": 0.6805841619225578, "mean_env_wait_ms": 0.8657687188187395, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0049326419830322266, "StateBufferConnector_ms": 0.008173227310180664, "ViewRequirementAgentConnector_ms": 0.20651233196258545}, "num_episodes": 18, "episode_return_max": 390.10000000000025, "episode_return_min": -143.90000000000057, "episode_return_mean": 158.19499999999974, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000, "num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.1803118026308, "num_env_steps_trained_throughput_per_sec": 199.1803118026308, "timesteps_total": 360000, "num_env_steps_sampled_lifetime": 360000, "num_agent_steps_sampled_lifetime": 1440000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1440000, "timers": {"training_iteration_time_ms": 16453.709, "restore_workers_time_ms": 0.047, "training_step_time_ms": 16453.55, "sample_time_ms": 3495.776, "learn_time_ms": 12934.766, "learn_throughput": 309.244, "synch_weights_time_ms": 19.29}, "counters": {"num_env_steps_sampled": 360000, "num_env_steps_trained": 360000, "num_agent_steps_sampled": 1440000, "num_agent_steps_trained": 1440000}, "done": false, "training_iteration": 90, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-18-47", "timestamp": 1723522727, "time_this_iter_s": 20.15921902656555, "time_total_s": 1595.3099336624146, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x330dc5670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1595.3099336624146, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 84.90357142857142, "ram_util_percent": 82.61428571428573}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9004120831313746, "cur_kl_coeff": 0.00013904571533203118, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.0107840420077088, "policy_loss": -1.7633693657381825e-06, "vf_loss": 1.0107854457759353, "vf_explained_var": 0.0008899182554275271, "kl": 0.002555615307514886, "entropy": 0.39051216500146047, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 32.12893347084207, "cur_kl_coeff": 6.661338147750938e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.9873119175118745, "policy_loss": -0.00180689950655929, "vf_loss": 5.989118815225268, "vf_explained_var": 0.4221931544245866, "kl": 0.002475688786519169, "entropy": 0.6548841597226561, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 171045.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "env_runners": {"episode_reward_max": 392.8, "episode_reward_min": -143.90000000000057, "episode_reward_mean": 167.47199999999984, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.8999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": 76.33099999999996, "predator_policy": 7.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [261.39999999999964, 160.5999999999989, 40.0000000000003, 40.0000000000003, 93.79999999999986, 40.0000000000003, 180.69999999999922, 63.10000000000016, 40.0000000000003, 40.0000000000003, 40.0000000000003, 97.79999999999859, 40.0000000000003, 29.600000000000186, -16.099999999999596, 36.70000000000025, 347.0, 340.8, 219.99999999999926, 294.7000000000004, 29.00000000000014, 276.6999999999997, 40.0000000000003, 371.9000000000002, 219.99999999999926, 219.99999999999926, 359.3000000000004, 179.99999999999946, 228.99999999999932, 181.29999999999902, 199.29999999999936, 303.5000000000015, 211.9999999999993, 390.10000000000025, 219.99999999999926, 40.0000000000003, 209.9999999999993, 292.7999999999998, 298.1000000000006, 163.5999999999995, 162.39999999999947, 236.89999999999958, 40.0000000000003, 195.89999999999938, 334.8999999999999, 140.29999999999907, 211.9999999999993, 126.39999999999878, 280.9999999999998, 219.99999999999926, 156.99999999999955, 216.69999999999928, 199.99999999999935, 190.79999999999941, 215.59999999999928, 61.60000000000039, 35.600000000000236, 338.8, 71.30000000000001, 125.49999999999977, 73.70000000000002, 155.79999999999959, 44.60000000000022, 40.5, -143.90000000000057, 99.89999999999944, 40.0000000000003, 205.99999999999932, 203.79999999999933, 250.39999999999966, 43.00000000000037, 212.59999999999943, 219.99999999999926, -39.19999999999986, 256.69999999999925, 318.09999999999957, 219.99999999999926, 52.60000000000028, 264.9999999999998, 54.20000000000026, 47.50000000000009, -41.399999999999615, 323.4999999999999, 219.99999999999926, 208.99999999999932, 204.7999999999993, 40.70000000000028, 202.89999999999935, 200.79999999999936, 193.89999999999938, 350.0, 274.89999999999964, 40.0000000000003, 272.0, 392.8, 333.200000000001, 214.4999999999993, 50.10000000000043, 123.19999999999986, 131.59999999999977], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [61.39999999999999, 200.0, 20.000000000000014, 140.59999999999962, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 63.800000000000026, 20.000000000000014, 20.000000000000014, 159.19999999999987, 9.49999999999997, 49.69999999999997, 7.399999999999965, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 5.299999999999967, 84.49999999999929, 20.000000000000014, 20.000000000000014, 29.000000000000163, -42.400000000000716, 20.000000000000014, -87.10000000000073, 13.699999999999964, 20.000000000000014, 170.0, 155.0, 176.0, 156.8, 20.000000000000014, 200.0, 200.0, 94.69999999999933, -1.0000000000000062, 20.000000000000014, 200.0, 67.69999999999997, 20.000000000000014, 20.000000000000014, 170.0, 191.89999999999995, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 184.6999999999999, 164.60000000000002, 170.0, -0.9999999999999992, 200.0, 29.0, 161.30000000000007, 20.000000000000014, 179.3, 20.000000000000014, 187.39999999999992, 106.0999999999996, 188.0, 20.000000000000014, 190.09999999999994, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 87.79999999999998, 200.0, 100.09999999999962, 197.0, 131.60000000000005, 20.000000000000014, 142.39999999999995, 20.000000000000014, 56.90000000000005, 170.0, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 182.0, 182.0, 146.90000000000006, 117.79999999999967, 9.499999999999964, 188.0, 20.000000000000014, 106.39999999999947, 20.000000000000014, 101.00000000000006, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 137.0, 13.699999999999964, 200.0, 20.000000000000014, 164.0, 15.799999999999963, 173.0, 200.0, 11.599999999999968, 20.000000000000014, 41.60000000000012, 20.000000000000014, 11.599999999999964, 200.0, 138.79999999999998, 72.19999999999999, -19.899999999999757, 105.49999999999997, 20.000000000000014, -259.30000000000007, 200.0, -17.799999999999955, 140.59999999999977, 29.0, 11.599999999999968, 19.400000000000034, 1.0999999999999865, -355.8999999999997, 20.000000000000014, 161.29999999999976, -135.40000000000012, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 15.799999999999963, 182.0, 170.0, 70.39999999999996, 26.30000000000013, 13.699999999999964, 167.29999999999998, 35.30000000000006, 200.0, 20.000000000000014, -131.20000000000005, 20.000000000000014, 76.69999999999929, 170.0, 200.0, 118.10000000000011, 200.0, 20.000000000000014, 32.600000000000016, 20.000000000000014, 106.39999999999998, 158.59999999999974, 17.899999999999988, 35.29999999999999, 99.19999999999997, -162.70000000000041, -135.4000000000006, 20.000000000000014, 200.0, 123.49999999999999, 200.0, 20.000000000000014, -0.9999999999999846, 200.0, 200.0, -17.199999999999868, 19.699999999999985, 20.000000000000014, 182.9, 20.000000000000014, 20.000000000000014, 174.8, 20.000000000000014, 173.9, 170.0, 170.0, 137.00000000000003, 137.90000000000006, 20.000000000000014, 20.000000000000014, 164.9, 97.10000000000004, 200.0, 192.8, 153.19999999999973, 170.0, 200.0, 9.499999999999964, 3.1999999999999726, 38.900000000000155, 163.99999999999983, -311.79999999999995, 60.500000000000036, 61.10000000000001], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 7.0, 5.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 0.0, 0.0, 0.0, 43.0, 0.0, 0.0, 51.0, 0.0, 3.0, 8.0, 14.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 11.0, 6.0, 6.0, 0.0, 13.0, 0.0, 4.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 10.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 133.0, 0.0, 33.0, 0.0, 4.0, 0.0, 9.0, 11.0, 60.0, 132.0, 0.0, 74.0, 0.0, 0.0, 7.0, 0.0, 0.0, 6.0, 10.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 0.0, 72.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 85.0, 26.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 22.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 5.0, 0.0, 8.0, 110.0, 161.0, 0.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.406991095588965, "mean_inference_ms": 4.024992733817692, "mean_action_processing_ms": 0.6779657457219908, "mean_env_wait_ms": 0.8542459534006216, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005456686019897461, "StateBufferConnector_ms": 0.008236527442932129, "ViewRequirementAgentConnector_ms": 0.19780468940734863}, "num_episodes": 23, "episode_return_max": 392.8, "episode_return_min": -143.90000000000057, "episode_return_mean": 167.47199999999984, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000, "num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 251.87432424213895, "num_env_steps_trained_throughput_per_sec": 251.87432424213895, "timesteps_total": 364000, "num_env_steps_sampled_lifetime": 364000, "num_agent_steps_sampled_lifetime": 1456000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1456000, "timers": {"training_iteration_time_ms": 16151.093, "restore_workers_time_ms": 0.047, "training_step_time_ms": 16150.933, "sample_time_ms": 3097.06, "learn_time_ms": 13030.247, "learn_throughput": 306.978, "synch_weights_time_ms": 20.076}, "counters": {"num_env_steps_sampled": 364000, "num_env_steps_trained": 364000, "num_agent_steps_sampled": 1456000, "num_agent_steps_trained": 1456000}, "done": false, "training_iteration": 91, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-19-03", "timestamp": 1723522743, "time_this_iter_s": 15.975978136062622, "time_total_s": 1611.2859117984772, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4fad5e0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1611.2859117984772, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 76.69130434782609, "ram_util_percent": 83.56521739130433}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2530254854746754, "cur_kl_coeff": 6.952285766601559e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 1.9248637316718935, "policy_loss": -0.0014220862632134447, "vf_loss": 1.9262855739505202, "vf_explained_var": 0.0034105533329898087, "kl": 0.00357955194837222, "entropy": 0.4933508260855599, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 42.87930915513367, "cur_kl_coeff": 3.330669073875469e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 7.133137325004295, "policy_loss": -0.0034582911701084526, "vf_loss": 7.136595604911683, "vf_explained_var": 0.23793296299914204, "kl": 0.004506754174154935, "entropy": 0.806860063599531, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 172935.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "env_runners": {"episode_reward_max": 392.8, "episode_reward_min": -143.90000000000057, "episode_reward_mean": 168.78499999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.8999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": 75.52249999999997, "predator_policy": 8.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 294.7000000000004, 29.00000000000014, 276.6999999999997, 40.0000000000003, 371.9000000000002, 219.99999999999926, 219.99999999999926, 359.3000000000004, 179.99999999999946, 228.99999999999932, 181.29999999999902, 199.29999999999936, 303.5000000000015, 211.9999999999993, 390.10000000000025, 219.99999999999926, 40.0000000000003, 209.9999999999993, 292.7999999999998, 298.1000000000006, 163.5999999999995, 162.39999999999947, 236.89999999999958, 40.0000000000003, 195.89999999999938, 334.8999999999999, 140.29999999999907, 211.9999999999993, 126.39999999999878, 280.9999999999998, 219.99999999999926, 156.99999999999955, 216.69999999999928, 199.99999999999935, 190.79999999999941, 215.59999999999928, 61.60000000000039, 35.600000000000236, 338.8, 71.30000000000001, 125.49999999999977, 73.70000000000002, 155.79999999999959, 44.60000000000022, 40.5, -143.90000000000057, 99.89999999999944, 40.0000000000003, 205.99999999999932, 203.79999999999933, 250.39999999999966, 43.00000000000037, 212.59999999999943, 219.99999999999926, -39.19999999999986, 256.69999999999925, 318.09999999999957, 219.99999999999926, 52.60000000000028, 264.9999999999998, 54.20000000000026, 47.50000000000009, -41.399999999999615, 323.4999999999999, 219.99999999999926, 208.99999999999932, 204.7999999999993, 40.70000000000028, 202.89999999999935, 200.79999999999936, 193.89999999999938, 350.0, 274.89999999999964, 40.0000000000003, 272.0, 392.8, 333.200000000001, 214.4999999999993, 50.10000000000043, 123.19999999999986, 131.59999999999977, 150.6999999999998, 150.09999999999908, 78.69999999999925, 115.29999999999978, 256.8999999999995, 94.39999999999989, 40.0000000000003, 356.8, 36.70000000000025, -25.999999999999837, 26.300000000000065, -11.99999999999989, 135.39999999999873, 123.49999999999878, 40.0000000000003, 260.49999999999994, 145.1999999999992, 34.200000000000095], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [20.000000000000014, 200.0, 200.0, 94.69999999999933, -1.0000000000000062, 20.000000000000014, 200.0, 67.69999999999997, 20.000000000000014, 20.000000000000014, 170.0, 191.89999999999995, 20.000000000000014, 200.0, 20.000000000000014, 200.0, 184.6999999999999, 164.60000000000002, 170.0, -0.9999999999999992, 200.0, 29.0, 161.30000000000007, 20.000000000000014, 179.3, 20.000000000000014, 187.39999999999992, 106.0999999999996, 188.0, 20.000000000000014, 190.09999999999994, 200.0, 200.0, 20.000000000000014, 20.000000000000014, 20.000000000000014, 185.0, 20.000000000000014, 87.79999999999998, 200.0, 100.09999999999962, 197.0, 131.60000000000005, 20.000000000000014, 142.39999999999995, 20.000000000000014, 56.90000000000005, 170.0, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 182.0, 182.0, 146.90000000000006, 117.79999999999967, 9.499999999999964, 188.0, 20.000000000000014, 106.39999999999947, 20.000000000000014, 101.00000000000006, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 137.0, 13.699999999999964, 200.0, 20.000000000000014, 164.0, 15.799999999999963, 173.0, 200.0, 11.599999999999968, 20.000000000000014, 41.60000000000012, 20.000000000000014, 11.599999999999964, 200.0, 138.79999999999998, 72.19999999999999, -19.899999999999757, 105.49999999999997, 20.000000000000014, -259.30000000000007, 200.0, -17.799999999999955, 140.59999999999977, 29.0, 11.599999999999968, 19.400000000000034, 1.0999999999999865, -355.8999999999997, 20.000000000000014, 161.29999999999976, -135.40000000000012, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 15.799999999999963, 182.0, 170.0, 70.39999999999996, 26.30000000000013, 13.699999999999964, 167.29999999999998, 35.30000000000006, 200.0, 20.000000000000014, -131.20000000000005, 20.000000000000014, 76.69999999999929, 170.0, 200.0, 118.10000000000011, 200.0, 20.000000000000014, 32.600000000000016, 20.000000000000014, 106.39999999999998, 158.59999999999974, 17.899999999999988, 35.29999999999999, 99.19999999999997, -162.70000000000041, -135.4000000000006, 20.000000000000014, 200.0, 123.49999999999999, 200.0, 20.000000000000014, -0.9999999999999846, 200.0, 200.0, -17.199999999999868, 19.699999999999985, 20.000000000000014, 182.9, 20.000000000000014, 20.000000000000014, 174.8, 20.000000000000014, 173.9, 170.0, 170.0, 137.00000000000003, 137.90000000000006, 20.000000000000014, 20.000000000000014, 164.9, 97.10000000000004, 200.0, 192.8, 153.19999999999973, 170.0, 200.0, 9.499999999999964, 3.1999999999999726, 38.900000000000155, 163.99999999999983, -311.79999999999995, 60.500000000000036, 61.10000000000001, 130.7000000000001, 20.000000000000014, -22.000000000000014, 151.0999999999997, 49.70000000000009, 20.000000000000014, -141.70000000000053, 170.0, 200.0, 56.89999999999996, 67.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 174.8, 20.000000000000014, 13.699999999999964, 76.39999999999935, -240.4000000000003, 13.99999999999997, -57.6999999999999, -106.9, 17.899999999999988, 115.39999999999947, 20.000000000000014, -1.0000000000000062, 114.49999999999946, 20.000000000000014, 20.000000000000014, 80.3, 171.20000000000002, 100.99999999999972, 39.20000000000022, 22.099999999999966, 1.099999999999983], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 11.0, 6.0, 6.0, 0.0, 13.0, 0.0, 4.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 10.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 133.0, 0.0, 33.0, 0.0, 4.0, 0.0, 9.0, 11.0, 60.0, 132.0, 0.0, 74.0, 0.0, 0.0, 7.0, 0.0, 0.0, 6.0, 10.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 0.0, 72.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 85.0, 26.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 22.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 5.0, 0.0, 8.0, 110.0, 161.0, 0.0, 10.0, 0.0, 0.0, 21.0, 0.0, 9.0, 0.0, 0.0, 87.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 7.0, 2.0, 3.0, 0.0, 7.0, 131.0, 39.0, 31.0, 76.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4154001410198156, "mean_inference_ms": 4.04483769432358, "mean_action_processing_ms": 0.6743986169427117, "mean_env_wait_ms": 0.8607184700869109, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00614774227142334, "StateBufferConnector_ms": 0.008321881294250488, "ViewRequirementAgentConnector_ms": 0.2026427984237671}, "num_episodes": 18, "episode_return_max": 392.8, "episode_return_min": -143.90000000000057, "episode_return_mean": 168.78499999999977, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000, "num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 253.26582583454785, "num_env_steps_trained_throughput_per_sec": 253.26582583454785, "timesteps_total": 368000, "num_env_steps_sampled_lifetime": 368000, "num_agent_steps_sampled_lifetime": 1472000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1472000, "timers": {"training_iteration_time_ms": 16083.203, "restore_workers_time_ms": 0.044, "training_step_time_ms": 16083.059, "sample_time_ms": 2920.77, "learn_time_ms": 13137.343, "learn_throughput": 304.476, "synch_weights_time_ms": 21.076}, "counters": {"num_env_steps_sampled": 368000, "num_env_steps_trained": 368000, "num_agent_steps_sampled": 1472000, "num_agent_steps_trained": 1472000}, "done": false, "training_iteration": 92, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-19-19", "timestamp": 1723522759, "time_this_iter_s": 15.827204942703247, "time_total_s": 1627.1131167411804, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4f03b80>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1627.1131167411804, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 79.84090909090911, "ram_util_percent": 83.37272727272726}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2388508279369306, "cur_kl_coeff": 3.4761428833007795e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.136224695235964, "policy_loss": -0.0005778077253135582, "vf_loss": 2.1368023282005675, "vf_explained_var": 0.0012386618467865797, "kl": 0.00529086228627535, "entropy": 0.46360503999644487, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 32.73213060504545, "cur_kl_coeff": 1.6653345369377344e-17, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.418515235658676, "policy_loss": -0.002252401725177175, "vf_loss": 6.420767631228008, "vf_explained_var": 0.4390220246933125, "kl": 0.0038805911728113118, "entropy": 0.8908038568875146, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 174825.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "env_runners": {"episode_reward_max": 392.8, "episode_reward_min": -143.90000000000057, "episode_reward_mean": 151.38799999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.8999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": 64.66399999999997, "predator_policy": 11.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [209.9999999999993, 292.7999999999998, 298.1000000000006, 163.5999999999995, 162.39999999999947, 236.89999999999958, 40.0000000000003, 195.89999999999938, 334.8999999999999, 140.29999999999907, 211.9999999999993, 126.39999999999878, 280.9999999999998, 219.99999999999926, 156.99999999999955, 216.69999999999928, 199.99999999999935, 190.79999999999941, 215.59999999999928, 61.60000000000039, 35.600000000000236, 338.8, 71.30000000000001, 125.49999999999977, 73.70000000000002, 155.79999999999959, 44.60000000000022, 40.5, -143.90000000000057, 99.89999999999944, 40.0000000000003, 205.99999999999932, 203.79999999999933, 250.39999999999966, 43.00000000000037, 212.59999999999943, 219.99999999999926, -39.19999999999986, 256.69999999999925, 318.09999999999957, 219.99999999999926, 52.60000000000028, 264.9999999999998, 54.20000000000026, 47.50000000000009, -41.399999999999615, 323.4999999999999, 219.99999999999926, 208.99999999999932, 204.7999999999993, 40.70000000000028, 202.89999999999935, 200.79999999999936, 193.89999999999938, 350.0, 274.89999999999964, 40.0000000000003, 272.0, 392.8, 333.200000000001, 214.4999999999993, 50.10000000000043, 123.19999999999986, 131.59999999999977, 150.6999999999998, 150.09999999999908, 78.69999999999925, 115.29999999999978, 256.8999999999995, 94.39999999999989, 40.0000000000003, 356.8, 36.70000000000025, -25.999999999999837, 26.300000000000065, -11.99999999999989, 135.39999999999873, 123.49999999999878, 40.0000000000003, 260.49999999999994, 145.1999999999992, 34.200000000000095, 139.8999999999997, 274.5999999999999, 128.19999999999982, 145.1999999999998, -38.89999999999985, 3.7000000000002125, 174.7999999999992, 131.29999999999987, 79.1999999999999, 209.39999999999918, 229.89999999999932, 40.0000000000003, 59.80000000000027, 211.89999999999975, 46.90000000000022, 387.0, -21.59999999999978, 45.80000000000048], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [185.0, 20.000000000000014, 87.79999999999998, 200.0, 100.09999999999962, 197.0, 131.60000000000005, 20.000000000000014, 142.39999999999995, 20.000000000000014, 56.90000000000005, 170.0, 20.000000000000014, 20.000000000000014, -3.0999999999999615, 182.0, 182.0, 146.90000000000006, 117.79999999999967, 9.499999999999964, 188.0, 20.000000000000014, 106.39999999999947, 20.000000000000014, 101.00000000000006, 170.0, 20.000000000000014, 200.0, 20.000000000000014, 137.0, 13.699999999999964, 200.0, 20.000000000000014, 164.0, 15.799999999999963, 173.0, 200.0, 11.599999999999968, 20.000000000000014, 41.60000000000012, 20.000000000000014, 11.599999999999964, 200.0, 138.79999999999998, 72.19999999999999, -19.899999999999757, 105.49999999999997, 20.000000000000014, -259.30000000000007, 200.0, -17.799999999999955, 140.59999999999977, 29.0, 11.599999999999968, 19.400000000000034, 1.0999999999999865, -355.8999999999997, 20.000000000000014, 161.29999999999976, -135.40000000000012, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 15.799999999999963, 182.0, 170.0, 70.39999999999996, 26.30000000000013, 13.699999999999964, 167.29999999999998, 35.30000000000006, 200.0, 20.000000000000014, -131.20000000000005, 20.000000000000014, 76.69999999999929, 170.0, 200.0, 118.10000000000011, 200.0, 20.000000000000014, 32.600000000000016, 20.000000000000014, 106.39999999999998, 158.59999999999974, 17.899999999999988, 35.29999999999999, 99.19999999999997, -162.70000000000041, -135.4000000000006, 20.000000000000014, 200.0, 123.49999999999999, 200.0, 20.000000000000014, -0.9999999999999846, 200.0, 200.0, -17.199999999999868, 19.699999999999985, 20.000000000000014, 182.9, 20.000000000000014, 20.000000000000014, 174.8, 20.000000000000014, 173.9, 170.0, 170.0, 137.00000000000003, 137.90000000000006, 20.000000000000014, 20.000000000000014, 164.9, 97.10000000000004, 200.0, 192.8, 153.19999999999973, 170.0, 200.0, 9.499999999999964, 3.1999999999999726, 38.900000000000155, 163.99999999999983, -311.79999999999995, 60.500000000000036, 61.10000000000001, 130.7000000000001, 20.000000000000014, -22.000000000000014, 151.0999999999997, 49.70000000000009, 20.000000000000014, -141.70000000000053, 170.0, 200.0, 56.89999999999996, 67.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 174.8, 20.000000000000014, 13.699999999999964, 76.39999999999935, -240.4000000000003, 13.99999999999997, -57.6999999999999, -106.9, 17.899999999999988, 115.39999999999947, 20.000000000000014, -1.0000000000000062, 114.49999999999946, 20.000000000000014, 20.000000000000014, 80.3, 171.20000000000002, 100.99999999999972, 39.20000000000022, 22.099999999999966, 1.099999999999983, -61.90000000000002, 147.8, 191.0, 80.5999999999996, 27.20000000000003, 100.99999999999997, 69.49999999999983, 70.7, -307.60000000000025, 112.69999999999999, 20.000000000000014, -49.30000000000004, 144.79999999999984, 20.000000000000014, 5.299999999999965, 119.0000000000001, -106.00000000000048, 45.199999999999974, 155.00000000000006, 46.40000000000019, 200.0, 29.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.79999999999998, 148.7, 63.19999999999997, 9.499999999999964, 31.40000000000011, 194.0, 191.0, 17.899999999999988, -95.50000000000021, -13.600000000000044, 43.400000000000226], "policy_predator_policy_reward": [5.0, 0.0, 0.0, 5.0, 1.0, 0.0, 0.0, 12.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 11.0, 6.0, 6.0, 0.0, 13.0, 0.0, 4.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 6.0, 10.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 19.0, 0.0, 0.0, 0.0, 133.0, 0.0, 33.0, 0.0, 4.0, 0.0, 9.0, 11.0, 60.0, 132.0, 0.0, 74.0, 0.0, 0.0, 7.0, 0.0, 0.0, 6.0, 10.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 0.0, 72.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 85.0, 26.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 22.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 5.0, 0.0, 8.0, 110.0, 161.0, 0.0, 10.0, 0.0, 0.0, 21.0, 0.0, 9.0, 0.0, 0.0, 87.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 7.0, 2.0, 3.0, 0.0, 7.0, 131.0, 39.0, 31.0, 76.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 11.0, 39.0, 15.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 107.0, 49.0, 0.0, 33.0, 0.0, 10.0, 0.0, 7.0, 75.0, 65.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 56.0, 0.0, 16.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4121687936452019, "mean_inference_ms": 4.037686970092593, "mean_action_processing_ms": 0.6718515323037952, "mean_env_wait_ms": 0.8586263227174865, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006679654121398926, "StateBufferConnector_ms": 0.008324623107910156, "ViewRequirementAgentConnector_ms": 0.22462010383605957}, "num_episodes": 18, "episode_return_max": 392.8, "episode_return_min": -143.90000000000057, "episode_return_mean": 151.38799999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000, "num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 264.45798255441525, "num_env_steps_trained_throughput_per_sec": 264.45798255441525, "timesteps_total": 372000, "num_env_steps_sampled_lifetime": 372000, "num_agent_steps_sampled_lifetime": 1488000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1488000, "timers": {"training_iteration_time_ms": 15865.259, "restore_workers_time_ms": 0.043, "training_step_time_ms": 15865.115, "sample_time_ms": 2702.439, "learn_time_ms": 13136.87, "learn_throughput": 304.487, "synch_weights_time_ms": 21.355}, "counters": {"num_env_steps_sampled": 372000, "num_env_steps_trained": 372000, "num_agent_steps_sampled": 1488000, "num_agent_steps_trained": 1488000}, "done": false, "training_iteration": 93, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-19-34", "timestamp": 1723522774, "time_this_iter_s": 15.205801963806152, "time_total_s": 1642.3189187049866, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x330dc5670>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1642.3189187049866, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 78.14090909090909, "ram_util_percent": 83.3}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8901087957675811, "cur_kl_coeff": 3.4761428833007795e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.6958625624656046, "policy_loss": -0.0005764510610668117, "vf_loss": 0.696438937573127, "vf_explained_var": 0.0027322251645345535, "kl": 0.002176628573180107, "entropy": 0.41631911781729847, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 37.57834781077173, "cur_kl_coeff": 8.326672684688672e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.080437651134672, "policy_loss": -0.0012698105280164373, "vf_loss": 6.08170744123913, "vf_explained_var": 0.5963375588888844, "kl": 0.002334597166741717, "entropy": 0.8016618212379476, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 176715.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -143.90000000000057, "episode_reward_mean": 141.66299999999978, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -355.8999999999997, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": 57.47149999999996, "predator_policy": 13.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [71.30000000000001, 125.49999999999977, 73.70000000000002, 155.79999999999959, 44.60000000000022, 40.5, -143.90000000000057, 99.89999999999944, 40.0000000000003, 205.99999999999932, 203.79999999999933, 250.39999999999966, 43.00000000000037, 212.59999999999943, 219.99999999999926, -39.19999999999986, 256.69999999999925, 318.09999999999957, 219.99999999999926, 52.60000000000028, 264.9999999999998, 54.20000000000026, 47.50000000000009, -41.399999999999615, 323.4999999999999, 219.99999999999926, 208.99999999999932, 204.7999999999993, 40.70000000000028, 202.89999999999935, 200.79999999999936, 193.89999999999938, 350.0, 274.89999999999964, 40.0000000000003, 272.0, 392.8, 333.200000000001, 214.4999999999993, 50.10000000000043, 123.19999999999986, 131.59999999999977, 150.6999999999998, 150.09999999999908, 78.69999999999925, 115.29999999999978, 256.8999999999995, 94.39999999999989, 40.0000000000003, 356.8, 36.70000000000025, -25.999999999999837, 26.300000000000065, -11.99999999999989, 135.39999999999873, 123.49999999999878, 40.0000000000003, 260.49999999999994, 145.1999999999992, 34.200000000000095, 139.8999999999997, 274.5999999999999, 128.19999999999982, 145.1999999999998, -38.89999999999985, 3.7000000000002125, 174.7999999999992, 131.29999999999987, 79.1999999999999, 209.39999999999918, 229.89999999999932, 40.0000000000003, 59.80000000000027, 211.89999999999975, 46.90000000000022, 387.0, -21.59999999999978, 45.80000000000048, 176.99999999999972, 327.39999999999975, 226.69999999999945, -46.09999999999987, 196.5999999999991, 36.70000000000025, 184.09999999999968, 214.6, -85.40000000000103, 15.800000000000237, 196.69999999999936, 219.09999999999926, 129.09999999999968, 199.99999999999935, 111.49999999999973, 40.0000000000003, 400.0, 107.39999999999912, 59.50000000000037, 83.60000000000022, 343.6000000000007, 219.99999999999926], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [72.19999999999999, -19.899999999999757, 105.49999999999997, 20.000000000000014, -259.30000000000007, 200.0, -17.799999999999955, 140.59999999999977, 29.0, 11.599999999999968, 19.400000000000034, 1.0999999999999865, -355.8999999999997, 20.000000000000014, 161.29999999999976, -135.40000000000012, 20.000000000000014, 20.000000000000014, 179.0, 20.000000000000014, 15.799999999999963, 182.0, 170.0, 70.39999999999996, 26.30000000000013, 13.699999999999964, 167.29999999999998, 35.30000000000006, 200.0, 20.000000000000014, -131.20000000000005, 20.000000000000014, 76.69999999999929, 170.0, 200.0, 118.10000000000011, 200.0, 20.000000000000014, 32.600000000000016, 20.000000000000014, 106.39999999999998, 158.59999999999974, 17.899999999999988, 35.29999999999999, 99.19999999999997, -162.70000000000041, -135.4000000000006, 20.000000000000014, 200.0, 123.49999999999999, 200.0, 20.000000000000014, -0.9999999999999846, 200.0, 200.0, -17.199999999999868, 19.699999999999985, 20.000000000000014, 182.9, 20.000000000000014, 20.000000000000014, 174.8, 20.000000000000014, 173.9, 170.0, 170.0, 137.00000000000003, 137.90000000000006, 20.000000000000014, 20.000000000000014, 164.9, 97.10000000000004, 200.0, 192.8, 153.19999999999973, 170.0, 200.0, 9.499999999999964, 3.1999999999999726, 38.900000000000155, 163.99999999999983, -311.79999999999995, 60.500000000000036, 61.10000000000001, 130.7000000000001, 20.000000000000014, -22.000000000000014, 151.0999999999997, 49.70000000000009, 20.000000000000014, -141.70000000000053, 170.0, 200.0, 56.89999999999996, 67.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 174.8, 20.000000000000014, 13.699999999999964, 76.39999999999935, -240.4000000000003, 13.99999999999997, -57.6999999999999, -106.9, 17.899999999999988, 115.39999999999947, 20.000000000000014, -1.0000000000000062, 114.49999999999946, 20.000000000000014, 20.000000000000014, 80.3, 171.20000000000002, 100.99999999999972, 39.20000000000022, 22.099999999999966, 1.099999999999983, -61.90000000000002, 147.8, 191.0, 80.5999999999996, 27.20000000000003, 100.99999999999997, 69.49999999999983, 70.7, -307.60000000000025, 112.69999999999999, 20.000000000000014, -49.30000000000004, 144.79999999999984, 20.000000000000014, 5.299999999999965, 119.0000000000001, -106.00000000000048, 45.199999999999974, 155.00000000000006, 46.40000000000019, 200.0, 29.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.79999999999998, 148.7, 63.19999999999997, 9.499999999999964, 31.40000000000011, 194.0, 191.0, 17.899999999999988, -95.50000000000021, -13.600000000000044, 43.400000000000226, 200.0, -148.00000000000028, 159.49999999999974, 164.89999999999998, 40.69999999999998, 179.0, -110.50000000000011, -55.59999999999991, 176.59999999999985, 20.000000000000014, 20.000000000000014, 13.699999999999964, 113.59999999999991, 66.50000000000001, 103.69999999999997, 101.9, 20.000000000000014, -219.40000000000043, -22.000000000000014, 15.799999999999963, 170.0, 13.699999999999964, 20.000000000000014, 199.1, 9.499999999999964, 113.59999999999997, 170.0, 20.000000000000014, 62.00000000000005, 42.49999999999998, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 82.3999999999996, 59.00000000000017, -32.49999999999984, -99.40000000000052, 91.99999999999997, 155.5999999999998, 182.0, 200.0, 20.000000000000014], "policy_predator_policy_reward": [19.0, 0.0, 0.0, 0.0, 133.0, 0.0, 33.0, 0.0, 4.0, 0.0, 9.0, 11.0, 60.0, 132.0, 0.0, 74.0, 0.0, 0.0, 7.0, 0.0, 0.0, 6.0, 10.0, 0.0, 0.0, 3.0, 10.0, 0.0, 0.0, 0.0, 72.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 85.0, 26.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 22.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 5.0, 0.0, 8.0, 110.0, 161.0, 0.0, 10.0, 0.0, 0.0, 21.0, 0.0, 9.0, 0.0, 0.0, 87.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 7.0, 2.0, 3.0, 0.0, 7.0, 131.0, 39.0, 31.0, 76.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 11.0, 39.0, 15.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 107.0, 49.0, 0.0, 33.0, 0.0, 10.0, 0.0, 7.0, 75.0, 65.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 56.0, 0.0, 16.0, 0.0, 80.0, 45.0, 3.0, 0.0, 0.0, 7.0, 54.0, 66.0, 0.0, 0.0, 3.0, 0.0, 0.0, 4.0, 9.0, 0.0, 73.0, 41.0, 20.0, 2.0, 13.0, 0.0, 0.0, 0.0, 0.0, 6.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 25.0, 8.0, 67.0, 24.0, 6.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4080275187130784, "mean_inference_ms": 4.028707312946867, "mean_action_processing_ms": 0.6687750897104422, "mean_env_wait_ms": 0.8558577378370724, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010250568389892578, "StateBufferConnector_ms": 0.008500218391418457, "ViewRequirementAgentConnector_ms": 0.22818052768707275}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -143.90000000000057, "episode_return_mean": 141.66299999999978, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000, "num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 211.68361951744023, "num_env_steps_trained_throughput_per_sec": 211.68361951744023, "timesteps_total": 376000, "num_env_steps_sampled_lifetime": 376000, "num_agent_steps_sampled_lifetime": 1504000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1504000, "timers": {"training_iteration_time_ms": 16019.754, "restore_workers_time_ms": 0.044, "training_step_time_ms": 16019.609, "sample_time_ms": 2599.439, "learn_time_ms": 13394.543, "learn_throughput": 298.629, "synch_weights_time_ms": 21.373}, "counters": {"num_env_steps_sampled": 376000, "num_env_steps_trained": 376000, "num_agent_steps_sampled": 1504000, "num_agent_steps_trained": 1504000}, "done": false, "training_iteration": 94, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-19-53", "timestamp": 1723522793, "time_this_iter_s": 19.159770727157593, "time_total_s": 1661.4786894321442, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d47430>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1661.4786894321442, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 95.9148148148148, "ram_util_percent": 83.77407407407408}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7312631902053321, "cur_kl_coeff": 1.7380714416503897e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.40261364379730175, "policy_loss": -0.0003934834847256305, "vf_loss": 0.40300703064776294, "vf_explained_var": -0.003692946232185162, "kl": 0.0055666837790250235, "entropy": 0.5111664807512647, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 38.59465342980844, "cur_kl_coeff": 4.163336342344336e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 4.439885582999578, "policy_loss": -0.001378694918282606, "vf_loss": 4.441264279683431, "vf_explained_var": 0.747212635146247, "kl": 0.002145448030622175, "entropy": 0.7599348106081524, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 178605.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -126.1000000000003, "episode_reward_mean": 153.62099999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -311.79999999999995, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 161.0}, "policy_reward_mean": {"prey_policy": 64.63549999999995, "predator_policy": 12.175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 52.60000000000028, 264.9999999999998, 54.20000000000026, 47.50000000000009, -41.399999999999615, 323.4999999999999, 219.99999999999926, 208.99999999999932, 204.7999999999993, 40.70000000000028, 202.89999999999935, 200.79999999999936, 193.89999999999938, 350.0, 274.89999999999964, 40.0000000000003, 272.0, 392.8, 333.200000000001, 214.4999999999993, 50.10000000000043, 123.19999999999986, 131.59999999999977, 150.6999999999998, 150.09999999999908, 78.69999999999925, 115.29999999999978, 256.8999999999995, 94.39999999999989, 40.0000000000003, 356.8, 36.70000000000025, -25.999999999999837, 26.300000000000065, -11.99999999999989, 135.39999999999873, 123.49999999999878, 40.0000000000003, 260.49999999999994, 145.1999999999992, 34.200000000000095, 139.8999999999997, 274.5999999999999, 128.19999999999982, 145.1999999999998, -38.89999999999985, 3.7000000000002125, 174.7999999999992, 131.29999999999987, 79.1999999999999, 209.39999999999918, 229.89999999999932, 40.0000000000003, 59.80000000000027, 211.89999999999975, 46.90000000000022, 387.0, -21.59999999999978, 45.80000000000048, 176.99999999999972, 327.39999999999975, 226.69999999999945, -46.09999999999987, 196.5999999999991, 36.70000000000025, 184.09999999999968, 214.6, -85.40000000000103, 15.800000000000237, 196.69999999999936, 219.09999999999926, 129.09999999999968, 199.99999999999935, 111.49999999999973, 40.0000000000003, 400.0, 107.39999999999912, 59.50000000000037, 83.60000000000022, 343.6000000000007, 219.99999999999926, 211.9999999999993, 207.99999999999932, 219.99999999999926, 74.30000000000015, 191.19999999999945, -126.1000000000003, 219.99999999999926, 237.99999999999937, 230.79999999999944, 239.09999999999954, 219.5999999999995, 236.09999999999957, 98.49999999999989, 160.6000000000001, 367.6, 194.79999999999947, 42.700000000000294, 347.4], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 20.000000000000014, 32.600000000000016, 20.000000000000014, 106.39999999999998, 158.59999999999974, 17.899999999999988, 35.29999999999999, 99.19999999999997, -162.70000000000041, -135.4000000000006, 20.000000000000014, 200.0, 123.49999999999999, 200.0, 20.000000000000014, -0.9999999999999846, 200.0, 200.0, -17.199999999999868, 19.699999999999985, 20.000000000000014, 182.9, 20.000000000000014, 20.000000000000014, 174.8, 20.000000000000014, 173.9, 170.0, 170.0, 137.00000000000003, 137.90000000000006, 20.000000000000014, 20.000000000000014, 164.9, 97.10000000000004, 200.0, 192.8, 153.19999999999973, 170.0, 200.0, 9.499999999999964, 3.1999999999999726, 38.900000000000155, 163.99999999999983, -311.79999999999995, 60.500000000000036, 61.10000000000001, 130.7000000000001, 20.000000000000014, -22.000000000000014, 151.0999999999997, 49.70000000000009, 20.000000000000014, -141.70000000000053, 170.0, 200.0, 56.89999999999996, 67.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 174.8, 20.000000000000014, 13.699999999999964, 76.39999999999935, -240.4000000000003, 13.99999999999997, -57.6999999999999, -106.9, 17.899999999999988, 115.39999999999947, 20.000000000000014, -1.0000000000000062, 114.49999999999946, 20.000000000000014, 20.000000000000014, 80.3, 171.20000000000002, 100.99999999999972, 39.20000000000022, 22.099999999999966, 1.099999999999983, -61.90000000000002, 147.8, 191.0, 80.5999999999996, 27.20000000000003, 100.99999999999997, 69.49999999999983, 70.7, -307.60000000000025, 112.69999999999999, 20.000000000000014, -49.30000000000004, 144.79999999999984, 20.000000000000014, 5.299999999999965, 119.0000000000001, -106.00000000000048, 45.199999999999974, 155.00000000000006, 46.40000000000019, 200.0, 29.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.79999999999998, 148.7, 63.19999999999997, 9.499999999999964, 31.40000000000011, 194.0, 191.0, 17.899999999999988, -95.50000000000021, -13.600000000000044, 43.400000000000226, 200.0, -148.00000000000028, 159.49999999999974, 164.89999999999998, 40.69999999999998, 179.0, -110.50000000000011, -55.59999999999991, 176.59999999999985, 20.000000000000014, 20.000000000000014, 13.699999999999964, 113.59999999999991, 66.50000000000001, 103.69999999999997, 101.9, 20.000000000000014, -219.40000000000043, -22.000000000000014, 15.799999999999963, 170.0, 13.699999999999964, 20.000000000000014, 199.1, 9.499999999999964, 113.59999999999997, 170.0, 20.000000000000014, 62.00000000000005, 42.49999999999998, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 82.3999999999996, 59.00000000000017, -32.49999999999984, -99.40000000000052, 91.99999999999997, 155.5999999999998, 182.0, 200.0, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 200.0, 11.599999999999964, 58.69999999999999, 166.7, 24.500000000000007, -297.1, 20.000000000000014, 20.000000000000014, 200.0, 37.999999999999986, 200.0, 93.80000000000008, 109.99999999999943, 52.09999999999997, 185.0, 41.59999999999998, 167.0, 55.100000000000016, 161.0, 197.29999999999998, -206.8000000000005, 79.39999999999998, 81.19999999999996, 200.0, 167.60000000000002, 174.80000000000004, 20.000000000000014, 22.70000000000001, 20.000000000000014, 172.39999999999998, 152.0], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 85.0, 26.0, 74.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 22.0, 1.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 0.0, 5.0, 0.0, 8.0, 110.0, 161.0, 0.0, 10.0, 0.0, 0.0, 21.0, 0.0, 9.0, 0.0, 0.0, 87.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 7.0, 2.0, 3.0, 0.0, 7.0, 131.0, 39.0, 31.0, 76.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 11.0, 39.0, 15.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 107.0, 49.0, 0.0, 33.0, 0.0, 10.0, 0.0, 7.0, 75.0, 65.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 56.0, 0.0, 16.0, 0.0, 80.0, 45.0, 3.0, 0.0, 0.0, 7.0, 54.0, 66.0, 0.0, 0.0, 3.0, 0.0, 0.0, 4.0, 9.0, 0.0, 73.0, 41.0, 20.0, 2.0, 13.0, 0.0, 0.0, 0.0, 0.0, 6.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 25.0, 8.0, 67.0, 24.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 151.0, 0.0, 0.0, 0.0, 0.0, 18.0, 9.0, 0.0, 2.0, 9.0, 2.0, 10.0, 10.0, 108.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.405331839434441, "mean_inference_ms": 4.021415630592932, "mean_action_processing_ms": 0.6663714342616852, "mean_env_wait_ms": 0.8540921682142678, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010204672813415527, "StateBufferConnector_ms": 0.0036423206329345703, "ViewRequirementAgentConnector_ms": 0.20541226863861084}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -126.1000000000003, "episode_return_mean": 153.62099999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000, "num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 142.1496548600487, "num_env_steps_trained_throughput_per_sec": 142.1496548600487, "timesteps_total": 380000, "num_env_steps_sampled_lifetime": 380000, "num_agent_steps_sampled_lifetime": 1520000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1520000, "timers": {"training_iteration_time_ms": 17372.231, "restore_workers_time_ms": 0.045, "training_step_time_ms": 17372.088, "sample_time_ms": 2947.586, "learn_time_ms": 14398.55, "learn_throughput": 277.806, "synch_weights_time_ms": 21.522}, "counters": {"num_env_steps_sampled": 380000, "num_env_steps_trained": 380000, "num_agent_steps_sampled": 1520000, "num_agent_steps_trained": 1520000}, "done": false, "training_iteration": 95, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-20-22", "timestamp": 1723522822, "time_this_iter_s": 28.366779804229736, "time_total_s": 1689.845469236374, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4fade50>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1689.845469236374, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 94.05, "ram_util_percent": 84.00750000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.0568076934034705, "cur_kl_coeff": 1.7380714416503897e-05, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.9950854194227348, "policy_loss": -0.001227808113224686, "vf_loss": 2.9963132074901035, "vf_explained_var": 0.0017657894936818925, "kl": 0.0031832137522694115, "entropy": 0.4385649518676536, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.96780575020288, "cur_kl_coeff": 2.081668171172168e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.884847469178457, "policy_loss": -0.0012886738614056002, "vf_loss": 6.886136152630761, "vf_explained_var": 0.29306879504017097, "kl": 0.002311186536764936, "entropy": 0.7995622443143653, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 180495.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -182.2000000000005, "episode_reward_mean": 148.55399999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -366.4, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 184.0}, "policy_reward_mean": {"prey_policy": 60.15199999999995, "predator_policy": 14.125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [131.59999999999977, 150.6999999999998, 150.09999999999908, 78.69999999999925, 115.29999999999978, 256.8999999999995, 94.39999999999989, 40.0000000000003, 356.8, 36.70000000000025, -25.999999999999837, 26.300000000000065, -11.99999999999989, 135.39999999999873, 123.49999999999878, 40.0000000000003, 260.49999999999994, 145.1999999999992, 34.200000000000095, 139.8999999999997, 274.5999999999999, 128.19999999999982, 145.1999999999998, -38.89999999999985, 3.7000000000002125, 174.7999999999992, 131.29999999999987, 79.1999999999999, 209.39999999999918, 229.89999999999932, 40.0000000000003, 59.80000000000027, 211.89999999999975, 46.90000000000022, 387.0, -21.59999999999978, 45.80000000000048, 176.99999999999972, 327.39999999999975, 226.69999999999945, -46.09999999999987, 196.5999999999991, 36.70000000000025, 184.09999999999968, 214.6, -85.40000000000103, 15.800000000000237, 196.69999999999936, 219.09999999999926, 129.09999999999968, 199.99999999999935, 111.49999999999973, 40.0000000000003, 400.0, 107.39999999999912, 59.50000000000037, 83.60000000000022, 343.6000000000007, 219.99999999999926, 211.9999999999993, 207.99999999999932, 219.99999999999926, 74.30000000000015, 191.19999999999945, -126.1000000000003, 219.99999999999926, 237.99999999999937, 230.79999999999944, 239.09999999999954, 219.5999999999995, 236.09999999999957, 98.49999999999989, 160.6000000000001, 367.6, 194.79999999999947, 42.700000000000294, 347.4, 94.19999999999959, 265.39999999999975, 29.000000000000128, 138.8999999999988, 218.19999999999925, 56.10000000000009, 237.99999999999977, 371.2000000000007, 165.9999999999991, 48.69999999999999, -182.2000000000005, 223.59999999999928, 219.99999999999926, -51.100000000000286, 400.0, 251.49999999999906, 161.49999999999955, 195.59999999999937, 400.0, 169.99999999999912, 219.99999999999926, 109.3999999999998, -6.500000000000028], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [60.500000000000036, 61.10000000000001, 130.7000000000001, 20.000000000000014, -22.000000000000014, 151.0999999999997, 49.70000000000009, 20.000000000000014, -141.70000000000053, 170.0, 200.0, 56.89999999999996, 67.39999999999996, 20.000000000000014, 20.000000000000014, 20.000000000000014, 173.0, 174.8, 20.000000000000014, 13.699999999999964, 76.39999999999935, -240.4000000000003, 13.99999999999997, -57.6999999999999, -106.9, 17.899999999999988, 115.39999999999947, 20.000000000000014, -1.0000000000000062, 114.49999999999946, 20.000000000000014, 20.000000000000014, 80.3, 171.20000000000002, 100.99999999999972, 39.20000000000022, 22.099999999999966, 1.099999999999983, -61.90000000000002, 147.8, 191.0, 80.5999999999996, 27.20000000000003, 100.99999999999997, 69.49999999999983, 70.7, -307.60000000000025, 112.69999999999999, 20.000000000000014, -49.30000000000004, 144.79999999999984, 20.000000000000014, 5.299999999999965, 119.0000000000001, -106.00000000000048, 45.199999999999974, 155.00000000000006, 46.40000000000019, 200.0, 29.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.79999999999998, 148.7, 63.19999999999997, 9.499999999999964, 31.40000000000011, 194.0, 191.0, 17.899999999999988, -95.50000000000021, -13.600000000000044, 43.400000000000226, 200.0, -148.00000000000028, 159.49999999999974, 164.89999999999998, 40.69999999999998, 179.0, -110.50000000000011, -55.59999999999991, 176.59999999999985, 20.000000000000014, 20.000000000000014, 13.699999999999964, 113.59999999999991, 66.50000000000001, 103.69999999999997, 101.9, 20.000000000000014, -219.40000000000043, -22.000000000000014, 15.799999999999963, 170.0, 13.699999999999964, 20.000000000000014, 199.1, 9.499999999999964, 113.59999999999997, 170.0, 20.000000000000014, 62.00000000000005, 42.49999999999998, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 82.3999999999996, 59.00000000000017, -32.49999999999984, -99.40000000000052, 91.99999999999997, 155.5999999999998, 182.0, 200.0, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 200.0, 11.599999999999964, 58.69999999999999, 166.7, 24.500000000000007, -297.1, 20.000000000000014, 20.000000000000014, 200.0, 37.999999999999986, 200.0, 93.80000000000008, 109.99999999999943, 52.09999999999997, 185.0, 41.59999999999998, 167.0, 55.100000000000016, 161.0, 197.29999999999998, -206.8000000000005, 79.39999999999998, 81.19999999999996, 200.0, 167.60000000000002, 174.80000000000004, 20.000000000000014, 22.70000000000001, 20.000000000000014, 172.39999999999998, 152.0, 57.20000000000014, 20.000000000000014, 79.39999999999975, 179.0, 20.000000000000014, -0.9999999999999846, 124.39999999999952, 9.499999999999964, 46.09999999999997, 172.09999999999982, 118.99999999999949, -250.90000000000003, 163.1, 74.89999999999996, 172.09999999999982, 199.1, 140.59999999999974, 25.40000000000004, -87.10000000000001, 84.79999999999997, -17.80000000000002, -366.4, 200.0, 23.60000000000008, 20.000000000000014, 200.0, -313.89999999999907, 84.79999999999997, 200.0, 200.0, 51.500000000000234, 200.0, 20.000000000000014, 141.5, 170.0, 11.599999999999964, 200.0, 200.0, 61.400000000000176, 101.59999999999974, 200.0, 20.000000000000014, -139.59999999999985, 173.0, -200.5, 20.000000000000014], "policy_predator_policy_reward": [0.0, 10.0, 0.0, 0.0, 21.0, 0.0, 9.0, 0.0, 0.0, 87.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 7.0, 2.0, 3.0, 0.0, 7.0, 131.0, 39.0, 31.0, 76.0, 1.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 9.0, 0.0, 5.0, 0.0, 0.0, 11.0, 39.0, 15.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 107.0, 49.0, 0.0, 33.0, 0.0, 10.0, 0.0, 7.0, 75.0, 65.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 56.0, 0.0, 16.0, 0.0, 80.0, 45.0, 3.0, 0.0, 0.0, 7.0, 54.0, 66.0, 0.0, 0.0, 3.0, 0.0, 0.0, 4.0, 9.0, 0.0, 73.0, 41.0, 20.0, 2.0, 13.0, 0.0, 0.0, 0.0, 0.0, 6.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 25.0, 8.0, 67.0, 24.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 151.0, 0.0, 0.0, 0.0, 0.0, 18.0, 9.0, 0.0, 2.0, 9.0, 2.0, 10.0, 10.0, 108.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 10.0, 10.0, 7.0, 0.0, 7.0, 0.0, 10.0, 0.0, 5.0, 0.0, 0.0, 129.0, 59.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 51.0, 18.0, 184.0, 0.0, 0.0, 0.0, 0.0, 159.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 50.0, 26.0, 102.0, 72.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.403086833628737, "mean_inference_ms": 4.013942117898053, "mean_action_processing_ms": 0.6635858160323014, "mean_env_wait_ms": 0.852393352329333, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00994563102722168, "StateBufferConnector_ms": 0.004656434059143066, "ViewRequirementAgentConnector_ms": 0.21261358261108398}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -182.2000000000005, "episode_return_mean": 148.55399999999975, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000, "num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 199.99453321141416, "num_env_steps_trained_throughput_per_sec": 199.99453321141416, "timesteps_total": 384000, "num_env_steps_sampled_lifetime": 384000, "num_agent_steps_sampled_lifetime": 1536000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1536000, "timers": {"training_iteration_time_ms": 17946.752, "restore_workers_time_ms": 0.048, "training_step_time_ms": 17946.605, "sample_time_ms": 3110.787, "learn_time_ms": 14810.595, "learn_throughput": 270.077, "synch_weights_time_ms": 20.79}, "counters": {"num_env_steps_sampled": 384000, "num_env_steps_trained": 384000, "num_agent_steps_sampled": 1536000, "num_agent_steps_trained": 1536000}, "done": false, "training_iteration": 96, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-20-42", "timestamp": 1723522842, "time_this_iter_s": 20.072676181793213, "time_total_s": 1709.9181454181671, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2877a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1709.9181454181671, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 87.77931034482759, "ram_util_percent": 83.75517241379309}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.1580812266401985, "cur_kl_coeff": 8.690357208251949e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 3.4425549185465254, "policy_loss": -0.0005269815275573699, "vf_loss": 3.443081902196168, "vf_explained_var": 0.0012041960128400691, "kl": 0.0022439480682717936, "entropy": 0.4340234556053051, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 37.064999651530435, "cur_kl_coeff": 1.040834085586084e-18, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.2631214800335115, "policy_loss": -0.0026307683184289585, "vf_loss": 6.265752232516253, "vf_explained_var": 0.2804199340797606, "kl": 0.004345711379048905, "entropy": 0.9390360998728918, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 182385.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -291.8999999999992, "episode_reward_mean": 143.18599999999975, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": 52.717999999999954, "predator_policy": 18.875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.200000000000095, 139.8999999999997, 274.5999999999999, 128.19999999999982, 145.1999999999998, -38.89999999999985, 3.7000000000002125, 174.7999999999992, 131.29999999999987, 79.1999999999999, 209.39999999999918, 229.89999999999932, 40.0000000000003, 59.80000000000027, 211.89999999999975, 46.90000000000022, 387.0, -21.59999999999978, 45.80000000000048, 176.99999999999972, 327.39999999999975, 226.69999999999945, -46.09999999999987, 196.5999999999991, 36.70000000000025, 184.09999999999968, 214.6, -85.40000000000103, 15.800000000000237, 196.69999999999936, 219.09999999999926, 129.09999999999968, 199.99999999999935, 111.49999999999973, 40.0000000000003, 400.0, 107.39999999999912, 59.50000000000037, 83.60000000000022, 343.6000000000007, 219.99999999999926, 211.9999999999993, 207.99999999999932, 219.99999999999926, 74.30000000000015, 191.19999999999945, -126.1000000000003, 219.99999999999926, 237.99999999999937, 230.79999999999944, 239.09999999999954, 219.5999999999995, 236.09999999999957, 98.49999999999989, 160.6000000000001, 367.6, 194.79999999999947, 42.700000000000294, 347.4, 94.19999999999959, 265.39999999999975, 29.000000000000128, 138.8999999999988, 218.19999999999925, 56.10000000000009, 237.99999999999977, 371.2000000000007, 165.9999999999991, 48.69999999999999, -182.2000000000005, 223.59999999999928, 219.99999999999926, -51.100000000000286, 400.0, 251.49999999999906, 161.49999999999955, 195.59999999999937, 400.0, 169.99999999999912, 219.99999999999926, 109.3999999999998, -6.500000000000028, -291.8999999999992, 110.59999999999872, -39.29999999999958, -2.800000000000086, 51.90000000000014, 105.69999999999993, 195.79999999999913, 225.2999999999992, 197.09999999999917, -63.40000000000019, -120.8000000000003, 378.0, 146.19999999999962, 139.99999999999937, 349.59999999999997, 138.59999999999977, 219.99999999999926, -173.3000000000006], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [22.099999999999966, 1.099999999999983, -61.90000000000002, 147.8, 191.0, 80.5999999999996, 27.20000000000003, 100.99999999999997, 69.49999999999983, 70.7, -307.60000000000025, 112.69999999999999, 20.000000000000014, -49.30000000000004, 144.79999999999984, 20.000000000000014, 5.299999999999965, 119.0000000000001, -106.00000000000048, 45.199999999999974, 155.00000000000006, 46.40000000000019, 200.0, 29.9, 20.000000000000014, 20.000000000000014, 20.000000000000014, 39.79999999999998, 148.7, 63.19999999999997, 9.499999999999964, 31.40000000000011, 194.0, 191.0, 17.899999999999988, -95.50000000000021, -13.600000000000044, 43.400000000000226, 200.0, -148.00000000000028, 159.49999999999974, 164.89999999999998, 40.69999999999998, 179.0, -110.50000000000011, -55.59999999999991, 176.59999999999985, 20.000000000000014, 20.000000000000014, 13.699999999999964, 113.59999999999991, 66.50000000000001, 103.69999999999997, 101.9, 20.000000000000014, -219.40000000000043, -22.000000000000014, 15.799999999999963, 170.0, 13.699999999999964, 20.000000000000014, 199.1, 9.499999999999964, 113.59999999999997, 170.0, 20.000000000000014, 62.00000000000005, 42.49999999999998, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 82.3999999999996, 59.00000000000017, -32.49999999999984, -99.40000000000052, 91.99999999999997, 155.5999999999998, 182.0, 200.0, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 200.0, 11.599999999999964, 58.69999999999999, 166.7, 24.500000000000007, -297.1, 20.000000000000014, 20.000000000000014, 200.0, 37.999999999999986, 200.0, 93.80000000000008, 109.99999999999943, 52.09999999999997, 185.0, 41.59999999999998, 167.0, 55.100000000000016, 161.0, 197.29999999999998, -206.8000000000005, 79.39999999999998, 81.19999999999996, 200.0, 167.60000000000002, 174.80000000000004, 20.000000000000014, 22.70000000000001, 20.000000000000014, 172.39999999999998, 152.0, 57.20000000000014, 20.000000000000014, 79.39999999999975, 179.0, 20.000000000000014, -0.9999999999999846, 124.39999999999952, 9.499999999999964, 46.09999999999997, 172.09999999999982, 118.99999999999949, -250.90000000000003, 163.1, 74.89999999999996, 172.09999999999982, 199.1, 140.59999999999974, 25.40000000000004, -87.10000000000001, 84.79999999999997, -17.80000000000002, -366.4, 200.0, 23.60000000000008, 20.000000000000014, 200.0, -313.89999999999907, 84.79999999999997, 200.0, 200.0, 51.500000000000234, 200.0, 20.000000000000014, 141.5, 170.0, 11.599999999999964, 200.0, 200.0, 61.400000000000176, 101.59999999999974, 200.0, 20.000000000000014, -139.59999999999985, 173.0, -200.5, 20.000000000000014, -349.59999999999997, -217.30000000000038, 20.000000000000014, 83.5999999999994, -164.80000000000064, 9.499999999999964, -87.10000000000001, -36.69999999999978, 23.899999999999963, 20.000000000000014, 85.69999999999997, 20.000000000000014, 130.69999999999982, 52.10000000000018, 35.30000000000022, 185.0, 91.99999999999997, 103.09999999999945, -177.40000000000012, 20.000000000000014, -343.30000000000007, 39.500000000000114, 200.0, 167.0, 117.2, 20.000000000000014, 145.09999999999968, -150.10000000000002, 200.0, 149.6, -205.60000000000053, 126.19999999999999, 20.000000000000014, 200.0, 18.199999999999967, -389.5], "policy_predator_policy_reward": [0.0, 11.0, 39.0, 15.0, 3.0, 0.0, 0.0, 0.0, 5.0, 0.0, 107.0, 49.0, 0.0, 33.0, 0.0, 10.0, 0.0, 7.0, 75.0, 65.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 2.0, 0.0, 56.0, 0.0, 16.0, 0.0, 80.0, 45.0, 3.0, 0.0, 0.0, 7.0, 54.0, 66.0, 0.0, 0.0, 3.0, 0.0, 0.0, 4.0, 9.0, 0.0, 73.0, 41.0, 20.0, 2.0, 13.0, 0.0, 0.0, 0.0, 0.0, 6.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 25.0, 8.0, 67.0, 24.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 151.0, 0.0, 0.0, 0.0, 0.0, 18.0, 9.0, 0.0, 2.0, 9.0, 2.0, 10.0, 10.0, 108.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 10.0, 10.0, 7.0, 0.0, 7.0, 0.0, 10.0, 0.0, 5.0, 0.0, 0.0, 129.0, 59.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 51.0, 18.0, 184.0, 0.0, 0.0, 0.0, 0.0, 159.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 50.0, 26.0, 102.0, 72.0, 90.0, 185.0, 7.0, 0.0, 42.0, 74.0, 50.0, 71.0, 6.0, 2.0, 0.0, 0.0, 10.0, 3.0, 5.0, 0.0, 0.0, 2.0, 0.0, 94.0, 116.0, 67.0, 11.0, 0.0, 0.0, 9.0, 64.0, 81.0, 0.0, 0.0, 123.0, 95.0, 0.0, 0.0, 3.0, 195.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4040869590950142, "mean_inference_ms": 4.014748605364175, "mean_action_processing_ms": 0.6622435229301962, "mean_env_wait_ms": 0.8524182329853133, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027796030044555664, "StateBufferConnector_ms": 0.004848599433898926, "ViewRequirementAgentConnector_ms": 0.21825897693634033}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -291.8999999999992, "episode_return_mean": 143.18599999999975, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000, "num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 171.8048264543216, "num_env_steps_trained_throughput_per_sec": 171.8048264543216, "timesteps_total": 388000, "num_env_steps_sampled_lifetime": 388000, "num_agent_steps_sampled_lifetime": 1552000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1552000, "timers": {"training_iteration_time_ms": 18884.897, "restore_workers_time_ms": 0.047, "training_step_time_ms": 18884.75, "sample_time_ms": 3483.053, "learn_time_ms": 15375.894, "learn_throughput": 260.147, "synch_weights_time_ms": 21.088}, "counters": {"num_env_steps_sampled": 388000, "num_env_steps_trained": 388000, "num_agent_steps_sampled": 1552000, "num_agent_steps_trained": 1552000}, "done": false, "training_iteration": 97, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-21-06", "timestamp": 1723522866, "time_this_iter_s": 23.460803985595703, "time_total_s": 1733.3789494037628, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d47040>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1733.3789494037628, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 92.50625, "ram_util_percent": 83.79374999999999}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9985727869733064, "cur_kl_coeff": 4.345178604125974e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.7578823865800307, "policy_loss": -0.0006584031657665653, "vf_loss": 0.7585407698201755, "vf_explained_var": 0.004423695171951617, "kl": 0.005084013833521283, "entropy": 0.49750199226475267, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 42.309241980314255, "cur_kl_coeff": 5.20417042793042e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 5.972386515582049, "policy_loss": -0.0017973712995333015, "vf_loss": 5.974183879579816, "vf_explained_var": 0.5645407224142993, "kl": 0.003428111062050914, "entropy": 0.8453218594114617, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 184275.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -291.8999999999992, "episode_reward_mean": 144.65999999999974, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": 52.42999999999997, "predator_policy": 19.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-46.09999999999987, 196.5999999999991, 36.70000000000025, 184.09999999999968, 214.6, -85.40000000000103, 15.800000000000237, 196.69999999999936, 219.09999999999926, 129.09999999999968, 199.99999999999935, 111.49999999999973, 40.0000000000003, 400.0, 107.39999999999912, 59.50000000000037, 83.60000000000022, 343.6000000000007, 219.99999999999926, 211.9999999999993, 207.99999999999932, 219.99999999999926, 74.30000000000015, 191.19999999999945, -126.1000000000003, 219.99999999999926, 237.99999999999937, 230.79999999999944, 239.09999999999954, 219.5999999999995, 236.09999999999957, 98.49999999999989, 160.6000000000001, 367.6, 194.79999999999947, 42.700000000000294, 347.4, 94.19999999999959, 265.39999999999975, 29.000000000000128, 138.8999999999988, 218.19999999999925, 56.10000000000009, 237.99999999999977, 371.2000000000007, 165.9999999999991, 48.69999999999999, -182.2000000000005, 223.59999999999928, 219.99999999999926, -51.100000000000286, 400.0, 251.49999999999906, 161.49999999999955, 195.59999999999937, 400.0, 169.99999999999912, 219.99999999999926, 109.3999999999998, -6.500000000000028, -291.8999999999992, 110.59999999999872, -39.29999999999958, -2.800000000000086, 51.90000000000014, 105.69999999999993, 195.79999999999913, 225.2999999999992, 197.09999999999917, -63.40000000000019, -120.8000000000003, 378.0, 146.19999999999962, 139.99999999999937, 349.59999999999997, 138.59999999999977, 219.99999999999926, -173.3000000000006, 45.80000000000003, 32.60000000000017, 177.09999999999948, 126.4, 164.19999999999956, 186.69999999999942, 77.30000000000015, 60.90000000000016, 219.99999999999926, -12.799999999999992, 259.39999999999975, 171.40000000000015, 40.0000000000003, 177.6999999999999, 208.0999999999995, 233.6999999999999, 16.40000000000016, 355.8999999999998, 219.99999999999926, 41.79999999999998, 176.80000000000018, 180.3999999999992], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [-110.50000000000011, -55.59999999999991, 176.59999999999985, 20.000000000000014, 20.000000000000014, 13.699999999999964, 113.59999999999991, 66.50000000000001, 103.69999999999997, 101.9, 20.000000000000014, -219.40000000000043, -22.000000000000014, 15.799999999999963, 170.0, 13.699999999999964, 20.000000000000014, 199.1, 9.499999999999964, 113.59999999999997, 170.0, 20.000000000000014, 62.00000000000005, 42.49999999999998, 20.000000000000014, 20.000000000000014, 200.0, 200.0, 20.000000000000014, 82.3999999999996, 59.00000000000017, -32.49999999999984, -99.40000000000052, 91.99999999999997, 155.5999999999998, 182.0, 200.0, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 200.0, 11.599999999999964, 58.69999999999999, 166.7, 24.500000000000007, -297.1, 20.000000000000014, 20.000000000000014, 200.0, 37.999999999999986, 200.0, 93.80000000000008, 109.99999999999943, 52.09999999999997, 185.0, 41.59999999999998, 167.0, 55.100000000000016, 161.0, 197.29999999999998, -206.8000000000005, 79.39999999999998, 81.19999999999996, 200.0, 167.60000000000002, 174.80000000000004, 20.000000000000014, 22.70000000000001, 20.000000000000014, 172.39999999999998, 152.0, 57.20000000000014, 20.000000000000014, 79.39999999999975, 179.0, 20.000000000000014, -0.9999999999999846, 124.39999999999952, 9.499999999999964, 46.09999999999997, 172.09999999999982, 118.99999999999949, -250.90000000000003, 163.1, 74.89999999999996, 172.09999999999982, 199.1, 140.59999999999974, 25.40000000000004, -87.10000000000001, 84.79999999999997, -17.80000000000002, -366.4, 200.0, 23.60000000000008, 20.000000000000014, 200.0, -313.89999999999907, 84.79999999999997, 200.0, 200.0, 51.500000000000234, 200.0, 20.000000000000014, 141.5, 170.0, 11.599999999999964, 200.0, 200.0, 61.400000000000176, 101.59999999999974, 200.0, 20.000000000000014, -139.59999999999985, 173.0, -200.5, 20.000000000000014, -349.59999999999997, -217.30000000000038, 20.000000000000014, 83.5999999999994, -164.80000000000064, 9.499999999999964, -87.10000000000001, -36.69999999999978, 23.899999999999963, 20.000000000000014, 85.69999999999997, 20.000000000000014, 130.69999999999982, 52.10000000000018, 35.30000000000022, 185.0, 91.99999999999997, 103.09999999999945, -177.40000000000012, 20.000000000000014, -343.30000000000007, 39.500000000000114, 200.0, 167.0, 117.2, 20.000000000000014, 145.09999999999968, -150.10000000000002, 200.0, 149.6, -205.60000000000053, 126.19999999999999, 20.000000000000014, 200.0, 18.199999999999967, -389.5, 137.00000000000003, -215.20000000000013, -11.499999999999819, 28.10000000000016, 13.699999999999964, 160.4, -349.60000000000014, 200.0, 22.70000000000001, 141.5, 20.000000000000014, 166.7, 70.40000000000008, -9.099999999999993, -19.600000000000136, 36.50000000000021, 200.0, 20.000000000000014, -3.0999999999999615, -57.69999999999992, 79.39999999999998, 170.0, 71.29999999999998, 91.10000000000007, 20.000000000000014, 20.000000000000014, 58.7, 118.99999999999999, 156.50000000000003, 41.600000000000115, 54.50000000000009, 144.2, 44.299999999999976, -250.90000000000026, 200.0, 155.90000000000006, 20.000000000000014, 200.0, 20.000000000000014, -11.199999999999854, 89.30000000000003, 87.49999999999997, 20.000000000000014, 160.39999999999986], "policy_predator_policy_reward": [54.0, 66.0, 0.0, 0.0, 3.0, 0.0, 0.0, 4.0, 9.0, 0.0, 73.0, 41.0, 20.0, 2.0, 13.0, 0.0, 0.0, 0.0, 0.0, 6.0, 10.0, 0.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 25.0, 8.0, 67.0, 24.0, 6.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 151.0, 0.0, 0.0, 0.0, 0.0, 18.0, 9.0, 0.0, 2.0, 9.0, 2.0, 10.0, 10.0, 108.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 10.0, 10.0, 7.0, 0.0, 7.0, 0.0, 10.0, 0.0, 5.0, 0.0, 0.0, 129.0, 59.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 51.0, 18.0, 184.0, 0.0, 0.0, 0.0, 0.0, 159.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 50.0, 26.0, 102.0, 72.0, 90.0, 185.0, 7.0, 0.0, 42.0, 74.0, 50.0, 71.0, 6.0, 2.0, 0.0, 0.0, 10.0, 3.0, 5.0, 0.0, 0.0, 2.0, 0.0, 94.0, 116.0, 67.0, 11.0, 0.0, 0.0, 9.0, 64.0, 81.0, 0.0, 0.0, 123.0, 95.0, 0.0, 0.0, 3.0, 195.0, 0.0, 124.0, 5.0, 11.0, 3.0, 0.0, 176.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 44.0, 0.0, 0.0, 37.0, 11.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 29.0, 6.0, 94.0, 129.0, 0.0, 0.0, 0.0, 0.0, 4.0, 29.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.399172189624773, "mean_inference_ms": 3.997419579671811, "mean_action_processing_ms": 0.6570395126905004, "mean_env_wait_ms": 0.8475278852802436, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.027187824249267578, "StateBufferConnector_ms": 0.004691720008850098, "ViewRequirementAgentConnector_ms": 0.23677325248718262}, "num_episodes": 22, "episode_return_max": 400.0, "episode_return_min": -291.8999999999992, "episode_return_mean": 144.65999999999974, "episodes_this_iter": 22}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000, "num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 190.6680677829494, "num_env_steps_trained_throughput_per_sec": 190.6680677829494, "timesteps_total": 392000, "num_env_steps_sampled_lifetime": 392000, "num_agent_steps_sampled_lifetime": 1568000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1568000, "timers": {"training_iteration_time_ms": 19538.343, "restore_workers_time_ms": 0.02, "training_step_time_ms": 19538.243, "sample_time_ms": 3679.638, "learn_time_ms": 15832.437, "learn_throughput": 252.646, "synch_weights_time_ms": 21.537}, "counters": {"num_env_steps_sampled": 392000, "num_env_steps_trained": 392000, "num_agent_steps_sampled": 1568000, "num_agent_steps_trained": 1568000}, "done": false, "training_iteration": 98, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-21-27", "timestamp": 1723522887, "time_this_iter_s": 21.104180097579956, "time_total_s": 1754.4831295013428, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b4d75dc0>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1754.4831295013428, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 96.91333333333334, "ram_util_percent": 82.89000000000001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4705066872179193, "cur_kl_coeff": 4.345178604125974e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 2.252008706299716, "policy_loss": -0.0012336794402765692, "vf_loss": 2.2532423900233374, "vf_explained_var": 0.0014389924271396859, "kl": 0.004425574240385831, "entropy": 0.4921122189709749, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 42.6303210749828, "cur_kl_coeff": 2.60208521396521e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.691549312248432, "policy_loss": -0.0009546865832316812, "vf_loss": 6.6925039957440084, "vf_explained_var": 0.3906177764216428, "kl": 0.002435774112964773, "entropy": 0.8848812959812306, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 186165.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -291.8999999999992, "episode_reward_mean": 143.21299999999968, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": 49.47649999999998, "predator_policy": 22.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [219.99999999999926, 211.9999999999993, 207.99999999999932, 219.99999999999926, 74.30000000000015, 191.19999999999945, -126.1000000000003, 219.99999999999926, 237.99999999999937, 230.79999999999944, 239.09999999999954, 219.5999999999995, 236.09999999999957, 98.49999999999989, 160.6000000000001, 367.6, 194.79999999999947, 42.700000000000294, 347.4, 94.19999999999959, 265.39999999999975, 29.000000000000128, 138.8999999999988, 218.19999999999925, 56.10000000000009, 237.99999999999977, 371.2000000000007, 165.9999999999991, 48.69999999999999, -182.2000000000005, 223.59999999999928, 219.99999999999926, -51.100000000000286, 400.0, 251.49999999999906, 161.49999999999955, 195.59999999999937, 400.0, 169.99999999999912, 219.99999999999926, 109.3999999999998, -6.500000000000028, -291.8999999999992, 110.59999999999872, -39.29999999999958, -2.800000000000086, 51.90000000000014, 105.69999999999993, 195.79999999999913, 225.2999999999992, 197.09999999999917, -63.40000000000019, -120.8000000000003, 378.0, 146.19999999999962, 139.99999999999937, 349.59999999999997, 138.59999999999977, 219.99999999999926, -173.3000000000006, 45.80000000000003, 32.60000000000017, 177.09999999999948, 126.4, 164.19999999999956, 186.69999999999942, 77.30000000000015, 60.90000000000016, 219.99999999999926, -12.799999999999992, 259.39999999999975, 171.40000000000015, 40.0000000000003, 177.6999999999999, 208.0999999999995, 233.6999999999999, 16.40000000000016, 355.8999999999998, 219.99999999999926, 41.79999999999998, 176.80000000000018, 180.3999999999992, 272.1999999999998, 62.70000000000006, 213.29999999999924, 58.40000000000021, 24.900000000000077, -68.79999999999998, 181.69999999999914, 207.3999999999993, 214.4999999999993, 207.99999999999932, 97.6, 180.39999999999998, 97.09999999999863, 19.100000000000204, 214.9999999999993, 166.0999999999995, 72.50000000000031, 40.0000000000003], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [200.0, 20.000000000000014, 188.0, 20.000000000000014, 20.000000000000014, 182.0, 20.000000000000014, 200.0, 11.599999999999964, 58.69999999999999, 166.7, 24.500000000000007, -297.1, 20.000000000000014, 20.000000000000014, 200.0, 37.999999999999986, 200.0, 93.80000000000008, 109.99999999999943, 52.09999999999997, 185.0, 41.59999999999998, 167.0, 55.100000000000016, 161.0, 197.29999999999998, -206.8000000000005, 79.39999999999998, 81.19999999999996, 200.0, 167.60000000000002, 174.80000000000004, 20.000000000000014, 22.70000000000001, 20.000000000000014, 172.39999999999998, 152.0, 57.20000000000014, 20.000000000000014, 79.39999999999975, 179.0, 20.000000000000014, -0.9999999999999846, 124.39999999999952, 9.499999999999964, 46.09999999999997, 172.09999999999982, 118.99999999999949, -250.90000000000003, 163.1, 74.89999999999996, 172.09999999999982, 199.1, 140.59999999999974, 25.40000000000004, -87.10000000000001, 84.79999999999997, -17.80000000000002, -366.4, 200.0, 23.60000000000008, 20.000000000000014, 200.0, -313.89999999999907, 84.79999999999997, 200.0, 200.0, 51.500000000000234, 200.0, 20.000000000000014, 141.5, 170.0, 11.599999999999964, 200.0, 200.0, 61.400000000000176, 101.59999999999974, 200.0, 20.000000000000014, -139.59999999999985, 173.0, -200.5, 20.000000000000014, -349.59999999999997, -217.30000000000038, 20.000000000000014, 83.5999999999994, -164.80000000000064, 9.499999999999964, -87.10000000000001, -36.69999999999978, 23.899999999999963, 20.000000000000014, 85.69999999999997, 20.000000000000014, 130.69999999999982, 52.10000000000018, 35.30000000000022, 185.0, 91.99999999999997, 103.09999999999945, -177.40000000000012, 20.000000000000014, -343.30000000000007, 39.500000000000114, 200.0, 167.0, 117.2, 20.000000000000014, 145.09999999999968, -150.10000000000002, 200.0, 149.6, -205.60000000000053, 126.19999999999999, 20.000000000000014, 200.0, 18.199999999999967, -389.5, 137.00000000000003, -215.20000000000013, -11.499999999999819, 28.10000000000016, 13.699999999999964, 160.4, -349.60000000000014, 200.0, 22.70000000000001, 141.5, 20.000000000000014, 166.7, 70.40000000000008, -9.099999999999993, -19.600000000000136, 36.50000000000021, 200.0, 20.000000000000014, -3.0999999999999615, -57.69999999999992, 79.39999999999998, 170.0, 71.29999999999998, 91.10000000000007, 20.000000000000014, 20.000000000000014, 58.7, 118.99999999999999, 156.50000000000003, 41.600000000000115, 54.50000000000009, 144.2, 44.299999999999976, -250.90000000000026, 200.0, 155.90000000000006, 20.000000000000014, 200.0, 20.000000000000014, -11.199999999999854, 89.30000000000003, 87.49999999999997, 20.000000000000014, 160.39999999999986, 182.0, 90.19999999999997, 200.0, -280.2999999999993, 157.69999999999973, 53.59999999999998, 41.59999999999998, -2.1999999999999855, -276.1, 20.000000000000014, 73.9999999999999, -290.79999999999995, 73.99999999999949, 100.69999999999999, 20.000000000000014, 187.39999999999998, 200.0, 9.499999999999979, 182.0, 20.000000000000014, 20.000000000000014, 77.59999999999997, 176.0, -223.60000000000002, 20.000000000000014, 70.09999999999974, -13.600000000000033, 13.69999999999997, 188.0, 20.000000000000014, 154.1, -0.9999999999999846, 48.50000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014], "policy_predator_policy_reward": [0.0, 0.0, 0.0, 4.0, 0.0, 6.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 151.0, 0.0, 0.0, 0.0, 0.0, 18.0, 9.0, 0.0, 2.0, 9.0, 2.0, 10.0, 10.0, 108.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 10.0, 10.0, 7.0, 0.0, 7.0, 0.0, 10.0, 0.0, 5.0, 0.0, 0.0, 129.0, 59.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 51.0, 18.0, 184.0, 0.0, 0.0, 0.0, 0.0, 159.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 50.0, 26.0, 102.0, 72.0, 90.0, 185.0, 7.0, 0.0, 42.0, 74.0, 50.0, 71.0, 6.0, 2.0, 0.0, 0.0, 10.0, 3.0, 5.0, 0.0, 0.0, 2.0, 0.0, 94.0, 116.0, 67.0, 11.0, 0.0, 0.0, 9.0, 64.0, 81.0, 0.0, 0.0, 123.0, 95.0, 0.0, 0.0, 3.0, 195.0, 0.0, 124.0, 5.0, 11.0, 3.0, 0.0, 176.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 44.0, 0.0, 0.0, 37.0, 11.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 29.0, 6.0, 94.0, 129.0, 0.0, 0.0, 0.0, 0.0, 4.0, 29.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 143.0, 0.0, 2.0, 0.0, 9.0, 10.0, 140.0, 141.0, 11.0, 137.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 6.0, 0.0, 0.0, 124.0, 104.0, 0.0, 7.0, 14.0, 5.0, 3.0, 4.0, 10.0, 3.0, 4.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.4094976301192594, "mean_inference_ms": 4.025424537718301, "mean_action_processing_ms": 0.6606225403340099, "mean_env_wait_ms": 0.8540782753161652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02341175079345703, "StateBufferConnector_ms": 0.004770040512084961, "ViewRequirementAgentConnector_ms": 0.24193859100341797}, "num_episodes": 18, "episode_return_max": 400.0, "episode_return_min": -291.8999999999992, "episode_return_mean": 143.21299999999968, "episodes_this_iter": 18}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000, "num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 232.84940225425908, "num_env_steps_trained_throughput_per_sec": 232.84940225425908, "timesteps_total": 396000, "num_env_steps_sampled_lifetime": 396000, "num_agent_steps_sampled_lifetime": 1584000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1584000, "timers": {"training_iteration_time_ms": 19535.792, "restore_workers_time_ms": 0.022, "training_step_time_ms": 19535.688, "sample_time_ms": 3721.29, "learn_time_ms": 15788.677, "learn_throughput": 253.346, "synch_weights_time_ms": 21.029}, "counters": {"num_env_steps_sampled": 396000, "num_env_steps_trained": 396000, "num_agent_steps_sampled": 1584000, "num_agent_steps_trained": 1584000}, "done": false, "training_iteration": 99, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-21-44", "timestamp": 1723522904, "time_this_iter_s": 17.21365714073181, "time_total_s": 1771.6967866420746, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2877a60>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1771.6967866420746, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 80.872, "ram_util_percent": 83.78}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"predator_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.489127365655448, "cur_kl_coeff": 2.172589302062987e-06, "cur_lr": 5.0000000000000016e-05, "total_loss": 0.946000682503458, "policy_loss": -0.0007611682101414002, "vf_loss": 0.9467618477249903, "vf_explained_var": 0.0013328615635160416, "kl": 0.00738972276396679, "entropy": 0.6374386637614518, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}, "prey_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 51.133621862893385, "cur_kl_coeff": 1.301042606982605e-19, "cur_lr": 5.0000000000000016e-05, "total_loss": 6.84453574034272, "policy_loss": -0.002710260272213312, "vf_loss": 6.847246014125764, "vf_explained_var": 0.44020573247677436, "kl": 0.020347193898898688, "entropy": 1.135920513275439, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 126.98412698412699, "num_grad_updates_lifetime": 188055.5, "diff_num_grad_updates_vs_sampler_policy": 944.5}}, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "env_runners": {"episode_reward_max": 400.0, "episode_reward_min": -291.8999999999992, "episode_reward_mean": 128.23099999999977, "episode_len_mean": 200.0, "episode_media": {}, "episodes_timesteps_total": 20000, "policy_reward_min": {"prey_policy": -389.5, "predator_policy": 0.0}, "policy_reward_max": {"prey_policy": 200.0, "predator_policy": 195.0}, "policy_reward_mean": {"prey_policy": 39.58549999999998, "predator_policy": 24.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [218.19999999999925, 56.10000000000009, 237.99999999999977, 371.2000000000007, 165.9999999999991, 48.69999999999999, -182.2000000000005, 223.59999999999928, 219.99999999999926, -51.100000000000286, 400.0, 251.49999999999906, 161.49999999999955, 195.59999999999937, 400.0, 169.99999999999912, 219.99999999999926, 109.3999999999998, -6.500000000000028, -291.8999999999992, 110.59999999999872, -39.29999999999958, -2.800000000000086, 51.90000000000014, 105.69999999999993, 195.79999999999913, 225.2999999999992, 197.09999999999917, -63.40000000000019, -120.8000000000003, 378.0, 146.19999999999962, 139.99999999999937, 349.59999999999997, 138.59999999999977, 219.99999999999926, -173.3000000000006, 45.80000000000003, 32.60000000000017, 177.09999999999948, 126.4, 164.19999999999956, 186.69999999999942, 77.30000000000015, 60.90000000000016, 219.99999999999926, -12.799999999999992, 259.39999999999975, 171.40000000000015, 40.0000000000003, 177.6999999999999, 208.0999999999995, 233.6999999999999, 16.40000000000016, 355.8999999999998, 219.99999999999926, 41.79999999999998, 176.80000000000018, 180.3999999999992, 272.1999999999998, 62.70000000000006, 213.29999999999924, 58.40000000000021, 24.900000000000077, -68.79999999999998, 181.69999999999914, 207.3999999999993, 214.4999999999993, 207.99999999999932, 97.6, 180.39999999999998, 97.09999999999863, 19.100000000000204, 214.9999999999993, 166.0999999999995, 72.50000000000031, 40.0000000000003, -101.90000000000015, 127.3, 213.3999999999993, 168.6999999999998, 122.19999999999973, 40.0000000000003, 120.79999999999951, 11.900000000000214, -96.6000000000007, 289.3000000000004, 206.39999999999932, 323.50000000000057, 315.7999999999999, 114.69999999999985, 25.700000000000074, 301.00000000000017, 66.20000000000024, 100.29999999999959, 59.80000000000027, 29.20000000000013, -160.20000000000056, 40.9000000000003, 305.5], "episode_lengths": [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], "policy_prey_policy_reward": [46.09999999999997, 172.09999999999982, 118.99999999999949, -250.90000000000003, 163.1, 74.89999999999996, 172.09999999999982, 199.1, 140.59999999999974, 25.40000000000004, -87.10000000000001, 84.79999999999997, -17.80000000000002, -366.4, 200.0, 23.60000000000008, 20.000000000000014, 200.0, -313.89999999999907, 84.79999999999997, 200.0, 200.0, 51.500000000000234, 200.0, 20.000000000000014, 141.5, 170.0, 11.599999999999964, 200.0, 200.0, 61.400000000000176, 101.59999999999974, 200.0, 20.000000000000014, -139.59999999999985, 173.0, -200.5, 20.000000000000014, -349.59999999999997, -217.30000000000038, 20.000000000000014, 83.5999999999994, -164.80000000000064, 9.499999999999964, -87.10000000000001, -36.69999999999978, 23.899999999999963, 20.000000000000014, 85.69999999999997, 20.000000000000014, 130.69999999999982, 52.10000000000018, 35.30000000000022, 185.0, 91.99999999999997, 103.09999999999945, -177.40000000000012, 20.000000000000014, -343.30000000000007, 39.500000000000114, 200.0, 167.0, 117.2, 20.000000000000014, 145.09999999999968, -150.10000000000002, 200.0, 149.6, -205.60000000000053, 126.19999999999999, 20.000000000000014, 200.0, 18.199999999999967, -389.5, 137.00000000000003, -215.20000000000013, -11.499999999999819, 28.10000000000016, 13.699999999999964, 160.4, -349.60000000000014, 200.0, 22.70000000000001, 141.5, 20.000000000000014, 166.7, 70.40000000000008, -9.099999999999993, -19.600000000000136, 36.50000000000021, 200.0, 20.000000000000014, -3.0999999999999615, -57.69999999999992, 79.39999999999998, 170.0, 71.29999999999998, 91.10000000000007, 20.000000000000014, 20.000000000000014, 58.7, 118.99999999999999, 156.50000000000003, 41.600000000000115, 54.50000000000009, 144.2, 44.299999999999976, -250.90000000000026, 200.0, 155.90000000000006, 20.000000000000014, 200.0, 20.000000000000014, -11.199999999999854, 89.30000000000003, 87.49999999999997, 20.000000000000014, 160.39999999999986, 182.0, 90.19999999999997, 200.0, -280.2999999999993, 157.69999999999973, 53.59999999999998, 41.59999999999998, -2.1999999999999855, -276.1, 20.000000000000014, 73.9999999999999, -290.79999999999995, 73.99999999999949, 100.69999999999999, 20.000000000000014, 187.39999999999998, 200.0, 9.499999999999979, 182.0, 20.000000000000014, 20.000000000000014, 77.59999999999997, 176.0, -223.60000000000002, 20.000000000000014, 70.09999999999974, -13.600000000000033, 13.69999999999997, 188.0, 20.000000000000014, 154.1, -0.9999999999999846, 48.50000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, 20.000000000000014, -313.9, 107.30000000000015, 20.000000000000014, 7.399999999999965, 200.0, 106.39999999999989, 62.29999999999996, 105.49999999999999, 13.699999999999964, 20.000000000000014, 20.000000000000014, 107.29999999999998, -11.499999999999819, 20.000000000000014, -204.10000000000022, -244.60000000000028, 20.000000000000014, 164.0, 125.29999999999953, 191.9, 9.499999999999964, 155.0, 144.49999999999986, 114.80000000000003, 176.0, 20.000000000000014, 94.69999999999997, 20.000000000000014, -7.299999999999898, 200.0, 100.9999999999999, -59.80000000000062, 56.00000000000019, 24.500000000000007, 75.79999999999978, 28.100000000000023, 31.700000000000124, 7.399999999999965, 15.799999999999963, -362.2, 20.000000000000014, 20.90000000000003, 20.000000000000014, 146.89999999999998, 158.59999999999997], "policy_predator_policy_reward": [0.0, 0.0, 129.0, 59.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 51.0, 18.0, 184.0, 0.0, 0.0, 0.0, 0.0, 159.0, 19.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 4.0, 0.0, 0.0, 7.0, 0.0, 0.0, 0.0, 50.0, 26.0, 102.0, 72.0, 90.0, 185.0, 7.0, 0.0, 42.0, 74.0, 50.0, 71.0, 6.0, 2.0, 0.0, 0.0, 10.0, 3.0, 5.0, 0.0, 0.0, 2.0, 0.0, 94.0, 116.0, 67.0, 11.0, 0.0, 0.0, 9.0, 64.0, 81.0, 0.0, 0.0, 123.0, 95.0, 0.0, 0.0, 3.0, 195.0, 0.0, 124.0, 5.0, 11.0, 3.0, 0.0, 176.0, 100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 44.0, 0.0, 0.0, 37.0, 11.0, 10.0, 0.0, 0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.0, 29.0, 6.0, 94.0, 129.0, 0.0, 0.0, 0.0, 0.0, 4.0, 29.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 143.0, 0.0, 2.0, 0.0, 9.0, 10.0, 140.0, 141.0, 11.0, 137.0, 7.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 6.0, 0.0, 0.0, 124.0, 104.0, 0.0, 7.0, 14.0, 5.0, 3.0, 4.0, 10.0, 3.0, 4.0, 0.0, 0.0, 0.0, 72.0, 120.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 10.0, 15.0, 106.0, 90.0, 2.0, 126.0, 0.0, 0.0, 0.0, 5.0, 10.0, 14.0, 18.0, 7.0, 0.0, 0.0, 0.0, 13.0, 0.0, 0.0, 38.0, 32.0, 0.0, 0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 182.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.398359010486777, "mean_inference_ms": 3.997229278449613, "mean_action_processing_ms": 0.6596902476507686, "mean_env_wait_ms": 0.8449338719219185, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.023086071014404297, "StateBufferConnector_ms": 0.004851698875427246, "ViewRequirementAgentConnector_ms": 0.24291563034057617}, "num_episodes": 23, "episode_return_max": 400.0, "episode_return_min": -291.8999999999992, "episode_return_mean": 128.23099999999977, "episodes_this_iter": 23}, "num_healthy_workers": 9, "num_in_flight_async_sample_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000, "num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 236.93880530035608, "num_env_steps_trained_throughput_per_sec": 236.93880530035608, "timesteps_total": 400000, "num_env_steps_sampled_lifetime": 400000, "num_agent_steps_sampled_lifetime": 1600000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 1600000, "timers": {"training_iteration_time_ms": 19215.762, "restore_workers_time_ms": 0.022, "training_step_time_ms": 19215.696, "sample_time_ms": 3625.91, "learn_time_ms": 15564.476, "learn_throughput": 256.995, "synch_weights_time_ms": 20.9}, "counters": {"num_env_steps_sampled": 400000, "num_env_steps_trained": 400000, "num_agent_steps_sampled": 1600000, "num_agent_steps_trained": 1600000}, "done": true, "training_iteration": 100, "trial_id": "5b7e3_00000", "date": "2024-08-13_00-22-01", "timestamp": 1723522921, "time_this_iter_s": 16.99360418319702, "time_total_s": 1788.6903908252716, "pid": 45178, "hostname": "joys-mbp.lan", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "placement_strategy": "PACK", "num_gpus": 0, "_fake_gpus": false, "num_cpus_for_main_process": 1, "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "enable_rl_module_and_learner": false, "enable_env_runner_and_connector_v2": false, "env": "custom_tag_v0", "env_config": {"num_prey": 2, "num_predators": 2, "prey_speed": 1, "predator_speed": 1, "map_size": 30, "max_steps": 200, "screen_size": 600, "grid_size": 10}, "observation_space": null, "action_space": null, "clip_rewards": null, "normalize_actions": true, "clip_actions": true, "_is_atari": null, "env_task_fn": null, "render_env": false, "action_mask_key": "action_mask", "env_runner_cls": null, "num_env_runners": 9, "num_envs_per_env_runner": 1, "num_cpus_per_env_runner": 1, "num_gpus_per_env_runner": 0, "custom_resources_per_env_runner": {}, "validate_env_runners_after_construction": true, "sample_timeout_s": 60.0, "_env_to_module_connector": null, "add_default_connectors_to_env_to_module_pipeline": true, "_module_to_env_connector": null, "add_default_connectors_to_module_to_env_pipeline": true, "episode_lookback_horizon": 1, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "compress_observations": false, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "enable_tf1_exec_eagerly": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "update_worker_filter_stats": true, "use_worker_filter_stats": true, "enable_connectors": true, "sampler_perf_stats_ema_coef": null, "num_learners": 0, "num_gpus_per_learner": 0, "num_cpus_per_learner": 1, "local_gpu_idx": 0, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "train_batch_size_per_learner": null, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "fcnet_weights_initializer": null, "fcnet_weights_initializer_config": null, "fcnet_bias_initializer": null, "fcnet_bias_initializer_config": null, "conv_filters": null, "conv_activation": "relu", "conv_kernel_initializer": null, "conv_kernel_initializer_config": null, "conv_bias_initializer": null, "conv_bias_initializer_config": null, "conv_transpose_kernel_initializer": null, "conv_transpose_kernel_initializer_config": null, "conv_transpose_bias_initializer": null, "conv_transpose_bias_initializer_config": null, "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "post_fcnet_weights_initializer": null, "post_fcnet_weights_initializer_config": null, "post_fcnet_bias_initializer": null, "post_fcnet_bias_initializer_config": null, "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "lstm_weights_initializer": null, "lstm_weights_initializer_config": null, "lstm_bias_initializer": null, "lstm_bias_initializer_config": null, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "_learner_connector": null, "add_default_connectors_to_learner_pipeline": true, "learner_config_dict": {}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "_per_module_overrides": {}, "count_steps_by": "env_steps", "policy_map_capacity": 100, "policy_mapping_fn": "<function get_policy_mapping_fn at 0x3b2877f70>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "input_read_method": "read_parquet", "input_read_method_kwargs": {}, "input_read_schema": {}, "map_batches_kwargs": {}, "iter_batches_kwargs": {}, "prelearner_class": null, "prelearner_module_synch_period": 10, "dataset_num_iters_per_learner": null, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 120.0, "evaluation_parallel_to_training": false, "evaluation_force_reset_envs_before_iteration": true, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_env_runners": 0, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 10.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "_run_training_always_in_thread": false, "_evaluation_parallel_to_training_wo_thread": false, "ignore_env_runner_failures": false, "recreate_failed_env_runners": false, "max_num_env_runner_restarts": 1000, "delay_between_env_runner_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_env_runner_failures_tolerance": 100, "env_runner_health_probe_timeout_s": 30, "env_runner_restore_timeout_s": 1800, "_model_config_dict": {}, "_rl_module_spec": null, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_initialize_loss_from_dummy_batch": false, "_dont_auto_sync_env_runner_states": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "enable_async_evaluation": -1, "custom_async_evaluation_function": -1, "_enable_rl_module_api": -1, "auto_wrap_old_gym_envs": -1, "disable_env_checking": -1, "always_attach_evaluation_results": -1, "replay_sequence_length": null, "_disable_execution_plan_api": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 128, "mini_batch_size_per_learner": null, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"prey_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}], "predator_policy": [null, "Box(0, 4, (10, 10), uint8)", "Discrete(5)", {}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch"}, "time_since_restore": 1788.6903908252716, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 81.57916666666667, "ram_util_percent": 83.14999999999999}}
